{
    "id": "H-79",
    "original_text": "Beyond PageRank: Machine Learning for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages. We show that we can significantly outperform PageRank using features that are independent of the link structure of the Web. We gain a further boost in accuracy by using data on the frequency at which users visit Web pages. We use RankNet, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics. The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random). Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning. H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval. General Terms Algorithms, Measurement, Performance, Experimentation. 1. INTRODUCTION Over the past decade, the Web has grown exponentially in size. Unfortunately, this growth has not been isolated to good-quality pages. The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly. The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information. Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first. To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking). However, having a good query-independent ranking (static ranking) is also crucially important for a search engine. A good static ranking algorithm provides numerous benefits: • Relevance: The static rank of a page provides a general indicator to the overall quality of the page. This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by static rank. By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found. The more accurate the static rank, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it. Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages. Among other factors, the static rank of a page is used to determine this prioritization. A better static rank thus provides the engine with a higher quality, more upto-date index. Google is often regarded as the first commercially successful search engine. Their ranking was originally based on the PageRank algorithm [5][27]. Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the static ranking of Web pages. Though PageRank has historically been thought to perform quite well, there has yet been little academic evidence to support this claim. Even worse, there has recently been work showing that PageRank may not perform any better than other simple measures on certain tasks. Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than PageRank [32]. They found similar results for the task of finding high quality companies [31]. PageRank has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17]. Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as PageRank. Despite these, the general belief remains among many, both academic and in the public, that PageRank is an essential factor for a good static rank. Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text. In this paper, we show there are a number of simple url- or pagebased features that significantly outperform PageRank (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web. We combine these and other static features using machine learning to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels). A machine learning approach for static ranking has other advantages besides the quality of the ranking. Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages static rank to an undeserved level through questionable techniques, also known as Web spamming). This is particularly true if the feature set is not known. In contrast, a single measure like PageRank can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page. With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank. This flexibility allows a ranking system to rapidly react to new spamming techniques. A machine learning approach to static ranking is also able to take advantage of any advances in the machine learning field. For example, recent work on adversarial classification [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it. Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the static rank. By moving static ranking to a machine learning framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of machine learning. Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet. These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful. For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page. A machine learning approach thus allows rapid development of a good static algorithm in new domains. This papers contribution is a systematic study of static features, including PageRank, for the purposes of (statically) ranking Web pages. Previous studies on PageRank typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages). Also, the performance of PageRank and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering. In contrast, we explore the use of PageRank and other features for the direct task of statically ranking Web pages. We first briefly describe the PageRank algorithm. In Section 3 we introduce RankNet, the machine learning technique used to combine static features into a final ranking. Section 4 describes the static features. The heart of the paper is in Section 5, which presents our experiments and results. We conclude with a discussion of related and future work. 2. PAGERANK The basic idea behind PageRank is simple: a link from a Web page to another can be seen as an endorsement of that page. In general, links are made by people. As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality. We can take advantage of this linkage information to order Web pages according to their perceived quality. Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step. In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links. If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j. The PageRank score for node j is defined as this probability: PR(j)=P(j). Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform). The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page. An alternative view for equation (1) is that each page is assigned a quality, P(j). A page gives an equal share of its quality to each page it points to. PageRank is computationally expensive. Our collection of 5 billion pages contains approximately 370 billion links. Computing PageRank requires iterating over these billions of links multiple times (until convergence). It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them. Though much work has been done on optimizing the PageRank computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3. RANKNET Much work in machine learning has been done on the problems of classification and regression. Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi. The classification problem is to learn a function f that maps yi=f(xi), for all i. When yi is real-valued as well, this is called regression. Static ranking can be seen as a regression problem. If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a regression function that mapped each pages features to their rank. However, this over-constrains the problem we wish to solve. All we really care about is the order of the pages, not the actual value assigned to them. Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them. For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j. The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a regression function, the result of this process is a function (f) that maps feature vectors to real values. This function can still be applied anywhere that a regressionlearned function could be applied. The only difference is the technique used to learn the function. By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do regression techniques. We used RankNet [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function. RankNet is a straightforward modification to the standard neural network back-prop algorithm. As with back-prop, RankNet attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight. The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the RankNet cost function is based on the difference between a pair of network outputs. That is, for each pair of feature vectors <i,j> in the training set, RankNet computes the network outputs oi and oj. Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost. RankNet also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function). In this paper, we used a probability of one for all pairs. In the next section, we will discuss the features used in our feature vectors, xi. 4. FEATURES To apply RankNet (or other machine learning techniques) to the ranking problem, we needed to extract a set of features from each page. We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity). We also optionally used the PageRank of a page as a feature. Below, we describe each of these feature categories in more detail. PageRank We computed PageRank on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages). This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines. Because PageRank is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible. Most previous studies on PageRank used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed PageRank using the standard value of 0.85 for α. Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time. We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN. The data is aggregated into a count, for each Web page, of the number of users who viewed that page. Though popularity data is generally unavailable, there are two other sources for it. The first is from proxy logs. For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus. Unfortunately, proxy data is quite biased and relatively small. Another source, internal to search engines, are records of which results their users clicked on. Such data was used by the search engine Direct Hit, and has recently been explored for dynamic ranking purposes [20]. An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search. The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed. More details are provided in section 5.5. Anchor text and inlinks These features are based on the information associated with links to the page in question. It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc. Page This category consists of features which may be determined by looking at the page (and its URL) alone. We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc. Domain This category contains features that are computed as averages across all pages in the domain. For example, the average number of outlinks on any page and the average PageRank. Many of these features have been used by others for ranking Web pages, particularly the anchor and page features. As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for static ranking. Also, to our knowledge, this is the first study on the use of actual page visitation popularity for static ranking. The closest similar work is on using click-through behavior (that is, which search engine results the users click on) to affect dynamic ranking (see e.g., [20]). Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for feature-based ranking). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages. Unless otherwise specified, fRank was trained with all of the features. 5. EXPERIMENTS In this section, we will demonstrate that we can out perform PageRank by applying machine learning to a straightforward set of features. Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a static ranking, we needed a gold standard defining the correct ordering for a set of pages. For this, we employed a dataset which contains human judgments for 28000 queries. For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges. The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent. There are approximately 500k judgments in all, or an average of 18 ratings per query. The queries are selected by randomly choosing queries from among those issued to the MSN search engine. The probability that a query is selected is proportional to its frequency among all 709 of the queries. As a result, common queries are more likely to be judged than uncommon queries. As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture. The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs search engine). This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query. Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries. This bias is good when evaluating the quality of static ranking for the purposes of index ordering and returning relevant documents. This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries. Because of this bias, however, the results in this paper are not applicable to crawl prioritization. In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages. To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query. The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high static rank. Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query. We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively. Each set contains all of the ratings for a given query, and no query appears in more than one set. The training set was used to train fRank. The validation set was used to select the model that had the highest performance. The test set was used for the final results. This data gives us a query-independent ordering of pages. The goal for a static ranking algorithm will be to reproduce this ordering as closely as possible. In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a static ranking. The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages. If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of relevance for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons. First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score). Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the static rank algorithm orders them correctly. 5.3 Method We trained fRank (a RankNet based neural network) using the following parameters. We used a fully connected 2 layer network. The hidden layer had 10 hidden nodes. The input weights to this layer were all initialized to be zero. The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1]. We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output. The cost function is the pairwise cross entropy cost function as discussed in section 3. The features in the training set were normalized to have zero mean and unit standard deviation. The same linear transformation was then applied to the features in the validation and test sets. For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other. The pairings were chosen uniformly at random (with replacement) from all possible pairings. When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs. Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread. We trained the network for 30 epochs. On each epoch, the training pairs were randomly shuffled. The initial training rate was 0.001. At each epoch, we checked the error on the training set. If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot. The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased. After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement). The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set. We report the pairwise accuracy on the test set, calculated using all possible pairs. These parameters were determined and fixed before the static rank experiments in this paper. In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7]. Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them. The only exception was the popularity features. As with most Web phenomenon, we found that the distribution of site popularity is Zipfian. To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple machine learning methods such as naïve Bayes. In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the PageRank for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms PageRank for the purposes of static ranking. With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of PageRank (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages). Note that one of fRanks input features is the PageRank of the page, so we would expect it to perform no worse than PageRank. The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page. Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 PageRank 56.70 fRank 67.43 There are a number of decisions that go into the computation of PageRank, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc. We were able to obtain a computation of PageRank from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters. It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation. We thus concluded that the quality of the PageRank is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it. We also wanted to find how well each feature set performed. To answer this, for each feature set, we trained and tested fRank using only that set of features. The results are shown in Table 2. As can be seen, every single feature set individually outperformed PageRank on this test. Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets. This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page. This is contrary to the common belief that the Web graph structure is the key to finding a good static ranking of Web pages. Table 2: Results for individual feature sets. Feature Set Accuracy (%) PageRank 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways. This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features. To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study. That is, for each set of features, we trained a network to contain all of the features except that set. We then compared the performance of the resulting network to the performance of the network with all of the features. Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set. Table 3: Ablation study. Shown is the decrease in accuracy when we train a network that has all but the given set of features. The last line is shows the effect of removing the anchor, PageRank, and domain features, hence a model containing no network or link-based information whatsoever. Feature Set Decrease in Accuracy PageRank 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, PageRank & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study. Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set. Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless. Beginning with no features, we greedily added the feature set that improved performance the most. The results are shown in Table 4. For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%. Table 4: fRank performance as feature sets are added. At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets). Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +PageRank 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of PageRank vs. fRank. In Table 5 are the top ten URLs returned for PageRank and for fRank. PageRanks results are heavily weighted towards technology sites. It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc. PageRanks bias toward technology can be explained through two processes. First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime. These generally link back to, in these examples, the Internet Explorer and QuickTime download sites. Consequently, PageRank ranks those pages highly. Though these pages are important, they are not as important as it may seem by looking at the link structure alone. One fix for this is to add information about the link to the PageRank computation, such as the size of the text, whether it was at the bottom of the page, etc. The other bias comes from the fact that the population of Web site authors is different than the population of Web users. Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual visitation popularity of a site (the popularity feature set), is able to eliminate some of that bias. It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked. The results confirm that fRank outperforms PageRank in pairwise accuracy. The two most important feature sets are the page and popularity features. This is surprising, as the page features consisted only of a few (8) simple features. Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best. In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users. For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user. This limited the possible features we could derive from this data. For possible extensions, see section 6.3, future work. For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user. However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP). One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user. Adding this feature dramatically improved the performance of fRank. We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain. We did this by using the set of features shown in Table 6. Table 6: URL functions used to compute the Popularity feature set. Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table. The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question. For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html. As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further. Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data. It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected. In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set. Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank. The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy. In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy. Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions. First, fRank performs significantly better than PageRank, even without any information about the Web graph. Second, the page level and popularity features were the most significant contributors to pairwise accuracy. Third, by collecting more popularity data, we can continue to improve fRanks performance. The popularity data provides two benefits to fRank. First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer. Second, the popularity data is more timely than PageRanks link information. The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6. RELATED AND FUTURE WORK 6.1 Improvements to PageRank Since the original PageRank paper, there has been work on improving it. Much of that work centers on speeding up and parallelizing the computation [15][25]. One recognized problem with PageRank is that of topic drift: A page about dogs will have high PageRank if it is linked to by many pages that themselves have high rank, regardless of their topic. In contrast, a search engine user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs. Hence, a link that is on topic should have higher weight than a link that is not. Richardson and Domingoss Query Dependent PageRank [29] and Haveliwalas Topic-Sensitive PageRank [16] are two approaches that tackle this problem. Other variations to PageRank include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3]. See Langville and Meyer [23] for a good survey of these, and other modifications to PageRank. 6.2 Other related work PageRank is not the only link analysis algorithm used for ranking Web pages. The most well-known other is HITS [22], which is used by the Teoma search engine [30]. HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs. Previous work has shown HITS to perform comparably to PageRank [1]. One field of interest is that of static index pruning (see e.g., Carmel et al. [8]). Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query. The pruning is typically done based on the frequency of query terms. Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search. Similar methods could be incorporated into the static rank (e.g., how many frequent queries contain words found on this page). Others have investigated the effect that PageRank has on the Web at large [9]. They argue that pages with high PageRank are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher PageRank than other pages. The same may occur for the popularity data. If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity. Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure. The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity. One interesting related work is that of Ivory and Hearst [19]. Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience. They used over 100 page level features, as well as features encompassing the performance and structure of the site. This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features. The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set. Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future. Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which search engine results are clicked on. Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking. Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall relevance of a search engine (i.e., the dynamic ranking). They do not apply their techniques to the problem of static ranking. 6.3 Future work There are many ways in which we would like to extend this work. First, fRank uses only a small number of features. We believe we could achieve even more significant results with more features. In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page). Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc. Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables. For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features. The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents. In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair. For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2. The experiments in this paper are biased toward pages that have higher than average quality. Also, fRank with all of the features can only be applied to pages that have already been crawled. Thus, fRank is primarily useful for index ordering and improving relevance, not for directing the crawl. We would like to investigate a machine learning approach for crawl prioritization as well. It may be that a combination of methods is best: for example, using PageRank to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy. Another interesting direction for exploration is to incorporate fRank and page-level features directly into the PageRank computation itself. Work on biasing the PageRank jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach. There is reason to believe that a direct application of [29], using the fRank of a page for its relevance, could lead to an improved overall static rank. Finally, the popularity data can be used in other interesting ways. The general surfing and searching habits of Web users varies by time of day. Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively). We can gain insight into these differences by using the popularity data, divided into segments of the day. When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages. We also plan to explore popularity features that use more than just the counts of how often a page was visited. For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc. Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14]. Finally, the popularity data could be used as the label rather than as a feature. Using fRank in this way to predict the popularity of a page may useful for the tasks of relevance, efficiency, and crawl priority. There is also significantly more popularity data than human labeled data, potentially enabling more complex machine learning methods, and significantly more features. 7. CONCLUSIONS A good static ranking is an important component for todays search engines and information retrieval systems. We have demonstrated that PageRank does not provide a very good static ranking; there are many simple features that individually out perform PageRank. By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than PageRank alone. A qualitative evaluation of the top documents shows that fRank is less technology-biased than PageRank; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit. The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as adversarial classification. We have only begun to explore the options, and believe that significant strides can be made in the area of static ranking by further experimentation with additional features, other machine learning techniques, and additional sources of data. 8. ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional PageRank computations and to Timo Burkard for assistance with the popularity data. Many thanks to Chris Burges for providing code and significant support in using training RankNets. Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9. REFERENCES [1] B. Amento, L. Terveen, and W. Hill. Does authority mean quality? Predicting expert quality ratings of Web documents. In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000. [2] B. Bartell, G. Cottrell, and R. Belew. Automatic combination of multiple ranked retrieval systems. In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1994. [3] P. Boldi, M. Santini, and S. Vigna. PageRank as a function of the damping factor. In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims. A machine learning architecture for optimizing web search engines. In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page. The anatomy of a large-scale hypertextual web search engine. In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998. Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson. Efficient PageRank approximation via graph aggregation. In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender. Learning to rank using gradient descent. In Proceedings of the 22nd International Conference on Machine Learning, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer. Static index pruning for information retrieval systems. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy. Impact of search engines on page popularity. In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams. Page Quality: In search of an unbiased web ranking. In Proceedings of the ACM SIGMOD 2005 Conference. Baltimore, Maryland. June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor. Relevance weighting for query independent evidence. In Proceedings of the 28th Annual Conference on Research and Development in Information Retrieval (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma. Adversarial Classification. In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y. Singer. Log-linear models for label-ranking. In Advances in Neural Information Processing Systems 16. Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005). Evaluating implicit measures to improve the search experiences. In the ACM Transactions on Information Systems, 23(2), pp. 147-168. April 2005. [15]T. Haveliwala. Efficient computation of PageRank. Stanford University Technical Report, 1999. [16]T. Haveliwala. Topic-sensitive PageRank. In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell. Very large scale retrieval and Web search. In D. Harman and E. Voorhees (eds), The TREC Book. MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer. Support vector learning for ordinal regression. In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst. Statistical profiles of highly-rated Web sites. In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims. Optimizing search engines using clickthrough data. In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay. Accurately Interpreting Clickthrough Data as Implicit Feedback. In Proceedings of the Conference on Research and Development in Information Retrieval (SIGIR), 2005. [22]J. Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer. Deeper inside PageRank. Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit. The effect of the back button in a random walk: application for PageRank. In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry. A uniform approach to accelerated PageRank computation. In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide. Static approximation of dynamically generated Web pages. In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd. The PageRank citation ranking: Bringing order to the web. Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston. User-centric Web crawling. In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos. The intelligent surfer: probabilistic combination of link and content information in PageRank. In Advances in Neural Information Processing Systems 14, pp. 1441-1448. Cambridge, MA: MIT Press, 2002. [30]C. Sherman. Teoma vs. Google, Round 2. Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking. Predicting fame and fortune: PageRank or indegree?. In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking. Query-independent evidence in home page finding. In ACM Transactions on Information Systems. 2003. 715",
    "original_translation": "Más allá de PageRank: Aprendizaje automático para la clasificación estática. Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un motor de búsqueda. Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización. Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. Google es frecuentemente considerado como el primer motor de búsqueda comercialmente exitoso. Su clasificación se basaba originalmente en el algoritmo PageRank [5][27]. Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la clasificación estática de páginas web. Aunque se ha pensado que PageRank ha tenido un buen rendimiento históricamente, todavía hay poca evidencia académica que respalde esta afirmación. Aún peor, recientemente se ha demostrado que PageRank puede no funcionar mejor que otras medidas simples en ciertas tareas. Upstill et al. han encontrado que para la tarea de encontrar páginas de inicio, el número de páginas que enlazan a una página y el tipo de URL fueron tan, o más, efectivos que PageRank [32]. Encontraron resultados similares para la tarea de encontrar empresas de alta calidad [31]. PageRank también se ha utilizado en sistemas para las grandes colecciones de TRECs y competencias de seguimiento web, pero con mucho menos éxito del esperado [17]. Finalmente, Amento et al. [1] encontraron que características simples, como el número de páginas en un sitio, tuvieron un rendimiento tan bueno como PageRank. A pesar de esto, la creencia general persiste entre muchos, tanto académicos como en el público, de que PageRank es un factor esencial para un buen rango estático. En caso de que esto falle, se asume que seguir utilizando la estructura de enlaces es crucial, ya sea en forma del número de enlaces entrantes o la cantidad de texto ancla. En este artículo, demostramos que existen una serie de características simples basadas en URL o en páginas que superan significativamente a PageRank (para el propósito de clasificar estáticamente páginas web) a pesar de ignorar la estructura de la web. Combinamos estas y otras características estáticas utilizando aprendizaje automático para lograr un sistema de clasificación que es significativamente mejor que PageRank (en acuerdo par a par con etiquetas humanas). Un enfoque de aprendizaje automático para la clasificación estática tiene otras ventajas además de la calidad de la clasificación. Debido a que la medida consta de muchas características, es más difícil para los usuarios malintencionados manipularla (es decir, elevar el rango estático de sus páginas a un nivel no merecido a través de técnicas cuestionables, también conocidas como spam en la web). Esto es especialmente cierto si el conjunto de características no se conoce. Por el contrario, una sola medida como PageRank puede ser más fácil de manipular porque los spammers solo necesitan concentrarse en un objetivo: cómo hacer que más páginas apunten a su página. Con un algoritmo que aprende, una característica que se vuelve inutilizable debido a la manipulación de spammers simplemente se reducirá o eliminará del cálculo final de rango. Esta flexibilidad permite que un sistema de clasificación reaccione rápidamente a nuevas técnicas de spam. Un enfoque de aprendizaje automático para la clasificación estática también puede aprovechar cualquier avance en el campo del aprendizaje automático. Por ejemplo, un trabajo reciente sobre clasificación adversarial [12] sugiere que puede ser posible modelar explícitamente las acciones de los spammers de páginas web (el adversario), ajustando el modelo de clasificación de antemano antes de que los spammers intenten evadirlo. Otro ejemplo es la eliminación de valores atípicos al construir el modelo, lo cual ayuda a reducir el efecto que los sitios únicos pueden tener en la calidad general de la clasificación estática. Al trasladar la clasificación estática a un marco de aprendizaje automático, no solo ganamos en precisión, sino también en la capacidad de reaccionar a las acciones de los spammers, de añadir rápidamente nuevas características al algoritmo de clasificación y de aprovechar los avances en el campo en rápido crecimiento del aprendizaje automático. Finalmente, creemos que habrá ventajas significativas al utilizar esta técnica para otros ámbitos, como la búsqueda en un disco duro local o en la intranet de una empresa. Estos son dominios donde la estructura de enlaces es particularmente débil (o inexistente), pero hay otras características específicas del dominio que podrían ser igual de poderosas. Por ejemplo, el autor de una página de intranet y su posición en la organización (por ejemplo, CEO, gerente o desarrollador) podrían proporcionar pistas significativas sobre la importancia de esa página. Un enfoque de aprendizaje automático permite el desarrollo rápido de un buen algoritmo estático en nuevos dominios. La contribución de este artículo es un estudio sistemático de las características estáticas, incluido PageRank, con el propósito de clasificar páginas web de forma estática. Estudios previos sobre PageRank típicamente utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Además, el rendimiento de PageRank y otras características estáticas suele evaluarse en el contexto de un sistema completo para la clasificación dinámica, o para otras tareas como la respuesta a preguntas. Por el contrario, exploramos el uso de PageRank y otras características para la tarea directa de clasificar estáticamente las páginas web. Primero describimos brevemente el algoritmo PageRank. En la Sección 3 presentamos RankNet, la técnica de aprendizaje automático utilizada para combinar las características estáticas en un ranking final. La sección 4 describe las características estáticas. El corazón del documento está en la Sección 5, la cual presenta nuestros experimentos y resultados. Concluimos con una discusión sobre el trabajo relacionado y futuro. 2. PAGERANK La idea básica detrás de PageRank es simple: un enlace de una página web a otra puede ser visto como un respaldo de esa página. En general, los enlaces son creados por personas. Por lo tanto, son indicativos de la calidad de las páginas a las que apuntan: al crear una página, un autor presumiblemente elige enlazar a páginas consideradas de buena calidad. Podemos aprovechar esta información de enlace para ordenar las páginas web según su calidad percibida. Imagina a un internauta que salta de página web en página web, eligiendo con probabilidad uniforme qué enlace seguir en cada paso. Para reducir el efecto de los callejones sin salida o ciclos interminables, el surfista saltará ocasionalmente a una página aleatoria con una pequeña probabilidad α, o cuando se encuentre en una página sin enlaces de salida. Si se promedia sobre un número suficiente de pasos, la probabilidad de que el surfista esté en la página j en algún momento en el tiempo está dada por la fórmula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Donde Fi es el conjunto de páginas a las que enlaza la página i, y Bj es el conjunto de páginas que enlazan a la página j. El puntaje de PageRank para el nodo j se define como esta probabilidad: PR(j)=P(j). Dado que la ecuación (1) es recursiva, debe evaluarse de forma iterativa hasta que P(j) converja (normalmente, la distribución inicial para P(j) es uniforme). La intuición es que, dado que un navegante aleatorio llegaría a la página con más frecuencia, es probable que sea una página mejor. Una vista alternativa para la ecuación (1) es que a cada página se le asigna una calidad, P(j). Una página otorga una parte igual de su calidad a cada página a la que apunta. PageRank es computacionalmente costoso. Nuestra colección de 5 mil millones de páginas contiene aproximadamente 370 mil millones de enlaces. Calcular el PageRank requiere iterar sobre miles de millones de enlaces varias veces (hasta converger). Requiere grandes cantidades de memoria (o esquemas de almacenamiento en caché muy inteligentes que ralentizan aún más el cálculo), y si se distribuye en múltiples máquinas, requiere una comunicación significativa entre ellas. Aunque se ha realizado mucho trabajo en la optimización del cálculo del PageRank (ver, por ejemplo, [25] y [6]), sigue siendo una propiedad relativamente lenta y costosa computacionalmente de calcular. 3. RANKNET Se ha realizado mucho trabajo en aprendizaje automático en los problemas de clasificación y regresión. Sea X={xi} una colección de vectores de características (típicamente, una característica es cualquier número real), y Y={yi} una colección de clases asociadas, donde yi es la clase del objeto descrito por el vector de características xi. El problema de clasificación consiste en aprender una función f que mapea yi=f(xi), para todo i. Cuando yi también es un valor real, esto se llama regresión. La clasificación estática se puede ver como un problema de regresión. Si dejamos que xi represente las características de la página i, y yi sea un valor (por ejemplo, el rango) para cada página, podríamos aprender una función de regresión que mapeara las características de cada página a su rango. Sin embargo, esto sobrecarga el problema que deseamos resolver. Todo lo que realmente nos importa es el orden de las páginas, no el valor real asignado a ellas. El trabajo reciente sobre este problema de clasificación [7][13][18] intenta directamente optimizar el orden de los objetos, en lugar del valor asignado a ellos. Para esto, sea Z={<i,j>} una colección de pares de elementos, donde el elemento i debe ser asignado un valor más alto que el elemento j. El objetivo del problema de clasificación, entonces, es aprender una función f tal que, )()(,, ji ffji xxZ >∈∀ 708. Nótese que, al igual que al aprender una función de regresión, el resultado de este proceso es una función (f) que mapea vectores de características a valores reales. Esta función todavía se puede aplicar en cualquier lugar donde se pueda aplicar una función aprendida por regresión. La única diferencia es la técnica utilizada para aprender la función. Al optimizar directamente el orden de los objetos, estos métodos pueden aprender una función que clasifica mejor que las técnicas de regresión. Utilizamos RankNet [7], una de las técnicas mencionadas para aprender funciones de clasificación, para aprender nuestra función de clasificación estática. RankNet es una modificación sencilla del algoritmo de retropropagación de la red neuronal estándar. Al igual que con back-prop, RankNet intenta minimizar el valor de una función de costo ajustando cada peso en la red de acuerdo con el gradiente de la función de costo con respecto a ese peso. La diferencia es que, mientras que una función de costo típica de una red neuronal se basa en la diferencia entre la salida de la red y la salida deseada, la función de costo de RankNet se basa en la diferencia entre un par de salidas de la red. Es decir, para cada par de vectores de características <i,j> en el conjunto de entrenamiento, RankNet calcula las salidas de la red oi y oj. Dado que se supone que el vector i está clasificado más alto que el vector j, cuanto mayor sea oj-oi, mayor será el costo. RankNet también permite que los pares en Z sean ponderados con una confianza (expresada como la probabilidad de que el par cumpla con el ordenamiento inducido por la función de clasificación). En este documento, utilizamos una probabilidad de uno para todos los pares. En la siguiente sección, discutiremos las características utilizadas en nuestros vectores de características, xi. 4. Para aplicar RankNet (u otras técnicas de aprendizaje automático) al problema de clasificación, necesitábamos extraer un conjunto de características de cada página. Dividimos nuestro conjunto de características en cuatro categorías mutuamente excluyentes: a nivel de página (Página), a nivel de dominio (Dominio), texto del enlace y enlaces entrantes (Anclaje) y popularidad (Popularidad). También opcionalmente utilizamos el PageRank de una página como una característica. A continuación, describimos cada una de estas categorías de características con más detalle. Calculamos PageRank en un grafo web de 5 mil millones de páginas rastreadas (y 20 mil millones de URLs conocidas enlazadas por estas páginas). Esto representa una parte significativa de la Web, y es aproximadamente la misma cantidad de páginas que utilizan Google, Yahoo y MSN para sus motores de búsqueda. Dado que PageRank es un algoritmo basado en grafos, es importante que se ejecute en la mayor cantidad posible de subconjuntos de la Web. La mayoría de los estudios previos sobre PageRank utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Calculamos PageRank utilizando el valor estándar de 0.85 para α. Otra característica que utilizamos es la popularidad real de una página web, medida como el número de veces que ha sido visitada por usuarios durante algún período de tiempo. Tenemos acceso a esos datos de usuarios que han instalado la barra de herramientas de MSN y han optado por proporcionarlos a MSN. Los datos se agregan en un recuento, para cada página web, del número de usuarios que vieron esa página. Aunque los datos de popularidad generalmente no están disponibles, hay otras dos fuentes para obtenerlos. El primero es de los registros de proxy. Por ejemplo, una universidad que requiere que sus estudiantes utilicen un proxy tiene un registro de todas las páginas que han visitado mientras están en el campus. Desafortunadamente, los datos de proxy son bastante sesgados y relativamente pequeños. Otra fuente, interna de los motores de búsqueda, son los registros de los resultados en los que hicieron clic sus usuarios. Tales datos fueron utilizados por el motor de búsqueda Direct Hit, y recientemente han sido explorados con fines de clasificación dinámica [20]. Una ventaja de los datos de la barra de herramientas sobre esto es que contiene información sobre las visitas a URL que no son solo el resultado de una búsqueda. La popularidad en bruto se procesa en una serie de características como el número de veces que se visualizó una página y el número de veces que se visualizó cualquier página en el dominio. Se proporcionan más detalles en la sección 5.5. Texto de anclaje e inlinks. Estas características se basan en la información asociada con los enlaces a la página en cuestión. Incluye características como la cantidad total de texto en los enlaces que apuntan a la página (texto de anclaje), el número de palabras únicas en ese texto, etc. Esta categoría consiste en características que pueden ser determinadas solo al observar la página (y su URL). Solo utilizamos ocho características simples como el número de palabras en el cuerpo, la frecuencia del término más común, etc. Este categoría contiene características que se calculan como promedios en todas las páginas del dominio. Por ejemplo, el número promedio de enlaces salientes en cualquier página y el PageRank promedio. Muchas de estas características han sido utilizadas por otros para clasificar páginas web, especialmente las características de anclaje y de la página. Como se mencionó, la evaluación suele ser para clasificación dinámica, y deseamos evaluar su uso para clasificación estática. Además, hasta donde sabemos, este es el primer estudio sobre el uso de la popularidad real de visitas a páginas para la clasificación estática. El trabajo similar más cercano se centra en el uso del comportamiento de clics (es decir, en los resultados de búsqueda en los que los usuarios hacen clic) para afectar la clasificación dinámica (ver, por ejemplo, [20]). Debido a que utilizamos una amplia variedad de características para crear un ranking estático, nos referimos a esto como fRank (para ranking basado en características). fRank utiliza RankNet y el conjunto de características descritas en esta sección para aprender una función de ranking para páginas web. A menos que se especifique lo contrario, fRank fue entrenado con todas las características. 5. EXPERIMENTOS En esta sección, demostraremos que podemos superar a PageRank aplicando aprendizaje automático a un conjunto sencillo de características. Antes de los resultados, primero discutimos los datos, la métrica de rendimiento y el método de entrenamiento. 5.1 Datos Para evaluar la calidad de un ranking estático, necesitábamos un estándar de oro que definiera el orden correcto para un conjunto de páginas. Para esto, empleamos un conjunto de datos que contiene juicios humanos para 28000 consultas. Para cada consulta, un número de resultados son asignados manualmente una calificación, de 0 a 4, por jueces humanos. La calificación está destinada a ser una medida de cuán relevante es el resultado para la consulta, donde 0 significa pobre y 4 significa excelente. Hay aproximadamente 500 mil juicios en total, o un promedio de 18 calificaciones por consulta. Las consultas se seleccionan eligiendo aleatoriamente consultas de entre aquellas emitidas al motor de búsqueda de MSN. La probabilidad de que se seleccione una consulta es proporcional a su frecuencia entre las 709 consultas. Como resultado, es más probable que las consultas comunes sean evaluadas que las consultas poco comunes. Como ejemplo de la diversidad de las consultas, las primeras cuatro consultas en el conjunto de entrenamiento son escuelas de chef, el autódromo de Chicagoland, el club de fans de los Eagles y la cultura turca. Los documentos seleccionados para evaluar son aquellos que esperábamos que, en promedio, fueran razonablemente relevantes (por ejemplo, los diez documentos principales devueltos por el motor de búsqueda de MSN). Esto proporciona significativamente más información que seleccionar documentos al azar en la web, la gran mayoría de los cuales serían irrelevantes para una consulta específica. Debido a este proceso, las páginas evaluadas tienden a ser de mayor calidad que la página promedio en la web, y suelen ser páginas que se devolverán en consultas de búsqueda comunes. Este sesgo es útil al evaluar la calidad de la clasificación estática con el fin de ordenar índices y devolver documentos relevantes. Esto se debe a que la parte más importante del índice que debe estar bien ordenada y ser relevante es la parte que se devuelve con frecuencia para las consultas de búsqueda. Debido a este sesgo, sin embargo, los resultados en este documento no son aplicables a la priorización de rastreo. Para obtener resultados experimentales sobre la priorización de rastreo, necesitaríamos calificaciones de una muestra aleatoria de páginas web. Para convertir los datos de dependientes de la consulta a independientes de la consulta, simplemente eliminamos la consulta, tomando el máximo sobre las evaluaciones para una URL que aparece en más de una consulta. El razonamiento detrás de esto es que una página que es relevante para una consulta y no relevante para otra probablemente sea una buena página y debería tener un alto rango estático. Debido a que evaluamos las páginas en consultas que ocurren con frecuencia, nuestros datos indican el orden correcto del índice y asignan un alto valor a las páginas que probablemente sean relevantes para una consulta común. Asignamos consultas al azar a un conjunto de entrenamiento, validación o prueba, de modo que contuvieran el 84%, 8% y 8% de las consultas, respectivamente. Cada conjunto contiene todas las calificaciones para una consulta dada, y ninguna consulta aparece en más de un conjunto. El conjunto de entrenamiento se utilizó para entrenar fRank. El conjunto de validación se utilizó para seleccionar el modelo que tuvo el mejor rendimiento. El conjunto de pruebas se utilizó para los resultados finales. Estos datos nos proporcionan un ordenamiento de páginas independiente de la consulta. El objetivo de un algoritmo de clasificación estática será reproducir este orden lo más fielmente posible. En la siguiente sección, describimos la medida que utilizamos para evaluar esto. 5.2 Medida Elegimos utilizar la precisión por pares para evaluar la calidad de un ranking estático. La precisión por pares es la fracción de tiempo en la que el algoritmo de clasificación y los jueces humanos están de acuerdo en el ordenamiento de un par de páginas web. Si S(x) es la clasificación estática asignada a la página x, y H(x) es el juicio humano de relevancia para x, entonces considera los siguientes conjuntos: )}()(:,{ yHxHyx >=pH y )}()(:,{ ySxSyx >=pS La precisión por pares es la porción de Hp que también está contenida en Sp: p pp H SH ∩ =precisiónpares Esta medida fue elegida por dos razones. Primero, los juicios humanos discretos proporcionan solo un orden parcial sobre las páginas web, lo que dificulta aplicar una medida como el coeficiente de correlación de orden de rango de Spearman (en la medida de precisión por pares, un par de documentos con el mismo juicio humano no afecta la puntuación). Segundo, la precisión por pares tiene un significado intuitivo: es la fracción de pares de documentos que, cuando los humanos afirman que uno es mejor que el otro, el algoritmo de clasificación estática los ordena correctamente. 5.3 Método Entrenamos fRank (una red neuronal basada en RankNet) utilizando los siguientes parámetros. Utilizamos una red de 2 capas completamente conectadas. La capa oculta tenía 10 nodos ocultos. Los pesos de entrada a esta capa se inicializaron todos en cero. Los pesos de la capa de salida (solo un nodo) se inicializaron utilizando una distribución aleatoria uniforme en el rango [-0.1, 0.1]. Utilizamos la función tangente hiperbólica (tanh) como función de transferencia de las entradas a la capa oculta, y una función lineal de la capa oculta a la salida. La función de costo es la función de costo de entropía cruzada por pares discutida en la sección 3. Las características en el conjunto de entrenamiento fueron normalizadas para tener media cero y desviación estándar unitaria. La misma transformación lineal fue luego aplicada a las características en los conjuntos de validación y prueba. Para el entrenamiento, presentamos a la red neuronal 5 millones de pares de páginas, donde una página tenía una calificación más alta que la otra. Las combinaciones fueron elegidas de forma uniforme al azar (con reemplazo) de todas las combinaciones posibles. Al formar las parejas, ignoramos la magnitud de la diferencia entre las calificaciones (la dispersión de calificaciones) de las dos URL. Por lo tanto, el peso para cada par era constante (uno), y la probabilidad de que se seleccionara un par era independiente de la diferencia de calificación. Entrenamos la red durante 30 épocas. En cada época, los pares de entrenamiento fueron mezclados aleatoriamente. La tasa de entrenamiento inicial fue de 0.001. En cada época, verificamos el error en el conjunto de entrenamiento. Si el error hubiera aumentado, entonces disminuimos la tasa de entrenamiento, bajo la hipótesis de que la red probablemente se había excedido. La tasa de entrenamiento en cada época se estableció de la siguiente manera: Tasa de entrenamiento = 1+ε κ Donde κ es la tasa inicial (0.001), y ε es el número de veces que el error del conjunto de entrenamiento ha aumentado. Después de cada época, medimos el rendimiento de la red neuronal en el conjunto de validación, utilizando 1 millón de pares (elegidos al azar con reemplazo). La red con la mayor precisión en pares en el conjunto de validación fue seleccionada, y luego probada en el conjunto de pruebas. Informamos la precisión por pares en el conjunto de pruebas, calculada utilizando todos los pares posibles. Estos parámetros fueron determinados y fijados antes de los experimentos de clasificación estática en este artículo. En particular, la elección de la tasa de entrenamiento inicial, el número de épocas y la función de decaimiento de la tasa de entrenamiento se tomaron directamente de Burges et al [7]. Aunque teníamos la opción de preprocesar cualquiera de las características antes de introducirlas en la red neuronal, nos abstuvimos de hacerlo en la mayoría de ellas. La única excepción fueron las características de popularidad. Como ocurre con la mayoría de los fenómenos web, descubrimos que la distribución de la popularidad de los sitios es Zipfiana. Para reducir el rango dinámico, y con suerte hacer que la característica sea más útil, presentamos a la red tanto las características de popularidad sin procesar, como el logaritmo de las mismas (Al igual que con las demás, los valores de las características logarítmicas también se normalizaron para tener media cero y desviación estándar unitaria). Aplicar fRank a un documento es computacionalmente eficiente, tomando un tiempo que es solo lineal en el número de características de entrada; por lo tanto, está dentro de un factor constante de otros métodos de aprendizaje automático simples como el Bayes ingenuo. En nuestros experimentos, calcular el fRank para las cinco mil millones de páginas web fue aproximadamente 100 veces más rápido que calcular el PageRank para el mismo conjunto. 5.4 Resultados Como muestra la Tabla 1, el fRank supera significativamente al PageRank para los propósitos de clasificación estática. Con una precisión de pares del 67.4%, fRank más que duplica la precisión de PageRank (en relación con la línea base del 50%, que es la precisión que se lograría con un orden aleatorio de páginas web). Ten en cuenta que una de las características de entrada de fRanks es el PageRank de la página, por lo que esperaríamos que su rendimiento no fuera peor que el de PageRank. El aumento significativo en precisión implica que las otras características (anclaje, popularidad, etc.) de hecho contienen información útil sobre la calidad general de una página. Tabla 1: Resultados Básicos Técnica Precisión (%) Ninguna (Línea base) 50.00 PageRank 56.70 fRank 67.43 Existen varias decisiones que intervienen en el cálculo de PageRank, como por ejemplo cómo tratar las páginas que no tienen enlaces salientes, la elección de α, la precisión numérica, el umbral de convergencia, etc. Pudimos obtener un cálculo de PageRank a partir de una implementación completamente independiente (proporcionada por Marc Najork) que variaba ligeramente en estos parámetros. Obtuvo una precisión de pares del 56.52%, casi idéntica a la obtenida por nuestra implementación. Por lo tanto, concluimos que la calidad del PageRank no es sensible a estas variaciones menores en el algoritmo, ni la baja precisión de los PageRanks se debió a problemas con nuestra implementación de él. También queríamos averiguar qué tan bien se desempeñaba cada conjunto de características. Para responder a esto, para cada conjunto de características, entrenamos y probamos fRank utilizando solo ese conjunto de características. Los resultados se muestran en la Tabla 2. Como se puede ver, cada conjunto de características individual superó a PageRank en esta prueba. Quizás el resultado más interesante es que las características a nivel de página tuvieron el mejor rendimiento de todos los conjuntos de características. Esto es sorprendente porque estas son características que no dependen de la estructura general del grafo de la Web, ni siquiera de qué páginas apuntan a una página dada. Esto va en contra de la creencia común de que la estructura del grafo web es la clave para encontrar una buena clasificación estática de las páginas web. Tabla 2: Resultados para conjuntos de características individuales. Debido a que estamos utilizando una red neuronal de dos capas, las características en la red aprendida pueden interactuar entre sí de maneras interesantes y no lineales. Esto significa que una característica particular que parece tener poco valor por sí sola podría ser muy importante cuando se utiliza en combinación con otras características. Para medir la contribución final de un conjunto de características, en el contexto de todas las demás características, realizamos un estudio de ablación. Es decir, para cada conjunto de características, entrenamos una red para contener todas las características excepto ese conjunto. Luego comparamos el rendimiento de la red resultante con el rendimiento de la red con todas las características. La Tabla 3 muestra los resultados de este experimento, donde la disminución en la precisión es la diferencia en la precisión por pares entre la red entrenada con todas las características y la red que carece del conjunto de características dado. Tabla 3: Estudio de ablación. Se muestra la disminución en precisión cuando entrenamos una red que tiene todas las características excepto el conjunto dado. La última línea muestra el efecto de eliminar las características del ancla, PageRank y dominio, por lo tanto, un modelo que no contiene ninguna información de red o basada en enlaces. Los resultados del estudio de ablación son consistentes con el estudio de conjunto de características individuales. Ambos muestran que el conjunto de características más importante es el conjunto de características a nivel de página, y el segundo más importante es el conjunto de características de popularidad. Finalmente, deseábamos ver cómo mejoraba el rendimiento de fRank a medida que añadíamos características; queríamos encontrar en qué punto añadir más conjuntos de características se volvía relativamente inútil. Comenzando sin características, añadimos ávidamente el conjunto de características que mejoró el rendimiento en mayor medida. Los resultados se muestran en la Tabla 4. Por ejemplo, la cuarta línea de la tabla muestra que fRank utilizando las características de página, popularidad y anclaje superó a cualquier red que utilizara la página, popularidad y algún otro conjunto de características, y que el rendimiento de esta red fue del 67.25%. Tabla 4: Rendimiento de fRank a medida que se agregan conjuntos de características. En cada fila, se añadió al conjunto de características aquella que proporcionó el mayor aumento en la precisión (es decir, realizamos una búsqueda ávida sobre conjuntos de características). Precisión del conjunto de características (%) Ninguna 50.00 +Página 63.93 +Popularidad 66.83 +Anclaje 67.25 +PageRank 67.31 +Dominio 67.43 711 Finalmente, presentamos una comparación cualitativa de PageRank vs. fRank. En la Tabla 5 se encuentran las diez URL principales devueltas para PageRank y para fRank. Los resultados de PageRank están fuertemente ponderados hacia sitios de tecnología. Contiene dos URL de QuickTime (software de reproducción de video de Apple), así como URL de Internet Explorer y FireFox (ambos navegadores web). Por otro lado, fRank contiene sitios más orientados al consumidor como American Express, Target, Dell, etc. El sesgo de PageRank hacia la tecnología puede explicarse a través de dos procesos. Primero, hay muchas páginas con botones en la parte inferior que sugieren que el sitio está optimizado para Internet Explorer, o que el visitante necesita QuickTime. Estos enlaces generalmente remiten, en estos ejemplos, a los sitios de descarga de Internet Explorer y QuickTime. Por consiguiente, PageRank clasifica esas páginas en posiciones altas. Aunque estas páginas son importantes, no son tan importantes como podría parecer al observar solo la estructura de enlaces. Una solución para esto es agregar información sobre el enlace al cálculo del PageRank, como el tamaño del texto, si estaba en la parte inferior de la página, etc. El otro sesgo proviene del hecho de que la población de autores de sitios web es diferente a la población de usuarios de la web. Los autores web tienden a estar orientados tecnológicamente, por lo que su comportamiento de enlace refleja esos intereses. fRank, al conocer la popularidad real de visitas de un sitio (el conjunto de características de popularidad), puede eliminar parte de ese sesgo. Tiene la capacidad de depender más de dónde visitan los usuarios reales de la Web que de dónde han enlazado los autores del sitio web. Los resultados confirman que fRank supera a PageRank en precisión por pares. Los dos conjuntos de características más importantes son las características de la página y de la popularidad. Esto es sorprendente, ya que las características de la página consistían solo en unas pocas (8) características simples. Experimentos adicionales encontraron que, de las características de la página, aquellas basadas en el texto de la página (en contraposición a la URL) tuvieron el mejor rendimiento. En la siguiente sección, exploramos la característica de popularidad con más detalle. 5.5 Datos de Popularidad Como se mencionó en la sección 4, nuestros datos de popularidad provienen de usuarios de la barra de herramientas de MSN. Por razones de privacidad, solo tuvimos acceso a un recuento agregado de cuántas veces fue visitada cada URL por cualquier usuario de la barra de herramientas. Esto limitó las características posibles que podríamos derivar de estos datos. Para posibles extensiones, consulte la sección 6.3, trabajo futuro. Para cada URL en nuestros conjuntos de entrenamiento y prueba, proporcionamos una característica a fRank que indicaba cuántas veces había sido visitada por un usuario de la barra de herramientas. Sin embargo, esta característica era bastante ruidosa y dispersa, especialmente para URL con parámetros de consulta (por ejemplo, http://search.msn.com/results.aspx?q=machine+learning&form=QBHP). Una solución fue proporcionar una característica adicional que era el número de veces que cualquier URL en el dominio dado fue visitada por un usuario de la barra de herramientas. La adición de esta característica mejoró drásticamente el rendimiento de fRank. Llevamos esto un paso más allá y utilizamos la estructura jerárquica incorporada de las URL para construir varios niveles de retroceso entre la URL completa y el dominio. Lo hicimos utilizando el conjunto de características mostradas en la Tabla 6. Tabla 6: Funciones de URL utilizadas para calcular el conjunto de características de Popularidad. Cada URL fue asignado una característica para cada función mostrada en la tabla. El valor de la característica era el recuento de la cantidad de veces que un usuario de la barra de herramientas visitó una URL, donde la función aplicada a esa URL coincide con la función aplicada a la URL en cuestión. Por ejemplo, la visita de un usuario a cnn.com/2005/sports.html incrementaría las características de Dominio y Dominio+1 para la URL cnn.com/2005/tech/wikipedia.html. Como se observa en la Tabla 7, agregar los recuentos de dominio mejoró significativamente la calidad de la característica de popularidad, y agregar las numerosas funciones de respaldo enumeradas en la Tabla 6 mejoró aún más la precisión. Tabla 7: Efecto de agregar retroceso a la característica de popularidad Conjunto de características Precisión (%) Recuento de URL 58.15 Recuento de URL y dominio 59.31 Todas las funciones de retroceso (Tabla 6) 60.82 Tabla 5: Diez mejores URL para PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Retroceder a subconjuntos de la URL es una técnica para tratar la escasez de datos. También es informativo ver cómo el rendimiento de fRank depende de la cantidad de datos de popularidad que hemos recopilado. En la Figura 1 mostramos el rendimiento de fRank entrenado solo con el conjunto de características de popularidad frente a la cantidad de datos que tenemos para el conjunto de características de popularidad. Cada día recibimos datos adicionales de popularidad, y como se puede ver en el gráfico, esto aumenta el rendimiento de fRank. La relación es logarítmica: duplicar la cantidad de datos de popularidad proporciona una mejora constante en la precisión de pares. En resumen, hemos encontrado que las características de popularidad proporcionan un impulso útil a la precisión general de fRank. Recopilando más datos de popularidad, así como empleando estrategias de retroceso simples, se mejora aún más este impulso. 5.6 Resumen de Resultados Los experimentos proporcionan varias conclusiones. Primero, fRank funciona significativamente mejor que PageRank, incluso sin tener información sobre el grafo web. En segundo lugar, las características a nivel de página y de popularidad fueron los contribuyentes más significativos a la precisión por pares. Tercero, al recopilar más datos de popularidad, podemos seguir mejorando el rendimiento de fRanks. Los datos de popularidad proporcionan dos beneficios a fRank. Primero, observamos que cualitativamente, el ordenamiento de fRanks de las páginas web tiene un sesgo más favorable que PageRanks. El ordenamiento de fRanks parece corresponder a lo que los usuarios de la web, en lugar de los autores de las páginas web, prefieren. Segundo, los datos de popularidad son más actuales que la información de enlaces de PageRank. La barra de herramientas proporciona información sobre qué páginas web encuentran interesantes las personas en este momento, mientras que los enlaces se agregan a las páginas más lentamente, a medida que los autores encuentran el tiempo y el interés. TRABAJO RELACIONADO Y FUTURO 6.1 Mejoras a PageRank Desde el artículo original de PageRank, ha habido trabajos para mejorarlo. Gran parte de ese trabajo se centra en acelerar y paralelizar el cálculo [15][25]. Un problema reconocido con PageRank es el de la deriva de temas: una página sobre perros tendrá un alto PageRank si está vinculada por muchas páginas que a su vez tienen un alto rango, independientemente de su tema. Por el contrario, un usuario de un motor de búsqueda que busca buenas páginas sobre perros probablemente preferiría encontrar páginas que son enlazadas por muchas páginas que tratan sobre perros. Por lo tanto, un enlace que esté relacionado con el tema debería tener más peso que un enlace que no lo esté. Richardson y el PageRank Dependiente de Consulta de Domingos [29] y el PageRank Sensible al Tema de Haveliwala [16] son dos enfoques que abordan este problema. Otras variaciones de PageRank incluyen ponderar de manera diferente los enlaces para enlaces inter e intra-dominio, agregar un paso hacia atrás al surfista aleatorio para simular el botón de retroceso en la mayoría de los navegadores [24] y modificar la probabilidad de salto (α) [3]. Consulte Langville y Meyer [23] para obtener una buena revisión de estas y otras modificaciones a PageRank. 6.2 Otros trabajos relacionados PageRank no es el único algoritmo de análisis de enlaces utilizado para clasificar páginas web. El otro más conocido es HITS [22], que es utilizado por el motor de búsqueda Teoma [30]. HITS produce una lista de hubs y autoridades, donde los hubs son páginas que apuntan a muchas páginas de autoridad, y las autoridades son páginas a las que apuntan muchos hubs. Trabajos anteriores han demostrado que HITS tiene un rendimiento comparable al de PageRank [1]. Un campo de interés es el de la poda de índices estáticos (ver, por ejemplo, Carmel et al. [8]). Los métodos de poda de índices estáticos reducen el tamaño del índice de los motores de búsqueda al eliminar documentos que es poco probable que sean devueltos por una consulta de búsqueda. La poda se realiza típicamente en función de la frecuencia de los términos de consulta. De manera similar, Pandey y Olston [28] sugieren rastrear las páginas con frecuencia si es probable que aparezcan incorrectamente (o no aparezcan) como resultado de una búsqueda. Métodos similares podrían ser incorporados en la clasificación estática (por ejemplo, cuántas consultas frecuentes contienen palabras encontradas en esta página). Otros han investigado el efecto que PageRank tiene en la Web en general [9]. Argumentan que las páginas con un alto PageRank son más propensas a ser encontradas por los usuarios de la web, por lo tanto, es más probable que sean enlazadas y, por ende, mantengan un PageRank más alto que otras páginas. Lo mismo puede ocurrir con los datos de popularidad. Si aumentamos la clasificación de las páginas populares, es más probable que se haga clic en ellas, lo que a su vez aumentará aún más su popularidad. Cho et al. [10] argumentan que una medida más apropiada de la calidad de una página web dependería no solo de la estructura de enlaces actual de la web, sino también de los cambios en esa estructura de enlaces. La misma técnica puede ser aplicable a los datos de popularidad: el cambio en la popularidad de una página puede ser más informativo que la popularidad absoluta. Un trabajo relacionado interesante es el de Ivory y Hearst [19]. Su objetivo era construir un modelo de sitios web que son considerados de alta calidad desde la perspectiva de contenido, estructura y navegación, diseño visual, funcionalidad, interactividad y experiencia general. Utilizaron más de 100 características a nivel de página, así como características que abarcan el rendimiento y la estructura del sitio. Esto les permitió describir cualitativamente las cualidades de una página que la hacen parecer atractiva (por ejemplo, el uso poco común de cursivas, al menos una fuente de 9 puntos, ...), y (en trabajos posteriores) construir un sistema que ayude a los autores de páginas web novedosas a crear páginas de calidad evaluándolas según estas características. Las principales diferencias entre este trabajo y el nuestro son el objetivo (descubrir qué constituye una buena página web vs. ordenar páginas web con fines de búsqueda en la web), el tamaño del estudio (utilizaron un conjunto de datos de menos de 6000 páginas vs. nuestro conjunto de 468,000), y nuestra comparación con PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Días de Datos de la Barra de Herramientas Precisión por Pares Figura 1: Relación entre la cantidad de datos de popularidad y el rendimiento del conjunto de características de popularidad. Ten en cuenta que el eje x es una escala logarítmica. Sin embargo, su trabajo proporciona ideas sobre características estáticas adicionales útiles que podríamos incorporar en fRank en el futuro. El trabajo reciente sobre la incorporación de características novedosas en la clasificación dinámica incluye el realizado por Joachims et al. [21], quienes investigan el uso de retroalimentación implícita de los usuarios, en forma de los resultados de búsqueda en el motor de búsqueda que se hacen clic. Craswell et al. [11] presentan un método para determinar la mejor transformación a aplicar a las características independientes de la consulta (como las utilizadas en este artículo) con el fin de mejorar la clasificación dinámica. Otros trabajos, como el de Boyan et al. [4] y Bartell et al. [2], aplican aprendizaje automático con el propósito de mejorar la relevancia general de un motor de búsqueda (es decir, el ranking dinámico). No aplican sus técnicas al problema de clasificación estática. 6.3 Trabajo futuro Hay muchas formas en las que nos gustaría ampliar este trabajo. Primero, Frank utiliza solo un pequeño número de características. Creemos que podríamos lograr resultados aún más significativos con más características. En particular, la existencia o falta de ciertas palabras podría resultar muy significativa (por ejemplo, \"en construcción\" probablemente signifique una página de baja calidad). Otras características podrían incluir el número de imágenes en una página, el tamaño de esas imágenes, el número de elementos de diseño (tablas, divs y spans), el uso de hojas de estilo, la conformidad con los estándares de W3C (como XHTML 1.0 Strict), el color de fondo de una página, etc. Muchas páginas se generan dinámicamente, cuyos contenidos pueden depender de parámetros en la URL, la hora del día, el usuario que visita el sitio, u otras variables. Para este tipo de páginas, puede ser útil aplicar las técnicas encontradas en [26] para formar una aproximación estática con el fin de extraer características. La gramática resultante que describe la página podría ser en sí misma una fuente de características adicionales que describen la complejidad de la página, como cuántos nodos no terminales tiene, la profundidad del árbol gramatical, etc. fRank permite especificar una confianza en cada emparejamiento de documentos. En el futuro, experimentaremos con probabilidades que dependen de la diferencia en los juicios humanos entre los dos elementos del par. Por ejemplo, un par de documentos donde uno fue calificado con un 4 y el otro con un 0 debería tener una mayor confianza que un par de documentos calificados con un 3 y un 2. Los experimentos en este artículo están sesgados hacia páginas que tienen una calidad superior al promedio. Además, fRank con todas las características solo se puede aplicar a páginas que ya han sido rastreadas. Por lo tanto, fRank es principalmente útil para el ordenamiento de índices y mejorar la relevancia, no para dirigir el rastreo. Nos gustaría investigar un enfoque de aprendizaje automático para la priorización de rastreo también. Puede ser que la mejor opción sea una combinación de métodos: por ejemplo, utilizar PageRank para seleccionar los mejores 5 mil millones de las 20 mil millones de páginas en la web, luego utilizar fRank para ordenar el índice y afectar la relevancia de la búsqueda. Otra dirección interesante para la exploración es incorporar las características de fRank y a nivel de página directamente en el cálculo de PageRank en sí mismo. El trabajo en el sesgo del vector de salto de PageRank [16] y la matriz de transición [29] ha demostrado la viabilidad y ventajas de este enfoque. Existe motivo para creer que una aplicación directa de [29], utilizando el fRank de una página para su relevancia, podría llevar a una mejora en el rango estático general. Finalmente, los datos de popularidad pueden ser utilizados de otras maneras interesantes. Los hábitos generales de navegación y búsqueda de los usuarios de la web varían según la hora del día. La actividad por la mañana, durante el día y en la tarde suele ser bastante diferente (por ejemplo, leer las noticias, resolver problemas y acceder al entretenimiento, respectivamente). Podemos obtener información sobre estas diferencias utilizando los datos de popularidad, divididos en segmentos del día. Cuando se emite una consulta, luego utilizaríamos los datos de popularidad que coincidan con el momento de la consulta para clasificar las páginas web. También planeamos explorar características de popularidad que utilicen más que solo el recuento de cuántas veces se visitó una página. Por ejemplo, cuánto tiempo los usuarios solían permanecer en una página, si abandonaron la página haciendo clic en un enlace o presionando el botón de retroceso, etc. Fox et al. realizaron un estudio que demostró que características como esta pueden ser valiosas para los propósitos de clasificación dinámica [14]. Finalmente, los datos de popularidad podrían ser utilizados como la etiqueta en lugar de como una característica. Utilizar fRank de esta manera para predecir la popularidad de una página puede ser útil para las tareas de relevancia, eficiencia y prioridad de rastreo. También hay significativamente más datos de popularidad que datos etiquetados por humanos, lo que potencialmente permite el uso de métodos de aprendizaje automático más complejos y muchas más características. 7. CONCLUSIONES Un buen ranking estático es un componente importante para los motores de búsqueda y sistemas de recuperación de información actuales. Hemos demostrado que PageRank no proporciona una clasificación estática muy buena; hay muchas características simples que superan individualmente a PageRank. Al combinar muchas características estáticas, fRank logra un ranking que tiene una precisión en pares significativamente mayor que PageRank solo. Una evaluación cualitativa de los documentos principales muestra que fRank está menos sesgado hacia la tecnología que PageRank; al utilizar datos de popularidad, está sesgado hacia las páginas que los usuarios de la web visitan, en lugar de hacia las páginas que los autores web crean. El componente de aprendizaje automático de fRank le otorga el beneficio adicional de ser más robusto contra los spammers, y le permite aprovechar los avances adicionales en la comunidad de aprendizaje automático en áreas como la clasificación adversarial. Hemos comenzado a explorar las opciones y creemos que se pueden lograr avances significativos en el área de clasificación estática mediante experimentación adicional con características adicionales, otras técnicas de aprendizaje automático y fuentes de datos adicionales. AGRADECIMIENTOS Gracias a Marc Najork por proporcionarnos cálculos adicionales de PageRank y a Timo Burkard por su ayuda con los datos de popularidad. Muchas gracias a Chris Burges por proporcionar código y un apoyo significativo en el uso del entrenamiento de RankNets. También agradecemos a Susan Dumais y Nick Craswell por sus ediciones y sugerencias. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2000. [2] B. Bartell, G. Cottrell y R. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la 17ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 1994. [3] P. Boldi, M. Santini y S. Vigna. PageRank como una función del factor de amortiguamiento. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. 714 [4] J. Boyan, D. Freitag y T. Joachims. Una arquitectura de aprendizaje automático para optimizar los motores de búsqueda web. En el taller de AAAI sobre Sistemas de Información Basados en Internet, agosto de 1996. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. En Actas de la Séptima Conferencia Internacional de la World Wide Web, Brisbane, Australia, 1998. Elsevier. [6] A. Broder, R. Lempel, F. Maghoul y J. Pederson. Aproximación eficiente de PageRank a través de la agregación de grafos. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, Bonn, Alemania, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 43-50, Nueva Orleans, Luisiana, EE. UU., septiembre de 2001. [9] J. Cho y S. Roy. Impacto de los motores de búsqueda en la popularidad de las páginas. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [10]J. Cho, S. Roy, R. Adams. Calidad de la página: En busca de una clasificación web imparcial. En las Actas de la Conferencia ACM SIGMOD 2005. Baltimore, Maryland. Junio de 2005. N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Anual sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), agosto de 2005. [12] N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma. Clasificación adversarial. En Actas de la Décima Conferencia Internacional sobre Descubrimiento de Conocimiento y Minería de Datos (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning y Y. Cantante. Modelos log-lineales para clasificación de etiquetas. En Avances en Sistemas de Procesamiento de Información Neural 16. Cambridge, MA: MIT Press, 2003. [14] S. Fox, K. S. Fox, K. Karnawat, M. Mydland, S. T. Dumais y T. White (2005). Evaluando medidas implícitas para mejorar las experiencias de búsqueda. En la revista ACM Transactions on Information Systems, 23(2), pp. 147-168. Abril de 2005. [15] T. Haveliwala. Cálculo eficiente de PageRank. Informe técnico de la Universidad de Stanford, 1999. [16] T. Haveliwala. PageRank sensible al tema. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2002. [17] D. Hawking y N. Craswell. Recuperación a gran escala y búsqueda en la web. En D. Harman y E. Voorhees (eds), El Libro de TREC. MIT Press. [18] R. Herbrich, T. Graepel y K. Obermayer. Aprendizaje de vectores de soporte para regresión ordinal. En Actas de la Novena Conferencia Internacional sobre Redes Neuronales Artificiales, pp. 97-102. 1999. [19] M. Ivory y M. Hearst. Perfiles estadísticos de sitios web altamente valorados. En Actas de la Conferencia ACM SIGCHI sobre Factores Humanos en Sistemas Informáticos, 2002. [20]T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de la Conferencia de la ACM sobre Descubrimiento de Conocimiento y Minería de Datos (KDD), 2002. [21] T. Joachims, L. Granka, B. Pang, H. Hembrooke y G. Gay. Interpretación precisa de los datos de clics como retroalimentación implícita. En Actas de la Conferencia sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2005. [22]J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM 46:5, pp. 604-32. 1999. [23]A. Langville y C. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet 1(3):335-380, 2004. [24] F. Matthieu y M. Bouklit. El efecto del botón de retroceso en un paseo aleatorio: aplicación para PageRank. En los trabajos y pósters de la pista alternativa de la Decimotercera Conferencia Internacional de la World Wide Web, 2004. [25]F. McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [26] Y. Minamide. Aproximación estática de páginas web generadas dinámicamente. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [27] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford, Stanford, CA, 1998. [28] S. Pandey y C. Olston. Rastreo web centrado en el usuario. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [29] M. Richardson y P. Domingos. El surfista inteligente: combinación probabilística de la información de enlaces y contenido en PageRank. En Advances in Neural Information Processing Systems 14, pp. 1441-1448. Cambridge, MA: MIT Press, 2002. [30]C. Sherman.\nCambridge, MA: MIT Press, 2002. [30]C. Sherman. Teoma vs. Google, Ronda 2. Disponible en World Wide Web (http://dc.internet.com/news/article.php/1002061), 2002. [31] T. Upstill, N. Craswell y D. Hawking. Prediciendo fama y fortuna: ¿PageRank o grado de entrada? En el Octavo Simposio de Computación de Documentos Australasiano. 2003. [32] T. Upstill, N. Craswell y D. Hawking. Evidencia independiente de la consulta en la búsqueda de la página de inicio. En ACM Transactions on Information Systems. 2003. 715",
    "original_sentences": [
        "Beyond PageRank: Machine Learning for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
        "We show that we can significantly outperform PageRank using features that are independent of the link structure of the Web.",
        "We gain a further boost in accuracy by using data on the frequency at which users visit Web pages.",
        "We use RankNet, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics.",
        "The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random).",
        "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning.",
        "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval.",
        "General Terms Algorithms, Measurement, Performance, Experimentation. 1.",
        "INTRODUCTION Over the past decade, the Web has grown exponentially in size.",
        "Unfortunately, this growth has not been isolated to good-quality pages.",
        "The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly.",
        "The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information.",
        "Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first.",
        "To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking).",
        "However, having a good query-independent ranking (static ranking) is also crucially important for a search engine.",
        "A good static ranking algorithm provides numerous benefits: • Relevance: The static rank of a page provides a general indicator to the overall quality of the page.",
        "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by static rank.",
        "By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found.",
        "The more accurate the static rank, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
        "Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages.",
        "Among other factors, the static rank of a page is used to determine this prioritization.",
        "A better static rank thus provides the engine with a higher quality, more upto-date index.",
        "Google is often regarded as the first commercially successful search engine.",
        "Their ranking was originally based on the PageRank algorithm [5][27].",
        "Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the static ranking of Web pages.",
        "Though PageRank has historically been thought to perform quite well, there has yet been little academic evidence to support this claim.",
        "Even worse, there has recently been work showing that PageRank may not perform any better than other simple measures on certain tasks.",
        "Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than PageRank [32].",
        "They found similar results for the task of finding high quality companies [31].",
        "PageRank has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17].",
        "Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as PageRank.",
        "Despite these, the general belief remains among many, both academic and in the public, that PageRank is an essential factor for a good static rank.",
        "Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text.",
        "In this paper, we show there are a number of simple url- or pagebased features that significantly outperform PageRank (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web.",
        "We combine these and other static features using machine learning to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels).",
        "A machine learning approach for static ranking has other advantages besides the quality of the ranking.",
        "Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages static rank to an undeserved level through questionable techniques, also known as Web spamming).",
        "This is particularly true if the feature set is not known.",
        "In contrast, a single measure like PageRank can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page.",
        "With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank.",
        "This flexibility allows a ranking system to rapidly react to new spamming techniques.",
        "A machine learning approach to static ranking is also able to take advantage of any advances in the machine learning field.",
        "For example, recent work on adversarial classification [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
        "Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the static rank.",
        "By moving static ranking to a machine learning framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of machine learning.",
        "Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet.",
        "These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful.",
        "For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page.",
        "A machine learning approach thus allows rapid development of a good static algorithm in new domains.",
        "This papers contribution is a systematic study of static features, including PageRank, for the purposes of (statically) ranking Web pages.",
        "Previous studies on PageRank typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages).",
        "Also, the performance of PageRank and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering.",
        "In contrast, we explore the use of PageRank and other features for the direct task of statically ranking Web pages.",
        "We first briefly describe the PageRank algorithm.",
        "In Section 3 we introduce RankNet, the machine learning technique used to combine static features into a final ranking.",
        "Section 4 describes the static features.",
        "The heart of the paper is in Section 5, which presents our experiments and results.",
        "We conclude with a discussion of related and future work. 2.",
        "PAGERANK The basic idea behind PageRank is simple: a link from a Web page to another can be seen as an endorsement of that page.",
        "In general, links are made by people.",
        "As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality.",
        "We can take advantage of this linkage information to order Web pages according to their perceived quality.",
        "Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step.",
        "In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links.",
        "If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j.",
        "The PageRank score for node j is defined as this probability: PR(j)=P(j).",
        "Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform).",
        "The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page.",
        "An alternative view for equation (1) is that each page is assigned a quality, P(j).",
        "A page gives an equal share of its quality to each page it points to.",
        "PageRank is computationally expensive.",
        "Our collection of 5 billion pages contains approximately 370 billion links.",
        "Computing PageRank requires iterating over these billions of links multiple times (until convergence).",
        "It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them.",
        "Though much work has been done on optimizing the PageRank computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3.",
        "RANKNET Much work in machine learning has been done on the problems of classification and regression.",
        "Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi.",
        "The classification problem is to learn a function f that maps yi=f(xi), for all i.",
        "When yi is real-valued as well, this is called regression.",
        "Static ranking can be seen as a regression problem.",
        "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a regression function that mapped each pages features to their rank.",
        "However, this over-constrains the problem we wish to solve.",
        "All we really care about is the order of the pages, not the actual value assigned to them.",
        "Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them.",
        "For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j.",
        "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a regression function, the result of this process is a function (f) that maps feature vectors to real values.",
        "This function can still be applied anywhere that a regressionlearned function could be applied.",
        "The only difference is the technique used to learn the function.",
        "By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do regression techniques.",
        "We used RankNet [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function.",
        "RankNet is a straightforward modification to the standard neural network back-prop algorithm.",
        "As with back-prop, RankNet attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight.",
        "The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the RankNet cost function is based on the difference between a pair of network outputs.",
        "That is, for each pair of feature vectors <i,j> in the training set, RankNet computes the network outputs oi and oj.",
        "Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost.",
        "RankNet also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function).",
        "In this paper, we used a probability of one for all pairs.",
        "In the next section, we will discuss the features used in our feature vectors, xi. 4.",
        "FEATURES To apply RankNet (or other machine learning techniques) to the ranking problem, we needed to extract a set of features from each page.",
        "We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity).",
        "We also optionally used the PageRank of a page as a feature.",
        "Below, we describe each of these feature categories in more detail.",
        "PageRank We computed PageRank on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages).",
        "This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines.",
        "Because PageRank is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible.",
        "Most previous studies on PageRank used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed PageRank using the standard value of 0.85 for α.",
        "Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time.",
        "We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN.",
        "The data is aggregated into a count, for each Web page, of the number of users who viewed that page.",
        "Though popularity data is generally unavailable, there are two other sources for it.",
        "The first is from proxy logs.",
        "For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus.",
        "Unfortunately, proxy data is quite biased and relatively small.",
        "Another source, internal to search engines, are records of which results their users clicked on.",
        "Such data was used by the search engine Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
        "An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search.",
        "The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed.",
        "More details are provided in section 5.5.",
        "Anchor text and inlinks These features are based on the information associated with links to the page in question.",
        "It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc.",
        "Page This category consists of features which may be determined by looking at the page (and its URL) alone.",
        "We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc.",
        "Domain This category contains features that are computed as averages across all pages in the domain.",
        "For example, the average number of outlinks on any page and the average PageRank.",
        "Many of these features have been used by others for ranking Web pages, particularly the anchor and page features.",
        "As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for static ranking.",
        "Also, to our knowledge, this is the first study on the use of actual page visitation popularity for static ranking.",
        "The closest similar work is on using click-through behavior (that is, which search engine results the users click on) to affect dynamic ranking (see e.g., [20]).",
        "Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for feature-based ranking). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages.",
        "Unless otherwise specified, fRank was trained with all of the features. 5.",
        "EXPERIMENTS In this section, we will demonstrate that we can out perform PageRank by applying machine learning to a straightforward set of features.",
        "Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a static ranking, we needed a gold standard defining the correct ordering for a set of pages.",
        "For this, we employed a dataset which contains human judgments for 28000 queries.",
        "For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges.",
        "The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent.",
        "There are approximately 500k judgments in all, or an average of 18 ratings per query.",
        "The queries are selected by randomly choosing queries from among those issued to the MSN search engine.",
        "The probability that a query is selected is proportional to its frequency among all 709 of the queries.",
        "As a result, common queries are more likely to be judged than uncommon queries.",
        "As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture.",
        "The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs search engine).",
        "This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query.",
        "Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries.",
        "This bias is good when evaluating the quality of static ranking for the purposes of index ordering and returning relevant documents.",
        "This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries.",
        "Because of this bias, however, the results in this paper are not applicable to crawl prioritization.",
        "In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages.",
        "To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query.",
        "The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high static rank.",
        "Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query.",
        "We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively.",
        "Each set contains all of the ratings for a given query, and no query appears in more than one set.",
        "The training set was used to train fRank.",
        "The validation set was used to select the model that had the highest performance.",
        "The test set was used for the final results.",
        "This data gives us a query-independent ordering of pages.",
        "The goal for a static ranking algorithm will be to reproduce this ordering as closely as possible.",
        "In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a static ranking.",
        "The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages.",
        "If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of relevance for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
        "First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score).",
        "Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the static rank algorithm orders them correctly. 5.3 Method We trained fRank (a RankNet based neural network) using the following parameters.",
        "We used a fully connected 2 layer network.",
        "The hidden layer had 10 hidden nodes.",
        "The input weights to this layer were all initialized to be zero.",
        "The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1].",
        "We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output.",
        "The cost function is the pairwise cross entropy cost function as discussed in section 3.",
        "The features in the training set were normalized to have zero mean and unit standard deviation.",
        "The same linear transformation was then applied to the features in the validation and test sets.",
        "For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other.",
        "The pairings were chosen uniformly at random (with replacement) from all possible pairings.",
        "When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs.",
        "Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread.",
        "We trained the network for 30 epochs.",
        "On each epoch, the training pairs were randomly shuffled.",
        "The initial training rate was 0.001.",
        "At each epoch, we checked the error on the training set.",
        "If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot.",
        "The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased.",
        "After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement).",
        "The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set.",
        "We report the pairwise accuracy on the test set, calculated using all possible pairs.",
        "These parameters were determined and fixed before the static rank experiments in this paper.",
        "In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7].",
        "Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them.",
        "The only exception was the popularity features.",
        "As with most Web phenomenon, we found that the distribution of site popularity is Zipfian.",
        "To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple machine learning methods such as naïve Bayes.",
        "In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the PageRank for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms PageRank for the purposes of static ranking.",
        "With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of PageRank (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages).",
        "Note that one of fRanks input features is the PageRank of the page, so we would expect it to perform no worse than PageRank.",
        "The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page.",
        "Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 PageRank 56.70 fRank 67.43 There are a number of decisions that go into the computation of PageRank, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc.",
        "We were able to obtain a computation of PageRank from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters.",
        "It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation.",
        "We thus concluded that the quality of the PageRank is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it.",
        "We also wanted to find how well each feature set performed.",
        "To answer this, for each feature set, we trained and tested fRank using only that set of features.",
        "The results are shown in Table 2.",
        "As can be seen, every single feature set individually outperformed PageRank on this test.",
        "Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets.",
        "This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page.",
        "This is contrary to the common belief that the Web graph structure is the key to finding a good static ranking of Web pages.",
        "Table 2: Results for individual feature sets.",
        "Feature Set Accuracy (%) PageRank 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways.",
        "This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features.",
        "To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study.",
        "That is, for each set of features, we trained a network to contain all of the features except that set.",
        "We then compared the performance of the resulting network to the performance of the network with all of the features.",
        "Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set.",
        "Table 3: Ablation study.",
        "Shown is the decrease in accuracy when we train a network that has all but the given set of features.",
        "The last line is shows the effect of removing the anchor, PageRank, and domain features, hence a model containing no network or link-based information whatsoever.",
        "Feature Set Decrease in Accuracy PageRank 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, PageRank & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study.",
        "Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set.",
        "Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless.",
        "Beginning with no features, we greedily added the feature set that improved performance the most.",
        "The results are shown in Table 4.",
        "For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%.",
        "Table 4: fRank performance as feature sets are added.",
        "At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets).",
        "Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +PageRank 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of PageRank vs. fRank.",
        "In Table 5 are the top ten URLs returned for PageRank and for fRank.",
        "PageRanks results are heavily weighted towards technology sites.",
        "It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc.",
        "PageRanks bias toward technology can be explained through two processes.",
        "First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime.",
        "These generally link back to, in these examples, the Internet Explorer and QuickTime download sites.",
        "Consequently, PageRank ranks those pages highly.",
        "Though these pages are important, they are not as important as it may seem by looking at the link structure alone.",
        "One fix for this is to add information about the link to the PageRank computation, such as the size of the text, whether it was at the bottom of the page, etc.",
        "The other bias comes from the fact that the population of Web site authors is different than the population of Web users.",
        "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual visitation popularity of a site (the popularity feature set), is able to eliminate some of that bias.",
        "It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked.",
        "The results confirm that fRank outperforms PageRank in pairwise accuracy.",
        "The two most important feature sets are the page and popularity features.",
        "This is surprising, as the page features consisted only of a few (8) simple features.",
        "Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best.",
        "In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users.",
        "For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user.",
        "This limited the possible features we could derive from this data.",
        "For possible extensions, see section 6.3, future work.",
        "For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user.",
        "However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
        "One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user.",
        "Adding this feature dramatically improved the performance of fRank.",
        "We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain.",
        "We did this by using the set of features shown in Table 6.",
        "Table 6: URL functions used to compute the Popularity feature set.",
        "Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table.",
        "The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question.",
        "For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html.",
        "As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further.",
        "Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data.",
        "It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected.",
        "In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set.",
        "Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank.",
        "The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy.",
        "In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy.",
        "Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions.",
        "First, fRank performs significantly better than PageRank, even without any information about the Web graph.",
        "Second, the page level and popularity features were the most significant contributors to pairwise accuracy.",
        "Third, by collecting more popularity data, we can continue to improve fRanks performance.",
        "The popularity data provides two benefits to fRank.",
        "First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer.",
        "Second, the popularity data is more timely than PageRanks link information.",
        "The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6.",
        "RELATED AND FUTURE WORK 6.1 Improvements to PageRank Since the original PageRank paper, there has been work on improving it.",
        "Much of that work centers on speeding up and parallelizing the computation [15][25].",
        "One recognized problem with PageRank is that of topic drift: A page about dogs will have high PageRank if it is linked to by many pages that themselves have high rank, regardless of their topic.",
        "In contrast, a search engine user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs.",
        "Hence, a link that is on topic should have higher weight than a link that is not.",
        "Richardson and Domingoss Query Dependent PageRank [29] and Haveliwalas Topic-Sensitive PageRank [16] are two approaches that tackle this problem.",
        "Other variations to PageRank include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3].",
        "See Langville and Meyer [23] for a good survey of these, and other modifications to PageRank. 6.2 Other related work PageRank is not the only link analysis algorithm used for ranking Web pages.",
        "The most well-known other is HITS [22], which is used by the Teoma search engine [30].",
        "HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs.",
        "Previous work has shown HITS to perform comparably to PageRank [1].",
        "One field of interest is that of static index pruning (see e.g., Carmel et al. [8]).",
        "Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query.",
        "The pruning is typically done based on the frequency of query terms.",
        "Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search.",
        "Similar methods could be incorporated into the static rank (e.g., how many frequent queries contain words found on this page).",
        "Others have investigated the effect that PageRank has on the Web at large [9].",
        "They argue that pages with high PageRank are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher PageRank than other pages.",
        "The same may occur for the popularity data.",
        "If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity.",
        "Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure.",
        "The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity.",
        "One interesting related work is that of Ivory and Hearst [19].",
        "Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience.",
        "They used over 100 page level features, as well as features encompassing the performance and structure of the site.",
        "This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features.",
        "The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set.",
        "Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future.",
        "Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which search engine results are clicked on.",
        "Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking.",
        "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall relevance of a search engine (i.e., the dynamic ranking).",
        "They do not apply their techniques to the problem of static ranking. 6.3 Future work There are many ways in which we would like to extend this work.",
        "First, fRank uses only a small number of features.",
        "We believe we could achieve even more significant results with more features.",
        "In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page).",
        "Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc.",
        "Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables.",
        "For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features.",
        "The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents.",
        "In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair.",
        "For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2.",
        "The experiments in this paper are biased toward pages that have higher than average quality.",
        "Also, fRank with all of the features can only be applied to pages that have already been crawled.",
        "Thus, fRank is primarily useful for index ordering and improving relevance, not for directing the crawl.",
        "We would like to investigate a machine learning approach for crawl prioritization as well.",
        "It may be that a combination of methods is best: for example, using PageRank to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy.",
        "Another interesting direction for exploration is to incorporate fRank and page-level features directly into the PageRank computation itself.",
        "Work on biasing the PageRank jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach.",
        "There is reason to believe that a direct application of [29], using the fRank of a page for its relevance, could lead to an improved overall static rank.",
        "Finally, the popularity data can be used in other interesting ways.",
        "The general surfing and searching habits of Web users varies by time of day.",
        "Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively).",
        "We can gain insight into these differences by using the popularity data, divided into segments of the day.",
        "When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages.",
        "We also plan to explore popularity features that use more than just the counts of how often a page was visited.",
        "For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc.",
        "Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14].",
        "Finally, the popularity data could be used as the label rather than as a feature.",
        "Using fRank in this way to predict the popularity of a page may useful for the tasks of relevance, efficiency, and crawl priority.",
        "There is also significantly more popularity data than human labeled data, potentially enabling more complex machine learning methods, and significantly more features. 7.",
        "CONCLUSIONS A good static ranking is an important component for todays search engines and information retrieval systems.",
        "We have demonstrated that PageRank does not provide a very good static ranking; there are many simple features that individually out perform PageRank.",
        "By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than PageRank alone.",
        "A qualitative evaluation of the top documents shows that fRank is less technology-biased than PageRank; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit.",
        "The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as adversarial classification.",
        "We have only begun to explore the options, and believe that significant strides can be made in the area of static ranking by further experimentation with additional features, other machine learning techniques, and additional sources of data. 8.",
        "ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional PageRank computations and to Timo Burkard for assistance with the popularity data.",
        "Many thanks to Chris Burges for providing code and significant support in using training RankNets.",
        "Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9.",
        "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
        "Does authority mean quality?",
        "Predicting expert quality ratings of Web documents.",
        "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
        "Automatic combination of multiple ranked retrieval systems.",
        "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
        "PageRank as a function of the damping factor.",
        "In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims.",
        "A machine learning architecture for optimizing web search engines.",
        "In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page.",
        "The anatomy of a large-scale hypertextual web search engine.",
        "In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998.",
        "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson.",
        "Efficient PageRank approximation via graph aggregation.",
        "In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
        "Learning to rank using gradient descent.",
        "In Proceedings of the 22nd International Conference on Machine Learning, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer.",
        "Static index pruning for information retrieval systems.",
        "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy.",
        "Impact of search engines on page popularity.",
        "In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams.",
        "Page Quality: In search of an unbiased web ranking.",
        "In Proceedings of the ACM SIGMOD 2005 Conference.",
        "Baltimore, Maryland.",
        "June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
        "Relevance weighting for query independent evidence.",
        "In Proceedings of the 28th Annual Conference on Research and Development in Information Retrieval (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
        "Adversarial Classification.",
        "In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y.",
        "Singer.",
        "Log-linear models for label-ranking.",
        "In Advances in Neural Information Processing Systems 16.",
        "Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005).",
        "Evaluating implicit measures to improve the search experiences.",
        "In the ACM Transactions on Information Systems, 23(2), pp. 147-168.",
        "April 2005. [15]T. Haveliwala.",
        "Efficient computation of PageRank.",
        "Stanford University Technical Report, 1999. [16]T. Haveliwala.",
        "Topic-sensitive PageRank.",
        "In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell.",
        "Very large scale retrieval and Web search.",
        "In D. Harman and E. Voorhees (eds), The TREC Book.",
        "MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer.",
        "Support vector learning for ordinal regression.",
        "In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst.",
        "Statistical profiles of highly-rated Web sites.",
        "In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims.",
        "Optimizing search engines using clickthrough data.",
        "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay.",
        "Accurately Interpreting Clickthrough Data as Implicit Feedback.",
        "In Proceedings of the Conference on Research and Development in Information Retrieval (SIGIR), 2005. [22]J. Kleinberg.",
        "Authoritative sources in a hyperlinked environment.",
        "Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer.",
        "Deeper inside PageRank.",
        "Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit.",
        "The effect of the back button in a random walk: application for PageRank.",
        "In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry.",
        "A uniform approach to accelerated PageRank computation.",
        "In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide.",
        "Static approximation of dynamically generated Web pages.",
        "In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd.",
        "The PageRank citation ranking: Bringing order to the web.",
        "Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston.",
        "User-centric Web crawling.",
        "In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos.",
        "The intelligent surfer: probabilistic combination of link and content information in PageRank.",
        "In Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
        "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.",
        "Teoma vs. Google, Round 2.",
        "Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking.",
        "Predicting fame and fortune: PageRank or indegree?.",
        "In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking.",
        "Query-independent evidence in home page finding.",
        "In ACM Transactions on Information Systems. 2003. 715"
    ],
    "translated_text_sentences": [
        "Más allá de PageRank: Aprendizaje automático para la clasificación estática.",
        "Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web.",
        "Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web.",
        "Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio.",
        "El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar).",
        "Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje.",
        "H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información.",
        "Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1.",
        "INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño.",
        "Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad.",
        "El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente.",
        "El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil.",
        "Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas.",
        "Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica).",
        "Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un motor de búsqueda.",
        "Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página.",
        "Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático.",
        "Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas.",
        "Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla.",
        "Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas.",
        "Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización.",
        "Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado.",
        "Google es frecuentemente considerado como el primer motor de búsqueda comercialmente exitoso.",
        "Su clasificación se basaba originalmente en el algoritmo PageRank [5][27].",
        "Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la clasificación estática de páginas web.",
        "Aunque se ha pensado que PageRank ha tenido un buen rendimiento históricamente, todavía hay poca evidencia académica que respalde esta afirmación.",
        "Aún peor, recientemente se ha demostrado que PageRank puede no funcionar mejor que otras medidas simples en ciertas tareas.",
        "Upstill et al. han encontrado que para la tarea de encontrar páginas de inicio, el número de páginas que enlazan a una página y el tipo de URL fueron tan, o más, efectivos que PageRank [32].",
        "Encontraron resultados similares para la tarea de encontrar empresas de alta calidad [31].",
        "PageRank también se ha utilizado en sistemas para las grandes colecciones de TRECs y competencias de seguimiento web, pero con mucho menos éxito del esperado [17].",
        "Finalmente, Amento et al. [1] encontraron que características simples, como el número de páginas en un sitio, tuvieron un rendimiento tan bueno como PageRank.",
        "A pesar de esto, la creencia general persiste entre muchos, tanto académicos como en el público, de que PageRank es un factor esencial para un buen rango estático.",
        "En caso de que esto falle, se asume que seguir utilizando la estructura de enlaces es crucial, ya sea en forma del número de enlaces entrantes o la cantidad de texto ancla.",
        "En este artículo, demostramos que existen una serie de características simples basadas en URL o en páginas que superan significativamente a PageRank (para el propósito de clasificar estáticamente páginas web) a pesar de ignorar la estructura de la web.",
        "Combinamos estas y otras características estáticas utilizando aprendizaje automático para lograr un sistema de clasificación que es significativamente mejor que PageRank (en acuerdo par a par con etiquetas humanas).",
        "Un enfoque de aprendizaje automático para la clasificación estática tiene otras ventajas además de la calidad de la clasificación.",
        "Debido a que la medida consta de muchas características, es más difícil para los usuarios malintencionados manipularla (es decir, elevar el rango estático de sus páginas a un nivel no merecido a través de técnicas cuestionables, también conocidas como spam en la web).",
        "Esto es especialmente cierto si el conjunto de características no se conoce.",
        "Por el contrario, una sola medida como PageRank puede ser más fácil de manipular porque los spammers solo necesitan concentrarse en un objetivo: cómo hacer que más páginas apunten a su página.",
        "Con un algoritmo que aprende, una característica que se vuelve inutilizable debido a la manipulación de spammers simplemente se reducirá o eliminará del cálculo final de rango.",
        "Esta flexibilidad permite que un sistema de clasificación reaccione rápidamente a nuevas técnicas de spam.",
        "Un enfoque de aprendizaje automático para la clasificación estática también puede aprovechar cualquier avance en el campo del aprendizaje automático.",
        "Por ejemplo, un trabajo reciente sobre clasificación adversarial [12] sugiere que puede ser posible modelar explícitamente las acciones de los spammers de páginas web (el adversario), ajustando el modelo de clasificación de antemano antes de que los spammers intenten evadirlo.",
        "Otro ejemplo es la eliminación de valores atípicos al construir el modelo, lo cual ayuda a reducir el efecto que los sitios únicos pueden tener en la calidad general de la clasificación estática.",
        "Al trasladar la clasificación estática a un marco de aprendizaje automático, no solo ganamos en precisión, sino también en la capacidad de reaccionar a las acciones de los spammers, de añadir rápidamente nuevas características al algoritmo de clasificación y de aprovechar los avances en el campo en rápido crecimiento del aprendizaje automático.",
        "Finalmente, creemos que habrá ventajas significativas al utilizar esta técnica para otros ámbitos, como la búsqueda en un disco duro local o en la intranet de una empresa.",
        "Estos son dominios donde la estructura de enlaces es particularmente débil (o inexistente), pero hay otras características específicas del dominio que podrían ser igual de poderosas.",
        "Por ejemplo, el autor de una página de intranet y su posición en la organización (por ejemplo, CEO, gerente o desarrollador) podrían proporcionar pistas significativas sobre la importancia de esa página.",
        "Un enfoque de aprendizaje automático permite el desarrollo rápido de un buen algoritmo estático en nuevos dominios.",
        "La contribución de este artículo es un estudio sistemático de las características estáticas, incluido PageRank, con el propósito de clasificar páginas web de forma estática.",
        "Estudios previos sobre PageRank típicamente utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas).",
        "Además, el rendimiento de PageRank y otras características estáticas suele evaluarse en el contexto de un sistema completo para la clasificación dinámica, o para otras tareas como la respuesta a preguntas.",
        "Por el contrario, exploramos el uso de PageRank y otras características para la tarea directa de clasificar estáticamente las páginas web.",
        "Primero describimos brevemente el algoritmo PageRank.",
        "En la Sección 3 presentamos RankNet, la técnica de aprendizaje automático utilizada para combinar las características estáticas en un ranking final.",
        "La sección 4 describe las características estáticas.",
        "El corazón del documento está en la Sección 5, la cual presenta nuestros experimentos y resultados.",
        "Concluimos con una discusión sobre el trabajo relacionado y futuro. 2.",
        "PAGERANK La idea básica detrás de PageRank es simple: un enlace de una página web a otra puede ser visto como un respaldo de esa página.",
        "En general, los enlaces son creados por personas.",
        "Por lo tanto, son indicativos de la calidad de las páginas a las que apuntan: al crear una página, un autor presumiblemente elige enlazar a páginas consideradas de buena calidad.",
        "Podemos aprovechar esta información de enlace para ordenar las páginas web según su calidad percibida.",
        "Imagina a un internauta que salta de página web en página web, eligiendo con probabilidad uniforme qué enlace seguir en cada paso.",
        "Para reducir el efecto de los callejones sin salida o ciclos interminables, el surfista saltará ocasionalmente a una página aleatoria con una pequeña probabilidad α, o cuando se encuentre en una página sin enlaces de salida.",
        "Si se promedia sobre un número suficiente de pasos, la probabilidad de que el surfista esté en la página j en algún momento en el tiempo está dada por la fórmula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Donde Fi es el conjunto de páginas a las que enlaza la página i, y Bj es el conjunto de páginas que enlazan a la página j.",
        "El puntaje de PageRank para el nodo j se define como esta probabilidad: PR(j)=P(j).",
        "Dado que la ecuación (1) es recursiva, debe evaluarse de forma iterativa hasta que P(j) converja (normalmente, la distribución inicial para P(j) es uniforme).",
        "La intuición es que, dado que un navegante aleatorio llegaría a la página con más frecuencia, es probable que sea una página mejor.",
        "Una vista alternativa para la ecuación (1) es que a cada página se le asigna una calidad, P(j).",
        "Una página otorga una parte igual de su calidad a cada página a la que apunta.",
        "PageRank es computacionalmente costoso.",
        "Nuestra colección de 5 mil millones de páginas contiene aproximadamente 370 mil millones de enlaces.",
        "Calcular el PageRank requiere iterar sobre miles de millones de enlaces varias veces (hasta converger).",
        "Requiere grandes cantidades de memoria (o esquemas de almacenamiento en caché muy inteligentes que ralentizan aún más el cálculo), y si se distribuye en múltiples máquinas, requiere una comunicación significativa entre ellas.",
        "Aunque se ha realizado mucho trabajo en la optimización del cálculo del PageRank (ver, por ejemplo, [25] y [6]), sigue siendo una propiedad relativamente lenta y costosa computacionalmente de calcular. 3.",
        "RANKNET Se ha realizado mucho trabajo en aprendizaje automático en los problemas de clasificación y regresión.",
        "Sea X={xi} una colección de vectores de características (típicamente, una característica es cualquier número real), y Y={yi} una colección de clases asociadas, donde yi es la clase del objeto descrito por el vector de características xi.",
        "El problema de clasificación consiste en aprender una función f que mapea yi=f(xi), para todo i.",
        "Cuando yi también es un valor real, esto se llama regresión.",
        "La clasificación estática se puede ver como un problema de regresión.",
        "Si dejamos que xi represente las características de la página i, y yi sea un valor (por ejemplo, el rango) para cada página, podríamos aprender una función de regresión que mapeara las características de cada página a su rango.",
        "Sin embargo, esto sobrecarga el problema que deseamos resolver.",
        "Todo lo que realmente nos importa es el orden de las páginas, no el valor real asignado a ellas.",
        "El trabajo reciente sobre este problema de clasificación [7][13][18] intenta directamente optimizar el orden de los objetos, en lugar del valor asignado a ellos.",
        "Para esto, sea Z={<i,j>} una colección de pares de elementos, donde el elemento i debe ser asignado un valor más alto que el elemento j.",
        "El objetivo del problema de clasificación, entonces, es aprender una función f tal que, )()(,, ji ffji xxZ >∈∀ 708. Nótese que, al igual que al aprender una función de regresión, el resultado de este proceso es una función (f) que mapea vectores de características a valores reales.",
        "Esta función todavía se puede aplicar en cualquier lugar donde se pueda aplicar una función aprendida por regresión.",
        "La única diferencia es la técnica utilizada para aprender la función.",
        "Al optimizar directamente el orden de los objetos, estos métodos pueden aprender una función que clasifica mejor que las técnicas de regresión.",
        "Utilizamos RankNet [7], una de las técnicas mencionadas para aprender funciones de clasificación, para aprender nuestra función de clasificación estática.",
        "RankNet es una modificación sencilla del algoritmo de retropropagación de la red neuronal estándar.",
        "Al igual que con back-prop, RankNet intenta minimizar el valor de una función de costo ajustando cada peso en la red de acuerdo con el gradiente de la función de costo con respecto a ese peso.",
        "La diferencia es que, mientras que una función de costo típica de una red neuronal se basa en la diferencia entre la salida de la red y la salida deseada, la función de costo de RankNet se basa en la diferencia entre un par de salidas de la red.",
        "Es decir, para cada par de vectores de características <i,j> en el conjunto de entrenamiento, RankNet calcula las salidas de la red oi y oj.",
        "Dado que se supone que el vector i está clasificado más alto que el vector j, cuanto mayor sea oj-oi, mayor será el costo.",
        "RankNet también permite que los pares en Z sean ponderados con una confianza (expresada como la probabilidad de que el par cumpla con el ordenamiento inducido por la función de clasificación).",
        "En este documento, utilizamos una probabilidad de uno para todos los pares.",
        "En la siguiente sección, discutiremos las características utilizadas en nuestros vectores de características, xi. 4.",
        "Para aplicar RankNet (u otras técnicas de aprendizaje automático) al problema de clasificación, necesitábamos extraer un conjunto de características de cada página.",
        "Dividimos nuestro conjunto de características en cuatro categorías mutuamente excluyentes: a nivel de página (Página), a nivel de dominio (Dominio), texto del enlace y enlaces entrantes (Anclaje) y popularidad (Popularidad).",
        "También opcionalmente utilizamos el PageRank de una página como una característica.",
        "A continuación, describimos cada una de estas categorías de características con más detalle.",
        "Calculamos PageRank en un grafo web de 5 mil millones de páginas rastreadas (y 20 mil millones de URLs conocidas enlazadas por estas páginas).",
        "Esto representa una parte significativa de la Web, y es aproximadamente la misma cantidad de páginas que utilizan Google, Yahoo y MSN para sus motores de búsqueda.",
        "Dado que PageRank es un algoritmo basado en grafos, es importante que se ejecute en la mayor cantidad posible de subconjuntos de la Web.",
        "La mayoría de los estudios previos sobre PageRank utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Calculamos PageRank utilizando el valor estándar de 0.85 para α.",
        "Otra característica que utilizamos es la popularidad real de una página web, medida como el número de veces que ha sido visitada por usuarios durante algún período de tiempo.",
        "Tenemos acceso a esos datos de usuarios que han instalado la barra de herramientas de MSN y han optado por proporcionarlos a MSN.",
        "Los datos se agregan en un recuento, para cada página web, del número de usuarios que vieron esa página.",
        "Aunque los datos de popularidad generalmente no están disponibles, hay otras dos fuentes para obtenerlos.",
        "El primero es de los registros de proxy.",
        "Por ejemplo, una universidad que requiere que sus estudiantes utilicen un proxy tiene un registro de todas las páginas que han visitado mientras están en el campus.",
        "Desafortunadamente, los datos de proxy son bastante sesgados y relativamente pequeños.",
        "Otra fuente, interna de los motores de búsqueda, son los registros de los resultados en los que hicieron clic sus usuarios.",
        "Tales datos fueron utilizados por el motor de búsqueda Direct Hit, y recientemente han sido explorados con fines de clasificación dinámica [20].",
        "Una ventaja de los datos de la barra de herramientas sobre esto es que contiene información sobre las visitas a URL que no son solo el resultado de una búsqueda.",
        "La popularidad en bruto se procesa en una serie de características como el número de veces que se visualizó una página y el número de veces que se visualizó cualquier página en el dominio.",
        "Se proporcionan más detalles en la sección 5.5.",
        "Texto de anclaje e inlinks. Estas características se basan en la información asociada con los enlaces a la página en cuestión.",
        "Incluye características como la cantidad total de texto en los enlaces que apuntan a la página (texto de anclaje), el número de palabras únicas en ese texto, etc.",
        "Esta categoría consiste en características que pueden ser determinadas solo al observar la página (y su URL).",
        "Solo utilizamos ocho características simples como el número de palabras en el cuerpo, la frecuencia del término más común, etc.",
        "Este categoría contiene características que se calculan como promedios en todas las páginas del dominio.",
        "Por ejemplo, el número promedio de enlaces salientes en cualquier página y el PageRank promedio.",
        "Muchas de estas características han sido utilizadas por otros para clasificar páginas web, especialmente las características de anclaje y de la página.",
        "Como se mencionó, la evaluación suele ser para clasificación dinámica, y deseamos evaluar su uso para clasificación estática.",
        "Además, hasta donde sabemos, este es el primer estudio sobre el uso de la popularidad real de visitas a páginas para la clasificación estática.",
        "El trabajo similar más cercano se centra en el uso del comportamiento de clics (es decir, en los resultados de búsqueda en los que los usuarios hacen clic) para afectar la clasificación dinámica (ver, por ejemplo, [20]).",
        "Debido a que utilizamos una amplia variedad de características para crear un ranking estático, nos referimos a esto como fRank (para ranking basado en características). fRank utiliza RankNet y el conjunto de características descritas en esta sección para aprender una función de ranking para páginas web.",
        "A menos que se especifique lo contrario, fRank fue entrenado con todas las características. 5.",
        "EXPERIMENTOS En esta sección, demostraremos que podemos superar a PageRank aplicando aprendizaje automático a un conjunto sencillo de características.",
        "Antes de los resultados, primero discutimos los datos, la métrica de rendimiento y el método de entrenamiento. 5.1 Datos Para evaluar la calidad de un ranking estático, necesitábamos un estándar de oro que definiera el orden correcto para un conjunto de páginas.",
        "Para esto, empleamos un conjunto de datos que contiene juicios humanos para 28000 consultas.",
        "Para cada consulta, un número de resultados son asignados manualmente una calificación, de 0 a 4, por jueces humanos.",
        "La calificación está destinada a ser una medida de cuán relevante es el resultado para la consulta, donde 0 significa pobre y 4 significa excelente.",
        "Hay aproximadamente 500 mil juicios en total, o un promedio de 18 calificaciones por consulta.",
        "Las consultas se seleccionan eligiendo aleatoriamente consultas de entre aquellas emitidas al motor de búsqueda de MSN.",
        "La probabilidad de que se seleccione una consulta es proporcional a su frecuencia entre las 709 consultas.",
        "Como resultado, es más probable que las consultas comunes sean evaluadas que las consultas poco comunes.",
        "Como ejemplo de la diversidad de las consultas, las primeras cuatro consultas en el conjunto de entrenamiento son escuelas de chef, el autódromo de Chicagoland, el club de fans de los Eagles y la cultura turca.",
        "Los documentos seleccionados para evaluar son aquellos que esperábamos que, en promedio, fueran razonablemente relevantes (por ejemplo, los diez documentos principales devueltos por el motor de búsqueda de MSN).",
        "Esto proporciona significativamente más información que seleccionar documentos al azar en la web, la gran mayoría de los cuales serían irrelevantes para una consulta específica.",
        "Debido a este proceso, las páginas evaluadas tienden a ser de mayor calidad que la página promedio en la web, y suelen ser páginas que se devolverán en consultas de búsqueda comunes.",
        "Este sesgo es útil al evaluar la calidad de la clasificación estática con el fin de ordenar índices y devolver documentos relevantes.",
        "Esto se debe a que la parte más importante del índice que debe estar bien ordenada y ser relevante es la parte que se devuelve con frecuencia para las consultas de búsqueda.",
        "Debido a este sesgo, sin embargo, los resultados en este documento no son aplicables a la priorización de rastreo.",
        "Para obtener resultados experimentales sobre la priorización de rastreo, necesitaríamos calificaciones de una muestra aleatoria de páginas web.",
        "Para convertir los datos de dependientes de la consulta a independientes de la consulta, simplemente eliminamos la consulta, tomando el máximo sobre las evaluaciones para una URL que aparece en más de una consulta.",
        "El razonamiento detrás de esto es que una página que es relevante para una consulta y no relevante para otra probablemente sea una buena página y debería tener un alto rango estático.",
        "Debido a que evaluamos las páginas en consultas que ocurren con frecuencia, nuestros datos indican el orden correcto del índice y asignan un alto valor a las páginas que probablemente sean relevantes para una consulta común.",
        "Asignamos consultas al azar a un conjunto de entrenamiento, validación o prueba, de modo que contuvieran el 84%, 8% y 8% de las consultas, respectivamente.",
        "Cada conjunto contiene todas las calificaciones para una consulta dada, y ninguna consulta aparece en más de un conjunto.",
        "El conjunto de entrenamiento se utilizó para entrenar fRank.",
        "El conjunto de validación se utilizó para seleccionar el modelo que tuvo el mejor rendimiento.",
        "El conjunto de pruebas se utilizó para los resultados finales.",
        "Estos datos nos proporcionan un ordenamiento de páginas independiente de la consulta.",
        "El objetivo de un algoritmo de clasificación estática será reproducir este orden lo más fielmente posible.",
        "En la siguiente sección, describimos la medida que utilizamos para evaluar esto. 5.2 Medida Elegimos utilizar la precisión por pares para evaluar la calidad de un ranking estático.",
        "La precisión por pares es la fracción de tiempo en la que el algoritmo de clasificación y los jueces humanos están de acuerdo en el ordenamiento de un par de páginas web.",
        "Si S(x) es la clasificación estática asignada a la página x, y H(x) es el juicio humano de relevancia para x, entonces considera los siguientes conjuntos: )}()(:,{ yHxHyx >=pH y )}()(:,{ ySxSyx >=pS La precisión por pares es la porción de Hp que también está contenida en Sp: p pp H SH ∩ =precisiónpares Esta medida fue elegida por dos razones.",
        "Primero, los juicios humanos discretos proporcionan solo un orden parcial sobre las páginas web, lo que dificulta aplicar una medida como el coeficiente de correlación de orden de rango de Spearman (en la medida de precisión por pares, un par de documentos con el mismo juicio humano no afecta la puntuación).",
        "Segundo, la precisión por pares tiene un significado intuitivo: es la fracción de pares de documentos que, cuando los humanos afirman que uno es mejor que el otro, el algoritmo de clasificación estática los ordena correctamente. 5.3 Método Entrenamos fRank (una red neuronal basada en RankNet) utilizando los siguientes parámetros.",
        "Utilizamos una red de 2 capas completamente conectadas.",
        "La capa oculta tenía 10 nodos ocultos.",
        "Los pesos de entrada a esta capa se inicializaron todos en cero.",
        "Los pesos de la capa de salida (solo un nodo) se inicializaron utilizando una distribución aleatoria uniforme en el rango [-0.1, 0.1].",
        "Utilizamos la función tangente hiperbólica (tanh) como función de transferencia de las entradas a la capa oculta, y una función lineal de la capa oculta a la salida.",
        "La función de costo es la función de costo de entropía cruzada por pares discutida en la sección 3.",
        "Las características en el conjunto de entrenamiento fueron normalizadas para tener media cero y desviación estándar unitaria.",
        "La misma transformación lineal fue luego aplicada a las características en los conjuntos de validación y prueba.",
        "Para el entrenamiento, presentamos a la red neuronal 5 millones de pares de páginas, donde una página tenía una calificación más alta que la otra.",
        "Las combinaciones fueron elegidas de forma uniforme al azar (con reemplazo) de todas las combinaciones posibles.",
        "Al formar las parejas, ignoramos la magnitud de la diferencia entre las calificaciones (la dispersión de calificaciones) de las dos URL.",
        "Por lo tanto, el peso para cada par era constante (uno), y la probabilidad de que se seleccionara un par era independiente de la diferencia de calificación.",
        "Entrenamos la red durante 30 épocas.",
        "En cada época, los pares de entrenamiento fueron mezclados aleatoriamente.",
        "La tasa de entrenamiento inicial fue de 0.001.",
        "En cada época, verificamos el error en el conjunto de entrenamiento.",
        "Si el error hubiera aumentado, entonces disminuimos la tasa de entrenamiento, bajo la hipótesis de que la red probablemente se había excedido.",
        "La tasa de entrenamiento en cada época se estableció de la siguiente manera: Tasa de entrenamiento = 1+ε κ Donde κ es la tasa inicial (0.001), y ε es el número de veces que el error del conjunto de entrenamiento ha aumentado.",
        "Después de cada época, medimos el rendimiento de la red neuronal en el conjunto de validación, utilizando 1 millón de pares (elegidos al azar con reemplazo).",
        "La red con la mayor precisión en pares en el conjunto de validación fue seleccionada, y luego probada en el conjunto de pruebas.",
        "Informamos la precisión por pares en el conjunto de pruebas, calculada utilizando todos los pares posibles.",
        "Estos parámetros fueron determinados y fijados antes de los experimentos de clasificación estática en este artículo.",
        "En particular, la elección de la tasa de entrenamiento inicial, el número de épocas y la función de decaimiento de la tasa de entrenamiento se tomaron directamente de Burges et al [7].",
        "Aunque teníamos la opción de preprocesar cualquiera de las características antes de introducirlas en la red neuronal, nos abstuvimos de hacerlo en la mayoría de ellas.",
        "La única excepción fueron las características de popularidad.",
        "Como ocurre con la mayoría de los fenómenos web, descubrimos que la distribución de la popularidad de los sitios es Zipfiana.",
        "Para reducir el rango dinámico, y con suerte hacer que la característica sea más útil, presentamos a la red tanto las características de popularidad sin procesar, como el logaritmo de las mismas (Al igual que con las demás, los valores de las características logarítmicas también se normalizaron para tener media cero y desviación estándar unitaria). Aplicar fRank a un documento es computacionalmente eficiente, tomando un tiempo que es solo lineal en el número de características de entrada; por lo tanto, está dentro de un factor constante de otros métodos de aprendizaje automático simples como el Bayes ingenuo.",
        "En nuestros experimentos, calcular el fRank para las cinco mil millones de páginas web fue aproximadamente 100 veces más rápido que calcular el PageRank para el mismo conjunto. 5.4 Resultados Como muestra la Tabla 1, el fRank supera significativamente al PageRank para los propósitos de clasificación estática.",
        "Con una precisión de pares del 67.4%, fRank más que duplica la precisión de PageRank (en relación con la línea base del 50%, que es la precisión que se lograría con un orden aleatorio de páginas web).",
        "Ten en cuenta que una de las características de entrada de fRanks es el PageRank de la página, por lo que esperaríamos que su rendimiento no fuera peor que el de PageRank.",
        "El aumento significativo en precisión implica que las otras características (anclaje, popularidad, etc.) de hecho contienen información útil sobre la calidad general de una página.",
        "Tabla 1: Resultados Básicos Técnica Precisión (%) Ninguna (Línea base) 50.00 PageRank 56.70 fRank 67.43 Existen varias decisiones que intervienen en el cálculo de PageRank, como por ejemplo cómo tratar las páginas que no tienen enlaces salientes, la elección de α, la precisión numérica, el umbral de convergencia, etc.",
        "Pudimos obtener un cálculo de PageRank a partir de una implementación completamente independiente (proporcionada por Marc Najork) que variaba ligeramente en estos parámetros.",
        "Obtuvo una precisión de pares del 56.52%, casi idéntica a la obtenida por nuestra implementación.",
        "Por lo tanto, concluimos que la calidad del PageRank no es sensible a estas variaciones menores en el algoritmo, ni la baja precisión de los PageRanks se debió a problemas con nuestra implementación de él.",
        "También queríamos averiguar qué tan bien se desempeñaba cada conjunto de características.",
        "Para responder a esto, para cada conjunto de características, entrenamos y probamos fRank utilizando solo ese conjunto de características.",
        "Los resultados se muestran en la Tabla 2.",
        "Como se puede ver, cada conjunto de características individual superó a PageRank en esta prueba.",
        "Quizás el resultado más interesante es que las características a nivel de página tuvieron el mejor rendimiento de todos los conjuntos de características.",
        "Esto es sorprendente porque estas son características que no dependen de la estructura general del grafo de la Web, ni siquiera de qué páginas apuntan a una página dada.",
        "Esto va en contra de la creencia común de que la estructura del grafo web es la clave para encontrar una buena clasificación estática de las páginas web.",
        "Tabla 2: Resultados para conjuntos de características individuales.",
        "Debido a que estamos utilizando una red neuronal de dos capas, las características en la red aprendida pueden interactuar entre sí de maneras interesantes y no lineales.",
        "Esto significa que una característica particular que parece tener poco valor por sí sola podría ser muy importante cuando se utiliza en combinación con otras características.",
        "Para medir la contribución final de un conjunto de características, en el contexto de todas las demás características, realizamos un estudio de ablación.",
        "Es decir, para cada conjunto de características, entrenamos una red para contener todas las características excepto ese conjunto.",
        "Luego comparamos el rendimiento de la red resultante con el rendimiento de la red con todas las características.",
        "La Tabla 3 muestra los resultados de este experimento, donde la disminución en la precisión es la diferencia en la precisión por pares entre la red entrenada con todas las características y la red que carece del conjunto de características dado.",
        "Tabla 3: Estudio de ablación.",
        "Se muestra la disminución en precisión cuando entrenamos una red que tiene todas las características excepto el conjunto dado.",
        "La última línea muestra el efecto de eliminar las características del ancla, PageRank y dominio, por lo tanto, un modelo que no contiene ninguna información de red o basada en enlaces.",
        "Los resultados del estudio de ablación son consistentes con el estudio de conjunto de características individuales.",
        "Ambos muestran que el conjunto de características más importante es el conjunto de características a nivel de página, y el segundo más importante es el conjunto de características de popularidad.",
        "Finalmente, deseábamos ver cómo mejoraba el rendimiento de fRank a medida que añadíamos características; queríamos encontrar en qué punto añadir más conjuntos de características se volvía relativamente inútil.",
        "Comenzando sin características, añadimos ávidamente el conjunto de características que mejoró el rendimiento en mayor medida.",
        "Los resultados se muestran en la Tabla 4.",
        "Por ejemplo, la cuarta línea de la tabla muestra que fRank utilizando las características de página, popularidad y anclaje superó a cualquier red que utilizara la página, popularidad y algún otro conjunto de características, y que el rendimiento de esta red fue del 67.25%.",
        "Tabla 4: Rendimiento de fRank a medida que se agregan conjuntos de características.",
        "En cada fila, se añadió al conjunto de características aquella que proporcionó el mayor aumento en la precisión (es decir, realizamos una búsqueda ávida sobre conjuntos de características).",
        "Precisión del conjunto de características (%) Ninguna 50.00 +Página 63.93 +Popularidad 66.83 +Anclaje 67.25 +PageRank 67.31 +Dominio 67.43 711 Finalmente, presentamos una comparación cualitativa de PageRank vs. fRank.",
        "En la Tabla 5 se encuentran las diez URL principales devueltas para PageRank y para fRank.",
        "Los resultados de PageRank están fuertemente ponderados hacia sitios de tecnología.",
        "Contiene dos URL de QuickTime (software de reproducción de video de Apple), así como URL de Internet Explorer y FireFox (ambos navegadores web). Por otro lado, fRank contiene sitios más orientados al consumidor como American Express, Target, Dell, etc.",
        "El sesgo de PageRank hacia la tecnología puede explicarse a través de dos procesos.",
        "Primero, hay muchas páginas con botones en la parte inferior que sugieren que el sitio está optimizado para Internet Explorer, o que el visitante necesita QuickTime.",
        "Estos enlaces generalmente remiten, en estos ejemplos, a los sitios de descarga de Internet Explorer y QuickTime.",
        "Por consiguiente, PageRank clasifica esas páginas en posiciones altas.",
        "Aunque estas páginas son importantes, no son tan importantes como podría parecer al observar solo la estructura de enlaces.",
        "Una solución para esto es agregar información sobre el enlace al cálculo del PageRank, como el tamaño del texto, si estaba en la parte inferior de la página, etc.",
        "El otro sesgo proviene del hecho de que la población de autores de sitios web es diferente a la población de usuarios de la web.",
        "Los autores web tienden a estar orientados tecnológicamente, por lo que su comportamiento de enlace refleja esos intereses. fRank, al conocer la popularidad real de visitas de un sitio (el conjunto de características de popularidad), puede eliminar parte de ese sesgo.",
        "Tiene la capacidad de depender más de dónde visitan los usuarios reales de la Web que de dónde han enlazado los autores del sitio web.",
        "Los resultados confirman que fRank supera a PageRank en precisión por pares.",
        "Los dos conjuntos de características más importantes son las características de la página y de la popularidad.",
        "Esto es sorprendente, ya que las características de la página consistían solo en unas pocas (8) características simples.",
        "Experimentos adicionales encontraron que, de las características de la página, aquellas basadas en el texto de la página (en contraposición a la URL) tuvieron el mejor rendimiento.",
        "En la siguiente sección, exploramos la característica de popularidad con más detalle. 5.5 Datos de Popularidad Como se mencionó en la sección 4, nuestros datos de popularidad provienen de usuarios de la barra de herramientas de MSN.",
        "Por razones de privacidad, solo tuvimos acceso a un recuento agregado de cuántas veces fue visitada cada URL por cualquier usuario de la barra de herramientas.",
        "Esto limitó las características posibles que podríamos derivar de estos datos.",
        "Para posibles extensiones, consulte la sección 6.3, trabajo futuro.",
        "Para cada URL en nuestros conjuntos de entrenamiento y prueba, proporcionamos una característica a fRank que indicaba cuántas veces había sido visitada por un usuario de la barra de herramientas.",
        "Sin embargo, esta característica era bastante ruidosa y dispersa, especialmente para URL con parámetros de consulta (por ejemplo, http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
        "Una solución fue proporcionar una característica adicional que era el número de veces que cualquier URL en el dominio dado fue visitada por un usuario de la barra de herramientas.",
        "La adición de esta característica mejoró drásticamente el rendimiento de fRank.",
        "Llevamos esto un paso más allá y utilizamos la estructura jerárquica incorporada de las URL para construir varios niveles de retroceso entre la URL completa y el dominio.",
        "Lo hicimos utilizando el conjunto de características mostradas en la Tabla 6.",
        "Tabla 6: Funciones de URL utilizadas para calcular el conjunto de características de Popularidad.",
        "Cada URL fue asignado una característica para cada función mostrada en la tabla.",
        "El valor de la característica era el recuento de la cantidad de veces que un usuario de la barra de herramientas visitó una URL, donde la función aplicada a esa URL coincide con la función aplicada a la URL en cuestión.",
        "Por ejemplo, la visita de un usuario a cnn.com/2005/sports.html incrementaría las características de Dominio y Dominio+1 para la URL cnn.com/2005/tech/wikipedia.html.",
        "Como se observa en la Tabla 7, agregar los recuentos de dominio mejoró significativamente la calidad de la característica de popularidad, y agregar las numerosas funciones de respaldo enumeradas en la Tabla 6 mejoró aún más la precisión.",
        "Tabla 7: Efecto de agregar retroceso a la característica de popularidad Conjunto de características Precisión (%) Recuento de URL 58.15 Recuento de URL y dominio 59.31 Todas las funciones de retroceso (Tabla 6) 60.82 Tabla 5: Diez mejores URL para PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Retroceder a subconjuntos de la URL es una técnica para tratar la escasez de datos.",
        "También es informativo ver cómo el rendimiento de fRank depende de la cantidad de datos de popularidad que hemos recopilado.",
        "En la Figura 1 mostramos el rendimiento de fRank entrenado solo con el conjunto de características de popularidad frente a la cantidad de datos que tenemos para el conjunto de características de popularidad.",
        "Cada día recibimos datos adicionales de popularidad, y como se puede ver en el gráfico, esto aumenta el rendimiento de fRank.",
        "La relación es logarítmica: duplicar la cantidad de datos de popularidad proporciona una mejora constante en la precisión de pares.",
        "En resumen, hemos encontrado que las características de popularidad proporcionan un impulso útil a la precisión general de fRank.",
        "Recopilando más datos de popularidad, así como empleando estrategias de retroceso simples, se mejora aún más este impulso. 5.6 Resumen de Resultados Los experimentos proporcionan varias conclusiones.",
        "Primero, fRank funciona significativamente mejor que PageRank, incluso sin tener información sobre el grafo web.",
        "En segundo lugar, las características a nivel de página y de popularidad fueron los contribuyentes más significativos a la precisión por pares.",
        "Tercero, al recopilar más datos de popularidad, podemos seguir mejorando el rendimiento de fRanks.",
        "Los datos de popularidad proporcionan dos beneficios a fRank.",
        "Primero, observamos que cualitativamente, el ordenamiento de fRanks de las páginas web tiene un sesgo más favorable que PageRanks. El ordenamiento de fRanks parece corresponder a lo que los usuarios de la web, en lugar de los autores de las páginas web, prefieren.",
        "Segundo, los datos de popularidad son más actuales que la información de enlaces de PageRank.",
        "La barra de herramientas proporciona información sobre qué páginas web encuentran interesantes las personas en este momento, mientras que los enlaces se agregan a las páginas más lentamente, a medida que los autores encuentran el tiempo y el interés.",
        "TRABAJO RELACIONADO Y FUTURO 6.1 Mejoras a PageRank Desde el artículo original de PageRank, ha habido trabajos para mejorarlo.",
        "Gran parte de ese trabajo se centra en acelerar y paralelizar el cálculo [15][25].",
        "Un problema reconocido con PageRank es el de la deriva de temas: una página sobre perros tendrá un alto PageRank si está vinculada por muchas páginas que a su vez tienen un alto rango, independientemente de su tema.",
        "Por el contrario, un usuario de un motor de búsqueda que busca buenas páginas sobre perros probablemente preferiría encontrar páginas que son enlazadas por muchas páginas que tratan sobre perros.",
        "Por lo tanto, un enlace que esté relacionado con el tema debería tener más peso que un enlace que no lo esté.",
        "Richardson y el PageRank Dependiente de Consulta de Domingos [29] y el PageRank Sensible al Tema de Haveliwala [16] son dos enfoques que abordan este problema.",
        "Otras variaciones de PageRank incluyen ponderar de manera diferente los enlaces para enlaces inter e intra-dominio, agregar un paso hacia atrás al surfista aleatorio para simular el botón de retroceso en la mayoría de los navegadores [24] y modificar la probabilidad de salto (α) [3].",
        "Consulte Langville y Meyer [23] para obtener una buena revisión de estas y otras modificaciones a PageRank. 6.2 Otros trabajos relacionados PageRank no es el único algoritmo de análisis de enlaces utilizado para clasificar páginas web.",
        "El otro más conocido es HITS [22], que es utilizado por el motor de búsqueda Teoma [30].",
        "HITS produce una lista de hubs y autoridades, donde los hubs son páginas que apuntan a muchas páginas de autoridad, y las autoridades son páginas a las que apuntan muchos hubs.",
        "Trabajos anteriores han demostrado que HITS tiene un rendimiento comparable al de PageRank [1].",
        "Un campo de interés es el de la poda de índices estáticos (ver, por ejemplo, Carmel et al. [8]).",
        "Los métodos de poda de índices estáticos reducen el tamaño del índice de los motores de búsqueda al eliminar documentos que es poco probable que sean devueltos por una consulta de búsqueda.",
        "La poda se realiza típicamente en función de la frecuencia de los términos de consulta.",
        "De manera similar, Pandey y Olston [28] sugieren rastrear las páginas con frecuencia si es probable que aparezcan incorrectamente (o no aparezcan) como resultado de una búsqueda.",
        "Métodos similares podrían ser incorporados en la clasificación estática (por ejemplo, cuántas consultas frecuentes contienen palabras encontradas en esta página).",
        "Otros han investigado el efecto que PageRank tiene en la Web en general [9].",
        "Argumentan que las páginas con un alto PageRank son más propensas a ser encontradas por los usuarios de la web, por lo tanto, es más probable que sean enlazadas y, por ende, mantengan un PageRank más alto que otras páginas.",
        "Lo mismo puede ocurrir con los datos de popularidad.",
        "Si aumentamos la clasificación de las páginas populares, es más probable que se haga clic en ellas, lo que a su vez aumentará aún más su popularidad.",
        "Cho et al. [10] argumentan que una medida más apropiada de la calidad de una página web dependería no solo de la estructura de enlaces actual de la web, sino también de los cambios en esa estructura de enlaces.",
        "La misma técnica puede ser aplicable a los datos de popularidad: el cambio en la popularidad de una página puede ser más informativo que la popularidad absoluta.",
        "Un trabajo relacionado interesante es el de Ivory y Hearst [19].",
        "Su objetivo era construir un modelo de sitios web que son considerados de alta calidad desde la perspectiva de contenido, estructura y navegación, diseño visual, funcionalidad, interactividad y experiencia general.",
        "Utilizaron más de 100 características a nivel de página, así como características que abarcan el rendimiento y la estructura del sitio.",
        "Esto les permitió describir cualitativamente las cualidades de una página que la hacen parecer atractiva (por ejemplo, el uso poco común de cursivas, al menos una fuente de 9 puntos, ...), y (en trabajos posteriores) construir un sistema que ayude a los autores de páginas web novedosas a crear páginas de calidad evaluándolas según estas características.",
        "Las principales diferencias entre este trabajo y el nuestro son el objetivo (descubrir qué constituye una buena página web vs. ordenar páginas web con fines de búsqueda en la web), el tamaño del estudio (utilizaron un conjunto de datos de menos de 6000 páginas vs. nuestro conjunto de 468,000), y nuestra comparación con PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Días de Datos de la Barra de Herramientas Precisión por Pares Figura 1: Relación entre la cantidad de datos de popularidad y el rendimiento del conjunto de características de popularidad.",
        "Ten en cuenta que el eje x es una escala logarítmica. Sin embargo, su trabajo proporciona ideas sobre características estáticas adicionales útiles que podríamos incorporar en fRank en el futuro.",
        "El trabajo reciente sobre la incorporación de características novedosas en la clasificación dinámica incluye el realizado por Joachims et al. [21], quienes investigan el uso de retroalimentación implícita de los usuarios, en forma de los resultados de búsqueda en el motor de búsqueda que se hacen clic.",
        "Craswell et al. [11] presentan un método para determinar la mejor transformación a aplicar a las características independientes de la consulta (como las utilizadas en este artículo) con el fin de mejorar la clasificación dinámica.",
        "Otros trabajos, como el de Boyan et al. [4] y Bartell et al. [2], aplican aprendizaje automático con el propósito de mejorar la relevancia general de un motor de búsqueda (es decir, el ranking dinámico).",
        "No aplican sus técnicas al problema de clasificación estática. 6.3 Trabajo futuro Hay muchas formas en las que nos gustaría ampliar este trabajo.",
        "Primero, Frank utiliza solo un pequeño número de características.",
        "Creemos que podríamos lograr resultados aún más significativos con más características.",
        "En particular, la existencia o falta de ciertas palabras podría resultar muy significativa (por ejemplo, \"en construcción\" probablemente signifique una página de baja calidad).",
        "Otras características podrían incluir el número de imágenes en una página, el tamaño de esas imágenes, el número de elementos de diseño (tablas, divs y spans), el uso de hojas de estilo, la conformidad con los estándares de W3C (como XHTML 1.0 Strict), el color de fondo de una página, etc.",
        "Muchas páginas se generan dinámicamente, cuyos contenidos pueden depender de parámetros en la URL, la hora del día, el usuario que visita el sitio, u otras variables.",
        "Para este tipo de páginas, puede ser útil aplicar las técnicas encontradas en [26] para formar una aproximación estática con el fin de extraer características.",
        "La gramática resultante que describe la página podría ser en sí misma una fuente de características adicionales que describen la complejidad de la página, como cuántos nodos no terminales tiene, la profundidad del árbol gramatical, etc. fRank permite especificar una confianza en cada emparejamiento de documentos.",
        "En el futuro, experimentaremos con probabilidades que dependen de la diferencia en los juicios humanos entre los dos elementos del par.",
        "Por ejemplo, un par de documentos donde uno fue calificado con un 4 y el otro con un 0 debería tener una mayor confianza que un par de documentos calificados con un 3 y un 2.",
        "Los experimentos en este artículo están sesgados hacia páginas que tienen una calidad superior al promedio.",
        "Además, fRank con todas las características solo se puede aplicar a páginas que ya han sido rastreadas.",
        "Por lo tanto, fRank es principalmente útil para el ordenamiento de índices y mejorar la relevancia, no para dirigir el rastreo.",
        "Nos gustaría investigar un enfoque de aprendizaje automático para la priorización de rastreo también.",
        "Puede ser que la mejor opción sea una combinación de métodos: por ejemplo, utilizar PageRank para seleccionar los mejores 5 mil millones de las 20 mil millones de páginas en la web, luego utilizar fRank para ordenar el índice y afectar la relevancia de la búsqueda.",
        "Otra dirección interesante para la exploración es incorporar las características de fRank y a nivel de página directamente en el cálculo de PageRank en sí mismo.",
        "El trabajo en el sesgo del vector de salto de PageRank [16] y la matriz de transición [29] ha demostrado la viabilidad y ventajas de este enfoque.",
        "Existe motivo para creer que una aplicación directa de [29], utilizando el fRank de una página para su relevancia, podría llevar a una mejora en el rango estático general.",
        "Finalmente, los datos de popularidad pueden ser utilizados de otras maneras interesantes.",
        "Los hábitos generales de navegación y búsqueda de los usuarios de la web varían según la hora del día.",
        "La actividad por la mañana, durante el día y en la tarde suele ser bastante diferente (por ejemplo, leer las noticias, resolver problemas y acceder al entretenimiento, respectivamente).",
        "Podemos obtener información sobre estas diferencias utilizando los datos de popularidad, divididos en segmentos del día.",
        "Cuando se emite una consulta, luego utilizaríamos los datos de popularidad que coincidan con el momento de la consulta para clasificar las páginas web.",
        "También planeamos explorar características de popularidad que utilicen más que solo el recuento de cuántas veces se visitó una página.",
        "Por ejemplo, cuánto tiempo los usuarios solían permanecer en una página, si abandonaron la página haciendo clic en un enlace o presionando el botón de retroceso, etc.",
        "Fox et al. realizaron un estudio que demostró que características como esta pueden ser valiosas para los propósitos de clasificación dinámica [14].",
        "Finalmente, los datos de popularidad podrían ser utilizados como la etiqueta en lugar de como una característica.",
        "Utilizar fRank de esta manera para predecir la popularidad de una página puede ser útil para las tareas de relevancia, eficiencia y prioridad de rastreo.",
        "También hay significativamente más datos de popularidad que datos etiquetados por humanos, lo que potencialmente permite el uso de métodos de aprendizaje automático más complejos y muchas más características. 7.",
        "CONCLUSIONES Un buen ranking estático es un componente importante para los motores de búsqueda y sistemas de recuperación de información actuales.",
        "Hemos demostrado que PageRank no proporciona una clasificación estática muy buena; hay muchas características simples que superan individualmente a PageRank.",
        "Al combinar muchas características estáticas, fRank logra un ranking que tiene una precisión en pares significativamente mayor que PageRank solo.",
        "Una evaluación cualitativa de los documentos principales muestra que fRank está menos sesgado hacia la tecnología que PageRank; al utilizar datos de popularidad, está sesgado hacia las páginas que los usuarios de la web visitan, en lugar de hacia las páginas que los autores web crean.",
        "El componente de aprendizaje automático de fRank le otorga el beneficio adicional de ser más robusto contra los spammers, y le permite aprovechar los avances adicionales en la comunidad de aprendizaje automático en áreas como la clasificación adversarial.",
        "Hemos comenzado a explorar las opciones y creemos que se pueden lograr avances significativos en el área de clasificación estática mediante experimentación adicional con características adicionales, otras técnicas de aprendizaje automático y fuentes de datos adicionales.",
        "AGRADECIMIENTOS Gracias a Marc Najork por proporcionarnos cálculos adicionales de PageRank y a Timo Burkard por su ayuda con los datos de popularidad.",
        "Muchas gracias a Chris Burges por proporcionar código y un apoyo significativo en el uso del entrenamiento de RankNets.",
        "También agradecemos a Susan Dumais y Nick Craswell por sus ediciones y sugerencias. 9.",
        "REFERENCIAS [1] B. Amento, L. Terveen y W. Hill.",
        "¿Significa autoridad calidad?",
        "Prediciendo las calificaciones de calidad de expertos de documentos web.",
        "En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2000. [2] B. Bartell, G. Cottrell y R. Belew.",
        "Combinación automática de múltiples sistemas de recuperación clasificados.",
        "En Actas de la 17ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 1994. [3] P. Boldi, M. Santini y S. Vigna.",
        "PageRank como una función del factor de amortiguamiento.",
        "En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. 714 [4] J. Boyan, D. Freitag y T. Joachims.",
        "Una arquitectura de aprendizaje automático para optimizar los motores de búsqueda web.",
        "En el taller de AAAI sobre Sistemas de Información Basados en Internet, agosto de 1996. [5] S. Brin y L. Page.",
        "La anatomía de un motor de búsqueda web hipertextual a gran escala.",
        "En Actas de la Séptima Conferencia Internacional de la World Wide Web, Brisbane, Australia, 1998.",
        "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul y J. Pederson.",
        "Aproximación eficiente de PageRank a través de la agregación de grafos.",
        "En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
        "Aprendiendo a clasificar utilizando descenso de gradiente.",
        "En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, Bonn, Alemania, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek y A. Soffer.",
        "Poda de índices estáticos para sistemas de recuperación de información.",
        "En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 43-50, Nueva Orleans, Luisiana, EE. UU., septiembre de 2001. [9] J. Cho y S. Roy.",
        "Impacto de los motores de búsqueda en la popularidad de las páginas.",
        "En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [10]J. Cho, S. Roy, R. Adams.",
        "Calidad de la página: En busca de una clasificación web imparcial.",
        "En las Actas de la Conferencia ACM SIGMOD 2005.",
        "Baltimore, Maryland.",
        "Junio de 2005. N. Craswell, S. Robertson, H. Zaragoza y M. Taylor.",
        "Ponderación de relevancia para evidencia independiente de la consulta.",
        "En Actas de la 28ª Conferencia Anual sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), agosto de 2005. [12] N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
        "Clasificación adversarial.",
        "En Actas de la Décima Conferencia Internacional sobre Descubrimiento de Conocimiento y Minería de Datos (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning y Y.",
        "Cantante.",
        "Modelos log-lineales para clasificación de etiquetas.",
        "En Avances en Sistemas de Procesamiento de Información Neural 16.",
        "Cambridge, MA: MIT Press, 2003. [14] S. Fox, K. S. Fox, K. Karnawat, M. Mydland, S. T. Dumais y T. White (2005).",
        "Evaluando medidas implícitas para mejorar las experiencias de búsqueda.",
        "En la revista ACM Transactions on Information Systems, 23(2), pp. 147-168.",
        "Abril de 2005. [15] T. Haveliwala.",
        "Cálculo eficiente de PageRank.",
        "Informe técnico de la Universidad de Stanford, 1999. [16] T. Haveliwala.",
        "PageRank sensible al tema.",
        "En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2002. [17] D. Hawking y N. Craswell.",
        "Recuperación a gran escala y búsqueda en la web.",
        "En D. Harman y E. Voorhees (eds), El Libro de TREC.",
        "MIT Press. [18] R. Herbrich, T. Graepel y K. Obermayer.",
        "Aprendizaje de vectores de soporte para regresión ordinal.",
        "En Actas de la Novena Conferencia Internacional sobre Redes Neuronales Artificiales, pp. 97-102. 1999. [19] M. Ivory y M. Hearst.",
        "Perfiles estadísticos de sitios web altamente valorados.",
        "En Actas de la Conferencia ACM SIGCHI sobre Factores Humanos en Sistemas Informáticos, 2002. [20]T. Joachims.",
        "Optimización de motores de búsqueda utilizando datos de clics.",
        "En Actas de la Conferencia de la ACM sobre Descubrimiento de Conocimiento y Minería de Datos (KDD), 2002. [21] T. Joachims, L. Granka, B. Pang, H. Hembrooke y G. Gay.",
        "Interpretación precisa de los datos de clics como retroalimentación implícita.",
        "En Actas de la Conferencia sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2005. [22]J. Kleinberg.",
        "Fuentes autorizadas en un entorno hiperenlazado.",
        "Revista de la ACM 46:5, pp. 604-32. 1999. [23]A. Langville y C. Meyer.",
        "Más profundo dentro de PageRank.",
        "Matemáticas en Internet 1(3):335-380, 2004. [24] F. Matthieu y M. Bouklit.",
        "El efecto del botón de retroceso en un paseo aleatorio: aplicación para PageRank.",
        "En los trabajos y pósters de la pista alternativa de la Decimotercera Conferencia Internacional de la World Wide Web, 2004. [25]F. McSherry.",
        "Un enfoque uniforme para el cálculo acelerado de PageRank.",
        "En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [26] Y. Minamide.",
        "Aproximación estática de páginas web generadas dinámicamente.",
        "En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [27] L. Page, S. Brin, R. Motwani y T. Winograd.",
        "El ranking de citas PageRank: Trayendo orden a la web.",
        "Informe técnico, Universidad de Stanford, Stanford, CA, 1998. [28] S. Pandey y C. Olston.",
        "Rastreo web centrado en el usuario.",
        "En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [29] M. Richardson y P. Domingos.",
        "El surfista inteligente: combinación probabilística de la información de enlaces y contenido en PageRank.",
        "En Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
        "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.\nCambridge, MA: MIT Press, 2002. [30]C. Sherman.",
        "Teoma vs. Google, Ronda 2.",
        "Disponible en World Wide Web (http://dc.internet.com/news/article.php/1002061), 2002. [31] T. Upstill, N. Craswell y D. Hawking.",
        "Prediciendo fama y fortuna: ¿PageRank o grado de entrada?",
        "En el Octavo Simposio de Computación de Documentos Australasiano. 2003. [32] T. Upstill, N. Craswell y D. Hawking.",
        "Evidencia independiente de la consulta en la búsqueda de la página de inicio.",
        "En ACM Transactions on Information Systems. 2003. 715"
    ],
    "error_count": 0,
    "keys": {
        "pagerank": {
            "translated_key": "PageRank",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Beyond <br>pagerank</br>: Machine Learning for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on <br>pagerank</br>, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We show that we can significantly outperform <br>pagerank</br> using features that are independent of the link structure of the Web.",
                "We gain a further boost in accuracy by using data on the frequency at which users visit Web pages.",
                "We use RankNet, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for <br>pagerank</br> or 50% for random).",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning.",
                "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval.",
                "General Terms Algorithms, Measurement, Performance, Experimentation. 1.",
                "INTRODUCTION Over the past decade, the Web has grown exponentially in size.",
                "Unfortunately, this growth has not been isolated to good-quality pages.",
                "The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly.",
                "The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information.",
                "Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first.",
                "To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking).",
                "However, having a good query-independent ranking (static ranking) is also crucially important for a search engine.",
                "A good static ranking algorithm provides numerous benefits: • Relevance: The static rank of a page provides a general indicator to the overall quality of the page.",
                "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by static rank.",
                "By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found.",
                "The more accurate the static rank, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages.",
                "Among other factors, the static rank of a page is used to determine this prioritization.",
                "A better static rank thus provides the engine with a higher quality, more upto-date index.",
                "Google is often regarded as the first commercially successful search engine.",
                "Their ranking was originally based on the <br>pagerank</br> algorithm [5][27].",
                "Due to this (and possibly due to Googles promotion of <br>pagerank</br> to the public), <br>pagerank</br> is widely regarded as the best method for the static ranking of Web pages.",
                "Though <br>pagerank</br> has historically been thought to perform quite well, there has yet been little academic evidence to support this claim.",
                "Even worse, there has recently been work showing that <br>pagerank</br> may not perform any better than other simple measures on certain tasks.",
                "Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than <br>pagerank</br> [32].",
                "They found similar results for the task of finding high quality companies [31].",
                "<br>pagerank</br> has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17].",
                "Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as <br>pagerank</br>.",
                "Despite these, the general belief remains among many, both academic and in the public, that <br>pagerank</br> is an essential factor for a good static rank.",
                "Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text.",
                "In this paper, we show there are a number of simple url- or pagebased features that significantly outperform <br>pagerank</br> (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web.",
                "We combine these and other static features using machine learning to achieve a ranking system that is significantly better than <br>pagerank</br> (in pairwise agreement with human labels).",
                "A machine learning approach for static ranking has other advantages besides the quality of the ranking.",
                "Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages static rank to an undeserved level through questionable techniques, also known as Web spamming).",
                "This is particularly true if the feature set is not known.",
                "In contrast, a single measure like <br>pagerank</br> can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page.",
                "With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank.",
                "This flexibility allows a ranking system to rapidly react to new spamming techniques.",
                "A machine learning approach to static ranking is also able to take advantage of any advances in the machine learning field.",
                "For example, recent work on adversarial classification [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
                "Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the static rank.",
                "By moving static ranking to a machine learning framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of machine learning.",
                "Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet.",
                "These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful.",
                "For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page.",
                "A machine learning approach thus allows rapid development of a good static algorithm in new domains.",
                "This papers contribution is a systematic study of static features, including <br>pagerank</br>, for the purposes of (statically) ranking Web pages.",
                "Previous studies on <br>pagerank</br> typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages).",
                "Also, the performance of <br>pagerank</br> and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering.",
                "In contrast, we explore the use of <br>pagerank</br> and other features for the direct task of statically ranking Web pages.",
                "We first briefly describe the <br>pagerank</br> algorithm.",
                "In Section 3 we introduce RankNet, the machine learning technique used to combine static features into a final ranking.",
                "Section 4 describes the static features.",
                "The heart of the paper is in Section 5, which presents our experiments and results.",
                "We conclude with a discussion of related and future work. 2.",
                "<br>pagerank</br> The basic idea behind <br>pagerank</br> is simple: a link from a Web page to another can be seen as an endorsement of that page.",
                "In general, links are made by people.",
                "As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality.",
                "We can take advantage of this linkage information to order Web pages according to their perceived quality.",
                "Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step.",
                "In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links.",
                "If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j.",
                "The <br>pagerank</br> score for node j is defined as this probability: PR(j)=P(j).",
                "Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform).",
                "The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page.",
                "An alternative view for equation (1) is that each page is assigned a quality, P(j).",
                "A page gives an equal share of its quality to each page it points to.",
                "<br>pagerank</br> is computationally expensive.",
                "Our collection of 5 billion pages contains approximately 370 billion links.",
                "Computing <br>pagerank</br> requires iterating over these billions of links multiple times (until convergence).",
                "It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them.",
                "Though much work has been done on optimizing the <br>pagerank</br> computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3.",
                "RANKNET Much work in machine learning has been done on the problems of classification and regression.",
                "Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi.",
                "The classification problem is to learn a function f that maps yi=f(xi), for all i.",
                "When yi is real-valued as well, this is called regression.",
                "Static ranking can be seen as a regression problem.",
                "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a regression function that mapped each pages features to their rank.",
                "However, this over-constrains the problem we wish to solve.",
                "All we really care about is the order of the pages, not the actual value assigned to them.",
                "Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them.",
                "For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j.",
                "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a regression function, the result of this process is a function (f) that maps feature vectors to real values.",
                "This function can still be applied anywhere that a regressionlearned function could be applied.",
                "The only difference is the technique used to learn the function.",
                "By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do regression techniques.",
                "We used RankNet [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function.",
                "RankNet is a straightforward modification to the standard neural network back-prop algorithm.",
                "As with back-prop, RankNet attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight.",
                "The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the RankNet cost function is based on the difference between a pair of network outputs.",
                "That is, for each pair of feature vectors <i,j> in the training set, RankNet computes the network outputs oi and oj.",
                "Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost.",
                "RankNet also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function).",
                "In this paper, we used a probability of one for all pairs.",
                "In the next section, we will discuss the features used in our feature vectors, xi. 4.",
                "FEATURES To apply RankNet (or other machine learning techniques) to the ranking problem, we needed to extract a set of features from each page.",
                "We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity).",
                "We also optionally used the <br>pagerank</br> of a page as a feature.",
                "Below, we describe each of these feature categories in more detail.",
                "<br>pagerank</br> We computed <br>pagerank</br> on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages).",
                "This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines.",
                "Because <br>pagerank</br> is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible.",
                "Most previous studies on <br>pagerank</br> used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed <br>pagerank</br> using the standard value of 0.85 for α.",
                "Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time.",
                "We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN.",
                "The data is aggregated into a count, for each Web page, of the number of users who viewed that page.",
                "Though popularity data is generally unavailable, there are two other sources for it.",
                "The first is from proxy logs.",
                "For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus.",
                "Unfortunately, proxy data is quite biased and relatively small.",
                "Another source, internal to search engines, are records of which results their users clicked on.",
                "Such data was used by the search engine Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
                "An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search.",
                "The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed.",
                "More details are provided in section 5.5.",
                "Anchor text and inlinks These features are based on the information associated with links to the page in question.",
                "It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc.",
                "Page This category consists of features which may be determined by looking at the page (and its URL) alone.",
                "We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc.",
                "Domain This category contains features that are computed as averages across all pages in the domain.",
                "For example, the average number of outlinks on any page and the average <br>pagerank</br>.",
                "Many of these features have been used by others for ranking Web pages, particularly the anchor and page features.",
                "As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for static ranking.",
                "Also, to our knowledge, this is the first study on the use of actual page visitation popularity for static ranking.",
                "The closest similar work is on using click-through behavior (that is, which search engine results the users click on) to affect dynamic ranking (see e.g., [20]).",
                "Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for feature-based ranking). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages.",
                "Unless otherwise specified, fRank was trained with all of the features. 5.",
                "EXPERIMENTS In this section, we will demonstrate that we can out perform <br>pagerank</br> by applying machine learning to a straightforward set of features.",
                "Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a static ranking, we needed a gold standard defining the correct ordering for a set of pages.",
                "For this, we employed a dataset which contains human judgments for 28000 queries.",
                "For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges.",
                "The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent.",
                "There are approximately 500k judgments in all, or an average of 18 ratings per query.",
                "The queries are selected by randomly choosing queries from among those issued to the MSN search engine.",
                "The probability that a query is selected is proportional to its frequency among all 709 of the queries.",
                "As a result, common queries are more likely to be judged than uncommon queries.",
                "As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture.",
                "The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs search engine).",
                "This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query.",
                "Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries.",
                "This bias is good when evaluating the quality of static ranking for the purposes of index ordering and returning relevant documents.",
                "This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries.",
                "Because of this bias, however, the results in this paper are not applicable to crawl prioritization.",
                "In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages.",
                "To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query.",
                "The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high static rank.",
                "Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query.",
                "We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively.",
                "Each set contains all of the ratings for a given query, and no query appears in more than one set.",
                "The training set was used to train fRank.",
                "The validation set was used to select the model that had the highest performance.",
                "The test set was used for the final results.",
                "This data gives us a query-independent ordering of pages.",
                "The goal for a static ranking algorithm will be to reproduce this ordering as closely as possible.",
                "In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a static ranking.",
                "The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages.",
                "If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of relevance for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
                "First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score).",
                "Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the static rank algorithm orders them correctly. 5.3 Method We trained fRank (a RankNet based neural network) using the following parameters.",
                "We used a fully connected 2 layer network.",
                "The hidden layer had 10 hidden nodes.",
                "The input weights to this layer were all initialized to be zero.",
                "The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1].",
                "We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output.",
                "The cost function is the pairwise cross entropy cost function as discussed in section 3.",
                "The features in the training set were normalized to have zero mean and unit standard deviation.",
                "The same linear transformation was then applied to the features in the validation and test sets.",
                "For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other.",
                "The pairings were chosen uniformly at random (with replacement) from all possible pairings.",
                "When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs.",
                "Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread.",
                "We trained the network for 30 epochs.",
                "On each epoch, the training pairs were randomly shuffled.",
                "The initial training rate was 0.001.",
                "At each epoch, we checked the error on the training set.",
                "If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot.",
                "The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased.",
                "After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement).",
                "The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set.",
                "We report the pairwise accuracy on the test set, calculated using all possible pairs.",
                "These parameters were determined and fixed before the static rank experiments in this paper.",
                "In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7].",
                "Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them.",
                "The only exception was the popularity features.",
                "As with most Web phenomenon, we found that the distribution of site popularity is Zipfian.",
                "To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple machine learning methods such as naïve Bayes.",
                "In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the <br>pagerank</br> for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms <br>pagerank</br> for the purposes of static ranking.",
                "With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of <br>pagerank</br> (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages).",
                "Note that one of fRanks input features is the <br>pagerank</br> of the page, so we would expect it to perform no worse than <br>pagerank</br>.",
                "The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page.",
                "Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 <br>pagerank</br> 56.70 fRank 67.43 There are a number of decisions that go into the computation of <br>pagerank</br>, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc.",
                "We were able to obtain a computation of <br>pagerank</br> from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters.",
                "It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation.",
                "We thus concluded that the quality of the <br>pagerank</br> is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it.",
                "We also wanted to find how well each feature set performed.",
                "To answer this, for each feature set, we trained and tested fRank using only that set of features.",
                "The results are shown in Table 2.",
                "As can be seen, every single feature set individually outperformed <br>pagerank</br> on this test.",
                "Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets.",
                "This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page.",
                "This is contrary to the common belief that the Web graph structure is the key to finding a good static ranking of Web pages.",
                "Table 2: Results for individual feature sets.",
                "Feature Set Accuracy (%) <br>pagerank</br> 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways.",
                "This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features.",
                "To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study.",
                "That is, for each set of features, we trained a network to contain all of the features except that set.",
                "We then compared the performance of the resulting network to the performance of the network with all of the features.",
                "Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set.",
                "Table 3: Ablation study.",
                "Shown is the decrease in accuracy when we train a network that has all but the given set of features.",
                "The last line is shows the effect of removing the anchor, <br>pagerank</br>, and domain features, hence a model containing no network or link-based information whatsoever.",
                "Feature Set Decrease in Accuracy <br>pagerank</br> 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, <br>pagerank</br> & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study.",
                "Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set.",
                "Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless.",
                "Beginning with no features, we greedily added the feature set that improved performance the most.",
                "The results are shown in Table 4.",
                "For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%.",
                "Table 4: fRank performance as feature sets are added.",
                "At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets).",
                "Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +<br>pagerank</br> 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of <br>pagerank</br> vs. fRank.",
                "In Table 5 are the top ten URLs returned for <br>pagerank</br> and for fRank.",
                "PageRanks results are heavily weighted towards technology sites.",
                "It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc.",
                "PageRanks bias toward technology can be explained through two processes.",
                "First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime.",
                "These generally link back to, in these examples, the Internet Explorer and QuickTime download sites.",
                "Consequently, <br>pagerank</br> ranks those pages highly.",
                "Though these pages are important, they are not as important as it may seem by looking at the link structure alone.",
                "One fix for this is to add information about the link to the <br>pagerank</br> computation, such as the size of the text, whether it was at the bottom of the page, etc.",
                "The other bias comes from the fact that the population of Web site authors is different than the population of Web users.",
                "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual visitation popularity of a site (the popularity feature set), is able to eliminate some of that bias.",
                "It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked.",
                "The results confirm that fRank outperforms <br>pagerank</br> in pairwise accuracy.",
                "The two most important feature sets are the page and popularity features.",
                "This is surprising, as the page features consisted only of a few (8) simple features.",
                "Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best.",
                "In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users.",
                "For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user.",
                "This limited the possible features we could derive from this data.",
                "For possible extensions, see section 6.3, future work.",
                "For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user.",
                "However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
                "One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user.",
                "Adding this feature dramatically improved the performance of fRank.",
                "We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain.",
                "We did this by using the set of features shown in Table 6.",
                "Table 6: URL functions used to compute the Popularity feature set.",
                "Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table.",
                "The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question.",
                "For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html.",
                "As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further.",
                "Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for <br>pagerank</br> vs. fRank <br>pagerank</br> fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data.",
                "It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected.",
                "In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set.",
                "Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank.",
                "The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy.",
                "In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy.",
                "Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions.",
                "First, fRank performs significantly better than <br>pagerank</br>, even without any information about the Web graph.",
                "Second, the page level and popularity features were the most significant contributors to pairwise accuracy.",
                "Third, by collecting more popularity data, we can continue to improve fRanks performance.",
                "The popularity data provides two benefits to fRank.",
                "First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer.",
                "Second, the popularity data is more timely than PageRanks link information.",
                "The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6.",
                "RELATED AND FUTURE WORK 6.1 Improvements to <br>pagerank</br> Since the original <br>pagerank</br> paper, there has been work on improving it.",
                "Much of that work centers on speeding up and parallelizing the computation [15][25].",
                "One recognized problem with <br>pagerank</br> is that of topic drift: A page about dogs will have high <br>pagerank</br> if it is linked to by many pages that themselves have high rank, regardless of their topic.",
                "In contrast, a search engine user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs.",
                "Hence, a link that is on topic should have higher weight than a link that is not.",
                "Richardson and Domingoss Query Dependent <br>pagerank</br> [29] and Haveliwalas Topic-Sensitive <br>pagerank</br> [16] are two approaches that tackle this problem.",
                "Other variations to <br>pagerank</br> include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3].",
                "See Langville and Meyer [23] for a good survey of these, and other modifications to <br>pagerank</br>. 6.2 Other related work <br>pagerank</br> is not the only link analysis algorithm used for ranking Web pages.",
                "The most well-known other is HITS [22], which is used by the Teoma search engine [30].",
                "HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs.",
                "Previous work has shown HITS to perform comparably to <br>pagerank</br> [1].",
                "One field of interest is that of static index pruning (see e.g., Carmel et al. [8]).",
                "Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query.",
                "The pruning is typically done based on the frequency of query terms.",
                "Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search.",
                "Similar methods could be incorporated into the static rank (e.g., how many frequent queries contain words found on this page).",
                "Others have investigated the effect that <br>pagerank</br> has on the Web at large [9].",
                "They argue that pages with high <br>pagerank</br> are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher <br>pagerank</br> than other pages.",
                "The same may occur for the popularity data.",
                "If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity.",
                "Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure.",
                "The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity.",
                "One interesting related work is that of Ivory and Hearst [19].",
                "Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience.",
                "They used over 100 page level features, as well as features encompassing the performance and structure of the site.",
                "This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features.",
                "The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with <br>pagerank</br>. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set.",
                "Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future.",
                "Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which search engine results are clicked on.",
                "Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking.",
                "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall relevance of a search engine (i.e., the dynamic ranking).",
                "They do not apply their techniques to the problem of static ranking. 6.3 Future work There are many ways in which we would like to extend this work.",
                "First, fRank uses only a small number of features.",
                "We believe we could achieve even more significant results with more features.",
                "In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page).",
                "Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc.",
                "Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables.",
                "For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features.",
                "The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents.",
                "In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair.",
                "For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2.",
                "The experiments in this paper are biased toward pages that have higher than average quality.",
                "Also, fRank with all of the features can only be applied to pages that have already been crawled.",
                "Thus, fRank is primarily useful for index ordering and improving relevance, not for directing the crawl.",
                "We would like to investigate a machine learning approach for crawl prioritization as well.",
                "It may be that a combination of methods is best: for example, using <br>pagerank</br> to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy.",
                "Another interesting direction for exploration is to incorporate fRank and page-level features directly into the <br>pagerank</br> computation itself.",
                "Work on biasing the <br>pagerank</br> jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach.",
                "There is reason to believe that a direct application of [29], using the fRank of a page for its relevance, could lead to an improved overall static rank.",
                "Finally, the popularity data can be used in other interesting ways.",
                "The general surfing and searching habits of Web users varies by time of day.",
                "Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively).",
                "We can gain insight into these differences by using the popularity data, divided into segments of the day.",
                "When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages.",
                "We also plan to explore popularity features that use more than just the counts of how often a page was visited.",
                "For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc.",
                "Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14].",
                "Finally, the popularity data could be used as the label rather than as a feature.",
                "Using fRank in this way to predict the popularity of a page may useful for the tasks of relevance, efficiency, and crawl priority.",
                "There is also significantly more popularity data than human labeled data, potentially enabling more complex machine learning methods, and significantly more features. 7.",
                "CONCLUSIONS A good static ranking is an important component for todays search engines and information retrieval systems.",
                "We have demonstrated that <br>pagerank</br> does not provide a very good static ranking; there are many simple features that individually out perform <br>pagerank</br>.",
                "By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than <br>pagerank</br> alone.",
                "A qualitative evaluation of the top documents shows that fRank is less technology-biased than <br>pagerank</br>; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit.",
                "The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as adversarial classification.",
                "We have only begun to explore the options, and believe that significant strides can be made in the area of static ranking by further experimentation with additional features, other machine learning techniques, and additional sources of data. 8.",
                "ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional <br>pagerank</br> computations and to Timo Burkard for assistance with the popularity data.",
                "Many thanks to Chris Burges for providing code and significant support in using training RankNets.",
                "Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of Web documents.",
                "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
                "<br>pagerank</br> as a function of the damping factor.",
                "In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims.",
                "A machine learning architecture for optimizing web search engines.",
                "In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998.",
                "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson.",
                "Efficient <br>pagerank</br> approximation via graph aggregation.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the 22nd International Conference on Machine Learning, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy.",
                "Impact of search engines on page popularity.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams.",
                "Page Quality: In search of an unbiased web ranking.",
                "In Proceedings of the ACM SIGMOD 2005 Conference.",
                "Baltimore, Maryland.",
                "June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proceedings of the 28th Annual Conference on Research and Development in Information Retrieval (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
                "Adversarial Classification.",
                "In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y.",
                "Singer.",
                "Log-linear models for label-ranking.",
                "In Advances in Neural Information Processing Systems 16.",
                "Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005).",
                "Evaluating implicit measures to improve the search experiences.",
                "In the ACM Transactions on Information Systems, 23(2), pp. 147-168.",
                "April 2005. [15]T. Haveliwala.",
                "Efficient computation of <br>pagerank</br>.",
                "Stanford University Technical Report, 1999. [16]T. Haveliwala.",
                "Topic-sensitive <br>pagerank</br>.",
                "In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell.",
                "Very large scale retrieval and Web search.",
                "In D. Harman and E. Voorhees (eds), The TREC Book.",
                "MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer.",
                "Support vector learning for ordinal regression.",
                "In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst.",
                "Statistical profiles of highly-rated Web sites.",
                "In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay.",
                "Accurately Interpreting Clickthrough Data as Implicit Feedback.",
                "In Proceedings of the Conference on Research and Development in Information Retrieval (SIGIR), 2005. [22]J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer.",
                "Deeper inside <br>pagerank</br>.",
                "Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit.",
                "The effect of the back button in a random walk: application for <br>pagerank</br>.",
                "In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry.",
                "A uniform approach to accelerated <br>pagerank</br> computation.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide.",
                "Static approximation of dynamically generated Web pages.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The <br>pagerank</br> citation ranking: Bringing order to the web.",
                "Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston.",
                "User-centric Web crawling.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos.",
                "The intelligent surfer: probabilistic combination of link and content information in <br>pagerank</br>.",
                "In Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
                "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.",
                "Teoma vs. Google, Round 2.",
                "Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: <br>pagerank</br> or indegree?.",
                "In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking.",
                "Query-independent evidence in home page finding.",
                "In ACM Transactions on Information Systems. 2003. 715"
            ],
            "original_annotated_samples": [
                "Beyond <br>pagerank</br>: Machine Learning for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on <br>pagerank</br>, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We show that we can significantly outperform <br>pagerank</br> using features that are independent of the link structure of the Web.",
                "The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for <br>pagerank</br> or 50% for random).",
                "Their ranking was originally based on the <br>pagerank</br> algorithm [5][27].",
                "Due to this (and possibly due to Googles promotion of <br>pagerank</br> to the public), <br>pagerank</br> is widely regarded as the best method for the static ranking of Web pages."
            ],
            "translated_annotated_samples": [
                "Más allá de <br>PageRank</br>: Aprendizaje automático para la clasificación estática.",
                "Demostramos que podemos superar significativamente a <br>PageRank</br> utilizando características que son independientes de la estructura de enlaces de la Web.",
                "El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de <br>PageRank</br> o el 50% al azar).",
                "Su clasificación se basaba originalmente en el algoritmo <br>PageRank</br> [5][27].",
                "Debido a esto (y posiblemente debido a la promoción de Google del <br>PageRank</br> al público), el <br>PageRank</br> es ampliamente considerado como el mejor método para la clasificación estática de páginas web."
            ],
            "translated_text": "Más allá de <br>PageRank</br>: Aprendizaje automático para la clasificación estática. Demostramos que podemos superar significativamente a <br>PageRank</br> utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de <br>PageRank</br> o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un motor de búsqueda. Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización. Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. Google es frecuentemente considerado como el primer motor de búsqueda comercialmente exitoso. Su clasificación se basaba originalmente en el algoritmo <br>PageRank</br> [5][27]. Debido a esto (y posiblemente debido a la promoción de Google del <br>PageRank</br> al público), el <br>PageRank</br> es ampliamente considerado como el mejor método para la clasificación estática de páginas web. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "ranknet": {
            "translated_key": "RankNet",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Beyond PageRank: Machine Learning for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We show that we can significantly outperform PageRank using features that are independent of the link structure of the Web.",
                "We gain a further boost in accuracy by using data on the frequency at which users visit Web pages.",
                "We use <br>ranknet</br>, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random).",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning.",
                "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval.",
                "General Terms Algorithms, Measurement, Performance, Experimentation. 1.",
                "INTRODUCTION Over the past decade, the Web has grown exponentially in size.",
                "Unfortunately, this growth has not been isolated to good-quality pages.",
                "The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly.",
                "The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information.",
                "Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first.",
                "To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking).",
                "However, having a good query-independent ranking (static ranking) is also crucially important for a search engine.",
                "A good static ranking algorithm provides numerous benefits: • Relevance: The static rank of a page provides a general indicator to the overall quality of the page.",
                "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by static rank.",
                "By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found.",
                "The more accurate the static rank, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages.",
                "Among other factors, the static rank of a page is used to determine this prioritization.",
                "A better static rank thus provides the engine with a higher quality, more upto-date index.",
                "Google is often regarded as the first commercially successful search engine.",
                "Their ranking was originally based on the PageRank algorithm [5][27].",
                "Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the static ranking of Web pages.",
                "Though PageRank has historically been thought to perform quite well, there has yet been little academic evidence to support this claim.",
                "Even worse, there has recently been work showing that PageRank may not perform any better than other simple measures on certain tasks.",
                "Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than PageRank [32].",
                "They found similar results for the task of finding high quality companies [31].",
                "PageRank has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17].",
                "Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as PageRank.",
                "Despite these, the general belief remains among many, both academic and in the public, that PageRank is an essential factor for a good static rank.",
                "Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text.",
                "In this paper, we show there are a number of simple url- or pagebased features that significantly outperform PageRank (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web.",
                "We combine these and other static features using machine learning to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels).",
                "A machine learning approach for static ranking has other advantages besides the quality of the ranking.",
                "Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages static rank to an undeserved level through questionable techniques, also known as Web spamming).",
                "This is particularly true if the feature set is not known.",
                "In contrast, a single measure like PageRank can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page.",
                "With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank.",
                "This flexibility allows a ranking system to rapidly react to new spamming techniques.",
                "A machine learning approach to static ranking is also able to take advantage of any advances in the machine learning field.",
                "For example, recent work on adversarial classification [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
                "Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the static rank.",
                "By moving static ranking to a machine learning framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of machine learning.",
                "Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet.",
                "These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful.",
                "For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page.",
                "A machine learning approach thus allows rapid development of a good static algorithm in new domains.",
                "This papers contribution is a systematic study of static features, including PageRank, for the purposes of (statically) ranking Web pages.",
                "Previous studies on PageRank typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages).",
                "Also, the performance of PageRank and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering.",
                "In contrast, we explore the use of PageRank and other features for the direct task of statically ranking Web pages.",
                "We first briefly describe the PageRank algorithm.",
                "In Section 3 we introduce <br>ranknet</br>, the machine learning technique used to combine static features into a final ranking.",
                "Section 4 describes the static features.",
                "The heart of the paper is in Section 5, which presents our experiments and results.",
                "We conclude with a discussion of related and future work. 2.",
                "PAGERANK The basic idea behind PageRank is simple: a link from a Web page to another can be seen as an endorsement of that page.",
                "In general, links are made by people.",
                "As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality.",
                "We can take advantage of this linkage information to order Web pages according to their perceived quality.",
                "Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step.",
                "In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links.",
                "If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j.",
                "The PageRank score for node j is defined as this probability: PR(j)=P(j).",
                "Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform).",
                "The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page.",
                "An alternative view for equation (1) is that each page is assigned a quality, P(j).",
                "A page gives an equal share of its quality to each page it points to.",
                "PageRank is computationally expensive.",
                "Our collection of 5 billion pages contains approximately 370 billion links.",
                "Computing PageRank requires iterating over these billions of links multiple times (until convergence).",
                "It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them.",
                "Though much work has been done on optimizing the PageRank computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3.",
                "<br>ranknet</br> Much work in machine learning has been done on the problems of classification and regression.",
                "Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi.",
                "The classification problem is to learn a function f that maps yi=f(xi), for all i.",
                "When yi is real-valued as well, this is called regression.",
                "Static ranking can be seen as a regression problem.",
                "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a regression function that mapped each pages features to their rank.",
                "However, this over-constrains the problem we wish to solve.",
                "All we really care about is the order of the pages, not the actual value assigned to them.",
                "Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them.",
                "For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j.",
                "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a regression function, the result of this process is a function (f) that maps feature vectors to real values.",
                "This function can still be applied anywhere that a regressionlearned function could be applied.",
                "The only difference is the technique used to learn the function.",
                "By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do regression techniques.",
                "We used <br>ranknet</br> [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function.",
                "<br>ranknet</br> is a straightforward modification to the standard neural network back-prop algorithm.",
                "As with back-prop, <br>ranknet</br> attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight.",
                "The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the <br>ranknet</br> cost function is based on the difference between a pair of network outputs.",
                "That is, for each pair of feature vectors <i,j> in the training set, <br>ranknet</br> computes the network outputs oi and oj.",
                "Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost.",
                "<br>ranknet</br> also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function).",
                "In this paper, we used a probability of one for all pairs.",
                "In the next section, we will discuss the features used in our feature vectors, xi. 4.",
                "FEATURES To apply <br>ranknet</br> (or other machine learning techniques) to the ranking problem, we needed to extract a set of features from each page.",
                "We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity).",
                "We also optionally used the PageRank of a page as a feature.",
                "Below, we describe each of these feature categories in more detail.",
                "PageRank We computed PageRank on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages).",
                "This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines.",
                "Because PageRank is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible.",
                "Most previous studies on PageRank used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed PageRank using the standard value of 0.85 for α.",
                "Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time.",
                "We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN.",
                "The data is aggregated into a count, for each Web page, of the number of users who viewed that page.",
                "Though popularity data is generally unavailable, there are two other sources for it.",
                "The first is from proxy logs.",
                "For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus.",
                "Unfortunately, proxy data is quite biased and relatively small.",
                "Another source, internal to search engines, are records of which results their users clicked on.",
                "Such data was used by the search engine Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
                "An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search.",
                "The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed.",
                "More details are provided in section 5.5.",
                "Anchor text and inlinks These features are based on the information associated with links to the page in question.",
                "It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc.",
                "Page This category consists of features which may be determined by looking at the page (and its URL) alone.",
                "We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc.",
                "Domain This category contains features that are computed as averages across all pages in the domain.",
                "For example, the average number of outlinks on any page and the average PageRank.",
                "Many of these features have been used by others for ranking Web pages, particularly the anchor and page features.",
                "As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for static ranking.",
                "Also, to our knowledge, this is the first study on the use of actual page visitation popularity for static ranking.",
                "The closest similar work is on using click-through behavior (that is, which search engine results the users click on) to affect dynamic ranking (see e.g., [20]).",
                "Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for feature-based ranking). fRank uses <br>ranknet</br> and the set of features described in this section to learn a ranking function for Web pages.",
                "Unless otherwise specified, fRank was trained with all of the features. 5.",
                "EXPERIMENTS In this section, we will demonstrate that we can out perform PageRank by applying machine learning to a straightforward set of features.",
                "Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a static ranking, we needed a gold standard defining the correct ordering for a set of pages.",
                "For this, we employed a dataset which contains human judgments for 28000 queries.",
                "For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges.",
                "The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent.",
                "There are approximately 500k judgments in all, or an average of 18 ratings per query.",
                "The queries are selected by randomly choosing queries from among those issued to the MSN search engine.",
                "The probability that a query is selected is proportional to its frequency among all 709 of the queries.",
                "As a result, common queries are more likely to be judged than uncommon queries.",
                "As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture.",
                "The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs search engine).",
                "This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query.",
                "Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries.",
                "This bias is good when evaluating the quality of static ranking for the purposes of index ordering and returning relevant documents.",
                "This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries.",
                "Because of this bias, however, the results in this paper are not applicable to crawl prioritization.",
                "In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages.",
                "To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query.",
                "The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high static rank.",
                "Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query.",
                "We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively.",
                "Each set contains all of the ratings for a given query, and no query appears in more than one set.",
                "The training set was used to train fRank.",
                "The validation set was used to select the model that had the highest performance.",
                "The test set was used for the final results.",
                "This data gives us a query-independent ordering of pages.",
                "The goal for a static ranking algorithm will be to reproduce this ordering as closely as possible.",
                "In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a static ranking.",
                "The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages.",
                "If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of relevance for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
                "First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score).",
                "Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the static rank algorithm orders them correctly. 5.3 Method We trained fRank (a <br>ranknet</br> based neural network) using the following parameters.",
                "We used a fully connected 2 layer network.",
                "The hidden layer had 10 hidden nodes.",
                "The input weights to this layer were all initialized to be zero.",
                "The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1].",
                "We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output.",
                "The cost function is the pairwise cross entropy cost function as discussed in section 3.",
                "The features in the training set were normalized to have zero mean and unit standard deviation.",
                "The same linear transformation was then applied to the features in the validation and test sets.",
                "For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other.",
                "The pairings were chosen uniformly at random (with replacement) from all possible pairings.",
                "When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs.",
                "Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread.",
                "We trained the network for 30 epochs.",
                "On each epoch, the training pairs were randomly shuffled.",
                "The initial training rate was 0.001.",
                "At each epoch, we checked the error on the training set.",
                "If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot.",
                "The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased.",
                "After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement).",
                "The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set.",
                "We report the pairwise accuracy on the test set, calculated using all possible pairs.",
                "These parameters were determined and fixed before the static rank experiments in this paper.",
                "In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7].",
                "Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them.",
                "The only exception was the popularity features.",
                "As with most Web phenomenon, we found that the distribution of site popularity is Zipfian.",
                "To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple machine learning methods such as naïve Bayes.",
                "In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the PageRank for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms PageRank for the purposes of static ranking.",
                "With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of PageRank (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages).",
                "Note that one of fRanks input features is the PageRank of the page, so we would expect it to perform no worse than PageRank.",
                "The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page.",
                "Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 PageRank 56.70 fRank 67.43 There are a number of decisions that go into the computation of PageRank, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc.",
                "We were able to obtain a computation of PageRank from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters.",
                "It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation.",
                "We thus concluded that the quality of the PageRank is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it.",
                "We also wanted to find how well each feature set performed.",
                "To answer this, for each feature set, we trained and tested fRank using only that set of features.",
                "The results are shown in Table 2.",
                "As can be seen, every single feature set individually outperformed PageRank on this test.",
                "Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets.",
                "This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page.",
                "This is contrary to the common belief that the Web graph structure is the key to finding a good static ranking of Web pages.",
                "Table 2: Results for individual feature sets.",
                "Feature Set Accuracy (%) PageRank 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways.",
                "This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features.",
                "To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study.",
                "That is, for each set of features, we trained a network to contain all of the features except that set.",
                "We then compared the performance of the resulting network to the performance of the network with all of the features.",
                "Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set.",
                "Table 3: Ablation study.",
                "Shown is the decrease in accuracy when we train a network that has all but the given set of features.",
                "The last line is shows the effect of removing the anchor, PageRank, and domain features, hence a model containing no network or link-based information whatsoever.",
                "Feature Set Decrease in Accuracy PageRank 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, PageRank & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study.",
                "Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set.",
                "Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless.",
                "Beginning with no features, we greedily added the feature set that improved performance the most.",
                "The results are shown in Table 4.",
                "For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%.",
                "Table 4: fRank performance as feature sets are added.",
                "At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets).",
                "Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +PageRank 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of PageRank vs. fRank.",
                "In Table 5 are the top ten URLs returned for PageRank and for fRank.",
                "PageRanks results are heavily weighted towards technology sites.",
                "It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc.",
                "PageRanks bias toward technology can be explained through two processes.",
                "First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime.",
                "These generally link back to, in these examples, the Internet Explorer and QuickTime download sites.",
                "Consequently, PageRank ranks those pages highly.",
                "Though these pages are important, they are not as important as it may seem by looking at the link structure alone.",
                "One fix for this is to add information about the link to the PageRank computation, such as the size of the text, whether it was at the bottom of the page, etc.",
                "The other bias comes from the fact that the population of Web site authors is different than the population of Web users.",
                "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual visitation popularity of a site (the popularity feature set), is able to eliminate some of that bias.",
                "It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked.",
                "The results confirm that fRank outperforms PageRank in pairwise accuracy.",
                "The two most important feature sets are the page and popularity features.",
                "This is surprising, as the page features consisted only of a few (8) simple features.",
                "Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best.",
                "In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users.",
                "For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user.",
                "This limited the possible features we could derive from this data.",
                "For possible extensions, see section 6.3, future work.",
                "For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user.",
                "However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
                "One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user.",
                "Adding this feature dramatically improved the performance of fRank.",
                "We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain.",
                "We did this by using the set of features shown in Table 6.",
                "Table 6: URL functions used to compute the Popularity feature set.",
                "Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table.",
                "The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question.",
                "For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html.",
                "As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further.",
                "Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data.",
                "It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected.",
                "In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set.",
                "Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank.",
                "The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy.",
                "In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy.",
                "Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions.",
                "First, fRank performs significantly better than PageRank, even without any information about the Web graph.",
                "Second, the page level and popularity features were the most significant contributors to pairwise accuracy.",
                "Third, by collecting more popularity data, we can continue to improve fRanks performance.",
                "The popularity data provides two benefits to fRank.",
                "First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer.",
                "Second, the popularity data is more timely than PageRanks link information.",
                "The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6.",
                "RELATED AND FUTURE WORK 6.1 Improvements to PageRank Since the original PageRank paper, there has been work on improving it.",
                "Much of that work centers on speeding up and parallelizing the computation [15][25].",
                "One recognized problem with PageRank is that of topic drift: A page about dogs will have high PageRank if it is linked to by many pages that themselves have high rank, regardless of their topic.",
                "In contrast, a search engine user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs.",
                "Hence, a link that is on topic should have higher weight than a link that is not.",
                "Richardson and Domingoss Query Dependent PageRank [29] and Haveliwalas Topic-Sensitive PageRank [16] are two approaches that tackle this problem.",
                "Other variations to PageRank include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3].",
                "See Langville and Meyer [23] for a good survey of these, and other modifications to PageRank. 6.2 Other related work PageRank is not the only link analysis algorithm used for ranking Web pages.",
                "The most well-known other is HITS [22], which is used by the Teoma search engine [30].",
                "HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs.",
                "Previous work has shown HITS to perform comparably to PageRank [1].",
                "One field of interest is that of static index pruning (see e.g., Carmel et al. [8]).",
                "Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query.",
                "The pruning is typically done based on the frequency of query terms.",
                "Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search.",
                "Similar methods could be incorporated into the static rank (e.g., how many frequent queries contain words found on this page).",
                "Others have investigated the effect that PageRank has on the Web at large [9].",
                "They argue that pages with high PageRank are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher PageRank than other pages.",
                "The same may occur for the popularity data.",
                "If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity.",
                "Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure.",
                "The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity.",
                "One interesting related work is that of Ivory and Hearst [19].",
                "Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience.",
                "They used over 100 page level features, as well as features encompassing the performance and structure of the site.",
                "This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features.",
                "The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set.",
                "Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future.",
                "Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which search engine results are clicked on.",
                "Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking.",
                "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall relevance of a search engine (i.e., the dynamic ranking).",
                "They do not apply their techniques to the problem of static ranking. 6.3 Future work There are many ways in which we would like to extend this work.",
                "First, fRank uses only a small number of features.",
                "We believe we could achieve even more significant results with more features.",
                "In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page).",
                "Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc.",
                "Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables.",
                "For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features.",
                "The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents.",
                "In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair.",
                "For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2.",
                "The experiments in this paper are biased toward pages that have higher than average quality.",
                "Also, fRank with all of the features can only be applied to pages that have already been crawled.",
                "Thus, fRank is primarily useful for index ordering and improving relevance, not for directing the crawl.",
                "We would like to investigate a machine learning approach for crawl prioritization as well.",
                "It may be that a combination of methods is best: for example, using PageRank to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy.",
                "Another interesting direction for exploration is to incorporate fRank and page-level features directly into the PageRank computation itself.",
                "Work on biasing the PageRank jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach.",
                "There is reason to believe that a direct application of [29], using the fRank of a page for its relevance, could lead to an improved overall static rank.",
                "Finally, the popularity data can be used in other interesting ways.",
                "The general surfing and searching habits of Web users varies by time of day.",
                "Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively).",
                "We can gain insight into these differences by using the popularity data, divided into segments of the day.",
                "When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages.",
                "We also plan to explore popularity features that use more than just the counts of how often a page was visited.",
                "For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc.",
                "Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14].",
                "Finally, the popularity data could be used as the label rather than as a feature.",
                "Using fRank in this way to predict the popularity of a page may useful for the tasks of relevance, efficiency, and crawl priority.",
                "There is also significantly more popularity data than human labeled data, potentially enabling more complex machine learning methods, and significantly more features. 7.",
                "CONCLUSIONS A good static ranking is an important component for todays search engines and information retrieval systems.",
                "We have demonstrated that PageRank does not provide a very good static ranking; there are many simple features that individually out perform PageRank.",
                "By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than PageRank alone.",
                "A qualitative evaluation of the top documents shows that fRank is less technology-biased than PageRank; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit.",
                "The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as adversarial classification.",
                "We have only begun to explore the options, and believe that significant strides can be made in the area of static ranking by further experimentation with additional features, other machine learning techniques, and additional sources of data. 8.",
                "ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional PageRank computations and to Timo Burkard for assistance with the popularity data.",
                "Many thanks to Chris Burges for providing code and significant support in using training RankNets.",
                "Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of Web documents.",
                "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
                "PageRank as a function of the damping factor.",
                "In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims.",
                "A machine learning architecture for optimizing web search engines.",
                "In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998.",
                "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson.",
                "Efficient PageRank approximation via graph aggregation.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the 22nd International Conference on Machine Learning, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy.",
                "Impact of search engines on page popularity.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams.",
                "Page Quality: In search of an unbiased web ranking.",
                "In Proceedings of the ACM SIGMOD 2005 Conference.",
                "Baltimore, Maryland.",
                "June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proceedings of the 28th Annual Conference on Research and Development in Information Retrieval (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
                "Adversarial Classification.",
                "In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y.",
                "Singer.",
                "Log-linear models for label-ranking.",
                "In Advances in Neural Information Processing Systems 16.",
                "Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005).",
                "Evaluating implicit measures to improve the search experiences.",
                "In the ACM Transactions on Information Systems, 23(2), pp. 147-168.",
                "April 2005. [15]T. Haveliwala.",
                "Efficient computation of PageRank.",
                "Stanford University Technical Report, 1999. [16]T. Haveliwala.",
                "Topic-sensitive PageRank.",
                "In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell.",
                "Very large scale retrieval and Web search.",
                "In D. Harman and E. Voorhees (eds), The TREC Book.",
                "MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer.",
                "Support vector learning for ordinal regression.",
                "In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst.",
                "Statistical profiles of highly-rated Web sites.",
                "In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay.",
                "Accurately Interpreting Clickthrough Data as Implicit Feedback.",
                "In Proceedings of the Conference on Research and Development in Information Retrieval (SIGIR), 2005. [22]J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit.",
                "The effect of the back button in a random walk: application for PageRank.",
                "In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry.",
                "A uniform approach to accelerated PageRank computation.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide.",
                "Static approximation of dynamically generated Web pages.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston.",
                "User-centric Web crawling.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos.",
                "The intelligent surfer: probabilistic combination of link and content information in PageRank.",
                "In Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
                "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.",
                "Teoma vs. Google, Round 2.",
                "Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: PageRank or indegree?.",
                "In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking.",
                "Query-independent evidence in home page finding.",
                "In ACM Transactions on Information Systems. 2003. 715"
            ],
            "original_annotated_samples": [
                "We use <br>ranknet</br>, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "In Section 3 we introduce <br>ranknet</br>, the machine learning technique used to combine static features into a final ranking.",
                "<br>ranknet</br> Much work in machine learning has been done on the problems of classification and regression.",
                "We used <br>ranknet</br> [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function.",
                "<br>ranknet</br> is a straightforward modification to the standard neural network back-prop algorithm."
            ],
            "translated_annotated_samples": [
                "Utilizamos <br>RankNet</br>, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio.",
                "En la Sección 3 presentamos <br>RankNet</br>, la técnica de aprendizaje automático utilizada para combinar las características estáticas en un ranking final.",
                "RANKNET Se ha realizado mucho trabajo en aprendizaje automático en los problemas de clasificación y regresión.",
                "Utilizamos <br>RankNet</br> [7], una de las técnicas mencionadas para aprender funciones de clasificación, para aprender nuestra función de clasificación estática.",
                "RankNet es una modificación sencilla del algoritmo de retropropagación de la red neuronal estándar."
            ],
            "translated_text": "Más allá de PageRank: Aprendizaje automático para la clasificación estática. Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos <br>RankNet</br>, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un motor de búsqueda. Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización. Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. Google es frecuentemente considerado como el primer motor de búsqueda comercialmente exitoso. Su clasificación se basaba originalmente en el algoritmo PageRank [5][27]. Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la clasificación estática de páginas web. Aunque se ha pensado que PageRank ha tenido un buen rendimiento históricamente, todavía hay poca evidencia académica que respalde esta afirmación. Aún peor, recientemente se ha demostrado que PageRank puede no funcionar mejor que otras medidas simples en ciertas tareas. Upstill et al. han encontrado que para la tarea de encontrar páginas de inicio, el número de páginas que enlazan a una página y el tipo de URL fueron tan, o más, efectivos que PageRank [32]. Encontraron resultados similares para la tarea de encontrar empresas de alta calidad [31]. PageRank también se ha utilizado en sistemas para las grandes colecciones de TRECs y competencias de seguimiento web, pero con mucho menos éxito del esperado [17]. Finalmente, Amento et al. [1] encontraron que características simples, como el número de páginas en un sitio, tuvieron un rendimiento tan bueno como PageRank. A pesar de esto, la creencia general persiste entre muchos, tanto académicos como en el público, de que PageRank es un factor esencial para un buen rango estático. En caso de que esto falle, se asume que seguir utilizando la estructura de enlaces es crucial, ya sea en forma del número de enlaces entrantes o la cantidad de texto ancla. En este artículo, demostramos que existen una serie de características simples basadas en URL o en páginas que superan significativamente a PageRank (para el propósito de clasificar estáticamente páginas web) a pesar de ignorar la estructura de la web. Combinamos estas y otras características estáticas utilizando aprendizaje automático para lograr un sistema de clasificación que es significativamente mejor que PageRank (en acuerdo par a par con etiquetas humanas). Un enfoque de aprendizaje automático para la clasificación estática tiene otras ventajas además de la calidad de la clasificación. Debido a que la medida consta de muchas características, es más difícil para los usuarios malintencionados manipularla (es decir, elevar el rango estático de sus páginas a un nivel no merecido a través de técnicas cuestionables, también conocidas como spam en la web). Esto es especialmente cierto si el conjunto de características no se conoce. Por el contrario, una sola medida como PageRank puede ser más fácil de manipular porque los spammers solo necesitan concentrarse en un objetivo: cómo hacer que más páginas apunten a su página. Con un algoritmo que aprende, una característica que se vuelve inutilizable debido a la manipulación de spammers simplemente se reducirá o eliminará del cálculo final de rango. Esta flexibilidad permite que un sistema de clasificación reaccione rápidamente a nuevas técnicas de spam. Un enfoque de aprendizaje automático para la clasificación estática también puede aprovechar cualquier avance en el campo del aprendizaje automático. Por ejemplo, un trabajo reciente sobre clasificación adversarial [12] sugiere que puede ser posible modelar explícitamente las acciones de los spammers de páginas web (el adversario), ajustando el modelo de clasificación de antemano antes de que los spammers intenten evadirlo. Otro ejemplo es la eliminación de valores atípicos al construir el modelo, lo cual ayuda a reducir el efecto que los sitios únicos pueden tener en la calidad general de la clasificación estática. Al trasladar la clasificación estática a un marco de aprendizaje automático, no solo ganamos en precisión, sino también en la capacidad de reaccionar a las acciones de los spammers, de añadir rápidamente nuevas características al algoritmo de clasificación y de aprovechar los avances en el campo en rápido crecimiento del aprendizaje automático. Finalmente, creemos que habrá ventajas significativas al utilizar esta técnica para otros ámbitos, como la búsqueda en un disco duro local o en la intranet de una empresa. Estos son dominios donde la estructura de enlaces es particularmente débil (o inexistente), pero hay otras características específicas del dominio que podrían ser igual de poderosas. Por ejemplo, el autor de una página de intranet y su posición en la organización (por ejemplo, CEO, gerente o desarrollador) podrían proporcionar pistas significativas sobre la importancia de esa página. Un enfoque de aprendizaje automático permite el desarrollo rápido de un buen algoritmo estático en nuevos dominios. La contribución de este artículo es un estudio sistemático de las características estáticas, incluido PageRank, con el propósito de clasificar páginas web de forma estática. Estudios previos sobre PageRank típicamente utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Además, el rendimiento de PageRank y otras características estáticas suele evaluarse en el contexto de un sistema completo para la clasificación dinámica, o para otras tareas como la respuesta a preguntas. Por el contrario, exploramos el uso de PageRank y otras características para la tarea directa de clasificar estáticamente las páginas web. Primero describimos brevemente el algoritmo PageRank. En la Sección 3 presentamos <br>RankNet</br>, la técnica de aprendizaje automático utilizada para combinar las características estáticas en un ranking final. La sección 4 describe las características estáticas. El corazón del documento está en la Sección 5, la cual presenta nuestros experimentos y resultados. Concluimos con una discusión sobre el trabajo relacionado y futuro. 2. PAGERANK La idea básica detrás de PageRank es simple: un enlace de una página web a otra puede ser visto como un respaldo de esa página. En general, los enlaces son creados por personas. Por lo tanto, son indicativos de la calidad de las páginas a las que apuntan: al crear una página, un autor presumiblemente elige enlazar a páginas consideradas de buena calidad. Podemos aprovechar esta información de enlace para ordenar las páginas web según su calidad percibida. Imagina a un internauta que salta de página web en página web, eligiendo con probabilidad uniforme qué enlace seguir en cada paso. Para reducir el efecto de los callejones sin salida o ciclos interminables, el surfista saltará ocasionalmente a una página aleatoria con una pequeña probabilidad α, o cuando se encuentre en una página sin enlaces de salida. Si se promedia sobre un número suficiente de pasos, la probabilidad de que el surfista esté en la página j en algún momento en el tiempo está dada por la fórmula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Donde Fi es el conjunto de páginas a las que enlaza la página i, y Bj es el conjunto de páginas que enlazan a la página j. El puntaje de PageRank para el nodo j se define como esta probabilidad: PR(j)=P(j). Dado que la ecuación (1) es recursiva, debe evaluarse de forma iterativa hasta que P(j) converja (normalmente, la distribución inicial para P(j) es uniforme). La intuición es que, dado que un navegante aleatorio llegaría a la página con más frecuencia, es probable que sea una página mejor. Una vista alternativa para la ecuación (1) es que a cada página se le asigna una calidad, P(j). Una página otorga una parte igual de su calidad a cada página a la que apunta. PageRank es computacionalmente costoso. Nuestra colección de 5 mil millones de páginas contiene aproximadamente 370 mil millones de enlaces. Calcular el PageRank requiere iterar sobre miles de millones de enlaces varias veces (hasta converger). Requiere grandes cantidades de memoria (o esquemas de almacenamiento en caché muy inteligentes que ralentizan aún más el cálculo), y si se distribuye en múltiples máquinas, requiere una comunicación significativa entre ellas. Aunque se ha realizado mucho trabajo en la optimización del cálculo del PageRank (ver, por ejemplo, [25] y [6]), sigue siendo una propiedad relativamente lenta y costosa computacionalmente de calcular. 3. RANKNET Se ha realizado mucho trabajo en aprendizaje automático en los problemas de clasificación y regresión. Sea X={xi} una colección de vectores de características (típicamente, una característica es cualquier número real), y Y={yi} una colección de clases asociadas, donde yi es la clase del objeto descrito por el vector de características xi. El problema de clasificación consiste en aprender una función f que mapea yi=f(xi), para todo i. Cuando yi también es un valor real, esto se llama regresión. La clasificación estática se puede ver como un problema de regresión. Si dejamos que xi represente las características de la página i, y yi sea un valor (por ejemplo, el rango) para cada página, podríamos aprender una función de regresión que mapeara las características de cada página a su rango. Sin embargo, esto sobrecarga el problema que deseamos resolver. Todo lo que realmente nos importa es el orden de las páginas, no el valor real asignado a ellas. El trabajo reciente sobre este problema de clasificación [7][13][18] intenta directamente optimizar el orden de los objetos, en lugar del valor asignado a ellos. Para esto, sea Z={<i,j>} una colección de pares de elementos, donde el elemento i debe ser asignado un valor más alto que el elemento j. El objetivo del problema de clasificación, entonces, es aprender una función f tal que, )()(,, ji ffji xxZ >∈∀ 708. Nótese que, al igual que al aprender una función de regresión, el resultado de este proceso es una función (f) que mapea vectores de características a valores reales. Esta función todavía se puede aplicar en cualquier lugar donde se pueda aplicar una función aprendida por regresión. La única diferencia es la técnica utilizada para aprender la función. Al optimizar directamente el orden de los objetos, estos métodos pueden aprender una función que clasifica mejor que las técnicas de regresión. Utilizamos <br>RankNet</br> [7], una de las técnicas mencionadas para aprender funciones de clasificación, para aprender nuestra función de clasificación estática. RankNet es una modificación sencilla del algoritmo de retropropagación de la red neuronal estándar. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "static ranking": {
            "translated_key": "clasificación estática",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Beyond PageRank: Machine Learning for <br>static ranking</br> Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We show that we can significantly outperform PageRank using features that are independent of the link structure of the Web.",
                "We gain a further boost in accuracy by using data on the frequency at which users visit Web pages.",
                "We use RankNet, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "The resulting model achieves a <br>static ranking</br> pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random).",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning.",
                "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval.",
                "General Terms Algorithms, Measurement, Performance, Experimentation. 1.",
                "INTRODUCTION Over the past decade, the Web has grown exponentially in size.",
                "Unfortunately, this growth has not been isolated to good-quality pages.",
                "The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly.",
                "The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information.",
                "Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first.",
                "To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking).",
                "However, having a good query-independent ranking (<br>static ranking</br>) is also crucially important for a search engine.",
                "A good <br>static ranking</br> algorithm provides numerous benefits: • Relevance: The static rank of a page provides a general indicator to the overall quality of the page.",
                "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by static rank.",
                "By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found.",
                "The more accurate the static rank, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages.",
                "Among other factors, the static rank of a page is used to determine this prioritization.",
                "A better static rank thus provides the engine with a higher quality, more upto-date index.",
                "Google is often regarded as the first commercially successful search engine.",
                "Their ranking was originally based on the PageRank algorithm [5][27].",
                "Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the <br>static ranking</br> of Web pages.",
                "Though PageRank has historically been thought to perform quite well, there has yet been little academic evidence to support this claim.",
                "Even worse, there has recently been work showing that PageRank may not perform any better than other simple measures on certain tasks.",
                "Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than PageRank [32].",
                "They found similar results for the task of finding high quality companies [31].",
                "PageRank has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17].",
                "Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as PageRank.",
                "Despite these, the general belief remains among many, both academic and in the public, that PageRank is an essential factor for a good static rank.",
                "Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text.",
                "In this paper, we show there are a number of simple url- or pagebased features that significantly outperform PageRank (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web.",
                "We combine these and other static features using machine learning to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels).",
                "A machine learning approach for <br>static ranking</br> has other advantages besides the quality of the ranking.",
                "Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages static rank to an undeserved level through questionable techniques, also known as Web spamming).",
                "This is particularly true if the feature set is not known.",
                "In contrast, a single measure like PageRank can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page.",
                "With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank.",
                "This flexibility allows a ranking system to rapidly react to new spamming techniques.",
                "A machine learning approach to <br>static ranking</br> is also able to take advantage of any advances in the machine learning field.",
                "For example, recent work on adversarial classification [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
                "Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the static rank.",
                "By moving <br>static ranking</br> to a machine learning framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of machine learning.",
                "Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet.",
                "These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful.",
                "For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page.",
                "A machine learning approach thus allows rapid development of a good static algorithm in new domains.",
                "This papers contribution is a systematic study of static features, including PageRank, for the purposes of (statically) ranking Web pages.",
                "Previous studies on PageRank typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages).",
                "Also, the performance of PageRank and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering.",
                "In contrast, we explore the use of PageRank and other features for the direct task of statically ranking Web pages.",
                "We first briefly describe the PageRank algorithm.",
                "In Section 3 we introduce RankNet, the machine learning technique used to combine static features into a final ranking.",
                "Section 4 describes the static features.",
                "The heart of the paper is in Section 5, which presents our experiments and results.",
                "We conclude with a discussion of related and future work. 2.",
                "PAGERANK The basic idea behind PageRank is simple: a link from a Web page to another can be seen as an endorsement of that page.",
                "In general, links are made by people.",
                "As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality.",
                "We can take advantage of this linkage information to order Web pages according to their perceived quality.",
                "Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step.",
                "In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links.",
                "If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j.",
                "The PageRank score for node j is defined as this probability: PR(j)=P(j).",
                "Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform).",
                "The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page.",
                "An alternative view for equation (1) is that each page is assigned a quality, P(j).",
                "A page gives an equal share of its quality to each page it points to.",
                "PageRank is computationally expensive.",
                "Our collection of 5 billion pages contains approximately 370 billion links.",
                "Computing PageRank requires iterating over these billions of links multiple times (until convergence).",
                "It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them.",
                "Though much work has been done on optimizing the PageRank computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3.",
                "RANKNET Much work in machine learning has been done on the problems of classification and regression.",
                "Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi.",
                "The classification problem is to learn a function f that maps yi=f(xi), for all i.",
                "When yi is real-valued as well, this is called regression.",
                "<br>static ranking</br> can be seen as a regression problem.",
                "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a regression function that mapped each pages features to their rank.",
                "However, this over-constrains the problem we wish to solve.",
                "All we really care about is the order of the pages, not the actual value assigned to them.",
                "Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them.",
                "For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j.",
                "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a regression function, the result of this process is a function (f) that maps feature vectors to real values.",
                "This function can still be applied anywhere that a regressionlearned function could be applied.",
                "The only difference is the technique used to learn the function.",
                "By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do regression techniques.",
                "We used RankNet [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function.",
                "RankNet is a straightforward modification to the standard neural network back-prop algorithm.",
                "As with back-prop, RankNet attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight.",
                "The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the RankNet cost function is based on the difference between a pair of network outputs.",
                "That is, for each pair of feature vectors <i,j> in the training set, RankNet computes the network outputs oi and oj.",
                "Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost.",
                "RankNet also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function).",
                "In this paper, we used a probability of one for all pairs.",
                "In the next section, we will discuss the features used in our feature vectors, xi. 4.",
                "FEATURES To apply RankNet (or other machine learning techniques) to the ranking problem, we needed to extract a set of features from each page.",
                "We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity).",
                "We also optionally used the PageRank of a page as a feature.",
                "Below, we describe each of these feature categories in more detail.",
                "PageRank We computed PageRank on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages).",
                "This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines.",
                "Because PageRank is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible.",
                "Most previous studies on PageRank used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed PageRank using the standard value of 0.85 for α.",
                "Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time.",
                "We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN.",
                "The data is aggregated into a count, for each Web page, of the number of users who viewed that page.",
                "Though popularity data is generally unavailable, there are two other sources for it.",
                "The first is from proxy logs.",
                "For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus.",
                "Unfortunately, proxy data is quite biased and relatively small.",
                "Another source, internal to search engines, are records of which results their users clicked on.",
                "Such data was used by the search engine Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
                "An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search.",
                "The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed.",
                "More details are provided in section 5.5.",
                "Anchor text and inlinks These features are based on the information associated with links to the page in question.",
                "It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc.",
                "Page This category consists of features which may be determined by looking at the page (and its URL) alone.",
                "We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc.",
                "Domain This category contains features that are computed as averages across all pages in the domain.",
                "For example, the average number of outlinks on any page and the average PageRank.",
                "Many of these features have been used by others for ranking Web pages, particularly the anchor and page features.",
                "As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for <br>static ranking</br>.",
                "Also, to our knowledge, this is the first study on the use of actual page visitation popularity for <br>static ranking</br>.",
                "The closest similar work is on using click-through behavior (that is, which search engine results the users click on) to affect dynamic ranking (see e.g., [20]).",
                "Because we use a wide variety of features to come up with a <br>static ranking</br>, we refer to this as fRank (for feature-based ranking). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages.",
                "Unless otherwise specified, fRank was trained with all of the features. 5.",
                "EXPERIMENTS In this section, we will demonstrate that we can out perform PageRank by applying machine learning to a straightforward set of features.",
                "Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a <br>static ranking</br>, we needed a gold standard defining the correct ordering for a set of pages.",
                "For this, we employed a dataset which contains human judgments for 28000 queries.",
                "For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges.",
                "The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent.",
                "There are approximately 500k judgments in all, or an average of 18 ratings per query.",
                "The queries are selected by randomly choosing queries from among those issued to the MSN search engine.",
                "The probability that a query is selected is proportional to its frequency among all 709 of the queries.",
                "As a result, common queries are more likely to be judged than uncommon queries.",
                "As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture.",
                "The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs search engine).",
                "This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query.",
                "Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries.",
                "This bias is good when evaluating the quality of <br>static ranking</br> for the purposes of index ordering and returning relevant documents.",
                "This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries.",
                "Because of this bias, however, the results in this paper are not applicable to crawl prioritization.",
                "In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages.",
                "To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query.",
                "The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high static rank.",
                "Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query.",
                "We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively.",
                "Each set contains all of the ratings for a given query, and no query appears in more than one set.",
                "The training set was used to train fRank.",
                "The validation set was used to select the model that had the highest performance.",
                "The test set was used for the final results.",
                "This data gives us a query-independent ordering of pages.",
                "The goal for a <br>static ranking</br> algorithm will be to reproduce this ordering as closely as possible.",
                "In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a <br>static ranking</br>.",
                "The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages.",
                "If S(x) is the <br>static ranking</br> assigned to page x, and H(x) is the human judgment of relevance for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
                "First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score).",
                "Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the static rank algorithm orders them correctly. 5.3 Method We trained fRank (a RankNet based neural network) using the following parameters.",
                "We used a fully connected 2 layer network.",
                "The hidden layer had 10 hidden nodes.",
                "The input weights to this layer were all initialized to be zero.",
                "The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1].",
                "We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output.",
                "The cost function is the pairwise cross entropy cost function as discussed in section 3.",
                "The features in the training set were normalized to have zero mean and unit standard deviation.",
                "The same linear transformation was then applied to the features in the validation and test sets.",
                "For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other.",
                "The pairings were chosen uniformly at random (with replacement) from all possible pairings.",
                "When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs.",
                "Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread.",
                "We trained the network for 30 epochs.",
                "On each epoch, the training pairs were randomly shuffled.",
                "The initial training rate was 0.001.",
                "At each epoch, we checked the error on the training set.",
                "If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot.",
                "The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased.",
                "After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement).",
                "The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set.",
                "We report the pairwise accuracy on the test set, calculated using all possible pairs.",
                "These parameters were determined and fixed before the static rank experiments in this paper.",
                "In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7].",
                "Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them.",
                "The only exception was the popularity features.",
                "As with most Web phenomenon, we found that the distribution of site popularity is Zipfian.",
                "To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple machine learning methods such as naïve Bayes.",
                "In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the PageRank for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms PageRank for the purposes of <br>static ranking</br>.",
                "With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of PageRank (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages).",
                "Note that one of fRanks input features is the PageRank of the page, so we would expect it to perform no worse than PageRank.",
                "The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page.",
                "Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 PageRank 56.70 fRank 67.43 There are a number of decisions that go into the computation of PageRank, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc.",
                "We were able to obtain a computation of PageRank from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters.",
                "It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation.",
                "We thus concluded that the quality of the PageRank is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it.",
                "We also wanted to find how well each feature set performed.",
                "To answer this, for each feature set, we trained and tested fRank using only that set of features.",
                "The results are shown in Table 2.",
                "As can be seen, every single feature set individually outperformed PageRank on this test.",
                "Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets.",
                "This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page.",
                "This is contrary to the common belief that the Web graph structure is the key to finding a good <br>static ranking</br> of Web pages.",
                "Table 2: Results for individual feature sets.",
                "Feature Set Accuracy (%) PageRank 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways.",
                "This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features.",
                "To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study.",
                "That is, for each set of features, we trained a network to contain all of the features except that set.",
                "We then compared the performance of the resulting network to the performance of the network with all of the features.",
                "Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set.",
                "Table 3: Ablation study.",
                "Shown is the decrease in accuracy when we train a network that has all but the given set of features.",
                "The last line is shows the effect of removing the anchor, PageRank, and domain features, hence a model containing no network or link-based information whatsoever.",
                "Feature Set Decrease in Accuracy PageRank 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, PageRank & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study.",
                "Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set.",
                "Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless.",
                "Beginning with no features, we greedily added the feature set that improved performance the most.",
                "The results are shown in Table 4.",
                "For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%.",
                "Table 4: fRank performance as feature sets are added.",
                "At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets).",
                "Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +PageRank 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of PageRank vs. fRank.",
                "In Table 5 are the top ten URLs returned for PageRank and for fRank.",
                "PageRanks results are heavily weighted towards technology sites.",
                "It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc.",
                "PageRanks bias toward technology can be explained through two processes.",
                "First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime.",
                "These generally link back to, in these examples, the Internet Explorer and QuickTime download sites.",
                "Consequently, PageRank ranks those pages highly.",
                "Though these pages are important, they are not as important as it may seem by looking at the link structure alone.",
                "One fix for this is to add information about the link to the PageRank computation, such as the size of the text, whether it was at the bottom of the page, etc.",
                "The other bias comes from the fact that the population of Web site authors is different than the population of Web users.",
                "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual visitation popularity of a site (the popularity feature set), is able to eliminate some of that bias.",
                "It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked.",
                "The results confirm that fRank outperforms PageRank in pairwise accuracy.",
                "The two most important feature sets are the page and popularity features.",
                "This is surprising, as the page features consisted only of a few (8) simple features.",
                "Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best.",
                "In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users.",
                "For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user.",
                "This limited the possible features we could derive from this data.",
                "For possible extensions, see section 6.3, future work.",
                "For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user.",
                "However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
                "One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user.",
                "Adding this feature dramatically improved the performance of fRank.",
                "We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain.",
                "We did this by using the set of features shown in Table 6.",
                "Table 6: URL functions used to compute the Popularity feature set.",
                "Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table.",
                "The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question.",
                "For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html.",
                "As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further.",
                "Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data.",
                "It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected.",
                "In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set.",
                "Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank.",
                "The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy.",
                "In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy.",
                "Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions.",
                "First, fRank performs significantly better than PageRank, even without any information about the Web graph.",
                "Second, the page level and popularity features were the most significant contributors to pairwise accuracy.",
                "Third, by collecting more popularity data, we can continue to improve fRanks performance.",
                "The popularity data provides two benefits to fRank.",
                "First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer.",
                "Second, the popularity data is more timely than PageRanks link information.",
                "The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6.",
                "RELATED AND FUTURE WORK 6.1 Improvements to PageRank Since the original PageRank paper, there has been work on improving it.",
                "Much of that work centers on speeding up and parallelizing the computation [15][25].",
                "One recognized problem with PageRank is that of topic drift: A page about dogs will have high PageRank if it is linked to by many pages that themselves have high rank, regardless of their topic.",
                "In contrast, a search engine user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs.",
                "Hence, a link that is on topic should have higher weight than a link that is not.",
                "Richardson and Domingoss Query Dependent PageRank [29] and Haveliwalas Topic-Sensitive PageRank [16] are two approaches that tackle this problem.",
                "Other variations to PageRank include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3].",
                "See Langville and Meyer [23] for a good survey of these, and other modifications to PageRank. 6.2 Other related work PageRank is not the only link analysis algorithm used for ranking Web pages.",
                "The most well-known other is HITS [22], which is used by the Teoma search engine [30].",
                "HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs.",
                "Previous work has shown HITS to perform comparably to PageRank [1].",
                "One field of interest is that of static index pruning (see e.g., Carmel et al. [8]).",
                "Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query.",
                "The pruning is typically done based on the frequency of query terms.",
                "Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search.",
                "Similar methods could be incorporated into the static rank (e.g., how many frequent queries contain words found on this page).",
                "Others have investigated the effect that PageRank has on the Web at large [9].",
                "They argue that pages with high PageRank are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher PageRank than other pages.",
                "The same may occur for the popularity data.",
                "If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity.",
                "Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure.",
                "The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity.",
                "One interesting related work is that of Ivory and Hearst [19].",
                "Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience.",
                "They used over 100 page level features, as well as features encompassing the performance and structure of the site.",
                "This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features.",
                "The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set.",
                "Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future.",
                "Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which search engine results are clicked on.",
                "Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking.",
                "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall relevance of a search engine (i.e., the dynamic ranking).",
                "They do not apply their techniques to the problem of <br>static ranking</br>. 6.3 Future work There are many ways in which we would like to extend this work.",
                "First, fRank uses only a small number of features.",
                "We believe we could achieve even more significant results with more features.",
                "In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page).",
                "Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc.",
                "Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables.",
                "For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features.",
                "The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents.",
                "In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair.",
                "For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2.",
                "The experiments in this paper are biased toward pages that have higher than average quality.",
                "Also, fRank with all of the features can only be applied to pages that have already been crawled.",
                "Thus, fRank is primarily useful for index ordering and improving relevance, not for directing the crawl.",
                "We would like to investigate a machine learning approach for crawl prioritization as well.",
                "It may be that a combination of methods is best: for example, using PageRank to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy.",
                "Another interesting direction for exploration is to incorporate fRank and page-level features directly into the PageRank computation itself.",
                "Work on biasing the PageRank jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach.",
                "There is reason to believe that a direct application of [29], using the fRank of a page for its relevance, could lead to an improved overall static rank.",
                "Finally, the popularity data can be used in other interesting ways.",
                "The general surfing and searching habits of Web users varies by time of day.",
                "Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively).",
                "We can gain insight into these differences by using the popularity data, divided into segments of the day.",
                "When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages.",
                "We also plan to explore popularity features that use more than just the counts of how often a page was visited.",
                "For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc.",
                "Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14].",
                "Finally, the popularity data could be used as the label rather than as a feature.",
                "Using fRank in this way to predict the popularity of a page may useful for the tasks of relevance, efficiency, and crawl priority.",
                "There is also significantly more popularity data than human labeled data, potentially enabling more complex machine learning methods, and significantly more features. 7.",
                "CONCLUSIONS A good <br>static ranking</br> is an important component for todays search engines and information retrieval systems.",
                "We have demonstrated that PageRank does not provide a very good <br>static ranking</br>; there are many simple features that individually out perform PageRank.",
                "By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than PageRank alone.",
                "A qualitative evaluation of the top documents shows that fRank is less technology-biased than PageRank; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit.",
                "The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as adversarial classification.",
                "We have only begun to explore the options, and believe that significant strides can be made in the area of <br>static ranking</br> by further experimentation with additional features, other machine learning techniques, and additional sources of data. 8.",
                "ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional PageRank computations and to Timo Burkard for assistance with the popularity data.",
                "Many thanks to Chris Burges for providing code and significant support in using training RankNets.",
                "Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of Web documents.",
                "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
                "PageRank as a function of the damping factor.",
                "In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims.",
                "A machine learning architecture for optimizing web search engines.",
                "In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998.",
                "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson.",
                "Efficient PageRank approximation via graph aggregation.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the 22nd International Conference on Machine Learning, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy.",
                "Impact of search engines on page popularity.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams.",
                "Page Quality: In search of an unbiased web ranking.",
                "In Proceedings of the ACM SIGMOD 2005 Conference.",
                "Baltimore, Maryland.",
                "June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proceedings of the 28th Annual Conference on Research and Development in Information Retrieval (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
                "Adversarial Classification.",
                "In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y.",
                "Singer.",
                "Log-linear models for label-ranking.",
                "In Advances in Neural Information Processing Systems 16.",
                "Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005).",
                "Evaluating implicit measures to improve the search experiences.",
                "In the ACM Transactions on Information Systems, 23(2), pp. 147-168.",
                "April 2005. [15]T. Haveliwala.",
                "Efficient computation of PageRank.",
                "Stanford University Technical Report, 1999. [16]T. Haveliwala.",
                "Topic-sensitive PageRank.",
                "In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell.",
                "Very large scale retrieval and Web search.",
                "In D. Harman and E. Voorhees (eds), The TREC Book.",
                "MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer.",
                "Support vector learning for ordinal regression.",
                "In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst.",
                "Statistical profiles of highly-rated Web sites.",
                "In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay.",
                "Accurately Interpreting Clickthrough Data as Implicit Feedback.",
                "In Proceedings of the Conference on Research and Development in Information Retrieval (SIGIR), 2005. [22]J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit.",
                "The effect of the back button in a random walk: application for PageRank.",
                "In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry.",
                "A uniform approach to accelerated PageRank computation.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide.",
                "Static approximation of dynamically generated Web pages.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston.",
                "User-centric Web crawling.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos.",
                "The intelligent surfer: probabilistic combination of link and content information in PageRank.",
                "In Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
                "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.",
                "Teoma vs. Google, Round 2.",
                "Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: PageRank or indegree?.",
                "In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking.",
                "Query-independent evidence in home page finding.",
                "In ACM Transactions on Information Systems. 2003. 715"
            ],
            "original_annotated_samples": [
                "Beyond PageRank: Machine Learning for <br>static ranking</br> Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "The resulting model achieves a <br>static ranking</br> pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random).",
                "However, having a good query-independent ranking (<br>static ranking</br>) is also crucially important for a search engine.",
                "A good <br>static ranking</br> algorithm provides numerous benefits: • Relevance: The static rank of a page provides a general indicator to the overall quality of the page.",
                "Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the <br>static ranking</br> of Web pages."
            ],
            "translated_annotated_samples": [
                "Más allá de PageRank: Aprendizaje automático para la <br>clasificación estática</br>.",
                "El modelo resultante logra una precisión de <br>clasificación par a par estática</br> del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar).",
                "Sin embargo, tener una buena clasificación independiente de consultas (<br>clasificación estática</br>) también es crucialmente importante para un motor de búsqueda.",
                "Un buen algoritmo de <br>clasificación estática</br> proporciona numerosos beneficios: • Relevancia: La <br>clasificación estática</br> de una página proporciona un indicador general de la calidad de la página.",
                "Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la <br>clasificación estática</br> de páginas web."
            ],
            "translated_text": "Más allá de PageRank: Aprendizaje automático para la <br>clasificación estática</br>. Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de <br>clasificación par a par estática</br> del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (<br>clasificación estática</br>) también es crucialmente importante para un motor de búsqueda. Un buen algoritmo de <br>clasificación estática</br> proporciona numerosos beneficios: • Relevancia: La <br>clasificación estática</br> de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización. Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. Google es frecuentemente considerado como el primer motor de búsqueda comercialmente exitoso. Su clasificación se basaba originalmente en el algoritmo PageRank [5][27]. Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la <br>clasificación estática</br> de páginas web. ",
            "candidates": [],
            "error": [
                [
                    "clasificación estática",
                    "clasificación par a par estática",
                    "clasificación estática",
                    "clasificación estática",
                    "clasificación estática",
                    "clasificación estática"
                ]
            ]
        },
        "information retrieval": {
            "translated_key": "recuperación de información",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Beyond PageRank: Machine Learning for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We show that we can significantly outperform PageRank using features that are independent of the link structure of the Web.",
                "We gain a further boost in accuracy by using data on the frequency at which users visit Web pages.",
                "We use RankNet, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random).",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning.",
                "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval.",
                "General Terms Algorithms, Measurement, Performance, Experimentation. 1.",
                "INTRODUCTION Over the past decade, the Web has grown exponentially in size.",
                "Unfortunately, this growth has not been isolated to good-quality pages.",
                "The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly.",
                "The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information.",
                "Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first.",
                "To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking).",
                "However, having a good query-independent ranking (static ranking) is also crucially important for a search engine.",
                "A good static ranking algorithm provides numerous benefits: • Relevance: The static rank of a page provides a general indicator to the overall quality of the page.",
                "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by static rank.",
                "By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found.",
                "The more accurate the static rank, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages.",
                "Among other factors, the static rank of a page is used to determine this prioritization.",
                "A better static rank thus provides the engine with a higher quality, more upto-date index.",
                "Google is often regarded as the first commercially successful search engine.",
                "Their ranking was originally based on the PageRank algorithm [5][27].",
                "Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the static ranking of Web pages.",
                "Though PageRank has historically been thought to perform quite well, there has yet been little academic evidence to support this claim.",
                "Even worse, there has recently been work showing that PageRank may not perform any better than other simple measures on certain tasks.",
                "Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than PageRank [32].",
                "They found similar results for the task of finding high quality companies [31].",
                "PageRank has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17].",
                "Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as PageRank.",
                "Despite these, the general belief remains among many, both academic and in the public, that PageRank is an essential factor for a good static rank.",
                "Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text.",
                "In this paper, we show there are a number of simple url- or pagebased features that significantly outperform PageRank (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web.",
                "We combine these and other static features using machine learning to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels).",
                "A machine learning approach for static ranking has other advantages besides the quality of the ranking.",
                "Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages static rank to an undeserved level through questionable techniques, also known as Web spamming).",
                "This is particularly true if the feature set is not known.",
                "In contrast, a single measure like PageRank can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page.",
                "With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank.",
                "This flexibility allows a ranking system to rapidly react to new spamming techniques.",
                "A machine learning approach to static ranking is also able to take advantage of any advances in the machine learning field.",
                "For example, recent work on adversarial classification [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
                "Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the static rank.",
                "By moving static ranking to a machine learning framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of machine learning.",
                "Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet.",
                "These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful.",
                "For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page.",
                "A machine learning approach thus allows rapid development of a good static algorithm in new domains.",
                "This papers contribution is a systematic study of static features, including PageRank, for the purposes of (statically) ranking Web pages.",
                "Previous studies on PageRank typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages).",
                "Also, the performance of PageRank and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering.",
                "In contrast, we explore the use of PageRank and other features for the direct task of statically ranking Web pages.",
                "We first briefly describe the PageRank algorithm.",
                "In Section 3 we introduce RankNet, the machine learning technique used to combine static features into a final ranking.",
                "Section 4 describes the static features.",
                "The heart of the paper is in Section 5, which presents our experiments and results.",
                "We conclude with a discussion of related and future work. 2.",
                "PAGERANK The basic idea behind PageRank is simple: a link from a Web page to another can be seen as an endorsement of that page.",
                "In general, links are made by people.",
                "As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality.",
                "We can take advantage of this linkage information to order Web pages according to their perceived quality.",
                "Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step.",
                "In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links.",
                "If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j.",
                "The PageRank score for node j is defined as this probability: PR(j)=P(j).",
                "Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform).",
                "The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page.",
                "An alternative view for equation (1) is that each page is assigned a quality, P(j).",
                "A page gives an equal share of its quality to each page it points to.",
                "PageRank is computationally expensive.",
                "Our collection of 5 billion pages contains approximately 370 billion links.",
                "Computing PageRank requires iterating over these billions of links multiple times (until convergence).",
                "It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them.",
                "Though much work has been done on optimizing the PageRank computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3.",
                "RANKNET Much work in machine learning has been done on the problems of classification and regression.",
                "Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi.",
                "The classification problem is to learn a function f that maps yi=f(xi), for all i.",
                "When yi is real-valued as well, this is called regression.",
                "Static ranking can be seen as a regression problem.",
                "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a regression function that mapped each pages features to their rank.",
                "However, this over-constrains the problem we wish to solve.",
                "All we really care about is the order of the pages, not the actual value assigned to them.",
                "Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them.",
                "For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j.",
                "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a regression function, the result of this process is a function (f) that maps feature vectors to real values.",
                "This function can still be applied anywhere that a regressionlearned function could be applied.",
                "The only difference is the technique used to learn the function.",
                "By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do regression techniques.",
                "We used RankNet [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function.",
                "RankNet is a straightforward modification to the standard neural network back-prop algorithm.",
                "As with back-prop, RankNet attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight.",
                "The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the RankNet cost function is based on the difference between a pair of network outputs.",
                "That is, for each pair of feature vectors <i,j> in the training set, RankNet computes the network outputs oi and oj.",
                "Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost.",
                "RankNet also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function).",
                "In this paper, we used a probability of one for all pairs.",
                "In the next section, we will discuss the features used in our feature vectors, xi. 4.",
                "FEATURES To apply RankNet (or other machine learning techniques) to the ranking problem, we needed to extract a set of features from each page.",
                "We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity).",
                "We also optionally used the PageRank of a page as a feature.",
                "Below, we describe each of these feature categories in more detail.",
                "PageRank We computed PageRank on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages).",
                "This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines.",
                "Because PageRank is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible.",
                "Most previous studies on PageRank used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed PageRank using the standard value of 0.85 for α.",
                "Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time.",
                "We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN.",
                "The data is aggregated into a count, for each Web page, of the number of users who viewed that page.",
                "Though popularity data is generally unavailable, there are two other sources for it.",
                "The first is from proxy logs.",
                "For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus.",
                "Unfortunately, proxy data is quite biased and relatively small.",
                "Another source, internal to search engines, are records of which results their users clicked on.",
                "Such data was used by the search engine Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
                "An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search.",
                "The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed.",
                "More details are provided in section 5.5.",
                "Anchor text and inlinks These features are based on the information associated with links to the page in question.",
                "It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc.",
                "Page This category consists of features which may be determined by looking at the page (and its URL) alone.",
                "We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc.",
                "Domain This category contains features that are computed as averages across all pages in the domain.",
                "For example, the average number of outlinks on any page and the average PageRank.",
                "Many of these features have been used by others for ranking Web pages, particularly the anchor and page features.",
                "As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for static ranking.",
                "Also, to our knowledge, this is the first study on the use of actual page visitation popularity for static ranking.",
                "The closest similar work is on using click-through behavior (that is, which search engine results the users click on) to affect dynamic ranking (see e.g., [20]).",
                "Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for feature-based ranking). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages.",
                "Unless otherwise specified, fRank was trained with all of the features. 5.",
                "EXPERIMENTS In this section, we will demonstrate that we can out perform PageRank by applying machine learning to a straightforward set of features.",
                "Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a static ranking, we needed a gold standard defining the correct ordering for a set of pages.",
                "For this, we employed a dataset which contains human judgments for 28000 queries.",
                "For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges.",
                "The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent.",
                "There are approximately 500k judgments in all, or an average of 18 ratings per query.",
                "The queries are selected by randomly choosing queries from among those issued to the MSN search engine.",
                "The probability that a query is selected is proportional to its frequency among all 709 of the queries.",
                "As a result, common queries are more likely to be judged than uncommon queries.",
                "As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture.",
                "The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs search engine).",
                "This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query.",
                "Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries.",
                "This bias is good when evaluating the quality of static ranking for the purposes of index ordering and returning relevant documents.",
                "This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries.",
                "Because of this bias, however, the results in this paper are not applicable to crawl prioritization.",
                "In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages.",
                "To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query.",
                "The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high static rank.",
                "Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query.",
                "We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively.",
                "Each set contains all of the ratings for a given query, and no query appears in more than one set.",
                "The training set was used to train fRank.",
                "The validation set was used to select the model that had the highest performance.",
                "The test set was used for the final results.",
                "This data gives us a query-independent ordering of pages.",
                "The goal for a static ranking algorithm will be to reproduce this ordering as closely as possible.",
                "In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a static ranking.",
                "The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages.",
                "If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of relevance for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
                "First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score).",
                "Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the static rank algorithm orders them correctly. 5.3 Method We trained fRank (a RankNet based neural network) using the following parameters.",
                "We used a fully connected 2 layer network.",
                "The hidden layer had 10 hidden nodes.",
                "The input weights to this layer were all initialized to be zero.",
                "The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1].",
                "We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output.",
                "The cost function is the pairwise cross entropy cost function as discussed in section 3.",
                "The features in the training set were normalized to have zero mean and unit standard deviation.",
                "The same linear transformation was then applied to the features in the validation and test sets.",
                "For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other.",
                "The pairings were chosen uniformly at random (with replacement) from all possible pairings.",
                "When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs.",
                "Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread.",
                "We trained the network for 30 epochs.",
                "On each epoch, the training pairs were randomly shuffled.",
                "The initial training rate was 0.001.",
                "At each epoch, we checked the error on the training set.",
                "If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot.",
                "The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased.",
                "After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement).",
                "The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set.",
                "We report the pairwise accuracy on the test set, calculated using all possible pairs.",
                "These parameters were determined and fixed before the static rank experiments in this paper.",
                "In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7].",
                "Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them.",
                "The only exception was the popularity features.",
                "As with most Web phenomenon, we found that the distribution of site popularity is Zipfian.",
                "To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple machine learning methods such as naïve Bayes.",
                "In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the PageRank for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms PageRank for the purposes of static ranking.",
                "With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of PageRank (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages).",
                "Note that one of fRanks input features is the PageRank of the page, so we would expect it to perform no worse than PageRank.",
                "The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page.",
                "Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 PageRank 56.70 fRank 67.43 There are a number of decisions that go into the computation of PageRank, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc.",
                "We were able to obtain a computation of PageRank from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters.",
                "It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation.",
                "We thus concluded that the quality of the PageRank is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it.",
                "We also wanted to find how well each feature set performed.",
                "To answer this, for each feature set, we trained and tested fRank using only that set of features.",
                "The results are shown in Table 2.",
                "As can be seen, every single feature set individually outperformed PageRank on this test.",
                "Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets.",
                "This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page.",
                "This is contrary to the common belief that the Web graph structure is the key to finding a good static ranking of Web pages.",
                "Table 2: Results for individual feature sets.",
                "Feature Set Accuracy (%) PageRank 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways.",
                "This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features.",
                "To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study.",
                "That is, for each set of features, we trained a network to contain all of the features except that set.",
                "We then compared the performance of the resulting network to the performance of the network with all of the features.",
                "Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set.",
                "Table 3: Ablation study.",
                "Shown is the decrease in accuracy when we train a network that has all but the given set of features.",
                "The last line is shows the effect of removing the anchor, PageRank, and domain features, hence a model containing no network or link-based information whatsoever.",
                "Feature Set Decrease in Accuracy PageRank 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, PageRank & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study.",
                "Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set.",
                "Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless.",
                "Beginning with no features, we greedily added the feature set that improved performance the most.",
                "The results are shown in Table 4.",
                "For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%.",
                "Table 4: fRank performance as feature sets are added.",
                "At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets).",
                "Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +PageRank 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of PageRank vs. fRank.",
                "In Table 5 are the top ten URLs returned for PageRank and for fRank.",
                "PageRanks results are heavily weighted towards technology sites.",
                "It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc.",
                "PageRanks bias toward technology can be explained through two processes.",
                "First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime.",
                "These generally link back to, in these examples, the Internet Explorer and QuickTime download sites.",
                "Consequently, PageRank ranks those pages highly.",
                "Though these pages are important, they are not as important as it may seem by looking at the link structure alone.",
                "One fix for this is to add information about the link to the PageRank computation, such as the size of the text, whether it was at the bottom of the page, etc.",
                "The other bias comes from the fact that the population of Web site authors is different than the population of Web users.",
                "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual visitation popularity of a site (the popularity feature set), is able to eliminate some of that bias.",
                "It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked.",
                "The results confirm that fRank outperforms PageRank in pairwise accuracy.",
                "The two most important feature sets are the page and popularity features.",
                "This is surprising, as the page features consisted only of a few (8) simple features.",
                "Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best.",
                "In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users.",
                "For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user.",
                "This limited the possible features we could derive from this data.",
                "For possible extensions, see section 6.3, future work.",
                "For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user.",
                "However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
                "One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user.",
                "Adding this feature dramatically improved the performance of fRank.",
                "We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain.",
                "We did this by using the set of features shown in Table 6.",
                "Table 6: URL functions used to compute the Popularity feature set.",
                "Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table.",
                "The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question.",
                "For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html.",
                "As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further.",
                "Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data.",
                "It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected.",
                "In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set.",
                "Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank.",
                "The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy.",
                "In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy.",
                "Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions.",
                "First, fRank performs significantly better than PageRank, even without any information about the Web graph.",
                "Second, the page level and popularity features were the most significant contributors to pairwise accuracy.",
                "Third, by collecting more popularity data, we can continue to improve fRanks performance.",
                "The popularity data provides two benefits to fRank.",
                "First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer.",
                "Second, the popularity data is more timely than PageRanks link information.",
                "The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6.",
                "RELATED AND FUTURE WORK 6.1 Improvements to PageRank Since the original PageRank paper, there has been work on improving it.",
                "Much of that work centers on speeding up and parallelizing the computation [15][25].",
                "One recognized problem with PageRank is that of topic drift: A page about dogs will have high PageRank if it is linked to by many pages that themselves have high rank, regardless of their topic.",
                "In contrast, a search engine user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs.",
                "Hence, a link that is on topic should have higher weight than a link that is not.",
                "Richardson and Domingoss Query Dependent PageRank [29] and Haveliwalas Topic-Sensitive PageRank [16] are two approaches that tackle this problem.",
                "Other variations to PageRank include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3].",
                "See Langville and Meyer [23] for a good survey of these, and other modifications to PageRank. 6.2 Other related work PageRank is not the only link analysis algorithm used for ranking Web pages.",
                "The most well-known other is HITS [22], which is used by the Teoma search engine [30].",
                "HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs.",
                "Previous work has shown HITS to perform comparably to PageRank [1].",
                "One field of interest is that of static index pruning (see e.g., Carmel et al. [8]).",
                "Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query.",
                "The pruning is typically done based on the frequency of query terms.",
                "Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search.",
                "Similar methods could be incorporated into the static rank (e.g., how many frequent queries contain words found on this page).",
                "Others have investigated the effect that PageRank has on the Web at large [9].",
                "They argue that pages with high PageRank are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher PageRank than other pages.",
                "The same may occur for the popularity data.",
                "If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity.",
                "Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure.",
                "The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity.",
                "One interesting related work is that of Ivory and Hearst [19].",
                "Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience.",
                "They used over 100 page level features, as well as features encompassing the performance and structure of the site.",
                "This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features.",
                "The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set.",
                "Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future.",
                "Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which search engine results are clicked on.",
                "Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking.",
                "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall relevance of a search engine (i.e., the dynamic ranking).",
                "They do not apply their techniques to the problem of static ranking. 6.3 Future work There are many ways in which we would like to extend this work.",
                "First, fRank uses only a small number of features.",
                "We believe we could achieve even more significant results with more features.",
                "In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page).",
                "Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc.",
                "Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables.",
                "For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features.",
                "The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents.",
                "In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair.",
                "For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2.",
                "The experiments in this paper are biased toward pages that have higher than average quality.",
                "Also, fRank with all of the features can only be applied to pages that have already been crawled.",
                "Thus, fRank is primarily useful for index ordering and improving relevance, not for directing the crawl.",
                "We would like to investigate a machine learning approach for crawl prioritization as well.",
                "It may be that a combination of methods is best: for example, using PageRank to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy.",
                "Another interesting direction for exploration is to incorporate fRank and page-level features directly into the PageRank computation itself.",
                "Work on biasing the PageRank jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach.",
                "There is reason to believe that a direct application of [29], using the fRank of a page for its relevance, could lead to an improved overall static rank.",
                "Finally, the popularity data can be used in other interesting ways.",
                "The general surfing and searching habits of Web users varies by time of day.",
                "Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively).",
                "We can gain insight into these differences by using the popularity data, divided into segments of the day.",
                "When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages.",
                "We also plan to explore popularity features that use more than just the counts of how often a page was visited.",
                "For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc.",
                "Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14].",
                "Finally, the popularity data could be used as the label rather than as a feature.",
                "Using fRank in this way to predict the popularity of a page may useful for the tasks of relevance, efficiency, and crawl priority.",
                "There is also significantly more popularity data than human labeled data, potentially enabling more complex machine learning methods, and significantly more features. 7.",
                "CONCLUSIONS A good static ranking is an important component for todays search engines and <br>information retrieval</br> systems.",
                "We have demonstrated that PageRank does not provide a very good static ranking; there are many simple features that individually out perform PageRank.",
                "By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than PageRank alone.",
                "A qualitative evaluation of the top documents shows that fRank is less technology-biased than PageRank; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit.",
                "The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as adversarial classification.",
                "We have only begun to explore the options, and believe that significant strides can be made in the area of static ranking by further experimentation with additional features, other machine learning techniques, and additional sources of data. 8.",
                "ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional PageRank computations and to Timo Burkard for assistance with the popularity data.",
                "Many thanks to Chris Burges for providing code and significant support in using training RankNets.",
                "Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of Web documents.",
                "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in <br>information retrieval</br>, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in <br>information retrieval</br>, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
                "PageRank as a function of the damping factor.",
                "In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims.",
                "A machine learning architecture for optimizing web search engines.",
                "In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998.",
                "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson.",
                "Efficient PageRank approximation via graph aggregation.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the 22nd International Conference on Machine Learning, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer.",
                "Static index pruning for <br>information retrieval</br> systems.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in <br>information retrieval</br>, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy.",
                "Impact of search engines on page popularity.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams.",
                "Page Quality: In search of an unbiased web ranking.",
                "In Proceedings of the ACM SIGMOD 2005 Conference.",
                "Baltimore, Maryland.",
                "June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proceedings of the 28th Annual Conference on Research and Development in <br>information retrieval</br> (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
                "Adversarial Classification.",
                "In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y.",
                "Singer.",
                "Log-linear models for label-ranking.",
                "In Advances in Neural Information Processing Systems 16.",
                "Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005).",
                "Evaluating implicit measures to improve the search experiences.",
                "In the ACM Transactions on Information Systems, 23(2), pp. 147-168.",
                "April 2005. [15]T. Haveliwala.",
                "Efficient computation of PageRank.",
                "Stanford University Technical Report, 1999. [16]T. Haveliwala.",
                "Topic-sensitive PageRank.",
                "In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell.",
                "Very large scale retrieval and Web search.",
                "In D. Harman and E. Voorhees (eds), The TREC Book.",
                "MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer.",
                "Support vector learning for ordinal regression.",
                "In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst.",
                "Statistical profiles of highly-rated Web sites.",
                "In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay.",
                "Accurately Interpreting Clickthrough Data as Implicit Feedback.",
                "In Proceedings of the Conference on Research and Development in <br>information retrieval</br> (SIGIR), 2005. [22]J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit.",
                "The effect of the back button in a random walk: application for PageRank.",
                "In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry.",
                "A uniform approach to accelerated PageRank computation.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide.",
                "Static approximation of dynamically generated Web pages.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston.",
                "User-centric Web crawling.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos.",
                "The intelligent surfer: probabilistic combination of link and content information in PageRank.",
                "In Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
                "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.",
                "Teoma vs. Google, Round 2.",
                "Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: PageRank or indegree?.",
                "In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking.",
                "Query-independent evidence in home page finding.",
                "In ACM Transactions on Information Systems. 2003. 715"
            ],
            "original_annotated_samples": [
                "CONCLUSIONS A good static ranking is an important component for todays search engines and <br>information retrieval</br> systems.",
                "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in <br>information retrieval</br>, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
                "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in <br>information retrieval</br>, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
                "Static index pruning for <br>information retrieval</br> systems.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in <br>information retrieval</br>, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy."
            ],
            "translated_annotated_samples": [
                "CONCLUSIONES Un buen ranking estático es un componente importante para los motores de búsqueda y sistemas de <br>recuperación de información</br> actuales.",
                "En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2000. [2] B. Bartell, G. Cottrell y R. Belew.",
                "En Actas de la 17ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 1994. [3] P. Boldi, M. Santini y S. Vigna.",
                "Poda de índices estáticos para sistemas de <br>recuperación de información</br>.",
                "En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 43-50, Nueva Orleans, Luisiana, EE. UU., septiembre de 2001. [9] J. Cho y S. Roy."
            ],
            "translated_text": "Más allá de PageRank: Aprendizaje automático para la clasificación estática. Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un motor de búsqueda. Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización. Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. Google es frecuentemente considerado como el primer motor de búsqueda comercialmente exitoso. Su clasificación se basaba originalmente en el algoritmo PageRank [5][27]. Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la clasificación estática de páginas web. Aunque se ha pensado que PageRank ha tenido un buen rendimiento históricamente, todavía hay poca evidencia académica que respalde esta afirmación. Aún peor, recientemente se ha demostrado que PageRank puede no funcionar mejor que otras medidas simples en ciertas tareas. Upstill et al. han encontrado que para la tarea de encontrar páginas de inicio, el número de páginas que enlazan a una página y el tipo de URL fueron tan, o más, efectivos que PageRank [32]. Encontraron resultados similares para la tarea de encontrar empresas de alta calidad [31]. PageRank también se ha utilizado en sistemas para las grandes colecciones de TRECs y competencias de seguimiento web, pero con mucho menos éxito del esperado [17]. Finalmente, Amento et al. [1] encontraron que características simples, como el número de páginas en un sitio, tuvieron un rendimiento tan bueno como PageRank. A pesar de esto, la creencia general persiste entre muchos, tanto académicos como en el público, de que PageRank es un factor esencial para un buen rango estático. En caso de que esto falle, se asume que seguir utilizando la estructura de enlaces es crucial, ya sea en forma del número de enlaces entrantes o la cantidad de texto ancla. En este artículo, demostramos que existen una serie de características simples basadas en URL o en páginas que superan significativamente a PageRank (para el propósito de clasificar estáticamente páginas web) a pesar de ignorar la estructura de la web. Combinamos estas y otras características estáticas utilizando aprendizaje automático para lograr un sistema de clasificación que es significativamente mejor que PageRank (en acuerdo par a par con etiquetas humanas). Un enfoque de aprendizaje automático para la clasificación estática tiene otras ventajas además de la calidad de la clasificación. Debido a que la medida consta de muchas características, es más difícil para los usuarios malintencionados manipularla (es decir, elevar el rango estático de sus páginas a un nivel no merecido a través de técnicas cuestionables, también conocidas como spam en la web). Esto es especialmente cierto si el conjunto de características no se conoce. Por el contrario, una sola medida como PageRank puede ser más fácil de manipular porque los spammers solo necesitan concentrarse en un objetivo: cómo hacer que más páginas apunten a su página. Con un algoritmo que aprende, una característica que se vuelve inutilizable debido a la manipulación de spammers simplemente se reducirá o eliminará del cálculo final de rango. Esta flexibilidad permite que un sistema de clasificación reaccione rápidamente a nuevas técnicas de spam. Un enfoque de aprendizaje automático para la clasificación estática también puede aprovechar cualquier avance en el campo del aprendizaje automático. Por ejemplo, un trabajo reciente sobre clasificación adversarial [12] sugiere que puede ser posible modelar explícitamente las acciones de los spammers de páginas web (el adversario), ajustando el modelo de clasificación de antemano antes de que los spammers intenten evadirlo. Otro ejemplo es la eliminación de valores atípicos al construir el modelo, lo cual ayuda a reducir el efecto que los sitios únicos pueden tener en la calidad general de la clasificación estática. Al trasladar la clasificación estática a un marco de aprendizaje automático, no solo ganamos en precisión, sino también en la capacidad de reaccionar a las acciones de los spammers, de añadir rápidamente nuevas características al algoritmo de clasificación y de aprovechar los avances en el campo en rápido crecimiento del aprendizaje automático. Finalmente, creemos que habrá ventajas significativas al utilizar esta técnica para otros ámbitos, como la búsqueda en un disco duro local o en la intranet de una empresa. Estos son dominios donde la estructura de enlaces es particularmente débil (o inexistente), pero hay otras características específicas del dominio que podrían ser igual de poderosas. Por ejemplo, el autor de una página de intranet y su posición en la organización (por ejemplo, CEO, gerente o desarrollador) podrían proporcionar pistas significativas sobre la importancia de esa página. Un enfoque de aprendizaje automático permite el desarrollo rápido de un buen algoritmo estático en nuevos dominios. La contribución de este artículo es un estudio sistemático de las características estáticas, incluido PageRank, con el propósito de clasificar páginas web de forma estática. Estudios previos sobre PageRank típicamente utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Además, el rendimiento de PageRank y otras características estáticas suele evaluarse en el contexto de un sistema completo para la clasificación dinámica, o para otras tareas como la respuesta a preguntas. Por el contrario, exploramos el uso de PageRank y otras características para la tarea directa de clasificar estáticamente las páginas web. Primero describimos brevemente el algoritmo PageRank. En la Sección 3 presentamos RankNet, la técnica de aprendizaje automático utilizada para combinar las características estáticas en un ranking final. La sección 4 describe las características estáticas. El corazón del documento está en la Sección 5, la cual presenta nuestros experimentos y resultados. Concluimos con una discusión sobre el trabajo relacionado y futuro. 2. PAGERANK La idea básica detrás de PageRank es simple: un enlace de una página web a otra puede ser visto como un respaldo de esa página. En general, los enlaces son creados por personas. Por lo tanto, son indicativos de la calidad de las páginas a las que apuntan: al crear una página, un autor presumiblemente elige enlazar a páginas consideradas de buena calidad. Podemos aprovechar esta información de enlace para ordenar las páginas web según su calidad percibida. Imagina a un internauta que salta de página web en página web, eligiendo con probabilidad uniforme qué enlace seguir en cada paso. Para reducir el efecto de los callejones sin salida o ciclos interminables, el surfista saltará ocasionalmente a una página aleatoria con una pequeña probabilidad α, o cuando se encuentre en una página sin enlaces de salida. Si se promedia sobre un número suficiente de pasos, la probabilidad de que el surfista esté en la página j en algún momento en el tiempo está dada por la fórmula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Donde Fi es el conjunto de páginas a las que enlaza la página i, y Bj es el conjunto de páginas que enlazan a la página j. El puntaje de PageRank para el nodo j se define como esta probabilidad: PR(j)=P(j). Dado que la ecuación (1) es recursiva, debe evaluarse de forma iterativa hasta que P(j) converja (normalmente, la distribución inicial para P(j) es uniforme). La intuición es que, dado que un navegante aleatorio llegaría a la página con más frecuencia, es probable que sea una página mejor. Una vista alternativa para la ecuación (1) es que a cada página se le asigna una calidad, P(j). Una página otorga una parte igual de su calidad a cada página a la que apunta. PageRank es computacionalmente costoso. Nuestra colección de 5 mil millones de páginas contiene aproximadamente 370 mil millones de enlaces. Calcular el PageRank requiere iterar sobre miles de millones de enlaces varias veces (hasta converger). Requiere grandes cantidades de memoria (o esquemas de almacenamiento en caché muy inteligentes que ralentizan aún más el cálculo), y si se distribuye en múltiples máquinas, requiere una comunicación significativa entre ellas. Aunque se ha realizado mucho trabajo en la optimización del cálculo del PageRank (ver, por ejemplo, [25] y [6]), sigue siendo una propiedad relativamente lenta y costosa computacionalmente de calcular. 3. RANKNET Se ha realizado mucho trabajo en aprendizaje automático en los problemas de clasificación y regresión. Sea X={xi} una colección de vectores de características (típicamente, una característica es cualquier número real), y Y={yi} una colección de clases asociadas, donde yi es la clase del objeto descrito por el vector de características xi. El problema de clasificación consiste en aprender una función f que mapea yi=f(xi), para todo i. Cuando yi también es un valor real, esto se llama regresión. La clasificación estática se puede ver como un problema de regresión. Si dejamos que xi represente las características de la página i, y yi sea un valor (por ejemplo, el rango) para cada página, podríamos aprender una función de regresión que mapeara las características de cada página a su rango. Sin embargo, esto sobrecarga el problema que deseamos resolver. Todo lo que realmente nos importa es el orden de las páginas, no el valor real asignado a ellas. El trabajo reciente sobre este problema de clasificación [7][13][18] intenta directamente optimizar el orden de los objetos, en lugar del valor asignado a ellos. Para esto, sea Z={<i,j>} una colección de pares de elementos, donde el elemento i debe ser asignado un valor más alto que el elemento j. El objetivo del problema de clasificación, entonces, es aprender una función f tal que, )()(,, ji ffji xxZ >∈∀ 708. Nótese que, al igual que al aprender una función de regresión, el resultado de este proceso es una función (f) que mapea vectores de características a valores reales. Esta función todavía se puede aplicar en cualquier lugar donde se pueda aplicar una función aprendida por regresión. La única diferencia es la técnica utilizada para aprender la función. Al optimizar directamente el orden de los objetos, estos métodos pueden aprender una función que clasifica mejor que las técnicas de regresión. Utilizamos RankNet [7], una de las técnicas mencionadas para aprender funciones de clasificación, para aprender nuestra función de clasificación estática. RankNet es una modificación sencilla del algoritmo de retropropagación de la red neuronal estándar. Al igual que con back-prop, RankNet intenta minimizar el valor de una función de costo ajustando cada peso en la red de acuerdo con el gradiente de la función de costo con respecto a ese peso. La diferencia es que, mientras que una función de costo típica de una red neuronal se basa en la diferencia entre la salida de la red y la salida deseada, la función de costo de RankNet se basa en la diferencia entre un par de salidas de la red. Es decir, para cada par de vectores de características <i,j> en el conjunto de entrenamiento, RankNet calcula las salidas de la red oi y oj. Dado que se supone que el vector i está clasificado más alto que el vector j, cuanto mayor sea oj-oi, mayor será el costo. RankNet también permite que los pares en Z sean ponderados con una confianza (expresada como la probabilidad de que el par cumpla con el ordenamiento inducido por la función de clasificación). En este documento, utilizamos una probabilidad de uno para todos los pares. En la siguiente sección, discutiremos las características utilizadas en nuestros vectores de características, xi. 4. Para aplicar RankNet (u otras técnicas de aprendizaje automático) al problema de clasificación, necesitábamos extraer un conjunto de características de cada página. Dividimos nuestro conjunto de características en cuatro categorías mutuamente excluyentes: a nivel de página (Página), a nivel de dominio (Dominio), texto del enlace y enlaces entrantes (Anclaje) y popularidad (Popularidad). También opcionalmente utilizamos el PageRank de una página como una característica. A continuación, describimos cada una de estas categorías de características con más detalle. Calculamos PageRank en un grafo web de 5 mil millones de páginas rastreadas (y 20 mil millones de URLs conocidas enlazadas por estas páginas). Esto representa una parte significativa de la Web, y es aproximadamente la misma cantidad de páginas que utilizan Google, Yahoo y MSN para sus motores de búsqueda. Dado que PageRank es un algoritmo basado en grafos, es importante que se ejecute en la mayor cantidad posible de subconjuntos de la Web. La mayoría de los estudios previos sobre PageRank utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Calculamos PageRank utilizando el valor estándar de 0.85 para α. Otra característica que utilizamos es la popularidad real de una página web, medida como el número de veces que ha sido visitada por usuarios durante algún período de tiempo. Tenemos acceso a esos datos de usuarios que han instalado la barra de herramientas de MSN y han optado por proporcionarlos a MSN. Los datos se agregan en un recuento, para cada página web, del número de usuarios que vieron esa página. Aunque los datos de popularidad generalmente no están disponibles, hay otras dos fuentes para obtenerlos. El primero es de los registros de proxy. Por ejemplo, una universidad que requiere que sus estudiantes utilicen un proxy tiene un registro de todas las páginas que han visitado mientras están en el campus. Desafortunadamente, los datos de proxy son bastante sesgados y relativamente pequeños. Otra fuente, interna de los motores de búsqueda, son los registros de los resultados en los que hicieron clic sus usuarios. Tales datos fueron utilizados por el motor de búsqueda Direct Hit, y recientemente han sido explorados con fines de clasificación dinámica [20]. Una ventaja de los datos de la barra de herramientas sobre esto es que contiene información sobre las visitas a URL que no son solo el resultado de una búsqueda. La popularidad en bruto se procesa en una serie de características como el número de veces que se visualizó una página y el número de veces que se visualizó cualquier página en el dominio. Se proporcionan más detalles en la sección 5.5. Texto de anclaje e inlinks. Estas características se basan en la información asociada con los enlaces a la página en cuestión. Incluye características como la cantidad total de texto en los enlaces que apuntan a la página (texto de anclaje), el número de palabras únicas en ese texto, etc. Esta categoría consiste en características que pueden ser determinadas solo al observar la página (y su URL). Solo utilizamos ocho características simples como el número de palabras en el cuerpo, la frecuencia del término más común, etc. Este categoría contiene características que se calculan como promedios en todas las páginas del dominio. Por ejemplo, el número promedio de enlaces salientes en cualquier página y el PageRank promedio. Muchas de estas características han sido utilizadas por otros para clasificar páginas web, especialmente las características de anclaje y de la página. Como se mencionó, la evaluación suele ser para clasificación dinámica, y deseamos evaluar su uso para clasificación estática. Además, hasta donde sabemos, este es el primer estudio sobre el uso de la popularidad real de visitas a páginas para la clasificación estática. El trabajo similar más cercano se centra en el uso del comportamiento de clics (es decir, en los resultados de búsqueda en los que los usuarios hacen clic) para afectar la clasificación dinámica (ver, por ejemplo, [20]). Debido a que utilizamos una amplia variedad de características para crear un ranking estático, nos referimos a esto como fRank (para ranking basado en características). fRank utiliza RankNet y el conjunto de características descritas en esta sección para aprender una función de ranking para páginas web. A menos que se especifique lo contrario, fRank fue entrenado con todas las características. 5. EXPERIMENTOS En esta sección, demostraremos que podemos superar a PageRank aplicando aprendizaje automático a un conjunto sencillo de características. Antes de los resultados, primero discutimos los datos, la métrica de rendimiento y el método de entrenamiento. 5.1 Datos Para evaluar la calidad de un ranking estático, necesitábamos un estándar de oro que definiera el orden correcto para un conjunto de páginas. Para esto, empleamos un conjunto de datos que contiene juicios humanos para 28000 consultas. Para cada consulta, un número de resultados son asignados manualmente una calificación, de 0 a 4, por jueces humanos. La calificación está destinada a ser una medida de cuán relevante es el resultado para la consulta, donde 0 significa pobre y 4 significa excelente. Hay aproximadamente 500 mil juicios en total, o un promedio de 18 calificaciones por consulta. Las consultas se seleccionan eligiendo aleatoriamente consultas de entre aquellas emitidas al motor de búsqueda de MSN. La probabilidad de que se seleccione una consulta es proporcional a su frecuencia entre las 709 consultas. Como resultado, es más probable que las consultas comunes sean evaluadas que las consultas poco comunes. Como ejemplo de la diversidad de las consultas, las primeras cuatro consultas en el conjunto de entrenamiento son escuelas de chef, el autódromo de Chicagoland, el club de fans de los Eagles y la cultura turca. Los documentos seleccionados para evaluar son aquellos que esperábamos que, en promedio, fueran razonablemente relevantes (por ejemplo, los diez documentos principales devueltos por el motor de búsqueda de MSN). Esto proporciona significativamente más información que seleccionar documentos al azar en la web, la gran mayoría de los cuales serían irrelevantes para una consulta específica. Debido a este proceso, las páginas evaluadas tienden a ser de mayor calidad que la página promedio en la web, y suelen ser páginas que se devolverán en consultas de búsqueda comunes. Este sesgo es útil al evaluar la calidad de la clasificación estática con el fin de ordenar índices y devolver documentos relevantes. Esto se debe a que la parte más importante del índice que debe estar bien ordenada y ser relevante es la parte que se devuelve con frecuencia para las consultas de búsqueda. Debido a este sesgo, sin embargo, los resultados en este documento no son aplicables a la priorización de rastreo. Para obtener resultados experimentales sobre la priorización de rastreo, necesitaríamos calificaciones de una muestra aleatoria de páginas web. Para convertir los datos de dependientes de la consulta a independientes de la consulta, simplemente eliminamos la consulta, tomando el máximo sobre las evaluaciones para una URL que aparece en más de una consulta. El razonamiento detrás de esto es que una página que es relevante para una consulta y no relevante para otra probablemente sea una buena página y debería tener un alto rango estático. Debido a que evaluamos las páginas en consultas que ocurren con frecuencia, nuestros datos indican el orden correcto del índice y asignan un alto valor a las páginas que probablemente sean relevantes para una consulta común. Asignamos consultas al azar a un conjunto de entrenamiento, validación o prueba, de modo que contuvieran el 84%, 8% y 8% de las consultas, respectivamente. Cada conjunto contiene todas las calificaciones para una consulta dada, y ninguna consulta aparece en más de un conjunto. El conjunto de entrenamiento se utilizó para entrenar fRank. El conjunto de validación se utilizó para seleccionar el modelo que tuvo el mejor rendimiento. El conjunto de pruebas se utilizó para los resultados finales. Estos datos nos proporcionan un ordenamiento de páginas independiente de la consulta. El objetivo de un algoritmo de clasificación estática será reproducir este orden lo más fielmente posible. En la siguiente sección, describimos la medida que utilizamos para evaluar esto. 5.2 Medida Elegimos utilizar la precisión por pares para evaluar la calidad de un ranking estático. La precisión por pares es la fracción de tiempo en la que el algoritmo de clasificación y los jueces humanos están de acuerdo en el ordenamiento de un par de páginas web. Si S(x) es la clasificación estática asignada a la página x, y H(x) es el juicio humano de relevancia para x, entonces considera los siguientes conjuntos: )}()(:,{ yHxHyx >=pH y )}()(:,{ ySxSyx >=pS La precisión por pares es la porción de Hp que también está contenida en Sp: p pp H SH ∩ =precisiónpares Esta medida fue elegida por dos razones. Primero, los juicios humanos discretos proporcionan solo un orden parcial sobre las páginas web, lo que dificulta aplicar una medida como el coeficiente de correlación de orden de rango de Spearman (en la medida de precisión por pares, un par de documentos con el mismo juicio humano no afecta la puntuación). Segundo, la precisión por pares tiene un significado intuitivo: es la fracción de pares de documentos que, cuando los humanos afirman que uno es mejor que el otro, el algoritmo de clasificación estática los ordena correctamente. 5.3 Método Entrenamos fRank (una red neuronal basada en RankNet) utilizando los siguientes parámetros. Utilizamos una red de 2 capas completamente conectadas. La capa oculta tenía 10 nodos ocultos. Los pesos de entrada a esta capa se inicializaron todos en cero. Los pesos de la capa de salida (solo un nodo) se inicializaron utilizando una distribución aleatoria uniforme en el rango [-0.1, 0.1]. Utilizamos la función tangente hiperbólica (tanh) como función de transferencia de las entradas a la capa oculta, y una función lineal de la capa oculta a la salida. La función de costo es la función de costo de entropía cruzada por pares discutida en la sección 3. Las características en el conjunto de entrenamiento fueron normalizadas para tener media cero y desviación estándar unitaria. La misma transformación lineal fue luego aplicada a las características en los conjuntos de validación y prueba. Para el entrenamiento, presentamos a la red neuronal 5 millones de pares de páginas, donde una página tenía una calificación más alta que la otra. Las combinaciones fueron elegidas de forma uniforme al azar (con reemplazo) de todas las combinaciones posibles. Al formar las parejas, ignoramos la magnitud de la diferencia entre las calificaciones (la dispersión de calificaciones) de las dos URL. Por lo tanto, el peso para cada par era constante (uno), y la probabilidad de que se seleccionara un par era independiente de la diferencia de calificación. Entrenamos la red durante 30 épocas. En cada época, los pares de entrenamiento fueron mezclados aleatoriamente. La tasa de entrenamiento inicial fue de 0.001. En cada época, verificamos el error en el conjunto de entrenamiento. Si el error hubiera aumentado, entonces disminuimos la tasa de entrenamiento, bajo la hipótesis de que la red probablemente se había excedido. La tasa de entrenamiento en cada época se estableció de la siguiente manera: Tasa de entrenamiento = 1+ε κ Donde κ es la tasa inicial (0.001), y ε es el número de veces que el error del conjunto de entrenamiento ha aumentado. Después de cada época, medimos el rendimiento de la red neuronal en el conjunto de validación, utilizando 1 millón de pares (elegidos al azar con reemplazo). La red con la mayor precisión en pares en el conjunto de validación fue seleccionada, y luego probada en el conjunto de pruebas. Informamos la precisión por pares en el conjunto de pruebas, calculada utilizando todos los pares posibles. Estos parámetros fueron determinados y fijados antes de los experimentos de clasificación estática en este artículo. En particular, la elección de la tasa de entrenamiento inicial, el número de épocas y la función de decaimiento de la tasa de entrenamiento se tomaron directamente de Burges et al [7]. Aunque teníamos la opción de preprocesar cualquiera de las características antes de introducirlas en la red neuronal, nos abstuvimos de hacerlo en la mayoría de ellas. La única excepción fueron las características de popularidad. Como ocurre con la mayoría de los fenómenos web, descubrimos que la distribución de la popularidad de los sitios es Zipfiana. Para reducir el rango dinámico, y con suerte hacer que la característica sea más útil, presentamos a la red tanto las características de popularidad sin procesar, como el logaritmo de las mismas (Al igual que con las demás, los valores de las características logarítmicas también se normalizaron para tener media cero y desviación estándar unitaria). Aplicar fRank a un documento es computacionalmente eficiente, tomando un tiempo que es solo lineal en el número de características de entrada; por lo tanto, está dentro de un factor constante de otros métodos de aprendizaje automático simples como el Bayes ingenuo. En nuestros experimentos, calcular el fRank para las cinco mil millones de páginas web fue aproximadamente 100 veces más rápido que calcular el PageRank para el mismo conjunto. 5.4 Resultados Como muestra la Tabla 1, el fRank supera significativamente al PageRank para los propósitos de clasificación estática. Con una precisión de pares del 67.4%, fRank más que duplica la precisión de PageRank (en relación con la línea base del 50%, que es la precisión que se lograría con un orden aleatorio de páginas web). Ten en cuenta que una de las características de entrada de fRanks es el PageRank de la página, por lo que esperaríamos que su rendimiento no fuera peor que el de PageRank. El aumento significativo en precisión implica que las otras características (anclaje, popularidad, etc.) de hecho contienen información útil sobre la calidad general de una página. Tabla 1: Resultados Básicos Técnica Precisión (%) Ninguna (Línea base) 50.00 PageRank 56.70 fRank 67.43 Existen varias decisiones que intervienen en el cálculo de PageRank, como por ejemplo cómo tratar las páginas que no tienen enlaces salientes, la elección de α, la precisión numérica, el umbral de convergencia, etc. Pudimos obtener un cálculo de PageRank a partir de una implementación completamente independiente (proporcionada por Marc Najork) que variaba ligeramente en estos parámetros. Obtuvo una precisión de pares del 56.52%, casi idéntica a la obtenida por nuestra implementación. Por lo tanto, concluimos que la calidad del PageRank no es sensible a estas variaciones menores en el algoritmo, ni la baja precisión de los PageRanks se debió a problemas con nuestra implementación de él. También queríamos averiguar qué tan bien se desempeñaba cada conjunto de características. Para responder a esto, para cada conjunto de características, entrenamos y probamos fRank utilizando solo ese conjunto de características. Los resultados se muestran en la Tabla 2. Como se puede ver, cada conjunto de características individual superó a PageRank en esta prueba. Quizás el resultado más interesante es que las características a nivel de página tuvieron el mejor rendimiento de todos los conjuntos de características. Esto es sorprendente porque estas son características que no dependen de la estructura general del grafo de la Web, ni siquiera de qué páginas apuntan a una página dada. Esto va en contra de la creencia común de que la estructura del grafo web es la clave para encontrar una buena clasificación estática de las páginas web. Tabla 2: Resultados para conjuntos de características individuales. Debido a que estamos utilizando una red neuronal de dos capas, las características en la red aprendida pueden interactuar entre sí de maneras interesantes y no lineales. Esto significa que una característica particular que parece tener poco valor por sí sola podría ser muy importante cuando se utiliza en combinación con otras características. Para medir la contribución final de un conjunto de características, en el contexto de todas las demás características, realizamos un estudio de ablación. Es decir, para cada conjunto de características, entrenamos una red para contener todas las características excepto ese conjunto. Luego comparamos el rendimiento de la red resultante con el rendimiento de la red con todas las características. La Tabla 3 muestra los resultados de este experimento, donde la disminución en la precisión es la diferencia en la precisión por pares entre la red entrenada con todas las características y la red que carece del conjunto de características dado. Tabla 3: Estudio de ablación. Se muestra la disminución en precisión cuando entrenamos una red que tiene todas las características excepto el conjunto dado. La última línea muestra el efecto de eliminar las características del ancla, PageRank y dominio, por lo tanto, un modelo que no contiene ninguna información de red o basada en enlaces. Los resultados del estudio de ablación son consistentes con el estudio de conjunto de características individuales. Ambos muestran que el conjunto de características más importante es el conjunto de características a nivel de página, y el segundo más importante es el conjunto de características de popularidad. Finalmente, deseábamos ver cómo mejoraba el rendimiento de fRank a medida que añadíamos características; queríamos encontrar en qué punto añadir más conjuntos de características se volvía relativamente inútil. Comenzando sin características, añadimos ávidamente el conjunto de características que mejoró el rendimiento en mayor medida. Los resultados se muestran en la Tabla 4. Por ejemplo, la cuarta línea de la tabla muestra que fRank utilizando las características de página, popularidad y anclaje superó a cualquier red que utilizara la página, popularidad y algún otro conjunto de características, y que el rendimiento de esta red fue del 67.25%. Tabla 4: Rendimiento de fRank a medida que se agregan conjuntos de características. En cada fila, se añadió al conjunto de características aquella que proporcionó el mayor aumento en la precisión (es decir, realizamos una búsqueda ávida sobre conjuntos de características). Precisión del conjunto de características (%) Ninguna 50.00 +Página 63.93 +Popularidad 66.83 +Anclaje 67.25 +PageRank 67.31 +Dominio 67.43 711 Finalmente, presentamos una comparación cualitativa de PageRank vs. fRank. En la Tabla 5 se encuentran las diez URL principales devueltas para PageRank y para fRank. Los resultados de PageRank están fuertemente ponderados hacia sitios de tecnología. Contiene dos URL de QuickTime (software de reproducción de video de Apple), así como URL de Internet Explorer y FireFox (ambos navegadores web). Por otro lado, fRank contiene sitios más orientados al consumidor como American Express, Target, Dell, etc. El sesgo de PageRank hacia la tecnología puede explicarse a través de dos procesos. Primero, hay muchas páginas con botones en la parte inferior que sugieren que el sitio está optimizado para Internet Explorer, o que el visitante necesita QuickTime. Estos enlaces generalmente remiten, en estos ejemplos, a los sitios de descarga de Internet Explorer y QuickTime. Por consiguiente, PageRank clasifica esas páginas en posiciones altas. Aunque estas páginas son importantes, no son tan importantes como podría parecer al observar solo la estructura de enlaces. Una solución para esto es agregar información sobre el enlace al cálculo del PageRank, como el tamaño del texto, si estaba en la parte inferior de la página, etc. El otro sesgo proviene del hecho de que la población de autores de sitios web es diferente a la población de usuarios de la web. Los autores web tienden a estar orientados tecnológicamente, por lo que su comportamiento de enlace refleja esos intereses. fRank, al conocer la popularidad real de visitas de un sitio (el conjunto de características de popularidad), puede eliminar parte de ese sesgo. Tiene la capacidad de depender más de dónde visitan los usuarios reales de la Web que de dónde han enlazado los autores del sitio web. Los resultados confirman que fRank supera a PageRank en precisión por pares. Los dos conjuntos de características más importantes son las características de la página y de la popularidad. Esto es sorprendente, ya que las características de la página consistían solo en unas pocas (8) características simples. Experimentos adicionales encontraron que, de las características de la página, aquellas basadas en el texto de la página (en contraposición a la URL) tuvieron el mejor rendimiento. En la siguiente sección, exploramos la característica de popularidad con más detalle. 5.5 Datos de Popularidad Como se mencionó en la sección 4, nuestros datos de popularidad provienen de usuarios de la barra de herramientas de MSN. Por razones de privacidad, solo tuvimos acceso a un recuento agregado de cuántas veces fue visitada cada URL por cualquier usuario de la barra de herramientas. Esto limitó las características posibles que podríamos derivar de estos datos. Para posibles extensiones, consulte la sección 6.3, trabajo futuro. Para cada URL en nuestros conjuntos de entrenamiento y prueba, proporcionamos una característica a fRank que indicaba cuántas veces había sido visitada por un usuario de la barra de herramientas. Sin embargo, esta característica era bastante ruidosa y dispersa, especialmente para URL con parámetros de consulta (por ejemplo, http://search.msn.com/results.aspx?q=machine+learning&form=QBHP). Una solución fue proporcionar una característica adicional que era el número de veces que cualquier URL en el dominio dado fue visitada por un usuario de la barra de herramientas. La adición de esta característica mejoró drásticamente el rendimiento de fRank. Llevamos esto un paso más allá y utilizamos la estructura jerárquica incorporada de las URL para construir varios niveles de retroceso entre la URL completa y el dominio. Lo hicimos utilizando el conjunto de características mostradas en la Tabla 6. Tabla 6: Funciones de URL utilizadas para calcular el conjunto de características de Popularidad. Cada URL fue asignado una característica para cada función mostrada en la tabla. El valor de la característica era el recuento de la cantidad de veces que un usuario de la barra de herramientas visitó una URL, donde la función aplicada a esa URL coincide con la función aplicada a la URL en cuestión. Por ejemplo, la visita de un usuario a cnn.com/2005/sports.html incrementaría las características de Dominio y Dominio+1 para la URL cnn.com/2005/tech/wikipedia.html. Como se observa en la Tabla 7, agregar los recuentos de dominio mejoró significativamente la calidad de la característica de popularidad, y agregar las numerosas funciones de respaldo enumeradas en la Tabla 6 mejoró aún más la precisión. Tabla 7: Efecto de agregar retroceso a la característica de popularidad Conjunto de características Precisión (%) Recuento de URL 58.15 Recuento de URL y dominio 59.31 Todas las funciones de retroceso (Tabla 6) 60.82 Tabla 5: Diez mejores URL para PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Retroceder a subconjuntos de la URL es una técnica para tratar la escasez de datos. También es informativo ver cómo el rendimiento de fRank depende de la cantidad de datos de popularidad que hemos recopilado. En la Figura 1 mostramos el rendimiento de fRank entrenado solo con el conjunto de características de popularidad frente a la cantidad de datos que tenemos para el conjunto de características de popularidad. Cada día recibimos datos adicionales de popularidad, y como se puede ver en el gráfico, esto aumenta el rendimiento de fRank. La relación es logarítmica: duplicar la cantidad de datos de popularidad proporciona una mejora constante en la precisión de pares. En resumen, hemos encontrado que las características de popularidad proporcionan un impulso útil a la precisión general de fRank. Recopilando más datos de popularidad, así como empleando estrategias de retroceso simples, se mejora aún más este impulso. 5.6 Resumen de Resultados Los experimentos proporcionan varias conclusiones. Primero, fRank funciona significativamente mejor que PageRank, incluso sin tener información sobre el grafo web. En segundo lugar, las características a nivel de página y de popularidad fueron los contribuyentes más significativos a la precisión por pares. Tercero, al recopilar más datos de popularidad, podemos seguir mejorando el rendimiento de fRanks. Los datos de popularidad proporcionan dos beneficios a fRank. Primero, observamos que cualitativamente, el ordenamiento de fRanks de las páginas web tiene un sesgo más favorable que PageRanks. El ordenamiento de fRanks parece corresponder a lo que los usuarios de la web, en lugar de los autores de las páginas web, prefieren. Segundo, los datos de popularidad son más actuales que la información de enlaces de PageRank. La barra de herramientas proporciona información sobre qué páginas web encuentran interesantes las personas en este momento, mientras que los enlaces se agregan a las páginas más lentamente, a medida que los autores encuentran el tiempo y el interés. TRABAJO RELACIONADO Y FUTURO 6.1 Mejoras a PageRank Desde el artículo original de PageRank, ha habido trabajos para mejorarlo. Gran parte de ese trabajo se centra en acelerar y paralelizar el cálculo [15][25]. Un problema reconocido con PageRank es el de la deriva de temas: una página sobre perros tendrá un alto PageRank si está vinculada por muchas páginas que a su vez tienen un alto rango, independientemente de su tema. Por el contrario, un usuario de un motor de búsqueda que busca buenas páginas sobre perros probablemente preferiría encontrar páginas que son enlazadas por muchas páginas que tratan sobre perros. Por lo tanto, un enlace que esté relacionado con el tema debería tener más peso que un enlace que no lo esté. Richardson y el PageRank Dependiente de Consulta de Domingos [29] y el PageRank Sensible al Tema de Haveliwala [16] son dos enfoques que abordan este problema. Otras variaciones de PageRank incluyen ponderar de manera diferente los enlaces para enlaces inter e intra-dominio, agregar un paso hacia atrás al surfista aleatorio para simular el botón de retroceso en la mayoría de los navegadores [24] y modificar la probabilidad de salto (α) [3]. Consulte Langville y Meyer [23] para obtener una buena revisión de estas y otras modificaciones a PageRank. 6.2 Otros trabajos relacionados PageRank no es el único algoritmo de análisis de enlaces utilizado para clasificar páginas web. El otro más conocido es HITS [22], que es utilizado por el motor de búsqueda Teoma [30]. HITS produce una lista de hubs y autoridades, donde los hubs son páginas que apuntan a muchas páginas de autoridad, y las autoridades son páginas a las que apuntan muchos hubs. Trabajos anteriores han demostrado que HITS tiene un rendimiento comparable al de PageRank [1]. Un campo de interés es el de la poda de índices estáticos (ver, por ejemplo, Carmel et al. [8]). Los métodos de poda de índices estáticos reducen el tamaño del índice de los motores de búsqueda al eliminar documentos que es poco probable que sean devueltos por una consulta de búsqueda. La poda se realiza típicamente en función de la frecuencia de los términos de consulta. De manera similar, Pandey y Olston [28] sugieren rastrear las páginas con frecuencia si es probable que aparezcan incorrectamente (o no aparezcan) como resultado de una búsqueda. Métodos similares podrían ser incorporados en la clasificación estática (por ejemplo, cuántas consultas frecuentes contienen palabras encontradas en esta página). Otros han investigado el efecto que PageRank tiene en la Web en general [9]. Argumentan que las páginas con un alto PageRank son más propensas a ser encontradas por los usuarios de la web, por lo tanto, es más probable que sean enlazadas y, por ende, mantengan un PageRank más alto que otras páginas. Lo mismo puede ocurrir con los datos de popularidad. Si aumentamos la clasificación de las páginas populares, es más probable que se haga clic en ellas, lo que a su vez aumentará aún más su popularidad. Cho et al. [10] argumentan que una medida más apropiada de la calidad de una página web dependería no solo de la estructura de enlaces actual de la web, sino también de los cambios en esa estructura de enlaces. La misma técnica puede ser aplicable a los datos de popularidad: el cambio en la popularidad de una página puede ser más informativo que la popularidad absoluta. Un trabajo relacionado interesante es el de Ivory y Hearst [19]. Su objetivo era construir un modelo de sitios web que son considerados de alta calidad desde la perspectiva de contenido, estructura y navegación, diseño visual, funcionalidad, interactividad y experiencia general. Utilizaron más de 100 características a nivel de página, así como características que abarcan el rendimiento y la estructura del sitio. Esto les permitió describir cualitativamente las cualidades de una página que la hacen parecer atractiva (por ejemplo, el uso poco común de cursivas, al menos una fuente de 9 puntos, ...), y (en trabajos posteriores) construir un sistema que ayude a los autores de páginas web novedosas a crear páginas de calidad evaluándolas según estas características. Las principales diferencias entre este trabajo y el nuestro son el objetivo (descubrir qué constituye una buena página web vs. ordenar páginas web con fines de búsqueda en la web), el tamaño del estudio (utilizaron un conjunto de datos de menos de 6000 páginas vs. nuestro conjunto de 468,000), y nuestra comparación con PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Días de Datos de la Barra de Herramientas Precisión por Pares Figura 1: Relación entre la cantidad de datos de popularidad y el rendimiento del conjunto de características de popularidad. Ten en cuenta que el eje x es una escala logarítmica. Sin embargo, su trabajo proporciona ideas sobre características estáticas adicionales útiles que podríamos incorporar en fRank en el futuro. El trabajo reciente sobre la incorporación de características novedosas en la clasificación dinámica incluye el realizado por Joachims et al. [21], quienes investigan el uso de retroalimentación implícita de los usuarios, en forma de los resultados de búsqueda en el motor de búsqueda que se hacen clic. Craswell et al. [11] presentan un método para determinar la mejor transformación a aplicar a las características independientes de la consulta (como las utilizadas en este artículo) con el fin de mejorar la clasificación dinámica. Otros trabajos, como el de Boyan et al. [4] y Bartell et al. [2], aplican aprendizaje automático con el propósito de mejorar la relevancia general de un motor de búsqueda (es decir, el ranking dinámico). No aplican sus técnicas al problema de clasificación estática. 6.3 Trabajo futuro Hay muchas formas en las que nos gustaría ampliar este trabajo. Primero, Frank utiliza solo un pequeño número de características. Creemos que podríamos lograr resultados aún más significativos con más características. En particular, la existencia o falta de ciertas palabras podría resultar muy significativa (por ejemplo, \"en construcción\" probablemente signifique una página de baja calidad). Otras características podrían incluir el número de imágenes en una página, el tamaño de esas imágenes, el número de elementos de diseño (tablas, divs y spans), el uso de hojas de estilo, la conformidad con los estándares de W3C (como XHTML 1.0 Strict), el color de fondo de una página, etc. Muchas páginas se generan dinámicamente, cuyos contenidos pueden depender de parámetros en la URL, la hora del día, el usuario que visita el sitio, u otras variables. Para este tipo de páginas, puede ser útil aplicar las técnicas encontradas en [26] para formar una aproximación estática con el fin de extraer características. La gramática resultante que describe la página podría ser en sí misma una fuente de características adicionales que describen la complejidad de la página, como cuántos nodos no terminales tiene, la profundidad del árbol gramatical, etc. fRank permite especificar una confianza en cada emparejamiento de documentos. En el futuro, experimentaremos con probabilidades que dependen de la diferencia en los juicios humanos entre los dos elementos del par. Por ejemplo, un par de documentos donde uno fue calificado con un 4 y el otro con un 0 debería tener una mayor confianza que un par de documentos calificados con un 3 y un 2. Los experimentos en este artículo están sesgados hacia páginas que tienen una calidad superior al promedio. Además, fRank con todas las características solo se puede aplicar a páginas que ya han sido rastreadas. Por lo tanto, fRank es principalmente útil para el ordenamiento de índices y mejorar la relevancia, no para dirigir el rastreo. Nos gustaría investigar un enfoque de aprendizaje automático para la priorización de rastreo también. Puede ser que la mejor opción sea una combinación de métodos: por ejemplo, utilizar PageRank para seleccionar los mejores 5 mil millones de las 20 mil millones de páginas en la web, luego utilizar fRank para ordenar el índice y afectar la relevancia de la búsqueda. Otra dirección interesante para la exploración es incorporar las características de fRank y a nivel de página directamente en el cálculo de PageRank en sí mismo. El trabajo en el sesgo del vector de salto de PageRank [16] y la matriz de transición [29] ha demostrado la viabilidad y ventajas de este enfoque. Existe motivo para creer que una aplicación directa de [29], utilizando el fRank de una página para su relevancia, podría llevar a una mejora en el rango estático general. Finalmente, los datos de popularidad pueden ser utilizados de otras maneras interesantes. Los hábitos generales de navegación y búsqueda de los usuarios de la web varían según la hora del día. La actividad por la mañana, durante el día y en la tarde suele ser bastante diferente (por ejemplo, leer las noticias, resolver problemas y acceder al entretenimiento, respectivamente). Podemos obtener información sobre estas diferencias utilizando los datos de popularidad, divididos en segmentos del día. Cuando se emite una consulta, luego utilizaríamos los datos de popularidad que coincidan con el momento de la consulta para clasificar las páginas web. También planeamos explorar características de popularidad que utilicen más que solo el recuento de cuántas veces se visitó una página. Por ejemplo, cuánto tiempo los usuarios solían permanecer en una página, si abandonaron la página haciendo clic en un enlace o presionando el botón de retroceso, etc. Fox et al. realizaron un estudio que demostró que características como esta pueden ser valiosas para los propósitos de clasificación dinámica [14]. Finalmente, los datos de popularidad podrían ser utilizados como la etiqueta en lugar de como una característica. Utilizar fRank de esta manera para predecir la popularidad de una página puede ser útil para las tareas de relevancia, eficiencia y prioridad de rastreo. También hay significativamente más datos de popularidad que datos etiquetados por humanos, lo que potencialmente permite el uso de métodos de aprendizaje automático más complejos y muchas más características. 7. CONCLUSIONES Un buen ranking estático es un componente importante para los motores de búsqueda y sistemas de <br>recuperación de información</br> actuales. Hemos demostrado que PageRank no proporciona una clasificación estática muy buena; hay muchas características simples que superan individualmente a PageRank. Al combinar muchas características estáticas, fRank logra un ranking que tiene una precisión en pares significativamente mayor que PageRank solo. Una evaluación cualitativa de los documentos principales muestra que fRank está menos sesgado hacia la tecnología que PageRank; al utilizar datos de popularidad, está sesgado hacia las páginas que los usuarios de la web visitan, en lugar de hacia las páginas que los autores web crean. El componente de aprendizaje automático de fRank le otorga el beneficio adicional de ser más robusto contra los spammers, y le permite aprovechar los avances adicionales en la comunidad de aprendizaje automático en áreas como la clasificación adversarial. Hemos comenzado a explorar las opciones y creemos que se pueden lograr avances significativos en el área de clasificación estática mediante experimentación adicional con características adicionales, otras técnicas de aprendizaje automático y fuentes de datos adicionales. AGRADECIMIENTOS Gracias a Marc Najork por proporcionarnos cálculos adicionales de PageRank y a Timo Burkard por su ayuda con los datos de popularidad. Muchas gracias a Chris Burges por proporcionar código y un apoyo significativo en el uso del entrenamiento de RankNets. También agradecemos a Susan Dumais y Nick Craswell por sus ediciones y sugerencias. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2000. [2] B. Bartell, G. Cottrell y R. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la 17ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 1994. [3] P. Boldi, M. Santini y S. Vigna. PageRank como una función del factor de amortiguamiento. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. 714 [4] J. Boyan, D. Freitag y T. Joachims. Una arquitectura de aprendizaje automático para optimizar los motores de búsqueda web. En el taller de AAAI sobre Sistemas de Información Basados en Internet, agosto de 1996. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. En Actas de la Séptima Conferencia Internacional de la World Wide Web, Brisbane, Australia, 1998. Elsevier. [6] A. Broder, R. Lempel, F. Maghoul y J. Pederson. Aproximación eficiente de PageRank a través de la agregación de grafos. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, Bonn, Alemania, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek y A. Soffer. Poda de índices estáticos para sistemas de <br>recuperación de información</br>. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 43-50, Nueva Orleans, Luisiana, EE. UU., septiembre de 2001. [9] J. Cho y S. Roy. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "feature-based ranking": {
            "translated_key": "ranking basado en características",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Beyond PageRank: Machine Learning for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We show that we can significantly outperform PageRank using features that are independent of the link structure of the Web.",
                "We gain a further boost in accuracy by using data on the frequency at which users visit Web pages.",
                "We use RankNet, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random).",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning.",
                "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval.",
                "General Terms Algorithms, Measurement, Performance, Experimentation. 1.",
                "INTRODUCTION Over the past decade, the Web has grown exponentially in size.",
                "Unfortunately, this growth has not been isolated to good-quality pages.",
                "The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly.",
                "The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information.",
                "Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first.",
                "To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking).",
                "However, having a good query-independent ranking (static ranking) is also crucially important for a search engine.",
                "A good static ranking algorithm provides numerous benefits: • Relevance: The static rank of a page provides a general indicator to the overall quality of the page.",
                "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by static rank.",
                "By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found.",
                "The more accurate the static rank, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages.",
                "Among other factors, the static rank of a page is used to determine this prioritization.",
                "A better static rank thus provides the engine with a higher quality, more upto-date index.",
                "Google is often regarded as the first commercially successful search engine.",
                "Their ranking was originally based on the PageRank algorithm [5][27].",
                "Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the static ranking of Web pages.",
                "Though PageRank has historically been thought to perform quite well, there has yet been little academic evidence to support this claim.",
                "Even worse, there has recently been work showing that PageRank may not perform any better than other simple measures on certain tasks.",
                "Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than PageRank [32].",
                "They found similar results for the task of finding high quality companies [31].",
                "PageRank has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17].",
                "Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as PageRank.",
                "Despite these, the general belief remains among many, both academic and in the public, that PageRank is an essential factor for a good static rank.",
                "Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text.",
                "In this paper, we show there are a number of simple url- or pagebased features that significantly outperform PageRank (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web.",
                "We combine these and other static features using machine learning to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels).",
                "A machine learning approach for static ranking has other advantages besides the quality of the ranking.",
                "Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages static rank to an undeserved level through questionable techniques, also known as Web spamming).",
                "This is particularly true if the feature set is not known.",
                "In contrast, a single measure like PageRank can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page.",
                "With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank.",
                "This flexibility allows a ranking system to rapidly react to new spamming techniques.",
                "A machine learning approach to static ranking is also able to take advantage of any advances in the machine learning field.",
                "For example, recent work on adversarial classification [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
                "Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the static rank.",
                "By moving static ranking to a machine learning framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of machine learning.",
                "Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet.",
                "These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful.",
                "For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page.",
                "A machine learning approach thus allows rapid development of a good static algorithm in new domains.",
                "This papers contribution is a systematic study of static features, including PageRank, for the purposes of (statically) ranking Web pages.",
                "Previous studies on PageRank typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages).",
                "Also, the performance of PageRank and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering.",
                "In contrast, we explore the use of PageRank and other features for the direct task of statically ranking Web pages.",
                "We first briefly describe the PageRank algorithm.",
                "In Section 3 we introduce RankNet, the machine learning technique used to combine static features into a final ranking.",
                "Section 4 describes the static features.",
                "The heart of the paper is in Section 5, which presents our experiments and results.",
                "We conclude with a discussion of related and future work. 2.",
                "PAGERANK The basic idea behind PageRank is simple: a link from a Web page to another can be seen as an endorsement of that page.",
                "In general, links are made by people.",
                "As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality.",
                "We can take advantage of this linkage information to order Web pages according to their perceived quality.",
                "Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step.",
                "In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links.",
                "If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j.",
                "The PageRank score for node j is defined as this probability: PR(j)=P(j).",
                "Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform).",
                "The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page.",
                "An alternative view for equation (1) is that each page is assigned a quality, P(j).",
                "A page gives an equal share of its quality to each page it points to.",
                "PageRank is computationally expensive.",
                "Our collection of 5 billion pages contains approximately 370 billion links.",
                "Computing PageRank requires iterating over these billions of links multiple times (until convergence).",
                "It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them.",
                "Though much work has been done on optimizing the PageRank computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3.",
                "RANKNET Much work in machine learning has been done on the problems of classification and regression.",
                "Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi.",
                "The classification problem is to learn a function f that maps yi=f(xi), for all i.",
                "When yi is real-valued as well, this is called regression.",
                "Static ranking can be seen as a regression problem.",
                "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a regression function that mapped each pages features to their rank.",
                "However, this over-constrains the problem we wish to solve.",
                "All we really care about is the order of the pages, not the actual value assigned to them.",
                "Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them.",
                "For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j.",
                "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a regression function, the result of this process is a function (f) that maps feature vectors to real values.",
                "This function can still be applied anywhere that a regressionlearned function could be applied.",
                "The only difference is the technique used to learn the function.",
                "By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do regression techniques.",
                "We used RankNet [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function.",
                "RankNet is a straightforward modification to the standard neural network back-prop algorithm.",
                "As with back-prop, RankNet attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight.",
                "The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the RankNet cost function is based on the difference between a pair of network outputs.",
                "That is, for each pair of feature vectors <i,j> in the training set, RankNet computes the network outputs oi and oj.",
                "Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost.",
                "RankNet also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function).",
                "In this paper, we used a probability of one for all pairs.",
                "In the next section, we will discuss the features used in our feature vectors, xi. 4.",
                "FEATURES To apply RankNet (or other machine learning techniques) to the ranking problem, we needed to extract a set of features from each page.",
                "We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity).",
                "We also optionally used the PageRank of a page as a feature.",
                "Below, we describe each of these feature categories in more detail.",
                "PageRank We computed PageRank on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages).",
                "This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines.",
                "Because PageRank is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible.",
                "Most previous studies on PageRank used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed PageRank using the standard value of 0.85 for α.",
                "Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time.",
                "We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN.",
                "The data is aggregated into a count, for each Web page, of the number of users who viewed that page.",
                "Though popularity data is generally unavailable, there are two other sources for it.",
                "The first is from proxy logs.",
                "For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus.",
                "Unfortunately, proxy data is quite biased and relatively small.",
                "Another source, internal to search engines, are records of which results their users clicked on.",
                "Such data was used by the search engine Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
                "An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search.",
                "The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed.",
                "More details are provided in section 5.5.",
                "Anchor text and inlinks These features are based on the information associated with links to the page in question.",
                "It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc.",
                "Page This category consists of features which may be determined by looking at the page (and its URL) alone.",
                "We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc.",
                "Domain This category contains features that are computed as averages across all pages in the domain.",
                "For example, the average number of outlinks on any page and the average PageRank.",
                "Many of these features have been used by others for ranking Web pages, particularly the anchor and page features.",
                "As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for static ranking.",
                "Also, to our knowledge, this is the first study on the use of actual page visitation popularity for static ranking.",
                "The closest similar work is on using click-through behavior (that is, which search engine results the users click on) to affect dynamic ranking (see e.g., [20]).",
                "Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for <br>feature-based ranking</br>). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages.",
                "Unless otherwise specified, fRank was trained with all of the features. 5.",
                "EXPERIMENTS In this section, we will demonstrate that we can out perform PageRank by applying machine learning to a straightforward set of features.",
                "Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a static ranking, we needed a gold standard defining the correct ordering for a set of pages.",
                "For this, we employed a dataset which contains human judgments for 28000 queries.",
                "For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges.",
                "The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent.",
                "There are approximately 500k judgments in all, or an average of 18 ratings per query.",
                "The queries are selected by randomly choosing queries from among those issued to the MSN search engine.",
                "The probability that a query is selected is proportional to its frequency among all 709 of the queries.",
                "As a result, common queries are more likely to be judged than uncommon queries.",
                "As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture.",
                "The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs search engine).",
                "This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query.",
                "Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries.",
                "This bias is good when evaluating the quality of static ranking for the purposes of index ordering and returning relevant documents.",
                "This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries.",
                "Because of this bias, however, the results in this paper are not applicable to crawl prioritization.",
                "In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages.",
                "To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query.",
                "The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high static rank.",
                "Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query.",
                "We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively.",
                "Each set contains all of the ratings for a given query, and no query appears in more than one set.",
                "The training set was used to train fRank.",
                "The validation set was used to select the model that had the highest performance.",
                "The test set was used for the final results.",
                "This data gives us a query-independent ordering of pages.",
                "The goal for a static ranking algorithm will be to reproduce this ordering as closely as possible.",
                "In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a static ranking.",
                "The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages.",
                "If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of relevance for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
                "First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score).",
                "Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the static rank algorithm orders them correctly. 5.3 Method We trained fRank (a RankNet based neural network) using the following parameters.",
                "We used a fully connected 2 layer network.",
                "The hidden layer had 10 hidden nodes.",
                "The input weights to this layer were all initialized to be zero.",
                "The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1].",
                "We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output.",
                "The cost function is the pairwise cross entropy cost function as discussed in section 3.",
                "The features in the training set were normalized to have zero mean and unit standard deviation.",
                "The same linear transformation was then applied to the features in the validation and test sets.",
                "For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other.",
                "The pairings were chosen uniformly at random (with replacement) from all possible pairings.",
                "When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs.",
                "Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread.",
                "We trained the network for 30 epochs.",
                "On each epoch, the training pairs were randomly shuffled.",
                "The initial training rate was 0.001.",
                "At each epoch, we checked the error on the training set.",
                "If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot.",
                "The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased.",
                "After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement).",
                "The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set.",
                "We report the pairwise accuracy on the test set, calculated using all possible pairs.",
                "These parameters were determined and fixed before the static rank experiments in this paper.",
                "In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7].",
                "Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them.",
                "The only exception was the popularity features.",
                "As with most Web phenomenon, we found that the distribution of site popularity is Zipfian.",
                "To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple machine learning methods such as naïve Bayes.",
                "In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the PageRank for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms PageRank for the purposes of static ranking.",
                "With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of PageRank (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages).",
                "Note that one of fRanks input features is the PageRank of the page, so we would expect it to perform no worse than PageRank.",
                "The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page.",
                "Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 PageRank 56.70 fRank 67.43 There are a number of decisions that go into the computation of PageRank, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc.",
                "We were able to obtain a computation of PageRank from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters.",
                "It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation.",
                "We thus concluded that the quality of the PageRank is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it.",
                "We also wanted to find how well each feature set performed.",
                "To answer this, for each feature set, we trained and tested fRank using only that set of features.",
                "The results are shown in Table 2.",
                "As can be seen, every single feature set individually outperformed PageRank on this test.",
                "Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets.",
                "This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page.",
                "This is contrary to the common belief that the Web graph structure is the key to finding a good static ranking of Web pages.",
                "Table 2: Results for individual feature sets.",
                "Feature Set Accuracy (%) PageRank 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways.",
                "This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features.",
                "To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study.",
                "That is, for each set of features, we trained a network to contain all of the features except that set.",
                "We then compared the performance of the resulting network to the performance of the network with all of the features.",
                "Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set.",
                "Table 3: Ablation study.",
                "Shown is the decrease in accuracy when we train a network that has all but the given set of features.",
                "The last line is shows the effect of removing the anchor, PageRank, and domain features, hence a model containing no network or link-based information whatsoever.",
                "Feature Set Decrease in Accuracy PageRank 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, PageRank & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study.",
                "Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set.",
                "Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless.",
                "Beginning with no features, we greedily added the feature set that improved performance the most.",
                "The results are shown in Table 4.",
                "For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%.",
                "Table 4: fRank performance as feature sets are added.",
                "At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets).",
                "Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +PageRank 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of PageRank vs. fRank.",
                "In Table 5 are the top ten URLs returned for PageRank and for fRank.",
                "PageRanks results are heavily weighted towards technology sites.",
                "It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc.",
                "PageRanks bias toward technology can be explained through two processes.",
                "First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime.",
                "These generally link back to, in these examples, the Internet Explorer and QuickTime download sites.",
                "Consequently, PageRank ranks those pages highly.",
                "Though these pages are important, they are not as important as it may seem by looking at the link structure alone.",
                "One fix for this is to add information about the link to the PageRank computation, such as the size of the text, whether it was at the bottom of the page, etc.",
                "The other bias comes from the fact that the population of Web site authors is different than the population of Web users.",
                "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual visitation popularity of a site (the popularity feature set), is able to eliminate some of that bias.",
                "It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked.",
                "The results confirm that fRank outperforms PageRank in pairwise accuracy.",
                "The two most important feature sets are the page and popularity features.",
                "This is surprising, as the page features consisted only of a few (8) simple features.",
                "Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best.",
                "In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users.",
                "For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user.",
                "This limited the possible features we could derive from this data.",
                "For possible extensions, see section 6.3, future work.",
                "For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user.",
                "However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
                "One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user.",
                "Adding this feature dramatically improved the performance of fRank.",
                "We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain.",
                "We did this by using the set of features shown in Table 6.",
                "Table 6: URL functions used to compute the Popularity feature set.",
                "Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table.",
                "The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question.",
                "For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html.",
                "As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further.",
                "Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data.",
                "It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected.",
                "In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set.",
                "Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank.",
                "The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy.",
                "In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy.",
                "Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions.",
                "First, fRank performs significantly better than PageRank, even without any information about the Web graph.",
                "Second, the page level and popularity features were the most significant contributors to pairwise accuracy.",
                "Third, by collecting more popularity data, we can continue to improve fRanks performance.",
                "The popularity data provides two benefits to fRank.",
                "First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer.",
                "Second, the popularity data is more timely than PageRanks link information.",
                "The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6.",
                "RELATED AND FUTURE WORK 6.1 Improvements to PageRank Since the original PageRank paper, there has been work on improving it.",
                "Much of that work centers on speeding up and parallelizing the computation [15][25].",
                "One recognized problem with PageRank is that of topic drift: A page about dogs will have high PageRank if it is linked to by many pages that themselves have high rank, regardless of their topic.",
                "In contrast, a search engine user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs.",
                "Hence, a link that is on topic should have higher weight than a link that is not.",
                "Richardson and Domingoss Query Dependent PageRank [29] and Haveliwalas Topic-Sensitive PageRank [16] are two approaches that tackle this problem.",
                "Other variations to PageRank include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3].",
                "See Langville and Meyer [23] for a good survey of these, and other modifications to PageRank. 6.2 Other related work PageRank is not the only link analysis algorithm used for ranking Web pages.",
                "The most well-known other is HITS [22], which is used by the Teoma search engine [30].",
                "HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs.",
                "Previous work has shown HITS to perform comparably to PageRank [1].",
                "One field of interest is that of static index pruning (see e.g., Carmel et al. [8]).",
                "Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query.",
                "The pruning is typically done based on the frequency of query terms.",
                "Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search.",
                "Similar methods could be incorporated into the static rank (e.g., how many frequent queries contain words found on this page).",
                "Others have investigated the effect that PageRank has on the Web at large [9].",
                "They argue that pages with high PageRank are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher PageRank than other pages.",
                "The same may occur for the popularity data.",
                "If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity.",
                "Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure.",
                "The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity.",
                "One interesting related work is that of Ivory and Hearst [19].",
                "Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience.",
                "They used over 100 page level features, as well as features encompassing the performance and structure of the site.",
                "This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features.",
                "The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set.",
                "Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future.",
                "Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which search engine results are clicked on.",
                "Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking.",
                "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall relevance of a search engine (i.e., the dynamic ranking).",
                "They do not apply their techniques to the problem of static ranking. 6.3 Future work There are many ways in which we would like to extend this work.",
                "First, fRank uses only a small number of features.",
                "We believe we could achieve even more significant results with more features.",
                "In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page).",
                "Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc.",
                "Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables.",
                "For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features.",
                "The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents.",
                "In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair.",
                "For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2.",
                "The experiments in this paper are biased toward pages that have higher than average quality.",
                "Also, fRank with all of the features can only be applied to pages that have already been crawled.",
                "Thus, fRank is primarily useful for index ordering and improving relevance, not for directing the crawl.",
                "We would like to investigate a machine learning approach for crawl prioritization as well.",
                "It may be that a combination of methods is best: for example, using PageRank to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy.",
                "Another interesting direction for exploration is to incorporate fRank and page-level features directly into the PageRank computation itself.",
                "Work on biasing the PageRank jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach.",
                "There is reason to believe that a direct application of [29], using the fRank of a page for its relevance, could lead to an improved overall static rank.",
                "Finally, the popularity data can be used in other interesting ways.",
                "The general surfing and searching habits of Web users varies by time of day.",
                "Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively).",
                "We can gain insight into these differences by using the popularity data, divided into segments of the day.",
                "When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages.",
                "We also plan to explore popularity features that use more than just the counts of how often a page was visited.",
                "For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc.",
                "Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14].",
                "Finally, the popularity data could be used as the label rather than as a feature.",
                "Using fRank in this way to predict the popularity of a page may useful for the tasks of relevance, efficiency, and crawl priority.",
                "There is also significantly more popularity data than human labeled data, potentially enabling more complex machine learning methods, and significantly more features. 7.",
                "CONCLUSIONS A good static ranking is an important component for todays search engines and information retrieval systems.",
                "We have demonstrated that PageRank does not provide a very good static ranking; there are many simple features that individually out perform PageRank.",
                "By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than PageRank alone.",
                "A qualitative evaluation of the top documents shows that fRank is less technology-biased than PageRank; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit.",
                "The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as adversarial classification.",
                "We have only begun to explore the options, and believe that significant strides can be made in the area of static ranking by further experimentation with additional features, other machine learning techniques, and additional sources of data. 8.",
                "ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional PageRank computations and to Timo Burkard for assistance with the popularity data.",
                "Many thanks to Chris Burges for providing code and significant support in using training RankNets.",
                "Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of Web documents.",
                "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
                "PageRank as a function of the damping factor.",
                "In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims.",
                "A machine learning architecture for optimizing web search engines.",
                "In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998.",
                "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson.",
                "Efficient PageRank approximation via graph aggregation.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the 22nd International Conference on Machine Learning, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy.",
                "Impact of search engines on page popularity.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams.",
                "Page Quality: In search of an unbiased web ranking.",
                "In Proceedings of the ACM SIGMOD 2005 Conference.",
                "Baltimore, Maryland.",
                "June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proceedings of the 28th Annual Conference on Research and Development in Information Retrieval (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
                "Adversarial Classification.",
                "In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y.",
                "Singer.",
                "Log-linear models for label-ranking.",
                "In Advances in Neural Information Processing Systems 16.",
                "Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005).",
                "Evaluating implicit measures to improve the search experiences.",
                "In the ACM Transactions on Information Systems, 23(2), pp. 147-168.",
                "April 2005. [15]T. Haveliwala.",
                "Efficient computation of PageRank.",
                "Stanford University Technical Report, 1999. [16]T. Haveliwala.",
                "Topic-sensitive PageRank.",
                "In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell.",
                "Very large scale retrieval and Web search.",
                "In D. Harman and E. Voorhees (eds), The TREC Book.",
                "MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer.",
                "Support vector learning for ordinal regression.",
                "In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst.",
                "Statistical profiles of highly-rated Web sites.",
                "In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay.",
                "Accurately Interpreting Clickthrough Data as Implicit Feedback.",
                "In Proceedings of the Conference on Research and Development in Information Retrieval (SIGIR), 2005. [22]J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit.",
                "The effect of the back button in a random walk: application for PageRank.",
                "In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry.",
                "A uniform approach to accelerated PageRank computation.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide.",
                "Static approximation of dynamically generated Web pages.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston.",
                "User-centric Web crawling.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos.",
                "The intelligent surfer: probabilistic combination of link and content information in PageRank.",
                "In Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
                "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.",
                "Teoma vs. Google, Round 2.",
                "Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: PageRank or indegree?.",
                "In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking.",
                "Query-independent evidence in home page finding.",
                "In ACM Transactions on Information Systems. 2003. 715"
            ],
            "original_annotated_samples": [
                "Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for <br>feature-based ranking</br>). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages."
            ],
            "translated_annotated_samples": [
                "Debido a que utilizamos una amplia variedad de características para crear un ranking estático, nos referimos a esto como fRank (para <br>ranking basado en características</br>). fRank utiliza RankNet y el conjunto de características descritas en esta sección para aprender una función de ranking para páginas web."
            ],
            "translated_text": "Más allá de PageRank: Aprendizaje automático para la clasificación estática. Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un motor de búsqueda. Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización. Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. Google es frecuentemente considerado como el primer motor de búsqueda comercialmente exitoso. Su clasificación se basaba originalmente en el algoritmo PageRank [5][27]. Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la clasificación estática de páginas web. Aunque se ha pensado que PageRank ha tenido un buen rendimiento históricamente, todavía hay poca evidencia académica que respalde esta afirmación. Aún peor, recientemente se ha demostrado que PageRank puede no funcionar mejor que otras medidas simples en ciertas tareas. Upstill et al. han encontrado que para la tarea de encontrar páginas de inicio, el número de páginas que enlazan a una página y el tipo de URL fueron tan, o más, efectivos que PageRank [32]. Encontraron resultados similares para la tarea de encontrar empresas de alta calidad [31]. PageRank también se ha utilizado en sistemas para las grandes colecciones de TRECs y competencias de seguimiento web, pero con mucho menos éxito del esperado [17]. Finalmente, Amento et al. [1] encontraron que características simples, como el número de páginas en un sitio, tuvieron un rendimiento tan bueno como PageRank. A pesar de esto, la creencia general persiste entre muchos, tanto académicos como en el público, de que PageRank es un factor esencial para un buen rango estático. En caso de que esto falle, se asume que seguir utilizando la estructura de enlaces es crucial, ya sea en forma del número de enlaces entrantes o la cantidad de texto ancla. En este artículo, demostramos que existen una serie de características simples basadas en URL o en páginas que superan significativamente a PageRank (para el propósito de clasificar estáticamente páginas web) a pesar de ignorar la estructura de la web. Combinamos estas y otras características estáticas utilizando aprendizaje automático para lograr un sistema de clasificación que es significativamente mejor que PageRank (en acuerdo par a par con etiquetas humanas). Un enfoque de aprendizaje automático para la clasificación estática tiene otras ventajas además de la calidad de la clasificación. Debido a que la medida consta de muchas características, es más difícil para los usuarios malintencionados manipularla (es decir, elevar el rango estático de sus páginas a un nivel no merecido a través de técnicas cuestionables, también conocidas como spam en la web). Esto es especialmente cierto si el conjunto de características no se conoce. Por el contrario, una sola medida como PageRank puede ser más fácil de manipular porque los spammers solo necesitan concentrarse en un objetivo: cómo hacer que más páginas apunten a su página. Con un algoritmo que aprende, una característica que se vuelve inutilizable debido a la manipulación de spammers simplemente se reducirá o eliminará del cálculo final de rango. Esta flexibilidad permite que un sistema de clasificación reaccione rápidamente a nuevas técnicas de spam. Un enfoque de aprendizaje automático para la clasificación estática también puede aprovechar cualquier avance en el campo del aprendizaje automático. Por ejemplo, un trabajo reciente sobre clasificación adversarial [12] sugiere que puede ser posible modelar explícitamente las acciones de los spammers de páginas web (el adversario), ajustando el modelo de clasificación de antemano antes de que los spammers intenten evadirlo. Otro ejemplo es la eliminación de valores atípicos al construir el modelo, lo cual ayuda a reducir el efecto que los sitios únicos pueden tener en la calidad general de la clasificación estática. Al trasladar la clasificación estática a un marco de aprendizaje automático, no solo ganamos en precisión, sino también en la capacidad de reaccionar a las acciones de los spammers, de añadir rápidamente nuevas características al algoritmo de clasificación y de aprovechar los avances en el campo en rápido crecimiento del aprendizaje automático. Finalmente, creemos que habrá ventajas significativas al utilizar esta técnica para otros ámbitos, como la búsqueda en un disco duro local o en la intranet de una empresa. Estos son dominios donde la estructura de enlaces es particularmente débil (o inexistente), pero hay otras características específicas del dominio que podrían ser igual de poderosas. Por ejemplo, el autor de una página de intranet y su posición en la organización (por ejemplo, CEO, gerente o desarrollador) podrían proporcionar pistas significativas sobre la importancia de esa página. Un enfoque de aprendizaje automático permite el desarrollo rápido de un buen algoritmo estático en nuevos dominios. La contribución de este artículo es un estudio sistemático de las características estáticas, incluido PageRank, con el propósito de clasificar páginas web de forma estática. Estudios previos sobre PageRank típicamente utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Además, el rendimiento de PageRank y otras características estáticas suele evaluarse en el contexto de un sistema completo para la clasificación dinámica, o para otras tareas como la respuesta a preguntas. Por el contrario, exploramos el uso de PageRank y otras características para la tarea directa de clasificar estáticamente las páginas web. Primero describimos brevemente el algoritmo PageRank. En la Sección 3 presentamos RankNet, la técnica de aprendizaje automático utilizada para combinar las características estáticas en un ranking final. La sección 4 describe las características estáticas. El corazón del documento está en la Sección 5, la cual presenta nuestros experimentos y resultados. Concluimos con una discusión sobre el trabajo relacionado y futuro. 2. PAGERANK La idea básica detrás de PageRank es simple: un enlace de una página web a otra puede ser visto como un respaldo de esa página. En general, los enlaces son creados por personas. Por lo tanto, son indicativos de la calidad de las páginas a las que apuntan: al crear una página, un autor presumiblemente elige enlazar a páginas consideradas de buena calidad. Podemos aprovechar esta información de enlace para ordenar las páginas web según su calidad percibida. Imagina a un internauta que salta de página web en página web, eligiendo con probabilidad uniforme qué enlace seguir en cada paso. Para reducir el efecto de los callejones sin salida o ciclos interminables, el surfista saltará ocasionalmente a una página aleatoria con una pequeña probabilidad α, o cuando se encuentre en una página sin enlaces de salida. Si se promedia sobre un número suficiente de pasos, la probabilidad de que el surfista esté en la página j en algún momento en el tiempo está dada por la fórmula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Donde Fi es el conjunto de páginas a las que enlaza la página i, y Bj es el conjunto de páginas que enlazan a la página j. El puntaje de PageRank para el nodo j se define como esta probabilidad: PR(j)=P(j). Dado que la ecuación (1) es recursiva, debe evaluarse de forma iterativa hasta que P(j) converja (normalmente, la distribución inicial para P(j) es uniforme). La intuición es que, dado que un navegante aleatorio llegaría a la página con más frecuencia, es probable que sea una página mejor. Una vista alternativa para la ecuación (1) es que a cada página se le asigna una calidad, P(j). Una página otorga una parte igual de su calidad a cada página a la que apunta. PageRank es computacionalmente costoso. Nuestra colección de 5 mil millones de páginas contiene aproximadamente 370 mil millones de enlaces. Calcular el PageRank requiere iterar sobre miles de millones de enlaces varias veces (hasta converger). Requiere grandes cantidades de memoria (o esquemas de almacenamiento en caché muy inteligentes que ralentizan aún más el cálculo), y si se distribuye en múltiples máquinas, requiere una comunicación significativa entre ellas. Aunque se ha realizado mucho trabajo en la optimización del cálculo del PageRank (ver, por ejemplo, [25] y [6]), sigue siendo una propiedad relativamente lenta y costosa computacionalmente de calcular. 3. RANKNET Se ha realizado mucho trabajo en aprendizaje automático en los problemas de clasificación y regresión. Sea X={xi} una colección de vectores de características (típicamente, una característica es cualquier número real), y Y={yi} una colección de clases asociadas, donde yi es la clase del objeto descrito por el vector de características xi. El problema de clasificación consiste en aprender una función f que mapea yi=f(xi), para todo i. Cuando yi también es un valor real, esto se llama regresión. La clasificación estática se puede ver como un problema de regresión. Si dejamos que xi represente las características de la página i, y yi sea un valor (por ejemplo, el rango) para cada página, podríamos aprender una función de regresión que mapeara las características de cada página a su rango. Sin embargo, esto sobrecarga el problema que deseamos resolver. Todo lo que realmente nos importa es el orden de las páginas, no el valor real asignado a ellas. El trabajo reciente sobre este problema de clasificación [7][13][18] intenta directamente optimizar el orden de los objetos, en lugar del valor asignado a ellos. Para esto, sea Z={<i,j>} una colección de pares de elementos, donde el elemento i debe ser asignado un valor más alto que el elemento j. El objetivo del problema de clasificación, entonces, es aprender una función f tal que, )()(,, ji ffji xxZ >∈∀ 708. Nótese que, al igual que al aprender una función de regresión, el resultado de este proceso es una función (f) que mapea vectores de características a valores reales. Esta función todavía se puede aplicar en cualquier lugar donde se pueda aplicar una función aprendida por regresión. La única diferencia es la técnica utilizada para aprender la función. Al optimizar directamente el orden de los objetos, estos métodos pueden aprender una función que clasifica mejor que las técnicas de regresión. Utilizamos RankNet [7], una de las técnicas mencionadas para aprender funciones de clasificación, para aprender nuestra función de clasificación estática. RankNet es una modificación sencilla del algoritmo de retropropagación de la red neuronal estándar. Al igual que con back-prop, RankNet intenta minimizar el valor de una función de costo ajustando cada peso en la red de acuerdo con el gradiente de la función de costo con respecto a ese peso. La diferencia es que, mientras que una función de costo típica de una red neuronal se basa en la diferencia entre la salida de la red y la salida deseada, la función de costo de RankNet se basa en la diferencia entre un par de salidas de la red. Es decir, para cada par de vectores de características <i,j> en el conjunto de entrenamiento, RankNet calcula las salidas de la red oi y oj. Dado que se supone que el vector i está clasificado más alto que el vector j, cuanto mayor sea oj-oi, mayor será el costo. RankNet también permite que los pares en Z sean ponderados con una confianza (expresada como la probabilidad de que el par cumpla con el ordenamiento inducido por la función de clasificación). En este documento, utilizamos una probabilidad de uno para todos los pares. En la siguiente sección, discutiremos las características utilizadas en nuestros vectores de características, xi. 4. Para aplicar RankNet (u otras técnicas de aprendizaje automático) al problema de clasificación, necesitábamos extraer un conjunto de características de cada página. Dividimos nuestro conjunto de características en cuatro categorías mutuamente excluyentes: a nivel de página (Página), a nivel de dominio (Dominio), texto del enlace y enlaces entrantes (Anclaje) y popularidad (Popularidad). También opcionalmente utilizamos el PageRank de una página como una característica. A continuación, describimos cada una de estas categorías de características con más detalle. Calculamos PageRank en un grafo web de 5 mil millones de páginas rastreadas (y 20 mil millones de URLs conocidas enlazadas por estas páginas). Esto representa una parte significativa de la Web, y es aproximadamente la misma cantidad de páginas que utilizan Google, Yahoo y MSN para sus motores de búsqueda. Dado que PageRank es un algoritmo basado en grafos, es importante que se ejecute en la mayor cantidad posible de subconjuntos de la Web. La mayoría de los estudios previos sobre PageRank utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Calculamos PageRank utilizando el valor estándar de 0.85 para α. Otra característica que utilizamos es la popularidad real de una página web, medida como el número de veces que ha sido visitada por usuarios durante algún período de tiempo. Tenemos acceso a esos datos de usuarios que han instalado la barra de herramientas de MSN y han optado por proporcionarlos a MSN. Los datos se agregan en un recuento, para cada página web, del número de usuarios que vieron esa página. Aunque los datos de popularidad generalmente no están disponibles, hay otras dos fuentes para obtenerlos. El primero es de los registros de proxy. Por ejemplo, una universidad que requiere que sus estudiantes utilicen un proxy tiene un registro de todas las páginas que han visitado mientras están en el campus. Desafortunadamente, los datos de proxy son bastante sesgados y relativamente pequeños. Otra fuente, interna de los motores de búsqueda, son los registros de los resultados en los que hicieron clic sus usuarios. Tales datos fueron utilizados por el motor de búsqueda Direct Hit, y recientemente han sido explorados con fines de clasificación dinámica [20]. Una ventaja de los datos de la barra de herramientas sobre esto es que contiene información sobre las visitas a URL que no son solo el resultado de una búsqueda. La popularidad en bruto se procesa en una serie de características como el número de veces que se visualizó una página y el número de veces que se visualizó cualquier página en el dominio. Se proporcionan más detalles en la sección 5.5. Texto de anclaje e inlinks. Estas características se basan en la información asociada con los enlaces a la página en cuestión. Incluye características como la cantidad total de texto en los enlaces que apuntan a la página (texto de anclaje), el número de palabras únicas en ese texto, etc. Esta categoría consiste en características que pueden ser determinadas solo al observar la página (y su URL). Solo utilizamos ocho características simples como el número de palabras en el cuerpo, la frecuencia del término más común, etc. Este categoría contiene características que se calculan como promedios en todas las páginas del dominio. Por ejemplo, el número promedio de enlaces salientes en cualquier página y el PageRank promedio. Muchas de estas características han sido utilizadas por otros para clasificar páginas web, especialmente las características de anclaje y de la página. Como se mencionó, la evaluación suele ser para clasificación dinámica, y deseamos evaluar su uso para clasificación estática. Además, hasta donde sabemos, este es el primer estudio sobre el uso de la popularidad real de visitas a páginas para la clasificación estática. El trabajo similar más cercano se centra en el uso del comportamiento de clics (es decir, en los resultados de búsqueda en los que los usuarios hacen clic) para afectar la clasificación dinámica (ver, por ejemplo, [20]). Debido a que utilizamos una amplia variedad de características para crear un ranking estático, nos referimos a esto como fRank (para <br>ranking basado en características</br>). fRank utiliza RankNet y el conjunto de características descritas en esta sección para aprender una función de ranking para páginas web. A menos que se especifique lo contrario, fRank fue entrenado con todas las características. 5. EXPERIMENTOS En esta sección, demostraremos que podemos superar a PageRank aplicando aprendizaje automático a un conjunto sencillo de características. Antes de los resultados, primero discutimos los datos, la métrica de rendimiento y el método de entrenamiento. 5.1 Datos Para evaluar la calidad de un ranking estático, necesitábamos un estándar de oro que definiera el orden correcto para un conjunto de páginas. Para esto, empleamos un conjunto de datos que contiene juicios humanos para 28000 consultas. Para cada consulta, un número de resultados son asignados manualmente una calificación, de 0 a 4, por jueces humanos. La calificación está destinada a ser una medida de cuán relevante es el resultado para la consulta, donde 0 significa pobre y 4 significa excelente. Hay aproximadamente 500 mil juicios en total, o un promedio de 18 calificaciones por consulta. Las consultas se seleccionan eligiendo aleatoriamente consultas de entre aquellas emitidas al motor de búsqueda de MSN. La probabilidad de que se seleccione una consulta es proporcional a su frecuencia entre las 709 consultas. Como resultado, es más probable que las consultas comunes sean evaluadas que las consultas poco comunes. Como ejemplo de la diversidad de las consultas, las primeras cuatro consultas en el conjunto de entrenamiento son escuelas de chef, el autódromo de Chicagoland, el club de fans de los Eagles y la cultura turca. Los documentos seleccionados para evaluar son aquellos que esperábamos que, en promedio, fueran razonablemente relevantes (por ejemplo, los diez documentos principales devueltos por el motor de búsqueda de MSN). Esto proporciona significativamente más información que seleccionar documentos al azar en la web, la gran mayoría de los cuales serían irrelevantes para una consulta específica. Debido a este proceso, las páginas evaluadas tienden a ser de mayor calidad que la página promedio en la web, y suelen ser páginas que se devolverán en consultas de búsqueda comunes. Este sesgo es útil al evaluar la calidad de la clasificación estática con el fin de ordenar índices y devolver documentos relevantes. Esto se debe a que la parte más importante del índice que debe estar bien ordenada y ser relevante es la parte que se devuelve con frecuencia para las consultas de búsqueda. Debido a este sesgo, sin embargo, los resultados en este documento no son aplicables a la priorización de rastreo. Para obtener resultados experimentales sobre la priorización de rastreo, necesitaríamos calificaciones de una muestra aleatoria de páginas web. Para convertir los datos de dependientes de la consulta a independientes de la consulta, simplemente eliminamos la consulta, tomando el máximo sobre las evaluaciones para una URL que aparece en más de una consulta. El razonamiento detrás de esto es que una página que es relevante para una consulta y no relevante para otra probablemente sea una buena página y debería tener un alto rango estático. Debido a que evaluamos las páginas en consultas que ocurren con frecuencia, nuestros datos indican el orden correcto del índice y asignan un alto valor a las páginas que probablemente sean relevantes para una consulta común. Asignamos consultas al azar a un conjunto de entrenamiento, validación o prueba, de modo que contuvieran el 84%, 8% y 8% de las consultas, respectivamente. Cada conjunto contiene todas las calificaciones para una consulta dada, y ninguna consulta aparece en más de un conjunto. El conjunto de entrenamiento se utilizó para entrenar fRank. El conjunto de validación se utilizó para seleccionar el modelo que tuvo el mejor rendimiento. El conjunto de pruebas se utilizó para los resultados finales. Estos datos nos proporcionan un ordenamiento de páginas independiente de la consulta. El objetivo de un algoritmo de clasificación estática será reproducir este orden lo más fielmente posible. En la siguiente sección, describimos la medida que utilizamos para evaluar esto. 5.2 Medida Elegimos utilizar la precisión por pares para evaluar la calidad de un ranking estático. La precisión por pares es la fracción de tiempo en la que el algoritmo de clasificación y los jueces humanos están de acuerdo en el ordenamiento de un par de páginas web. Si S(x) es la clasificación estática asignada a la página x, y H(x) es el juicio humano de relevancia para x, entonces considera los siguientes conjuntos: )}()(:,{ yHxHyx >=pH y )}()(:,{ ySxSyx >=pS La precisión por pares es la porción de Hp que también está contenida en Sp: p pp H SH ∩ =precisiónpares Esta medida fue elegida por dos razones. Primero, los juicios humanos discretos proporcionan solo un orden parcial sobre las páginas web, lo que dificulta aplicar una medida como el coeficiente de correlación de orden de rango de Spearman (en la medida de precisión por pares, un par de documentos con el mismo juicio humano no afecta la puntuación). Segundo, la precisión por pares tiene un significado intuitivo: es la fracción de pares de documentos que, cuando los humanos afirman que uno es mejor que el otro, el algoritmo de clasificación estática los ordena correctamente. 5.3 Método Entrenamos fRank (una red neuronal basada en RankNet) utilizando los siguientes parámetros. Utilizamos una red de 2 capas completamente conectadas. La capa oculta tenía 10 nodos ocultos. Los pesos de entrada a esta capa se inicializaron todos en cero. Los pesos de la capa de salida (solo un nodo) se inicializaron utilizando una distribución aleatoria uniforme en el rango [-0.1, 0.1]. Utilizamos la función tangente hiperbólica (tanh) como función de transferencia de las entradas a la capa oculta, y una función lineal de la capa oculta a la salida. La función de costo es la función de costo de entropía cruzada por pares discutida en la sección 3. Las características en el conjunto de entrenamiento fueron normalizadas para tener media cero y desviación estándar unitaria. La misma transformación lineal fue luego aplicada a las características en los conjuntos de validación y prueba. Para el entrenamiento, presentamos a la red neuronal 5 millones de pares de páginas, donde una página tenía una calificación más alta que la otra. Las combinaciones fueron elegidas de forma uniforme al azar (con reemplazo) de todas las combinaciones posibles. Al formar las parejas, ignoramos la magnitud de la diferencia entre las calificaciones (la dispersión de calificaciones) de las dos URL. Por lo tanto, el peso para cada par era constante (uno), y la probabilidad de que se seleccionara un par era independiente de la diferencia de calificación. Entrenamos la red durante 30 épocas. En cada época, los pares de entrenamiento fueron mezclados aleatoriamente. La tasa de entrenamiento inicial fue de 0.001. En cada época, verificamos el error en el conjunto de entrenamiento. Si el error hubiera aumentado, entonces disminuimos la tasa de entrenamiento, bajo la hipótesis de que la red probablemente se había excedido. La tasa de entrenamiento en cada época se estableció de la siguiente manera: Tasa de entrenamiento = 1+ε κ Donde κ es la tasa inicial (0.001), y ε es el número de veces que el error del conjunto de entrenamiento ha aumentado. Después de cada época, medimos el rendimiento de la red neuronal en el conjunto de validación, utilizando 1 millón de pares (elegidos al azar con reemplazo). La red con la mayor precisión en pares en el conjunto de validación fue seleccionada, y luego probada en el conjunto de pruebas. Informamos la precisión por pares en el conjunto de pruebas, calculada utilizando todos los pares posibles. Estos parámetros fueron determinados y fijados antes de los experimentos de clasificación estática en este artículo. En particular, la elección de la tasa de entrenamiento inicial, el número de épocas y la función de decaimiento de la tasa de entrenamiento se tomaron directamente de Burges et al [7]. Aunque teníamos la opción de preprocesar cualquiera de las características antes de introducirlas en la red neuronal, nos abstuvimos de hacerlo en la mayoría de ellas. La única excepción fueron las características de popularidad. Como ocurre con la mayoría de los fenómenos web, descubrimos que la distribución de la popularidad de los sitios es Zipfiana. Para reducir el rango dinámico, y con suerte hacer que la característica sea más útil, presentamos a la red tanto las características de popularidad sin procesar, como el logaritmo de las mismas (Al igual que con las demás, los valores de las características logarítmicas también se normalizaron para tener media cero y desviación estándar unitaria). Aplicar fRank a un documento es computacionalmente eficiente, tomando un tiempo que es solo lineal en el número de características de entrada; por lo tanto, está dentro de un factor constante de otros métodos de aprendizaje automático simples como el Bayes ingenuo. En nuestros experimentos, calcular el fRank para las cinco mil millones de páginas web fue aproximadamente 100 veces más rápido que calcular el PageRank para el mismo conjunto. 5.4 Resultados Como muestra la Tabla 1, el fRank supera significativamente al PageRank para los propósitos de clasificación estática. Con una precisión de pares del 67.4%, fRank más que duplica la precisión de PageRank (en relación con la línea base del 50%, que es la precisión que se lograría con un orden aleatorio de páginas web). Ten en cuenta que una de las características de entrada de fRanks es el PageRank de la página, por lo que esperaríamos que su rendimiento no fuera peor que el de PageRank. El aumento significativo en precisión implica que las otras características (anclaje, popularidad, etc.) de hecho contienen información útil sobre la calidad general de una página. Tabla 1: Resultados Básicos Técnica Precisión (%) Ninguna (Línea base) 50.00 PageRank 56.70 fRank 67.43 Existen varias decisiones que intervienen en el cálculo de PageRank, como por ejemplo cómo tratar las páginas que no tienen enlaces salientes, la elección de α, la precisión numérica, el umbral de convergencia, etc. Pudimos obtener un cálculo de PageRank a partir de una implementación completamente independiente (proporcionada por Marc Najork) que variaba ligeramente en estos parámetros. Obtuvo una precisión de pares del 56.52%, casi idéntica a la obtenida por nuestra implementación. Por lo tanto, concluimos que la calidad del PageRank no es sensible a estas variaciones menores en el algoritmo, ni la baja precisión de los PageRanks se debió a problemas con nuestra implementación de él. También queríamos averiguar qué tan bien se desempeñaba cada conjunto de características. Para responder a esto, para cada conjunto de características, entrenamos y probamos fRank utilizando solo ese conjunto de características. Los resultados se muestran en la Tabla 2. Como se puede ver, cada conjunto de características individual superó a PageRank en esta prueba. Quizás el resultado más interesante es que las características a nivel de página tuvieron el mejor rendimiento de todos los conjuntos de características. Esto es sorprendente porque estas son características que no dependen de la estructura general del grafo de la Web, ni siquiera de qué páginas apuntan a una página dada. Esto va en contra de la creencia común de que la estructura del grafo web es la clave para encontrar una buena clasificación estática de las páginas web. Tabla 2: Resultados para conjuntos de características individuales. Debido a que estamos utilizando una red neuronal de dos capas, las características en la red aprendida pueden interactuar entre sí de maneras interesantes y no lineales. Esto significa que una característica particular que parece tener poco valor por sí sola podría ser muy importante cuando se utiliza en combinación con otras características. Para medir la contribución final de un conjunto de características, en el contexto de todas las demás características, realizamos un estudio de ablación. Es decir, para cada conjunto de características, entrenamos una red para contener todas las características excepto ese conjunto. Luego comparamos el rendimiento de la red resultante con el rendimiento de la red con todas las características. La Tabla 3 muestra los resultados de este experimento, donde la disminución en la precisión es la diferencia en la precisión por pares entre la red entrenada con todas las características y la red que carece del conjunto de características dado. Tabla 3: Estudio de ablación. Se muestra la disminución en precisión cuando entrenamos una red que tiene todas las características excepto el conjunto dado. La última línea muestra el efecto de eliminar las características del ancla, PageRank y dominio, por lo tanto, un modelo que no contiene ninguna información de red o basada en enlaces. Los resultados del estudio de ablación son consistentes con el estudio de conjunto de características individuales. Ambos muestran que el conjunto de características más importante es el conjunto de características a nivel de página, y el segundo más importante es el conjunto de características de popularidad. Finalmente, deseábamos ver cómo mejoraba el rendimiento de fRank a medida que añadíamos características; queríamos encontrar en qué punto añadir más conjuntos de características se volvía relativamente inútil. Comenzando sin características, añadimos ávidamente el conjunto de características que mejoró el rendimiento en mayor medida. Los resultados se muestran en la Tabla 4. Por ejemplo, la cuarta línea de la tabla muestra que fRank utilizando las características de página, popularidad y anclaje superó a cualquier red que utilizara la página, popularidad y algún otro conjunto de características, y que el rendimiento de esta red fue del 67.25%. Tabla 4: Rendimiento de fRank a medida que se agregan conjuntos de características. En cada fila, se añadió al conjunto de características aquella que proporcionó el mayor aumento en la precisión (es decir, realizamos una búsqueda ávida sobre conjuntos de características). Precisión del conjunto de características (%) Ninguna 50.00 +Página 63.93 +Popularidad 66.83 +Anclaje 67.25 +PageRank 67.31 +Dominio 67.43 711 Finalmente, presentamos una comparación cualitativa de PageRank vs. fRank. En la Tabla 5 se encuentran las diez URL principales devueltas para PageRank y para fRank. Los resultados de PageRank están fuertemente ponderados hacia sitios de tecnología. Contiene dos URL de QuickTime (software de reproducción de video de Apple), así como URL de Internet Explorer y FireFox (ambos navegadores web). Por otro lado, fRank contiene sitios más orientados al consumidor como American Express, Target, Dell, etc. El sesgo de PageRank hacia la tecnología puede explicarse a través de dos procesos. Primero, hay muchas páginas con botones en la parte inferior que sugieren que el sitio está optimizado para Internet Explorer, o que el visitante necesita QuickTime. Estos enlaces generalmente remiten, en estos ejemplos, a los sitios de descarga de Internet Explorer y QuickTime. Por consiguiente, PageRank clasifica esas páginas en posiciones altas. Aunque estas páginas son importantes, no son tan importantes como podría parecer al observar solo la estructura de enlaces. Una solución para esto es agregar información sobre el enlace al cálculo del PageRank, como el tamaño del texto, si estaba en la parte inferior de la página, etc. El otro sesgo proviene del hecho de que la población de autores de sitios web es diferente a la población de usuarios de la web. Los autores web tienden a estar orientados tecnológicamente, por lo que su comportamiento de enlace refleja esos intereses. fRank, al conocer la popularidad real de visitas de un sitio (el conjunto de características de popularidad), puede eliminar parte de ese sesgo. Tiene la capacidad de depender más de dónde visitan los usuarios reales de la Web que de dónde han enlazado los autores del sitio web. Los resultados confirman que fRank supera a PageRank en precisión por pares. Los dos conjuntos de características más importantes son las características de la página y de la popularidad. Esto es sorprendente, ya que las características de la página consistían solo en unas pocas (8) características simples. Experimentos adicionales encontraron que, de las características de la página, aquellas basadas en el texto de la página (en contraposición a la URL) tuvieron el mejor rendimiento. En la siguiente sección, exploramos la característica de popularidad con más detalle. 5.5 Datos de Popularidad Como se mencionó en la sección 4, nuestros datos de popularidad provienen de usuarios de la barra de herramientas de MSN. Por razones de privacidad, solo tuvimos acceso a un recuento agregado de cuántas veces fue visitada cada URL por cualquier usuario de la barra de herramientas. Esto limitó las características posibles que podríamos derivar de estos datos. Para posibles extensiones, consulte la sección 6.3, trabajo futuro. Para cada URL en nuestros conjuntos de entrenamiento y prueba, proporcionamos una característica a fRank que indicaba cuántas veces había sido visitada por un usuario de la barra de herramientas. Sin embargo, esta característica era bastante ruidosa y dispersa, especialmente para URL con parámetros de consulta (por ejemplo, http://search.msn.com/results.aspx?q=machine+learning&form=QBHP). Una solución fue proporcionar una característica adicional que era el número de veces que cualquier URL en el dominio dado fue visitada por un usuario de la barra de herramientas. La adición de esta característica mejoró drásticamente el rendimiento de fRank. Llevamos esto un paso más allá y utilizamos la estructura jerárquica incorporada de las URL para construir varios niveles de retroceso entre la URL completa y el dominio. Lo hicimos utilizando el conjunto de características mostradas en la Tabla 6. Tabla 6: Funciones de URL utilizadas para calcular el conjunto de características de Popularidad. Cada URL fue asignado una característica para cada función mostrada en la tabla. El valor de la característica era el recuento de la cantidad de veces que un usuario de la barra de herramientas visitó una URL, donde la función aplicada a esa URL coincide con la función aplicada a la URL en cuestión. Por ejemplo, la visita de un usuario a cnn.com/2005/sports.html incrementaría las características de Dominio y Dominio+1 para la URL cnn.com/2005/tech/wikipedia.html. Como se observa en la Tabla 7, agregar los recuentos de dominio mejoró significativamente la calidad de la característica de popularidad, y agregar las numerosas funciones de respaldo enumeradas en la Tabla 6 mejoró aún más la precisión. Tabla 7: Efecto de agregar retroceso a la característica de popularidad Conjunto de características Precisión (%) Recuento de URL 58.15 Recuento de URL y dominio 59.31 Todas las funciones de retroceso (Tabla 6) 60.82 Tabla 5: Diez mejores URL para PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Retroceder a subconjuntos de la URL es una técnica para tratar la escasez de datos. También es informativo ver cómo el rendimiento de fRank depende de la cantidad de datos de popularidad que hemos recopilado. En la Figura 1 mostramos el rendimiento de fRank entrenado solo con el conjunto de características de popularidad frente a la cantidad de datos que tenemos para el conjunto de características de popularidad. Cada día recibimos datos adicionales de popularidad, y como se puede ver en el gráfico, esto aumenta el rendimiento de fRank. La relación es logarítmica: duplicar la cantidad de datos de popularidad proporciona una mejora constante en la precisión de pares. En resumen, hemos encontrado que las características de popularidad proporcionan un impulso útil a la precisión general de fRank. Recopilando más datos de popularidad, así como empleando estrategias de retroceso simples, se mejora aún más este impulso. 5.6 Resumen de Resultados Los experimentos proporcionan varias conclusiones. Primero, fRank funciona significativamente mejor que PageRank, incluso sin tener información sobre el grafo web. En segundo lugar, las características a nivel de página y de popularidad fueron los contribuyentes más significativos a la precisión por pares. Tercero, al recopilar más datos de popularidad, podemos seguir mejorando el rendimiento de fRanks. Los datos de popularidad proporcionan dos beneficios a fRank. Primero, observamos que cualitativamente, el ordenamiento de fRanks de las páginas web tiene un sesgo más favorable que PageRanks. El ordenamiento de fRanks parece corresponder a lo que los usuarios de la web, en lugar de los autores de las páginas web, prefieren. Segundo, los datos de popularidad son más actuales que la información de enlaces de PageRank. La barra de herramientas proporciona información sobre qué páginas web encuentran interesantes las personas en este momento, mientras que los enlaces se agregan a las páginas más lentamente, a medida que los autores encuentran el tiempo y el interés. TRABAJO RELACIONADO Y FUTURO 6.1 Mejoras a PageRank Desde el artículo original de PageRank, ha habido trabajos para mejorarlo. Gran parte de ese trabajo se centra en acelerar y paralelizar el cálculo [15][25]. Un problema reconocido con PageRank es el de la deriva de temas: una página sobre perros tendrá un alto PageRank si está vinculada por muchas páginas que a su vez tienen un alto rango, independientemente de su tema. Por el contrario, un usuario de un motor de búsqueda que busca buenas páginas sobre perros probablemente preferiría encontrar páginas que son enlazadas por muchas páginas que tratan sobre perros. Por lo tanto, un enlace que esté relacionado con el tema debería tener más peso que un enlace que no lo esté. Richardson y el PageRank Dependiente de Consulta de Domingos [29] y el PageRank Sensible al Tema de Haveliwala [16] son dos enfoques que abordan este problema. Otras variaciones de PageRank incluyen ponderar de manera diferente los enlaces para enlaces inter e intra-dominio, agregar un paso hacia atrás al surfista aleatorio para simular el botón de retroceso en la mayoría de los navegadores [24] y modificar la probabilidad de salto (α) [3]. Consulte Langville y Meyer [23] para obtener una buena revisión de estas y otras modificaciones a PageRank. 6.2 Otros trabajos relacionados PageRank no es el único algoritmo de análisis de enlaces utilizado para clasificar páginas web. El otro más conocido es HITS [22], que es utilizado por el motor de búsqueda Teoma [30]. HITS produce una lista de hubs y autoridades, donde los hubs son páginas que apuntan a muchas páginas de autoridad, y las autoridades son páginas a las que apuntan muchos hubs. Trabajos anteriores han demostrado que HITS tiene un rendimiento comparable al de PageRank [1]. Un campo de interés es el de la poda de índices estáticos (ver, por ejemplo, Carmel et al. [8]). Los métodos de poda de índices estáticos reducen el tamaño del índice de los motores de búsqueda al eliminar documentos que es poco probable que sean devueltos por una consulta de búsqueda. La poda se realiza típicamente en función de la frecuencia de los términos de consulta. De manera similar, Pandey y Olston [28] sugieren rastrear las páginas con frecuencia si es probable que aparezcan incorrectamente (o no aparezcan) como resultado de una búsqueda. Métodos similares podrían ser incorporados en la clasificación estática (por ejemplo, cuántas consultas frecuentes contienen palabras encontradas en esta página). Otros han investigado el efecto que PageRank tiene en la Web en general [9]. Argumentan que las páginas con un alto PageRank son más propensas a ser encontradas por los usuarios de la web, por lo tanto, es más probable que sean enlazadas y, por ende, mantengan un PageRank más alto que otras páginas. Lo mismo puede ocurrir con los datos de popularidad. Si aumentamos la clasificación de las páginas populares, es más probable que se haga clic en ellas, lo que a su vez aumentará aún más su popularidad. Cho et al. [10] argumentan que una medida más apropiada de la calidad de una página web dependería no solo de la estructura de enlaces actual de la web, sino también de los cambios en esa estructura de enlaces. La misma técnica puede ser aplicable a los datos de popularidad: el cambio en la popularidad de una página puede ser más informativo que la popularidad absoluta. Un trabajo relacionado interesante es el de Ivory y Hearst [19]. Su objetivo era construir un modelo de sitios web que son considerados de alta calidad desde la perspectiva de contenido, estructura y navegación, diseño visual, funcionalidad, interactividad y experiencia general. Utilizaron más de 100 características a nivel de página, así como características que abarcan el rendimiento y la estructura del sitio. Esto les permitió describir cualitativamente las cualidades de una página que la hacen parecer atractiva (por ejemplo, el uso poco común de cursivas, al menos una fuente de 9 puntos, ...), y (en trabajos posteriores) construir un sistema que ayude a los autores de páginas web novedosas a crear páginas de calidad evaluándolas según estas características. Las principales diferencias entre este trabajo y el nuestro son el objetivo (descubrir qué constituye una buena página web vs. ordenar páginas web con fines de búsqueda en la web), el tamaño del estudio (utilizaron un conjunto de datos de menos de 6000 páginas vs. nuestro conjunto de 468,000), y nuestra comparación con PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Días de Datos de la Barra de Herramientas Precisión por Pares Figura 1: Relación entre la cantidad de datos de popularidad y el rendimiento del conjunto de características de popularidad. Ten en cuenta que el eje x es una escala logarítmica. Sin embargo, su trabajo proporciona ideas sobre características estáticas adicionales útiles que podríamos incorporar en fRank en el futuro. El trabajo reciente sobre la incorporación de características novedosas en la clasificación dinámica incluye el realizado por Joachims et al. [21], quienes investigan el uso de retroalimentación implícita de los usuarios, en forma de los resultados de búsqueda en el motor de búsqueda que se hacen clic. Craswell et al. [11] presentan un método para determinar la mejor transformación a aplicar a las características independientes de la consulta (como las utilizadas en este artículo) con el fin de mejorar la clasificación dinámica. Otros trabajos, como el de Boyan et al. [4] y Bartell et al. [2], aplican aprendizaje automático con el propósito de mejorar la relevancia general de un motor de búsqueda (es decir, el ranking dinámico). No aplican sus técnicas al problema de clasificación estática. 6.3 Trabajo futuro Hay muchas formas en las que nos gustaría ampliar este trabajo. Primero, Frank utiliza solo un pequeño número de características. Creemos que podríamos lograr resultados aún más significativos con más características. En particular, la existencia o falta de ciertas palabras podría resultar muy significativa (por ejemplo, \"en construcción\" probablemente signifique una página de baja calidad). Otras características podrían incluir el número de imágenes en una página, el tamaño de esas imágenes, el número de elementos de diseño (tablas, divs y spans), el uso de hojas de estilo, la conformidad con los estándares de W3C (como XHTML 1.0 Strict), el color de fondo de una página, etc. Muchas páginas se generan dinámicamente, cuyos contenidos pueden depender de parámetros en la URL, la hora del día, el usuario que visita el sitio, u otras variables. Para este tipo de páginas, puede ser útil aplicar las técnicas encontradas en [26] para formar una aproximación estática con el fin de extraer características. La gramática resultante que describe la página podría ser en sí misma una fuente de características adicionales que describen la complejidad de la página, como cuántos nodos no terminales tiene, la profundidad del árbol gramatical, etc. fRank permite especificar una confianza en cada emparejamiento de documentos. En el futuro, experimentaremos con probabilidades que dependen de la diferencia en los juicios humanos entre los dos elementos del par. Por ejemplo, un par de documentos donde uno fue calificado con un 4 y el otro con un 0 debería tener una mayor confianza que un par de documentos calificados con un 3 y un 2. Los experimentos en este artículo están sesgados hacia páginas que tienen una calidad superior al promedio. Además, fRank con todas las características solo se puede aplicar a páginas que ya han sido rastreadas. Por lo tanto, fRank es principalmente útil para el ordenamiento de índices y mejorar la relevancia, no para dirigir el rastreo. Nos gustaría investigar un enfoque de aprendizaje automático para la priorización de rastreo también. Puede ser que la mejor opción sea una combinación de métodos: por ejemplo, utilizar PageRank para seleccionar los mejores 5 mil millones de las 20 mil millones de páginas en la web, luego utilizar fRank para ordenar el índice y afectar la relevancia de la búsqueda. Otra dirección interesante para la exploración es incorporar las características de fRank y a nivel de página directamente en el cálculo de PageRank en sí mismo. El trabajo en el sesgo del vector de salto de PageRank [16] y la matriz de transición [29] ha demostrado la viabilidad y ventajas de este enfoque. Existe motivo para creer que una aplicación directa de [29], utilizando el fRank de una página para su relevancia, podría llevar a una mejora en el rango estático general. Finalmente, los datos de popularidad pueden ser utilizados de otras maneras interesantes. Los hábitos generales de navegación y búsqueda de los usuarios de la web varían según la hora del día. La actividad por la mañana, durante el día y en la tarde suele ser bastante diferente (por ejemplo, leer las noticias, resolver problemas y acceder al entretenimiento, respectivamente). Podemos obtener información sobre estas diferencias utilizando los datos de popularidad, divididos en segmentos del día. Cuando se emite una consulta, luego utilizaríamos los datos de popularidad que coincidan con el momento de la consulta para clasificar las páginas web. También planeamos explorar características de popularidad que utilicen más que solo el recuento de cuántas veces se visitó una página. Por ejemplo, cuánto tiempo los usuarios solían permanecer en una página, si abandonaron la página haciendo clic en un enlace o presionando el botón de retroceso, etc. Fox et al. realizaron un estudio que demostró que características como esta pueden ser valiosas para los propósitos de clasificación dinámica [14]. Finalmente, los datos de popularidad podrían ser utilizados como la etiqueta en lugar de como una característica. Utilizar fRank de esta manera para predecir la popularidad de una página puede ser útil para las tareas de relevancia, eficiencia y prioridad de rastreo. También hay significativamente más datos de popularidad que datos etiquetados por humanos, lo que potencialmente permite el uso de métodos de aprendizaje automático más complejos y muchas más características. 7. CONCLUSIONES Un buen ranking estático es un componente importante para los motores de búsqueda y sistemas de recuperación de información actuales. Hemos demostrado que PageRank no proporciona una clasificación estática muy buena; hay muchas características simples que superan individualmente a PageRank. Al combinar muchas características estáticas, fRank logra un ranking que tiene una precisión en pares significativamente mayor que PageRank solo. Una evaluación cualitativa de los documentos principales muestra que fRank está menos sesgado hacia la tecnología que PageRank; al utilizar datos de popularidad, está sesgado hacia las páginas que los usuarios de la web visitan, en lugar de hacia las páginas que los autores web crean. El componente de aprendizaje automático de fRank le otorga el beneficio adicional de ser más robusto contra los spammers, y le permite aprovechar los avances adicionales en la comunidad de aprendizaje automático en áreas como la clasificación adversarial. Hemos comenzado a explorar las opciones y creemos que se pueden lograr avances significativos en el área de clasificación estática mediante experimentación adicional con características adicionales, otras técnicas de aprendizaje automático y fuentes de datos adicionales. AGRADECIMIENTOS Gracias a Marc Najork por proporcionarnos cálculos adicionales de PageRank y a Timo Burkard por su ayuda con los datos de popularidad. Muchas gracias a Chris Burges por proporcionar código y un apoyo significativo en el uso del entrenamiento de RankNets. También agradecemos a Susan Dumais y Nick Craswell por sus ediciones y sugerencias. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2000. [2] B. Bartell, G. Cottrell y R. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la 17ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 1994. [3] P. Boldi, M. Santini y S. Vigna. PageRank como una función del factor de amortiguamiento. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. 714 [4] J. Boyan, D. Freitag y T. Joachims. Una arquitectura de aprendizaje automático para optimizar los motores de búsqueda web. En el taller de AAAI sobre Sistemas de Información Basados en Internet, agosto de 1996. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. En Actas de la Séptima Conferencia Internacional de la World Wide Web, Brisbane, Australia, 1998. Elsevier. [6] A. Broder, R. Lempel, F. Maghoul y J. Pederson. Aproximación eficiente de PageRank a través de la agregación de grafos. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, Bonn, Alemania, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 43-50, Nueva Orleans, Luisiana, EE. UU., septiembre de 2001. [9] J. Cho y S. Roy. Impacto de los motores de búsqueda en la popularidad de las páginas. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [10]J. Cho, S. Roy, R. Adams. Calidad de la página: En busca de una clasificación web imparcial. En las Actas de la Conferencia ACM SIGMOD 2005. Baltimore, Maryland. Junio de 2005. N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Anual sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), agosto de 2005. [12] N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma. Clasificación adversarial. En Actas de la Décima Conferencia Internacional sobre Descubrimiento de Conocimiento y Minería de Datos (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning y Y. Cantante. Modelos log-lineales para clasificación de etiquetas. En Avances en Sistemas de Procesamiento de Información Neural 16. Cambridge, MA: MIT Press, 2003. [14] S. Fox, K. S. Fox, K. Karnawat, M. Mydland, S. T. Dumais y T. White (2005). Evaluando medidas implícitas para mejorar las experiencias de búsqueda. En la revista ACM Transactions on Information Systems, 23(2), pp. 147-168. Abril de 2005. [15] T. Haveliwala. Cálculo eficiente de PageRank. Informe técnico de la Universidad de Stanford, 1999. [16] T. Haveliwala. PageRank sensible al tema. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2002. [17] D. Hawking y N. Craswell. Recuperación a gran escala y búsqueda en la web. En D. Harman y E. Voorhees (eds), El Libro de TREC. MIT Press. [18] R. Herbrich, T. Graepel y K. Obermayer. Aprendizaje de vectores de soporte para regresión ordinal. En Actas de la Novena Conferencia Internacional sobre Redes Neuronales Artificiales, pp. 97-102. 1999. [19] M. Ivory y M. Hearst. Perfiles estadísticos de sitios web altamente valorados. En Actas de la Conferencia ACM SIGCHI sobre Factores Humanos en Sistemas Informáticos, 2002. [20]T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de la Conferencia de la ACM sobre Descubrimiento de Conocimiento y Minería de Datos (KDD), 2002. [21] T. Joachims, L. Granka, B. Pang, H. Hembrooke y G. Gay. Interpretación precisa de los datos de clics como retroalimentación implícita. En Actas de la Conferencia sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2005. [22]J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM 46:5, pp. 604-32. 1999. [23]A. Langville y C. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet 1(3):335-380, 2004. [24] F. Matthieu y M. Bouklit. El efecto del botón de retroceso en un paseo aleatorio: aplicación para PageRank. En los trabajos y pósters de la pista alternativa de la Decimotercera Conferencia Internacional de la World Wide Web, 2004. [25]F. McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [26] Y. Minamide. Aproximación estática de páginas web generadas dinámicamente. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [27] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford, Stanford, CA, 1998. [28] S. Pandey y C. Olston. Rastreo web centrado en el usuario. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [29] M. Richardson y P. Domingos. El surfista inteligente: combinación probabilística de la información de enlaces y contenido en PageRank. En Advances in Neural Information Processing Systems 14, pp. 1441-1448. Cambridge, MA: MIT Press, 2002. [30]C. Sherman.\nCambridge, MA: MIT Press, 2002. [30]C. Sherman. Teoma vs. Google, Ronda 2. Disponible en World Wide Web (http://dc.internet.com/news/article.php/1002061), 2002. [31] T. Upstill, N. Craswell y D. Hawking. Prediciendo fama y fortuna: ¿PageRank o grado de entrada? En el Octavo Simposio de Computación de Documentos Australasiano. 2003. [32] T. Upstill, N. Craswell y D. Hawking. Evidencia independiente de la consulta en la búsqueda de la página de inicio. En ACM Transactions on Information Systems. 2003. 715 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "machine learning": {
            "translated_key": "aprendizaje automático",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Beyond PageRank: <br>machine learning</br> for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We show that we can significantly outperform PageRank using features that are independent of the link structure of the Web.",
                "We gain a further boost in accuracy by using data on the frequency at which users visit Web pages.",
                "We use RankNet, a ranking <br>machine learning</br> algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random).",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning.",
                "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval.",
                "General Terms Algorithms, Measurement, Performance, Experimentation. 1.",
                "INTRODUCTION Over the past decade, the Web has grown exponentially in size.",
                "Unfortunately, this growth has not been isolated to good-quality pages.",
                "The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly.",
                "The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information.",
                "Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first.",
                "To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking).",
                "However, having a good query-independent ranking (static ranking) is also crucially important for a search engine.",
                "A good static ranking algorithm provides numerous benefits: • Relevance: The static rank of a page provides a general indicator to the overall quality of the page.",
                "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by static rank.",
                "By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found.",
                "The more accurate the static rank, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages.",
                "Among other factors, the static rank of a page is used to determine this prioritization.",
                "A better static rank thus provides the engine with a higher quality, more upto-date index.",
                "Google is often regarded as the first commercially successful search engine.",
                "Their ranking was originally based on the PageRank algorithm [5][27].",
                "Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the static ranking of Web pages.",
                "Though PageRank has historically been thought to perform quite well, there has yet been little academic evidence to support this claim.",
                "Even worse, there has recently been work showing that PageRank may not perform any better than other simple measures on certain tasks.",
                "Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than PageRank [32].",
                "They found similar results for the task of finding high quality companies [31].",
                "PageRank has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17].",
                "Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as PageRank.",
                "Despite these, the general belief remains among many, both academic and in the public, that PageRank is an essential factor for a good static rank.",
                "Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text.",
                "In this paper, we show there are a number of simple url- or pagebased features that significantly outperform PageRank (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web.",
                "We combine these and other static features using <br>machine learning</br> to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels).",
                "A <br>machine learning</br> approach for static ranking has other advantages besides the quality of the ranking.",
                "Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages static rank to an undeserved level through questionable techniques, also known as Web spamming).",
                "This is particularly true if the feature set is not known.",
                "In contrast, a single measure like PageRank can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page.",
                "With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank.",
                "This flexibility allows a ranking system to rapidly react to new spamming techniques.",
                "A <br>machine learning</br> approach to static ranking is also able to take advantage of any advances in the <br>machine learning</br> field.",
                "For example, recent work on adversarial classification [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
                "Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the static rank.",
                "By moving static ranking to a <br>machine learning</br> framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of <br>machine learning</br>.",
                "Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet.",
                "These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful.",
                "For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page.",
                "A <br>machine learning</br> approach thus allows rapid development of a good static algorithm in new domains.",
                "This papers contribution is a systematic study of static features, including PageRank, for the purposes of (statically) ranking Web pages.",
                "Previous studies on PageRank typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages).",
                "Also, the performance of PageRank and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering.",
                "In contrast, we explore the use of PageRank and other features for the direct task of statically ranking Web pages.",
                "We first briefly describe the PageRank algorithm.",
                "In Section 3 we introduce RankNet, the <br>machine learning</br> technique used to combine static features into a final ranking.",
                "Section 4 describes the static features.",
                "The heart of the paper is in Section 5, which presents our experiments and results.",
                "We conclude with a discussion of related and future work. 2.",
                "PAGERANK The basic idea behind PageRank is simple: a link from a Web page to another can be seen as an endorsement of that page.",
                "In general, links are made by people.",
                "As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality.",
                "We can take advantage of this linkage information to order Web pages according to their perceived quality.",
                "Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step.",
                "In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links.",
                "If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j.",
                "The PageRank score for node j is defined as this probability: PR(j)=P(j).",
                "Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform).",
                "The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page.",
                "An alternative view for equation (1) is that each page is assigned a quality, P(j).",
                "A page gives an equal share of its quality to each page it points to.",
                "PageRank is computationally expensive.",
                "Our collection of 5 billion pages contains approximately 370 billion links.",
                "Computing PageRank requires iterating over these billions of links multiple times (until convergence).",
                "It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them.",
                "Though much work has been done on optimizing the PageRank computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3.",
                "RANKNET Much work in <br>machine learning</br> has been done on the problems of classification and regression.",
                "Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi.",
                "The classification problem is to learn a function f that maps yi=f(xi), for all i.",
                "When yi is real-valued as well, this is called regression.",
                "Static ranking can be seen as a regression problem.",
                "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a regression function that mapped each pages features to their rank.",
                "However, this over-constrains the problem we wish to solve.",
                "All we really care about is the order of the pages, not the actual value assigned to them.",
                "Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them.",
                "For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j.",
                "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a regression function, the result of this process is a function (f) that maps feature vectors to real values.",
                "This function can still be applied anywhere that a regressionlearned function could be applied.",
                "The only difference is the technique used to learn the function.",
                "By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do regression techniques.",
                "We used RankNet [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function.",
                "RankNet is a straightforward modification to the standard neural network back-prop algorithm.",
                "As with back-prop, RankNet attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight.",
                "The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the RankNet cost function is based on the difference between a pair of network outputs.",
                "That is, for each pair of feature vectors <i,j> in the training set, RankNet computes the network outputs oi and oj.",
                "Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost.",
                "RankNet also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function).",
                "In this paper, we used a probability of one for all pairs.",
                "In the next section, we will discuss the features used in our feature vectors, xi. 4.",
                "FEATURES To apply RankNet (or other <br>machine learning</br> techniques) to the ranking problem, we needed to extract a set of features from each page.",
                "We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity).",
                "We also optionally used the PageRank of a page as a feature.",
                "Below, we describe each of these feature categories in more detail.",
                "PageRank We computed PageRank on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages).",
                "This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines.",
                "Because PageRank is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible.",
                "Most previous studies on PageRank used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed PageRank using the standard value of 0.85 for α.",
                "Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time.",
                "We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN.",
                "The data is aggregated into a count, for each Web page, of the number of users who viewed that page.",
                "Though popularity data is generally unavailable, there are two other sources for it.",
                "The first is from proxy logs.",
                "For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus.",
                "Unfortunately, proxy data is quite biased and relatively small.",
                "Another source, internal to search engines, are records of which results their users clicked on.",
                "Such data was used by the search engine Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
                "An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search.",
                "The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed.",
                "More details are provided in section 5.5.",
                "Anchor text and inlinks These features are based on the information associated with links to the page in question.",
                "It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc.",
                "Page This category consists of features which may be determined by looking at the page (and its URL) alone.",
                "We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc.",
                "Domain This category contains features that are computed as averages across all pages in the domain.",
                "For example, the average number of outlinks on any page and the average PageRank.",
                "Many of these features have been used by others for ranking Web pages, particularly the anchor and page features.",
                "As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for static ranking.",
                "Also, to our knowledge, this is the first study on the use of actual page visitation popularity for static ranking.",
                "The closest similar work is on using click-through behavior (that is, which search engine results the users click on) to affect dynamic ranking (see e.g., [20]).",
                "Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for feature-based ranking). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages.",
                "Unless otherwise specified, fRank was trained with all of the features. 5.",
                "EXPERIMENTS In this section, we will demonstrate that we can out perform PageRank by applying <br>machine learning</br> to a straightforward set of features.",
                "Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a static ranking, we needed a gold standard defining the correct ordering for a set of pages.",
                "For this, we employed a dataset which contains human judgments for 28000 queries.",
                "For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges.",
                "The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent.",
                "There are approximately 500k judgments in all, or an average of 18 ratings per query.",
                "The queries are selected by randomly choosing queries from among those issued to the MSN search engine.",
                "The probability that a query is selected is proportional to its frequency among all 709 of the queries.",
                "As a result, common queries are more likely to be judged than uncommon queries.",
                "As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture.",
                "The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs search engine).",
                "This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query.",
                "Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries.",
                "This bias is good when evaluating the quality of static ranking for the purposes of index ordering and returning relevant documents.",
                "This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries.",
                "Because of this bias, however, the results in this paper are not applicable to crawl prioritization.",
                "In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages.",
                "To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query.",
                "The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high static rank.",
                "Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query.",
                "We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively.",
                "Each set contains all of the ratings for a given query, and no query appears in more than one set.",
                "The training set was used to train fRank.",
                "The validation set was used to select the model that had the highest performance.",
                "The test set was used for the final results.",
                "This data gives us a query-independent ordering of pages.",
                "The goal for a static ranking algorithm will be to reproduce this ordering as closely as possible.",
                "In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a static ranking.",
                "The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages.",
                "If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of relevance for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
                "First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score).",
                "Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the static rank algorithm orders them correctly. 5.3 Method We trained fRank (a RankNet based neural network) using the following parameters.",
                "We used a fully connected 2 layer network.",
                "The hidden layer had 10 hidden nodes.",
                "The input weights to this layer were all initialized to be zero.",
                "The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1].",
                "We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output.",
                "The cost function is the pairwise cross entropy cost function as discussed in section 3.",
                "The features in the training set were normalized to have zero mean and unit standard deviation.",
                "The same linear transformation was then applied to the features in the validation and test sets.",
                "For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other.",
                "The pairings were chosen uniformly at random (with replacement) from all possible pairings.",
                "When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs.",
                "Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread.",
                "We trained the network for 30 epochs.",
                "On each epoch, the training pairs were randomly shuffled.",
                "The initial training rate was 0.001.",
                "At each epoch, we checked the error on the training set.",
                "If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot.",
                "The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased.",
                "After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement).",
                "The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set.",
                "We report the pairwise accuracy on the test set, calculated using all possible pairs.",
                "These parameters were determined and fixed before the static rank experiments in this paper.",
                "In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7].",
                "Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them.",
                "The only exception was the popularity features.",
                "As with most Web phenomenon, we found that the distribution of site popularity is Zipfian.",
                "To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple <br>machine learning</br> methods such as naïve Bayes.",
                "In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the PageRank for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms PageRank for the purposes of static ranking.",
                "With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of PageRank (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages).",
                "Note that one of fRanks input features is the PageRank of the page, so we would expect it to perform no worse than PageRank.",
                "The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page.",
                "Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 PageRank 56.70 fRank 67.43 There are a number of decisions that go into the computation of PageRank, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc.",
                "We were able to obtain a computation of PageRank from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters.",
                "It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation.",
                "We thus concluded that the quality of the PageRank is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it.",
                "We also wanted to find how well each feature set performed.",
                "To answer this, for each feature set, we trained and tested fRank using only that set of features.",
                "The results are shown in Table 2.",
                "As can be seen, every single feature set individually outperformed PageRank on this test.",
                "Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets.",
                "This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page.",
                "This is contrary to the common belief that the Web graph structure is the key to finding a good static ranking of Web pages.",
                "Table 2: Results for individual feature sets.",
                "Feature Set Accuracy (%) PageRank 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways.",
                "This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features.",
                "To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study.",
                "That is, for each set of features, we trained a network to contain all of the features except that set.",
                "We then compared the performance of the resulting network to the performance of the network with all of the features.",
                "Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set.",
                "Table 3: Ablation study.",
                "Shown is the decrease in accuracy when we train a network that has all but the given set of features.",
                "The last line is shows the effect of removing the anchor, PageRank, and domain features, hence a model containing no network or link-based information whatsoever.",
                "Feature Set Decrease in Accuracy PageRank 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, PageRank & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study.",
                "Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set.",
                "Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless.",
                "Beginning with no features, we greedily added the feature set that improved performance the most.",
                "The results are shown in Table 4.",
                "For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%.",
                "Table 4: fRank performance as feature sets are added.",
                "At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets).",
                "Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +PageRank 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of PageRank vs. fRank.",
                "In Table 5 are the top ten URLs returned for PageRank and for fRank.",
                "PageRanks results are heavily weighted towards technology sites.",
                "It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc.",
                "PageRanks bias toward technology can be explained through two processes.",
                "First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime.",
                "These generally link back to, in these examples, the Internet Explorer and QuickTime download sites.",
                "Consequently, PageRank ranks those pages highly.",
                "Though these pages are important, they are not as important as it may seem by looking at the link structure alone.",
                "One fix for this is to add information about the link to the PageRank computation, such as the size of the text, whether it was at the bottom of the page, etc.",
                "The other bias comes from the fact that the population of Web site authors is different than the population of Web users.",
                "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual visitation popularity of a site (the popularity feature set), is able to eliminate some of that bias.",
                "It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked.",
                "The results confirm that fRank outperforms PageRank in pairwise accuracy.",
                "The two most important feature sets are the page and popularity features.",
                "This is surprising, as the page features consisted only of a few (8) simple features.",
                "Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best.",
                "In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users.",
                "For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user.",
                "This limited the possible features we could derive from this data.",
                "For possible extensions, see section 6.3, future work.",
                "For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user.",
                "However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
                "One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user.",
                "Adding this feature dramatically improved the performance of fRank.",
                "We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain.",
                "We did this by using the set of features shown in Table 6.",
                "Table 6: URL functions used to compute the Popularity feature set.",
                "Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table.",
                "The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question.",
                "For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html.",
                "As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further.",
                "Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data.",
                "It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected.",
                "In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set.",
                "Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank.",
                "The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy.",
                "In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy.",
                "Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions.",
                "First, fRank performs significantly better than PageRank, even without any information about the Web graph.",
                "Second, the page level and popularity features were the most significant contributors to pairwise accuracy.",
                "Third, by collecting more popularity data, we can continue to improve fRanks performance.",
                "The popularity data provides two benefits to fRank.",
                "First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer.",
                "Second, the popularity data is more timely than PageRanks link information.",
                "The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6.",
                "RELATED AND FUTURE WORK 6.1 Improvements to PageRank Since the original PageRank paper, there has been work on improving it.",
                "Much of that work centers on speeding up and parallelizing the computation [15][25].",
                "One recognized problem with PageRank is that of topic drift: A page about dogs will have high PageRank if it is linked to by many pages that themselves have high rank, regardless of their topic.",
                "In contrast, a search engine user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs.",
                "Hence, a link that is on topic should have higher weight than a link that is not.",
                "Richardson and Domingoss Query Dependent PageRank [29] and Haveliwalas Topic-Sensitive PageRank [16] are two approaches that tackle this problem.",
                "Other variations to PageRank include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3].",
                "See Langville and Meyer [23] for a good survey of these, and other modifications to PageRank. 6.2 Other related work PageRank is not the only link analysis algorithm used for ranking Web pages.",
                "The most well-known other is HITS [22], which is used by the Teoma search engine [30].",
                "HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs.",
                "Previous work has shown HITS to perform comparably to PageRank [1].",
                "One field of interest is that of static index pruning (see e.g., Carmel et al. [8]).",
                "Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query.",
                "The pruning is typically done based on the frequency of query terms.",
                "Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search.",
                "Similar methods could be incorporated into the static rank (e.g., how many frequent queries contain words found on this page).",
                "Others have investigated the effect that PageRank has on the Web at large [9].",
                "They argue that pages with high PageRank are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher PageRank than other pages.",
                "The same may occur for the popularity data.",
                "If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity.",
                "Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure.",
                "The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity.",
                "One interesting related work is that of Ivory and Hearst [19].",
                "Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience.",
                "They used over 100 page level features, as well as features encompassing the performance and structure of the site.",
                "This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features.",
                "The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set.",
                "Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future.",
                "Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which search engine results are clicked on.",
                "Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking.",
                "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply <br>machine learning</br> for the purposes of improving the overall relevance of a search engine (i.e., the dynamic ranking).",
                "They do not apply their techniques to the problem of static ranking. 6.3 Future work There are many ways in which we would like to extend this work.",
                "First, fRank uses only a small number of features.",
                "We believe we could achieve even more significant results with more features.",
                "In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page).",
                "Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc.",
                "Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables.",
                "For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features.",
                "The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents.",
                "In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair.",
                "For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2.",
                "The experiments in this paper are biased toward pages that have higher than average quality.",
                "Also, fRank with all of the features can only be applied to pages that have already been crawled.",
                "Thus, fRank is primarily useful for index ordering and improving relevance, not for directing the crawl.",
                "We would like to investigate a <br>machine learning</br> approach for crawl prioritization as well.",
                "It may be that a combination of methods is best: for example, using PageRank to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy.",
                "Another interesting direction for exploration is to incorporate fRank and page-level features directly into the PageRank computation itself.",
                "Work on biasing the PageRank jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach.",
                "There is reason to believe that a direct application of [29], using the fRank of a page for its relevance, could lead to an improved overall static rank.",
                "Finally, the popularity data can be used in other interesting ways.",
                "The general surfing and searching habits of Web users varies by time of day.",
                "Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively).",
                "We can gain insight into these differences by using the popularity data, divided into segments of the day.",
                "When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages.",
                "We also plan to explore popularity features that use more than just the counts of how often a page was visited.",
                "For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc.",
                "Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14].",
                "Finally, the popularity data could be used as the label rather than as a feature.",
                "Using fRank in this way to predict the popularity of a page may useful for the tasks of relevance, efficiency, and crawl priority.",
                "There is also significantly more popularity data than human labeled data, potentially enabling more complex <br>machine learning</br> methods, and significantly more features. 7.",
                "CONCLUSIONS A good static ranking is an important component for todays search engines and information retrieval systems.",
                "We have demonstrated that PageRank does not provide a very good static ranking; there are many simple features that individually out perform PageRank.",
                "By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than PageRank alone.",
                "A qualitative evaluation of the top documents shows that fRank is less technology-biased than PageRank; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit.",
                "The <br>machine learning</br> component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the <br>machine learning</br> community in areas such as adversarial classification.",
                "We have only begun to explore the options, and believe that significant strides can be made in the area of static ranking by further experimentation with additional features, other <br>machine learning</br> techniques, and additional sources of data. 8.",
                "ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional PageRank computations and to Timo Burkard for assistance with the popularity data.",
                "Many thanks to Chris Burges for providing code and significant support in using training RankNets.",
                "Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of Web documents.",
                "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
                "PageRank as a function of the damping factor.",
                "In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims.",
                "A <br>machine learning</br> architecture for optimizing web search engines.",
                "In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998.",
                "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson.",
                "Efficient PageRank approximation via graph aggregation.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the 22nd International Conference on <br>machine learning</br>, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy.",
                "Impact of search engines on page popularity.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams.",
                "Page Quality: In search of an unbiased web ranking.",
                "In Proceedings of the ACM SIGMOD 2005 Conference.",
                "Baltimore, Maryland.",
                "June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proceedings of the 28th Annual Conference on Research and Development in Information Retrieval (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
                "Adversarial Classification.",
                "In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y.",
                "Singer.",
                "Log-linear models for label-ranking.",
                "In Advances in Neural Information Processing Systems 16.",
                "Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005).",
                "Evaluating implicit measures to improve the search experiences.",
                "In the ACM Transactions on Information Systems, 23(2), pp. 147-168.",
                "April 2005. [15]T. Haveliwala.",
                "Efficient computation of PageRank.",
                "Stanford University Technical Report, 1999. [16]T. Haveliwala.",
                "Topic-sensitive PageRank.",
                "In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell.",
                "Very large scale retrieval and Web search.",
                "In D. Harman and E. Voorhees (eds), The TREC Book.",
                "MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer.",
                "Support vector learning for ordinal regression.",
                "In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst.",
                "Statistical profiles of highly-rated Web sites.",
                "In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay.",
                "Accurately Interpreting Clickthrough Data as Implicit Feedback.",
                "In Proceedings of the Conference on Research and Development in Information Retrieval (SIGIR), 2005. [22]J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit.",
                "The effect of the back button in a random walk: application for PageRank.",
                "In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry.",
                "A uniform approach to accelerated PageRank computation.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide.",
                "Static approximation of dynamically generated Web pages.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston.",
                "User-centric Web crawling.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos.",
                "The intelligent surfer: probabilistic combination of link and content information in PageRank.",
                "In Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
                "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.",
                "Teoma vs. Google, Round 2.",
                "Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: PageRank or indegree?.",
                "In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking.",
                "Query-independent evidence in home page finding.",
                "In ACM Transactions on Information Systems. 2003. 715"
            ],
            "original_annotated_samples": [
                "Beyond PageRank: <br>machine learning</br> for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We use RankNet, a ranking <br>machine learning</br> algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "We combine these and other static features using <br>machine learning</br> to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels).",
                "A <br>machine learning</br> approach for static ranking has other advantages besides the quality of the ranking.",
                "A <br>machine learning</br> approach to static ranking is also able to take advantage of any advances in the <br>machine learning</br> field."
            ],
            "translated_annotated_samples": [
                "Más allá de PageRank: Aprendizaje automático para la clasificación estática.",
                "Utilizamos RankNet, un algoritmo de <br>aprendizaje automático</br> de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio.",
                "Combinamos estas y otras características estáticas utilizando <br>aprendizaje automático</br> para lograr un sistema de clasificación que es significativamente mejor que PageRank (en acuerdo par a par con etiquetas humanas).",
                "Un enfoque de <br>aprendizaje automático</br> para la clasificación estática tiene otras ventajas además de la calidad de la clasificación.",
                "Un enfoque de <br>aprendizaje automático</br> para la clasificación estática también puede aprovechar cualquier avance en el campo del <br>aprendizaje automático</br>."
            ],
            "translated_text": "Más allá de PageRank: Aprendizaje automático para la clasificación estática. Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de <br>aprendizaje automático</br> de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un motor de búsqueda. Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización. Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. Google es frecuentemente considerado como el primer motor de búsqueda comercialmente exitoso. Su clasificación se basaba originalmente en el algoritmo PageRank [5][27]. Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la clasificación estática de páginas web. Aunque se ha pensado que PageRank ha tenido un buen rendimiento históricamente, todavía hay poca evidencia académica que respalde esta afirmación. Aún peor, recientemente se ha demostrado que PageRank puede no funcionar mejor que otras medidas simples en ciertas tareas. Upstill et al. han encontrado que para la tarea de encontrar páginas de inicio, el número de páginas que enlazan a una página y el tipo de URL fueron tan, o más, efectivos que PageRank [32]. Encontraron resultados similares para la tarea de encontrar empresas de alta calidad [31]. PageRank también se ha utilizado en sistemas para las grandes colecciones de TRECs y competencias de seguimiento web, pero con mucho menos éxito del esperado [17]. Finalmente, Amento et al. [1] encontraron que características simples, como el número de páginas en un sitio, tuvieron un rendimiento tan bueno como PageRank. A pesar de esto, la creencia general persiste entre muchos, tanto académicos como en el público, de que PageRank es un factor esencial para un buen rango estático. En caso de que esto falle, se asume que seguir utilizando la estructura de enlaces es crucial, ya sea en forma del número de enlaces entrantes o la cantidad de texto ancla. En este artículo, demostramos que existen una serie de características simples basadas en URL o en páginas que superan significativamente a PageRank (para el propósito de clasificar estáticamente páginas web) a pesar de ignorar la estructura de la web. Combinamos estas y otras características estáticas utilizando <br>aprendizaje automático</br> para lograr un sistema de clasificación que es significativamente mejor que PageRank (en acuerdo par a par con etiquetas humanas). Un enfoque de <br>aprendizaje automático</br> para la clasificación estática tiene otras ventajas además de la calidad de la clasificación. Debido a que la medida consta de muchas características, es más difícil para los usuarios malintencionados manipularla (es decir, elevar el rango estático de sus páginas a un nivel no merecido a través de técnicas cuestionables, también conocidas como spam en la web). Esto es especialmente cierto si el conjunto de características no se conoce. Por el contrario, una sola medida como PageRank puede ser más fácil de manipular porque los spammers solo necesitan concentrarse en un objetivo: cómo hacer que más páginas apunten a su página. Con un algoritmo que aprende, una característica que se vuelve inutilizable debido a la manipulación de spammers simplemente se reducirá o eliminará del cálculo final de rango. Esta flexibilidad permite que un sistema de clasificación reaccione rápidamente a nuevas técnicas de spam. Un enfoque de <br>aprendizaje automático</br> para la clasificación estática también puede aprovechar cualquier avance en el campo del <br>aprendizaje automático</br>. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "adversarial classification": {
            "translated_key": "clasificación adversarial",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Beyond PageRank: Machine Learning for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We show that we can significantly outperform PageRank using features that are independent of the link structure of the Web.",
                "We gain a further boost in accuracy by using data on the frequency at which users visit Web pages.",
                "We use RankNet, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random).",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning.",
                "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval.",
                "General Terms Algorithms, Measurement, Performance, Experimentation. 1.",
                "INTRODUCTION Over the past decade, the Web has grown exponentially in size.",
                "Unfortunately, this growth has not been isolated to good-quality pages.",
                "The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly.",
                "The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information.",
                "Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first.",
                "To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking).",
                "However, having a good query-independent ranking (static ranking) is also crucially important for a search engine.",
                "A good static ranking algorithm provides numerous benefits: • Relevance: The static rank of a page provides a general indicator to the overall quality of the page.",
                "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by static rank.",
                "By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found.",
                "The more accurate the static rank, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages.",
                "Among other factors, the static rank of a page is used to determine this prioritization.",
                "A better static rank thus provides the engine with a higher quality, more upto-date index.",
                "Google is often regarded as the first commercially successful search engine.",
                "Their ranking was originally based on the PageRank algorithm [5][27].",
                "Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the static ranking of Web pages.",
                "Though PageRank has historically been thought to perform quite well, there has yet been little academic evidence to support this claim.",
                "Even worse, there has recently been work showing that PageRank may not perform any better than other simple measures on certain tasks.",
                "Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than PageRank [32].",
                "They found similar results for the task of finding high quality companies [31].",
                "PageRank has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17].",
                "Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as PageRank.",
                "Despite these, the general belief remains among many, both academic and in the public, that PageRank is an essential factor for a good static rank.",
                "Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text.",
                "In this paper, we show there are a number of simple url- or pagebased features that significantly outperform PageRank (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web.",
                "We combine these and other static features using machine learning to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels).",
                "A machine learning approach for static ranking has other advantages besides the quality of the ranking.",
                "Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages static rank to an undeserved level through questionable techniques, also known as Web spamming).",
                "This is particularly true if the feature set is not known.",
                "In contrast, a single measure like PageRank can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page.",
                "With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank.",
                "This flexibility allows a ranking system to rapidly react to new spamming techniques.",
                "A machine learning approach to static ranking is also able to take advantage of any advances in the machine learning field.",
                "For example, recent work on <br>adversarial classification</br> [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
                "Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the static rank.",
                "By moving static ranking to a machine learning framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of machine learning.",
                "Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet.",
                "These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful.",
                "For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page.",
                "A machine learning approach thus allows rapid development of a good static algorithm in new domains.",
                "This papers contribution is a systematic study of static features, including PageRank, for the purposes of (statically) ranking Web pages.",
                "Previous studies on PageRank typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages).",
                "Also, the performance of PageRank and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering.",
                "In contrast, we explore the use of PageRank and other features for the direct task of statically ranking Web pages.",
                "We first briefly describe the PageRank algorithm.",
                "In Section 3 we introduce RankNet, the machine learning technique used to combine static features into a final ranking.",
                "Section 4 describes the static features.",
                "The heart of the paper is in Section 5, which presents our experiments and results.",
                "We conclude with a discussion of related and future work. 2.",
                "PAGERANK The basic idea behind PageRank is simple: a link from a Web page to another can be seen as an endorsement of that page.",
                "In general, links are made by people.",
                "As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality.",
                "We can take advantage of this linkage information to order Web pages according to their perceived quality.",
                "Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step.",
                "In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links.",
                "If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j.",
                "The PageRank score for node j is defined as this probability: PR(j)=P(j).",
                "Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform).",
                "The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page.",
                "An alternative view for equation (1) is that each page is assigned a quality, P(j).",
                "A page gives an equal share of its quality to each page it points to.",
                "PageRank is computationally expensive.",
                "Our collection of 5 billion pages contains approximately 370 billion links.",
                "Computing PageRank requires iterating over these billions of links multiple times (until convergence).",
                "It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them.",
                "Though much work has been done on optimizing the PageRank computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3.",
                "RANKNET Much work in machine learning has been done on the problems of classification and regression.",
                "Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi.",
                "The classification problem is to learn a function f that maps yi=f(xi), for all i.",
                "When yi is real-valued as well, this is called regression.",
                "Static ranking can be seen as a regression problem.",
                "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a regression function that mapped each pages features to their rank.",
                "However, this over-constrains the problem we wish to solve.",
                "All we really care about is the order of the pages, not the actual value assigned to them.",
                "Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them.",
                "For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j.",
                "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a regression function, the result of this process is a function (f) that maps feature vectors to real values.",
                "This function can still be applied anywhere that a regressionlearned function could be applied.",
                "The only difference is the technique used to learn the function.",
                "By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do regression techniques.",
                "We used RankNet [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function.",
                "RankNet is a straightforward modification to the standard neural network back-prop algorithm.",
                "As with back-prop, RankNet attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight.",
                "The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the RankNet cost function is based on the difference between a pair of network outputs.",
                "That is, for each pair of feature vectors <i,j> in the training set, RankNet computes the network outputs oi and oj.",
                "Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost.",
                "RankNet also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function).",
                "In this paper, we used a probability of one for all pairs.",
                "In the next section, we will discuss the features used in our feature vectors, xi. 4.",
                "FEATURES To apply RankNet (or other machine learning techniques) to the ranking problem, we needed to extract a set of features from each page.",
                "We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity).",
                "We also optionally used the PageRank of a page as a feature.",
                "Below, we describe each of these feature categories in more detail.",
                "PageRank We computed PageRank on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages).",
                "This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines.",
                "Because PageRank is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible.",
                "Most previous studies on PageRank used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed PageRank using the standard value of 0.85 for α.",
                "Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time.",
                "We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN.",
                "The data is aggregated into a count, for each Web page, of the number of users who viewed that page.",
                "Though popularity data is generally unavailable, there are two other sources for it.",
                "The first is from proxy logs.",
                "For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus.",
                "Unfortunately, proxy data is quite biased and relatively small.",
                "Another source, internal to search engines, are records of which results their users clicked on.",
                "Such data was used by the search engine Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
                "An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search.",
                "The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed.",
                "More details are provided in section 5.5.",
                "Anchor text and inlinks These features are based on the information associated with links to the page in question.",
                "It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc.",
                "Page This category consists of features which may be determined by looking at the page (and its URL) alone.",
                "We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc.",
                "Domain This category contains features that are computed as averages across all pages in the domain.",
                "For example, the average number of outlinks on any page and the average PageRank.",
                "Many of these features have been used by others for ranking Web pages, particularly the anchor and page features.",
                "As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for static ranking.",
                "Also, to our knowledge, this is the first study on the use of actual page visitation popularity for static ranking.",
                "The closest similar work is on using click-through behavior (that is, which search engine results the users click on) to affect dynamic ranking (see e.g., [20]).",
                "Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for feature-based ranking). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages.",
                "Unless otherwise specified, fRank was trained with all of the features. 5.",
                "EXPERIMENTS In this section, we will demonstrate that we can out perform PageRank by applying machine learning to a straightforward set of features.",
                "Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a static ranking, we needed a gold standard defining the correct ordering for a set of pages.",
                "For this, we employed a dataset which contains human judgments for 28000 queries.",
                "For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges.",
                "The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent.",
                "There are approximately 500k judgments in all, or an average of 18 ratings per query.",
                "The queries are selected by randomly choosing queries from among those issued to the MSN search engine.",
                "The probability that a query is selected is proportional to its frequency among all 709 of the queries.",
                "As a result, common queries are more likely to be judged than uncommon queries.",
                "As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture.",
                "The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs search engine).",
                "This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query.",
                "Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries.",
                "This bias is good when evaluating the quality of static ranking for the purposes of index ordering and returning relevant documents.",
                "This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries.",
                "Because of this bias, however, the results in this paper are not applicable to crawl prioritization.",
                "In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages.",
                "To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query.",
                "The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high static rank.",
                "Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query.",
                "We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively.",
                "Each set contains all of the ratings for a given query, and no query appears in more than one set.",
                "The training set was used to train fRank.",
                "The validation set was used to select the model that had the highest performance.",
                "The test set was used for the final results.",
                "This data gives us a query-independent ordering of pages.",
                "The goal for a static ranking algorithm will be to reproduce this ordering as closely as possible.",
                "In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a static ranking.",
                "The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages.",
                "If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of relevance for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
                "First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score).",
                "Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the static rank algorithm orders them correctly. 5.3 Method We trained fRank (a RankNet based neural network) using the following parameters.",
                "We used a fully connected 2 layer network.",
                "The hidden layer had 10 hidden nodes.",
                "The input weights to this layer were all initialized to be zero.",
                "The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1].",
                "We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output.",
                "The cost function is the pairwise cross entropy cost function as discussed in section 3.",
                "The features in the training set were normalized to have zero mean and unit standard deviation.",
                "The same linear transformation was then applied to the features in the validation and test sets.",
                "For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other.",
                "The pairings were chosen uniformly at random (with replacement) from all possible pairings.",
                "When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs.",
                "Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread.",
                "We trained the network for 30 epochs.",
                "On each epoch, the training pairs were randomly shuffled.",
                "The initial training rate was 0.001.",
                "At each epoch, we checked the error on the training set.",
                "If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot.",
                "The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased.",
                "After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement).",
                "The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set.",
                "We report the pairwise accuracy on the test set, calculated using all possible pairs.",
                "These parameters were determined and fixed before the static rank experiments in this paper.",
                "In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7].",
                "Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them.",
                "The only exception was the popularity features.",
                "As with most Web phenomenon, we found that the distribution of site popularity is Zipfian.",
                "To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple machine learning methods such as naïve Bayes.",
                "In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the PageRank for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms PageRank for the purposes of static ranking.",
                "With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of PageRank (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages).",
                "Note that one of fRanks input features is the PageRank of the page, so we would expect it to perform no worse than PageRank.",
                "The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page.",
                "Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 PageRank 56.70 fRank 67.43 There are a number of decisions that go into the computation of PageRank, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc.",
                "We were able to obtain a computation of PageRank from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters.",
                "It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation.",
                "We thus concluded that the quality of the PageRank is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it.",
                "We also wanted to find how well each feature set performed.",
                "To answer this, for each feature set, we trained and tested fRank using only that set of features.",
                "The results are shown in Table 2.",
                "As can be seen, every single feature set individually outperformed PageRank on this test.",
                "Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets.",
                "This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page.",
                "This is contrary to the common belief that the Web graph structure is the key to finding a good static ranking of Web pages.",
                "Table 2: Results for individual feature sets.",
                "Feature Set Accuracy (%) PageRank 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways.",
                "This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features.",
                "To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study.",
                "That is, for each set of features, we trained a network to contain all of the features except that set.",
                "We then compared the performance of the resulting network to the performance of the network with all of the features.",
                "Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set.",
                "Table 3: Ablation study.",
                "Shown is the decrease in accuracy when we train a network that has all but the given set of features.",
                "The last line is shows the effect of removing the anchor, PageRank, and domain features, hence a model containing no network or link-based information whatsoever.",
                "Feature Set Decrease in Accuracy PageRank 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, PageRank & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study.",
                "Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set.",
                "Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless.",
                "Beginning with no features, we greedily added the feature set that improved performance the most.",
                "The results are shown in Table 4.",
                "For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%.",
                "Table 4: fRank performance as feature sets are added.",
                "At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets).",
                "Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +PageRank 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of PageRank vs. fRank.",
                "In Table 5 are the top ten URLs returned for PageRank and for fRank.",
                "PageRanks results are heavily weighted towards technology sites.",
                "It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc.",
                "PageRanks bias toward technology can be explained through two processes.",
                "First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime.",
                "These generally link back to, in these examples, the Internet Explorer and QuickTime download sites.",
                "Consequently, PageRank ranks those pages highly.",
                "Though these pages are important, they are not as important as it may seem by looking at the link structure alone.",
                "One fix for this is to add information about the link to the PageRank computation, such as the size of the text, whether it was at the bottom of the page, etc.",
                "The other bias comes from the fact that the population of Web site authors is different than the population of Web users.",
                "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual visitation popularity of a site (the popularity feature set), is able to eliminate some of that bias.",
                "It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked.",
                "The results confirm that fRank outperforms PageRank in pairwise accuracy.",
                "The two most important feature sets are the page and popularity features.",
                "This is surprising, as the page features consisted only of a few (8) simple features.",
                "Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best.",
                "In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users.",
                "For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user.",
                "This limited the possible features we could derive from this data.",
                "For possible extensions, see section 6.3, future work.",
                "For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user.",
                "However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
                "One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user.",
                "Adding this feature dramatically improved the performance of fRank.",
                "We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain.",
                "We did this by using the set of features shown in Table 6.",
                "Table 6: URL functions used to compute the Popularity feature set.",
                "Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table.",
                "The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question.",
                "For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html.",
                "As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further.",
                "Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data.",
                "It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected.",
                "In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set.",
                "Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank.",
                "The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy.",
                "In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy.",
                "Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions.",
                "First, fRank performs significantly better than PageRank, even without any information about the Web graph.",
                "Second, the page level and popularity features were the most significant contributors to pairwise accuracy.",
                "Third, by collecting more popularity data, we can continue to improve fRanks performance.",
                "The popularity data provides two benefits to fRank.",
                "First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer.",
                "Second, the popularity data is more timely than PageRanks link information.",
                "The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6.",
                "RELATED AND FUTURE WORK 6.1 Improvements to PageRank Since the original PageRank paper, there has been work on improving it.",
                "Much of that work centers on speeding up and parallelizing the computation [15][25].",
                "One recognized problem with PageRank is that of topic drift: A page about dogs will have high PageRank if it is linked to by many pages that themselves have high rank, regardless of their topic.",
                "In contrast, a search engine user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs.",
                "Hence, a link that is on topic should have higher weight than a link that is not.",
                "Richardson and Domingoss Query Dependent PageRank [29] and Haveliwalas Topic-Sensitive PageRank [16] are two approaches that tackle this problem.",
                "Other variations to PageRank include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3].",
                "See Langville and Meyer [23] for a good survey of these, and other modifications to PageRank. 6.2 Other related work PageRank is not the only link analysis algorithm used for ranking Web pages.",
                "The most well-known other is HITS [22], which is used by the Teoma search engine [30].",
                "HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs.",
                "Previous work has shown HITS to perform comparably to PageRank [1].",
                "One field of interest is that of static index pruning (see e.g., Carmel et al. [8]).",
                "Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query.",
                "The pruning is typically done based on the frequency of query terms.",
                "Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search.",
                "Similar methods could be incorporated into the static rank (e.g., how many frequent queries contain words found on this page).",
                "Others have investigated the effect that PageRank has on the Web at large [9].",
                "They argue that pages with high PageRank are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher PageRank than other pages.",
                "The same may occur for the popularity data.",
                "If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity.",
                "Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure.",
                "The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity.",
                "One interesting related work is that of Ivory and Hearst [19].",
                "Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience.",
                "They used over 100 page level features, as well as features encompassing the performance and structure of the site.",
                "This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features.",
                "The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set.",
                "Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future.",
                "Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which search engine results are clicked on.",
                "Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking.",
                "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall relevance of a search engine (i.e., the dynamic ranking).",
                "They do not apply their techniques to the problem of static ranking. 6.3 Future work There are many ways in which we would like to extend this work.",
                "First, fRank uses only a small number of features.",
                "We believe we could achieve even more significant results with more features.",
                "In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page).",
                "Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc.",
                "Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables.",
                "For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features.",
                "The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents.",
                "In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair.",
                "For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2.",
                "The experiments in this paper are biased toward pages that have higher than average quality.",
                "Also, fRank with all of the features can only be applied to pages that have already been crawled.",
                "Thus, fRank is primarily useful for index ordering and improving relevance, not for directing the crawl.",
                "We would like to investigate a machine learning approach for crawl prioritization as well.",
                "It may be that a combination of methods is best: for example, using PageRank to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy.",
                "Another interesting direction for exploration is to incorporate fRank and page-level features directly into the PageRank computation itself.",
                "Work on biasing the PageRank jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach.",
                "There is reason to believe that a direct application of [29], using the fRank of a page for its relevance, could lead to an improved overall static rank.",
                "Finally, the popularity data can be used in other interesting ways.",
                "The general surfing and searching habits of Web users varies by time of day.",
                "Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively).",
                "We can gain insight into these differences by using the popularity data, divided into segments of the day.",
                "When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages.",
                "We also plan to explore popularity features that use more than just the counts of how often a page was visited.",
                "For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc.",
                "Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14].",
                "Finally, the popularity data could be used as the label rather than as a feature.",
                "Using fRank in this way to predict the popularity of a page may useful for the tasks of relevance, efficiency, and crawl priority.",
                "There is also significantly more popularity data than human labeled data, potentially enabling more complex machine learning methods, and significantly more features. 7.",
                "CONCLUSIONS A good static ranking is an important component for todays search engines and information retrieval systems.",
                "We have demonstrated that PageRank does not provide a very good static ranking; there are many simple features that individually out perform PageRank.",
                "By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than PageRank alone.",
                "A qualitative evaluation of the top documents shows that fRank is less technology-biased than PageRank; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit.",
                "The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as <br>adversarial classification</br>.",
                "We have only begun to explore the options, and believe that significant strides can be made in the area of static ranking by further experimentation with additional features, other machine learning techniques, and additional sources of data. 8.",
                "ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional PageRank computations and to Timo Burkard for assistance with the popularity data.",
                "Many thanks to Chris Burges for providing code and significant support in using training RankNets.",
                "Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of Web documents.",
                "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
                "PageRank as a function of the damping factor.",
                "In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims.",
                "A machine learning architecture for optimizing web search engines.",
                "In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998.",
                "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson.",
                "Efficient PageRank approximation via graph aggregation.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the 22nd International Conference on Machine Learning, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy.",
                "Impact of search engines on page popularity.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams.",
                "Page Quality: In search of an unbiased web ranking.",
                "In Proceedings of the ACM SIGMOD 2005 Conference.",
                "Baltimore, Maryland.",
                "June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proceedings of the 28th Annual Conference on Research and Development in Information Retrieval (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
                "<br>adversarial classification</br>.",
                "In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y.",
                "Singer.",
                "Log-linear models for label-ranking.",
                "In Advances in Neural Information Processing Systems 16.",
                "Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005).",
                "Evaluating implicit measures to improve the search experiences.",
                "In the ACM Transactions on Information Systems, 23(2), pp. 147-168.",
                "April 2005. [15]T. Haveliwala.",
                "Efficient computation of PageRank.",
                "Stanford University Technical Report, 1999. [16]T. Haveliwala.",
                "Topic-sensitive PageRank.",
                "In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell.",
                "Very large scale retrieval and Web search.",
                "In D. Harman and E. Voorhees (eds), The TREC Book.",
                "MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer.",
                "Support vector learning for ordinal regression.",
                "In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst.",
                "Statistical profiles of highly-rated Web sites.",
                "In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay.",
                "Accurately Interpreting Clickthrough Data as Implicit Feedback.",
                "In Proceedings of the Conference on Research and Development in Information Retrieval (SIGIR), 2005. [22]J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit.",
                "The effect of the back button in a random walk: application for PageRank.",
                "In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry.",
                "A uniform approach to accelerated PageRank computation.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide.",
                "Static approximation of dynamically generated Web pages.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston.",
                "User-centric Web crawling.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos.",
                "The intelligent surfer: probabilistic combination of link and content information in PageRank.",
                "In Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
                "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.",
                "Teoma vs. Google, Round 2.",
                "Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: PageRank or indegree?.",
                "In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking.",
                "Query-independent evidence in home page finding.",
                "In ACM Transactions on Information Systems. 2003. 715"
            ],
            "original_annotated_samples": [
                "For example, recent work on <br>adversarial classification</br> [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
                "The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as <br>adversarial classification</br>.",
                "<br>adversarial classification</br>."
            ],
            "translated_annotated_samples": [
                "Por ejemplo, un trabajo reciente sobre <br>clasificación adversarial</br> [12] sugiere que puede ser posible modelar explícitamente las acciones de los spammers de páginas web (el adversario), ajustando el modelo de clasificación de antemano antes de que los spammers intenten evadirlo.",
                "El componente de aprendizaje automático de fRank le otorga el beneficio adicional de ser más robusto contra los spammers, y le permite aprovechar los avances adicionales en la comunidad de aprendizaje automático en áreas como la <br>clasificación adversarial</br>.",
                "Clasificación adversarial."
            ],
            "translated_text": "Más allá de PageRank: Aprendizaje automático para la clasificación estática. Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un motor de búsqueda. Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización. Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. Google es frecuentemente considerado como el primer motor de búsqueda comercialmente exitoso. Su clasificación se basaba originalmente en el algoritmo PageRank [5][27]. Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la clasificación estática de páginas web. Aunque se ha pensado que PageRank ha tenido un buen rendimiento históricamente, todavía hay poca evidencia académica que respalde esta afirmación. Aún peor, recientemente se ha demostrado que PageRank puede no funcionar mejor que otras medidas simples en ciertas tareas. Upstill et al. han encontrado que para la tarea de encontrar páginas de inicio, el número de páginas que enlazan a una página y el tipo de URL fueron tan, o más, efectivos que PageRank [32]. Encontraron resultados similares para la tarea de encontrar empresas de alta calidad [31]. PageRank también se ha utilizado en sistemas para las grandes colecciones de TRECs y competencias de seguimiento web, pero con mucho menos éxito del esperado [17]. Finalmente, Amento et al. [1] encontraron que características simples, como el número de páginas en un sitio, tuvieron un rendimiento tan bueno como PageRank. A pesar de esto, la creencia general persiste entre muchos, tanto académicos como en el público, de que PageRank es un factor esencial para un buen rango estático. En caso de que esto falle, se asume que seguir utilizando la estructura de enlaces es crucial, ya sea en forma del número de enlaces entrantes o la cantidad de texto ancla. En este artículo, demostramos que existen una serie de características simples basadas en URL o en páginas que superan significativamente a PageRank (para el propósito de clasificar estáticamente páginas web) a pesar de ignorar la estructura de la web. Combinamos estas y otras características estáticas utilizando aprendizaje automático para lograr un sistema de clasificación que es significativamente mejor que PageRank (en acuerdo par a par con etiquetas humanas). Un enfoque de aprendizaje automático para la clasificación estática tiene otras ventajas además de la calidad de la clasificación. Debido a que la medida consta de muchas características, es más difícil para los usuarios malintencionados manipularla (es decir, elevar el rango estático de sus páginas a un nivel no merecido a través de técnicas cuestionables, también conocidas como spam en la web). Esto es especialmente cierto si el conjunto de características no se conoce. Por el contrario, una sola medida como PageRank puede ser más fácil de manipular porque los spammers solo necesitan concentrarse en un objetivo: cómo hacer que más páginas apunten a su página. Con un algoritmo que aprende, una característica que se vuelve inutilizable debido a la manipulación de spammers simplemente se reducirá o eliminará del cálculo final de rango. Esta flexibilidad permite que un sistema de clasificación reaccione rápidamente a nuevas técnicas de spam. Un enfoque de aprendizaje automático para la clasificación estática también puede aprovechar cualquier avance en el campo del aprendizaje automático. Por ejemplo, un trabajo reciente sobre <br>clasificación adversarial</br> [12] sugiere que puede ser posible modelar explícitamente las acciones de los spammers de páginas web (el adversario), ajustando el modelo de clasificación de antemano antes de que los spammers intenten evadirlo. Otro ejemplo es la eliminación de valores atípicos al construir el modelo, lo cual ayuda a reducir el efecto que los sitios únicos pueden tener en la calidad general de la clasificación estática. Al trasladar la clasificación estática a un marco de aprendizaje automático, no solo ganamos en precisión, sino también en la capacidad de reaccionar a las acciones de los spammers, de añadir rápidamente nuevas características al algoritmo de clasificación y de aprovechar los avances en el campo en rápido crecimiento del aprendizaje automático. Finalmente, creemos que habrá ventajas significativas al utilizar esta técnica para otros ámbitos, como la búsqueda en un disco duro local o en la intranet de una empresa. Estos son dominios donde la estructura de enlaces es particularmente débil (o inexistente), pero hay otras características específicas del dominio que podrían ser igual de poderosas. Por ejemplo, el autor de una página de intranet y su posición en la organización (por ejemplo, CEO, gerente o desarrollador) podrían proporcionar pistas significativas sobre la importancia de esa página. Un enfoque de aprendizaje automático permite el desarrollo rápido de un buen algoritmo estático en nuevos dominios. La contribución de este artículo es un estudio sistemático de las características estáticas, incluido PageRank, con el propósito de clasificar páginas web de forma estática. Estudios previos sobre PageRank típicamente utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Además, el rendimiento de PageRank y otras características estáticas suele evaluarse en el contexto de un sistema completo para la clasificación dinámica, o para otras tareas como la respuesta a preguntas. Por el contrario, exploramos el uso de PageRank y otras características para la tarea directa de clasificar estáticamente las páginas web. Primero describimos brevemente el algoritmo PageRank. En la Sección 3 presentamos RankNet, la técnica de aprendizaje automático utilizada para combinar las características estáticas en un ranking final. La sección 4 describe las características estáticas. El corazón del documento está en la Sección 5, la cual presenta nuestros experimentos y resultados. Concluimos con una discusión sobre el trabajo relacionado y futuro. 2. PAGERANK La idea básica detrás de PageRank es simple: un enlace de una página web a otra puede ser visto como un respaldo de esa página. En general, los enlaces son creados por personas. Por lo tanto, son indicativos de la calidad de las páginas a las que apuntan: al crear una página, un autor presumiblemente elige enlazar a páginas consideradas de buena calidad. Podemos aprovechar esta información de enlace para ordenar las páginas web según su calidad percibida. Imagina a un internauta que salta de página web en página web, eligiendo con probabilidad uniforme qué enlace seguir en cada paso. Para reducir el efecto de los callejones sin salida o ciclos interminables, el surfista saltará ocasionalmente a una página aleatoria con una pequeña probabilidad α, o cuando se encuentre en una página sin enlaces de salida. Si se promedia sobre un número suficiente de pasos, la probabilidad de que el surfista esté en la página j en algún momento en el tiempo está dada por la fórmula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Donde Fi es el conjunto de páginas a las que enlaza la página i, y Bj es el conjunto de páginas que enlazan a la página j. El puntaje de PageRank para el nodo j se define como esta probabilidad: PR(j)=P(j). Dado que la ecuación (1) es recursiva, debe evaluarse de forma iterativa hasta que P(j) converja (normalmente, la distribución inicial para P(j) es uniforme). La intuición es que, dado que un navegante aleatorio llegaría a la página con más frecuencia, es probable que sea una página mejor. Una vista alternativa para la ecuación (1) es que a cada página se le asigna una calidad, P(j). Una página otorga una parte igual de su calidad a cada página a la que apunta. PageRank es computacionalmente costoso. Nuestra colección de 5 mil millones de páginas contiene aproximadamente 370 mil millones de enlaces. Calcular el PageRank requiere iterar sobre miles de millones de enlaces varias veces (hasta converger). Requiere grandes cantidades de memoria (o esquemas de almacenamiento en caché muy inteligentes que ralentizan aún más el cálculo), y si se distribuye en múltiples máquinas, requiere una comunicación significativa entre ellas. Aunque se ha realizado mucho trabajo en la optimización del cálculo del PageRank (ver, por ejemplo, [25] y [6]), sigue siendo una propiedad relativamente lenta y costosa computacionalmente de calcular. 3. RANKNET Se ha realizado mucho trabajo en aprendizaje automático en los problemas de clasificación y regresión. Sea X={xi} una colección de vectores de características (típicamente, una característica es cualquier número real), y Y={yi} una colección de clases asociadas, donde yi es la clase del objeto descrito por el vector de características xi. El problema de clasificación consiste en aprender una función f que mapea yi=f(xi), para todo i. Cuando yi también es un valor real, esto se llama regresión. La clasificación estática se puede ver como un problema de regresión. Si dejamos que xi represente las características de la página i, y yi sea un valor (por ejemplo, el rango) para cada página, podríamos aprender una función de regresión que mapeara las características de cada página a su rango. Sin embargo, esto sobrecarga el problema que deseamos resolver. Todo lo que realmente nos importa es el orden de las páginas, no el valor real asignado a ellas. El trabajo reciente sobre este problema de clasificación [7][13][18] intenta directamente optimizar el orden de los objetos, en lugar del valor asignado a ellos. Para esto, sea Z={<i,j>} una colección de pares de elementos, donde el elemento i debe ser asignado un valor más alto que el elemento j. El objetivo del problema de clasificación, entonces, es aprender una función f tal que, )()(,, ji ffji xxZ >∈∀ 708. Nótese que, al igual que al aprender una función de regresión, el resultado de este proceso es una función (f) que mapea vectores de características a valores reales. Esta función todavía se puede aplicar en cualquier lugar donde se pueda aplicar una función aprendida por regresión. La única diferencia es la técnica utilizada para aprender la función. Al optimizar directamente el orden de los objetos, estos métodos pueden aprender una función que clasifica mejor que las técnicas de regresión. Utilizamos RankNet [7], una de las técnicas mencionadas para aprender funciones de clasificación, para aprender nuestra función de clasificación estática. RankNet es una modificación sencilla del algoritmo de retropropagación de la red neuronal estándar. Al igual que con back-prop, RankNet intenta minimizar el valor de una función de costo ajustando cada peso en la red de acuerdo con el gradiente de la función de costo con respecto a ese peso. La diferencia es que, mientras que una función de costo típica de una red neuronal se basa en la diferencia entre la salida de la red y la salida deseada, la función de costo de RankNet se basa en la diferencia entre un par de salidas de la red. Es decir, para cada par de vectores de características <i,j> en el conjunto de entrenamiento, RankNet calcula las salidas de la red oi y oj. Dado que se supone que el vector i está clasificado más alto que el vector j, cuanto mayor sea oj-oi, mayor será el costo. RankNet también permite que los pares en Z sean ponderados con una confianza (expresada como la probabilidad de que el par cumpla con el ordenamiento inducido por la función de clasificación). En este documento, utilizamos una probabilidad de uno para todos los pares. En la siguiente sección, discutiremos las características utilizadas en nuestros vectores de características, xi. 4. Para aplicar RankNet (u otras técnicas de aprendizaje automático) al problema de clasificación, necesitábamos extraer un conjunto de características de cada página. Dividimos nuestro conjunto de características en cuatro categorías mutuamente excluyentes: a nivel de página (Página), a nivel de dominio (Dominio), texto del enlace y enlaces entrantes (Anclaje) y popularidad (Popularidad). También opcionalmente utilizamos el PageRank de una página como una característica. A continuación, describimos cada una de estas categorías de características con más detalle. Calculamos PageRank en un grafo web de 5 mil millones de páginas rastreadas (y 20 mil millones de URLs conocidas enlazadas por estas páginas). Esto representa una parte significativa de la Web, y es aproximadamente la misma cantidad de páginas que utilizan Google, Yahoo y MSN para sus motores de búsqueda. Dado que PageRank es un algoritmo basado en grafos, es importante que se ejecute en la mayor cantidad posible de subconjuntos de la Web. La mayoría de los estudios previos sobre PageRank utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Calculamos PageRank utilizando el valor estándar de 0.85 para α. Otra característica que utilizamos es la popularidad real de una página web, medida como el número de veces que ha sido visitada por usuarios durante algún período de tiempo. Tenemos acceso a esos datos de usuarios que han instalado la barra de herramientas de MSN y han optado por proporcionarlos a MSN. Los datos se agregan en un recuento, para cada página web, del número de usuarios que vieron esa página. Aunque los datos de popularidad generalmente no están disponibles, hay otras dos fuentes para obtenerlos. El primero es de los registros de proxy. Por ejemplo, una universidad que requiere que sus estudiantes utilicen un proxy tiene un registro de todas las páginas que han visitado mientras están en el campus. Desafortunadamente, los datos de proxy son bastante sesgados y relativamente pequeños. Otra fuente, interna de los motores de búsqueda, son los registros de los resultados en los que hicieron clic sus usuarios. Tales datos fueron utilizados por el motor de búsqueda Direct Hit, y recientemente han sido explorados con fines de clasificación dinámica [20]. Una ventaja de los datos de la barra de herramientas sobre esto es que contiene información sobre las visitas a URL que no son solo el resultado de una búsqueda. La popularidad en bruto se procesa en una serie de características como el número de veces que se visualizó una página y el número de veces que se visualizó cualquier página en el dominio. Se proporcionan más detalles en la sección 5.5. Texto de anclaje e inlinks. Estas características se basan en la información asociada con los enlaces a la página en cuestión. Incluye características como la cantidad total de texto en los enlaces que apuntan a la página (texto de anclaje), el número de palabras únicas en ese texto, etc. Esta categoría consiste en características que pueden ser determinadas solo al observar la página (y su URL). Solo utilizamos ocho características simples como el número de palabras en el cuerpo, la frecuencia del término más común, etc. Este categoría contiene características que se calculan como promedios en todas las páginas del dominio. Por ejemplo, el número promedio de enlaces salientes en cualquier página y el PageRank promedio. Muchas de estas características han sido utilizadas por otros para clasificar páginas web, especialmente las características de anclaje y de la página. Como se mencionó, la evaluación suele ser para clasificación dinámica, y deseamos evaluar su uso para clasificación estática. Además, hasta donde sabemos, este es el primer estudio sobre el uso de la popularidad real de visitas a páginas para la clasificación estática. El trabajo similar más cercano se centra en el uso del comportamiento de clics (es decir, en los resultados de búsqueda en los que los usuarios hacen clic) para afectar la clasificación dinámica (ver, por ejemplo, [20]). Debido a que utilizamos una amplia variedad de características para crear un ranking estático, nos referimos a esto como fRank (para ranking basado en características). fRank utiliza RankNet y el conjunto de características descritas en esta sección para aprender una función de ranking para páginas web. A menos que se especifique lo contrario, fRank fue entrenado con todas las características. 5. EXPERIMENTOS En esta sección, demostraremos que podemos superar a PageRank aplicando aprendizaje automático a un conjunto sencillo de características. Antes de los resultados, primero discutimos los datos, la métrica de rendimiento y el método de entrenamiento. 5.1 Datos Para evaluar la calidad de un ranking estático, necesitábamos un estándar de oro que definiera el orden correcto para un conjunto de páginas. Para esto, empleamos un conjunto de datos que contiene juicios humanos para 28000 consultas. Para cada consulta, un número de resultados son asignados manualmente una calificación, de 0 a 4, por jueces humanos. La calificación está destinada a ser una medida de cuán relevante es el resultado para la consulta, donde 0 significa pobre y 4 significa excelente. Hay aproximadamente 500 mil juicios en total, o un promedio de 18 calificaciones por consulta. Las consultas se seleccionan eligiendo aleatoriamente consultas de entre aquellas emitidas al motor de búsqueda de MSN. La probabilidad de que se seleccione una consulta es proporcional a su frecuencia entre las 709 consultas. Como resultado, es más probable que las consultas comunes sean evaluadas que las consultas poco comunes. Como ejemplo de la diversidad de las consultas, las primeras cuatro consultas en el conjunto de entrenamiento son escuelas de chef, el autódromo de Chicagoland, el club de fans de los Eagles y la cultura turca. Los documentos seleccionados para evaluar son aquellos que esperábamos que, en promedio, fueran razonablemente relevantes (por ejemplo, los diez documentos principales devueltos por el motor de búsqueda de MSN). Esto proporciona significativamente más información que seleccionar documentos al azar en la web, la gran mayoría de los cuales serían irrelevantes para una consulta específica. Debido a este proceso, las páginas evaluadas tienden a ser de mayor calidad que la página promedio en la web, y suelen ser páginas que se devolverán en consultas de búsqueda comunes. Este sesgo es útil al evaluar la calidad de la clasificación estática con el fin de ordenar índices y devolver documentos relevantes. Esto se debe a que la parte más importante del índice que debe estar bien ordenada y ser relevante es la parte que se devuelve con frecuencia para las consultas de búsqueda. Debido a este sesgo, sin embargo, los resultados en este documento no son aplicables a la priorización de rastreo. Para obtener resultados experimentales sobre la priorización de rastreo, necesitaríamos calificaciones de una muestra aleatoria de páginas web. Para convertir los datos de dependientes de la consulta a independientes de la consulta, simplemente eliminamos la consulta, tomando el máximo sobre las evaluaciones para una URL que aparece en más de una consulta. El razonamiento detrás de esto es que una página que es relevante para una consulta y no relevante para otra probablemente sea una buena página y debería tener un alto rango estático. Debido a que evaluamos las páginas en consultas que ocurren con frecuencia, nuestros datos indican el orden correcto del índice y asignan un alto valor a las páginas que probablemente sean relevantes para una consulta común. Asignamos consultas al azar a un conjunto de entrenamiento, validación o prueba, de modo que contuvieran el 84%, 8% y 8% de las consultas, respectivamente. Cada conjunto contiene todas las calificaciones para una consulta dada, y ninguna consulta aparece en más de un conjunto. El conjunto de entrenamiento se utilizó para entrenar fRank. El conjunto de validación se utilizó para seleccionar el modelo que tuvo el mejor rendimiento. El conjunto de pruebas se utilizó para los resultados finales. Estos datos nos proporcionan un ordenamiento de páginas independiente de la consulta. El objetivo de un algoritmo de clasificación estática será reproducir este orden lo más fielmente posible. En la siguiente sección, describimos la medida que utilizamos para evaluar esto. 5.2 Medida Elegimos utilizar la precisión por pares para evaluar la calidad de un ranking estático. La precisión por pares es la fracción de tiempo en la que el algoritmo de clasificación y los jueces humanos están de acuerdo en el ordenamiento de un par de páginas web. Si S(x) es la clasificación estática asignada a la página x, y H(x) es el juicio humano de relevancia para x, entonces considera los siguientes conjuntos: )}()(:,{ yHxHyx >=pH y )}()(:,{ ySxSyx >=pS La precisión por pares es la porción de Hp que también está contenida en Sp: p pp H SH ∩ =precisiónpares Esta medida fue elegida por dos razones. Primero, los juicios humanos discretos proporcionan solo un orden parcial sobre las páginas web, lo que dificulta aplicar una medida como el coeficiente de correlación de orden de rango de Spearman (en la medida de precisión por pares, un par de documentos con el mismo juicio humano no afecta la puntuación). Segundo, la precisión por pares tiene un significado intuitivo: es la fracción de pares de documentos que, cuando los humanos afirman que uno es mejor que el otro, el algoritmo de clasificación estática los ordena correctamente. 5.3 Método Entrenamos fRank (una red neuronal basada en RankNet) utilizando los siguientes parámetros. Utilizamos una red de 2 capas completamente conectadas. La capa oculta tenía 10 nodos ocultos. Los pesos de entrada a esta capa se inicializaron todos en cero. Los pesos de la capa de salida (solo un nodo) se inicializaron utilizando una distribución aleatoria uniforme en el rango [-0.1, 0.1]. Utilizamos la función tangente hiperbólica (tanh) como función de transferencia de las entradas a la capa oculta, y una función lineal de la capa oculta a la salida. La función de costo es la función de costo de entropía cruzada por pares discutida en la sección 3. Las características en el conjunto de entrenamiento fueron normalizadas para tener media cero y desviación estándar unitaria. La misma transformación lineal fue luego aplicada a las características en los conjuntos de validación y prueba. Para el entrenamiento, presentamos a la red neuronal 5 millones de pares de páginas, donde una página tenía una calificación más alta que la otra. Las combinaciones fueron elegidas de forma uniforme al azar (con reemplazo) de todas las combinaciones posibles. Al formar las parejas, ignoramos la magnitud de la diferencia entre las calificaciones (la dispersión de calificaciones) de las dos URL. Por lo tanto, el peso para cada par era constante (uno), y la probabilidad de que se seleccionara un par era independiente de la diferencia de calificación. Entrenamos la red durante 30 épocas. En cada época, los pares de entrenamiento fueron mezclados aleatoriamente. La tasa de entrenamiento inicial fue de 0.001. En cada época, verificamos el error en el conjunto de entrenamiento. Si el error hubiera aumentado, entonces disminuimos la tasa de entrenamiento, bajo la hipótesis de que la red probablemente se había excedido. La tasa de entrenamiento en cada época se estableció de la siguiente manera: Tasa de entrenamiento = 1+ε κ Donde κ es la tasa inicial (0.001), y ε es el número de veces que el error del conjunto de entrenamiento ha aumentado. Después de cada época, medimos el rendimiento de la red neuronal en el conjunto de validación, utilizando 1 millón de pares (elegidos al azar con reemplazo). La red con la mayor precisión en pares en el conjunto de validación fue seleccionada, y luego probada en el conjunto de pruebas. Informamos la precisión por pares en el conjunto de pruebas, calculada utilizando todos los pares posibles. Estos parámetros fueron determinados y fijados antes de los experimentos de clasificación estática en este artículo. En particular, la elección de la tasa de entrenamiento inicial, el número de épocas y la función de decaimiento de la tasa de entrenamiento se tomaron directamente de Burges et al [7]. Aunque teníamos la opción de preprocesar cualquiera de las características antes de introducirlas en la red neuronal, nos abstuvimos de hacerlo en la mayoría de ellas. La única excepción fueron las características de popularidad. Como ocurre con la mayoría de los fenómenos web, descubrimos que la distribución de la popularidad de los sitios es Zipfiana. Para reducir el rango dinámico, y con suerte hacer que la característica sea más útil, presentamos a la red tanto las características de popularidad sin procesar, como el logaritmo de las mismas (Al igual que con las demás, los valores de las características logarítmicas también se normalizaron para tener media cero y desviación estándar unitaria). Aplicar fRank a un documento es computacionalmente eficiente, tomando un tiempo que es solo lineal en el número de características de entrada; por lo tanto, está dentro de un factor constante de otros métodos de aprendizaje automático simples como el Bayes ingenuo. En nuestros experimentos, calcular el fRank para las cinco mil millones de páginas web fue aproximadamente 100 veces más rápido que calcular el PageRank para el mismo conjunto. 5.4 Resultados Como muestra la Tabla 1, el fRank supera significativamente al PageRank para los propósitos de clasificación estática. Con una precisión de pares del 67.4%, fRank más que duplica la precisión de PageRank (en relación con la línea base del 50%, que es la precisión que se lograría con un orden aleatorio de páginas web). Ten en cuenta que una de las características de entrada de fRanks es el PageRank de la página, por lo que esperaríamos que su rendimiento no fuera peor que el de PageRank. El aumento significativo en precisión implica que las otras características (anclaje, popularidad, etc.) de hecho contienen información útil sobre la calidad general de una página. Tabla 1: Resultados Básicos Técnica Precisión (%) Ninguna (Línea base) 50.00 PageRank 56.70 fRank 67.43 Existen varias decisiones que intervienen en el cálculo de PageRank, como por ejemplo cómo tratar las páginas que no tienen enlaces salientes, la elección de α, la precisión numérica, el umbral de convergencia, etc. Pudimos obtener un cálculo de PageRank a partir de una implementación completamente independiente (proporcionada por Marc Najork) que variaba ligeramente en estos parámetros. Obtuvo una precisión de pares del 56.52%, casi idéntica a la obtenida por nuestra implementación. Por lo tanto, concluimos que la calidad del PageRank no es sensible a estas variaciones menores en el algoritmo, ni la baja precisión de los PageRanks se debió a problemas con nuestra implementación de él. También queríamos averiguar qué tan bien se desempeñaba cada conjunto de características. Para responder a esto, para cada conjunto de características, entrenamos y probamos fRank utilizando solo ese conjunto de características. Los resultados se muestran en la Tabla 2. Como se puede ver, cada conjunto de características individual superó a PageRank en esta prueba. Quizás el resultado más interesante es que las características a nivel de página tuvieron el mejor rendimiento de todos los conjuntos de características. Esto es sorprendente porque estas son características que no dependen de la estructura general del grafo de la Web, ni siquiera de qué páginas apuntan a una página dada. Esto va en contra de la creencia común de que la estructura del grafo web es la clave para encontrar una buena clasificación estática de las páginas web. Tabla 2: Resultados para conjuntos de características individuales. Debido a que estamos utilizando una red neuronal de dos capas, las características en la red aprendida pueden interactuar entre sí de maneras interesantes y no lineales. Esto significa que una característica particular que parece tener poco valor por sí sola podría ser muy importante cuando se utiliza en combinación con otras características. Para medir la contribución final de un conjunto de características, en el contexto de todas las demás características, realizamos un estudio de ablación. Es decir, para cada conjunto de características, entrenamos una red para contener todas las características excepto ese conjunto. Luego comparamos el rendimiento de la red resultante con el rendimiento de la red con todas las características. La Tabla 3 muestra los resultados de este experimento, donde la disminución en la precisión es la diferencia en la precisión por pares entre la red entrenada con todas las características y la red que carece del conjunto de características dado. Tabla 3: Estudio de ablación. Se muestra la disminución en precisión cuando entrenamos una red que tiene todas las características excepto el conjunto dado. La última línea muestra el efecto de eliminar las características del ancla, PageRank y dominio, por lo tanto, un modelo que no contiene ninguna información de red o basada en enlaces. Los resultados del estudio de ablación son consistentes con el estudio de conjunto de características individuales. Ambos muestran que el conjunto de características más importante es el conjunto de características a nivel de página, y el segundo más importante es el conjunto de características de popularidad. Finalmente, deseábamos ver cómo mejoraba el rendimiento de fRank a medida que añadíamos características; queríamos encontrar en qué punto añadir más conjuntos de características se volvía relativamente inútil. Comenzando sin características, añadimos ávidamente el conjunto de características que mejoró el rendimiento en mayor medida. Los resultados se muestran en la Tabla 4. Por ejemplo, la cuarta línea de la tabla muestra que fRank utilizando las características de página, popularidad y anclaje superó a cualquier red que utilizara la página, popularidad y algún otro conjunto de características, y que el rendimiento de esta red fue del 67.25%. Tabla 4: Rendimiento de fRank a medida que se agregan conjuntos de características. En cada fila, se añadió al conjunto de características aquella que proporcionó el mayor aumento en la precisión (es decir, realizamos una búsqueda ávida sobre conjuntos de características). Precisión del conjunto de características (%) Ninguna 50.00 +Página 63.93 +Popularidad 66.83 +Anclaje 67.25 +PageRank 67.31 +Dominio 67.43 711 Finalmente, presentamos una comparación cualitativa de PageRank vs. fRank. En la Tabla 5 se encuentran las diez URL principales devueltas para PageRank y para fRank. Los resultados de PageRank están fuertemente ponderados hacia sitios de tecnología. Contiene dos URL de QuickTime (software de reproducción de video de Apple), así como URL de Internet Explorer y FireFox (ambos navegadores web). Por otro lado, fRank contiene sitios más orientados al consumidor como American Express, Target, Dell, etc. El sesgo de PageRank hacia la tecnología puede explicarse a través de dos procesos. Primero, hay muchas páginas con botones en la parte inferior que sugieren que el sitio está optimizado para Internet Explorer, o que el visitante necesita QuickTime. Estos enlaces generalmente remiten, en estos ejemplos, a los sitios de descarga de Internet Explorer y QuickTime. Por consiguiente, PageRank clasifica esas páginas en posiciones altas. Aunque estas páginas son importantes, no son tan importantes como podría parecer al observar solo la estructura de enlaces. Una solución para esto es agregar información sobre el enlace al cálculo del PageRank, como el tamaño del texto, si estaba en la parte inferior de la página, etc. El otro sesgo proviene del hecho de que la población de autores de sitios web es diferente a la población de usuarios de la web. Los autores web tienden a estar orientados tecnológicamente, por lo que su comportamiento de enlace refleja esos intereses. fRank, al conocer la popularidad real de visitas de un sitio (el conjunto de características de popularidad), puede eliminar parte de ese sesgo. Tiene la capacidad de depender más de dónde visitan los usuarios reales de la Web que de dónde han enlazado los autores del sitio web. Los resultados confirman que fRank supera a PageRank en precisión por pares. Los dos conjuntos de características más importantes son las características de la página y de la popularidad. Esto es sorprendente, ya que las características de la página consistían solo en unas pocas (8) características simples. Experimentos adicionales encontraron que, de las características de la página, aquellas basadas en el texto de la página (en contraposición a la URL) tuvieron el mejor rendimiento. En la siguiente sección, exploramos la característica de popularidad con más detalle. 5.5 Datos de Popularidad Como se mencionó en la sección 4, nuestros datos de popularidad provienen de usuarios de la barra de herramientas de MSN. Por razones de privacidad, solo tuvimos acceso a un recuento agregado de cuántas veces fue visitada cada URL por cualquier usuario de la barra de herramientas. Esto limitó las características posibles que podríamos derivar de estos datos. Para posibles extensiones, consulte la sección 6.3, trabajo futuro. Para cada URL en nuestros conjuntos de entrenamiento y prueba, proporcionamos una característica a fRank que indicaba cuántas veces había sido visitada por un usuario de la barra de herramientas. Sin embargo, esta característica era bastante ruidosa y dispersa, especialmente para URL con parámetros de consulta (por ejemplo, http://search.msn.com/results.aspx?q=machine+learning&form=QBHP). Una solución fue proporcionar una característica adicional que era el número de veces que cualquier URL en el dominio dado fue visitada por un usuario de la barra de herramientas. La adición de esta característica mejoró drásticamente el rendimiento de fRank. Llevamos esto un paso más allá y utilizamos la estructura jerárquica incorporada de las URL para construir varios niveles de retroceso entre la URL completa y el dominio. Lo hicimos utilizando el conjunto de características mostradas en la Tabla 6. Tabla 6: Funciones de URL utilizadas para calcular el conjunto de características de Popularidad. Cada URL fue asignado una característica para cada función mostrada en la tabla. El valor de la característica era el recuento de la cantidad de veces que un usuario de la barra de herramientas visitó una URL, donde la función aplicada a esa URL coincide con la función aplicada a la URL en cuestión. Por ejemplo, la visita de un usuario a cnn.com/2005/sports.html incrementaría las características de Dominio y Dominio+1 para la URL cnn.com/2005/tech/wikipedia.html. Como se observa en la Tabla 7, agregar los recuentos de dominio mejoró significativamente la calidad de la característica de popularidad, y agregar las numerosas funciones de respaldo enumeradas en la Tabla 6 mejoró aún más la precisión. Tabla 7: Efecto de agregar retroceso a la característica de popularidad Conjunto de características Precisión (%) Recuento de URL 58.15 Recuento de URL y dominio 59.31 Todas las funciones de retroceso (Tabla 6) 60.82 Tabla 5: Diez mejores URL para PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Retroceder a subconjuntos de la URL es una técnica para tratar la escasez de datos. También es informativo ver cómo el rendimiento de fRank depende de la cantidad de datos de popularidad que hemos recopilado. En la Figura 1 mostramos el rendimiento de fRank entrenado solo con el conjunto de características de popularidad frente a la cantidad de datos que tenemos para el conjunto de características de popularidad. Cada día recibimos datos adicionales de popularidad, y como se puede ver en el gráfico, esto aumenta el rendimiento de fRank. La relación es logarítmica: duplicar la cantidad de datos de popularidad proporciona una mejora constante en la precisión de pares. En resumen, hemos encontrado que las características de popularidad proporcionan un impulso útil a la precisión general de fRank. Recopilando más datos de popularidad, así como empleando estrategias de retroceso simples, se mejora aún más este impulso. 5.6 Resumen de Resultados Los experimentos proporcionan varias conclusiones. Primero, fRank funciona significativamente mejor que PageRank, incluso sin tener información sobre el grafo web. En segundo lugar, las características a nivel de página y de popularidad fueron los contribuyentes más significativos a la precisión por pares. Tercero, al recopilar más datos de popularidad, podemos seguir mejorando el rendimiento de fRanks. Los datos de popularidad proporcionan dos beneficios a fRank. Primero, observamos que cualitativamente, el ordenamiento de fRanks de las páginas web tiene un sesgo más favorable que PageRanks. El ordenamiento de fRanks parece corresponder a lo que los usuarios de la web, en lugar de los autores de las páginas web, prefieren. Segundo, los datos de popularidad son más actuales que la información de enlaces de PageRank. La barra de herramientas proporciona información sobre qué páginas web encuentran interesantes las personas en este momento, mientras que los enlaces se agregan a las páginas más lentamente, a medida que los autores encuentran el tiempo y el interés. TRABAJO RELACIONADO Y FUTURO 6.1 Mejoras a PageRank Desde el artículo original de PageRank, ha habido trabajos para mejorarlo. Gran parte de ese trabajo se centra en acelerar y paralelizar el cálculo [15][25]. Un problema reconocido con PageRank es el de la deriva de temas: una página sobre perros tendrá un alto PageRank si está vinculada por muchas páginas que a su vez tienen un alto rango, independientemente de su tema. Por el contrario, un usuario de un motor de búsqueda que busca buenas páginas sobre perros probablemente preferiría encontrar páginas que son enlazadas por muchas páginas que tratan sobre perros. Por lo tanto, un enlace que esté relacionado con el tema debería tener más peso que un enlace que no lo esté. Richardson y el PageRank Dependiente de Consulta de Domingos [29] y el PageRank Sensible al Tema de Haveliwala [16] son dos enfoques que abordan este problema. Otras variaciones de PageRank incluyen ponderar de manera diferente los enlaces para enlaces inter e intra-dominio, agregar un paso hacia atrás al surfista aleatorio para simular el botón de retroceso en la mayoría de los navegadores [24] y modificar la probabilidad de salto (α) [3]. Consulte Langville y Meyer [23] para obtener una buena revisión de estas y otras modificaciones a PageRank. 6.2 Otros trabajos relacionados PageRank no es el único algoritmo de análisis de enlaces utilizado para clasificar páginas web. El otro más conocido es HITS [22], que es utilizado por el motor de búsqueda Teoma [30]. HITS produce una lista de hubs y autoridades, donde los hubs son páginas que apuntan a muchas páginas de autoridad, y las autoridades son páginas a las que apuntan muchos hubs. Trabajos anteriores han demostrado que HITS tiene un rendimiento comparable al de PageRank [1]. Un campo de interés es el de la poda de índices estáticos (ver, por ejemplo, Carmel et al. [8]). Los métodos de poda de índices estáticos reducen el tamaño del índice de los motores de búsqueda al eliminar documentos que es poco probable que sean devueltos por una consulta de búsqueda. La poda se realiza típicamente en función de la frecuencia de los términos de consulta. De manera similar, Pandey y Olston [28] sugieren rastrear las páginas con frecuencia si es probable que aparezcan incorrectamente (o no aparezcan) como resultado de una búsqueda. Métodos similares podrían ser incorporados en la clasificación estática (por ejemplo, cuántas consultas frecuentes contienen palabras encontradas en esta página). Otros han investigado el efecto que PageRank tiene en la Web en general [9]. Argumentan que las páginas con un alto PageRank son más propensas a ser encontradas por los usuarios de la web, por lo tanto, es más probable que sean enlazadas y, por ende, mantengan un PageRank más alto que otras páginas. Lo mismo puede ocurrir con los datos de popularidad. Si aumentamos la clasificación de las páginas populares, es más probable que se haga clic en ellas, lo que a su vez aumentará aún más su popularidad. Cho et al. [10] argumentan que una medida más apropiada de la calidad de una página web dependería no solo de la estructura de enlaces actual de la web, sino también de los cambios en esa estructura de enlaces. La misma técnica puede ser aplicable a los datos de popularidad: el cambio en la popularidad de una página puede ser más informativo que la popularidad absoluta. Un trabajo relacionado interesante es el de Ivory y Hearst [19]. Su objetivo era construir un modelo de sitios web que son considerados de alta calidad desde la perspectiva de contenido, estructura y navegación, diseño visual, funcionalidad, interactividad y experiencia general. Utilizaron más de 100 características a nivel de página, así como características que abarcan el rendimiento y la estructura del sitio. Esto les permitió describir cualitativamente las cualidades de una página que la hacen parecer atractiva (por ejemplo, el uso poco común de cursivas, al menos una fuente de 9 puntos, ...), y (en trabajos posteriores) construir un sistema que ayude a los autores de páginas web novedosas a crear páginas de calidad evaluándolas según estas características. Las principales diferencias entre este trabajo y el nuestro son el objetivo (descubrir qué constituye una buena página web vs. ordenar páginas web con fines de búsqueda en la web), el tamaño del estudio (utilizaron un conjunto de datos de menos de 6000 páginas vs. nuestro conjunto de 468,000), y nuestra comparación con PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Días de Datos de la Barra de Herramientas Precisión por Pares Figura 1: Relación entre la cantidad de datos de popularidad y el rendimiento del conjunto de características de popularidad. Ten en cuenta que el eje x es una escala logarítmica. Sin embargo, su trabajo proporciona ideas sobre características estáticas adicionales útiles que podríamos incorporar en fRank en el futuro. El trabajo reciente sobre la incorporación de características novedosas en la clasificación dinámica incluye el realizado por Joachims et al. [21], quienes investigan el uso de retroalimentación implícita de los usuarios, en forma de los resultados de búsqueda en el motor de búsqueda que se hacen clic. Craswell et al. [11] presentan un método para determinar la mejor transformación a aplicar a las características independientes de la consulta (como las utilizadas en este artículo) con el fin de mejorar la clasificación dinámica. Otros trabajos, como el de Boyan et al. [4] y Bartell et al. [2], aplican aprendizaje automático con el propósito de mejorar la relevancia general de un motor de búsqueda (es decir, el ranking dinámico). No aplican sus técnicas al problema de clasificación estática. 6.3 Trabajo futuro Hay muchas formas en las que nos gustaría ampliar este trabajo. Primero, Frank utiliza solo un pequeño número de características. Creemos que podríamos lograr resultados aún más significativos con más características. En particular, la existencia o falta de ciertas palabras podría resultar muy significativa (por ejemplo, \"en construcción\" probablemente signifique una página de baja calidad). Otras características podrían incluir el número de imágenes en una página, el tamaño de esas imágenes, el número de elementos de diseño (tablas, divs y spans), el uso de hojas de estilo, la conformidad con los estándares de W3C (como XHTML 1.0 Strict), el color de fondo de una página, etc. Muchas páginas se generan dinámicamente, cuyos contenidos pueden depender de parámetros en la URL, la hora del día, el usuario que visita el sitio, u otras variables. Para este tipo de páginas, puede ser útil aplicar las técnicas encontradas en [26] para formar una aproximación estática con el fin de extraer características. La gramática resultante que describe la página podría ser en sí misma una fuente de características adicionales que describen la complejidad de la página, como cuántos nodos no terminales tiene, la profundidad del árbol gramatical, etc. fRank permite especificar una confianza en cada emparejamiento de documentos. En el futuro, experimentaremos con probabilidades que dependen de la diferencia en los juicios humanos entre los dos elementos del par. Por ejemplo, un par de documentos donde uno fue calificado con un 4 y el otro con un 0 debería tener una mayor confianza que un par de documentos calificados con un 3 y un 2. Los experimentos en este artículo están sesgados hacia páginas que tienen una calidad superior al promedio. Además, fRank con todas las características solo se puede aplicar a páginas que ya han sido rastreadas. Por lo tanto, fRank es principalmente útil para el ordenamiento de índices y mejorar la relevancia, no para dirigir el rastreo. Nos gustaría investigar un enfoque de aprendizaje automático para la priorización de rastreo también. Puede ser que la mejor opción sea una combinación de métodos: por ejemplo, utilizar PageRank para seleccionar los mejores 5 mil millones de las 20 mil millones de páginas en la web, luego utilizar fRank para ordenar el índice y afectar la relevancia de la búsqueda. Otra dirección interesante para la exploración es incorporar las características de fRank y a nivel de página directamente en el cálculo de PageRank en sí mismo. El trabajo en el sesgo del vector de salto de PageRank [16] y la matriz de transición [29] ha demostrado la viabilidad y ventajas de este enfoque. Existe motivo para creer que una aplicación directa de [29], utilizando el fRank de una página para su relevancia, podría llevar a una mejora en el rango estático general. Finalmente, los datos de popularidad pueden ser utilizados de otras maneras interesantes. Los hábitos generales de navegación y búsqueda de los usuarios de la web varían según la hora del día. La actividad por la mañana, durante el día y en la tarde suele ser bastante diferente (por ejemplo, leer las noticias, resolver problemas y acceder al entretenimiento, respectivamente). Podemos obtener información sobre estas diferencias utilizando los datos de popularidad, divididos en segmentos del día. Cuando se emite una consulta, luego utilizaríamos los datos de popularidad que coincidan con el momento de la consulta para clasificar las páginas web. También planeamos explorar características de popularidad que utilicen más que solo el recuento de cuántas veces se visitó una página. Por ejemplo, cuánto tiempo los usuarios solían permanecer en una página, si abandonaron la página haciendo clic en un enlace o presionando el botón de retroceso, etc. Fox et al. realizaron un estudio que demostró que características como esta pueden ser valiosas para los propósitos de clasificación dinámica [14]. Finalmente, los datos de popularidad podrían ser utilizados como la etiqueta en lugar de como una característica. Utilizar fRank de esta manera para predecir la popularidad de una página puede ser útil para las tareas de relevancia, eficiencia y prioridad de rastreo. También hay significativamente más datos de popularidad que datos etiquetados por humanos, lo que potencialmente permite el uso de métodos de aprendizaje automático más complejos y muchas más características. 7. CONCLUSIONES Un buen ranking estático es un componente importante para los motores de búsqueda y sistemas de recuperación de información actuales. Hemos demostrado que PageRank no proporciona una clasificación estática muy buena; hay muchas características simples que superan individualmente a PageRank. Al combinar muchas características estáticas, fRank logra un ranking que tiene una precisión en pares significativamente mayor que PageRank solo. Una evaluación cualitativa de los documentos principales muestra que fRank está menos sesgado hacia la tecnología que PageRank; al utilizar datos de popularidad, está sesgado hacia las páginas que los usuarios de la web visitan, en lugar de hacia las páginas que los autores web crean. El componente de aprendizaje automático de fRank le otorga el beneficio adicional de ser más robusto contra los spammers, y le permite aprovechar los avances adicionales en la comunidad de aprendizaje automático en áreas como la <br>clasificación adversarial</br>. Hemos comenzado a explorar las opciones y creemos que se pueden lograr avances significativos en el área de clasificación estática mediante experimentación adicional con características adicionales, otras técnicas de aprendizaje automático y fuentes de datos adicionales. AGRADECIMIENTOS Gracias a Marc Najork por proporcionarnos cálculos adicionales de PageRank y a Timo Burkard por su ayuda con los datos de popularidad. Muchas gracias a Chris Burges por proporcionar código y un apoyo significativo en el uso del entrenamiento de RankNets. También agradecemos a Susan Dumais y Nick Craswell por sus ediciones y sugerencias. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2000. [2] B. Bartell, G. Cottrell y R. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la 17ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 1994. [3] P. Boldi, M. Santini y S. Vigna. PageRank como una función del factor de amortiguamiento. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. 714 [4] J. Boyan, D. Freitag y T. Joachims. Una arquitectura de aprendizaje automático para optimizar los motores de búsqueda web. En el taller de AAAI sobre Sistemas de Información Basados en Internet, agosto de 1996. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. En Actas de la Séptima Conferencia Internacional de la World Wide Web, Brisbane, Australia, 1998. Elsevier. [6] A. Broder, R. Lempel, F. Maghoul y J. Pederson. Aproximación eficiente de PageRank a través de la agregación de grafos. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, Bonn, Alemania, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 43-50, Nueva Orleans, Luisiana, EE. UU., septiembre de 2001. [9] J. Cho y S. Roy. Impacto de los motores de búsqueda en la popularidad de las páginas. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [10]J. Cho, S. Roy, R. Adams. Calidad de la página: En busca de una clasificación web imparcial. En las Actas de la Conferencia ACM SIGMOD 2005. Baltimore, Maryland. Junio de 2005. N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Anual sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), agosto de 2005. [12] N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma. Clasificación adversarial. En Actas de la Décima Conferencia Internacional sobre Descubrimiento de Conocimiento y Minería de Datos (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning y Y. Cantante. Modelos log-lineales para clasificación de etiquetas. En Avances en Sistemas de Procesamiento de Información Neural 16. Cambridge, MA: MIT Press, 2003. [14] S. Fox, K. S. Fox, K. Karnawat, M. Mydland, S. T. Dumais y T. White (2005). Evaluando medidas implícitas para mejorar las experiencias de búsqueda. En la revista ACM Transactions on Information Systems, 23(2), pp. 147-168. Abril de 2005. [15] T. Haveliwala. Cálculo eficiente de PageRank. Informe técnico de la Universidad de Stanford, 1999. [16] T. Haveliwala. PageRank sensible al tema. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2002. [17] D. Hawking y N. Craswell. Recuperación a gran escala y búsqueda en la web. En D. Harman y E. Voorhees (eds), El Libro de TREC. MIT Press. [18] R. Herbrich, T. Graepel y K. Obermayer. Aprendizaje de vectores de soporte para regresión ordinal. En Actas de la Novena Conferencia Internacional sobre Redes Neuronales Artificiales, pp. 97-102. 1999. [19] M. Ivory y M. Hearst. Perfiles estadísticos de sitios web altamente valorados. En Actas de la Conferencia ACM SIGCHI sobre Factores Humanos en Sistemas Informáticos, 2002. [20]T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de la Conferencia de la ACM sobre Descubrimiento de Conocimiento y Minería de Datos (KDD), 2002. [21] T. Joachims, L. Granka, B. Pang, H. Hembrooke y G. Gay. Interpretación precisa de los datos de clics como retroalimentación implícita. En Actas de la Conferencia sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2005. [22]J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM 46:5, pp. 604-32. 1999. [23]A. Langville y C. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet 1(3):335-380, 2004. [24] F. Matthieu y M. Bouklit. El efecto del botón de retroceso en un paseo aleatorio: aplicación para PageRank. En los trabajos y pósters de la pista alternativa de la Decimotercera Conferencia Internacional de la World Wide Web, 2004. [25]F. McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [26] Y. Minamide. Aproximación estática de páginas web generadas dinámicamente. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [27] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford, Stanford, CA, 1998. [28] S. Pandey y C. Olston. Rastreo web centrado en el usuario. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [29] M. Richardson y P. Domingos. El surfista inteligente: combinación probabilística de la información de enlaces y contenido en PageRank. En Advances in Neural Information Processing Systems 14, pp. 1441-1448. Cambridge, MA: MIT Press, 2002. [30]C. Sherman.\nCambridge, MA: MIT Press, 2002. [30]C. Sherman. Teoma vs. Google, Ronda 2. Disponible en World Wide Web (http://dc.internet.com/news/article.php/1002061), 2002. [31] T. Upstill, N. Craswell y D. Hawking. Prediciendo fama y fortuna: ¿PageRank o grado de entrada? En el Octavo Simposio de Computación de Documentos Australasiano. 2003. [32] T. Upstill, N. Craswell y D. Hawking. Evidencia independiente de la consulta en la búsqueda de la página de inicio. En ACM Transactions on Information Systems. 2003. 715 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "regression": {
            "translated_key": "regresión",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Beyond PageRank: Machine Learning for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We show that we can significantly outperform PageRank using features that are independent of the link structure of the Web.",
                "We gain a further boost in accuracy by using data on the frequency at which users visit Web pages.",
                "We use RankNet, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random).",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning.",
                "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval.",
                "General Terms Algorithms, Measurement, Performance, Experimentation. 1.",
                "INTRODUCTION Over the past decade, the Web has grown exponentially in size.",
                "Unfortunately, this growth has not been isolated to good-quality pages.",
                "The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly.",
                "The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information.",
                "Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first.",
                "To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking).",
                "However, having a good query-independent ranking (static ranking) is also crucially important for a search engine.",
                "A good static ranking algorithm provides numerous benefits: • Relevance: The static rank of a page provides a general indicator to the overall quality of the page.",
                "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by static rank.",
                "By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found.",
                "The more accurate the static rank, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages.",
                "Among other factors, the static rank of a page is used to determine this prioritization.",
                "A better static rank thus provides the engine with a higher quality, more upto-date index.",
                "Google is often regarded as the first commercially successful search engine.",
                "Their ranking was originally based on the PageRank algorithm [5][27].",
                "Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the static ranking of Web pages.",
                "Though PageRank has historically been thought to perform quite well, there has yet been little academic evidence to support this claim.",
                "Even worse, there has recently been work showing that PageRank may not perform any better than other simple measures on certain tasks.",
                "Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than PageRank [32].",
                "They found similar results for the task of finding high quality companies [31].",
                "PageRank has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17].",
                "Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as PageRank.",
                "Despite these, the general belief remains among many, both academic and in the public, that PageRank is an essential factor for a good static rank.",
                "Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text.",
                "In this paper, we show there are a number of simple url- or pagebased features that significantly outperform PageRank (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web.",
                "We combine these and other static features using machine learning to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels).",
                "A machine learning approach for static ranking has other advantages besides the quality of the ranking.",
                "Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages static rank to an undeserved level through questionable techniques, also known as Web spamming).",
                "This is particularly true if the feature set is not known.",
                "In contrast, a single measure like PageRank can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page.",
                "With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank.",
                "This flexibility allows a ranking system to rapidly react to new spamming techniques.",
                "A machine learning approach to static ranking is also able to take advantage of any advances in the machine learning field.",
                "For example, recent work on adversarial classification [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
                "Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the static rank.",
                "By moving static ranking to a machine learning framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of machine learning.",
                "Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet.",
                "These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful.",
                "For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page.",
                "A machine learning approach thus allows rapid development of a good static algorithm in new domains.",
                "This papers contribution is a systematic study of static features, including PageRank, for the purposes of (statically) ranking Web pages.",
                "Previous studies on PageRank typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages).",
                "Also, the performance of PageRank and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering.",
                "In contrast, we explore the use of PageRank and other features for the direct task of statically ranking Web pages.",
                "We first briefly describe the PageRank algorithm.",
                "In Section 3 we introduce RankNet, the machine learning technique used to combine static features into a final ranking.",
                "Section 4 describes the static features.",
                "The heart of the paper is in Section 5, which presents our experiments and results.",
                "We conclude with a discussion of related and future work. 2.",
                "PAGERANK The basic idea behind PageRank is simple: a link from a Web page to another can be seen as an endorsement of that page.",
                "In general, links are made by people.",
                "As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality.",
                "We can take advantage of this linkage information to order Web pages according to their perceived quality.",
                "Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step.",
                "In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links.",
                "If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j.",
                "The PageRank score for node j is defined as this probability: PR(j)=P(j).",
                "Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform).",
                "The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page.",
                "An alternative view for equation (1) is that each page is assigned a quality, P(j).",
                "A page gives an equal share of its quality to each page it points to.",
                "PageRank is computationally expensive.",
                "Our collection of 5 billion pages contains approximately 370 billion links.",
                "Computing PageRank requires iterating over these billions of links multiple times (until convergence).",
                "It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them.",
                "Though much work has been done on optimizing the PageRank computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3.",
                "RANKNET Much work in machine learning has been done on the problems of classification and <br>regression</br>.",
                "Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi.",
                "The classification problem is to learn a function f that maps yi=f(xi), for all i.",
                "When yi is real-valued as well, this is called <br>regression</br>.",
                "Static ranking can be seen as a <br>regression</br> problem.",
                "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a <br>regression</br> function that mapped each pages features to their rank.",
                "However, this over-constrains the problem we wish to solve.",
                "All we really care about is the order of the pages, not the actual value assigned to them.",
                "Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them.",
                "For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j.",
                "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a <br>regression</br> function, the result of this process is a function (f) that maps feature vectors to real values.",
                "This function can still be applied anywhere that a regressionlearned function could be applied.",
                "The only difference is the technique used to learn the function.",
                "By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do <br>regression</br> techniques.",
                "We used RankNet [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function.",
                "RankNet is a straightforward modification to the standard neural network back-prop algorithm.",
                "As with back-prop, RankNet attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight.",
                "The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the RankNet cost function is based on the difference between a pair of network outputs.",
                "That is, for each pair of feature vectors <i,j> in the training set, RankNet computes the network outputs oi and oj.",
                "Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost.",
                "RankNet also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function).",
                "In this paper, we used a probability of one for all pairs.",
                "In the next section, we will discuss the features used in our feature vectors, xi. 4.",
                "FEATURES To apply RankNet (or other machine learning techniques) to the ranking problem, we needed to extract a set of features from each page.",
                "We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity).",
                "We also optionally used the PageRank of a page as a feature.",
                "Below, we describe each of these feature categories in more detail.",
                "PageRank We computed PageRank on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages).",
                "This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines.",
                "Because PageRank is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible.",
                "Most previous studies on PageRank used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed PageRank using the standard value of 0.85 for α.",
                "Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time.",
                "We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN.",
                "The data is aggregated into a count, for each Web page, of the number of users who viewed that page.",
                "Though popularity data is generally unavailable, there are two other sources for it.",
                "The first is from proxy logs.",
                "For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus.",
                "Unfortunately, proxy data is quite biased and relatively small.",
                "Another source, internal to search engines, are records of which results their users clicked on.",
                "Such data was used by the search engine Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
                "An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search.",
                "The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed.",
                "More details are provided in section 5.5.",
                "Anchor text and inlinks These features are based on the information associated with links to the page in question.",
                "It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc.",
                "Page This category consists of features which may be determined by looking at the page (and its URL) alone.",
                "We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc.",
                "Domain This category contains features that are computed as averages across all pages in the domain.",
                "For example, the average number of outlinks on any page and the average PageRank.",
                "Many of these features have been used by others for ranking Web pages, particularly the anchor and page features.",
                "As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for static ranking.",
                "Also, to our knowledge, this is the first study on the use of actual page visitation popularity for static ranking.",
                "The closest similar work is on using click-through behavior (that is, which search engine results the users click on) to affect dynamic ranking (see e.g., [20]).",
                "Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for feature-based ranking). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages.",
                "Unless otherwise specified, fRank was trained with all of the features. 5.",
                "EXPERIMENTS In this section, we will demonstrate that we can out perform PageRank by applying machine learning to a straightforward set of features.",
                "Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a static ranking, we needed a gold standard defining the correct ordering for a set of pages.",
                "For this, we employed a dataset which contains human judgments for 28000 queries.",
                "For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges.",
                "The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent.",
                "There are approximately 500k judgments in all, or an average of 18 ratings per query.",
                "The queries are selected by randomly choosing queries from among those issued to the MSN search engine.",
                "The probability that a query is selected is proportional to its frequency among all 709 of the queries.",
                "As a result, common queries are more likely to be judged than uncommon queries.",
                "As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture.",
                "The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs search engine).",
                "This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query.",
                "Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries.",
                "This bias is good when evaluating the quality of static ranking for the purposes of index ordering and returning relevant documents.",
                "This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries.",
                "Because of this bias, however, the results in this paper are not applicable to crawl prioritization.",
                "In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages.",
                "To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query.",
                "The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high static rank.",
                "Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query.",
                "We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively.",
                "Each set contains all of the ratings for a given query, and no query appears in more than one set.",
                "The training set was used to train fRank.",
                "The validation set was used to select the model that had the highest performance.",
                "The test set was used for the final results.",
                "This data gives us a query-independent ordering of pages.",
                "The goal for a static ranking algorithm will be to reproduce this ordering as closely as possible.",
                "In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a static ranking.",
                "The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages.",
                "If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of relevance for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
                "First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score).",
                "Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the static rank algorithm orders them correctly. 5.3 Method We trained fRank (a RankNet based neural network) using the following parameters.",
                "We used a fully connected 2 layer network.",
                "The hidden layer had 10 hidden nodes.",
                "The input weights to this layer were all initialized to be zero.",
                "The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1].",
                "We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output.",
                "The cost function is the pairwise cross entropy cost function as discussed in section 3.",
                "The features in the training set were normalized to have zero mean and unit standard deviation.",
                "The same linear transformation was then applied to the features in the validation and test sets.",
                "For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other.",
                "The pairings were chosen uniformly at random (with replacement) from all possible pairings.",
                "When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs.",
                "Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread.",
                "We trained the network for 30 epochs.",
                "On each epoch, the training pairs were randomly shuffled.",
                "The initial training rate was 0.001.",
                "At each epoch, we checked the error on the training set.",
                "If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot.",
                "The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased.",
                "After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement).",
                "The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set.",
                "We report the pairwise accuracy on the test set, calculated using all possible pairs.",
                "These parameters were determined and fixed before the static rank experiments in this paper.",
                "In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7].",
                "Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them.",
                "The only exception was the popularity features.",
                "As with most Web phenomenon, we found that the distribution of site popularity is Zipfian.",
                "To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple machine learning methods such as naïve Bayes.",
                "In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the PageRank for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms PageRank for the purposes of static ranking.",
                "With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of PageRank (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages).",
                "Note that one of fRanks input features is the PageRank of the page, so we would expect it to perform no worse than PageRank.",
                "The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page.",
                "Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 PageRank 56.70 fRank 67.43 There are a number of decisions that go into the computation of PageRank, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc.",
                "We were able to obtain a computation of PageRank from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters.",
                "It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation.",
                "We thus concluded that the quality of the PageRank is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it.",
                "We also wanted to find how well each feature set performed.",
                "To answer this, for each feature set, we trained and tested fRank using only that set of features.",
                "The results are shown in Table 2.",
                "As can be seen, every single feature set individually outperformed PageRank on this test.",
                "Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets.",
                "This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page.",
                "This is contrary to the common belief that the Web graph structure is the key to finding a good static ranking of Web pages.",
                "Table 2: Results for individual feature sets.",
                "Feature Set Accuracy (%) PageRank 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways.",
                "This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features.",
                "To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study.",
                "That is, for each set of features, we trained a network to contain all of the features except that set.",
                "We then compared the performance of the resulting network to the performance of the network with all of the features.",
                "Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set.",
                "Table 3: Ablation study.",
                "Shown is the decrease in accuracy when we train a network that has all but the given set of features.",
                "The last line is shows the effect of removing the anchor, PageRank, and domain features, hence a model containing no network or link-based information whatsoever.",
                "Feature Set Decrease in Accuracy PageRank 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, PageRank & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study.",
                "Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set.",
                "Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless.",
                "Beginning with no features, we greedily added the feature set that improved performance the most.",
                "The results are shown in Table 4.",
                "For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%.",
                "Table 4: fRank performance as feature sets are added.",
                "At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets).",
                "Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +PageRank 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of PageRank vs. fRank.",
                "In Table 5 are the top ten URLs returned for PageRank and for fRank.",
                "PageRanks results are heavily weighted towards technology sites.",
                "It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc.",
                "PageRanks bias toward technology can be explained through two processes.",
                "First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime.",
                "These generally link back to, in these examples, the Internet Explorer and QuickTime download sites.",
                "Consequently, PageRank ranks those pages highly.",
                "Though these pages are important, they are not as important as it may seem by looking at the link structure alone.",
                "One fix for this is to add information about the link to the PageRank computation, such as the size of the text, whether it was at the bottom of the page, etc.",
                "The other bias comes from the fact that the population of Web site authors is different than the population of Web users.",
                "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual visitation popularity of a site (the popularity feature set), is able to eliminate some of that bias.",
                "It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked.",
                "The results confirm that fRank outperforms PageRank in pairwise accuracy.",
                "The two most important feature sets are the page and popularity features.",
                "This is surprising, as the page features consisted only of a few (8) simple features.",
                "Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best.",
                "In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users.",
                "For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user.",
                "This limited the possible features we could derive from this data.",
                "For possible extensions, see section 6.3, future work.",
                "For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user.",
                "However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
                "One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user.",
                "Adding this feature dramatically improved the performance of fRank.",
                "We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain.",
                "We did this by using the set of features shown in Table 6.",
                "Table 6: URL functions used to compute the Popularity feature set.",
                "Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table.",
                "The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question.",
                "For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html.",
                "As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further.",
                "Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data.",
                "It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected.",
                "In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set.",
                "Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank.",
                "The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy.",
                "In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy.",
                "Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions.",
                "First, fRank performs significantly better than PageRank, even without any information about the Web graph.",
                "Second, the page level and popularity features were the most significant contributors to pairwise accuracy.",
                "Third, by collecting more popularity data, we can continue to improve fRanks performance.",
                "The popularity data provides two benefits to fRank.",
                "First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer.",
                "Second, the popularity data is more timely than PageRanks link information.",
                "The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6.",
                "RELATED AND FUTURE WORK 6.1 Improvements to PageRank Since the original PageRank paper, there has been work on improving it.",
                "Much of that work centers on speeding up and parallelizing the computation [15][25].",
                "One recognized problem with PageRank is that of topic drift: A page about dogs will have high PageRank if it is linked to by many pages that themselves have high rank, regardless of their topic.",
                "In contrast, a search engine user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs.",
                "Hence, a link that is on topic should have higher weight than a link that is not.",
                "Richardson and Domingoss Query Dependent PageRank [29] and Haveliwalas Topic-Sensitive PageRank [16] are two approaches that tackle this problem.",
                "Other variations to PageRank include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3].",
                "See Langville and Meyer [23] for a good survey of these, and other modifications to PageRank. 6.2 Other related work PageRank is not the only link analysis algorithm used for ranking Web pages.",
                "The most well-known other is HITS [22], which is used by the Teoma search engine [30].",
                "HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs.",
                "Previous work has shown HITS to perform comparably to PageRank [1].",
                "One field of interest is that of static index pruning (see e.g., Carmel et al. [8]).",
                "Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query.",
                "The pruning is typically done based on the frequency of query terms.",
                "Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search.",
                "Similar methods could be incorporated into the static rank (e.g., how many frequent queries contain words found on this page).",
                "Others have investigated the effect that PageRank has on the Web at large [9].",
                "They argue that pages with high PageRank are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher PageRank than other pages.",
                "The same may occur for the popularity data.",
                "If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity.",
                "Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure.",
                "The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity.",
                "One interesting related work is that of Ivory and Hearst [19].",
                "Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience.",
                "They used over 100 page level features, as well as features encompassing the performance and structure of the site.",
                "This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features.",
                "The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set.",
                "Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future.",
                "Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which search engine results are clicked on.",
                "Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking.",
                "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall relevance of a search engine (i.e., the dynamic ranking).",
                "They do not apply their techniques to the problem of static ranking. 6.3 Future work There are many ways in which we would like to extend this work.",
                "First, fRank uses only a small number of features.",
                "We believe we could achieve even more significant results with more features.",
                "In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page).",
                "Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc.",
                "Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables.",
                "For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features.",
                "The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents.",
                "In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair.",
                "For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2.",
                "The experiments in this paper are biased toward pages that have higher than average quality.",
                "Also, fRank with all of the features can only be applied to pages that have already been crawled.",
                "Thus, fRank is primarily useful for index ordering and improving relevance, not for directing the crawl.",
                "We would like to investigate a machine learning approach for crawl prioritization as well.",
                "It may be that a combination of methods is best: for example, using PageRank to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy.",
                "Another interesting direction for exploration is to incorporate fRank and page-level features directly into the PageRank computation itself.",
                "Work on biasing the PageRank jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach.",
                "There is reason to believe that a direct application of [29], using the fRank of a page for its relevance, could lead to an improved overall static rank.",
                "Finally, the popularity data can be used in other interesting ways.",
                "The general surfing and searching habits of Web users varies by time of day.",
                "Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively).",
                "We can gain insight into these differences by using the popularity data, divided into segments of the day.",
                "When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages.",
                "We also plan to explore popularity features that use more than just the counts of how often a page was visited.",
                "For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc.",
                "Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14].",
                "Finally, the popularity data could be used as the label rather than as a feature.",
                "Using fRank in this way to predict the popularity of a page may useful for the tasks of relevance, efficiency, and crawl priority.",
                "There is also significantly more popularity data than human labeled data, potentially enabling more complex machine learning methods, and significantly more features. 7.",
                "CONCLUSIONS A good static ranking is an important component for todays search engines and information retrieval systems.",
                "We have demonstrated that PageRank does not provide a very good static ranking; there are many simple features that individually out perform PageRank.",
                "By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than PageRank alone.",
                "A qualitative evaluation of the top documents shows that fRank is less technology-biased than PageRank; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit.",
                "The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as adversarial classification.",
                "We have only begun to explore the options, and believe that significant strides can be made in the area of static ranking by further experimentation with additional features, other machine learning techniques, and additional sources of data. 8.",
                "ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional PageRank computations and to Timo Burkard for assistance with the popularity data.",
                "Many thanks to Chris Burges for providing code and significant support in using training RankNets.",
                "Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of Web documents.",
                "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
                "PageRank as a function of the damping factor.",
                "In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims.",
                "A machine learning architecture for optimizing web search engines.",
                "In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998.",
                "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson.",
                "Efficient PageRank approximation via graph aggregation.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the 22nd International Conference on Machine Learning, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy.",
                "Impact of search engines on page popularity.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams.",
                "Page Quality: In search of an unbiased web ranking.",
                "In Proceedings of the ACM SIGMOD 2005 Conference.",
                "Baltimore, Maryland.",
                "June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proceedings of the 28th Annual Conference on Research and Development in Information Retrieval (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
                "Adversarial Classification.",
                "In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y.",
                "Singer.",
                "Log-linear models for label-ranking.",
                "In Advances in Neural Information Processing Systems 16.",
                "Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005).",
                "Evaluating implicit measures to improve the search experiences.",
                "In the ACM Transactions on Information Systems, 23(2), pp. 147-168.",
                "April 2005. [15]T. Haveliwala.",
                "Efficient computation of PageRank.",
                "Stanford University Technical Report, 1999. [16]T. Haveliwala.",
                "Topic-sensitive PageRank.",
                "In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell.",
                "Very large scale retrieval and Web search.",
                "In D. Harman and E. Voorhees (eds), The TREC Book.",
                "MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer.",
                "Support vector learning for ordinal <br>regression</br>.",
                "In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst.",
                "Statistical profiles of highly-rated Web sites.",
                "In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay.",
                "Accurately Interpreting Clickthrough Data as Implicit Feedback.",
                "In Proceedings of the Conference on Research and Development in Information Retrieval (SIGIR), 2005. [22]J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit.",
                "The effect of the back button in a random walk: application for PageRank.",
                "In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry.",
                "A uniform approach to accelerated PageRank computation.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide.",
                "Static approximation of dynamically generated Web pages.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston.",
                "User-centric Web crawling.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos.",
                "The intelligent surfer: probabilistic combination of link and content information in PageRank.",
                "In Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
                "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.",
                "Teoma vs. Google, Round 2.",
                "Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: PageRank or indegree?.",
                "In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking.",
                "Query-independent evidence in home page finding.",
                "In ACM Transactions on Information Systems. 2003. 715"
            ],
            "original_annotated_samples": [
                "RANKNET Much work in machine learning has been done on the problems of classification and <br>regression</br>.",
                "When yi is real-valued as well, this is called <br>regression</br>.",
                "Static ranking can be seen as a <br>regression</br> problem.",
                "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a <br>regression</br> function that mapped each pages features to their rank.",
                "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a <br>regression</br> function, the result of this process is a function (f) that maps feature vectors to real values."
            ],
            "translated_annotated_samples": [
                "RANKNET Se ha realizado mucho trabajo en aprendizaje automático en los problemas de clasificación y <br>regresión</br>.",
                "Cuando yi también es un valor real, esto se llama <br>regresión</br>.",
                "La clasificación estática se puede ver como un <br>problema de regresión</br>.",
                "Si dejamos que xi represente las características de la página i, y yi sea un valor (por ejemplo, el rango) para cada página, podríamos aprender una función de <br>regresión</br> que mapeara las características de cada página a su rango.",
                "El objetivo del problema de clasificación, entonces, es aprender una función f tal que, )()(,, ji ffji xxZ >∈∀ 708. Nótese que, al igual que al aprender una <br>función de regresión</br>, el resultado de este proceso es una función (f) que mapea vectores de características a valores reales."
            ],
            "translated_text": "Más allá de PageRank: Aprendizaje automático para la clasificación estática. Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un motor de búsqueda. Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización. Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. Google es frecuentemente considerado como el primer motor de búsqueda comercialmente exitoso. Su clasificación se basaba originalmente en el algoritmo PageRank [5][27]. Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la clasificación estática de páginas web. Aunque se ha pensado que PageRank ha tenido un buen rendimiento históricamente, todavía hay poca evidencia académica que respalde esta afirmación. Aún peor, recientemente se ha demostrado que PageRank puede no funcionar mejor que otras medidas simples en ciertas tareas. Upstill et al. han encontrado que para la tarea de encontrar páginas de inicio, el número de páginas que enlazan a una página y el tipo de URL fueron tan, o más, efectivos que PageRank [32]. Encontraron resultados similares para la tarea de encontrar empresas de alta calidad [31]. PageRank también se ha utilizado en sistemas para las grandes colecciones de TRECs y competencias de seguimiento web, pero con mucho menos éxito del esperado [17]. Finalmente, Amento et al. [1] encontraron que características simples, como el número de páginas en un sitio, tuvieron un rendimiento tan bueno como PageRank. A pesar de esto, la creencia general persiste entre muchos, tanto académicos como en el público, de que PageRank es un factor esencial para un buen rango estático. En caso de que esto falle, se asume que seguir utilizando la estructura de enlaces es crucial, ya sea en forma del número de enlaces entrantes o la cantidad de texto ancla. En este artículo, demostramos que existen una serie de características simples basadas en URL o en páginas que superan significativamente a PageRank (para el propósito de clasificar estáticamente páginas web) a pesar de ignorar la estructura de la web. Combinamos estas y otras características estáticas utilizando aprendizaje automático para lograr un sistema de clasificación que es significativamente mejor que PageRank (en acuerdo par a par con etiquetas humanas). Un enfoque de aprendizaje automático para la clasificación estática tiene otras ventajas además de la calidad de la clasificación. Debido a que la medida consta de muchas características, es más difícil para los usuarios malintencionados manipularla (es decir, elevar el rango estático de sus páginas a un nivel no merecido a través de técnicas cuestionables, también conocidas como spam en la web). Esto es especialmente cierto si el conjunto de características no se conoce. Por el contrario, una sola medida como PageRank puede ser más fácil de manipular porque los spammers solo necesitan concentrarse en un objetivo: cómo hacer que más páginas apunten a su página. Con un algoritmo que aprende, una característica que se vuelve inutilizable debido a la manipulación de spammers simplemente se reducirá o eliminará del cálculo final de rango. Esta flexibilidad permite que un sistema de clasificación reaccione rápidamente a nuevas técnicas de spam. Un enfoque de aprendizaje automático para la clasificación estática también puede aprovechar cualquier avance en el campo del aprendizaje automático. Por ejemplo, un trabajo reciente sobre clasificación adversarial [12] sugiere que puede ser posible modelar explícitamente las acciones de los spammers de páginas web (el adversario), ajustando el modelo de clasificación de antemano antes de que los spammers intenten evadirlo. Otro ejemplo es la eliminación de valores atípicos al construir el modelo, lo cual ayuda a reducir el efecto que los sitios únicos pueden tener en la calidad general de la clasificación estática. Al trasladar la clasificación estática a un marco de aprendizaje automático, no solo ganamos en precisión, sino también en la capacidad de reaccionar a las acciones de los spammers, de añadir rápidamente nuevas características al algoritmo de clasificación y de aprovechar los avances en el campo en rápido crecimiento del aprendizaje automático. Finalmente, creemos que habrá ventajas significativas al utilizar esta técnica para otros ámbitos, como la búsqueda en un disco duro local o en la intranet de una empresa. Estos son dominios donde la estructura de enlaces es particularmente débil (o inexistente), pero hay otras características específicas del dominio que podrían ser igual de poderosas. Por ejemplo, el autor de una página de intranet y su posición en la organización (por ejemplo, CEO, gerente o desarrollador) podrían proporcionar pistas significativas sobre la importancia de esa página. Un enfoque de aprendizaje automático permite el desarrollo rápido de un buen algoritmo estático en nuevos dominios. La contribución de este artículo es un estudio sistemático de las características estáticas, incluido PageRank, con el propósito de clasificar páginas web de forma estática. Estudios previos sobre PageRank típicamente utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Además, el rendimiento de PageRank y otras características estáticas suele evaluarse en el contexto de un sistema completo para la clasificación dinámica, o para otras tareas como la respuesta a preguntas. Por el contrario, exploramos el uso de PageRank y otras características para la tarea directa de clasificar estáticamente las páginas web. Primero describimos brevemente el algoritmo PageRank. En la Sección 3 presentamos RankNet, la técnica de aprendizaje automático utilizada para combinar las características estáticas en un ranking final. La sección 4 describe las características estáticas. El corazón del documento está en la Sección 5, la cual presenta nuestros experimentos y resultados. Concluimos con una discusión sobre el trabajo relacionado y futuro. 2. PAGERANK La idea básica detrás de PageRank es simple: un enlace de una página web a otra puede ser visto como un respaldo de esa página. En general, los enlaces son creados por personas. Por lo tanto, son indicativos de la calidad de las páginas a las que apuntan: al crear una página, un autor presumiblemente elige enlazar a páginas consideradas de buena calidad. Podemos aprovechar esta información de enlace para ordenar las páginas web según su calidad percibida. Imagina a un internauta que salta de página web en página web, eligiendo con probabilidad uniforme qué enlace seguir en cada paso. Para reducir el efecto de los callejones sin salida o ciclos interminables, el surfista saltará ocasionalmente a una página aleatoria con una pequeña probabilidad α, o cuando se encuentre en una página sin enlaces de salida. Si se promedia sobre un número suficiente de pasos, la probabilidad de que el surfista esté en la página j en algún momento en el tiempo está dada por la fórmula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Donde Fi es el conjunto de páginas a las que enlaza la página i, y Bj es el conjunto de páginas que enlazan a la página j. El puntaje de PageRank para el nodo j se define como esta probabilidad: PR(j)=P(j). Dado que la ecuación (1) es recursiva, debe evaluarse de forma iterativa hasta que P(j) converja (normalmente, la distribución inicial para P(j) es uniforme). La intuición es que, dado que un navegante aleatorio llegaría a la página con más frecuencia, es probable que sea una página mejor. Una vista alternativa para la ecuación (1) es que a cada página se le asigna una calidad, P(j). Una página otorga una parte igual de su calidad a cada página a la que apunta. PageRank es computacionalmente costoso. Nuestra colección de 5 mil millones de páginas contiene aproximadamente 370 mil millones de enlaces. Calcular el PageRank requiere iterar sobre miles de millones de enlaces varias veces (hasta converger). Requiere grandes cantidades de memoria (o esquemas de almacenamiento en caché muy inteligentes que ralentizan aún más el cálculo), y si se distribuye en múltiples máquinas, requiere una comunicación significativa entre ellas. Aunque se ha realizado mucho trabajo en la optimización del cálculo del PageRank (ver, por ejemplo, [25] y [6]), sigue siendo una propiedad relativamente lenta y costosa computacionalmente de calcular. 3. RANKNET Se ha realizado mucho trabajo en aprendizaje automático en los problemas de clasificación y <br>regresión</br>. Sea X={xi} una colección de vectores de características (típicamente, una característica es cualquier número real), y Y={yi} una colección de clases asociadas, donde yi es la clase del objeto descrito por el vector de características xi. El problema de clasificación consiste en aprender una función f que mapea yi=f(xi), para todo i. Cuando yi también es un valor real, esto se llama <br>regresión</br>. La clasificación estática se puede ver como un <br>problema de regresión</br>. Si dejamos que xi represente las características de la página i, y yi sea un valor (por ejemplo, el rango) para cada página, podríamos aprender una función de <br>regresión</br> que mapeara las características de cada página a su rango. Sin embargo, esto sobrecarga el problema que deseamos resolver. Todo lo que realmente nos importa es el orden de las páginas, no el valor real asignado a ellas. El trabajo reciente sobre este problema de clasificación [7][13][18] intenta directamente optimizar el orden de los objetos, en lugar del valor asignado a ellos. Para esto, sea Z={<i,j>} una colección de pares de elementos, donde el elemento i debe ser asignado un valor más alto que el elemento j. El objetivo del problema de clasificación, entonces, es aprender una función f tal que, )()(,, ji ffji xxZ >∈∀ 708. Nótese que, al igual que al aprender una <br>función de regresión</br>, el resultado de este proceso es una función (f) que mapea vectores de características a valores reales. ",
            "candidates": [],
            "error": [
                [
                    "regresión",
                    "regresión",
                    "problema de regresión",
                    "regresión",
                    "función de regresión"
                ]
            ]
        },
        "relevance": {
            "translated_key": "relevancia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Beyond PageRank: Machine Learning for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We show that we can significantly outperform PageRank using features that are independent of the link structure of the Web.",
                "We gain a further boost in accuracy by using data on the frequency at which users visit Web pages.",
                "We use RankNet, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random).",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning.",
                "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval.",
                "General Terms Algorithms, Measurement, Performance, Experimentation. 1.",
                "INTRODUCTION Over the past decade, the Web has grown exponentially in size.",
                "Unfortunately, this growth has not been isolated to good-quality pages.",
                "The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly.",
                "The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information.",
                "Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first.",
                "To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking).",
                "However, having a good query-independent ranking (static ranking) is also crucially important for a search engine.",
                "A good static ranking algorithm provides numerous benefits: • <br>relevance</br>: The static rank of a page provides a general indicator to the overall quality of the page.",
                "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by static rank.",
                "By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found.",
                "The more accurate the static rank, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages.",
                "Among other factors, the static rank of a page is used to determine this prioritization.",
                "A better static rank thus provides the engine with a higher quality, more upto-date index.",
                "Google is often regarded as the first commercially successful search engine.",
                "Their ranking was originally based on the PageRank algorithm [5][27].",
                "Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the static ranking of Web pages.",
                "Though PageRank has historically been thought to perform quite well, there has yet been little academic evidence to support this claim.",
                "Even worse, there has recently been work showing that PageRank may not perform any better than other simple measures on certain tasks.",
                "Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than PageRank [32].",
                "They found similar results for the task of finding high quality companies [31].",
                "PageRank has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17].",
                "Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as PageRank.",
                "Despite these, the general belief remains among many, both academic and in the public, that PageRank is an essential factor for a good static rank.",
                "Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text.",
                "In this paper, we show there are a number of simple url- or pagebased features that significantly outperform PageRank (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web.",
                "We combine these and other static features using machine learning to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels).",
                "A machine learning approach for static ranking has other advantages besides the quality of the ranking.",
                "Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages static rank to an undeserved level through questionable techniques, also known as Web spamming).",
                "This is particularly true if the feature set is not known.",
                "In contrast, a single measure like PageRank can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page.",
                "With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank.",
                "This flexibility allows a ranking system to rapidly react to new spamming techniques.",
                "A machine learning approach to static ranking is also able to take advantage of any advances in the machine learning field.",
                "For example, recent work on adversarial classification [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
                "Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the static rank.",
                "By moving static ranking to a machine learning framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of machine learning.",
                "Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet.",
                "These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful.",
                "For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page.",
                "A machine learning approach thus allows rapid development of a good static algorithm in new domains.",
                "This papers contribution is a systematic study of static features, including PageRank, for the purposes of (statically) ranking Web pages.",
                "Previous studies on PageRank typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages).",
                "Also, the performance of PageRank and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering.",
                "In contrast, we explore the use of PageRank and other features for the direct task of statically ranking Web pages.",
                "We first briefly describe the PageRank algorithm.",
                "In Section 3 we introduce RankNet, the machine learning technique used to combine static features into a final ranking.",
                "Section 4 describes the static features.",
                "The heart of the paper is in Section 5, which presents our experiments and results.",
                "We conclude with a discussion of related and future work. 2.",
                "PAGERANK The basic idea behind PageRank is simple: a link from a Web page to another can be seen as an endorsement of that page.",
                "In general, links are made by people.",
                "As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality.",
                "We can take advantage of this linkage information to order Web pages according to their perceived quality.",
                "Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step.",
                "In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links.",
                "If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j.",
                "The PageRank score for node j is defined as this probability: PR(j)=P(j).",
                "Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform).",
                "The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page.",
                "An alternative view for equation (1) is that each page is assigned a quality, P(j).",
                "A page gives an equal share of its quality to each page it points to.",
                "PageRank is computationally expensive.",
                "Our collection of 5 billion pages contains approximately 370 billion links.",
                "Computing PageRank requires iterating over these billions of links multiple times (until convergence).",
                "It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them.",
                "Though much work has been done on optimizing the PageRank computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3.",
                "RANKNET Much work in machine learning has been done on the problems of classification and regression.",
                "Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi.",
                "The classification problem is to learn a function f that maps yi=f(xi), for all i.",
                "When yi is real-valued as well, this is called regression.",
                "Static ranking can be seen as a regression problem.",
                "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a regression function that mapped each pages features to their rank.",
                "However, this over-constrains the problem we wish to solve.",
                "All we really care about is the order of the pages, not the actual value assigned to them.",
                "Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them.",
                "For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j.",
                "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a regression function, the result of this process is a function (f) that maps feature vectors to real values.",
                "This function can still be applied anywhere that a regressionlearned function could be applied.",
                "The only difference is the technique used to learn the function.",
                "By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do regression techniques.",
                "We used RankNet [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function.",
                "RankNet is a straightforward modification to the standard neural network back-prop algorithm.",
                "As with back-prop, RankNet attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight.",
                "The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the RankNet cost function is based on the difference between a pair of network outputs.",
                "That is, for each pair of feature vectors <i,j> in the training set, RankNet computes the network outputs oi and oj.",
                "Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost.",
                "RankNet also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function).",
                "In this paper, we used a probability of one for all pairs.",
                "In the next section, we will discuss the features used in our feature vectors, xi. 4.",
                "FEATURES To apply RankNet (or other machine learning techniques) to the ranking problem, we needed to extract a set of features from each page.",
                "We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity).",
                "We also optionally used the PageRank of a page as a feature.",
                "Below, we describe each of these feature categories in more detail.",
                "PageRank We computed PageRank on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages).",
                "This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines.",
                "Because PageRank is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible.",
                "Most previous studies on PageRank used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed PageRank using the standard value of 0.85 for α.",
                "Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time.",
                "We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN.",
                "The data is aggregated into a count, for each Web page, of the number of users who viewed that page.",
                "Though popularity data is generally unavailable, there are two other sources for it.",
                "The first is from proxy logs.",
                "For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus.",
                "Unfortunately, proxy data is quite biased and relatively small.",
                "Another source, internal to search engines, are records of which results their users clicked on.",
                "Such data was used by the search engine Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
                "An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search.",
                "The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed.",
                "More details are provided in section 5.5.",
                "Anchor text and inlinks These features are based on the information associated with links to the page in question.",
                "It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc.",
                "Page This category consists of features which may be determined by looking at the page (and its URL) alone.",
                "We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc.",
                "Domain This category contains features that are computed as averages across all pages in the domain.",
                "For example, the average number of outlinks on any page and the average PageRank.",
                "Many of these features have been used by others for ranking Web pages, particularly the anchor and page features.",
                "As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for static ranking.",
                "Also, to our knowledge, this is the first study on the use of actual page visitation popularity for static ranking.",
                "The closest similar work is on using click-through behavior (that is, which search engine results the users click on) to affect dynamic ranking (see e.g., [20]).",
                "Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for feature-based ranking). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages.",
                "Unless otherwise specified, fRank was trained with all of the features. 5.",
                "EXPERIMENTS In this section, we will demonstrate that we can out perform PageRank by applying machine learning to a straightforward set of features.",
                "Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a static ranking, we needed a gold standard defining the correct ordering for a set of pages.",
                "For this, we employed a dataset which contains human judgments for 28000 queries.",
                "For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges.",
                "The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent.",
                "There are approximately 500k judgments in all, or an average of 18 ratings per query.",
                "The queries are selected by randomly choosing queries from among those issued to the MSN search engine.",
                "The probability that a query is selected is proportional to its frequency among all 709 of the queries.",
                "As a result, common queries are more likely to be judged than uncommon queries.",
                "As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture.",
                "The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs search engine).",
                "This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query.",
                "Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries.",
                "This bias is good when evaluating the quality of static ranking for the purposes of index ordering and returning relevant documents.",
                "This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries.",
                "Because of this bias, however, the results in this paper are not applicable to crawl prioritization.",
                "In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages.",
                "To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query.",
                "The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high static rank.",
                "Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query.",
                "We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively.",
                "Each set contains all of the ratings for a given query, and no query appears in more than one set.",
                "The training set was used to train fRank.",
                "The validation set was used to select the model that had the highest performance.",
                "The test set was used for the final results.",
                "This data gives us a query-independent ordering of pages.",
                "The goal for a static ranking algorithm will be to reproduce this ordering as closely as possible.",
                "In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a static ranking.",
                "The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages.",
                "If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of <br>relevance</br> for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
                "First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score).",
                "Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the static rank algorithm orders them correctly. 5.3 Method We trained fRank (a RankNet based neural network) using the following parameters.",
                "We used a fully connected 2 layer network.",
                "The hidden layer had 10 hidden nodes.",
                "The input weights to this layer were all initialized to be zero.",
                "The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1].",
                "We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output.",
                "The cost function is the pairwise cross entropy cost function as discussed in section 3.",
                "The features in the training set were normalized to have zero mean and unit standard deviation.",
                "The same linear transformation was then applied to the features in the validation and test sets.",
                "For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other.",
                "The pairings were chosen uniformly at random (with replacement) from all possible pairings.",
                "When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs.",
                "Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread.",
                "We trained the network for 30 epochs.",
                "On each epoch, the training pairs were randomly shuffled.",
                "The initial training rate was 0.001.",
                "At each epoch, we checked the error on the training set.",
                "If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot.",
                "The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased.",
                "After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement).",
                "The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set.",
                "We report the pairwise accuracy on the test set, calculated using all possible pairs.",
                "These parameters were determined and fixed before the static rank experiments in this paper.",
                "In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7].",
                "Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them.",
                "The only exception was the popularity features.",
                "As with most Web phenomenon, we found that the distribution of site popularity is Zipfian.",
                "To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple machine learning methods such as naïve Bayes.",
                "In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the PageRank for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms PageRank for the purposes of static ranking.",
                "With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of PageRank (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages).",
                "Note that one of fRanks input features is the PageRank of the page, so we would expect it to perform no worse than PageRank.",
                "The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page.",
                "Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 PageRank 56.70 fRank 67.43 There are a number of decisions that go into the computation of PageRank, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc.",
                "We were able to obtain a computation of PageRank from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters.",
                "It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation.",
                "We thus concluded that the quality of the PageRank is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it.",
                "We also wanted to find how well each feature set performed.",
                "To answer this, for each feature set, we trained and tested fRank using only that set of features.",
                "The results are shown in Table 2.",
                "As can be seen, every single feature set individually outperformed PageRank on this test.",
                "Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets.",
                "This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page.",
                "This is contrary to the common belief that the Web graph structure is the key to finding a good static ranking of Web pages.",
                "Table 2: Results for individual feature sets.",
                "Feature Set Accuracy (%) PageRank 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways.",
                "This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features.",
                "To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study.",
                "That is, for each set of features, we trained a network to contain all of the features except that set.",
                "We then compared the performance of the resulting network to the performance of the network with all of the features.",
                "Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set.",
                "Table 3: Ablation study.",
                "Shown is the decrease in accuracy when we train a network that has all but the given set of features.",
                "The last line is shows the effect of removing the anchor, PageRank, and domain features, hence a model containing no network or link-based information whatsoever.",
                "Feature Set Decrease in Accuracy PageRank 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, PageRank & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study.",
                "Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set.",
                "Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless.",
                "Beginning with no features, we greedily added the feature set that improved performance the most.",
                "The results are shown in Table 4.",
                "For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%.",
                "Table 4: fRank performance as feature sets are added.",
                "At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets).",
                "Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +PageRank 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of PageRank vs. fRank.",
                "In Table 5 are the top ten URLs returned for PageRank and for fRank.",
                "PageRanks results are heavily weighted towards technology sites.",
                "It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc.",
                "PageRanks bias toward technology can be explained through two processes.",
                "First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime.",
                "These generally link back to, in these examples, the Internet Explorer and QuickTime download sites.",
                "Consequently, PageRank ranks those pages highly.",
                "Though these pages are important, they are not as important as it may seem by looking at the link structure alone.",
                "One fix for this is to add information about the link to the PageRank computation, such as the size of the text, whether it was at the bottom of the page, etc.",
                "The other bias comes from the fact that the population of Web site authors is different than the population of Web users.",
                "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual visitation popularity of a site (the popularity feature set), is able to eliminate some of that bias.",
                "It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked.",
                "The results confirm that fRank outperforms PageRank in pairwise accuracy.",
                "The two most important feature sets are the page and popularity features.",
                "This is surprising, as the page features consisted only of a few (8) simple features.",
                "Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best.",
                "In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users.",
                "For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user.",
                "This limited the possible features we could derive from this data.",
                "For possible extensions, see section 6.3, future work.",
                "For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user.",
                "However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
                "One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user.",
                "Adding this feature dramatically improved the performance of fRank.",
                "We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain.",
                "We did this by using the set of features shown in Table 6.",
                "Table 6: URL functions used to compute the Popularity feature set.",
                "Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table.",
                "The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question.",
                "For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html.",
                "As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further.",
                "Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data.",
                "It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected.",
                "In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set.",
                "Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank.",
                "The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy.",
                "In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy.",
                "Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions.",
                "First, fRank performs significantly better than PageRank, even without any information about the Web graph.",
                "Second, the page level and popularity features were the most significant contributors to pairwise accuracy.",
                "Third, by collecting more popularity data, we can continue to improve fRanks performance.",
                "The popularity data provides two benefits to fRank.",
                "First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer.",
                "Second, the popularity data is more timely than PageRanks link information.",
                "The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6.",
                "RELATED AND FUTURE WORK 6.1 Improvements to PageRank Since the original PageRank paper, there has been work on improving it.",
                "Much of that work centers on speeding up and parallelizing the computation [15][25].",
                "One recognized problem with PageRank is that of topic drift: A page about dogs will have high PageRank if it is linked to by many pages that themselves have high rank, regardless of their topic.",
                "In contrast, a search engine user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs.",
                "Hence, a link that is on topic should have higher weight than a link that is not.",
                "Richardson and Domingoss Query Dependent PageRank [29] and Haveliwalas Topic-Sensitive PageRank [16] are two approaches that tackle this problem.",
                "Other variations to PageRank include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3].",
                "See Langville and Meyer [23] for a good survey of these, and other modifications to PageRank. 6.2 Other related work PageRank is not the only link analysis algorithm used for ranking Web pages.",
                "The most well-known other is HITS [22], which is used by the Teoma search engine [30].",
                "HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs.",
                "Previous work has shown HITS to perform comparably to PageRank [1].",
                "One field of interest is that of static index pruning (see e.g., Carmel et al. [8]).",
                "Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query.",
                "The pruning is typically done based on the frequency of query terms.",
                "Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search.",
                "Similar methods could be incorporated into the static rank (e.g., how many frequent queries contain words found on this page).",
                "Others have investigated the effect that PageRank has on the Web at large [9].",
                "They argue that pages with high PageRank are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher PageRank than other pages.",
                "The same may occur for the popularity data.",
                "If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity.",
                "Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure.",
                "The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity.",
                "One interesting related work is that of Ivory and Hearst [19].",
                "Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience.",
                "They used over 100 page level features, as well as features encompassing the performance and structure of the site.",
                "This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features.",
                "The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set.",
                "Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future.",
                "Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which search engine results are clicked on.",
                "Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking.",
                "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall <br>relevance</br> of a search engine (i.e., the dynamic ranking).",
                "They do not apply their techniques to the problem of static ranking. 6.3 Future work There are many ways in which we would like to extend this work.",
                "First, fRank uses only a small number of features.",
                "We believe we could achieve even more significant results with more features.",
                "In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page).",
                "Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc.",
                "Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables.",
                "For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features.",
                "The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents.",
                "In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair.",
                "For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2.",
                "The experiments in this paper are biased toward pages that have higher than average quality.",
                "Also, fRank with all of the features can only be applied to pages that have already been crawled.",
                "Thus, fRank is primarily useful for index ordering and improving <br>relevance</br>, not for directing the crawl.",
                "We would like to investigate a machine learning approach for crawl prioritization as well.",
                "It may be that a combination of methods is best: for example, using PageRank to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy.",
                "Another interesting direction for exploration is to incorporate fRank and page-level features directly into the PageRank computation itself.",
                "Work on biasing the PageRank jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach.",
                "There is reason to believe that a direct application of [29], using the fRank of a page for its <br>relevance</br>, could lead to an improved overall static rank.",
                "Finally, the popularity data can be used in other interesting ways.",
                "The general surfing and searching habits of Web users varies by time of day.",
                "Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively).",
                "We can gain insight into these differences by using the popularity data, divided into segments of the day.",
                "When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages.",
                "We also plan to explore popularity features that use more than just the counts of how often a page was visited.",
                "For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc.",
                "Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14].",
                "Finally, the popularity data could be used as the label rather than as a feature.",
                "Using fRank in this way to predict the popularity of a page may useful for the tasks of <br>relevance</br>, efficiency, and crawl priority.",
                "There is also significantly more popularity data than human labeled data, potentially enabling more complex machine learning methods, and significantly more features. 7.",
                "CONCLUSIONS A good static ranking is an important component for todays search engines and information retrieval systems.",
                "We have demonstrated that PageRank does not provide a very good static ranking; there are many simple features that individually out perform PageRank.",
                "By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than PageRank alone.",
                "A qualitative evaluation of the top documents shows that fRank is less technology-biased than PageRank; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit.",
                "The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as adversarial classification.",
                "We have only begun to explore the options, and believe that significant strides can be made in the area of static ranking by further experimentation with additional features, other machine learning techniques, and additional sources of data. 8.",
                "ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional PageRank computations and to Timo Burkard for assistance with the popularity data.",
                "Many thanks to Chris Burges for providing code and significant support in using training RankNets.",
                "Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of Web documents.",
                "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
                "PageRank as a function of the damping factor.",
                "In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims.",
                "A machine learning architecture for optimizing web search engines.",
                "In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998.",
                "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson.",
                "Efficient PageRank approximation via graph aggregation.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the 22nd International Conference on Machine Learning, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy.",
                "Impact of search engines on page popularity.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams.",
                "Page Quality: In search of an unbiased web ranking.",
                "In Proceedings of the ACM SIGMOD 2005 Conference.",
                "Baltimore, Maryland.",
                "June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "<br>relevance</br> weighting for query independent evidence.",
                "In Proceedings of the 28th Annual Conference on Research and Development in Information Retrieval (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
                "Adversarial Classification.",
                "In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y.",
                "Singer.",
                "Log-linear models for label-ranking.",
                "In Advances in Neural Information Processing Systems 16.",
                "Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005).",
                "Evaluating implicit measures to improve the search experiences.",
                "In the ACM Transactions on Information Systems, 23(2), pp. 147-168.",
                "April 2005. [15]T. Haveliwala.",
                "Efficient computation of PageRank.",
                "Stanford University Technical Report, 1999. [16]T. Haveliwala.",
                "Topic-sensitive PageRank.",
                "In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell.",
                "Very large scale retrieval and Web search.",
                "In D. Harman and E. Voorhees (eds), The TREC Book.",
                "MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer.",
                "Support vector learning for ordinal regression.",
                "In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst.",
                "Statistical profiles of highly-rated Web sites.",
                "In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay.",
                "Accurately Interpreting Clickthrough Data as Implicit Feedback.",
                "In Proceedings of the Conference on Research and Development in Information Retrieval (SIGIR), 2005. [22]J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit.",
                "The effect of the back button in a random walk: application for PageRank.",
                "In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry.",
                "A uniform approach to accelerated PageRank computation.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide.",
                "Static approximation of dynamically generated Web pages.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston.",
                "User-centric Web crawling.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos.",
                "The intelligent surfer: probabilistic combination of link and content information in PageRank.",
                "In Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
                "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.",
                "Teoma vs. Google, Round 2.",
                "Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: PageRank or indegree?.",
                "In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking.",
                "Query-independent evidence in home page finding.",
                "In ACM Transactions on Information Systems. 2003. 715"
            ],
            "original_annotated_samples": [
                "A good static ranking algorithm provides numerous benefits: • <br>relevance</br>: The static rank of a page provides a general indicator to the overall quality of the page.",
                "If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of <br>relevance</br> for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
                "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall <br>relevance</br> of a search engine (i.e., the dynamic ranking).",
                "Thus, fRank is primarily useful for index ordering and improving <br>relevance</br>, not for directing the crawl.",
                "There is reason to believe that a direct application of [29], using the fRank of a page for its <br>relevance</br>, could lead to an improved overall static rank."
            ],
            "translated_annotated_samples": [
                "Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página.",
                "Si S(x) es la clasificación estática asignada a la página x, y H(x) es el juicio humano de <br>relevancia</br> para x, entonces considera los siguientes conjuntos: )}()(:,{ yHxHyx >=pH y )}()(:,{ ySxSyx >=pS La precisión por pares es la porción de Hp que también está contenida en Sp: p pp H SH ∩ =precisiónpares Esta medida fue elegida por dos razones.",
                "Otros trabajos, como el de Boyan et al. [4] y Bartell et al. [2], aplican aprendizaje automático con el propósito de mejorar la <br>relevancia</br> general de un motor de búsqueda (es decir, el ranking dinámico).",
                "Por lo tanto, fRank es principalmente útil para el ordenamiento de índices y mejorar la <br>relevancia</br>, no para dirigir el rastreo.",
                "Existe motivo para creer que una aplicación directa de [29], utilizando el fRank de una página para su <br>relevancia</br>, podría llevar a una mejora en el rango estático general."
            ],
            "translated_text": "Más allá de PageRank: Aprendizaje automático para la clasificación estática. Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un motor de búsqueda. Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización. Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. Google es frecuentemente considerado como el primer motor de búsqueda comercialmente exitoso. Su clasificación se basaba originalmente en el algoritmo PageRank [5][27]. Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la clasificación estática de páginas web. Aunque se ha pensado que PageRank ha tenido un buen rendimiento históricamente, todavía hay poca evidencia académica que respalde esta afirmación. Aún peor, recientemente se ha demostrado que PageRank puede no funcionar mejor que otras medidas simples en ciertas tareas. Upstill et al. han encontrado que para la tarea de encontrar páginas de inicio, el número de páginas que enlazan a una página y el tipo de URL fueron tan, o más, efectivos que PageRank [32]. Encontraron resultados similares para la tarea de encontrar empresas de alta calidad [31]. PageRank también se ha utilizado en sistemas para las grandes colecciones de TRECs y competencias de seguimiento web, pero con mucho menos éxito del esperado [17]. Finalmente, Amento et al. [1] encontraron que características simples, como el número de páginas en un sitio, tuvieron un rendimiento tan bueno como PageRank. A pesar de esto, la creencia general persiste entre muchos, tanto académicos como en el público, de que PageRank es un factor esencial para un buen rango estático. En caso de que esto falle, se asume que seguir utilizando la estructura de enlaces es crucial, ya sea en forma del número de enlaces entrantes o la cantidad de texto ancla. En este artículo, demostramos que existen una serie de características simples basadas en URL o en páginas que superan significativamente a PageRank (para el propósito de clasificar estáticamente páginas web) a pesar de ignorar la estructura de la web. Combinamos estas y otras características estáticas utilizando aprendizaje automático para lograr un sistema de clasificación que es significativamente mejor que PageRank (en acuerdo par a par con etiquetas humanas). Un enfoque de aprendizaje automático para la clasificación estática tiene otras ventajas además de la calidad de la clasificación. Debido a que la medida consta de muchas características, es más difícil para los usuarios malintencionados manipularla (es decir, elevar el rango estático de sus páginas a un nivel no merecido a través de técnicas cuestionables, también conocidas como spam en la web). Esto es especialmente cierto si el conjunto de características no se conoce. Por el contrario, una sola medida como PageRank puede ser más fácil de manipular porque los spammers solo necesitan concentrarse en un objetivo: cómo hacer que más páginas apunten a su página. Con un algoritmo que aprende, una característica que se vuelve inutilizable debido a la manipulación de spammers simplemente se reducirá o eliminará del cálculo final de rango. Esta flexibilidad permite que un sistema de clasificación reaccione rápidamente a nuevas técnicas de spam. Un enfoque de aprendizaje automático para la clasificación estática también puede aprovechar cualquier avance en el campo del aprendizaje automático. Por ejemplo, un trabajo reciente sobre clasificación adversarial [12] sugiere que puede ser posible modelar explícitamente las acciones de los spammers de páginas web (el adversario), ajustando el modelo de clasificación de antemano antes de que los spammers intenten evadirlo. Otro ejemplo es la eliminación de valores atípicos al construir el modelo, lo cual ayuda a reducir el efecto que los sitios únicos pueden tener en la calidad general de la clasificación estática. Al trasladar la clasificación estática a un marco de aprendizaje automático, no solo ganamos en precisión, sino también en la capacidad de reaccionar a las acciones de los spammers, de añadir rápidamente nuevas características al algoritmo de clasificación y de aprovechar los avances en el campo en rápido crecimiento del aprendizaje automático. Finalmente, creemos que habrá ventajas significativas al utilizar esta técnica para otros ámbitos, como la búsqueda en un disco duro local o en la intranet de una empresa. Estos son dominios donde la estructura de enlaces es particularmente débil (o inexistente), pero hay otras características específicas del dominio que podrían ser igual de poderosas. Por ejemplo, el autor de una página de intranet y su posición en la organización (por ejemplo, CEO, gerente o desarrollador) podrían proporcionar pistas significativas sobre la importancia de esa página. Un enfoque de aprendizaje automático permite el desarrollo rápido de un buen algoritmo estático en nuevos dominios. La contribución de este artículo es un estudio sistemático de las características estáticas, incluido PageRank, con el propósito de clasificar páginas web de forma estática. Estudios previos sobre PageRank típicamente utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Además, el rendimiento de PageRank y otras características estáticas suele evaluarse en el contexto de un sistema completo para la clasificación dinámica, o para otras tareas como la respuesta a preguntas. Por el contrario, exploramos el uso de PageRank y otras características para la tarea directa de clasificar estáticamente las páginas web. Primero describimos brevemente el algoritmo PageRank. En la Sección 3 presentamos RankNet, la técnica de aprendizaje automático utilizada para combinar las características estáticas en un ranking final. La sección 4 describe las características estáticas. El corazón del documento está en la Sección 5, la cual presenta nuestros experimentos y resultados. Concluimos con una discusión sobre el trabajo relacionado y futuro. 2. PAGERANK La idea básica detrás de PageRank es simple: un enlace de una página web a otra puede ser visto como un respaldo de esa página. En general, los enlaces son creados por personas. Por lo tanto, son indicativos de la calidad de las páginas a las que apuntan: al crear una página, un autor presumiblemente elige enlazar a páginas consideradas de buena calidad. Podemos aprovechar esta información de enlace para ordenar las páginas web según su calidad percibida. Imagina a un internauta que salta de página web en página web, eligiendo con probabilidad uniforme qué enlace seguir en cada paso. Para reducir el efecto de los callejones sin salida o ciclos interminables, el surfista saltará ocasionalmente a una página aleatoria con una pequeña probabilidad α, o cuando se encuentre en una página sin enlaces de salida. Si se promedia sobre un número suficiente de pasos, la probabilidad de que el surfista esté en la página j en algún momento en el tiempo está dada por la fórmula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Donde Fi es el conjunto de páginas a las que enlaza la página i, y Bj es el conjunto de páginas que enlazan a la página j. El puntaje de PageRank para el nodo j se define como esta probabilidad: PR(j)=P(j). Dado que la ecuación (1) es recursiva, debe evaluarse de forma iterativa hasta que P(j) converja (normalmente, la distribución inicial para P(j) es uniforme). La intuición es que, dado que un navegante aleatorio llegaría a la página con más frecuencia, es probable que sea una página mejor. Una vista alternativa para la ecuación (1) es que a cada página se le asigna una calidad, P(j). Una página otorga una parte igual de su calidad a cada página a la que apunta. PageRank es computacionalmente costoso. Nuestra colección de 5 mil millones de páginas contiene aproximadamente 370 mil millones de enlaces. Calcular el PageRank requiere iterar sobre miles de millones de enlaces varias veces (hasta converger). Requiere grandes cantidades de memoria (o esquemas de almacenamiento en caché muy inteligentes que ralentizan aún más el cálculo), y si se distribuye en múltiples máquinas, requiere una comunicación significativa entre ellas. Aunque se ha realizado mucho trabajo en la optimización del cálculo del PageRank (ver, por ejemplo, [25] y [6]), sigue siendo una propiedad relativamente lenta y costosa computacionalmente de calcular. 3. RANKNET Se ha realizado mucho trabajo en aprendizaje automático en los problemas de clasificación y regresión. Sea X={xi} una colección de vectores de características (típicamente, una característica es cualquier número real), y Y={yi} una colección de clases asociadas, donde yi es la clase del objeto descrito por el vector de características xi. El problema de clasificación consiste en aprender una función f que mapea yi=f(xi), para todo i. Cuando yi también es un valor real, esto se llama regresión. La clasificación estática se puede ver como un problema de regresión. Si dejamos que xi represente las características de la página i, y yi sea un valor (por ejemplo, el rango) para cada página, podríamos aprender una función de regresión que mapeara las características de cada página a su rango. Sin embargo, esto sobrecarga el problema que deseamos resolver. Todo lo que realmente nos importa es el orden de las páginas, no el valor real asignado a ellas. El trabajo reciente sobre este problema de clasificación [7][13][18] intenta directamente optimizar el orden de los objetos, en lugar del valor asignado a ellos. Para esto, sea Z={<i,j>} una colección de pares de elementos, donde el elemento i debe ser asignado un valor más alto que el elemento j. El objetivo del problema de clasificación, entonces, es aprender una función f tal que, )()(,, ji ffji xxZ >∈∀ 708. Nótese que, al igual que al aprender una función de regresión, el resultado de este proceso es una función (f) que mapea vectores de características a valores reales. Esta función todavía se puede aplicar en cualquier lugar donde se pueda aplicar una función aprendida por regresión. La única diferencia es la técnica utilizada para aprender la función. Al optimizar directamente el orden de los objetos, estos métodos pueden aprender una función que clasifica mejor que las técnicas de regresión. Utilizamos RankNet [7], una de las técnicas mencionadas para aprender funciones de clasificación, para aprender nuestra función de clasificación estática. RankNet es una modificación sencilla del algoritmo de retropropagación de la red neuronal estándar. Al igual que con back-prop, RankNet intenta minimizar el valor de una función de costo ajustando cada peso en la red de acuerdo con el gradiente de la función de costo con respecto a ese peso. La diferencia es que, mientras que una función de costo típica de una red neuronal se basa en la diferencia entre la salida de la red y la salida deseada, la función de costo de RankNet se basa en la diferencia entre un par de salidas de la red. Es decir, para cada par de vectores de características <i,j> en el conjunto de entrenamiento, RankNet calcula las salidas de la red oi y oj. Dado que se supone que el vector i está clasificado más alto que el vector j, cuanto mayor sea oj-oi, mayor será el costo. RankNet también permite que los pares en Z sean ponderados con una confianza (expresada como la probabilidad de que el par cumpla con el ordenamiento inducido por la función de clasificación). En este documento, utilizamos una probabilidad de uno para todos los pares. En la siguiente sección, discutiremos las características utilizadas en nuestros vectores de características, xi. 4. Para aplicar RankNet (u otras técnicas de aprendizaje automático) al problema de clasificación, necesitábamos extraer un conjunto de características de cada página. Dividimos nuestro conjunto de características en cuatro categorías mutuamente excluyentes: a nivel de página (Página), a nivel de dominio (Dominio), texto del enlace y enlaces entrantes (Anclaje) y popularidad (Popularidad). También opcionalmente utilizamos el PageRank de una página como una característica. A continuación, describimos cada una de estas categorías de características con más detalle. Calculamos PageRank en un grafo web de 5 mil millones de páginas rastreadas (y 20 mil millones de URLs conocidas enlazadas por estas páginas). Esto representa una parte significativa de la Web, y es aproximadamente la misma cantidad de páginas que utilizan Google, Yahoo y MSN para sus motores de búsqueda. Dado que PageRank es un algoritmo basado en grafos, es importante que se ejecute en la mayor cantidad posible de subconjuntos de la Web. La mayoría de los estudios previos sobre PageRank utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Calculamos PageRank utilizando el valor estándar de 0.85 para α. Otra característica que utilizamos es la popularidad real de una página web, medida como el número de veces que ha sido visitada por usuarios durante algún período de tiempo. Tenemos acceso a esos datos de usuarios que han instalado la barra de herramientas de MSN y han optado por proporcionarlos a MSN. Los datos se agregan en un recuento, para cada página web, del número de usuarios que vieron esa página. Aunque los datos de popularidad generalmente no están disponibles, hay otras dos fuentes para obtenerlos. El primero es de los registros de proxy. Por ejemplo, una universidad que requiere que sus estudiantes utilicen un proxy tiene un registro de todas las páginas que han visitado mientras están en el campus. Desafortunadamente, los datos de proxy son bastante sesgados y relativamente pequeños. Otra fuente, interna de los motores de búsqueda, son los registros de los resultados en los que hicieron clic sus usuarios. Tales datos fueron utilizados por el motor de búsqueda Direct Hit, y recientemente han sido explorados con fines de clasificación dinámica [20]. Una ventaja de los datos de la barra de herramientas sobre esto es que contiene información sobre las visitas a URL que no son solo el resultado de una búsqueda. La popularidad en bruto se procesa en una serie de características como el número de veces que se visualizó una página y el número de veces que se visualizó cualquier página en el dominio. Se proporcionan más detalles en la sección 5.5. Texto de anclaje e inlinks. Estas características se basan en la información asociada con los enlaces a la página en cuestión. Incluye características como la cantidad total de texto en los enlaces que apuntan a la página (texto de anclaje), el número de palabras únicas en ese texto, etc. Esta categoría consiste en características que pueden ser determinadas solo al observar la página (y su URL). Solo utilizamos ocho características simples como el número de palabras en el cuerpo, la frecuencia del término más común, etc. Este categoría contiene características que se calculan como promedios en todas las páginas del dominio. Por ejemplo, el número promedio de enlaces salientes en cualquier página y el PageRank promedio. Muchas de estas características han sido utilizadas por otros para clasificar páginas web, especialmente las características de anclaje y de la página. Como se mencionó, la evaluación suele ser para clasificación dinámica, y deseamos evaluar su uso para clasificación estática. Además, hasta donde sabemos, este es el primer estudio sobre el uso de la popularidad real de visitas a páginas para la clasificación estática. El trabajo similar más cercano se centra en el uso del comportamiento de clics (es decir, en los resultados de búsqueda en los que los usuarios hacen clic) para afectar la clasificación dinámica (ver, por ejemplo, [20]). Debido a que utilizamos una amplia variedad de características para crear un ranking estático, nos referimos a esto como fRank (para ranking basado en características). fRank utiliza RankNet y el conjunto de características descritas en esta sección para aprender una función de ranking para páginas web. A menos que se especifique lo contrario, fRank fue entrenado con todas las características. 5. EXPERIMENTOS En esta sección, demostraremos que podemos superar a PageRank aplicando aprendizaje automático a un conjunto sencillo de características. Antes de los resultados, primero discutimos los datos, la métrica de rendimiento y el método de entrenamiento. 5.1 Datos Para evaluar la calidad de un ranking estático, necesitábamos un estándar de oro que definiera el orden correcto para un conjunto de páginas. Para esto, empleamos un conjunto de datos que contiene juicios humanos para 28000 consultas. Para cada consulta, un número de resultados son asignados manualmente una calificación, de 0 a 4, por jueces humanos. La calificación está destinada a ser una medida de cuán relevante es el resultado para la consulta, donde 0 significa pobre y 4 significa excelente. Hay aproximadamente 500 mil juicios en total, o un promedio de 18 calificaciones por consulta. Las consultas se seleccionan eligiendo aleatoriamente consultas de entre aquellas emitidas al motor de búsqueda de MSN. La probabilidad de que se seleccione una consulta es proporcional a su frecuencia entre las 709 consultas. Como resultado, es más probable que las consultas comunes sean evaluadas que las consultas poco comunes. Como ejemplo de la diversidad de las consultas, las primeras cuatro consultas en el conjunto de entrenamiento son escuelas de chef, el autódromo de Chicagoland, el club de fans de los Eagles y la cultura turca. Los documentos seleccionados para evaluar son aquellos que esperábamos que, en promedio, fueran razonablemente relevantes (por ejemplo, los diez documentos principales devueltos por el motor de búsqueda de MSN). Esto proporciona significativamente más información que seleccionar documentos al azar en la web, la gran mayoría de los cuales serían irrelevantes para una consulta específica. Debido a este proceso, las páginas evaluadas tienden a ser de mayor calidad que la página promedio en la web, y suelen ser páginas que se devolverán en consultas de búsqueda comunes. Este sesgo es útil al evaluar la calidad de la clasificación estática con el fin de ordenar índices y devolver documentos relevantes. Esto se debe a que la parte más importante del índice que debe estar bien ordenada y ser relevante es la parte que se devuelve con frecuencia para las consultas de búsqueda. Debido a este sesgo, sin embargo, los resultados en este documento no son aplicables a la priorización de rastreo. Para obtener resultados experimentales sobre la priorización de rastreo, necesitaríamos calificaciones de una muestra aleatoria de páginas web. Para convertir los datos de dependientes de la consulta a independientes de la consulta, simplemente eliminamos la consulta, tomando el máximo sobre las evaluaciones para una URL que aparece en más de una consulta. El razonamiento detrás de esto es que una página que es relevante para una consulta y no relevante para otra probablemente sea una buena página y debería tener un alto rango estático. Debido a que evaluamos las páginas en consultas que ocurren con frecuencia, nuestros datos indican el orden correcto del índice y asignan un alto valor a las páginas que probablemente sean relevantes para una consulta común. Asignamos consultas al azar a un conjunto de entrenamiento, validación o prueba, de modo que contuvieran el 84%, 8% y 8% de las consultas, respectivamente. Cada conjunto contiene todas las calificaciones para una consulta dada, y ninguna consulta aparece en más de un conjunto. El conjunto de entrenamiento se utilizó para entrenar fRank. El conjunto de validación se utilizó para seleccionar el modelo que tuvo el mejor rendimiento. El conjunto de pruebas se utilizó para los resultados finales. Estos datos nos proporcionan un ordenamiento de páginas independiente de la consulta. El objetivo de un algoritmo de clasificación estática será reproducir este orden lo más fielmente posible. En la siguiente sección, describimos la medida que utilizamos para evaluar esto. 5.2 Medida Elegimos utilizar la precisión por pares para evaluar la calidad de un ranking estático. La precisión por pares es la fracción de tiempo en la que el algoritmo de clasificación y los jueces humanos están de acuerdo en el ordenamiento de un par de páginas web. Si S(x) es la clasificación estática asignada a la página x, y H(x) es el juicio humano de <br>relevancia</br> para x, entonces considera los siguientes conjuntos: )}()(:,{ yHxHyx >=pH y )}()(:,{ ySxSyx >=pS La precisión por pares es la porción de Hp que también está contenida en Sp: p pp H SH ∩ =precisiónpares Esta medida fue elegida por dos razones. Primero, los juicios humanos discretos proporcionan solo un orden parcial sobre las páginas web, lo que dificulta aplicar una medida como el coeficiente de correlación de orden de rango de Spearman (en la medida de precisión por pares, un par de documentos con el mismo juicio humano no afecta la puntuación). Segundo, la precisión por pares tiene un significado intuitivo: es la fracción de pares de documentos que, cuando los humanos afirman que uno es mejor que el otro, el algoritmo de clasificación estática los ordena correctamente. 5.3 Método Entrenamos fRank (una red neuronal basada en RankNet) utilizando los siguientes parámetros. Utilizamos una red de 2 capas completamente conectadas. La capa oculta tenía 10 nodos ocultos. Los pesos de entrada a esta capa se inicializaron todos en cero. Los pesos de la capa de salida (solo un nodo) se inicializaron utilizando una distribución aleatoria uniforme en el rango [-0.1, 0.1]. Utilizamos la función tangente hiperbólica (tanh) como función de transferencia de las entradas a la capa oculta, y una función lineal de la capa oculta a la salida. La función de costo es la función de costo de entropía cruzada por pares discutida en la sección 3. Las características en el conjunto de entrenamiento fueron normalizadas para tener media cero y desviación estándar unitaria. La misma transformación lineal fue luego aplicada a las características en los conjuntos de validación y prueba. Para el entrenamiento, presentamos a la red neuronal 5 millones de pares de páginas, donde una página tenía una calificación más alta que la otra. Las combinaciones fueron elegidas de forma uniforme al azar (con reemplazo) de todas las combinaciones posibles. Al formar las parejas, ignoramos la magnitud de la diferencia entre las calificaciones (la dispersión de calificaciones) de las dos URL. Por lo tanto, el peso para cada par era constante (uno), y la probabilidad de que se seleccionara un par era independiente de la diferencia de calificación. Entrenamos la red durante 30 épocas. En cada época, los pares de entrenamiento fueron mezclados aleatoriamente. La tasa de entrenamiento inicial fue de 0.001. En cada época, verificamos el error en el conjunto de entrenamiento. Si el error hubiera aumentado, entonces disminuimos la tasa de entrenamiento, bajo la hipótesis de que la red probablemente se había excedido. La tasa de entrenamiento en cada época se estableció de la siguiente manera: Tasa de entrenamiento = 1+ε κ Donde κ es la tasa inicial (0.001), y ε es el número de veces que el error del conjunto de entrenamiento ha aumentado. Después de cada época, medimos el rendimiento de la red neuronal en el conjunto de validación, utilizando 1 millón de pares (elegidos al azar con reemplazo). La red con la mayor precisión en pares en el conjunto de validación fue seleccionada, y luego probada en el conjunto de pruebas. Informamos la precisión por pares en el conjunto de pruebas, calculada utilizando todos los pares posibles. Estos parámetros fueron determinados y fijados antes de los experimentos de clasificación estática en este artículo. En particular, la elección de la tasa de entrenamiento inicial, el número de épocas y la función de decaimiento de la tasa de entrenamiento se tomaron directamente de Burges et al [7]. Aunque teníamos la opción de preprocesar cualquiera de las características antes de introducirlas en la red neuronal, nos abstuvimos de hacerlo en la mayoría de ellas. La única excepción fueron las características de popularidad. Como ocurre con la mayoría de los fenómenos web, descubrimos que la distribución de la popularidad de los sitios es Zipfiana. Para reducir el rango dinámico, y con suerte hacer que la característica sea más útil, presentamos a la red tanto las características de popularidad sin procesar, como el logaritmo de las mismas (Al igual que con las demás, los valores de las características logarítmicas también se normalizaron para tener media cero y desviación estándar unitaria). Aplicar fRank a un documento es computacionalmente eficiente, tomando un tiempo que es solo lineal en el número de características de entrada; por lo tanto, está dentro de un factor constante de otros métodos de aprendizaje automático simples como el Bayes ingenuo. En nuestros experimentos, calcular el fRank para las cinco mil millones de páginas web fue aproximadamente 100 veces más rápido que calcular el PageRank para el mismo conjunto. 5.4 Resultados Como muestra la Tabla 1, el fRank supera significativamente al PageRank para los propósitos de clasificación estática. Con una precisión de pares del 67.4%, fRank más que duplica la precisión de PageRank (en relación con la línea base del 50%, que es la precisión que se lograría con un orden aleatorio de páginas web). Ten en cuenta que una de las características de entrada de fRanks es el PageRank de la página, por lo que esperaríamos que su rendimiento no fuera peor que el de PageRank. El aumento significativo en precisión implica que las otras características (anclaje, popularidad, etc.) de hecho contienen información útil sobre la calidad general de una página. Tabla 1: Resultados Básicos Técnica Precisión (%) Ninguna (Línea base) 50.00 PageRank 56.70 fRank 67.43 Existen varias decisiones que intervienen en el cálculo de PageRank, como por ejemplo cómo tratar las páginas que no tienen enlaces salientes, la elección de α, la precisión numérica, el umbral de convergencia, etc. Pudimos obtener un cálculo de PageRank a partir de una implementación completamente independiente (proporcionada por Marc Najork) que variaba ligeramente en estos parámetros. Obtuvo una precisión de pares del 56.52%, casi idéntica a la obtenida por nuestra implementación. Por lo tanto, concluimos que la calidad del PageRank no es sensible a estas variaciones menores en el algoritmo, ni la baja precisión de los PageRanks se debió a problemas con nuestra implementación de él. También queríamos averiguar qué tan bien se desempeñaba cada conjunto de características. Para responder a esto, para cada conjunto de características, entrenamos y probamos fRank utilizando solo ese conjunto de características. Los resultados se muestran en la Tabla 2. Como se puede ver, cada conjunto de características individual superó a PageRank en esta prueba. Quizás el resultado más interesante es que las características a nivel de página tuvieron el mejor rendimiento de todos los conjuntos de características. Esto es sorprendente porque estas son características que no dependen de la estructura general del grafo de la Web, ni siquiera de qué páginas apuntan a una página dada. Esto va en contra de la creencia común de que la estructura del grafo web es la clave para encontrar una buena clasificación estática de las páginas web. Tabla 2: Resultados para conjuntos de características individuales. Debido a que estamos utilizando una red neuronal de dos capas, las características en la red aprendida pueden interactuar entre sí de maneras interesantes y no lineales. Esto significa que una característica particular que parece tener poco valor por sí sola podría ser muy importante cuando se utiliza en combinación con otras características. Para medir la contribución final de un conjunto de características, en el contexto de todas las demás características, realizamos un estudio de ablación. Es decir, para cada conjunto de características, entrenamos una red para contener todas las características excepto ese conjunto. Luego comparamos el rendimiento de la red resultante con el rendimiento de la red con todas las características. La Tabla 3 muestra los resultados de este experimento, donde la disminución en la precisión es la diferencia en la precisión por pares entre la red entrenada con todas las características y la red que carece del conjunto de características dado. Tabla 3: Estudio de ablación. Se muestra la disminución en precisión cuando entrenamos una red que tiene todas las características excepto el conjunto dado. La última línea muestra el efecto de eliminar las características del ancla, PageRank y dominio, por lo tanto, un modelo que no contiene ninguna información de red o basada en enlaces. Los resultados del estudio de ablación son consistentes con el estudio de conjunto de características individuales. Ambos muestran que el conjunto de características más importante es el conjunto de características a nivel de página, y el segundo más importante es el conjunto de características de popularidad. Finalmente, deseábamos ver cómo mejoraba el rendimiento de fRank a medida que añadíamos características; queríamos encontrar en qué punto añadir más conjuntos de características se volvía relativamente inútil. Comenzando sin características, añadimos ávidamente el conjunto de características que mejoró el rendimiento en mayor medida. Los resultados se muestran en la Tabla 4. Por ejemplo, la cuarta línea de la tabla muestra que fRank utilizando las características de página, popularidad y anclaje superó a cualquier red que utilizara la página, popularidad y algún otro conjunto de características, y que el rendimiento de esta red fue del 67.25%. Tabla 4: Rendimiento de fRank a medida que se agregan conjuntos de características. En cada fila, se añadió al conjunto de características aquella que proporcionó el mayor aumento en la precisión (es decir, realizamos una búsqueda ávida sobre conjuntos de características). Precisión del conjunto de características (%) Ninguna 50.00 +Página 63.93 +Popularidad 66.83 +Anclaje 67.25 +PageRank 67.31 +Dominio 67.43 711 Finalmente, presentamos una comparación cualitativa de PageRank vs. fRank. En la Tabla 5 se encuentran las diez URL principales devueltas para PageRank y para fRank. Los resultados de PageRank están fuertemente ponderados hacia sitios de tecnología. Contiene dos URL de QuickTime (software de reproducción de video de Apple), así como URL de Internet Explorer y FireFox (ambos navegadores web). Por otro lado, fRank contiene sitios más orientados al consumidor como American Express, Target, Dell, etc. El sesgo de PageRank hacia la tecnología puede explicarse a través de dos procesos. Primero, hay muchas páginas con botones en la parte inferior que sugieren que el sitio está optimizado para Internet Explorer, o que el visitante necesita QuickTime. Estos enlaces generalmente remiten, en estos ejemplos, a los sitios de descarga de Internet Explorer y QuickTime. Por consiguiente, PageRank clasifica esas páginas en posiciones altas. Aunque estas páginas son importantes, no son tan importantes como podría parecer al observar solo la estructura de enlaces. Una solución para esto es agregar información sobre el enlace al cálculo del PageRank, como el tamaño del texto, si estaba en la parte inferior de la página, etc. El otro sesgo proviene del hecho de que la población de autores de sitios web es diferente a la población de usuarios de la web. Los autores web tienden a estar orientados tecnológicamente, por lo que su comportamiento de enlace refleja esos intereses. fRank, al conocer la popularidad real de visitas de un sitio (el conjunto de características de popularidad), puede eliminar parte de ese sesgo. Tiene la capacidad de depender más de dónde visitan los usuarios reales de la Web que de dónde han enlazado los autores del sitio web. Los resultados confirman que fRank supera a PageRank en precisión por pares. Los dos conjuntos de características más importantes son las características de la página y de la popularidad. Esto es sorprendente, ya que las características de la página consistían solo en unas pocas (8) características simples. Experimentos adicionales encontraron que, de las características de la página, aquellas basadas en el texto de la página (en contraposición a la URL) tuvieron el mejor rendimiento. En la siguiente sección, exploramos la característica de popularidad con más detalle. 5.5 Datos de Popularidad Como se mencionó en la sección 4, nuestros datos de popularidad provienen de usuarios de la barra de herramientas de MSN. Por razones de privacidad, solo tuvimos acceso a un recuento agregado de cuántas veces fue visitada cada URL por cualquier usuario de la barra de herramientas. Esto limitó las características posibles que podríamos derivar de estos datos. Para posibles extensiones, consulte la sección 6.3, trabajo futuro. Para cada URL en nuestros conjuntos de entrenamiento y prueba, proporcionamos una característica a fRank que indicaba cuántas veces había sido visitada por un usuario de la barra de herramientas. Sin embargo, esta característica era bastante ruidosa y dispersa, especialmente para URL con parámetros de consulta (por ejemplo, http://search.msn.com/results.aspx?q=machine+learning&form=QBHP). Una solución fue proporcionar una característica adicional que era el número de veces que cualquier URL en el dominio dado fue visitada por un usuario de la barra de herramientas. La adición de esta característica mejoró drásticamente el rendimiento de fRank. Llevamos esto un paso más allá y utilizamos la estructura jerárquica incorporada de las URL para construir varios niveles de retroceso entre la URL completa y el dominio. Lo hicimos utilizando el conjunto de características mostradas en la Tabla 6. Tabla 6: Funciones de URL utilizadas para calcular el conjunto de características de Popularidad. Cada URL fue asignado una característica para cada función mostrada en la tabla. El valor de la característica era el recuento de la cantidad de veces que un usuario de la barra de herramientas visitó una URL, donde la función aplicada a esa URL coincide con la función aplicada a la URL en cuestión. Por ejemplo, la visita de un usuario a cnn.com/2005/sports.html incrementaría las características de Dominio y Dominio+1 para la URL cnn.com/2005/tech/wikipedia.html. Como se observa en la Tabla 7, agregar los recuentos de dominio mejoró significativamente la calidad de la característica de popularidad, y agregar las numerosas funciones de respaldo enumeradas en la Tabla 6 mejoró aún más la precisión. Tabla 7: Efecto de agregar retroceso a la característica de popularidad Conjunto de características Precisión (%) Recuento de URL 58.15 Recuento de URL y dominio 59.31 Todas las funciones de retroceso (Tabla 6) 60.82 Tabla 5: Diez mejores URL para PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Retroceder a subconjuntos de la URL es una técnica para tratar la escasez de datos. También es informativo ver cómo el rendimiento de fRank depende de la cantidad de datos de popularidad que hemos recopilado. En la Figura 1 mostramos el rendimiento de fRank entrenado solo con el conjunto de características de popularidad frente a la cantidad de datos que tenemos para el conjunto de características de popularidad. Cada día recibimos datos adicionales de popularidad, y como se puede ver en el gráfico, esto aumenta el rendimiento de fRank. La relación es logarítmica: duplicar la cantidad de datos de popularidad proporciona una mejora constante en la precisión de pares. En resumen, hemos encontrado que las características de popularidad proporcionan un impulso útil a la precisión general de fRank. Recopilando más datos de popularidad, así como empleando estrategias de retroceso simples, se mejora aún más este impulso. 5.6 Resumen de Resultados Los experimentos proporcionan varias conclusiones. Primero, fRank funciona significativamente mejor que PageRank, incluso sin tener información sobre el grafo web. En segundo lugar, las características a nivel de página y de popularidad fueron los contribuyentes más significativos a la precisión por pares. Tercero, al recopilar más datos de popularidad, podemos seguir mejorando el rendimiento de fRanks. Los datos de popularidad proporcionan dos beneficios a fRank. Primero, observamos que cualitativamente, el ordenamiento de fRanks de las páginas web tiene un sesgo más favorable que PageRanks. El ordenamiento de fRanks parece corresponder a lo que los usuarios de la web, en lugar de los autores de las páginas web, prefieren. Segundo, los datos de popularidad son más actuales que la información de enlaces de PageRank. La barra de herramientas proporciona información sobre qué páginas web encuentran interesantes las personas en este momento, mientras que los enlaces se agregan a las páginas más lentamente, a medida que los autores encuentran el tiempo y el interés. TRABAJO RELACIONADO Y FUTURO 6.1 Mejoras a PageRank Desde el artículo original de PageRank, ha habido trabajos para mejorarlo. Gran parte de ese trabajo se centra en acelerar y paralelizar el cálculo [15][25]. Un problema reconocido con PageRank es el de la deriva de temas: una página sobre perros tendrá un alto PageRank si está vinculada por muchas páginas que a su vez tienen un alto rango, independientemente de su tema. Por el contrario, un usuario de un motor de búsqueda que busca buenas páginas sobre perros probablemente preferiría encontrar páginas que son enlazadas por muchas páginas que tratan sobre perros. Por lo tanto, un enlace que esté relacionado con el tema debería tener más peso que un enlace que no lo esté. Richardson y el PageRank Dependiente de Consulta de Domingos [29] y el PageRank Sensible al Tema de Haveliwala [16] son dos enfoques que abordan este problema. Otras variaciones de PageRank incluyen ponderar de manera diferente los enlaces para enlaces inter e intra-dominio, agregar un paso hacia atrás al surfista aleatorio para simular el botón de retroceso en la mayoría de los navegadores [24] y modificar la probabilidad de salto (α) [3]. Consulte Langville y Meyer [23] para obtener una buena revisión de estas y otras modificaciones a PageRank. 6.2 Otros trabajos relacionados PageRank no es el único algoritmo de análisis de enlaces utilizado para clasificar páginas web. El otro más conocido es HITS [22], que es utilizado por el motor de búsqueda Teoma [30]. HITS produce una lista de hubs y autoridades, donde los hubs son páginas que apuntan a muchas páginas de autoridad, y las autoridades son páginas a las que apuntan muchos hubs. Trabajos anteriores han demostrado que HITS tiene un rendimiento comparable al de PageRank [1]. Un campo de interés es el de la poda de índices estáticos (ver, por ejemplo, Carmel et al. [8]). Los métodos de poda de índices estáticos reducen el tamaño del índice de los motores de búsqueda al eliminar documentos que es poco probable que sean devueltos por una consulta de búsqueda. La poda se realiza típicamente en función de la frecuencia de los términos de consulta. De manera similar, Pandey y Olston [28] sugieren rastrear las páginas con frecuencia si es probable que aparezcan incorrectamente (o no aparezcan) como resultado de una búsqueda. Métodos similares podrían ser incorporados en la clasificación estática (por ejemplo, cuántas consultas frecuentes contienen palabras encontradas en esta página). Otros han investigado el efecto que PageRank tiene en la Web en general [9]. Argumentan que las páginas con un alto PageRank son más propensas a ser encontradas por los usuarios de la web, por lo tanto, es más probable que sean enlazadas y, por ende, mantengan un PageRank más alto que otras páginas. Lo mismo puede ocurrir con los datos de popularidad. Si aumentamos la clasificación de las páginas populares, es más probable que se haga clic en ellas, lo que a su vez aumentará aún más su popularidad. Cho et al. [10] argumentan que una medida más apropiada de la calidad de una página web dependería no solo de la estructura de enlaces actual de la web, sino también de los cambios en esa estructura de enlaces. La misma técnica puede ser aplicable a los datos de popularidad: el cambio en la popularidad de una página puede ser más informativo que la popularidad absoluta. Un trabajo relacionado interesante es el de Ivory y Hearst [19]. Su objetivo era construir un modelo de sitios web que son considerados de alta calidad desde la perspectiva de contenido, estructura y navegación, diseño visual, funcionalidad, interactividad y experiencia general. Utilizaron más de 100 características a nivel de página, así como características que abarcan el rendimiento y la estructura del sitio. Esto les permitió describir cualitativamente las cualidades de una página que la hacen parecer atractiva (por ejemplo, el uso poco común de cursivas, al menos una fuente de 9 puntos, ...), y (en trabajos posteriores) construir un sistema que ayude a los autores de páginas web novedosas a crear páginas de calidad evaluándolas según estas características. Las principales diferencias entre este trabajo y el nuestro son el objetivo (descubrir qué constituye una buena página web vs. ordenar páginas web con fines de búsqueda en la web), el tamaño del estudio (utilizaron un conjunto de datos de menos de 6000 páginas vs. nuestro conjunto de 468,000), y nuestra comparación con PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Días de Datos de la Barra de Herramientas Precisión por Pares Figura 1: Relación entre la cantidad de datos de popularidad y el rendimiento del conjunto de características de popularidad. Ten en cuenta que el eje x es una escala logarítmica. Sin embargo, su trabajo proporciona ideas sobre características estáticas adicionales útiles que podríamos incorporar en fRank en el futuro. El trabajo reciente sobre la incorporación de características novedosas en la clasificación dinámica incluye el realizado por Joachims et al. [21], quienes investigan el uso de retroalimentación implícita de los usuarios, en forma de los resultados de búsqueda en el motor de búsqueda que se hacen clic. Craswell et al. [11] presentan un método para determinar la mejor transformación a aplicar a las características independientes de la consulta (como las utilizadas en este artículo) con el fin de mejorar la clasificación dinámica. Otros trabajos, como el de Boyan et al. [4] y Bartell et al. [2], aplican aprendizaje automático con el propósito de mejorar la <br>relevancia</br> general de un motor de búsqueda (es decir, el ranking dinámico). No aplican sus técnicas al problema de clasificación estática. 6.3 Trabajo futuro Hay muchas formas en las que nos gustaría ampliar este trabajo. Primero, Frank utiliza solo un pequeño número de características. Creemos que podríamos lograr resultados aún más significativos con más características. En particular, la existencia o falta de ciertas palabras podría resultar muy significativa (por ejemplo, \"en construcción\" probablemente signifique una página de baja calidad). Otras características podrían incluir el número de imágenes en una página, el tamaño de esas imágenes, el número de elementos de diseño (tablas, divs y spans), el uso de hojas de estilo, la conformidad con los estándares de W3C (como XHTML 1.0 Strict), el color de fondo de una página, etc. Muchas páginas se generan dinámicamente, cuyos contenidos pueden depender de parámetros en la URL, la hora del día, el usuario que visita el sitio, u otras variables. Para este tipo de páginas, puede ser útil aplicar las técnicas encontradas en [26] para formar una aproximación estática con el fin de extraer características. La gramática resultante que describe la página podría ser en sí misma una fuente de características adicionales que describen la complejidad de la página, como cuántos nodos no terminales tiene, la profundidad del árbol gramatical, etc. fRank permite especificar una confianza en cada emparejamiento de documentos. En el futuro, experimentaremos con probabilidades que dependen de la diferencia en los juicios humanos entre los dos elementos del par. Por ejemplo, un par de documentos donde uno fue calificado con un 4 y el otro con un 0 debería tener una mayor confianza que un par de documentos calificados con un 3 y un 2. Los experimentos en este artículo están sesgados hacia páginas que tienen una calidad superior al promedio. Además, fRank con todas las características solo se puede aplicar a páginas que ya han sido rastreadas. Por lo tanto, fRank es principalmente útil para el ordenamiento de índices y mejorar la <br>relevancia</br>, no para dirigir el rastreo. Nos gustaría investigar un enfoque de aprendizaje automático para la priorización de rastreo también. Puede ser que la mejor opción sea una combinación de métodos: por ejemplo, utilizar PageRank para seleccionar los mejores 5 mil millones de las 20 mil millones de páginas en la web, luego utilizar fRank para ordenar el índice y afectar la relevancia de la búsqueda. Otra dirección interesante para la exploración es incorporar las características de fRank y a nivel de página directamente en el cálculo de PageRank en sí mismo. El trabajo en el sesgo del vector de salto de PageRank [16] y la matriz de transición [29] ha demostrado la viabilidad y ventajas de este enfoque. Existe motivo para creer que una aplicación directa de [29], utilizando el fRank de una página para su <br>relevancia</br>, podría llevar a una mejora en el rango estático general. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "visitation popularity": {
            "translated_key": "popularidad real de visitas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Beyond PageRank: Machine Learning for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We show that we can significantly outperform PageRank using features that are independent of the link structure of the Web.",
                "We gain a further boost in accuracy by using data on the frequency at which users visit Web pages.",
                "We use RankNet, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random).",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning.",
                "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval.",
                "General Terms Algorithms, Measurement, Performance, Experimentation. 1.",
                "INTRODUCTION Over the past decade, the Web has grown exponentially in size.",
                "Unfortunately, this growth has not been isolated to good-quality pages.",
                "The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly.",
                "The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information.",
                "Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first.",
                "To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking).",
                "However, having a good query-independent ranking (static ranking) is also crucially important for a search engine.",
                "A good static ranking algorithm provides numerous benefits: • Relevance: The static rank of a page provides a general indicator to the overall quality of the page.",
                "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by static rank.",
                "By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found.",
                "The more accurate the static rank, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages.",
                "Among other factors, the static rank of a page is used to determine this prioritization.",
                "A better static rank thus provides the engine with a higher quality, more upto-date index.",
                "Google is often regarded as the first commercially successful search engine.",
                "Their ranking was originally based on the PageRank algorithm [5][27].",
                "Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the static ranking of Web pages.",
                "Though PageRank has historically been thought to perform quite well, there has yet been little academic evidence to support this claim.",
                "Even worse, there has recently been work showing that PageRank may not perform any better than other simple measures on certain tasks.",
                "Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than PageRank [32].",
                "They found similar results for the task of finding high quality companies [31].",
                "PageRank has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17].",
                "Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as PageRank.",
                "Despite these, the general belief remains among many, both academic and in the public, that PageRank is an essential factor for a good static rank.",
                "Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text.",
                "In this paper, we show there are a number of simple url- or pagebased features that significantly outperform PageRank (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web.",
                "We combine these and other static features using machine learning to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels).",
                "A machine learning approach for static ranking has other advantages besides the quality of the ranking.",
                "Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages static rank to an undeserved level through questionable techniques, also known as Web spamming).",
                "This is particularly true if the feature set is not known.",
                "In contrast, a single measure like PageRank can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page.",
                "With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank.",
                "This flexibility allows a ranking system to rapidly react to new spamming techniques.",
                "A machine learning approach to static ranking is also able to take advantage of any advances in the machine learning field.",
                "For example, recent work on adversarial classification [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
                "Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the static rank.",
                "By moving static ranking to a machine learning framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of machine learning.",
                "Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet.",
                "These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful.",
                "For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page.",
                "A machine learning approach thus allows rapid development of a good static algorithm in new domains.",
                "This papers contribution is a systematic study of static features, including PageRank, for the purposes of (statically) ranking Web pages.",
                "Previous studies on PageRank typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages).",
                "Also, the performance of PageRank and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering.",
                "In contrast, we explore the use of PageRank and other features for the direct task of statically ranking Web pages.",
                "We first briefly describe the PageRank algorithm.",
                "In Section 3 we introduce RankNet, the machine learning technique used to combine static features into a final ranking.",
                "Section 4 describes the static features.",
                "The heart of the paper is in Section 5, which presents our experiments and results.",
                "We conclude with a discussion of related and future work. 2.",
                "PAGERANK The basic idea behind PageRank is simple: a link from a Web page to another can be seen as an endorsement of that page.",
                "In general, links are made by people.",
                "As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality.",
                "We can take advantage of this linkage information to order Web pages according to their perceived quality.",
                "Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step.",
                "In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links.",
                "If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j.",
                "The PageRank score for node j is defined as this probability: PR(j)=P(j).",
                "Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform).",
                "The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page.",
                "An alternative view for equation (1) is that each page is assigned a quality, P(j).",
                "A page gives an equal share of its quality to each page it points to.",
                "PageRank is computationally expensive.",
                "Our collection of 5 billion pages contains approximately 370 billion links.",
                "Computing PageRank requires iterating over these billions of links multiple times (until convergence).",
                "It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them.",
                "Though much work has been done on optimizing the PageRank computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3.",
                "RANKNET Much work in machine learning has been done on the problems of classification and regression.",
                "Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi.",
                "The classification problem is to learn a function f that maps yi=f(xi), for all i.",
                "When yi is real-valued as well, this is called regression.",
                "Static ranking can be seen as a regression problem.",
                "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a regression function that mapped each pages features to their rank.",
                "However, this over-constrains the problem we wish to solve.",
                "All we really care about is the order of the pages, not the actual value assigned to them.",
                "Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them.",
                "For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j.",
                "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a regression function, the result of this process is a function (f) that maps feature vectors to real values.",
                "This function can still be applied anywhere that a regressionlearned function could be applied.",
                "The only difference is the technique used to learn the function.",
                "By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do regression techniques.",
                "We used RankNet [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function.",
                "RankNet is a straightforward modification to the standard neural network back-prop algorithm.",
                "As with back-prop, RankNet attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight.",
                "The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the RankNet cost function is based on the difference between a pair of network outputs.",
                "That is, for each pair of feature vectors <i,j> in the training set, RankNet computes the network outputs oi and oj.",
                "Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost.",
                "RankNet also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function).",
                "In this paper, we used a probability of one for all pairs.",
                "In the next section, we will discuss the features used in our feature vectors, xi. 4.",
                "FEATURES To apply RankNet (or other machine learning techniques) to the ranking problem, we needed to extract a set of features from each page.",
                "We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity).",
                "We also optionally used the PageRank of a page as a feature.",
                "Below, we describe each of these feature categories in more detail.",
                "PageRank We computed PageRank on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages).",
                "This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines.",
                "Because PageRank is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible.",
                "Most previous studies on PageRank used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed PageRank using the standard value of 0.85 for α.",
                "Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time.",
                "We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN.",
                "The data is aggregated into a count, for each Web page, of the number of users who viewed that page.",
                "Though popularity data is generally unavailable, there are two other sources for it.",
                "The first is from proxy logs.",
                "For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus.",
                "Unfortunately, proxy data is quite biased and relatively small.",
                "Another source, internal to search engines, are records of which results their users clicked on.",
                "Such data was used by the search engine Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
                "An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search.",
                "The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed.",
                "More details are provided in section 5.5.",
                "Anchor text and inlinks These features are based on the information associated with links to the page in question.",
                "It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc.",
                "Page This category consists of features which may be determined by looking at the page (and its URL) alone.",
                "We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc.",
                "Domain This category contains features that are computed as averages across all pages in the domain.",
                "For example, the average number of outlinks on any page and the average PageRank.",
                "Many of these features have been used by others for ranking Web pages, particularly the anchor and page features.",
                "As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for static ranking.",
                "Also, to our knowledge, this is the first study on the use of actual page <br>visitation popularity</br> for static ranking.",
                "The closest similar work is on using click-through behavior (that is, which search engine results the users click on) to affect dynamic ranking (see e.g., [20]).",
                "Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for feature-based ranking). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages.",
                "Unless otherwise specified, fRank was trained with all of the features. 5.",
                "EXPERIMENTS In this section, we will demonstrate that we can out perform PageRank by applying machine learning to a straightforward set of features.",
                "Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a static ranking, we needed a gold standard defining the correct ordering for a set of pages.",
                "For this, we employed a dataset which contains human judgments for 28000 queries.",
                "For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges.",
                "The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent.",
                "There are approximately 500k judgments in all, or an average of 18 ratings per query.",
                "The queries are selected by randomly choosing queries from among those issued to the MSN search engine.",
                "The probability that a query is selected is proportional to its frequency among all 709 of the queries.",
                "As a result, common queries are more likely to be judged than uncommon queries.",
                "As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture.",
                "The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs search engine).",
                "This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query.",
                "Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries.",
                "This bias is good when evaluating the quality of static ranking for the purposes of index ordering and returning relevant documents.",
                "This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries.",
                "Because of this bias, however, the results in this paper are not applicable to crawl prioritization.",
                "In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages.",
                "To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query.",
                "The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high static rank.",
                "Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query.",
                "We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively.",
                "Each set contains all of the ratings for a given query, and no query appears in more than one set.",
                "The training set was used to train fRank.",
                "The validation set was used to select the model that had the highest performance.",
                "The test set was used for the final results.",
                "This data gives us a query-independent ordering of pages.",
                "The goal for a static ranking algorithm will be to reproduce this ordering as closely as possible.",
                "In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a static ranking.",
                "The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages.",
                "If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of relevance for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
                "First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score).",
                "Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the static rank algorithm orders them correctly. 5.3 Method We trained fRank (a RankNet based neural network) using the following parameters.",
                "We used a fully connected 2 layer network.",
                "The hidden layer had 10 hidden nodes.",
                "The input weights to this layer were all initialized to be zero.",
                "The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1].",
                "We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output.",
                "The cost function is the pairwise cross entropy cost function as discussed in section 3.",
                "The features in the training set were normalized to have zero mean and unit standard deviation.",
                "The same linear transformation was then applied to the features in the validation and test sets.",
                "For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other.",
                "The pairings were chosen uniformly at random (with replacement) from all possible pairings.",
                "When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs.",
                "Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread.",
                "We trained the network for 30 epochs.",
                "On each epoch, the training pairs were randomly shuffled.",
                "The initial training rate was 0.001.",
                "At each epoch, we checked the error on the training set.",
                "If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot.",
                "The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased.",
                "After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement).",
                "The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set.",
                "We report the pairwise accuracy on the test set, calculated using all possible pairs.",
                "These parameters were determined and fixed before the static rank experiments in this paper.",
                "In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7].",
                "Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them.",
                "The only exception was the popularity features.",
                "As with most Web phenomenon, we found that the distribution of site popularity is Zipfian.",
                "To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple machine learning methods such as naïve Bayes.",
                "In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the PageRank for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms PageRank for the purposes of static ranking.",
                "With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of PageRank (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages).",
                "Note that one of fRanks input features is the PageRank of the page, so we would expect it to perform no worse than PageRank.",
                "The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page.",
                "Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 PageRank 56.70 fRank 67.43 There are a number of decisions that go into the computation of PageRank, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc.",
                "We were able to obtain a computation of PageRank from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters.",
                "It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation.",
                "We thus concluded that the quality of the PageRank is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it.",
                "We also wanted to find how well each feature set performed.",
                "To answer this, for each feature set, we trained and tested fRank using only that set of features.",
                "The results are shown in Table 2.",
                "As can be seen, every single feature set individually outperformed PageRank on this test.",
                "Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets.",
                "This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page.",
                "This is contrary to the common belief that the Web graph structure is the key to finding a good static ranking of Web pages.",
                "Table 2: Results for individual feature sets.",
                "Feature Set Accuracy (%) PageRank 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways.",
                "This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features.",
                "To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study.",
                "That is, for each set of features, we trained a network to contain all of the features except that set.",
                "We then compared the performance of the resulting network to the performance of the network with all of the features.",
                "Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set.",
                "Table 3: Ablation study.",
                "Shown is the decrease in accuracy when we train a network that has all but the given set of features.",
                "The last line is shows the effect of removing the anchor, PageRank, and domain features, hence a model containing no network or link-based information whatsoever.",
                "Feature Set Decrease in Accuracy PageRank 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, PageRank & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study.",
                "Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set.",
                "Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless.",
                "Beginning with no features, we greedily added the feature set that improved performance the most.",
                "The results are shown in Table 4.",
                "For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%.",
                "Table 4: fRank performance as feature sets are added.",
                "At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets).",
                "Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +PageRank 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of PageRank vs. fRank.",
                "In Table 5 are the top ten URLs returned for PageRank and for fRank.",
                "PageRanks results are heavily weighted towards technology sites.",
                "It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc.",
                "PageRanks bias toward technology can be explained through two processes.",
                "First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime.",
                "These generally link back to, in these examples, the Internet Explorer and QuickTime download sites.",
                "Consequently, PageRank ranks those pages highly.",
                "Though these pages are important, they are not as important as it may seem by looking at the link structure alone.",
                "One fix for this is to add information about the link to the PageRank computation, such as the size of the text, whether it was at the bottom of the page, etc.",
                "The other bias comes from the fact that the population of Web site authors is different than the population of Web users.",
                "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual <br>visitation popularity</br> of a site (the popularity feature set), is able to eliminate some of that bias.",
                "It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked.",
                "The results confirm that fRank outperforms PageRank in pairwise accuracy.",
                "The two most important feature sets are the page and popularity features.",
                "This is surprising, as the page features consisted only of a few (8) simple features.",
                "Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best.",
                "In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users.",
                "For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user.",
                "This limited the possible features we could derive from this data.",
                "For possible extensions, see section 6.3, future work.",
                "For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user.",
                "However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
                "One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user.",
                "Adding this feature dramatically improved the performance of fRank.",
                "We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain.",
                "We did this by using the set of features shown in Table 6.",
                "Table 6: URL functions used to compute the Popularity feature set.",
                "Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table.",
                "The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question.",
                "For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html.",
                "As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further.",
                "Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data.",
                "It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected.",
                "In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set.",
                "Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank.",
                "The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy.",
                "In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy.",
                "Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions.",
                "First, fRank performs significantly better than PageRank, even without any information about the Web graph.",
                "Second, the page level and popularity features were the most significant contributors to pairwise accuracy.",
                "Third, by collecting more popularity data, we can continue to improve fRanks performance.",
                "The popularity data provides two benefits to fRank.",
                "First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer.",
                "Second, the popularity data is more timely than PageRanks link information.",
                "The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6.",
                "RELATED AND FUTURE WORK 6.1 Improvements to PageRank Since the original PageRank paper, there has been work on improving it.",
                "Much of that work centers on speeding up and parallelizing the computation [15][25].",
                "One recognized problem with PageRank is that of topic drift: A page about dogs will have high PageRank if it is linked to by many pages that themselves have high rank, regardless of their topic.",
                "In contrast, a search engine user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs.",
                "Hence, a link that is on topic should have higher weight than a link that is not.",
                "Richardson and Domingoss Query Dependent PageRank [29] and Haveliwalas Topic-Sensitive PageRank [16] are two approaches that tackle this problem.",
                "Other variations to PageRank include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3].",
                "See Langville and Meyer [23] for a good survey of these, and other modifications to PageRank. 6.2 Other related work PageRank is not the only link analysis algorithm used for ranking Web pages.",
                "The most well-known other is HITS [22], which is used by the Teoma search engine [30].",
                "HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs.",
                "Previous work has shown HITS to perform comparably to PageRank [1].",
                "One field of interest is that of static index pruning (see e.g., Carmel et al. [8]).",
                "Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query.",
                "The pruning is typically done based on the frequency of query terms.",
                "Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search.",
                "Similar methods could be incorporated into the static rank (e.g., how many frequent queries contain words found on this page).",
                "Others have investigated the effect that PageRank has on the Web at large [9].",
                "They argue that pages with high PageRank are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher PageRank than other pages.",
                "The same may occur for the popularity data.",
                "If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity.",
                "Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure.",
                "The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity.",
                "One interesting related work is that of Ivory and Hearst [19].",
                "Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience.",
                "They used over 100 page level features, as well as features encompassing the performance and structure of the site.",
                "This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features.",
                "The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set.",
                "Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future.",
                "Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which search engine results are clicked on.",
                "Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking.",
                "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall relevance of a search engine (i.e., the dynamic ranking).",
                "They do not apply their techniques to the problem of static ranking. 6.3 Future work There are many ways in which we would like to extend this work.",
                "First, fRank uses only a small number of features.",
                "We believe we could achieve even more significant results with more features.",
                "In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page).",
                "Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc.",
                "Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables.",
                "For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features.",
                "The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents.",
                "In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair.",
                "For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2.",
                "The experiments in this paper are biased toward pages that have higher than average quality.",
                "Also, fRank with all of the features can only be applied to pages that have already been crawled.",
                "Thus, fRank is primarily useful for index ordering and improving relevance, not for directing the crawl.",
                "We would like to investigate a machine learning approach for crawl prioritization as well.",
                "It may be that a combination of methods is best: for example, using PageRank to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy.",
                "Another interesting direction for exploration is to incorporate fRank and page-level features directly into the PageRank computation itself.",
                "Work on biasing the PageRank jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach.",
                "There is reason to believe that a direct application of [29], using the fRank of a page for its relevance, could lead to an improved overall static rank.",
                "Finally, the popularity data can be used in other interesting ways.",
                "The general surfing and searching habits of Web users varies by time of day.",
                "Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively).",
                "We can gain insight into these differences by using the popularity data, divided into segments of the day.",
                "When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages.",
                "We also plan to explore popularity features that use more than just the counts of how often a page was visited.",
                "For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc.",
                "Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14].",
                "Finally, the popularity data could be used as the label rather than as a feature.",
                "Using fRank in this way to predict the popularity of a page may useful for the tasks of relevance, efficiency, and crawl priority.",
                "There is also significantly more popularity data than human labeled data, potentially enabling more complex machine learning methods, and significantly more features. 7.",
                "CONCLUSIONS A good static ranking is an important component for todays search engines and information retrieval systems.",
                "We have demonstrated that PageRank does not provide a very good static ranking; there are many simple features that individually out perform PageRank.",
                "By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than PageRank alone.",
                "A qualitative evaluation of the top documents shows that fRank is less technology-biased than PageRank; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit.",
                "The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as adversarial classification.",
                "We have only begun to explore the options, and believe that significant strides can be made in the area of static ranking by further experimentation with additional features, other machine learning techniques, and additional sources of data. 8.",
                "ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional PageRank computations and to Timo Burkard for assistance with the popularity data.",
                "Many thanks to Chris Burges for providing code and significant support in using training RankNets.",
                "Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of Web documents.",
                "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
                "PageRank as a function of the damping factor.",
                "In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims.",
                "A machine learning architecture for optimizing web search engines.",
                "In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998.",
                "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson.",
                "Efficient PageRank approximation via graph aggregation.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the 22nd International Conference on Machine Learning, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy.",
                "Impact of search engines on page popularity.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams.",
                "Page Quality: In search of an unbiased web ranking.",
                "In Proceedings of the ACM SIGMOD 2005 Conference.",
                "Baltimore, Maryland.",
                "June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proceedings of the 28th Annual Conference on Research and Development in Information Retrieval (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
                "Adversarial Classification.",
                "In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y.",
                "Singer.",
                "Log-linear models for label-ranking.",
                "In Advances in Neural Information Processing Systems 16.",
                "Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005).",
                "Evaluating implicit measures to improve the search experiences.",
                "In the ACM Transactions on Information Systems, 23(2), pp. 147-168.",
                "April 2005. [15]T. Haveliwala.",
                "Efficient computation of PageRank.",
                "Stanford University Technical Report, 1999. [16]T. Haveliwala.",
                "Topic-sensitive PageRank.",
                "In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell.",
                "Very large scale retrieval and Web search.",
                "In D. Harman and E. Voorhees (eds), The TREC Book.",
                "MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer.",
                "Support vector learning for ordinal regression.",
                "In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst.",
                "Statistical profiles of highly-rated Web sites.",
                "In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay.",
                "Accurately Interpreting Clickthrough Data as Implicit Feedback.",
                "In Proceedings of the Conference on Research and Development in Information Retrieval (SIGIR), 2005. [22]J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit.",
                "The effect of the back button in a random walk: application for PageRank.",
                "In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry.",
                "A uniform approach to accelerated PageRank computation.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide.",
                "Static approximation of dynamically generated Web pages.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston.",
                "User-centric Web crawling.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos.",
                "The intelligent surfer: probabilistic combination of link and content information in PageRank.",
                "In Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
                "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.",
                "Teoma vs. Google, Round 2.",
                "Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: PageRank or indegree?.",
                "In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking.",
                "Query-independent evidence in home page finding.",
                "In ACM Transactions on Information Systems. 2003. 715"
            ],
            "original_annotated_samples": [
                "Also, to our knowledge, this is the first study on the use of actual page <br>visitation popularity</br> for static ranking.",
                "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual <br>visitation popularity</br> of a site (the popularity feature set), is able to eliminate some of that bias."
            ],
            "translated_annotated_samples": [
                "Además, hasta donde sabemos, este es el primer estudio sobre el uso de la <br>popularidad real de visitas</br> a páginas para la clasificación estática.",
                "Los autores web tienden a estar orientados tecnológicamente, por lo que su comportamiento de enlace refleja esos intereses. fRank, al conocer la <br>popularidad real de visitas</br> de un sitio (el conjunto de características de popularidad), puede eliminar parte de ese sesgo."
            ],
            "translated_text": "Más allá de PageRank: Aprendizaje automático para la clasificación estática. Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un motor de búsqueda. Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización. Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. Google es frecuentemente considerado como el primer motor de búsqueda comercialmente exitoso. Su clasificación se basaba originalmente en el algoritmo PageRank [5][27]. Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la clasificación estática de páginas web. Aunque se ha pensado que PageRank ha tenido un buen rendimiento históricamente, todavía hay poca evidencia académica que respalde esta afirmación. Aún peor, recientemente se ha demostrado que PageRank puede no funcionar mejor que otras medidas simples en ciertas tareas. Upstill et al. han encontrado que para la tarea de encontrar páginas de inicio, el número de páginas que enlazan a una página y el tipo de URL fueron tan, o más, efectivos que PageRank [32]. Encontraron resultados similares para la tarea de encontrar empresas de alta calidad [31]. PageRank también se ha utilizado en sistemas para las grandes colecciones de TRECs y competencias de seguimiento web, pero con mucho menos éxito del esperado [17]. Finalmente, Amento et al. [1] encontraron que características simples, como el número de páginas en un sitio, tuvieron un rendimiento tan bueno como PageRank. A pesar de esto, la creencia general persiste entre muchos, tanto académicos como en el público, de que PageRank es un factor esencial para un buen rango estático. En caso de que esto falle, se asume que seguir utilizando la estructura de enlaces es crucial, ya sea en forma del número de enlaces entrantes o la cantidad de texto ancla. En este artículo, demostramos que existen una serie de características simples basadas en URL o en páginas que superan significativamente a PageRank (para el propósito de clasificar estáticamente páginas web) a pesar de ignorar la estructura de la web. Combinamos estas y otras características estáticas utilizando aprendizaje automático para lograr un sistema de clasificación que es significativamente mejor que PageRank (en acuerdo par a par con etiquetas humanas). Un enfoque de aprendizaje automático para la clasificación estática tiene otras ventajas además de la calidad de la clasificación. Debido a que la medida consta de muchas características, es más difícil para los usuarios malintencionados manipularla (es decir, elevar el rango estático de sus páginas a un nivel no merecido a través de técnicas cuestionables, también conocidas como spam en la web). Esto es especialmente cierto si el conjunto de características no se conoce. Por el contrario, una sola medida como PageRank puede ser más fácil de manipular porque los spammers solo necesitan concentrarse en un objetivo: cómo hacer que más páginas apunten a su página. Con un algoritmo que aprende, una característica que se vuelve inutilizable debido a la manipulación de spammers simplemente se reducirá o eliminará del cálculo final de rango. Esta flexibilidad permite que un sistema de clasificación reaccione rápidamente a nuevas técnicas de spam. Un enfoque de aprendizaje automático para la clasificación estática también puede aprovechar cualquier avance en el campo del aprendizaje automático. Por ejemplo, un trabajo reciente sobre clasificación adversarial [12] sugiere que puede ser posible modelar explícitamente las acciones de los spammers de páginas web (el adversario), ajustando el modelo de clasificación de antemano antes de que los spammers intenten evadirlo. Otro ejemplo es la eliminación de valores atípicos al construir el modelo, lo cual ayuda a reducir el efecto que los sitios únicos pueden tener en la calidad general de la clasificación estática. Al trasladar la clasificación estática a un marco de aprendizaje automático, no solo ganamos en precisión, sino también en la capacidad de reaccionar a las acciones de los spammers, de añadir rápidamente nuevas características al algoritmo de clasificación y de aprovechar los avances en el campo en rápido crecimiento del aprendizaje automático. Finalmente, creemos que habrá ventajas significativas al utilizar esta técnica para otros ámbitos, como la búsqueda en un disco duro local o en la intranet de una empresa. Estos son dominios donde la estructura de enlaces es particularmente débil (o inexistente), pero hay otras características específicas del dominio que podrían ser igual de poderosas. Por ejemplo, el autor de una página de intranet y su posición en la organización (por ejemplo, CEO, gerente o desarrollador) podrían proporcionar pistas significativas sobre la importancia de esa página. Un enfoque de aprendizaje automático permite el desarrollo rápido de un buen algoritmo estático en nuevos dominios. La contribución de este artículo es un estudio sistemático de las características estáticas, incluido PageRank, con el propósito de clasificar páginas web de forma estática. Estudios previos sobre PageRank típicamente utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Además, el rendimiento de PageRank y otras características estáticas suele evaluarse en el contexto de un sistema completo para la clasificación dinámica, o para otras tareas como la respuesta a preguntas. Por el contrario, exploramos el uso de PageRank y otras características para la tarea directa de clasificar estáticamente las páginas web. Primero describimos brevemente el algoritmo PageRank. En la Sección 3 presentamos RankNet, la técnica de aprendizaje automático utilizada para combinar las características estáticas en un ranking final. La sección 4 describe las características estáticas. El corazón del documento está en la Sección 5, la cual presenta nuestros experimentos y resultados. Concluimos con una discusión sobre el trabajo relacionado y futuro. 2. PAGERANK La idea básica detrás de PageRank es simple: un enlace de una página web a otra puede ser visto como un respaldo de esa página. En general, los enlaces son creados por personas. Por lo tanto, son indicativos de la calidad de las páginas a las que apuntan: al crear una página, un autor presumiblemente elige enlazar a páginas consideradas de buena calidad. Podemos aprovechar esta información de enlace para ordenar las páginas web según su calidad percibida. Imagina a un internauta que salta de página web en página web, eligiendo con probabilidad uniforme qué enlace seguir en cada paso. Para reducir el efecto de los callejones sin salida o ciclos interminables, el surfista saltará ocasionalmente a una página aleatoria con una pequeña probabilidad α, o cuando se encuentre en una página sin enlaces de salida. Si se promedia sobre un número suficiente de pasos, la probabilidad de que el surfista esté en la página j en algún momento en el tiempo está dada por la fórmula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Donde Fi es el conjunto de páginas a las que enlaza la página i, y Bj es el conjunto de páginas que enlazan a la página j. El puntaje de PageRank para el nodo j se define como esta probabilidad: PR(j)=P(j). Dado que la ecuación (1) es recursiva, debe evaluarse de forma iterativa hasta que P(j) converja (normalmente, la distribución inicial para P(j) es uniforme). La intuición es que, dado que un navegante aleatorio llegaría a la página con más frecuencia, es probable que sea una página mejor. Una vista alternativa para la ecuación (1) es que a cada página se le asigna una calidad, P(j). Una página otorga una parte igual de su calidad a cada página a la que apunta. PageRank es computacionalmente costoso. Nuestra colección de 5 mil millones de páginas contiene aproximadamente 370 mil millones de enlaces. Calcular el PageRank requiere iterar sobre miles de millones de enlaces varias veces (hasta converger). Requiere grandes cantidades de memoria (o esquemas de almacenamiento en caché muy inteligentes que ralentizan aún más el cálculo), y si se distribuye en múltiples máquinas, requiere una comunicación significativa entre ellas. Aunque se ha realizado mucho trabajo en la optimización del cálculo del PageRank (ver, por ejemplo, [25] y [6]), sigue siendo una propiedad relativamente lenta y costosa computacionalmente de calcular. 3. RANKNET Se ha realizado mucho trabajo en aprendizaje automático en los problemas de clasificación y regresión. Sea X={xi} una colección de vectores de características (típicamente, una característica es cualquier número real), y Y={yi} una colección de clases asociadas, donde yi es la clase del objeto descrito por el vector de características xi. El problema de clasificación consiste en aprender una función f que mapea yi=f(xi), para todo i. Cuando yi también es un valor real, esto se llama regresión. La clasificación estática se puede ver como un problema de regresión. Si dejamos que xi represente las características de la página i, y yi sea un valor (por ejemplo, el rango) para cada página, podríamos aprender una función de regresión que mapeara las características de cada página a su rango. Sin embargo, esto sobrecarga el problema que deseamos resolver. Todo lo que realmente nos importa es el orden de las páginas, no el valor real asignado a ellas. El trabajo reciente sobre este problema de clasificación [7][13][18] intenta directamente optimizar el orden de los objetos, en lugar del valor asignado a ellos. Para esto, sea Z={<i,j>} una colección de pares de elementos, donde el elemento i debe ser asignado un valor más alto que el elemento j. El objetivo del problema de clasificación, entonces, es aprender una función f tal que, )()(,, ji ffji xxZ >∈∀ 708. Nótese que, al igual que al aprender una función de regresión, el resultado de este proceso es una función (f) que mapea vectores de características a valores reales. Esta función todavía se puede aplicar en cualquier lugar donde se pueda aplicar una función aprendida por regresión. La única diferencia es la técnica utilizada para aprender la función. Al optimizar directamente el orden de los objetos, estos métodos pueden aprender una función que clasifica mejor que las técnicas de regresión. Utilizamos RankNet [7], una de las técnicas mencionadas para aprender funciones de clasificación, para aprender nuestra función de clasificación estática. RankNet es una modificación sencilla del algoritmo de retropropagación de la red neuronal estándar. Al igual que con back-prop, RankNet intenta minimizar el valor de una función de costo ajustando cada peso en la red de acuerdo con el gradiente de la función de costo con respecto a ese peso. La diferencia es que, mientras que una función de costo típica de una red neuronal se basa en la diferencia entre la salida de la red y la salida deseada, la función de costo de RankNet se basa en la diferencia entre un par de salidas de la red. Es decir, para cada par de vectores de características <i,j> en el conjunto de entrenamiento, RankNet calcula las salidas de la red oi y oj. Dado que se supone que el vector i está clasificado más alto que el vector j, cuanto mayor sea oj-oi, mayor será el costo. RankNet también permite que los pares en Z sean ponderados con una confianza (expresada como la probabilidad de que el par cumpla con el ordenamiento inducido por la función de clasificación). En este documento, utilizamos una probabilidad de uno para todos los pares. En la siguiente sección, discutiremos las características utilizadas en nuestros vectores de características, xi. 4. Para aplicar RankNet (u otras técnicas de aprendizaje automático) al problema de clasificación, necesitábamos extraer un conjunto de características de cada página. Dividimos nuestro conjunto de características en cuatro categorías mutuamente excluyentes: a nivel de página (Página), a nivel de dominio (Dominio), texto del enlace y enlaces entrantes (Anclaje) y popularidad (Popularidad). También opcionalmente utilizamos el PageRank de una página como una característica. A continuación, describimos cada una de estas categorías de características con más detalle. Calculamos PageRank en un grafo web de 5 mil millones de páginas rastreadas (y 20 mil millones de URLs conocidas enlazadas por estas páginas). Esto representa una parte significativa de la Web, y es aproximadamente la misma cantidad de páginas que utilizan Google, Yahoo y MSN para sus motores de búsqueda. Dado que PageRank es un algoritmo basado en grafos, es importante que se ejecute en la mayor cantidad posible de subconjuntos de la Web. La mayoría de los estudios previos sobre PageRank utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Calculamos PageRank utilizando el valor estándar de 0.85 para α. Otra característica que utilizamos es la popularidad real de una página web, medida como el número de veces que ha sido visitada por usuarios durante algún período de tiempo. Tenemos acceso a esos datos de usuarios que han instalado la barra de herramientas de MSN y han optado por proporcionarlos a MSN. Los datos se agregan en un recuento, para cada página web, del número de usuarios que vieron esa página. Aunque los datos de popularidad generalmente no están disponibles, hay otras dos fuentes para obtenerlos. El primero es de los registros de proxy. Por ejemplo, una universidad que requiere que sus estudiantes utilicen un proxy tiene un registro de todas las páginas que han visitado mientras están en el campus. Desafortunadamente, los datos de proxy son bastante sesgados y relativamente pequeños. Otra fuente, interna de los motores de búsqueda, son los registros de los resultados en los que hicieron clic sus usuarios. Tales datos fueron utilizados por el motor de búsqueda Direct Hit, y recientemente han sido explorados con fines de clasificación dinámica [20]. Una ventaja de los datos de la barra de herramientas sobre esto es que contiene información sobre las visitas a URL que no son solo el resultado de una búsqueda. La popularidad en bruto se procesa en una serie de características como el número de veces que se visualizó una página y el número de veces que se visualizó cualquier página en el dominio. Se proporcionan más detalles en la sección 5.5. Texto de anclaje e inlinks. Estas características se basan en la información asociada con los enlaces a la página en cuestión. Incluye características como la cantidad total de texto en los enlaces que apuntan a la página (texto de anclaje), el número de palabras únicas en ese texto, etc. Esta categoría consiste en características que pueden ser determinadas solo al observar la página (y su URL). Solo utilizamos ocho características simples como el número de palabras en el cuerpo, la frecuencia del término más común, etc. Este categoría contiene características que se calculan como promedios en todas las páginas del dominio. Por ejemplo, el número promedio de enlaces salientes en cualquier página y el PageRank promedio. Muchas de estas características han sido utilizadas por otros para clasificar páginas web, especialmente las características de anclaje y de la página. Como se mencionó, la evaluación suele ser para clasificación dinámica, y deseamos evaluar su uso para clasificación estática. Además, hasta donde sabemos, este es el primer estudio sobre el uso de la <br>popularidad real de visitas</br> a páginas para la clasificación estática. El trabajo similar más cercano se centra en el uso del comportamiento de clics (es decir, en los resultados de búsqueda en los que los usuarios hacen clic) para afectar la clasificación dinámica (ver, por ejemplo, [20]). Debido a que utilizamos una amplia variedad de características para crear un ranking estático, nos referimos a esto como fRank (para ranking basado en características). fRank utiliza RankNet y el conjunto de características descritas en esta sección para aprender una función de ranking para páginas web. A menos que se especifique lo contrario, fRank fue entrenado con todas las características. 5. EXPERIMENTOS En esta sección, demostraremos que podemos superar a PageRank aplicando aprendizaje automático a un conjunto sencillo de características. Antes de los resultados, primero discutimos los datos, la métrica de rendimiento y el método de entrenamiento. 5.1 Datos Para evaluar la calidad de un ranking estático, necesitábamos un estándar de oro que definiera el orden correcto para un conjunto de páginas. Para esto, empleamos un conjunto de datos que contiene juicios humanos para 28000 consultas. Para cada consulta, un número de resultados son asignados manualmente una calificación, de 0 a 4, por jueces humanos. La calificación está destinada a ser una medida de cuán relevante es el resultado para la consulta, donde 0 significa pobre y 4 significa excelente. Hay aproximadamente 500 mil juicios en total, o un promedio de 18 calificaciones por consulta. Las consultas se seleccionan eligiendo aleatoriamente consultas de entre aquellas emitidas al motor de búsqueda de MSN. La probabilidad de que se seleccione una consulta es proporcional a su frecuencia entre las 709 consultas. Como resultado, es más probable que las consultas comunes sean evaluadas que las consultas poco comunes. Como ejemplo de la diversidad de las consultas, las primeras cuatro consultas en el conjunto de entrenamiento son escuelas de chef, el autódromo de Chicagoland, el club de fans de los Eagles y la cultura turca. Los documentos seleccionados para evaluar son aquellos que esperábamos que, en promedio, fueran razonablemente relevantes (por ejemplo, los diez documentos principales devueltos por el motor de búsqueda de MSN). Esto proporciona significativamente más información que seleccionar documentos al azar en la web, la gran mayoría de los cuales serían irrelevantes para una consulta específica. Debido a este proceso, las páginas evaluadas tienden a ser de mayor calidad que la página promedio en la web, y suelen ser páginas que se devolverán en consultas de búsqueda comunes. Este sesgo es útil al evaluar la calidad de la clasificación estática con el fin de ordenar índices y devolver documentos relevantes. Esto se debe a que la parte más importante del índice que debe estar bien ordenada y ser relevante es la parte que se devuelve con frecuencia para las consultas de búsqueda. Debido a este sesgo, sin embargo, los resultados en este documento no son aplicables a la priorización de rastreo. Para obtener resultados experimentales sobre la priorización de rastreo, necesitaríamos calificaciones de una muestra aleatoria de páginas web. Para convertir los datos de dependientes de la consulta a independientes de la consulta, simplemente eliminamos la consulta, tomando el máximo sobre las evaluaciones para una URL que aparece en más de una consulta. El razonamiento detrás de esto es que una página que es relevante para una consulta y no relevante para otra probablemente sea una buena página y debería tener un alto rango estático. Debido a que evaluamos las páginas en consultas que ocurren con frecuencia, nuestros datos indican el orden correcto del índice y asignan un alto valor a las páginas que probablemente sean relevantes para una consulta común. Asignamos consultas al azar a un conjunto de entrenamiento, validación o prueba, de modo que contuvieran el 84%, 8% y 8% de las consultas, respectivamente. Cada conjunto contiene todas las calificaciones para una consulta dada, y ninguna consulta aparece en más de un conjunto. El conjunto de entrenamiento se utilizó para entrenar fRank. El conjunto de validación se utilizó para seleccionar el modelo que tuvo el mejor rendimiento. El conjunto de pruebas se utilizó para los resultados finales. Estos datos nos proporcionan un ordenamiento de páginas independiente de la consulta. El objetivo de un algoritmo de clasificación estática será reproducir este orden lo más fielmente posible. En la siguiente sección, describimos la medida que utilizamos para evaluar esto. 5.2 Medida Elegimos utilizar la precisión por pares para evaluar la calidad de un ranking estático. La precisión por pares es la fracción de tiempo en la que el algoritmo de clasificación y los jueces humanos están de acuerdo en el ordenamiento de un par de páginas web. Si S(x) es la clasificación estática asignada a la página x, y H(x) es el juicio humano de relevancia para x, entonces considera los siguientes conjuntos: )}()(:,{ yHxHyx >=pH y )}()(:,{ ySxSyx >=pS La precisión por pares es la porción de Hp que también está contenida en Sp: p pp H SH ∩ =precisiónpares Esta medida fue elegida por dos razones. Primero, los juicios humanos discretos proporcionan solo un orden parcial sobre las páginas web, lo que dificulta aplicar una medida como el coeficiente de correlación de orden de rango de Spearman (en la medida de precisión por pares, un par de documentos con el mismo juicio humano no afecta la puntuación). Segundo, la precisión por pares tiene un significado intuitivo: es la fracción de pares de documentos que, cuando los humanos afirman que uno es mejor que el otro, el algoritmo de clasificación estática los ordena correctamente. 5.3 Método Entrenamos fRank (una red neuronal basada en RankNet) utilizando los siguientes parámetros. Utilizamos una red de 2 capas completamente conectadas. La capa oculta tenía 10 nodos ocultos. Los pesos de entrada a esta capa se inicializaron todos en cero. Los pesos de la capa de salida (solo un nodo) se inicializaron utilizando una distribución aleatoria uniforme en el rango [-0.1, 0.1]. Utilizamos la función tangente hiperbólica (tanh) como función de transferencia de las entradas a la capa oculta, y una función lineal de la capa oculta a la salida. La función de costo es la función de costo de entropía cruzada por pares discutida en la sección 3. Las características en el conjunto de entrenamiento fueron normalizadas para tener media cero y desviación estándar unitaria. La misma transformación lineal fue luego aplicada a las características en los conjuntos de validación y prueba. Para el entrenamiento, presentamos a la red neuronal 5 millones de pares de páginas, donde una página tenía una calificación más alta que la otra. Las combinaciones fueron elegidas de forma uniforme al azar (con reemplazo) de todas las combinaciones posibles. Al formar las parejas, ignoramos la magnitud de la diferencia entre las calificaciones (la dispersión de calificaciones) de las dos URL. Por lo tanto, el peso para cada par era constante (uno), y la probabilidad de que se seleccionara un par era independiente de la diferencia de calificación. Entrenamos la red durante 30 épocas. En cada época, los pares de entrenamiento fueron mezclados aleatoriamente. La tasa de entrenamiento inicial fue de 0.001. En cada época, verificamos el error en el conjunto de entrenamiento. Si el error hubiera aumentado, entonces disminuimos la tasa de entrenamiento, bajo la hipótesis de que la red probablemente se había excedido. La tasa de entrenamiento en cada época se estableció de la siguiente manera: Tasa de entrenamiento = 1+ε κ Donde κ es la tasa inicial (0.001), y ε es el número de veces que el error del conjunto de entrenamiento ha aumentado. Después de cada época, medimos el rendimiento de la red neuronal en el conjunto de validación, utilizando 1 millón de pares (elegidos al azar con reemplazo). La red con la mayor precisión en pares en el conjunto de validación fue seleccionada, y luego probada en el conjunto de pruebas. Informamos la precisión por pares en el conjunto de pruebas, calculada utilizando todos los pares posibles. Estos parámetros fueron determinados y fijados antes de los experimentos de clasificación estática en este artículo. En particular, la elección de la tasa de entrenamiento inicial, el número de épocas y la función de decaimiento de la tasa de entrenamiento se tomaron directamente de Burges et al [7]. Aunque teníamos la opción de preprocesar cualquiera de las características antes de introducirlas en la red neuronal, nos abstuvimos de hacerlo en la mayoría de ellas. La única excepción fueron las características de popularidad. Como ocurre con la mayoría de los fenómenos web, descubrimos que la distribución de la popularidad de los sitios es Zipfiana. Para reducir el rango dinámico, y con suerte hacer que la característica sea más útil, presentamos a la red tanto las características de popularidad sin procesar, como el logaritmo de las mismas (Al igual que con las demás, los valores de las características logarítmicas también se normalizaron para tener media cero y desviación estándar unitaria). Aplicar fRank a un documento es computacionalmente eficiente, tomando un tiempo que es solo lineal en el número de características de entrada; por lo tanto, está dentro de un factor constante de otros métodos de aprendizaje automático simples como el Bayes ingenuo. En nuestros experimentos, calcular el fRank para las cinco mil millones de páginas web fue aproximadamente 100 veces más rápido que calcular el PageRank para el mismo conjunto. 5.4 Resultados Como muestra la Tabla 1, el fRank supera significativamente al PageRank para los propósitos de clasificación estática. Con una precisión de pares del 67.4%, fRank más que duplica la precisión de PageRank (en relación con la línea base del 50%, que es la precisión que se lograría con un orden aleatorio de páginas web). Ten en cuenta que una de las características de entrada de fRanks es el PageRank de la página, por lo que esperaríamos que su rendimiento no fuera peor que el de PageRank. El aumento significativo en precisión implica que las otras características (anclaje, popularidad, etc.) de hecho contienen información útil sobre la calidad general de una página. Tabla 1: Resultados Básicos Técnica Precisión (%) Ninguna (Línea base) 50.00 PageRank 56.70 fRank 67.43 Existen varias decisiones que intervienen en el cálculo de PageRank, como por ejemplo cómo tratar las páginas que no tienen enlaces salientes, la elección de α, la precisión numérica, el umbral de convergencia, etc. Pudimos obtener un cálculo de PageRank a partir de una implementación completamente independiente (proporcionada por Marc Najork) que variaba ligeramente en estos parámetros. Obtuvo una precisión de pares del 56.52%, casi idéntica a la obtenida por nuestra implementación. Por lo tanto, concluimos que la calidad del PageRank no es sensible a estas variaciones menores en el algoritmo, ni la baja precisión de los PageRanks se debió a problemas con nuestra implementación de él. También queríamos averiguar qué tan bien se desempeñaba cada conjunto de características. Para responder a esto, para cada conjunto de características, entrenamos y probamos fRank utilizando solo ese conjunto de características. Los resultados se muestran en la Tabla 2. Como se puede ver, cada conjunto de características individual superó a PageRank en esta prueba. Quizás el resultado más interesante es que las características a nivel de página tuvieron el mejor rendimiento de todos los conjuntos de características. Esto es sorprendente porque estas son características que no dependen de la estructura general del grafo de la Web, ni siquiera de qué páginas apuntan a una página dada. Esto va en contra de la creencia común de que la estructura del grafo web es la clave para encontrar una buena clasificación estática de las páginas web. Tabla 2: Resultados para conjuntos de características individuales. Debido a que estamos utilizando una red neuronal de dos capas, las características en la red aprendida pueden interactuar entre sí de maneras interesantes y no lineales. Esto significa que una característica particular que parece tener poco valor por sí sola podría ser muy importante cuando se utiliza en combinación con otras características. Para medir la contribución final de un conjunto de características, en el contexto de todas las demás características, realizamos un estudio de ablación. Es decir, para cada conjunto de características, entrenamos una red para contener todas las características excepto ese conjunto. Luego comparamos el rendimiento de la red resultante con el rendimiento de la red con todas las características. La Tabla 3 muestra los resultados de este experimento, donde la disminución en la precisión es la diferencia en la precisión por pares entre la red entrenada con todas las características y la red que carece del conjunto de características dado. Tabla 3: Estudio de ablación. Se muestra la disminución en precisión cuando entrenamos una red que tiene todas las características excepto el conjunto dado. La última línea muestra el efecto de eliminar las características del ancla, PageRank y dominio, por lo tanto, un modelo que no contiene ninguna información de red o basada en enlaces. Los resultados del estudio de ablación son consistentes con el estudio de conjunto de características individuales. Ambos muestran que el conjunto de características más importante es el conjunto de características a nivel de página, y el segundo más importante es el conjunto de características de popularidad. Finalmente, deseábamos ver cómo mejoraba el rendimiento de fRank a medida que añadíamos características; queríamos encontrar en qué punto añadir más conjuntos de características se volvía relativamente inútil. Comenzando sin características, añadimos ávidamente el conjunto de características que mejoró el rendimiento en mayor medida. Los resultados se muestran en la Tabla 4. Por ejemplo, la cuarta línea de la tabla muestra que fRank utilizando las características de página, popularidad y anclaje superó a cualquier red que utilizara la página, popularidad y algún otro conjunto de características, y que el rendimiento de esta red fue del 67.25%. Tabla 4: Rendimiento de fRank a medida que se agregan conjuntos de características. En cada fila, se añadió al conjunto de características aquella que proporcionó el mayor aumento en la precisión (es decir, realizamos una búsqueda ávida sobre conjuntos de características). Precisión del conjunto de características (%) Ninguna 50.00 +Página 63.93 +Popularidad 66.83 +Anclaje 67.25 +PageRank 67.31 +Dominio 67.43 711 Finalmente, presentamos una comparación cualitativa de PageRank vs. fRank. En la Tabla 5 se encuentran las diez URL principales devueltas para PageRank y para fRank. Los resultados de PageRank están fuertemente ponderados hacia sitios de tecnología. Contiene dos URL de QuickTime (software de reproducción de video de Apple), así como URL de Internet Explorer y FireFox (ambos navegadores web). Por otro lado, fRank contiene sitios más orientados al consumidor como American Express, Target, Dell, etc. El sesgo de PageRank hacia la tecnología puede explicarse a través de dos procesos. Primero, hay muchas páginas con botones en la parte inferior que sugieren que el sitio está optimizado para Internet Explorer, o que el visitante necesita QuickTime. Estos enlaces generalmente remiten, en estos ejemplos, a los sitios de descarga de Internet Explorer y QuickTime. Por consiguiente, PageRank clasifica esas páginas en posiciones altas. Aunque estas páginas son importantes, no son tan importantes como podría parecer al observar solo la estructura de enlaces. Una solución para esto es agregar información sobre el enlace al cálculo del PageRank, como el tamaño del texto, si estaba en la parte inferior de la página, etc. El otro sesgo proviene del hecho de que la población de autores de sitios web es diferente a la población de usuarios de la web. Los autores web tienden a estar orientados tecnológicamente, por lo que su comportamiento de enlace refleja esos intereses. fRank, al conocer la <br>popularidad real de visitas</br> de un sitio (el conjunto de características de popularidad), puede eliminar parte de ese sesgo. Tiene la capacidad de depender más de dónde visitan los usuarios reales de la Web que de dónde han enlazado los autores del sitio web. Los resultados confirman que fRank supera a PageRank en precisión por pares. Los dos conjuntos de características más importantes son las características de la página y de la popularidad. Esto es sorprendente, ya que las características de la página consistían solo en unas pocas (8) características simples. Experimentos adicionales encontraron que, de las características de la página, aquellas basadas en el texto de la página (en contraposición a la URL) tuvieron el mejor rendimiento. En la siguiente sección, exploramos la característica de popularidad con más detalle. 5.5 Datos de Popularidad Como se mencionó en la sección 4, nuestros datos de popularidad provienen de usuarios de la barra de herramientas de MSN. Por razones de privacidad, solo tuvimos acceso a un recuento agregado de cuántas veces fue visitada cada URL por cualquier usuario de la barra de herramientas. Esto limitó las características posibles que podríamos derivar de estos datos. Para posibles extensiones, consulte la sección 6.3, trabajo futuro. Para cada URL en nuestros conjuntos de entrenamiento y prueba, proporcionamos una característica a fRank que indicaba cuántas veces había sido visitada por un usuario de la barra de herramientas. Sin embargo, esta característica era bastante ruidosa y dispersa, especialmente para URL con parámetros de consulta (por ejemplo, http://search.msn.com/results.aspx?q=machine+learning&form=QBHP). Una solución fue proporcionar una característica adicional que era el número de veces que cualquier URL en el dominio dado fue visitada por un usuario de la barra de herramientas. La adición de esta característica mejoró drásticamente el rendimiento de fRank. Llevamos esto un paso más allá y utilizamos la estructura jerárquica incorporada de las URL para construir varios niveles de retroceso entre la URL completa y el dominio. Lo hicimos utilizando el conjunto de características mostradas en la Tabla 6. Tabla 6: Funciones de URL utilizadas para calcular el conjunto de características de Popularidad. Cada URL fue asignado una característica para cada función mostrada en la tabla. El valor de la característica era el recuento de la cantidad de veces que un usuario de la barra de herramientas visitó una URL, donde la función aplicada a esa URL coincide con la función aplicada a la URL en cuestión. Por ejemplo, la visita de un usuario a cnn.com/2005/sports.html incrementaría las características de Dominio y Dominio+1 para la URL cnn.com/2005/tech/wikipedia.html. Como se observa en la Tabla 7, agregar los recuentos de dominio mejoró significativamente la calidad de la característica de popularidad, y agregar las numerosas funciones de respaldo enumeradas en la Tabla 6 mejoró aún más la precisión. Tabla 7: Efecto de agregar retroceso a la característica de popularidad Conjunto de características Precisión (%) Recuento de URL 58.15 Recuento de URL y dominio 59.31 Todas las funciones de retroceso (Tabla 6) 60.82 Tabla 5: Diez mejores URL para PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Retroceder a subconjuntos de la URL es una técnica para tratar la escasez de datos. También es informativo ver cómo el rendimiento de fRank depende de la cantidad de datos de popularidad que hemos recopilado. En la Figura 1 mostramos el rendimiento de fRank entrenado solo con el conjunto de características de popularidad frente a la cantidad de datos que tenemos para el conjunto de características de popularidad. Cada día recibimos datos adicionales de popularidad, y como se puede ver en el gráfico, esto aumenta el rendimiento de fRank. La relación es logarítmica: duplicar la cantidad de datos de popularidad proporciona una mejora constante en la precisión de pares. En resumen, hemos encontrado que las características de popularidad proporcionan un impulso útil a la precisión general de fRank. Recopilando más datos de popularidad, así como empleando estrategias de retroceso simples, se mejora aún más este impulso. 5.6 Resumen de Resultados Los experimentos proporcionan varias conclusiones. Primero, fRank funciona significativamente mejor que PageRank, incluso sin tener información sobre el grafo web. En segundo lugar, las características a nivel de página y de popularidad fueron los contribuyentes más significativos a la precisión por pares. Tercero, al recopilar más datos de popularidad, podemos seguir mejorando el rendimiento de fRanks. Los datos de popularidad proporcionan dos beneficios a fRank. Primero, observamos que cualitativamente, el ordenamiento de fRanks de las páginas web tiene un sesgo más favorable que PageRanks. El ordenamiento de fRanks parece corresponder a lo que los usuarios de la web, en lugar de los autores de las páginas web, prefieren. Segundo, los datos de popularidad son más actuales que la información de enlaces de PageRank. La barra de herramientas proporciona información sobre qué páginas web encuentran interesantes las personas en este momento, mientras que los enlaces se agregan a las páginas más lentamente, a medida que los autores encuentran el tiempo y el interés. TRABAJO RELACIONADO Y FUTURO 6.1 Mejoras a PageRank Desde el artículo original de PageRank, ha habido trabajos para mejorarlo. Gran parte de ese trabajo se centra en acelerar y paralelizar el cálculo [15][25]. Un problema reconocido con PageRank es el de la deriva de temas: una página sobre perros tendrá un alto PageRank si está vinculada por muchas páginas que a su vez tienen un alto rango, independientemente de su tema. Por el contrario, un usuario de un motor de búsqueda que busca buenas páginas sobre perros probablemente preferiría encontrar páginas que son enlazadas por muchas páginas que tratan sobre perros. Por lo tanto, un enlace que esté relacionado con el tema debería tener más peso que un enlace que no lo esté. Richardson y el PageRank Dependiente de Consulta de Domingos [29] y el PageRank Sensible al Tema de Haveliwala [16] son dos enfoques que abordan este problema. Otras variaciones de PageRank incluyen ponderar de manera diferente los enlaces para enlaces inter e intra-dominio, agregar un paso hacia atrás al surfista aleatorio para simular el botón de retroceso en la mayoría de los navegadores [24] y modificar la probabilidad de salto (α) [3]. Consulte Langville y Meyer [23] para obtener una buena revisión de estas y otras modificaciones a PageRank. 6.2 Otros trabajos relacionados PageRank no es el único algoritmo de análisis de enlaces utilizado para clasificar páginas web. El otro más conocido es HITS [22], que es utilizado por el motor de búsqueda Teoma [30]. HITS produce una lista de hubs y autoridades, donde los hubs son páginas que apuntan a muchas páginas de autoridad, y las autoridades son páginas a las que apuntan muchos hubs. Trabajos anteriores han demostrado que HITS tiene un rendimiento comparable al de PageRank [1]. Un campo de interés es el de la poda de índices estáticos (ver, por ejemplo, Carmel et al. [8]). Los métodos de poda de índices estáticos reducen el tamaño del índice de los motores de búsqueda al eliminar documentos que es poco probable que sean devueltos por una consulta de búsqueda. La poda se realiza típicamente en función de la frecuencia de los términos de consulta. De manera similar, Pandey y Olston [28] sugieren rastrear las páginas con frecuencia si es probable que aparezcan incorrectamente (o no aparezcan) como resultado de una búsqueda. Métodos similares podrían ser incorporados en la clasificación estática (por ejemplo, cuántas consultas frecuentes contienen palabras encontradas en esta página). Otros han investigado el efecto que PageRank tiene en la Web en general [9]. Argumentan que las páginas con un alto PageRank son más propensas a ser encontradas por los usuarios de la web, por lo tanto, es más probable que sean enlazadas y, por ende, mantengan un PageRank más alto que otras páginas. Lo mismo puede ocurrir con los datos de popularidad. Si aumentamos la clasificación de las páginas populares, es más probable que se haga clic en ellas, lo que a su vez aumentará aún más su popularidad. Cho et al. [10] argumentan que una medida más apropiada de la calidad de una página web dependería no solo de la estructura de enlaces actual de la web, sino también de los cambios en esa estructura de enlaces. La misma técnica puede ser aplicable a los datos de popularidad: el cambio en la popularidad de una página puede ser más informativo que la popularidad absoluta. Un trabajo relacionado interesante es el de Ivory y Hearst [19]. Su objetivo era construir un modelo de sitios web que son considerados de alta calidad desde la perspectiva de contenido, estructura y navegación, diseño visual, funcionalidad, interactividad y experiencia general. Utilizaron más de 100 características a nivel de página, así como características que abarcan el rendimiento y la estructura del sitio. Esto les permitió describir cualitativamente las cualidades de una página que la hacen parecer atractiva (por ejemplo, el uso poco común de cursivas, al menos una fuente de 9 puntos, ...), y (en trabajos posteriores) construir un sistema que ayude a los autores de páginas web novedosas a crear páginas de calidad evaluándolas según estas características. Las principales diferencias entre este trabajo y el nuestro son el objetivo (descubrir qué constituye una buena página web vs. ordenar páginas web con fines de búsqueda en la web), el tamaño del estudio (utilizaron un conjunto de datos de menos de 6000 páginas vs. nuestro conjunto de 468,000), y nuestra comparación con PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Días de Datos de la Barra de Herramientas Precisión por Pares Figura 1: Relación entre la cantidad de datos de popularidad y el rendimiento del conjunto de características de popularidad. Ten en cuenta que el eje x es una escala logarítmica. Sin embargo, su trabajo proporciona ideas sobre características estáticas adicionales útiles que podríamos incorporar en fRank en el futuro. El trabajo reciente sobre la incorporación de características novedosas en la clasificación dinámica incluye el realizado por Joachims et al. [21], quienes investigan el uso de retroalimentación implícita de los usuarios, en forma de los resultados de búsqueda en el motor de búsqueda que se hacen clic. Craswell et al. [11] presentan un método para determinar la mejor transformación a aplicar a las características independientes de la consulta (como las utilizadas en este artículo) con el fin de mejorar la clasificación dinámica. Otros trabajos, como el de Boyan et al. [4] y Bartell et al. [2], aplican aprendizaje automático con el propósito de mejorar la relevancia general de un motor de búsqueda (es decir, el ranking dinámico). No aplican sus técnicas al problema de clasificación estática. 6.3 Trabajo futuro Hay muchas formas en las que nos gustaría ampliar este trabajo. Primero, Frank utiliza solo un pequeño número de características. Creemos que podríamos lograr resultados aún más significativos con más características. En particular, la existencia o falta de ciertas palabras podría resultar muy significativa (por ejemplo, \"en construcción\" probablemente signifique una página de baja calidad). Otras características podrían incluir el número de imágenes en una página, el tamaño de esas imágenes, el número de elementos de diseño (tablas, divs y spans), el uso de hojas de estilo, la conformidad con los estándares de W3C (como XHTML 1.0 Strict), el color de fondo de una página, etc. Muchas páginas se generan dinámicamente, cuyos contenidos pueden depender de parámetros en la URL, la hora del día, el usuario que visita el sitio, u otras variables. Para este tipo de páginas, puede ser útil aplicar las técnicas encontradas en [26] para formar una aproximación estática con el fin de extraer características. La gramática resultante que describe la página podría ser en sí misma una fuente de características adicionales que describen la complejidad de la página, como cuántos nodos no terminales tiene, la profundidad del árbol gramatical, etc. fRank permite especificar una confianza en cada emparejamiento de documentos. En el futuro, experimentaremos con probabilidades que dependen de la diferencia en los juicios humanos entre los dos elementos del par. Por ejemplo, un par de documentos donde uno fue calificado con un 4 y el otro con un 0 debería tener una mayor confianza que un par de documentos calificados con un 3 y un 2. Los experimentos en este artículo están sesgados hacia páginas que tienen una calidad superior al promedio. Además, fRank con todas las características solo se puede aplicar a páginas que ya han sido rastreadas. Por lo tanto, fRank es principalmente útil para el ordenamiento de índices y mejorar la relevancia, no para dirigir el rastreo. Nos gustaría investigar un enfoque de aprendizaje automático para la priorización de rastreo también. Puede ser que la mejor opción sea una combinación de métodos: por ejemplo, utilizar PageRank para seleccionar los mejores 5 mil millones de las 20 mil millones de páginas en la web, luego utilizar fRank para ordenar el índice y afectar la relevancia de la búsqueda. Otra dirección interesante para la exploración es incorporar las características de fRank y a nivel de página directamente en el cálculo de PageRank en sí mismo. El trabajo en el sesgo del vector de salto de PageRank [16] y la matriz de transición [29] ha demostrado la viabilidad y ventajas de este enfoque. Existe motivo para creer que una aplicación directa de [29], utilizando el fRank de una página para su relevancia, podría llevar a una mejora en el rango estático general. Finalmente, los datos de popularidad pueden ser utilizados de otras maneras interesantes. Los hábitos generales de navegación y búsqueda de los usuarios de la web varían según la hora del día. La actividad por la mañana, durante el día y en la tarde suele ser bastante diferente (por ejemplo, leer las noticias, resolver problemas y acceder al entretenimiento, respectivamente). Podemos obtener información sobre estas diferencias utilizando los datos de popularidad, divididos en segmentos del día. Cuando se emite una consulta, luego utilizaríamos los datos de popularidad que coincidan con el momento de la consulta para clasificar las páginas web. También planeamos explorar características de popularidad que utilicen más que solo el recuento de cuántas veces se visitó una página. Por ejemplo, cuánto tiempo los usuarios solían permanecer en una página, si abandonaron la página haciendo clic en un enlace o presionando el botón de retroceso, etc. Fox et al. realizaron un estudio que demostró que características como esta pueden ser valiosas para los propósitos de clasificación dinámica [14]. Finalmente, los datos de popularidad podrían ser utilizados como la etiqueta en lugar de como una característica. Utilizar fRank de esta manera para predecir la popularidad de una página puede ser útil para las tareas de relevancia, eficiencia y prioridad de rastreo. También hay significativamente más datos de popularidad que datos etiquetados por humanos, lo que potencialmente permite el uso de métodos de aprendizaje automático más complejos y muchas más características. 7. CONCLUSIONES Un buen ranking estático es un componente importante para los motores de búsqueda y sistemas de recuperación de información actuales. Hemos demostrado que PageRank no proporciona una clasificación estática muy buena; hay muchas características simples que superan individualmente a PageRank. Al combinar muchas características estáticas, fRank logra un ranking que tiene una precisión en pares significativamente mayor que PageRank solo. Una evaluación cualitativa de los documentos principales muestra que fRank está menos sesgado hacia la tecnología que PageRank; al utilizar datos de popularidad, está sesgado hacia las páginas que los usuarios de la web visitan, en lugar de hacia las páginas que los autores web crean. El componente de aprendizaje automático de fRank le otorga el beneficio adicional de ser más robusto contra los spammers, y le permite aprovechar los avances adicionales en la comunidad de aprendizaje automático en áreas como la clasificación adversarial. Hemos comenzado a explorar las opciones y creemos que se pueden lograr avances significativos en el área de clasificación estática mediante experimentación adicional con características adicionales, otras técnicas de aprendizaje automático y fuentes de datos adicionales. AGRADECIMIENTOS Gracias a Marc Najork por proporcionarnos cálculos adicionales de PageRank y a Timo Burkard por su ayuda con los datos de popularidad. Muchas gracias a Chris Burges por proporcionar código y un apoyo significativo en el uso del entrenamiento de RankNets. También agradecemos a Susan Dumais y Nick Craswell por sus ediciones y sugerencias. 9. REFERENCIAS [1] B. Amento, L. Terveen y W. Hill. ¿Significa autoridad calidad? Prediciendo las calificaciones de calidad de expertos de documentos web. En Actas de la 23ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 2000. [2] B. Bartell, G. Cottrell y R. Belew. Combinación automática de múltiples sistemas de recuperación clasificados. En Actas de la 17ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, 1994. [3] P. Boldi, M. Santini y S. Vigna. PageRank como una función del factor de amortiguamiento. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. 714 [4] J. Boyan, D. Freitag y T. Joachims. Una arquitectura de aprendizaje automático para optimizar los motores de búsqueda web. En el taller de AAAI sobre Sistemas de Información Basados en Internet, agosto de 1996. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. En Actas de la Séptima Conferencia Internacional de la World Wide Web, Brisbane, Australia, 1998. Elsevier. [6] A. Broder, R. Lempel, F. Maghoul y J. Pederson. Aproximación eficiente de PageRank a través de la agregación de grafos. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender. Aprendiendo a clasificar utilizando descenso de gradiente. En Actas de la 22ª Conferencia Internacional sobre Aprendizaje Automático, Bonn, Alemania, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek y A. Soffer. Poda de índices estáticos para sistemas de recuperación de información. En Actas de la 24ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 43-50, Nueva Orleans, Luisiana, EE. UU., septiembre de 2001. [9] J. Cho y S. Roy. Impacto de los motores de búsqueda en la popularidad de las páginas. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [10]J. Cho, S. Roy, R. Adams. Calidad de la página: En busca de una clasificación web imparcial. En las Actas de la Conferencia ACM SIGMOD 2005. Baltimore, Maryland. Junio de 2005. N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para evidencia independiente de la consulta. En Actas de la 28ª Conferencia Anual sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), agosto de 2005. [12] N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma. Clasificación adversarial. En Actas de la Décima Conferencia Internacional sobre Descubrimiento de Conocimiento y Minería de Datos (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning y Y. Cantante. Modelos log-lineales para clasificación de etiquetas. En Avances en Sistemas de Procesamiento de Información Neural 16. Cambridge, MA: MIT Press, 2003. [14] S. Fox, K. S. Fox, K. Karnawat, M. Mydland, S. T. Dumais y T. White (2005). Evaluando medidas implícitas para mejorar las experiencias de búsqueda. En la revista ACM Transactions on Information Systems, 23(2), pp. 147-168. Abril de 2005. [15] T. Haveliwala. Cálculo eficiente de PageRank. Informe técnico de la Universidad de Stanford, 1999. [16] T. Haveliwala. PageRank sensible al tema. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2002. [17] D. Hawking y N. Craswell. Recuperación a gran escala y búsqueda en la web. En D. Harman y E. Voorhees (eds), El Libro de TREC. MIT Press. [18] R. Herbrich, T. Graepel y K. Obermayer. Aprendizaje de vectores de soporte para regresión ordinal. En Actas de la Novena Conferencia Internacional sobre Redes Neuronales Artificiales, pp. 97-102. 1999. [19] M. Ivory y M. Hearst. Perfiles estadísticos de sitios web altamente valorados. En Actas de la Conferencia ACM SIGCHI sobre Factores Humanos en Sistemas Informáticos, 2002. [20]T. Joachims. Optimización de motores de búsqueda utilizando datos de clics. En Actas de la Conferencia de la ACM sobre Descubrimiento de Conocimiento y Minería de Datos (KDD), 2002. [21] T. Joachims, L. Granka, B. Pang, H. Hembrooke y G. Gay. Interpretación precisa de los datos de clics como retroalimentación implícita. En Actas de la Conferencia sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2005. [22]J. Kleinberg. Fuentes autorizadas en un entorno hiperenlazado. Revista de la ACM 46:5, pp. 604-32. 1999. [23]A. Langville y C. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet 1(3):335-380, 2004. [24] F. Matthieu y M. Bouklit. El efecto del botón de retroceso en un paseo aleatorio: aplicación para PageRank. En los trabajos y pósters de la pista alternativa de la Decimotercera Conferencia Internacional de la World Wide Web, 2004. [25]F. McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [26] Y. Minamide. Aproximación estática de páginas web generadas dinámicamente. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [27] L. Page, S. Brin, R. Motwani y T. Winograd. El ranking de citas PageRank: Trayendo orden a la web. Informe técnico, Universidad de Stanford, Stanford, CA, 1998. [28] S. Pandey y C. Olston. Rastreo web centrado en el usuario. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [29] M. Richardson y P. Domingos. El surfista inteligente: combinación probabilística de la información de enlaces y contenido en PageRank. En Advances in Neural Information Processing Systems 14, pp. 1441-1448. Cambridge, MA: MIT Press, 2002. [30]C. Sherman.\nCambridge, MA: MIT Press, 2002. [30]C. Sherman. Teoma vs. Google, Ronda 2. Disponible en World Wide Web (http://dc.internet.com/news/article.php/1002061), 2002. [31] T. Upstill, N. Craswell y D. Hawking. Prediciendo fama y fortuna: ¿PageRank o grado de entrada? En el Octavo Simposio de Computación de Documentos Australasiano. 2003. [32] T. Upstill, N. Craswell y D. Hawking. Evidencia independiente de la consulta en la búsqueda de la página de inicio. En ACM Transactions on Information Systems. 2003. 715 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "static rank": {
            "translated_key": "clasificación estática",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Beyond PageRank: Machine Learning for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We show that we can significantly outperform PageRank using features that are independent of the link structure of the Web.",
                "We gain a further boost in accuracy by using data on the frequency at which users visit Web pages.",
                "We use RankNet, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random).",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning.",
                "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval.",
                "General Terms Algorithms, Measurement, Performance, Experimentation. 1.",
                "INTRODUCTION Over the past decade, the Web has grown exponentially in size.",
                "Unfortunately, this growth has not been isolated to good-quality pages.",
                "The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly.",
                "The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information.",
                "Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first.",
                "To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking).",
                "However, having a good query-independent ranking (static ranking) is also crucially important for a search engine.",
                "A good static ranking algorithm provides numerous benefits: • Relevance: The <br>static rank</br> of a page provides a general indicator to the overall quality of the page.",
                "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by <br>static rank</br>.",
                "By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found.",
                "The more accurate the <br>static rank</br>, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages.",
                "Among other factors, the <br>static rank</br> of a page is used to determine this prioritization.",
                "A better <br>static rank</br> thus provides the engine with a higher quality, more upto-date index.",
                "Google is often regarded as the first commercially successful search engine.",
                "Their ranking was originally based on the PageRank algorithm [5][27].",
                "Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the static ranking of Web pages.",
                "Though PageRank has historically been thought to perform quite well, there has yet been little academic evidence to support this claim.",
                "Even worse, there has recently been work showing that PageRank may not perform any better than other simple measures on certain tasks.",
                "Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than PageRank [32].",
                "They found similar results for the task of finding high quality companies [31].",
                "PageRank has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17].",
                "Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as PageRank.",
                "Despite these, the general belief remains among many, both academic and in the public, that PageRank is an essential factor for a good <br>static rank</br>.",
                "Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text.",
                "In this paper, we show there are a number of simple url- or pagebased features that significantly outperform PageRank (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web.",
                "We combine these and other static features using machine learning to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels).",
                "A machine learning approach for static ranking has other advantages besides the quality of the ranking.",
                "Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages <br>static rank</br> to an undeserved level through questionable techniques, also known as Web spamming).",
                "This is particularly true if the feature set is not known.",
                "In contrast, a single measure like PageRank can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page.",
                "With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank.",
                "This flexibility allows a ranking system to rapidly react to new spamming techniques.",
                "A machine learning approach to static ranking is also able to take advantage of any advances in the machine learning field.",
                "For example, recent work on adversarial classification [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
                "Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the <br>static rank</br>.",
                "By moving static ranking to a machine learning framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of machine learning.",
                "Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet.",
                "These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful.",
                "For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page.",
                "A machine learning approach thus allows rapid development of a good static algorithm in new domains.",
                "This papers contribution is a systematic study of static features, including PageRank, for the purposes of (statically) ranking Web pages.",
                "Previous studies on PageRank typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages).",
                "Also, the performance of PageRank and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering.",
                "In contrast, we explore the use of PageRank and other features for the direct task of statically ranking Web pages.",
                "We first briefly describe the PageRank algorithm.",
                "In Section 3 we introduce RankNet, the machine learning technique used to combine static features into a final ranking.",
                "Section 4 describes the static features.",
                "The heart of the paper is in Section 5, which presents our experiments and results.",
                "We conclude with a discussion of related and future work. 2.",
                "PAGERANK The basic idea behind PageRank is simple: a link from a Web page to another can be seen as an endorsement of that page.",
                "In general, links are made by people.",
                "As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality.",
                "We can take advantage of this linkage information to order Web pages according to their perceived quality.",
                "Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step.",
                "In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links.",
                "If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j.",
                "The PageRank score for node j is defined as this probability: PR(j)=P(j).",
                "Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform).",
                "The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page.",
                "An alternative view for equation (1) is that each page is assigned a quality, P(j).",
                "A page gives an equal share of its quality to each page it points to.",
                "PageRank is computationally expensive.",
                "Our collection of 5 billion pages contains approximately 370 billion links.",
                "Computing PageRank requires iterating over these billions of links multiple times (until convergence).",
                "It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them.",
                "Though much work has been done on optimizing the PageRank computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3.",
                "RANKNET Much work in machine learning has been done on the problems of classification and regression.",
                "Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi.",
                "The classification problem is to learn a function f that maps yi=f(xi), for all i.",
                "When yi is real-valued as well, this is called regression.",
                "Static ranking can be seen as a regression problem.",
                "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a regression function that mapped each pages features to their rank.",
                "However, this over-constrains the problem we wish to solve.",
                "All we really care about is the order of the pages, not the actual value assigned to them.",
                "Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them.",
                "For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j.",
                "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a regression function, the result of this process is a function (f) that maps feature vectors to real values.",
                "This function can still be applied anywhere that a regressionlearned function could be applied.",
                "The only difference is the technique used to learn the function.",
                "By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do regression techniques.",
                "We used RankNet [7], one of the aforementioned techniques for learning ranking functions, to learn our <br>static rank</br> function.",
                "RankNet is a straightforward modification to the standard neural network back-prop algorithm.",
                "As with back-prop, RankNet attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight.",
                "The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the RankNet cost function is based on the difference between a pair of network outputs.",
                "That is, for each pair of feature vectors <i,j> in the training set, RankNet computes the network outputs oi and oj.",
                "Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost.",
                "RankNet also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function).",
                "In this paper, we used a probability of one for all pairs.",
                "In the next section, we will discuss the features used in our feature vectors, xi. 4.",
                "FEATURES To apply RankNet (or other machine learning techniques) to the ranking problem, we needed to extract a set of features from each page.",
                "We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity).",
                "We also optionally used the PageRank of a page as a feature.",
                "Below, we describe each of these feature categories in more detail.",
                "PageRank We computed PageRank on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages).",
                "This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines.",
                "Because PageRank is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible.",
                "Most previous studies on PageRank used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed PageRank using the standard value of 0.85 for α.",
                "Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time.",
                "We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN.",
                "The data is aggregated into a count, for each Web page, of the number of users who viewed that page.",
                "Though popularity data is generally unavailable, there are two other sources for it.",
                "The first is from proxy logs.",
                "For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus.",
                "Unfortunately, proxy data is quite biased and relatively small.",
                "Another source, internal to search engines, are records of which results their users clicked on.",
                "Such data was used by the search engine Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
                "An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search.",
                "The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed.",
                "More details are provided in section 5.5.",
                "Anchor text and inlinks These features are based on the information associated with links to the page in question.",
                "It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc.",
                "Page This category consists of features which may be determined by looking at the page (and its URL) alone.",
                "We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc.",
                "Domain This category contains features that are computed as averages across all pages in the domain.",
                "For example, the average number of outlinks on any page and the average PageRank.",
                "Many of these features have been used by others for ranking Web pages, particularly the anchor and page features.",
                "As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for static ranking.",
                "Also, to our knowledge, this is the first study on the use of actual page visitation popularity for static ranking.",
                "The closest similar work is on using click-through behavior (that is, which search engine results the users click on) to affect dynamic ranking (see e.g., [20]).",
                "Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for feature-based ranking). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages.",
                "Unless otherwise specified, fRank was trained with all of the features. 5.",
                "EXPERIMENTS In this section, we will demonstrate that we can out perform PageRank by applying machine learning to a straightforward set of features.",
                "Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a static ranking, we needed a gold standard defining the correct ordering for a set of pages.",
                "For this, we employed a dataset which contains human judgments for 28000 queries.",
                "For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges.",
                "The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent.",
                "There are approximately 500k judgments in all, or an average of 18 ratings per query.",
                "The queries are selected by randomly choosing queries from among those issued to the MSN search engine.",
                "The probability that a query is selected is proportional to its frequency among all 709 of the queries.",
                "As a result, common queries are more likely to be judged than uncommon queries.",
                "As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture.",
                "The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs search engine).",
                "This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query.",
                "Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries.",
                "This bias is good when evaluating the quality of static ranking for the purposes of index ordering and returning relevant documents.",
                "This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries.",
                "Because of this bias, however, the results in this paper are not applicable to crawl prioritization.",
                "In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages.",
                "To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query.",
                "The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high <br>static rank</br>.",
                "Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query.",
                "We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively.",
                "Each set contains all of the ratings for a given query, and no query appears in more than one set.",
                "The training set was used to train fRank.",
                "The validation set was used to select the model that had the highest performance.",
                "The test set was used for the final results.",
                "This data gives us a query-independent ordering of pages.",
                "The goal for a static ranking algorithm will be to reproduce this ordering as closely as possible.",
                "In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a static ranking.",
                "The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages.",
                "If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of relevance for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
                "First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score).",
                "Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the <br>static rank</br> algorithm orders them correctly. 5.3 Method We trained fRank (a RankNet based neural network) using the following parameters.",
                "We used a fully connected 2 layer network.",
                "The hidden layer had 10 hidden nodes.",
                "The input weights to this layer were all initialized to be zero.",
                "The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1].",
                "We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output.",
                "The cost function is the pairwise cross entropy cost function as discussed in section 3.",
                "The features in the training set were normalized to have zero mean and unit standard deviation.",
                "The same linear transformation was then applied to the features in the validation and test sets.",
                "For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other.",
                "The pairings were chosen uniformly at random (with replacement) from all possible pairings.",
                "When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs.",
                "Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread.",
                "We trained the network for 30 epochs.",
                "On each epoch, the training pairs were randomly shuffled.",
                "The initial training rate was 0.001.",
                "At each epoch, we checked the error on the training set.",
                "If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot.",
                "The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased.",
                "After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement).",
                "The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set.",
                "We report the pairwise accuracy on the test set, calculated using all possible pairs.",
                "These parameters were determined and fixed before the <br>static rank</br> experiments in this paper.",
                "In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7].",
                "Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them.",
                "The only exception was the popularity features.",
                "As with most Web phenomenon, we found that the distribution of site popularity is Zipfian.",
                "To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple machine learning methods such as naïve Bayes.",
                "In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the PageRank for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms PageRank for the purposes of static ranking.",
                "With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of PageRank (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages).",
                "Note that one of fRanks input features is the PageRank of the page, so we would expect it to perform no worse than PageRank.",
                "The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page.",
                "Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 PageRank 56.70 fRank 67.43 There are a number of decisions that go into the computation of PageRank, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc.",
                "We were able to obtain a computation of PageRank from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters.",
                "It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation.",
                "We thus concluded that the quality of the PageRank is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it.",
                "We also wanted to find how well each feature set performed.",
                "To answer this, for each feature set, we trained and tested fRank using only that set of features.",
                "The results are shown in Table 2.",
                "As can be seen, every single feature set individually outperformed PageRank on this test.",
                "Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets.",
                "This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page.",
                "This is contrary to the common belief that the Web graph structure is the key to finding a good static ranking of Web pages.",
                "Table 2: Results for individual feature sets.",
                "Feature Set Accuracy (%) PageRank 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways.",
                "This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features.",
                "To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study.",
                "That is, for each set of features, we trained a network to contain all of the features except that set.",
                "We then compared the performance of the resulting network to the performance of the network with all of the features.",
                "Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set.",
                "Table 3: Ablation study.",
                "Shown is the decrease in accuracy when we train a network that has all but the given set of features.",
                "The last line is shows the effect of removing the anchor, PageRank, and domain features, hence a model containing no network or link-based information whatsoever.",
                "Feature Set Decrease in Accuracy PageRank 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, PageRank & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study.",
                "Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set.",
                "Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless.",
                "Beginning with no features, we greedily added the feature set that improved performance the most.",
                "The results are shown in Table 4.",
                "For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%.",
                "Table 4: fRank performance as feature sets are added.",
                "At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets).",
                "Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +PageRank 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of PageRank vs. fRank.",
                "In Table 5 are the top ten URLs returned for PageRank and for fRank.",
                "PageRanks results are heavily weighted towards technology sites.",
                "It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc.",
                "PageRanks bias toward technology can be explained through two processes.",
                "First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime.",
                "These generally link back to, in these examples, the Internet Explorer and QuickTime download sites.",
                "Consequently, PageRank ranks those pages highly.",
                "Though these pages are important, they are not as important as it may seem by looking at the link structure alone.",
                "One fix for this is to add information about the link to the PageRank computation, such as the size of the text, whether it was at the bottom of the page, etc.",
                "The other bias comes from the fact that the population of Web site authors is different than the population of Web users.",
                "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual visitation popularity of a site (the popularity feature set), is able to eliminate some of that bias.",
                "It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked.",
                "The results confirm that fRank outperforms PageRank in pairwise accuracy.",
                "The two most important feature sets are the page and popularity features.",
                "This is surprising, as the page features consisted only of a few (8) simple features.",
                "Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best.",
                "In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users.",
                "For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user.",
                "This limited the possible features we could derive from this data.",
                "For possible extensions, see section 6.3, future work.",
                "For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user.",
                "However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
                "One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user.",
                "Adding this feature dramatically improved the performance of fRank.",
                "We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain.",
                "We did this by using the set of features shown in Table 6.",
                "Table 6: URL functions used to compute the Popularity feature set.",
                "Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table.",
                "The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question.",
                "For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html.",
                "As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further.",
                "Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data.",
                "It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected.",
                "In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set.",
                "Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank.",
                "The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy.",
                "In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy.",
                "Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions.",
                "First, fRank performs significantly better than PageRank, even without any information about the Web graph.",
                "Second, the page level and popularity features were the most significant contributors to pairwise accuracy.",
                "Third, by collecting more popularity data, we can continue to improve fRanks performance.",
                "The popularity data provides two benefits to fRank.",
                "First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer.",
                "Second, the popularity data is more timely than PageRanks link information.",
                "The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6.",
                "RELATED AND FUTURE WORK 6.1 Improvements to PageRank Since the original PageRank paper, there has been work on improving it.",
                "Much of that work centers on speeding up and parallelizing the computation [15][25].",
                "One recognized problem with PageRank is that of topic drift: A page about dogs will have high PageRank if it is linked to by many pages that themselves have high rank, regardless of their topic.",
                "In contrast, a search engine user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs.",
                "Hence, a link that is on topic should have higher weight than a link that is not.",
                "Richardson and Domingoss Query Dependent PageRank [29] and Haveliwalas Topic-Sensitive PageRank [16] are two approaches that tackle this problem.",
                "Other variations to PageRank include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3].",
                "See Langville and Meyer [23] for a good survey of these, and other modifications to PageRank. 6.2 Other related work PageRank is not the only link analysis algorithm used for ranking Web pages.",
                "The most well-known other is HITS [22], which is used by the Teoma search engine [30].",
                "HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs.",
                "Previous work has shown HITS to perform comparably to PageRank [1].",
                "One field of interest is that of static index pruning (see e.g., Carmel et al. [8]).",
                "Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query.",
                "The pruning is typically done based on the frequency of query terms.",
                "Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search.",
                "Similar methods could be incorporated into the <br>static rank</br> (e.g., how many frequent queries contain words found on this page).",
                "Others have investigated the effect that PageRank has on the Web at large [9].",
                "They argue that pages with high PageRank are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher PageRank than other pages.",
                "The same may occur for the popularity data.",
                "If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity.",
                "Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure.",
                "The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity.",
                "One interesting related work is that of Ivory and Hearst [19].",
                "Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience.",
                "They used over 100 page level features, as well as features encompassing the performance and structure of the site.",
                "This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features.",
                "The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set.",
                "Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future.",
                "Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which search engine results are clicked on.",
                "Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking.",
                "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall relevance of a search engine (i.e., the dynamic ranking).",
                "They do not apply their techniques to the problem of static ranking. 6.3 Future work There are many ways in which we would like to extend this work.",
                "First, fRank uses only a small number of features.",
                "We believe we could achieve even more significant results with more features.",
                "In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page).",
                "Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc.",
                "Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables.",
                "For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features.",
                "The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents.",
                "In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair.",
                "For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2.",
                "The experiments in this paper are biased toward pages that have higher than average quality.",
                "Also, fRank with all of the features can only be applied to pages that have already been crawled.",
                "Thus, fRank is primarily useful for index ordering and improving relevance, not for directing the crawl.",
                "We would like to investigate a machine learning approach for crawl prioritization as well.",
                "It may be that a combination of methods is best: for example, using PageRank to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy.",
                "Another interesting direction for exploration is to incorporate fRank and page-level features directly into the PageRank computation itself.",
                "Work on biasing the PageRank jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach.",
                "There is reason to believe that a direct application of [29], using the fRank of a page for its relevance, could lead to an improved overall <br>static rank</br>.",
                "Finally, the popularity data can be used in other interesting ways.",
                "The general surfing and searching habits of Web users varies by time of day.",
                "Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively).",
                "We can gain insight into these differences by using the popularity data, divided into segments of the day.",
                "When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages.",
                "We also plan to explore popularity features that use more than just the counts of how often a page was visited.",
                "For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc.",
                "Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14].",
                "Finally, the popularity data could be used as the label rather than as a feature.",
                "Using fRank in this way to predict the popularity of a page may useful for the tasks of relevance, efficiency, and crawl priority.",
                "There is also significantly more popularity data than human labeled data, potentially enabling more complex machine learning methods, and significantly more features. 7.",
                "CONCLUSIONS A good static ranking is an important component for todays search engines and information retrieval systems.",
                "We have demonstrated that PageRank does not provide a very good static ranking; there are many simple features that individually out perform PageRank.",
                "By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than PageRank alone.",
                "A qualitative evaluation of the top documents shows that fRank is less technology-biased than PageRank; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit.",
                "The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as adversarial classification.",
                "We have only begun to explore the options, and believe that significant strides can be made in the area of static ranking by further experimentation with additional features, other machine learning techniques, and additional sources of data. 8.",
                "ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional PageRank computations and to Timo Burkard for assistance with the popularity data.",
                "Many thanks to Chris Burges for providing code and significant support in using training RankNets.",
                "Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of Web documents.",
                "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
                "PageRank as a function of the damping factor.",
                "In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims.",
                "A machine learning architecture for optimizing web search engines.",
                "In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998.",
                "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson.",
                "Efficient PageRank approximation via graph aggregation.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the 22nd International Conference on Machine Learning, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy.",
                "Impact of search engines on page popularity.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams.",
                "Page Quality: In search of an unbiased web ranking.",
                "In Proceedings of the ACM SIGMOD 2005 Conference.",
                "Baltimore, Maryland.",
                "June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proceedings of the 28th Annual Conference on Research and Development in Information Retrieval (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
                "Adversarial Classification.",
                "In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y.",
                "Singer.",
                "Log-linear models for label-ranking.",
                "In Advances in Neural Information Processing Systems 16.",
                "Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005).",
                "Evaluating implicit measures to improve the search experiences.",
                "In the ACM Transactions on Information Systems, 23(2), pp. 147-168.",
                "April 2005. [15]T. Haveliwala.",
                "Efficient computation of PageRank.",
                "Stanford University Technical Report, 1999. [16]T. Haveliwala.",
                "Topic-sensitive PageRank.",
                "In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell.",
                "Very large scale retrieval and Web search.",
                "In D. Harman and E. Voorhees (eds), The TREC Book.",
                "MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer.",
                "Support vector learning for ordinal regression.",
                "In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst.",
                "Statistical profiles of highly-rated Web sites.",
                "In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay.",
                "Accurately Interpreting Clickthrough Data as Implicit Feedback.",
                "In Proceedings of the Conference on Research and Development in Information Retrieval (SIGIR), 2005. [22]J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit.",
                "The effect of the back button in a random walk: application for PageRank.",
                "In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry.",
                "A uniform approach to accelerated PageRank computation.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide.",
                "Static approximation of dynamically generated Web pages.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston.",
                "User-centric Web crawling.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos.",
                "The intelligent surfer: probabilistic combination of link and content information in PageRank.",
                "In Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
                "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.",
                "Teoma vs. Google, Round 2.",
                "Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: PageRank or indegree?.",
                "In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking.",
                "Query-independent evidence in home page finding.",
                "In ACM Transactions on Information Systems. 2003. 715"
            ],
            "original_annotated_samples": [
                "A good static ranking algorithm provides numerous benefits: • Relevance: The <br>static rank</br> of a page provides a general indicator to the overall quality of the page.",
                "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by <br>static rank</br>.",
                "The more accurate the <br>static rank</br>, the better this early-stopping ability, and hence the quicker the search engine may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Among other factors, the <br>static rank</br> of a page is used to determine this prioritization.",
                "A better <br>static rank</br> thus provides the engine with a higher quality, more upto-date index."
            ],
            "translated_annotated_samples": [
                "Un buen algoritmo de <br>clasificación estática</br> proporciona numerosos beneficios: • Relevancia: La <br>clasificación estática</br> de una página proporciona un indicador general de la calidad de la página.",
                "Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por <br>rango estático</br>.",
                "Cuanto más preciso sea el <br>rango estático</br>, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla.",
                "Entre otros factores, se utiliza la <br>clasificación estática</br> de una página para determinar esta priorización.",
                "Un <br>rango estático</br> mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado."
            ],
            "translated_text": "Más allá de PageRank: Aprendizaje automático para la clasificación estática. Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un motor de búsqueda. Un buen algoritmo de <br>clasificación estática</br> proporciona numerosos beneficios: • Relevancia: La <br>clasificación estática</br> de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por <br>rango estático</br>. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el <br>rango estático</br>, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el motor de búsqueda a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la <br>clasificación estática</br> de una página para determinar esta priorización. Un <br>rango estático</br> mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. ",
            "candidates": [],
            "error": [
                [
                    "clasificación estática",
                    "clasificación estática",
                    "rango estático",
                    "rango estático",
                    "clasificación estática",
                    "rango estático"
                ]
            ]
        },
        "search engine": {
            "translated_key": "motor de búsqueda",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Beyond PageRank: Machine Learning for Static Ranking Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015 amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 brill@microsoft.com ABSTRACT Since the publication of Brin and Pages paper on PageRank, many in the Web community have depended on PageRank for the static (query-independent) ordering of Web pages.",
                "We show that we can significantly outperform PageRank using features that are independent of the link structure of the Web.",
                "We gain a further boost in accuracy by using data on the frequency at which users visit Web pages.",
                "We use RankNet, a ranking machine learning algorithm, to combine these and other static features based on anchor text and domain characteristics.",
                "The resulting model achieves a static ranking pairwise accuracy of 67.3% (vs. 56.7% for PageRank or 50% for random).",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning.",
                "H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval.",
                "General Terms Algorithms, Measurement, Performance, Experimentation. 1.",
                "INTRODUCTION Over the past decade, the Web has grown exponentially in size.",
                "Unfortunately, this growth has not been isolated to good-quality pages.",
                "The number of incorrect, spamming, and malicious (e.g., phishing) sites has also grown rapidly.",
                "The sheer number of both good and bad pages on the Web has led to an increasing reliance on search engines for the discovery of useful information.",
                "Users rely on search engines not only to return pages related to their search query, but also to separate the good from the bad, and order results so that the best pages are suggested first.",
                "To date, most work on Web page ranking has focused on improving the ordering of the results returned to the user (querydependent ranking, or dynamic ranking).",
                "However, having a good query-independent ranking (static ranking) is also crucially important for a <br>search engine</br>.",
                "A good static ranking algorithm provides numerous benefits: • Relevance: The static rank of a page provides a general indicator to the overall quality of the page.",
                "This is a useful input to the dynamic ranking algorithm. • Efficiency: Typically, the search engines index is ordered by static rank.",
                "By traversing the index from highquality to low-quality pages, the dynamic ranker may abort the search when it determines that no later page will have as high of a dynamic rank as those already found.",
                "The more accurate the static rank, the better this early-stopping ability, and hence the quicker the <br>search engine</br> may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Search engines need a way to prioritize their crawl-to determine which pages to recrawl, how frequently, and how often to seek out new pages.",
                "Among other factors, the static rank of a page is used to determine this prioritization.",
                "A better static rank thus provides the engine with a higher quality, more upto-date index.",
                "Google is often regarded as the first commercially successful <br>search engine</br>.",
                "Their ranking was originally based on the PageRank algorithm [5][27].",
                "Due to this (and possibly due to Googles promotion of PageRank to the public), PageRank is widely regarded as the best method for the static ranking of Web pages.",
                "Though PageRank has historically been thought to perform quite well, there has yet been little academic evidence to support this claim.",
                "Even worse, there has recently been work showing that PageRank may not perform any better than other simple measures on certain tasks.",
                "Upstill et al. have found that for the task of finding home pages, the number of pages linking to a page and the type of URL were as, or more, effective than PageRank [32].",
                "They found similar results for the task of finding high quality companies [31].",
                "PageRank has also been used in systems for TRECs very large collection and Web track competitions, but with much less success than had been expected [17].",
                "Finally, Amento et al. [1] found that simple features, such as the number of pages on a site, performed as well as PageRank.",
                "Despite these, the general belief remains among many, both academic and in the public, that PageRank is an essential factor for a good static rank.",
                "Failing this, it is still assumed that using the link structure is crucial, in the form of the number of inlinks or the amount of anchor text.",
                "In this paper, we show there are a number of simple url- or pagebased features that significantly outperform PageRank (for the purposes of statically ranking Web pages) despite ignoring the structure of the Web.",
                "We combine these and other static features using machine learning to achieve a ranking system that is significantly better than PageRank (in pairwise agreement with human labels).",
                "A machine learning approach for static ranking has other advantages besides the quality of the ranking.",
                "Because the measure consists of many features, it is harder for malicious users to manipulate it (i.e., to raise their pages static rank to an undeserved level through questionable techniques, also known as Web spamming).",
                "This is particularly true if the feature set is not known.",
                "In contrast, a single measure like PageRank can be easier to manipulate because spammers need only concentrate on one goal: how to cause more pages to point to their page.",
                "With an algorithm that learns, a feature that becomes unusable due to spammer manipulation will simply be reduced or removed from the final computation of rank.",
                "This flexibility allows a ranking system to rapidly react to new spamming techniques.",
                "A machine learning approach to static ranking is also able to take advantage of any advances in the machine learning field.",
                "For example, recent work on adversarial classification [12] suggests that it may be possible to explicitly model the Web page spammers (the adversary) actions, adjusting the ranking model in advance of the spammers attempts to circumvent it.",
                "Another example is the elimination of outliers in constructing the model, which helps reduce the effect that unique sites may have on the overall quality of the static rank.",
                "By moving static ranking to a machine learning framework, we not only gain in accuracy, but also gain in the ability to react to spammers actions, to rapidly add new features to the ranking algorithm, and to leverage advances in the rapidly growing field of machine learning.",
                "Finally, we believe there will be significant advantages to using this technique for other domains, such as searching a local hard drive or a corporations intranet.",
                "These are domains where the link structure is particularly weak (or non-existent), but there are other domain-specific features that could be just as powerful.",
                "For example, the author of an intranet page and his/her position in the organization (e.g., CEO, manager, or developer) could provide significant clues as to the importance of that page.",
                "A machine learning approach thus allows rapid development of a good static algorithm in new domains.",
                "This papers contribution is a systematic study of static features, including PageRank, for the purposes of (statically) ranking Web pages.",
                "Previous studies on PageRank typically used subsets of the Web that are significantly smaller (e.g., the TREC VLC2 corpus, used by many, contains only 19 million pages).",
                "Also, the performance of PageRank and other static features has typically been evaluated in the context of a complete system for dynamic ranking, or for other tasks such as question answering.",
                "In contrast, we explore the use of PageRank and other features for the direct task of statically ranking Web pages.",
                "We first briefly describe the PageRank algorithm.",
                "In Section 3 we introduce RankNet, the machine learning technique used to combine static features into a final ranking.",
                "Section 4 describes the static features.",
                "The heart of the paper is in Section 5, which presents our experiments and results.",
                "We conclude with a discussion of related and future work. 2.",
                "PAGERANK The basic idea behind PageRank is simple: a link from a Web page to another can be seen as an endorsement of that page.",
                "In general, links are made by people.",
                "As such, they are indicative of the quality of the pages to which they point - when creating a page, an author presumably chooses to link to pages deemed to be of good quality.",
                "We can take advantage of this linkage information to order Web pages according to their perceived quality.",
                "Imagine a Web surfer who jumps from Web page to Web page, choosing with uniform probability which link to follow at each step.",
                "In order to reduce the effect of dead-ends or endless cycles the surfer will occasionally jump to a random page with some small probability α, or when on a page with no out-links.",
                "If averaged over a sufficient number of steps, the probability the surfer is on page j at some point in time is given by the formula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Where Fi is the set of pages that page i links to, and Bj is the set of pages that link to page j.",
                "The PageRank score for node j is defined as this probability: PR(j)=P(j).",
                "Because equation (1) is recursive, it must be iteratively evaluated until P(j) converges (typically, the initial distribution for P(j) is uniform).",
                "The intuition is, because a random surfer would end up at the page more frequently, it is likely a better page.",
                "An alternative view for equation (1) is that each page is assigned a quality, P(j).",
                "A page gives an equal share of its quality to each page it points to.",
                "PageRank is computationally expensive.",
                "Our collection of 5 billion pages contains approximately 370 billion links.",
                "Computing PageRank requires iterating over these billions of links multiple times (until convergence).",
                "It requires large amounts of memory (or very smart caching schemes that slow the computation down even further), and if spread across multiple machines, requires significant communication between them.",
                "Though much work has been done on optimizing the PageRank computation (see e.g., [25] and [6]), it remains a relatively slow, computationally expensive property to compute. 3.",
                "RANKNET Much work in machine learning has been done on the problems of classification and regression.",
                "Let X={xi} be a collection of feature vectors (typically, a feature is any real valued number), and Y={yi} be a collection of associated classes, where yi is the class of the object described by feature vector xi.",
                "The classification problem is to learn a function f that maps yi=f(xi), for all i.",
                "When yi is real-valued as well, this is called regression.",
                "Static ranking can be seen as a regression problem.",
                "If we let xi represent features of page i, and yi be a value (say, the rank) for each page, we could learn a regression function that mapped each pages features to their rank.",
                "However, this over-constrains the problem we wish to solve.",
                "All we really care about is the order of the pages, not the actual value assigned to them.",
                "Recent work on this ranking problem [7][13][18] directly attempts to optimize the ordering of the objects, rather than the value assigned to them.",
                "For these, let Z={<i,j>} be a collection of pairs of items, where item i should be assigned a higher value than item j.",
                "The goal of the ranking problem, then, is to learn a function f such that, )()(,, ji ffji xxZ >∈∀ 708 Note that, as with learning a regression function, the result of this process is a function (f) that maps feature vectors to real values.",
                "This function can still be applied anywhere that a regressionlearned function could be applied.",
                "The only difference is the technique used to learn the function.",
                "By directly optimizing the ordering of objects, these methods are able to learn a function that does a better job of ranking than do regression techniques.",
                "We used RankNet [7], one of the aforementioned techniques for learning ranking functions, to learn our static rank function.",
                "RankNet is a straightforward modification to the standard neural network back-prop algorithm.",
                "As with back-prop, RankNet attempts to minimize the value of a cost function by adjusting each weight in the network according to the gradient of the cost function with respect to that weight.",
                "The difference is that, while a typical neural network cost function is based on the difference between the network output and the desired output, the RankNet cost function is based on the difference between a pair of network outputs.",
                "That is, for each pair of feature vectors <i,j> in the training set, RankNet computes the network outputs oi and oj.",
                "Since vector i is supposed to be ranked higher than vector j, the larger is oj-oi, the larger the cost.",
                "RankNet also allows the pairs in Z to be weighted with a confidence (posed as the probability that the pair satisfies the ordering induced by the ranking function).",
                "In this paper, we used a probability of one for all pairs.",
                "In the next section, we will discuss the features used in our feature vectors, xi. 4.",
                "FEATURES To apply RankNet (or other machine learning techniques) to the ranking problem, we needed to extract a set of features from each page.",
                "We divided our feature set into four, mutually exclusive, categories: page-level (Page), domain-level (Domain), anchor text and inlinks (Anchor), and popularity (Popularity).",
                "We also optionally used the PageRank of a page as a feature.",
                "Below, we describe each of these feature categories in more detail.",
                "PageRank We computed PageRank on a Web graph of 5 billion crawled pages (and 20 billion known URLs linked to by these pages).",
                "This represents a significant portion of the Web, and is approximately the same number of pages as are used by Google, Yahoo, and MSN for their search engines.",
                "Because PageRank is a graph-based algorithm, it is important that it be run on as large a subset of the Web as possible.",
                "Most previous studies on PageRank used subsets of the Web that are significantly smaller (e.g. the TREC VLC2 corpus, used by many, contains only 19 million pages) We computed PageRank using the standard value of 0.85 for α.",
                "Popularity Another feature we used is the actual popularity of a Web page, measured as the number of times that it has been visited by users over some period of time.",
                "We have access to such data from users who have installed the MSN toolbar and have opted to provide it to MSN.",
                "The data is aggregated into a count, for each Web page, of the number of users who viewed that page.",
                "Though popularity data is generally unavailable, there are two other sources for it.",
                "The first is from proxy logs.",
                "For example, a university that requires its students to use a proxy has a record of all the pages they have visited while on campus.",
                "Unfortunately, proxy data is quite biased and relatively small.",
                "Another source, internal to search engines, are records of which results their users clicked on.",
                "Such data was used by the <br>search engine</br> Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
                "An advantage of the toolbar data over this is that it contains information about URL visits that are not just the result of a search.",
                "The raw popularity is processed into a number of features such as the number of times a page was viewed and the number of times any page in the domain was viewed.",
                "More details are provided in section 5.5.",
                "Anchor text and inlinks These features are based on the information associated with links to the page in question.",
                "It includes features such as the total amount of text in links pointing to the page (anchor text), the number of unique words in that text, etc.",
                "Page This category consists of features which may be determined by looking at the page (and its URL) alone.",
                "We used only eight, simple features such as the number of words in the body, the frequency of the most common term, etc.",
                "Domain This category contains features that are computed as averages across all pages in the domain.",
                "For example, the average number of outlinks on any page and the average PageRank.",
                "Many of these features have been used by others for ranking Web pages, particularly the anchor and page features.",
                "As mentioned, the evaluation is typically for dynamic ranking, and we wish to evaluate the use of them for static ranking.",
                "Also, to our knowledge, this is the first study on the use of actual page visitation popularity for static ranking.",
                "The closest similar work is on using click-through behavior (that is, which <br>search engine</br> results the users click on) to affect dynamic ranking (see e.g., [20]).",
                "Because we use a wide variety of features to come up with a static ranking, we refer to this as fRank (for feature-based ranking). fRank uses RankNet and the set of features described in this section to learn a ranking function for Web pages.",
                "Unless otherwise specified, fRank was trained with all of the features. 5.",
                "EXPERIMENTS In this section, we will demonstrate that we can out perform PageRank by applying machine learning to a straightforward set of features.",
                "Before the results, we first discuss the data, the performance metric, and the training method. 5.1 Data In order to evaluate the quality of a static ranking, we needed a gold standard defining the correct ordering for a set of pages.",
                "For this, we employed a dataset which contains human judgments for 28000 queries.",
                "For each query, a number of results are manually assigned a rating, from 0 to 4, by human judges.",
                "The rating is meant to be a measure of how relevant the result is for the query, where 0 means poor and 4 means excellent.",
                "There are approximately 500k judgments in all, or an average of 18 ratings per query.",
                "The queries are selected by randomly choosing queries from among those issued to the MSN <br>search engine</br>.",
                "The probability that a query is selected is proportional to its frequency among all 709 of the queries.",
                "As a result, common queries are more likely to be judged than uncommon queries.",
                "As an example of how diverse the queries are, the first four queries in the training set are chef schools, chicagoland speedway, eagles fan club, and Turkish culture.",
                "The documents selected for judging are those that we expected would, on average, be reasonably relevant (for example, the top ten documents returned by MSNs <br>search engine</br>).",
                "This provides significantly more information than randomly selecting documents on the Web, the vast majority of which would be irrelevant to a given query.",
                "Because of this process, the judged pages tend to be of higher quality than the average page on the Web, and tend to be pages that will be returned for common search queries.",
                "This bias is good when evaluating the quality of static ranking for the purposes of index ordering and returning relevant documents.",
                "This is because the most important portion of the index to be well-ordered and relevant is the portion that is frequently returned for search queries.",
                "Because of this bias, however, the results in this paper are not applicable to crawl prioritization.",
                "In order to obtain experimental results on crawl prioritization, we would need ratings on a random sample of Web pages.",
                "To convert the data from query-dependent to query-independent, we simply removed the query, taking the maximum over judgments for a URL that appears in more than one query.",
                "The reasoning behind this is that a page that is relevant for some query and irrelevant for another is probably a decent page and should have a high static rank.",
                "Because we evaluated the pages on queries that occur frequently, our data indicates the correct index ordering, and assigns high value to pages that are likely to be relevant to a common query.",
                "We randomly assigned queries to a training, validation, or test set, such that they contained 84%, 8%, and 8% of the queries, respectively.",
                "Each set contains all of the ratings for a given query, and no query appears in more than one set.",
                "The training set was used to train fRank.",
                "The validation set was used to select the model that had the highest performance.",
                "The test set was used for the final results.",
                "This data gives us a query-independent ordering of pages.",
                "The goal for a static ranking algorithm will be to reproduce this ordering as closely as possible.",
                "In the next section, we describe the measure we used to evaluate this. 5.2 Measure We chose to use pairwise accuracy to evaluate the quality of a static ranking.",
                "The pairwise accuracy is the fraction of time that the ranking algorithm and human judges agree on the ordering of a pair of Web pages.",
                "If S(x) is the static ranking assigned to page x, and H(x) is the human judgment of relevance for x, then consider the following sets: )}()(:,{ yHxHyx >=pH and )}()(:,{ ySxSyx >=pS The pairwise accuracy is the portion of Hp that is also contained in Sp: p pp H SH ∩ =accuracypairwise This measure was chosen for two reasons.",
                "First, the discrete human judgments provide only a partial ordering over Web pages, making it difficult to apply a measure such as the Spearman rank order correlation coefficient (in the pairwise accuracy measure, a pair of documents with the same human judgment does not affect the score).",
                "Second, the pairwise accuracy has an intuitive meaning: it is the fraction of pairs of documents that, when the humans claim one is better than the other, the static rank algorithm orders them correctly. 5.3 Method We trained fRank (a RankNet based neural network) using the following parameters.",
                "We used a fully connected 2 layer network.",
                "The hidden layer had 10 hidden nodes.",
                "The input weights to this layer were all initialized to be zero.",
                "The output layer (just a single node) weights were initialized using a uniform random distribution in the range [-0.1, 0.1].",
                "We used tanh as the transfer function from the inputs to the hidden layer, and a linear function from the hidden layer to the output.",
                "The cost function is the pairwise cross entropy cost function as discussed in section 3.",
                "The features in the training set were normalized to have zero mean and unit standard deviation.",
                "The same linear transformation was then applied to the features in the validation and test sets.",
                "For training, we presented the network with 5 million pairings of pages, where one page had a higher rating than the other.",
                "The pairings were chosen uniformly at random (with replacement) from all possible pairings.",
                "When forming the pairs, we ignored the magnitude of the difference between the ratings (the rating spread) for the two URLs.",
                "Hence, the weight for each pair was constant (one), and the probability of a pair being selected was independent of its rating spread.",
                "We trained the network for 30 epochs.",
                "On each epoch, the training pairs were randomly shuffled.",
                "The initial training rate was 0.001.",
                "At each epoch, we checked the error on the training set.",
                "If the error had increased, then we decreased the training rate, under the hypothesis that the network had probably overshot.",
                "The training rate at each epoch was thus set to: Training rate = 1+ε κ Where κ is the initial rate (0.001), and ε is the number of times the training set error has increased.",
                "After each epoch, we measured the performance of the neural network on the validation set, using 1 million pairs (chosen randomly with replacement).",
                "The network with the highest pairwise accuracy on the validation set was selected, and then tested on the test set.",
                "We report the pairwise accuracy on the test set, calculated using all possible pairs.",
                "These parameters were determined and fixed before the static rank experiments in this paper.",
                "In particular, the choice of initial training rate, number of epochs, and training rate decay function were taken directly from Burges et al [7].",
                "Though we had the option of preprocessing any of the features before they were input to the neural network, we refrained from doing so on most of them.",
                "The only exception was the popularity features.",
                "As with most Web phenomenon, we found that the distribution of site popularity is Zipfian.",
                "To reduce the dynamic range, and hopefully make the feature more useful, we presented the network with both the unpreprocessed, as well as the logarithm, of the popularity features (As with the others, the logarithmic feature values were also normalized to have zero mean and unit standard deviation). 710 Applying fRank to a document is computationally efficient, taking time that is only linear in the number of input features; it is thus within a constant factor of other simple machine learning methods such as naïve Bayes.",
                "In our experiments, computing the fRank for all five billion Web pages was approximately 100 times faster than computing the PageRank for the same set. 5.4 Results As Table 1 shows, fRank significantly outperforms PageRank for the purposes of static ranking.",
                "With a pairwise accuracy of 67.4%, fRank more than doubles the accuracy of PageRank (relative to the baseline of 50%, which is the accuracy that would be achieved by a random ordering of Web pages).",
                "Note that one of fRanks input features is the PageRank of the page, so we would expect it to perform no worse than PageRank.",
                "The significant increase in accuracy implies that the other features (anchor, popularity, etc.) do in fact contain useful information regarding the overall quality of a page.",
                "Table 1: Basic Results Technique Accuracy (%) None (Baseline) 50.00 PageRank 56.70 fRank 67.43 There are a number of decisions that go into the computation of PageRank, such as how to deal with pages that have no outlinks, the choice of α, numeric precision, convergence threshold, etc.",
                "We were able to obtain a computation of PageRank from a completely independent implementation (provided by Marc Najork) that varied somewhat in these parameters.",
                "It achieved a pairwise accuracy of 56.52%, nearly identical to that obtained by our implementation.",
                "We thus concluded that the quality of the PageRank is not sensitive to these minor variations in algorithm, nor was PageRanks low accuracy due to problems with our implementation of it.",
                "We also wanted to find how well each feature set performed.",
                "To answer this, for each feature set, we trained and tested fRank using only that set of features.",
                "The results are shown in Table 2.",
                "As can be seen, every single feature set individually outperformed PageRank on this test.",
                "Perhaps the most interesting result is that the Page-level features had the highest performance out of all the feature sets.",
                "This is surprising because these are features that do not depend on the overall graph structure of the Web, nor even on what pages point to a given page.",
                "This is contrary to the common belief that the Web graph structure is the key to finding a good static ranking of Web pages.",
                "Table 2: Results for individual feature sets.",
                "Feature Set Accuracy (%) PageRank 56.70 Popularity 60.82 Anchor 59.09 Page 63.93 Domain 59.03 All Features 67.43 Because we are using a two-layer neural network, the features in the learned network can interact with each other in interesting, nonlinear ways.",
                "This means that a particular feature that appears to have little value in isolation could actually be very important when used in combination with other features.",
                "To measure the final contribution of a feature set, in the context of all the other features, we performed an ablation study.",
                "That is, for each set of features, we trained a network to contain all of the features except that set.",
                "We then compared the performance of the resulting network to the performance of the network with all of the features.",
                "Table 3 shows the results of this experiment, where the decrease in accuracy is the difference in pairwise accuracy between the network trained with all of the features, and the network missing the given feature set.",
                "Table 3: Ablation study.",
                "Shown is the decrease in accuracy when we train a network that has all but the given set of features.",
                "The last line is shows the effect of removing the anchor, PageRank, and domain features, hence a model containing no network or link-based information whatsoever.",
                "Feature Set Decrease in Accuracy PageRank 0.18 Popularity 0.78 Anchor 0.47 Page 5.42 Domain Anchor, PageRank & Domain 0.10 0.60 The results of the ablation study are consistent with the individual feature set study.",
                "Both show that the most important feature set is the Page-level feature set, and the second most important is the popularity feature set.",
                "Finally, we wished to see how the performance of fRank improved as we added features; we wanted to find at what point adding more feature sets became relatively useless.",
                "Beginning with no features, we greedily added the feature set that improved performance the most.",
                "The results are shown in Table 4.",
                "For example, the fourth line of the table shows that fRank using the page, popularity, and anchor features outperformed any network that used the page, popularity, and some other feature set, and that the performance of this network was 67.25%.",
                "Table 4: fRank performance as feature sets are added.",
                "At each row, the feature set that gave the greatest increase in accuracy was added to the list of features (i.e., we conducted a greedy search over feature sets).",
                "Feature Set Accuracy (%) None 50.00 +Page 63.93 +Popularity 66.83 +Anchor 67.25 +PageRank 67.31 +Domain 67.43 711 Finally, we present a qualitative comparison of PageRank vs. fRank.",
                "In Table 5 are the top ten URLs returned for PageRank and for fRank.",
                "PageRanks results are heavily weighted towards technology sites.",
                "It contains two QuickTime URLs (Apples video playback software), as well as Internet Explorer and FireFox URLs (both of which are Web browsers). fRank, on the other hand, contains more consumer-oriented sites such as American Express, Target, Dell, etc.",
                "PageRanks bias toward technology can be explained through two processes.",
                "First, there are many pages with buttons at the bottom suggesting that the site is optimized for Internet Explorer, or that the visitor needs QuickTime.",
                "These generally link back to, in these examples, the Internet Explorer and QuickTime download sites.",
                "Consequently, PageRank ranks those pages highly.",
                "Though these pages are important, they are not as important as it may seem by looking at the link structure alone.",
                "One fix for this is to add information about the link to the PageRank computation, such as the size of the text, whether it was at the bottom of the page, etc.",
                "The other bias comes from the fact that the population of Web site authors is different than the population of Web users.",
                "Web authors tend to be technologically-oriented, and thus their linking behavior reflects those interests. fRank, by knowing the actual visitation popularity of a site (the popularity feature set), is able to eliminate some of that bias.",
                "It has the ability to depend more on where actual Web users visit rather than where the Web site authors have linked.",
                "The results confirm that fRank outperforms PageRank in pairwise accuracy.",
                "The two most important feature sets are the page and popularity features.",
                "This is surprising, as the page features consisted only of a few (8) simple features.",
                "Further experiments found that, of the page features, those based on the text of the page (as opposed to the URL) performed the best.",
                "In the next section, we explore the popularity feature in more detail. 5.5 Popularity Data As mentioned in section 4, our popularity data came from MSN toolbar users.",
                "For privacy reasons, we had access only to an aggregate count of, for each URL, how many times it was visited by any toolbar user.",
                "This limited the possible features we could derive from this data.",
                "For possible extensions, see section 6.3, future work.",
                "For each URL in our train and test sets, we provided a feature to fRank which was how many times it had been visited by a toolbar user.",
                "However, this feature was quite noisy and sparse, particularly for URLs with query parameters (e.g., http://search.msn.com/results.aspx?q=machine+learning&form=QBHP).",
                "One solution was to provide an additional feature which was the number of times any URL at the given domain was visited by a toolbar user.",
                "Adding this feature dramatically improved the performance of fRank.",
                "We took this one step further and used the built-in hierarchical structure of URLs to construct many levels of backoff between the full URL and the domain.",
                "We did this by using the set of features shown in Table 6.",
                "Table 6: URL functions used to compute the Popularity feature set.",
                "Function Example Exact URL cnn.com/2005/tech/wikipedia.html?v=mobile No Params cnn.com/2005/tech/wikipedia.html Page wikipedia.html URL-1 cnn.com/2005/tech URL-2 cnn.com/2005 … Domain cnn.com Domain+1 cnn.com/2005 … Each URL was assigned one feature for each function shown in the table.",
                "The value of the feature was the count of the number of times a toolbar user visited a URL, where the function applied to that URL matches the function applied to the URL in question.",
                "For example, a users visit to cnn.com/2005/sports.html would increment the Domain and Domain+1 features for the URL cnn.com/2005/tech/wikipedia.html.",
                "As seen in Table 7, adding the domain counts significantly improved the quality of the popularity feature, and adding the numerous backoff functions listed in Table 6 improved the accuracy even further.",
                "Table 7: Effect of adding backoff to the popularity feature set Features Accuracy (%) URL count 58.15 URL and Domain counts 59.31 All backoff functions (Table 6) 60.82 Table 5: Top ten URLs for PageRank vs. fRank PageRank fRank google.com google.com apple.com/quicktime/download yahoo.com amazon.com americanexpress.com yahoo.com hp.com microsoft.com/windows/ie target.com apple.com/quicktime bestbuy.com mapquest.com dell.com ebay.com autotrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 Backing off to subsets of the URL is one technique for dealing with the sparsity of data.",
                "It is also informative to see how the performance of fRank depends on the amount of popularity data that we have collected.",
                "In Figure 1 we show the performance of fRank trained with only the popularity feature set vs. the amount of data we have for the popularity feature set.",
                "Each day, we receive additional popularity data, and as can be seen in the plot, this increases the performance of fRank.",
                "The relation is logarithmic: doubling the amount of popularity data provides a constant improvement in pairwise accuracy.",
                "In summary, we have found that the popularity features provide a useful boost to the overall fRank accuracy.",
                "Gathering more popularity data, as well as employing simple backoff strategies, improve this boost even further. 5.6 Summary of Results The experiments provide a number of conclusions.",
                "First, fRank performs significantly better than PageRank, even without any information about the Web graph.",
                "Second, the page level and popularity features were the most significant contributors to pairwise accuracy.",
                "Third, by collecting more popularity data, we can continue to improve fRanks performance.",
                "The popularity data provides two benefits to fRank.",
                "First, we see that qualitatively, fRanks ordering of Web pages has a more favorable bias than PageRanks. fRanks ordering seems to correspond to what Web users, rather than Web page authors, prefer.",
                "Second, the popularity data is more timely than PageRanks link information.",
                "The toolbar provides information about which Web pages people find interesting right now, whereas links are added to pages more slowly, as authors find the time and interest. 6.",
                "RELATED AND FUTURE WORK 6.1 Improvements to PageRank Since the original PageRank paper, there has been work on improving it.",
                "Much of that work centers on speeding up and parallelizing the computation [15][25].",
                "One recognized problem with PageRank is that of topic drift: A page about dogs will have high PageRank if it is linked to by many pages that themselves have high rank, regardless of their topic.",
                "In contrast, a <br>search engine</br> user looking for good pages about dogs would likely prefer to find pages that are pointed to by many pages that are themselves about dogs.",
                "Hence, a link that is on topic should have higher weight than a link that is not.",
                "Richardson and Domingoss Query Dependent PageRank [29] and Haveliwalas Topic-Sensitive PageRank [16] are two approaches that tackle this problem.",
                "Other variations to PageRank include differently weighting links for inter- vs. intra-domain links, adding a backwards step to the random surfer to simulate the back button on most browsers [24] and modifying the jump probability (α) [3].",
                "See Langville and Meyer [23] for a good survey of these, and other modifications to PageRank. 6.2 Other related work PageRank is not the only link analysis algorithm used for ranking Web pages.",
                "The most well-known other is HITS [22], which is used by the Teoma <br>search engine</br> [30].",
                "HITS produces a list of hubs and authorities, where hubs are pages that point to many authority pages, and authorities are pages that are pointed to by many hubs.",
                "Previous work has shown HITS to perform comparably to PageRank [1].",
                "One field of interest is that of static index pruning (see e.g., Carmel et al. [8]).",
                "Static index pruning methods reduce the size of the search engines index by removing documents that are unlikely to be returned by a search query.",
                "The pruning is typically done based on the frequency of query terms.",
                "Similarly, Pandey and Olston [28] suggest crawling pages frequently if they are likely to incorrectly appear (or not appear) as a result of a search.",
                "Similar methods could be incorporated into the static rank (e.g., how many frequent queries contain words found on this page).",
                "Others have investigated the effect that PageRank has on the Web at large [9].",
                "They argue that pages with high PageRank are more likely to be found by Web users, thus more likely to be linked to, and thus more likely to maintain a higher PageRank than other pages.",
                "The same may occur for the popularity data.",
                "If we increase the ranking for popular pages, they are more likely to be clicked on, thus further increasing their popularity.",
                "Cho et al. [10] argue that a more appropriate measure of Web page quality would depend on not only the current link structure of the Web, but also on the change in that link structure.",
                "The same technique may be applicable to popularity data: the change in popularity of a page may be more informative than the absolute popularity.",
                "One interesting related work is that of Ivory and Hearst [19].",
                "Their goal was to build a model of Web sites that are considered high quality from the perspective of content, structure and navigation, visual design, functionality, interactivity, and overall experience.",
                "They used over 100 page level features, as well as features encompassing the performance and structure of the site.",
                "This let them qualitatively describe the qualities of a page that make it appear attractive (e.g., rare use of italics, at least 9 point font, …), and (in later work) to build a system that assists novel Web page authors in creating quality pages by evaluating it according to these features.",
                "The primary differences between this work and ours are the goal (discovering what constitutes a good Web page vs. ordering Web pages for the purposes of Web search), the size of the study (they used a dataset of less than 6000 pages vs. our set of 468,000), and our comparison with PageRank. y = 0.577Ln(x) + 58.283 R 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Days of Toolbar Data PairwiseAccuracy Figure 1: Relation between the amount of popularity data and the performance of the popularity feature set.",
                "Note the x-axis is a logarithmic scale. 713 Nevertheless, their work provides insights to additional useful static features that we could incorporate into fRank in the future.",
                "Recent work on incorporating novel features into dynamic ranking includes that by Joachims et al. [21], who investigate the use of implicit feedback from users, in the form of which <br>search engine</br> results are clicked on.",
                "Craswell et al. [11] present a method for determining the best transformation to apply to query independent features (such as those used in this paper) for the purposes of improving dynamic ranking.",
                "Other work, such as Boyan et al. [4] and Bartell et al. [2] apply machine learning for the purposes of improving the overall relevance of a <br>search engine</br> (i.e., the dynamic ranking).",
                "They do not apply their techniques to the problem of static ranking. 6.3 Future work There are many ways in which we would like to extend this work.",
                "First, fRank uses only a small number of features.",
                "We believe we could achieve even more significant results with more features.",
                "In particular the existence, or lack thereof, of certain words could prove very significant (for instance, under construction probably signifies a low quality page).",
                "Other features could include the number of images on a page, size of those images, number of layout elements (tables, divs, and spans), use of style sheets, conforming to W3C standards (like XHTML 1.0 Strict), background color of a page, etc.",
                "Many pages are generated dynamically, the contents of which may depend on parameters in the URL, the time of day, the user visiting the site, or other variables.",
                "For such pages, it may be useful to apply the techniques found in [26] to form a static approximation for the purposes of extracting features.",
                "The resulting grammar describing the page could itself be a source of additional features describing the complexity of the page, such as how many non-terminal nodes it has, the depth of the grammar tree, etc. fRank allows one to specify a confidence in each pairing of documents.",
                "In the future, we will experiment with probabilities that depend on the difference in human judgments between the two items in the pair.",
                "For example, a pair of documents where one was rated 4 and the other 0 should have a higher confidence than a pair of documents rated 3 and 2.",
                "The experiments in this paper are biased toward pages that have higher than average quality.",
                "Also, fRank with all of the features can only be applied to pages that have already been crawled.",
                "Thus, fRank is primarily useful for index ordering and improving relevance, not for directing the crawl.",
                "We would like to investigate a machine learning approach for crawl prioritization as well.",
                "It may be that a combination of methods is best: for example, using PageRank to select the best 5 billion of the 20 billion pages on the Web, then using fRank to order the index and affect search relevancy.",
                "Another interesting direction for exploration is to incorporate fRank and page-level features directly into the PageRank computation itself.",
                "Work on biasing the PageRank jump vector [16], and transition matrix [29], have demonstrated the feasibility and advantages of such an approach.",
                "There is reason to believe that a direct application of [29], using the fRank of a page for its relevance, could lead to an improved overall static rank.",
                "Finally, the popularity data can be used in other interesting ways.",
                "The general surfing and searching habits of Web users varies by time of day.",
                "Activity in the morning, daytime, and evening are often quite different (e.g., reading the news, solving problems, and accessing entertainment, respectively).",
                "We can gain insight into these differences by using the popularity data, divided into segments of the day.",
                "When a query is issued, we would then use the popularity data matching the time of query in order to do the ranking of Web pages.",
                "We also plan to explore popularity features that use more than just the counts of how often a page was visited.",
                "For example, how long users tended to dwell on a page, did they leave the page by clicking a link or by hitting the back button, etc.",
                "Fox et al. did a study that showed that features such as this can be valuable for the purposes of dynamic ranking [14].",
                "Finally, the popularity data could be used as the label rather than as a feature.",
                "Using fRank in this way to predict the popularity of a page may useful for the tasks of relevance, efficiency, and crawl priority.",
                "There is also significantly more popularity data than human labeled data, potentially enabling more complex machine learning methods, and significantly more features. 7.",
                "CONCLUSIONS A good static ranking is an important component for todays search engines and information retrieval systems.",
                "We have demonstrated that PageRank does not provide a very good static ranking; there are many simple features that individually out perform PageRank.",
                "By combining many static features, fRank achieves a ranking that has a significantly higher pairwise accuracy than PageRank alone.",
                "A qualitative evaluation of the top documents shows that fRank is less technology-biased than PageRank; by using popularity data, it is biased toward pages that Web users, rather than Web authors, visit.",
                "The machine learning component of fRank gives it the additional benefit of being more robust against spammers, and allows it to leverage further developments in the machine learning community in areas such as adversarial classification.",
                "We have only begun to explore the options, and believe that significant strides can be made in the area of static ranking by further experimentation with additional features, other machine learning techniques, and additional sources of data. 8.",
                "ACKNOWLEDGMENTS Thank you to Marc Najork for providing us with additional PageRank computations and to Timo Burkard for assistance with the popularity data.",
                "Many thanks to Chris Burges for providing code and significant support in using training RankNets.",
                "Also, we thank Susan Dumais and Nick Craswell for their edits and suggestions. 9.",
                "REFERENCES [1] B. Amento, L. Terveen, and W. Hill.",
                "Does authority mean quality?",
                "Predicting expert quality ratings of Web documents.",
                "In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 2000. [2] B. Bartell, G. Cottrell, and R. Belew.",
                "Automatic combination of multiple ranked retrieval systems.",
                "In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1994. [3] P. Boldi, M. Santini, and S. Vigna.",
                "PageRank as a function of the damping factor.",
                "In Proceedings of the International World Wide Web Conference, May 2005. 714 [4] J. Boyan, D. Freitag, and T. Joachims.",
                "A machine learning architecture for optimizing web search engines.",
                "In AAAI Workshop on Internet Based Information Systems, August 1996. [5] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web <br>search engine</br>.",
                "In Proceedings of the Seventh International Wide Web Conference, Brisbane, Australia, 1998.",
                "Elsevier. [6] A. Broder, R. Lempel, F. Maghoul, and J. Pederson.",
                "Efficient PageRank approximation via graph aggregation.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender.",
                "Learning to rank using gradient descent.",
                "In Proceedings of the 22nd International Conference on Machine Learning, Bonn, Germany, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 43-50, New Orleans, Louisiana, USA, September 2001. [9] J. Cho and S. Roy.",
                "Impact of search engines on page popularity.",
                "In Proceedings of the International World Wide Web Conference, May 2004. [10]J. Cho, S. Roy, R. Adams.",
                "Page Quality: In search of an unbiased web ranking.",
                "In Proceedings of the ACM SIGMOD 2005 Conference.",
                "Baltimore, Maryland.",
                "June 2005. [11]N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.",
                "Relevance weighting for query independent evidence.",
                "In Proceedings of the 28th Annual Conference on Research and Development in Information Retrieval (SIGIR), August, 2005. [12]N. Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma.",
                "Adversarial Classification.",
                "In Proceedings of the Tenth International Conference on Knowledge Discovery and Data Mining (pp. 99-108), Seattle, WA, 2004. [13]O. Dekel, C. Manning, and Y.",
                "Singer.",
                "Log-linear models for label-ranking.",
                "In Advances in Neural Information Processing Systems 16.",
                "Cambridge, MA: MIT Press, 2003. [14]S. Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais and T. White (2005).",
                "Evaluating implicit measures to improve the search experiences.",
                "In the ACM Transactions on Information Systems, 23(2), pp. 147-168.",
                "April 2005. [15]T. Haveliwala.",
                "Efficient computation of PageRank.",
                "Stanford University Technical Report, 1999. [16]T. Haveliwala.",
                "Topic-sensitive PageRank.",
                "In Proceedings of the International World Wide Web Conference, May 2002. [17]D. Hawking and N. Craswell.",
                "Very large scale retrieval and Web search.",
                "In D. Harman and E. Voorhees (eds), The TREC Book.",
                "MIT Press. [18]R. Herbrich, T. Graepel, and K. Obermayer.",
                "Support vector learning for ordinal regression.",
                "In Proceedings of the Ninth International Conference on Artificial Neural Networks, pp. 97-102. 1999. [19]M. Ivory and M. Hearst.",
                "Statistical profiles of highly-rated Web sites.",
                "In Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, 2002. [20]T. Joachims.",
                "Optimizing search engines using clickthrough data.",
                "In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD), 2002. [21]T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay.",
                "Accurately Interpreting Clickthrough Data as Implicit Feedback.",
                "In Proceedings of the Conference on Research and Development in Information Retrieval (SIGIR), 2005. [22]J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM 46:5, pp. 604-32. 1999. [23]A. Langville and C. Meyer.",
                "Deeper inside PageRank.",
                "Internet Mathematics 1(3):335-380, 2004. [24]F. Matthieu and M. Bouklit.",
                "The effect of the back button in a random walk: application for PageRank.",
                "In Alternate track papers and posters of the Thirteenth International World Wide Web Conference, 2004. [25]F. McSherry.",
                "A uniform approach to accelerated PageRank computation.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [26]Y. Minamide.",
                "Static approximation of dynamically generated Web pages.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [27]L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The PageRank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University, Stanford, CA, 1998. [28]S. Pandey and C. Olston.",
                "User-centric Web crawling.",
                "In Proceedings of the International World Wide Web Conference, May 2005. [29]M. Richardson and P. Domingos.",
                "The intelligent surfer: probabilistic combination of link and content information in PageRank.",
                "In Advances in Neural Information Processing Systems 14, pp. 1441-1448.",
                "Cambridge, MA: MIT Press, 2002. [30]C. Sherman.",
                "Teoma vs. Google, Round 2.",
                "Available from World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31]T. Upstill, N. Craswell, and D. Hawking.",
                "Predicting fame and fortune: PageRank or indegree?.",
                "In the Eighth Australasian Document Computing Symposium. 2003. [32]T. Upstill, N. Craswell, and D. Hawking.",
                "Query-independent evidence in home page finding.",
                "In ACM Transactions on Information Systems. 2003. 715"
            ],
            "original_annotated_samples": [
                "However, having a good query-independent ranking (static ranking) is also crucially important for a <br>search engine</br>.",
                "The more accurate the static rank, the better this early-stopping ability, and hence the quicker the <br>search engine</br> may respond to queries. • Crawl Priority: The Web grows and changes as quickly as search engines can crawl it.",
                "Google is often regarded as the first commercially successful <br>search engine</br>.",
                "Such data was used by the <br>search engine</br> Direct Hit, and has recently been explored for dynamic ranking purposes [20].",
                "The closest similar work is on using click-through behavior (that is, which <br>search engine</br> results the users click on) to affect dynamic ranking (see e.g., [20])."
            ],
            "translated_annotated_samples": [
                "Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un <br>motor de búsqueda</br>.",
                "Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el <br>motor de búsqueda</br> a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla.",
                "Google es frecuentemente considerado como el primer <br>motor de búsqueda</br> comercialmente exitoso.",
                "Tales datos fueron utilizados por el <br>motor de búsqueda</br> Direct Hit, y recientemente han sido explorados con fines de clasificación dinámica [20].",
                "El trabajo similar más cercano se centra en el uso del comportamiento de clics (es decir, en los resultados de búsqueda en los que los usuarios hacen clic) para afectar la clasificación dinámica (ver, por ejemplo, [20])."
            ],
            "translated_text": "Más allá de PageRank: Aprendizaje automático para la clasificación estática. Demostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlaces de la Web. Obtenemos un impulso adicional en precisión al utilizar datos sobre la frecuencia con la que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto del ancla y las características del dominio. El modelo resultante logra una precisión de clasificación par a par estática del 67.3% (en comparación con el 56.7% de PageRank o el 50% al azar). Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Términos generales Algoritmos, Medición, Rendimiento, Experimentación. 1. INTRODUCCIÓN En la última década, la Web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha limitado a páginas de buena calidad. El número de sitios incorrectos, de spam y maliciosos (por ejemplo, de phishing) también ha crecido rápidamente. El simple hecho de la gran cantidad de páginas tanto buenas como malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para descubrir información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar lo bueno de lo malo y ordenar los resultados de manera que se sugieran primero las mejores páginas. Hasta la fecha, la mayoría de los trabajos sobre la clasificación de páginas web se han centrado en mejorar el orden de los resultados devueltos al usuario (clasificación dependiente de la consulta, o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de consultas (clasificación estática) también es crucialmente importante para un <br>motor de búsqueda</br>. Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: La clasificación estática de una página proporciona un indicador general de la calidad de la página. Este es un aporte útil para el algoritmo de clasificación dinámica. • Eficiencia: Normalmente, el índice de los motores de búsqueda se ordena por rango estático. Al recorrer el índice desde las páginas de alta calidad hasta las de baja calidad, el clasificador dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como las ya encontradas. Cuanto más preciso sea el rango estático, mejor será esta capacidad de detención temprana, y por lo tanto, más rápido podrá responder el <br>motor de búsqueda</br> a las consultas. • Prioridad de rastreo: La Web crece y cambia tan rápidamente como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas volver a rastrear, con qué frecuencia y cuándo buscar nuevas páginas. Entre otros factores, se utiliza la clasificación estática de una página para determinar esta priorización. Un rango estático mejor proporciona al motor de búsqueda un índice de mayor calidad y más actualizado. Google es frecuentemente considerado como el primer <br>motor de búsqueda</br> comercialmente exitoso. Su clasificación se basaba originalmente en el algoritmo PageRank [5][27]. Debido a esto (y posiblemente debido a la promoción de Google del PageRank al público), el PageRank es ampliamente considerado como el mejor método para la clasificación estática de páginas web. Aunque se ha pensado que PageRank ha tenido un buen rendimiento históricamente, todavía hay poca evidencia académica que respalde esta afirmación. Aún peor, recientemente se ha demostrado que PageRank puede no funcionar mejor que otras medidas simples en ciertas tareas. Upstill et al. han encontrado que para la tarea de encontrar páginas de inicio, el número de páginas que enlazan a una página y el tipo de URL fueron tan, o más, efectivos que PageRank [32]. Encontraron resultados similares para la tarea de encontrar empresas de alta calidad [31]. PageRank también se ha utilizado en sistemas para las grandes colecciones de TRECs y competencias de seguimiento web, pero con mucho menos éxito del esperado [17]. Finalmente, Amento et al. [1] encontraron que características simples, como el número de páginas en un sitio, tuvieron un rendimiento tan bueno como PageRank. A pesar de esto, la creencia general persiste entre muchos, tanto académicos como en el público, de que PageRank es un factor esencial para un buen rango estático. En caso de que esto falle, se asume que seguir utilizando la estructura de enlaces es crucial, ya sea en forma del número de enlaces entrantes o la cantidad de texto ancla. En este artículo, demostramos que existen una serie de características simples basadas en URL o en páginas que superan significativamente a PageRank (para el propósito de clasificar estáticamente páginas web) a pesar de ignorar la estructura de la web. Combinamos estas y otras características estáticas utilizando aprendizaje automático para lograr un sistema de clasificación que es significativamente mejor que PageRank (en acuerdo par a par con etiquetas humanas). Un enfoque de aprendizaje automático para la clasificación estática tiene otras ventajas además de la calidad de la clasificación. Debido a que la medida consta de muchas características, es más difícil para los usuarios malintencionados manipularla (es decir, elevar el rango estático de sus páginas a un nivel no merecido a través de técnicas cuestionables, también conocidas como spam en la web). Esto es especialmente cierto si el conjunto de características no se conoce. Por el contrario, una sola medida como PageRank puede ser más fácil de manipular porque los spammers solo necesitan concentrarse en un objetivo: cómo hacer que más páginas apunten a su página. Con un algoritmo que aprende, una característica que se vuelve inutilizable debido a la manipulación de spammers simplemente se reducirá o eliminará del cálculo final de rango. Esta flexibilidad permite que un sistema de clasificación reaccione rápidamente a nuevas técnicas de spam. Un enfoque de aprendizaje automático para la clasificación estática también puede aprovechar cualquier avance en el campo del aprendizaje automático. Por ejemplo, un trabajo reciente sobre clasificación adversarial [12] sugiere que puede ser posible modelar explícitamente las acciones de los spammers de páginas web (el adversario), ajustando el modelo de clasificación de antemano antes de que los spammers intenten evadirlo. Otro ejemplo es la eliminación de valores atípicos al construir el modelo, lo cual ayuda a reducir el efecto que los sitios únicos pueden tener en la calidad general de la clasificación estática. Al trasladar la clasificación estática a un marco de aprendizaje automático, no solo ganamos en precisión, sino también en la capacidad de reaccionar a las acciones de los spammers, de añadir rápidamente nuevas características al algoritmo de clasificación y de aprovechar los avances en el campo en rápido crecimiento del aprendizaje automático. Finalmente, creemos que habrá ventajas significativas al utilizar esta técnica para otros ámbitos, como la búsqueda en un disco duro local o en la intranet de una empresa. Estos son dominios donde la estructura de enlaces es particularmente débil (o inexistente), pero hay otras características específicas del dominio que podrían ser igual de poderosas. Por ejemplo, el autor de una página de intranet y su posición en la organización (por ejemplo, CEO, gerente o desarrollador) podrían proporcionar pistas significativas sobre la importancia de esa página. Un enfoque de aprendizaje automático permite el desarrollo rápido de un buen algoritmo estático en nuevos dominios. La contribución de este artículo es un estudio sistemático de las características estáticas, incluido PageRank, con el propósito de clasificar páginas web de forma estática. Estudios previos sobre PageRank típicamente utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Además, el rendimiento de PageRank y otras características estáticas suele evaluarse en el contexto de un sistema completo para la clasificación dinámica, o para otras tareas como la respuesta a preguntas. Por el contrario, exploramos el uso de PageRank y otras características para la tarea directa de clasificar estáticamente las páginas web. Primero describimos brevemente el algoritmo PageRank. En la Sección 3 presentamos RankNet, la técnica de aprendizaje automático utilizada para combinar las características estáticas en un ranking final. La sección 4 describe las características estáticas. El corazón del documento está en la Sección 5, la cual presenta nuestros experimentos y resultados. Concluimos con una discusión sobre el trabajo relacionado y futuro. 2. PAGERANK La idea básica detrás de PageRank es simple: un enlace de una página web a otra puede ser visto como un respaldo de esa página. En general, los enlaces son creados por personas. Por lo tanto, son indicativos de la calidad de las páginas a las que apuntan: al crear una página, un autor presumiblemente elige enlazar a páginas consideradas de buena calidad. Podemos aprovechar esta información de enlace para ordenar las páginas web según su calidad percibida. Imagina a un internauta que salta de página web en página web, eligiendo con probabilidad uniforme qué enlace seguir en cada paso. Para reducir el efecto de los callejones sin salida o ciclos interminables, el surfista saltará ocasionalmente a una página aleatoria con una pequeña probabilidad α, o cuando se encuentre en una página sin enlaces de salida. Si se promedia sobre un número suficiente de pasos, la probabilidad de que el surfista esté en la página j en algún momento en el tiempo está dada por la fórmula: ∑∈ + − = ji i iP N jP B F )()1( )( α α (1) Donde Fi es el conjunto de páginas a las que enlaza la página i, y Bj es el conjunto de páginas que enlazan a la página j. El puntaje de PageRank para el nodo j se define como esta probabilidad: PR(j)=P(j). Dado que la ecuación (1) es recursiva, debe evaluarse de forma iterativa hasta que P(j) converja (normalmente, la distribución inicial para P(j) es uniforme). La intuición es que, dado que un navegante aleatorio llegaría a la página con más frecuencia, es probable que sea una página mejor. Una vista alternativa para la ecuación (1) es que a cada página se le asigna una calidad, P(j). Una página otorga una parte igual de su calidad a cada página a la que apunta. PageRank es computacionalmente costoso. Nuestra colección de 5 mil millones de páginas contiene aproximadamente 370 mil millones de enlaces. Calcular el PageRank requiere iterar sobre miles de millones de enlaces varias veces (hasta converger). Requiere grandes cantidades de memoria (o esquemas de almacenamiento en caché muy inteligentes que ralentizan aún más el cálculo), y si se distribuye en múltiples máquinas, requiere una comunicación significativa entre ellas. Aunque se ha realizado mucho trabajo en la optimización del cálculo del PageRank (ver, por ejemplo, [25] y [6]), sigue siendo una propiedad relativamente lenta y costosa computacionalmente de calcular. 3. RANKNET Se ha realizado mucho trabajo en aprendizaje automático en los problemas de clasificación y regresión. Sea X={xi} una colección de vectores de características (típicamente, una característica es cualquier número real), y Y={yi} una colección de clases asociadas, donde yi es la clase del objeto descrito por el vector de características xi. El problema de clasificación consiste en aprender una función f que mapea yi=f(xi), para todo i. Cuando yi también es un valor real, esto se llama regresión. La clasificación estática se puede ver como un problema de regresión. Si dejamos que xi represente las características de la página i, y yi sea un valor (por ejemplo, el rango) para cada página, podríamos aprender una función de regresión que mapeara las características de cada página a su rango. Sin embargo, esto sobrecarga el problema que deseamos resolver. Todo lo que realmente nos importa es el orden de las páginas, no el valor real asignado a ellas. El trabajo reciente sobre este problema de clasificación [7][13][18] intenta directamente optimizar el orden de los objetos, en lugar del valor asignado a ellos. Para esto, sea Z={<i,j>} una colección de pares de elementos, donde el elemento i debe ser asignado un valor más alto que el elemento j. El objetivo del problema de clasificación, entonces, es aprender una función f tal que, )()(,, ji ffji xxZ >∈∀ 708. Nótese que, al igual que al aprender una función de regresión, el resultado de este proceso es una función (f) que mapea vectores de características a valores reales. Esta función todavía se puede aplicar en cualquier lugar donde se pueda aplicar una función aprendida por regresión. La única diferencia es la técnica utilizada para aprender la función. Al optimizar directamente el orden de los objetos, estos métodos pueden aprender una función que clasifica mejor que las técnicas de regresión. Utilizamos RankNet [7], una de las técnicas mencionadas para aprender funciones de clasificación, para aprender nuestra función de clasificación estática. RankNet es una modificación sencilla del algoritmo de retropropagación de la red neuronal estándar. Al igual que con back-prop, RankNet intenta minimizar el valor de una función de costo ajustando cada peso en la red de acuerdo con el gradiente de la función de costo con respecto a ese peso. La diferencia es que, mientras que una función de costo típica de una red neuronal se basa en la diferencia entre la salida de la red y la salida deseada, la función de costo de RankNet se basa en la diferencia entre un par de salidas de la red. Es decir, para cada par de vectores de características <i,j> en el conjunto de entrenamiento, RankNet calcula las salidas de la red oi y oj. Dado que se supone que el vector i está clasificado más alto que el vector j, cuanto mayor sea oj-oi, mayor será el costo. RankNet también permite que los pares en Z sean ponderados con una confianza (expresada como la probabilidad de que el par cumpla con el ordenamiento inducido por la función de clasificación). En este documento, utilizamos una probabilidad de uno para todos los pares. En la siguiente sección, discutiremos las características utilizadas en nuestros vectores de características, xi. 4. Para aplicar RankNet (u otras técnicas de aprendizaje automático) al problema de clasificación, necesitábamos extraer un conjunto de características de cada página. Dividimos nuestro conjunto de características en cuatro categorías mutuamente excluyentes: a nivel de página (Página), a nivel de dominio (Dominio), texto del enlace y enlaces entrantes (Anclaje) y popularidad (Popularidad). También opcionalmente utilizamos el PageRank de una página como una característica. A continuación, describimos cada una de estas categorías de características con más detalle. Calculamos PageRank en un grafo web de 5 mil millones de páginas rastreadas (y 20 mil millones de URLs conocidas enlazadas por estas páginas). Esto representa una parte significativa de la Web, y es aproximadamente la misma cantidad de páginas que utilizan Google, Yahoo y MSN para sus motores de búsqueda. Dado que PageRank es un algoritmo basado en grafos, es importante que se ejecute en la mayor cantidad posible de subconjuntos de la Web. La mayoría de los estudios previos sobre PageRank utilizaron subconjuntos de la Web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Calculamos PageRank utilizando el valor estándar de 0.85 para α. Otra característica que utilizamos es la popularidad real de una página web, medida como el número de veces que ha sido visitada por usuarios durante algún período de tiempo. Tenemos acceso a esos datos de usuarios que han instalado la barra de herramientas de MSN y han optado por proporcionarlos a MSN. Los datos se agregan en un recuento, para cada página web, del número de usuarios que vieron esa página. Aunque los datos de popularidad generalmente no están disponibles, hay otras dos fuentes para obtenerlos. El primero es de los registros de proxy. Por ejemplo, una universidad que requiere que sus estudiantes utilicen un proxy tiene un registro de todas las páginas que han visitado mientras están en el campus. Desafortunadamente, los datos de proxy son bastante sesgados y relativamente pequeños. Otra fuente, interna de los motores de búsqueda, son los registros de los resultados en los que hicieron clic sus usuarios. Tales datos fueron utilizados por el <br>motor de búsqueda</br> Direct Hit, y recientemente han sido explorados con fines de clasificación dinámica [20]. Una ventaja de los datos de la barra de herramientas sobre esto es que contiene información sobre las visitas a URL que no son solo el resultado de una búsqueda. La popularidad en bruto se procesa en una serie de características como el número de veces que se visualizó una página y el número de veces que se visualizó cualquier página en el dominio. Se proporcionan más detalles en la sección 5.5. Texto de anclaje e inlinks. Estas características se basan en la información asociada con los enlaces a la página en cuestión. Incluye características como la cantidad total de texto en los enlaces que apuntan a la página (texto de anclaje), el número de palabras únicas en ese texto, etc. Esta categoría consiste en características que pueden ser determinadas solo al observar la página (y su URL). Solo utilizamos ocho características simples como el número de palabras en el cuerpo, la frecuencia del término más común, etc. Este categoría contiene características que se calculan como promedios en todas las páginas del dominio. Por ejemplo, el número promedio de enlaces salientes en cualquier página y el PageRank promedio. Muchas de estas características han sido utilizadas por otros para clasificar páginas web, especialmente las características de anclaje y de la página. Como se mencionó, la evaluación suele ser para clasificación dinámica, y deseamos evaluar su uso para clasificación estática. Además, hasta donde sabemos, este es el primer estudio sobre el uso de la popularidad real de visitas a páginas para la clasificación estática. El trabajo similar más cercano se centra en el uso del comportamiento de clics (es decir, en los resultados de búsqueda en los que los usuarios hacen clic) para afectar la clasificación dinámica (ver, por ejemplo, [20]). ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}