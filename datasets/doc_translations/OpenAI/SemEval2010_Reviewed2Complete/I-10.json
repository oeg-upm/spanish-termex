{
    "id": "I-10",
    "original_text": "SMILE: Sound Multi-agent Incremental LEarning ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av. du pr´esident Kennedy, 75116 Paris Henry Soldano LIPN, UMR 7030 CNRS, University Paris-Nord, 99 Av. J-B Clement, 93430, Villetaneuse ABSTRACT This article deals with the problem of collaborative learning in a multi-agent system. Here each agent can update incrementally its beliefs B (the concept representation) so that it is in a way kept consistent with the whole set of information K (the examples) that he has received from the environment or other agents. We extend this notion of consistency (or soundness) to the whole MAS and discuss how to obtain that, at any moment, a same consistent concept representation is present in each agent. The corresponding protocol is applied to supervised concept learning. The resulting method SMILE (standing for Sound Multiagent Incremental LEarning) is described and experimented here. Surprisingly some difficult boolean formulas are better learned, given the same learning set, by a Multi agent system than by a single agent. Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Concept learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent system General Terms Experimentation, Algorithms, Measurement, Performance 1. INTRODUCTION This article deals with the problem of collaborative concept learning in a multi-agent system. [6] introduces a characterisation of learning in multi-agent system according to the level of awareness of the agents. At level 1, agents learn ∗The primary author of this paper is a student. in the system without taking into account the presence of other agents, except through the modification brought upon the environment by their action. Level 2 implies direct interaction between the agents as they can exchange messages to improve their learning. Level 3 would require agents to take into account the competencies of other agents, and be able to learn from observation of the other agents behaviour (while considering them as independant entities and not indetermined part of the environment as in level 1). We focus in this paper on level 2, studying direct interaction between agents involved in a learning process. Each agent is assumed to be able to learn incrementally from the data he receives, meaning that each agent can update his belief set B to keep it consistent with the whole set of information K that he has received from the environment or from other agents. In such a case, we will say that he is a-consistent. Here, the belief set B represents hypothetical knowledge that can therefore be revised, whereas the set of information K represents certain knowledge, consisting of non revisable observations and facts. Moreover, we suppose that at least a part Bc of the beliefs of each agent is common to all agents and must stay that way. Therefore, an update of this common set Bc by agent r must provoke an update of Bc for the whole community of agents. It leads us to define what is the mas-consistency of an agent with respect to the community. The update process of the community beliefs when one of its members gets new information can then be defined as the consistency maintenance process ensuring that every agent in the community will stay masconsistent. This mas-consistency maintenance process of an agent getting new information gives him the role of a learner and implies communication with other agents acting as critics. However, agents are not specialised and can in turn be learners or critics, none of them being kept to a specific role. Pieces of information are distributed among the agents, but can be redundant. There is no central memory. The work described here has its origin in a former work concerning learning in an intentional multi-agent system using a BDI formalism [6]. In that work, agents had plans, each of them being associated with a context defining in which conditions it can be triggered. Plans (each of them having its own context) were common to the whole set of agents in the community. Agents had to adapt their plan contexts depending on the failure or success of executed plans, using a learning mechanism and asking other agents for examples (plans successes or failures). However this work lacked a collective learning protocol enabling a real autonomy of the multi-agent system. The study of such a protocol is the object of the present paper. In section 2 we formally define the mas-consistency of an update mechanism for the whole MAS and we propose a generic update mechanism proved to be mas consistent. In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent update mechanism to collaborative concept learning. Section 4 describes various experiments on SMILE and discusses various issues including how the accuracy and the simplicity of the current hypothesis vary when comparing single agent learning and mas learning. In section 5 we briefly present some related works and then conclude in section 6 by discussing further investigations on mas consistent learning. 2. FORMAL MODEL 2.1 Definitions and framework In this section, we present a general formulation of collective incremental learning in a cognitive multi agent system. We represent a MAS as a set of agents r1, ..., rn. Each agent ri has a belief set Bi consisting of all the revisable knowledge he has. Part of these knowledges must be shared with other agents. The part of Bi that is common to all agents is denoted as BC . This common part provokes a dependency between the agents. If an agent ri updates his belief set Bi to Bi, changing in the process BC into BC , all other agents rk must then update their belief set Bk to Bk so that BC ⊆ Bk. Moreover, each agent ri has stored some certain information Ki. We suppose that some consistency property Cons(Bi, Ki) can be verified by the agent itself between its beliefs Bi and its information Ki. As said before, Bi represents knowledge that might be revised whereas Ki represents observed facts, taken as being true, and which can possibly contradict Bi. Definition 1. a-consistency of an agent An agent ri is a-consistent iff Cons(Bi, Ki) is true. Example 1. Agent r1 has a set of plans which are in the common part BC of B1. Each plan P has a triggering context d(P) (which acts as a pre-condition) and a body. Some piece of information k could be plan P, triggered in situation s, has failed in spite of s being an instance of d(P). If this piece of information is added to K1, then agent r1 is not a-consistent anymore: Cons(B1, K1 ∪ k) is false. We also want to define some notion of consistency for the whole MAS depending on the belief and information sets of its constituting elements. We will first define the consistency of an agent ri with respect to its belief set Bi and its own information set Ki together with all information sets K1...Kn from the other agents of the MAS. We will simply do that by considering what would be the a-consistency of the agent if he has the information of all the other agents. We call this notion the mas-consistency: Definition 2. mas-consistency of an agent An agent ri is mas-consistent iff Cons(Bi, Ki ∪ K) is true, where K = ∪j∈{1,..,n}−{i}Kj 1 is the set of all information from other agents of the MAS. 1 We will note this ∪ Kj when the context is similar. Example 2. Using the previous example, suppose that the piece of information k is included in the information K2 of agent r2. As long as the piece of information is not transmitted to r1, and so added to K1 , r1 remains a-consistent. However, r1 is not mas-consistent as k is in the set K of all information of the MAS. The global consistency of the MAS is then simply the mas-consistency of all its agents. Definition 3. Consistency of a MAS A MAS r1,...,rn is consistent iff all its agents ri are masconsistent. We now define the required properties for a revision mechanism M updating an agent ri when it gets a piece of information k. In the following, we will suppose that: • Update is always possible, that is, an agent can always modify its belief set Bi in order to regain its a-consistency. We will say that each agent is locally efficient. • Considering two sets of information Cons(Bi, K1) and Cons(Bi, K2), we also have Cons(Bi, K1 ∪ K2). That is, a-consistency of the agents is additive. • If a piece of information k concerning the common set BC is consistent with an agent, it is consistent with all agents: for all pair of agents (ri,rj) such that Cons(Bi, Ki) and Cons(Bj, Kj) are true, we have, for all piece of information k: Cons(Bi, Ki ∪ k) iff Cons(Bj, Kj ∪ k). In such a case, we will say that the MAS is coherent. This last condition simply means that the common belief set BC is independent of the possible differences between the belief sets Bi of each agent ri. In the simplest case, B1 = ... = Bn = BC . M will also be viewed as an incremental learning mechanism and represented as an application changing Bi in Bi. In the following, we shall note ri(Bi, Ki) for ri when it is useful. Definition 4. a-consistency of a revision An update mechanism M is a-consistent iff for any agent ri and any piece of information k reaching ri, the a-consistency of this agent is preserved. In other words, iff: ri(Bi, Ki) a-consistent ⇒ ri(Bi, Ki) a-consistent, where Bi = M(Bi) and Ki = Ki ∪ k is the set of all information from other agents of the MAS. In the same way, we define the mas-consistency of a revision mechanism as the a-consistency of this mechanism should the agents dispose of all information in the MAS. In the following, we shall note, if needed, ri(Bi, Ki, K) for the agent ri in MAS r1 . . . rn. Definition 5. mas-consistency of a revision An update mechanism Ms is mas-consistent iff for all agent ri and all pieces of information k reaching ri, the masconsistency of this agent is preserved. In other words, if: ri(Bi, Ki, K) mas-consistent ⇒ ri(Bi, Ki, K) mas-consistent, where Bi = Ms(Bi), Ki = Ki ∪ k, and K = ∪Kj is the set of all information from the MAS. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 165 At last, when a mas-consistent mechanism is applied by an agent getting a new piece of information, a desirable sideeffect of the mechanism should be that all others agents remains mas-consistent after any modification of the common part BC , that is, the MAS itself should become consistent again. This property is defined as follows: Definition 6. Strong mas-consistency of a revision An update mechanism Ms is strongly mas-consistent iff - Ms is mas-consistent, and - the application of Ms by an agent preserves the consistency of the MAS. 2.2 A strongly mas-consistent update mechanism The general idea is that, since information is distributed among all the agents of the MAS, there must be some interaction between the learner agent and the other agents in a strongly mas-consistent update mechanism Ms. In order to ensure its mas-consistency, Ms will be constituted of reiterated applications by the learner agent ri of an internal a-consistent mechanism M, followed by some interactions between ri and the other agents, until ri regain its masconsistency. We describe below such a mechanism, first with a description of an interaction, then an iteration, and finally a statement of the termination condition of the mechanism. The mechanism is triggered by an agent ri upon receipt of a piece of information k disrupting the mas-consistency. We shall note M(Bi) the belief set of the learner agent ri after an update, BC the common part modified by ri, and Bj the belief set of another agent rj induced by the modification of its common part BC in BC . An interaction I(ri, rj) between the learner agent ri and another agent rj, acting as critic is constituted of the following steps: • agent ri sends the update BC of the common part of its beliefs. Having applied its update mechanism, ri is a-consistent. • agent rj checks the modification Bj of its beliefs induced by the update BC . If this modification preserve its a-consistency, rj adopts this modification. • agent rj sends either an acceptation of BC or a denial along with one (or more) piece(s) of information k such that Cons(Bj, k ) is false. An iteration of Ms will then be composed of: • the reception by the learner agent ri of a piece of information and the update M(Bi) restoring its aconsistency • a set of interactions I(ri, rj) (in which several critic agents can possibly participate). If at least one piece of information k is transmitted to ri, the addition of k will necessarily make ri a-inconsistent and a new iteration will then occur. This mechanism Ms ends when no agent can provide such a piece of information k . When it is the case, the masconsistency of the learner agent ri is restored. Proposition 1. Let r1,...,rn be a consistent MAS in which agent ri receives a piece of information k breaking its aconsistency, and M an a-consistent internal update mechanism. The update mechanism Ms described above is strongly mas-consistent. Proof. The proof directly derives from the mechanism description. This mechanism ensures that each time an agent receives an event, its mas-consistency will be restored. As the other agents all adopt the final update BC , they are all mas-consistent, and the MAS is consistent. Therefore Ms is a strongly consistent update mechanism. In the mechanism Ms described above, the learner agent is the only one that receives and memorizes information during the mechanism execution. It ensures that Ms terminates. The pieces of information transmitted by other agents and memorized by the learner agent are redundant as they are already present in the MAS, more precisely in the memory of the critic agents that transmitted them. Note that the mechanism Ms proposed here does not explicitly indicate the order nor the scope of the interactions. We will consider in the following that the modification proposal BC is sent sequentially to the different agents (synchronous mechanism). Moreover, the response of a critic agent will only contain one piece of information inconsistent with the proposed modification. We will say that the response of the agent is minimal. This mechanism Ms, being synchronous with minimal response, minimizes the amount of information transmitted by the agents. We will now illustrate it in the case of multi-agent concept learning. 3. SOUNDMULTI-AGENTINCREMENTAL LEARNING 3.1 The learning task We experiment the mechanism proposed above in the case of incremental MAS concept learning. We consider here a hypothesis language in which a hypothesis is a disjunction of terms. Each term is a conjunction of atoms from a set A. An example is represented by a tag + or − and a description 2 composed of a subset of atoms e ⊆ A. A term covers an example if its constituting atoms are included in the example. A hypothesis covers an example if one of its term covers it. This representation will be used below for learning boolean formulae. Negative literals are here represented by additional atoms, like not − a. The boolean formulae f =(a ∧ b) ∨ (b ∧ ¬c) will then be written (a ∧ b) ∨ (b ∧ not − c). A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 Incremental learning process The learning process is an update mechanism that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis. Before this update, the given hypothesis is complete, meaning that it covers all positive examples of E+ , and 2 When no confusion is possible, the word example will be used to refer to the pair (tag, description) as well as the description alone. 166 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) coherent, meaning that it does not cover any negative example of E− . After the update, the new hypothesis must be complete and coherent with the new memory state E ∪ {e}. We describe below our single agent update mechanism, inspired from a previous work on incremental learning[7]. In the following, a hypothesis H for the target formula f is a list of terms h, each of them being a conjunction of atoms. H is coherent if all terms h are coherent, and H is complete if each element of E+ is covered by at least one term h of H. Each term is by construction the lgg (least general generalization) of a subset of positives instances {e1, ..., en}[5], that is the most specific term covering {e1, ..., en}. The lgg operator is defined by considering examples as terms, so we denote as lgg(e) the most specific term that covers e, and as lgg(h, e) the most specific term which is more general than h and that covers e. Restricting the term to lgg is the basis of a lot of Bottom-Up learning algorithms (for instance [5]). In the typology proposed by [9], our update mechanism is an incremental learner with full instance memory: learning is made by successive updates and all examples are stored. The update mechanism depends of the ongoing hypothesis H, the ongoing examples E+ and E− , and the new example e. There are three possible cases: • e is positive and H covers e, or e is negative and H does not cover e. No update is needed, H is already complete and coherent with E ∪ {e}. • e is positive and H does not cover e: e is denoted as a positive counterexample of H. Then we seek to generalize in turn the terms h of H. As soon as a correct generalization h = lgg(h, e) is found, h replaces h in H. If there is a term that is less general that h , it is discarded. If no generalization is correct (meaning here coherent), H ∪ lgg(e) replaces H. • e is negative and H covers e: e is denoted as a negative counterexample of H. Each term h covering e is then discarded from H and replaced by a set of terms {h1, ...., hn} that is, as a whole, coherent with E− ∪ {e} and that covers the examples of E+ uncovered by H − {h}. Terms of the final hypothesis H that are less general than others are discarded from H. We will now describe the case where e = e− is a covered negative example. The following functions are used here: • coveredOnlyBy(h, E+) gives the subset of E+ covered by h and no other term of H. • bestCover(h1, h2) gives h1 if h1 covers more examples from uncoveredPos than h2, otherwise it gives h2. • covered(h) gives the elements of uncoveredPos covered by h. // Specialization of each h covering e− for each h of H covering e− do H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= atoms that are neither in e− nor in h while (uncoveredPos = ∅) do // seeking the best specialization of h hc=h best=⊥ // ⊥ covers no example for each a of Ar do hc= h ∧ a best = bestCover(hc, best) endfor Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) endwhile endfor Terms of H that are less general than others are discarded. Note that this mechanism tends to both make a minimal update of the current hypothesis and minimize the number of terms in the hypothesis, in particular by discarding terms less general than other ones after updating a hypothesis. 3.3 Collective learning If H is the current hypothesis, Ei the current example memory of agent ri and E the set of all the examples received by the system, the notation of section 2 becomes Bi = BC = H, Ki = Ei and K = E. Cons(H, Ei) states that H is complete and coherent with Ei. In such a case, ri is a-consistent. The piece of information k received by agent ri is here simply an example e along with its tag. If e is such that the current hypothesis H is not complete or coherent with Ei ∪ {e}, e contradicts H: ri becomes a-inconsistent, and therefore the MAS is not consistent anymore. The update of a hypothesis when a new example arrives is an a- consistent mechanism. Following proposition 1 this mechanism can be used to produce a strong mas-consistent mechanism: upon reception of a new example in the MAS by an agent r, an update is possibly needed and, after a set of interactions between r and the other agents, results in a new hypothesis shared by all the agents and that restores the consistency of the MAS, that is which is complete and coherent with the set ES of all the examples present in the MAS. It is clear that by minimizing the number of hypothesis modifications, this synchronous and minimal mechanism minimize the number of examples received by the learner from other agents, and therefore, the total number of examples stored in the system. 4. EXPERIMENTS In the following, we will learn a boolean formula that is a difficult test for the learning method: the 11-multiplexer (see [4]). It concerns 3 address boolean attributes a0, a1, a2 and 8 data boolean attributes d0, ..., d7. Formulae f11 is satisfied if the number coded by the 3 address attributes is the number of a data attribute whose value is 1. Its formula is the following: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0). There are 2048 = 211 possible examples, half of whom are positive (meaning they satisfy f11) while the other half is negative. An experiment is typically composed of 50 trials. Each run corresponds to a sequence of 600 examples that are incrementally learned by a Multi Agent System with n agents The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 167 (n-MAS). A number of variables such as accuracy, (i.e. the frequency of correct classification of a set of unseen examples), hypothesis size (i.e. the number of terms in the current formula) or number of stored examples, is recorded each time 25 examples are received by the system during those runs. In the protocol that is used here, a new example is sent to a random agent when the MAS is consistent. The next example will be sent in turn to an other agent when the MAS consistency will have been restored. In such a way we simulate a kind of slow learning: the frequency of example arrivals is slow compared to the time taken by an update. 4.1 Efficiency of MAS concept learning 4.1.1 Execution time We briefly discuss here execution time of learning in the MAS. Note that the whole set of action and interaction in the MAS is simulated on a single processor. Figure 1 shows that time linearly depends on the number of agents. At the end of the most active part of learning (200 examples), a 16MAS has taken 4 times more learning time than a 4-MAS. This execution time represents the whole set of learning and Figure 1: Execution time of a n-MAS (from n = 2 at the bottom to n = 20 on the top). communication activity and hints at the cost of maintaining a consistent learning hypothesis in a MAS composed of autonomous agents. 4.1.2 Redundancy in the MAS memory We study now the distribution of the examples in the MAS memory. Redundancy is written RS = nS/ne, where nS is the total number of examples stored in the MAS, that is the sum of the sizes of agents examples memories Ei, and ne is the total number of examples received from the environment in the MAS. In figure 2, we compare redundancies in 2 to 20 agents MAS. There is a peak, slowly moving from 80 to 100 examples, that represents the number of examples for which the learning is most active. For 20 agents, maximal redundancy is no more than 6, which is far less than the maximal theoretical value of 20. Note that when learning becomes less active, redundancy tends towards its minimal value 1: when there is no more updates, examples are only Figure 2: Redundancy of examples stored in a nMAS (from n = 2 at the bottom to n = 20 on the top) . stored by the agent that receives them. 4.1.3 A n-MAS selects a simpler solution than a single agent The proposed mechanism tends to minimize the number of terms in the selected hypothesis. During learning, the size of the current hypothesis grows up beyond the optimum, and then decreases when the MAS converges. In the Multiplexer 11 testbed, the optimal number of terms is 8, but there also exist equivalent formulas with more terms. It is interesting to note that in this case the 10-MAS converges towards an exact solution closer to the optimal number of terms (here 8) (see Figure 3). After 1450 examples have been presented both 1-MAS and 10-MAS have exactly learned the concept (the respective accuracies are 0.9999 and 1) but the single agent expresses in average the result as a 11.0 terms DNF whereas the 10-MAS expresses it as a 8.8 terms DNF. However for some other boolean functions we found that during learning 1-MAS always produces larger hypotheses than 10-MAS but that both MAS converge to hypotheses with similar size results. 4.1.4 A n-MAS is more accurate than a single agent Figure 4 shows the improvement brought by a MAS with n agents compared to a single agent. This improvement was not especially expected, because whether we have one or n agents, when N examples are given to the MAS it has access to the same amount of information, maintains only on ongoing hypothesis and uses the same basic revision algorithm whenever an agent has to modify the current hypothesis. Note that if the accuracy of 1, 2, 4 and 10-MAS are significantly different, getting better as the number of agents increases, there is no clear difference beyond this point: the accuracy curve of the 100 agents MAS is very close to the one of the 10 agents MAS. 4.1.4.1 Boolean formulas. To evaluate this accuracy improvement, we have experimented our protocol on other problems of boolean function learning, As in the Multiplexer-11 case, these functions 168 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 3: Size of the hypothesis built by 1 and 10MAS: the M11 case. Figure 4: Accuracy of a n-MAS: the M11 case (from bottom to top, n = 1, 2, 4, 10, 100). are learnt in the form of more or less syntactically complex DNF3 (that is with more or less conjunctive terms in the DNF), but are also more or less difficult to learn as it can be difficult to get its way in the hypothesis space to reach them. Furthermore, the presence in the description of irrelevant attributes (that is attributes that does not belong to the target DNF) makes the problem more difficult. The following problems have been selected to experiment our protocol: (i) the multiplexer-11 with 9 irrelevant attributes: M11 9, (ii) the 20-multiplexer M20 (with 4 address bits and 16 data bits), (iii) a difficult parity problem (see [4]) the Xorp m: there must be an odd number of bits with value 1 in the p first attributes for the instance to be positive, the p others bits being irrelevant, and (iv) a simple DNF formula (a ∧ b ∧ c) ∨ (c ∧ d ∧ e)(e ∧ f ∧ g) ∧ (g ∧ h ∧ i) with 19 irrelevant attributes. The following table sums up some information about these problems, giving the total number of attributes including irrelevant ones, the number of irrelevant 3 Disjunctive Normal Forms attributes, the minimal number of terms of the corresponding DNF, and the number of learning examples used. Pb att. irre. att. terms ex. M11 11 0 8 200 M11 9 20 9 8 200 M20 20 0 16 450 Xor3 25 28 25 4 200 Xor5 5 10 5 16 180 Xor5 15 20 15 16 600 Simple4-9 19 28 19 4 200 Below are given the accuracy results of our learning mechanism with a single agent and a 10 agents MAS, along with the results of two standard algorithms implemented with the learning environment WEKA[16]: JRip (an implementation of RIPPER[2]) and Id3[12]. For the experiments with JRip and Id3, we measured the mean accuracy on 50 trials, each time randomly separating examples in a learning set and a test set. JRip and Id3 parameters are default parameters, except that JRip is used without pruning. The following table shows the results: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 It is clear that difficult problems are better solved with more agents (see for instance xor5 15). We think that these benefits, which can be important with an increasing number of agents, are due to the fact that each agent really memorizes only part of the total number of examples, and this part is partly selected by other agents as counter examples, which cause a greater number of current hypothesis updates and therefore, a better exploration of the hypotheses space. 4.1.4.2 ML database problems. We did also experiments with some non boolean problems. We considered only two classes (positive/negative) problems, taken from the UCIs learning problems database[3]. In all these problems, examples are described as a vector of couples (attribute, value). The value domains can be either boolean, numeric (wholly ordered set), or nominal (non-ordered set). An adequate set of atoms A must be constituted for each problem. For instance, if a is a numeric attribute, we define at most k threshold si, giving k+1 intervals of uniform density4 . Therefore, each distinct threshold si gives two atoms a ≤ si and a > si. In our experiments, we took a maximal number of threshold k = 8. For instance, in the iono problem case, there were 34 numeric attributes, and an instance is described with 506 atoms. Below are given the accuracy results of our system along with previous results. The column Nb ex. refer to the 4 The probability for the value of a to be in any interval is constant The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 169 number of examples used for learning5 . Column (1) represents minimal and maximal accuracy values for the thirty three classifiers tested in [8]. Column (2) represents the results of [13], where various learning methods are compared to ensemble learning methods using weighted classifiers sets. Column S-1 and S-10 gives the accuracy of SMILE with respectively 1 and 10 agents. Pb Nb ex. (1) (2) S-1 S-10 ttt 862/574 // 76.2-99.7 99.7 99.9 kr-vs-kp 2876/958 // 91.4-99.4 96.8 97.3 iono 315 // 88.0-91.8 87.2 88.1 bupa 310 57-72 58-69.3 62.5 63.3 breastw 614 91-97 94.3-97.3 94.7 94.7 vote 391 94-96 95.3-96 91.9 92.6 pima 691 // 71.5- 73.4 65.0 65.0 heart 243 66-86 77.1-84.1 69.5 70.7 This table shows that the incremental algorithm corresponding to the single agent case, gives honorable results relatively to non-incremental classical methods using larger and more complex hypotheses. In some cases, there is an accuracy improvement with a 10 agents MAS. However, with such benchmarks data, which are often noisy, the difficulty does not really come from the way in which the search space is explored, and therefore the improvement observed is not always significant. The same kind of phenomenon have been observed with methods dedicated to hard boolean problems [4]. 4.2 MAS synchronization Here we consider that n single agents learn without interactions and at a given time start interacting thus forming a MAS. The purpose is to observe how the agents take advantage of collaboration when they start from different states of beliefs and memories. We compare in this section a 1-MAS, a 10-MAS (ref) and a 10-MAS (100sync) whose agents did not communicate during the arrival of the first 100 examples (10 by agents). The three accuracy curves are shown in figure 5. By comparing the single agent curve and the synchronized 10-MAS, we can observe that after the beginning of the synchronization, that is at 125 examples, accuracies are identical. This was expected since as soon as an example e received by the MAS contradicts the current hypothesis of the agent ra receiving it, this agent makes an update and its new hypothesis is proposed to the others agents for criticism. Therefore, this first contradictory example brings the MAS to reach consistency relatively to the whole set of examples present in agents memories. A higher accuracy, corresponding to a 10-MAS is obtained later, from the 175th example. In other words, the benefit of a better exploration of the research space is obtained slightly later in the learning process. Note that this synchronization happens naturally in all situations where agents have, for some reason, a divergence between their hypothesis and the system memory. This includes the fusion of two MAS into a single one or the arrival of new agents in an existing MAS. 4.3 Experiments on asynchronous learning: the effect of a large data stream 5 For ttt and kr-vs-kp, our protocol did not use more than respectively 574 and 958 learning examples, so we put another number in the column. Figure 5: Accuracies of a 1-MAS, a 10-MAS, and a 10-MAS synchronized after 100 examples. In this experiment we relax our slow learning mode: the examples are sent at a given rate to the MAS. The resulting example stream is measured in ms−1 , and represents the number of examples sent to the MAS each ms. Whenever the stream is too large, the MAS cannot reach MAS consistency on reception of an example from the environment before a new example arrives. This means that the update process, started by agent r0 as he received an example, may be unfinished when a new example is received by r0 or another agent r1. As a result, a critic agent may have at instant t to send counterexamples of hypotheses sent by various agents. However as far as the agents, in our setting, memorizes all the examples they receive whenever the stream ends, the MAS necessarily reaches MAS consistency with respect to all the examples received so far. In our experiments, though its learning curve is slowed down during the intense learning phase (corresponding to low accuracy of the current hypotheses), the MAS still reaches a satisfying hypothesis later on as there are less and less counterexamples in the example stream. In Figure 6 we compare the accuracies of two 11-MAS respectively submitted to example streams of different rates when learning the M11 formula. The learning curve of the MAS receiving an example at a 1/33 ms−1 rate is almost not altered (see Figure 4) whereas the 1/16 ms−1 MAS is first severely slowed down before catching up with the first one. 5. RELATED WORKS Since 96 [15], various work have been performed on learning in MAS, but rather few on concept learning. In [11] the MAS performs a form of ensemble learning in which the agents are lazy learners (no explicit representation is maintained) and sell useless examples to other agents. In [10] each agent observes all the examples but only perceive a part of their representation. In mutual online concept learning [14] the agents converge to a unique hypothesis, but each agent produces examples from its own concept representation, thus resulting in a kind of synchronization rather than in pure concept learning. 170 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 6: Accuracies of two asynchronous 11-MAS (1/33ms−1 and 1/16ms−1 example rates) . 6. CONCLUSION We have presented here and experimented a protocol for MAS online concept learning. The main feature of this collaborative learning mechanism is that it maintains a consistency property: though during the learning process each agent only receives and stores, with some limited redundancy, part of the examples received by the MAS, at any moment the current hypothesis is consistent with the whole set of examples. The hypotheses of our experiments do not address the issues of distributed MAS such as faults (for instance messages could be lost or corrupted) or other failures in general (crash, byzantine faults, etc.). Nevertheless, our framework is open, i.e., the agents can leave the system or enter it while the consistency mechanism is preserved. For instance if we introduce a timeout mechanism, even when a critic agent crashes or omits to answer, the consistency with the other critics (within the remaining agents) is entailed. In [1], a similar approach has been applied to MAS abduction problems: the hypotheses to maintain, given an incomplete information, are then facts or statements. Further work concerns first coupling induction and abduction in order to perform collaborative concept learning when examples are only partially observed by each agent, and second, investigating partial memory learning: how learning is preserved whenever one agent or the whole MAS forgets some selected examples. Aknowledgments We are very grateful to Dominique Bouthinon for implementing late modifications in SMILE, so much easing our experiments. Part of this work has been performed during the first authors visit to the Atelier De BioInformatique of Paris VI university, France. 7. REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson. When agents communicate hypotheses in critical situations. In DALT-2006, May 2006. [2] W. W. Cohen. Fast effective rule induction. In ICML, pages 115-123, 1995. [3] C. B. D.J. Newman, S. Hettich and C. Merz. UCI repository of machine learning databases, 1998. [4] S. Esmeir and S. Markovitch. Lookahead-based algorithms for anytime induction of decision trees. In ICMLO4, pages 257-264. Morgan Kaufmann, 2004. [5] J. F¨urnkranz. A pathology of bottom-up hill-climbing in inductive rule learning. In ALT, volume 2533 of LNCS, pages 263-277. Springer, 2002. [6] A. Guerra-Hern´andez, A. ElFallah-Seghrouchni, and H. Soldano. Learning in BDI multi-agent systems. In CLIMA IV, volume 3259, pages 218-233. Springer Verlag, 2004. [7] M. Henniche. Mgi: an incremental bottom-up algorithm. In IEEE Aust. and New Zealand Conference on Intelligent Information Systems, pages 347-351, 1994. [8] T.-S. Lim, W.-Y. Loh, and Y.-S. Shih. A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms. Machine Learning, 40(3):203-228, 2000. [9] M. A. Maloof and R. S. Michalski. Incremental learning with partial instance memory. Artif. Intell., 154(1-2):95-126, 2004. [10] P. J. Modi and W.-M. Shen. Collaborative multiagent learning for classification tasks. In AGENTS 01, pages 37-38. ACM Press, 2001. [11] S. Onta˜non and E. Plaza. Recycling data for multi-agent learning. In ICML 05, pages 633-640. ACM Press, 2005. [12] J. R. Quinlan. Induction of decision trees. Machine Learning, 1(1):81-106, 1986. [13] U. R¨uckert and S. Kramer. Towards tight bounds for rule learning. In ICML 04 (International conference on Machine learning), page 90, New York, NY, USA, 2004. ACM Press. [14] J. Wang and L. Gasser. Mutual online concept learning for multiple agents. In AAMAS, pages 362-369. ACM Press, 2002. [15] G. Weiß and S. Sen, editors. Adaption and Learning in Multi-Agent Systems, volume 1042 of Lecture Notes in Computer Science. Springer, 1996. [16] I. H. Witten and E. Frank. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufmann, October 1999. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 171",
    "original_translation": "SMILE: Aprendizaje Incremental Multiagente de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av. del presidente Kennedy, 75116 París Henry Soldano LIPN, UMR 7030 CNRS, Universidad Paris-Norte, 99 Av. J-B Clement, 93430, Villetaneuse RESUMEN Este artículo trata sobre el problema del aprendizaje colaborativo en un sistema multiagente. Aquí cada agente puede actualizar de forma incremental sus creencias B (la representación del concepto) para que se mantenga consistente con el conjunto completo de información K (los ejemplos) que ha recibido del entorno u otros agentes. Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo lograr que, en cualquier momento, una misma representación conceptual consistente esté presente en cada agente. El protocolo correspondiente se aplica al aprendizaje supervisado de conceptos. El método resultante SMILE (que significa Sound Multiagent Incremental LEarning) se describe y experimenta aquí. Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de múltiples agentes que por un solo agente. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de conceptos; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistema multiagente Términos Generales Experimentación, Algoritmos, Medición, Rendimiento 1. INTRODUCCIÓN Este artículo trata sobre el problema del aprendizaje colaborativo de conceptos en un sistema multiagente. [6] introduce una caracterización del aprendizaje en un sistema multiagente según el nivel de conciencia de los agentes. En el nivel 1, los agentes aprenden ∗El autor principal de este artículo es un estudiante. en el sistema sin tener en cuenta la presencia de otros agentes, excepto a través de la modificación que traen al entorno con sus acciones. El nivel 2 implica una interacción directa entre los agentes, ya que pueden intercambiar mensajes para mejorar su aprendizaje. El nivel 3 requeriría que los agentes tengan en cuenta las competencias de otros agentes y sean capaces de aprender observando el comportamiento de los otros agentes (considerándolos como entidades independientes y no como parte indeterminada del entorno como en el nivel 1). En este artículo nos enfocamos en el nivel 2, estudiando la interacción directa entre los agentes involucrados en un proceso de aprendizaje. Cada agente se asume capaz de aprender de forma incremental a partir de los datos que recibe, lo que significa que cada agente puede actualizar su conjunto de creencias B para mantenerlo consistente con el conjunto completo de información K que ha recibido del entorno o de otros agentes. En tal caso, diremos que es a-inconsistente. Aquí, el conjunto de creencias B representa conocimiento hipotético que por lo tanto puede ser revisado, mientras que el conjunto de información K representa conocimiento cierto, compuesto por observaciones y hechos no revisables. Además, suponemos que al menos una parte Bc de las creencias de cada agente es común a todos los agentes y debe mantenerse de esa manera. Por lo tanto, una actualización de este conjunto común Bc por parte del agente r debe provocar una actualización de Bc para toda la comunidad de agentes. Nos lleva a definir cuál es la mas-consistencia de un agente con respecto a la comunidad. El proceso de actualización de las creencias de la comunidad cuando uno de sus miembros recibe nueva información puede entonces definirse como el proceso de mantenimiento de la consistencia que garantiza que cada agente en la comunidad permanecerá más consistente. Este proceso de mantenimiento de la mas-consistencia de un agente al recibir nueva información le otorga el rol de aprendiz e implica la comunicación con otros agentes que actúan como críticos. Sin embargo, los agentes no están especializados y a su vez pueden ser aprendices o críticos, ninguno de ellos está limitado a un rol específico. Las piezas de información se distribuyen entre los agentes, pero pueden ser redundantes. No hay memoria central. El trabajo descrito aquí tiene su origen en un trabajo anterior sobre el aprendizaje en un sistema multiagente intencional utilizando un formalismo BDI [6]. En ese trabajo, los agentes tenían planes, cada uno de ellos asociado con un contexto que define en qué condiciones puede ser activado. Los planes (cada uno con su propio contexto) eran comunes a todo el conjunto de agentes en la comunidad. Los agentes tuvieron que adaptar su plan en función del contexto, dependiendo del fracaso o éxito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo a otros agentes ejemplos (éxitos o fracasos de planes). Sin embargo, este trabajo carecía de un protocolo de aprendizaje colectivo que permitiera una verdadera autonomía del sistema multiagente. El estudio de dicho protocolo es el objeto del presente artículo. En la sección 2 definimos formalmente la mas-consistencia de un mecanismo de actualización para todo el MAS y proponemos un mecanismo de actualización genérico demostrado que es mas consistente. En la sección 3 describimos SMILE, un aprendiz de conceptos multiagente incremental que aplica nuestro mecanismo de actualización mas consistente para el aprendizaje colaborativo de conceptos. La sección 4 describe varios experimentos sobre SMILE y discute varios problemas, incluyendo cómo varían la precisión y la simplicidad de la hipótesis actual al comparar el aprendizaje de un solo agente y el aprendizaje de múltiples agentes. En la sección 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la sección 6 discutiendo investigaciones adicionales sobre el aprendizaje más consistente. MODELO FORMAL 2.1 Definiciones y marco En esta sección, presentamos una formulación general del aprendizaje incremental colectivo en un sistema cognitivo de múltiples agentes. Representamos un MAS como un conjunto de agentes r1, ..., rn. Cada agente ri tiene un conjunto de creencias Bi que consiste en todo el conocimiento revisable que posee. Parte de estos conocimientos deben ser compartidos con otros agentes. La parte de Bi que es común a todos los agentes se denota como BC. Esta parte común provoca una dependencia entre los agentes. Si un agente ri actualiza su conjunto de creencias Bi a Bi, cambiando en el proceso BC en BC, entonces todos los demás agentes rk deben actualizar su conjunto de creencias Bk a Bk para que BC ⊆ Bk. Además, cada agente ri ha almacenado cierta información Ki. Suponemos que alguna propiedad de consistencia Cons(Bi, Ki) puede ser verificada por el agente mismo entre sus creencias Bi y su información Ki. Como se dijo antes, Bi representa el conocimiento que podría ser revisado, mientras que Ki representa hechos observados, considerados verdaderos, y que posiblemente puedan contradecir a Bi. Definición 1. a-consistencia de un agente Un agente ri es a-consistente si Cons(Bi, Ki) es verdadero. Ejemplo 1. El agente r1 tiene un conjunto de planes que se encuentran en la parte común BC de B1. Cada plan P tiene un contexto desencadenante d(P) (que actúa como una precondición) y un cuerpo. Alguna pieza de información k podría ser el plan P, desencadenado en la situación s, ha fallado a pesar de que s es una instancia de d(P). Si esta pieza de información se agrega a K1, entonces el agente r1 ya no es a-consistente: Cons(B1, K1 ∪ k) es falso. También queremos definir alguna noción de consistencia para todo el MAS dependiendo de los conjuntos de creencias e información de sus elementos constituyentes. Primero definiremos la consistencia de un agente ri con respecto a su conjunto de creencias Bi y su propio conjunto de información Ki junto con todos los conjuntos de información K1...Kn de los otros agentes del MAS. Simplemente lo haremos considerando cuál sería la a-consistencia del agente si tuviera la información de todos los demás agentes. Llamamos a esta noción la mas-consistencia: Definición 2. Un agente ri es mas-consistente si Cons(Bi, Ki ∪ K) es verdadero, donde K = ∪j∈{1,..,n}−{i}Kj 1 es el conjunto de toda la información de los otros agentes del MAS. 1 Lo notaremos como ∪ Kj cuando el contexto sea similar. Ejemplo 2. Usando el ejemplo anterior, supongamos que la pieza de información k está incluida en la información K2 del agente r2. Si la pieza de información no se transmite a r1, y por lo tanto no se agrega a K1, r1 permanece a-consistente. Sin embargo, r1 no es tan consistente como k en el conjunto K de toda la información del MAS. La consistencia global del MAS es simplemente la mas-consistencia de todos sus agentes. Definición 3. La consistencia de un MAS A MAS r1,...,rn es consistente si todos sus agentes ri son masconsistentes. Ahora definimos las propiedades requeridas para un mecanismo de revisión M que actualiza a un agente ri cuando recibe una pieza de información k. En lo siguiente, supondremos que: • La actualización siempre es posible, es decir, un agente siempre puede modificar su conjunto de creencias Bi para recuperar su a-consistencia. Diremos que cada agente es localmente eficiente. • Considerando dos conjuntos de información Cons(Bi, K1) y Cons(Bi, K2), también tenemos Cons(Bi, K1 ∪ K2). Es decir, la a-consistencia de los agentes es aditiva. • Si una pieza de información k relacionada con el conjunto común BC es consistente con un agente, es consistente con todos los agentes: para todos los pares de agentes (ri, rj) tales que Cons(Bi, Ki) y Cons(Bj, Kj) son verdaderos, tenemos, para toda pieza de información k: Cons(Bi, Ki ∪ k) si y solo si Cons(Bj, Kj ∪ k). En tal caso, diremos que el MAS es coherente. Esta última condición simplemente significa que el conjunto de creencias común BC es independiente de las posibles diferencias entre los conjuntos de creencias Bi de cada agente ri. En el caso más simple, B1 = ... = Bn = BC. M también será visto como un mecanismo de aprendizaje incremental y representado como una aplicación que cambia Bi en Bi. En lo siguiente, anotaremos ri(Bi, Ki) para ri cuando sea útil. Definición 4. a-consistencia de una revisión Un mecanismo de actualización M es a-consistente si, para cualquier agente ri y cualquier pieza de información k que llegue a ri, la a-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki) a-consistente ⇒ ri(Bi, Ki) a-consistente, donde Bi = M(Bi) y Ki = Ki ∪ k es el conjunto de toda la información de otros agentes del MAS. De la misma manera, definimos la mas-consistencia de un mecanismo de revisión como la a-consistencia de este mecanismo si los agentes disponen de toda la información en el MAS. En lo siguiente, anotaremos, si es necesario, ri(Bi, Ki, K) para el agente ri en el MAS r1 . . . rn. Definición 5. mas-consistencia de una revisión Un mecanismo de actualización Ms es mas-consistente si para todo agente ri y toda pieza de información k que llega a ri, la mas-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki, K) más-consistente ⇒ ri(Bi, Ki, K) más-consistente, donde Bi = Ms(Bi), Ki = Ki ∪ k, y K = ∪Kj es el conjunto de toda la información del MAS. El Sexto Internacional. En última instancia, cuando un agente aplica un mecanismo mas-consistente al recibir una nueva pieza de información, un efecto secundario deseable del mecanismo debería ser que todos los demás agentes permanezcan mas-consistentes después de cualquier modificación de la parte común BC, es decir, el MAS en sí mismo debería volver a ser consistente. Esta propiedad se define de la siguiente manera: Definición 6. La fuerte mas-consistencia de un mecanismo de actualización. Un mecanismo de actualización Ms es fuertemente mas-consistente si - Ms es mas-consistente, y - la aplicación de Ms por un agente preserva la consistencia del MAS. 2.2 Un mecanismo de actualización fuertemente mas-consistente. La idea general es que, dado que la información está distribuida entre todos los agentes del MAS, debe haber alguna interacción entre el agente aprendiz y los demás agentes en un mecanismo de actualización fuertemente mas-consistente Ms. Para garantizar su mas-consistencia, Ms estará constituido por aplicaciones reiteradas por parte del agente aprendiz ri de un mecanismo interno a-consistente M, seguido por algunas interacciones entre ri y los otros agentes, hasta que ri recupere su mas-consistencia. Describimos a continuación un mecanismo, primero con una descripción de una interacción, luego una iteración y finalmente una declaración de la condición de terminación del mecanismo. El mecanismo es activado por un agente ri al recibir una pieza de información k que interrumpe la mas-consistencia. Tomaremos M(Bi) como el conjunto de creencias del agente aprendiz ri después de una actualización, BC la parte común modificada por ri, y Bj el conjunto de creencias de otro agente rj inducido por la modificación de su parte común BC en BC. Una interacción I(ri, rj) entre el agente aprendiz ri y otro agente rj, actuando como crítico, está constituida por los siguientes pasos: • el agente ri envía la actualización BC de la parte común de sus creencias. Habiendo aplicado su mecanismo de actualización, ri es a-consistente. • El agente rj verifica la modificación Bj de sus creencias inducida por la actualización BC. Si esta modificación conserva su a-consistencia, rj adopta esta modificación. El agente rj envía ya sea una aceptación de BC o una negación junto con una (o más) pieza(s) de información k tal que Cons(Bj, k) es falso. Una iteración de Ms estará compuesta por: • la recepción por parte del agente aprendiz ri de una pieza de información y la actualización M(Bi) restaurando su consistencia • un conjunto de interacciones I(ri, rj) (en las cuales varios agentes críticos posiblemente puedan participar). Si al menos una pieza de información k es transmitida a ri, la adición de k necesariamente hará que ri sea inconsistente y entonces ocurrirá una nueva iteración. Este mecanismo termina cuando ningún agente puede proporcionar tal pieza de información k. Cuando es el caso, se restaura la masconsistencia del agente aprendiz ri. Proposición 1. Dejen que r1,...,rn sea un MAS consistente en el que el agente ri recibe una pieza de información k que rompe su consistencia, y M sea un mecanismo interno de actualización a-consistente. El mecanismo de actualización descrito anteriormente por Ms es altamente mas-consistente. Prueba. La prueba se deriva directamente de la descripción del mecanismo. Este mecanismo asegura que cada vez que un agente recibe un evento, su mas-consistencia será restaurada. Como los otros agentes adoptan la actualización final BC, todos son mas-coherentes y el MAS es coherente. Por lo tanto, Ms es un mecanismo de actualización fuertemente consistente. En el mecanismo descrito anteriormente, el agente aprendiz es el único que recibe y memoriza información durante la ejecución del mecanismo. Se asegura de que Ms termine. Las piezas de información transmitidas por otros agentes y memorizadas por el agente aprendiz son redundantes, ya que ya están presentes en el MAS, más precisamente en la memoria de los agentes críticos que las transmitieron. Se debe tener en cuenta que el mecanismo propuesto por la Sra. aquí no indica explícitamente el orden ni el alcance de las interacciones. Consideraremos en lo siguiente que la propuesta de modificación BC se envía secuencialmente a los diferentes agentes (mecanismo síncrono). Además, la respuesta de un agente crítico solo contendrá una pieza de información inconsistente con la modificación propuesta. Diremos que la respuesta del agente es mínima. Este mecanismo, siendo sincrónico con una respuesta mínima, minimiza la cantidad de información transmitida por los agentes. Ahora lo ilustraremos en el caso del aprendizaje de conceptos multiagente. 3. APRENDIZAJE INCREMENTAL DE MÚLTIPLES AGENTES 3.1 La tarea de aprendizaje Experimentamos el mecanismo propuesto anteriormente en el caso del aprendizaje conceptual MAS incremental. Aquí consideramos un lenguaje de hipótesis en el cual una hipótesis es una disyunción de términos. Cada término es una conjunción de átomos de un conjunto A. Un ejemplo está representado por una etiqueta + o − y una descripción 2 compuesta por un subconjunto de átomos e ⊆ A. Un término abarca un ejemplo si sus átomos constituyentes están incluidos en el ejemplo. Una hipótesis abarca un ejemplo si uno de sus términos lo abarca. Esta representación se utilizará a continuación para aprender fórmulas booleanas. Los literales negativos se representan aquí mediante átomos adicionales, como not − a. La fórmula booleana f = (a ∧ b) ∨ (b ∧ ¬c) se escribirá entonces como (a ∧ b) ∨ (b ∧ no − c). Un ejemplo positivo de f, como {no − a, b, no − c}, representa un modelo para f. 3.2 Proceso de aprendizaje incremental El proceso de aprendizaje es un mecanismo de actualización que, dado una hipótesis actual H, una memoria E = E+ ∪ E− llenada con los ejemplos recibidos previamente, y un nuevo ejemplo positivo o negativo e, produce una nueva hipótesis actualizada. Antes de esta actualización, la hipótesis dada es completa, lo que significa que cubre todos los ejemplos positivos de E+, y 2 Cuando no haya posibilidad de confusión, la palabra ejemplo se utilizará para referirse al par (etiqueta, descripción) así como a la descripción sola. 166 La Sexta Conferencia Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) es coherente, lo que significa que no cubre ningún ejemplo negativo de E−. Después de la actualización, la nueva hipótesis debe ser completa y coherente con el nuevo estado de memoria E ∪ {e}. Describimos a continuación nuestro mecanismo de actualización de agente único, inspirado en un trabajo previo sobre aprendizaje incremental[7]. En lo siguiente, una hipótesis H para la fórmula objetivo f es una lista de términos h, cada uno de ellos siendo una conjunción de átomos. H es coherente si todos los términos h son coherentes, y H es completo si cada elemento de E+ está cubierto por al menos un término h de H. Cada término es, por construcción, la lgg (generalización general menos general) de un subconjunto de instancias positivas {e1, ..., en}, es decir, el término más específico que cubre {e1, ..., en}. El operador lgg se define considerando ejemplos como términos, por lo que denotamos como lgg(e) al término más específico que cubre e, y como lgg(h, e) al término más específico que es más general que h y que cubre e. Restringir el término a lgg es la base de muchos algoritmos de aprendizaje de abajo hacia arriba (por ejemplo [5]). En la tipología propuesta por [9], nuestro mecanismo de actualización es un aprendiz incremental con memoria completa de instancias: el aprendizaje se realiza mediante actualizaciones sucesivas y se almacenan todos los ejemplos. El mecanismo de actualización depende de la hipótesis en curso H, los ejemplos en curso E+ y E−, y el nuevo ejemplo e. Hay tres casos posibles: • e es positivo y H cubre e, o e es negativo y H no cubre e. No se necesita actualización, H ya es completo y coherente con E ∪ {e}. • e es positivo y H no cubre e: e se denota como un contraejemplo positivo de H. Luego buscamos generalizar a su vez los términos h de H. Tan pronto como se encuentre una generalización correcta h = lgg(h, e), h reemplaza a h en H. Si hay un término que es menos general que h, se descarta. Si ninguna generalización es correcta (es decir, coherente), H ∪ lgg(e) reemplaza a H. • e es negativo y H cubre e: e se denota como un contraejemplo negativo de H. Cada término h que cubre e es entonces descartado de H y reemplazado por un conjunto de términos {h1, ...., hn} que, en su totalidad, es coherente con E− ∪ {e} y que cubre los ejemplos de E+ no cubiertos por H − {h}. Los términos de la hipótesis final H que son menos generales que otros son descartados de H. Ahora describiremos el caso en el que e = e− es un ejemplo negativo cubierto. Las siguientes funciones se utilizan aquí: • coveredOnlyBy(h, E+) da el subconjunto de E+ cubierto por h y ningún otro término de H. • bestCover(h1, h2) da h1 si h1 cubre más ejemplos de uncoveredPos que h2, de lo contrario da h2. • covered(h) da los elementos de uncoveredPos cubiertos por h. // Especialización de cada h cubriendo e− para cada h de H cubriendo e− hacer H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= átomos que no están ni en e− ni en h mientras (uncoveredPos = ∅) hacer // buscando la mejor especialización de h hc=h best=⊥ // ⊥ no cubre ningún ejemplo para cada a de Ar hacer hc= h ∧ a best = bestCover(hc, best) finpara Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) finmientras finpara Los términos de H que son menos generales que otros son descartados. Ten en cuenta que este mecanismo tiende tanto a hacer una actualización mínima de la hipótesis actual como a minimizar el número de términos en la hipótesis, en particular descartando términos menos generales que otros después de actualizar una hipótesis. 3.3 Aprendizaje colectivo Si H es la hipótesis actual, Ei es la memoria actual de ejemplos del agente ri y E es el conjunto de todos los ejemplos recibidos por el sistema, la notación de la sección 2 se convierte en Bi = BC = H, Ki = Ei y K = E. Cons(H, Ei) establece que H es completo y coherente con Ei. En tal caso, ri es a-consistente. La pieza de información k recibida por el agente ri es aquí simplemente un ejemplo e junto con su etiqueta. Si e es tal que la hipótesis actual H no es completa ni coherente con Ei ∪ {e}, e contradice a H: ri se vuelve a-inconsistente, y por lo tanto el MAS ya no es consistente. La actualización de una hipótesis cuando llega un nuevo ejemplo es un mecanismo a-consistente. Siguiendo la proposición 1, este mecanismo puede ser utilizado para producir un mecanismo fuerte mas-consistente: al recibir un nuevo ejemplo en el MAS por un agente r, posiblemente se necesite una actualización y, después de un conjunto de interacciones entre r y los otros agentes, resulta en una nueva hipótesis compartida por todos los agentes y que restaura la consistencia del MAS, es decir, que es completa y coherente con el conjunto ES de todos los ejemplos presentes en el MAS. Es claro que al minimizar el número de modificaciones de hipótesis, este mecanismo sincrónico y minimalista reduce el número de ejemplos recibidos por el aprendiz de otros agentes, y por ende, el número total de ejemplos almacenados en el sistema. 4. EXPERIMENTOS En lo siguiente, aprenderemos una fórmula booleana que es una prueba difícil para el método de aprendizaje: el 11-multiplexor (ver [4]). Se refiere a 3 atributos booleanos de dirección a0, a1, a2 y 8 atributos booleanos de datos d0, ..., d7. La fórmula f11 se cumple si el número codificado por los 3 atributos de dirección es el número de un atributo de datos cuyo valor es 1. Su fórmula es la siguiente: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0). Hay 2048 = 211 posibles ejemplos, la mitad de los cuales son positivos (lo que significa que satisfacen f11) mientras que la otra mitad es negativa. Un experimento suele estar compuesto por 50 pruebas. Cada ejecución corresponde a una secuencia de 600 ejemplos que son aprendidos de forma incremental por un Sistema Multiagente con n agentes. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 167 (n-MAS). Un número de variables como la precisión (es decir, la frecuencia de clasificación correcta de un conjunto de ejemplos no vistos), el tamaño de la hipótesis (es decir, el número de términos en la fórmula actual) o el número de ejemplos almacenados, se registra cada vez que el sistema recibe 25 ejemplos durante esas ejecuciones. En el protocolo que se utiliza aquí, un nuevo ejemplo se envía a un agente aleatorio cuando el MAS es consistente. El siguiente ejemplo será enviado a su vez a otro agente cuando la consistencia del MAS haya sido restaurada. De esta manera simulamos una especie de aprendizaje lento: la frecuencia de llegada de ejemplos es lenta en comparación con el tiempo que lleva una actualización. 4.1 Eficiencia del aprendizaje conceptual en MAS 4.1.1 Tiempo de ejecución Discutimos brevemente aquí el tiempo de ejecución del aprendizaje en el MAS. Se debe tener en cuenta que todo el conjunto de acciones e interacciones en el MAS se simula en un solo procesador. La Figura 1 muestra que el tiempo depende linealmente del número de agentes. Al final de la parte más activa del aprendizaje (200 ejemplos), un 16MAS ha tomado 4 veces más tiempo de aprendizaje que un 4-MAS. Este tiempo de ejecución representa el conjunto completo de aprendizaje y la Figura 1: Tiempo de ejecución de un n-MAS (desde n = 2 en la parte inferior hasta n = 20 en la parte superior). actividad de comunicación y sugiere el costo de mantener una hipótesis de aprendizaje consistente en un MAS compuesto por agentes autónomos. 4.1.2 Redundancia en la memoria del MAS Estudiamos ahora la distribución de los ejemplos en la memoria del MAS. La redundancia se escribe RS = nS/ne, donde nS es el número total de ejemplos almacenados en el MAS, que es la suma de los tamaños de las memorias de ejemplos de los agentes Ei, y ne es el número total de ejemplos recibidos del entorno en el MAS. En la figura 2, comparamos las redundancias en MAS de 2 a 20 agentes. Hay un pico que se mueve lentamente de 80 a 100 ejemplos, que representa la cantidad de ejemplos para los cuales el aprendizaje es más activo. Para 20 agentes, la redundancia máxima no es más de 6, lo cual es mucho menor que el valor teórico máximo de 20. Ten en cuenta que cuando el aprendizaje se vuelve menos activo, la redundancia tiende hacia su valor mínimo 1: cuando ya no hay más actualizaciones, los ejemplos son solo la Figura 2: Redundancia de ejemplos almacenados en un nMAS (de n = 2 en la parte inferior a n = 20 en la parte superior) almacenados por el agente que los recibe. Un n-MAS selecciona una solución más simple que un solo agente. El mecanismo propuesto tiende a minimizar el número de términos en la hipótesis seleccionada. Durante el aprendizaje, el tamaño de la hipótesis actual crece más allá del óptimo, y luego disminuye cuando el MAS converge. En el banco de pruebas Multiplexer 11, el número óptimo de términos es 8, pero también existen fórmulas equivalentes con más términos. Es interesante notar que en este caso el 10-MAS converge hacia una solución exacta más cercana al número óptimo de términos (en este caso 8) (ver Figura 3). Después de haber presentado 1450 ejemplos, tanto el 1-MAS como el 10-MAS han aprendido exactamente el concepto (las precisiones respectivas son 0.9999 y 1), pero el agente individual expresa en promedio el resultado como una DNF de 11.0 términos, mientras que el 10-MAS lo expresa como una DNF de 8.8 términos. Sin embargo, para algunas otras funciones booleanas encontramos que durante el aprendizaje, 1-MAS siempre produce hipótesis más grandes que 10-MAS, pero que ambos MAS convergen a hipótesis con resultados de tamaño similar. 4.1.4 Un n-MAS es más preciso que un agente único. La Figura 4 muestra la mejora proporcionada por un MAS con n agentes en comparación con un agente único. Esta mejora no era especialmente esperada, porque ya sea que tengamos uno o n agentes, cuando se le dan N ejemplos al MAS, tiene acceso a la misma cantidad de información, mantiene solo una hipótesis en curso y utiliza el mismo algoritmo básico de revisión cada vez que un agente tiene que modificar la hipótesis actual. Ten en cuenta que si la precisión de los MAS de 1, 2, 4 y 10 es significativamente diferente, mejorando a medida que aumenta el número de agentes, no hay una diferencia clara más allá de este punto: la curva de precisión de los MAS de 100 agentes es muy similar a la de los MAS de 10 agentes. 4.1.4.1 Fórmulas booleanas. Para evaluar esta mejora de precisión, hemos experimentado nuestro protocolo en otros problemas de aprendizaje de funciones booleanas. Como en el caso del Multiplexor-11, estas funciones 168 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 3: Tamaño de la hipótesis construida por 1 y 10MAS: el caso M11. Figura 4: Precisión de un n-MAS: el caso M11 (de abajo hacia arriba, n = 1, 2, 4, 10, 100). Se aprenden en forma de DNF3 más o menos sintácticamente complejos (es decir, con más o menos términos conjuntivos en la DNF), pero también son más o menos difíciles de aprender, ya que puede ser difícil encontrar su camino en el espacio de hipótesis para alcanzarlos. Además, la presencia en la descripción de atributos irrelevantes (es decir, atributos que no pertenecen al DNF objetivo) hace que el problema sea más difícil. Los siguientes problemas han sido seleccionados para experimentar con nuestro protocolo: (i) el multiplexor-11 con 9 atributos irrelevantes: M11 9, (ii) el multiplexor-20 M20 (con 4 bits de dirección y 16 bits de datos), (iii) un problema de paridad difícil (ver [4]) el Xorp m: debe haber un número impar de bits con valor 1 en los primeros p atributos para que la instancia sea positiva, los p bits restantes son irrelevantes, y (iv) una fórmula DNF simple (a ∧ b ∧ c) ∨ (c ∧ d ∧ e) ∨ (e ∧ f ∧ g) ∧ (g ∧ h ∧ i) con 19 atributos irrelevantes. La siguiente tabla resume alguna información sobre estos problemas, proporcionando el número total de atributos, incluidos los irrelevantes, el número de atributos irrelevantes en Forma Normal Disyuntiva 3, el número mínimo de términos de la DNF correspondiente, y el número de ejemplos de aprendizaje utilizados. Pb att. irre. att. términos ex. A continuación se presentan los resultados de precisión de nuestro mecanismo de aprendizaje con un solo agente y un MAS de 10 agentes, junto con los resultados de dos algoritmos estándar implementados con el entorno de aprendizaje WEKA[16]: JRip (una implementación de RIPPER[2]) e Id3[12]. Para los experimentos con JRip e Id3, medimos la precisión media en 50 pruebas, separando aleatoriamente los ejemplos en un conjunto de aprendizaje y un conjunto de prueba cada vez. Los parámetros de JRip e Id3 son los predeterminados, excepto que JRip se utiliza sin poda. La siguiente tabla muestra los resultados: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 Es claro que los problemas difíciles se resuelven mejor con más agentes (ver por ejemplo xor5 15). Creemos que estos beneficios, que pueden ser importantes con un número creciente de agentes, se deben al hecho de que cada agente realmente memoriza solo parte del número total de ejemplos, y esta parte es seleccionada en parte por otros agentes como contraejemplos, lo que provoca un mayor número de actualizaciones de hipótesis actuales y, por lo tanto, una mejor exploración del espacio de hipótesis. 4.1.4.2 Problemas de base de datos de ML. También realizamos experimentos con algunos problemas no booleanos. Consideramos solo problemas de dos clases (positivo/negativo), tomados de la base de datos de problemas de aprendizaje de UCIs. En todos estos problemas, los ejemplos se describen como un vector de pares (atributo, valor). Los dominios de valor pueden ser booleanos, numéricos (conjunto totalmente ordenado) o nominales (conjunto no ordenado). Un conjunto adecuado de átomos A debe ser constituido para cada problema. Por ejemplo, si a es un atributo numérico, definimos como máximo k umbrales si, dando k+1 intervalos de densidad uniforme. Por lo tanto, cada umbral distintivo si da dos átomos, uno ≤ si y otro > si. En nuestros experimentos, tomamos un número máximo de umbral k = 8. Por ejemplo, en el caso del problema de iono, había 34 atributos numéricos, y una instancia se describe con 506 átomos. A continuación se presentan los resultados de precisión de nuestro sistema junto con los resultados anteriores. La columna Nb ex. se refiere al 4. La probabilidad de que el valor de a esté en cualquier intervalo es constante. El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 169 número de ejemplos utilizados para el aprendizaje5. La columna (1) representa los valores de precisión mínima y máxima para los treinta y tres clasificadores probados en [8]. La columna (2) representa los resultados de [13], donde se comparan varios métodos de aprendizaje con métodos de aprendizaje en conjunto utilizando conjuntos de clasificadores ponderados. La columna S-1 y S-10 dan la precisión de SMILE con 1 y 10 agentes, respectivamente. Esta tabla muestra que el algoritmo incremental correspondiente al caso de un solo agente, proporciona resultados honorables en relación a los métodos clásicos no incrementales que utilizan hipótesis más grandes y complejas. En algunos casos, hay una mejora en la precisión con un MAS de 10 agentes. Sin embargo, con datos de referencia de este tipo, que suelen ser ruidosos, la dificultad no radica realmente en la forma en que se explora el espacio de búsqueda, por lo que la mejora observada no siempre es significativa. El mismo tipo de fenómeno se ha observado con métodos dedicados a problemas booleanos difíciles [4]. 4.2 Sincronización de MAS En este caso consideramos que n agentes individuales aprenden sin interacciones y en un momento dado comienzan a interactuar, formando así un MAS. El propósito es observar cómo los agentes aprovechan la colaboración cuando parten de diferentes estados de creencias y memorias. En esta sección comparamos un 1-MAS, un 10-MAS (ref) y un 10-MAS (100sync) cuyos agentes no se comunicaron durante la llegada de los primeros 100 ejemplos (10 por agentes). Las tres curvas de precisión se muestran en la figura 5. Al comparar la curva del agente individual con la del 10-MAS sincronizado, podemos observar que después del inicio de la sincronización, es decir, en 125 ejemplos, las precisiones son idénticas. Esto era esperado ya que tan pronto como un ejemplo e recibido por el MAS contradice la hipótesis actual del agente ra que lo recibe, este agente realiza una actualización y su nueva hipótesis es propuesta a los otros agentes para su crítica. Por lo tanto, este primer ejemplo contradictorio lleva al MAS a alcanzar coherencia en relación con todo el conjunto de ejemplos presentes en la memoria de los agentes. Una mayor precisión, correspondiente a un 10-MAS, se obtiene más tarde, a partir del ejemplo 175. En otras palabras, el beneficio de una mejor exploración del espacio de investigación se obtiene ligeramente más tarde en el proceso de aprendizaje. Ten en cuenta que esta sincronización ocurre de forma natural en todas las situaciones en las que los agentes tienen, por alguna razón, una divergencia entre su hipótesis y la memoria del sistema. Esto incluye la fusión de dos MAS en una sola o la llegada de nuevos agentes en un MAS existente. 4.3 Experimentos sobre el aprendizaje asincrónico: el efecto de un gran flujo de datos. Para ttt y kr-vs-kp, nuestro protocolo no utilizó más de 574 y 958 ejemplos de aprendizaje respectivamente, por lo que colocamos otro número en la columna. Figura 5: Precisión de un 1-MAS, un 10-MAS y un 10-MAS sincronizado después de 100 ejemplos. En este experimento relajamos nuestro modo de aprendizaje lento: los ejemplos se envían a una velocidad determinada al MAS. El flujo de ejemplos resultante se mide en ms−1, y representa la cantidad de ejemplos enviados al MAS cada milisegundo. Cuando el flujo es demasiado grande, el MAS no puede alcanzar la consistencia del MAS al recibir un ejemplo del entorno antes de que llegue un nuevo ejemplo. Esto significa que el proceso de actualización, iniciado por el agente r0 al recibir un ejemplo, puede estar incompleto cuando un nuevo ejemplo es recibido por r0 u otro agente r1. Como resultado, un agente crítico puede tener que enviar contraejemplos de hipótesis enviadas por varios agentes en el instante t. Sin embargo, en nuestro entorno, a medida que los agentes memorizan todos los ejemplos que reciben cuando finaliza el flujo, el MAS alcanza necesariamente consistencia MAS con respecto a todos los ejemplos recibidos hasta el momento. En nuestros experimentos, aunque la curva de aprendizaje se ralentiza durante la fase intensa de aprendizaje (correspondiente a una baja precisión de las hipótesis actuales), el MAS aún logra alcanzar una hipótesis satisfactoria más adelante, ya que hay menos contraejemplos en el flujo de ejemplos. En la Figura 6 comparamos las precisiones de dos 11-MAS respectivamente sometidos a flujos de ejemplos de diferentes tasas al aprender la fórmula M11. La curva de aprendizaje del MAS al recibir un ejemplo a una velocidad de 1/33 ms−1 casi no se ve alterada (ver Figura 4), mientras que el MAS a 1/16 ms−1 primero se ralentiza severamente antes de alcanzar al primero. 5. TRABAJOS RELACIONADOS Desde el 96 [15], se han realizado varios trabajos sobre el aprendizaje en Sistemas Multiagente, pero muy pocos sobre el aprendizaje de conceptos. En [11] el MAS realiza una forma de aprendizaje en conjunto en la que los agentes son aprendices perezosos (no se mantiene una representación explícita) y venden ejemplos inútiles a otros agentes. En [10] cada agente observa todos los ejemplos pero solo percibe una parte de su representación. En el aprendizaje de conceptos en línea mutuo, los agentes convergen hacia una hipótesis única, pero cada agente produce ejemplos desde su propia representación del concepto, lo que resulta en una especie de sincronización en lugar de un aprendizaje de conceptos puro. 170 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Precisión de dos sistemas multiagente asincrónicos de 11 agentes (tasas de ejemplo de 1/33ms−1 y 1/16ms−1). 6. CONCLUSIÓN Hemos presentado y experimentado un protocolo para el aprendizaje de conceptos en línea de MAS. La característica principal de este mecanismo de aprendizaje colaborativo es que mantiene una propiedad de consistencia: aunque durante el proceso de aprendizaje cada agente solo recibe y almacena, con cierta redundancia limitada, parte de los ejemplos recibidos por el MAS, en cualquier momento la hipótesis actual es consistente con todo el conjunto de ejemplos. Las hipótesis de nuestros experimentos no abordan los problemas de los MAS distribuidos, como fallos (por ejemplo, mensajes perdidos o corruptos) u otras fallas en general (crash, fallos bizantinos, etc.). Sin embargo, nuestro marco de trabajo es abierto, es decir, los agentes pueden salir del sistema o ingresar a él mientras se preserva el mecanismo de consistencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente crítico se bloquea o no responde, se garantiza la consistencia con los otros críticos (dentro de los agentes restantes). En [1], se ha aplicado un enfoque similar a los problemas de abducción en MAS: las hipótesis a mantener, dada una información incompleta, son entonces hechos o afirmaciones. El trabajo adicional se refiere en primer lugar a acoplar la inducción y la abducción para realizar un aprendizaje colaborativo de conceptos cuando los ejemplos son solo parcialmente observados por cada agente, y en segundo lugar, a investigar el aprendizaje de memoria parcial: cómo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados. Agradecimientos Estamos muy agradecidos a Dominique Bouthinon por implementar las modificaciones tardías en SMILE, facilitando mucho nuestros experimentos. Parte de este trabajo se realizó durante la visita del primer autor al Atelier De BioInformatique de la Universidad Paris VI, Francia. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En DALT-2006, mayo de 2006. [2] W. W. Cohen. Inducción de reglas rápida y efectiva. En ICML, páginas 115-123, 1995. [3] C. B. D.J. Newman, S. Hettich y C. Merz. Repositorio de bases de datos de aprendizaje automático de UCI, 1998. [4] S. Esmeir y S. Markovitch. Algoritmos basados en anticipación para la inducción en cualquier momento de árboles de decisión. En ICMLO4, páginas 257-264. Morgan Kaufmann, 2004. [5] J. F¨urnkranz. \n\nMorgan Kaufmann, 2004. [5] J. F¨urnkranz. Una patología de la escalada de colina de abajo hacia arriba en el aprendizaje inductivo de reglas. En ALT, volumen 2533 de LNCS, páginas 263-277. Springer, 2002. [6] A. Guerra-Hernández, A. ElFallah-Seghrouchni y H. Soldano. Aprendizaje en sistemas multiagente BDI. En CLIMA IV, volumen 3259, páginas 218-233. Springer Verlag, 2004. [7] M. Henniche. \n\nSpringer Verlag, 2004. [7] M. Henniche. Mgi: un algoritmo incremental de abajo hacia arriba. En la Conferencia IEEE de Australia y Nueva Zelanda sobre Sistemas de Información Inteligente, páginas 347-351, 1994. [8] T.-S. Lim, W.-Y. Loh, y Y.-S. Shih. Una comparación de la precisión de predicción, complejidad y tiempo de entrenamiento de treinta y tres algoritmos de clasificación antiguos y nuevos. Aprendizaje automático, 40(3):203-228, 2000. [9] M. A. Maloof y R. S. Michalski. Aprendizaje incremental con memoria parcial de instancias. I'm sorry, but the sentence \"Artif.\" is not a complete sentence. Can you provide more context or a complete sentence for me to translate to Spanish? Intell., 154(1-2):95-126, 2004. [10] P. J. Modi y W.-M. Shen. Aprendizaje colaborativo multiagente para tareas de clasificación. En AGENTS 01, páginas 37-38. ACM Press, 2001. [11] S. Onta˜non y E. Plaza. Reciclaje de datos para el aprendizaje multiagente. En ICML 05, páginas 633-640. ACM Press, 2005. [12] J. R. Quinlan. \n\nACM Press, 2005. [12] J. R. Quinlan. Inducción de árboles de decisión. Aprendizaje automático, 1(1):81-106, 1986. [13] U. R¨uckert y S. Kramer. Hacia límites ajustados para el aprendizaje de reglas. En ICML 04 (Conferencia Internacional sobre Aprendizaje Automático), página 90, Nueva York, NY, EE. UU., 2004. ACM Press. [14] J. Wang y L. Gasser. Aprendizaje de conceptos en línea mutuo para múltiples agentes. En AAMAS, páginas 362-369. ACM Press, 2002. [15] G. Weiß y S. Sen, editores. Adaptación y Aprendizaje en Sistemas Multiagente, volumen 1042 de las Notas de Conferencia en Ciencias de la Computación. Springer, 1996. [16] I. H. Witten y E. Frank. Minería de datos: Herramientas y técnicas prácticas de aprendizaje automático con implementaciones en Java. Morgan Kaufmann, octubre de 1999. La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 171",
    "original_sentences": [
        "SMILE: Sound Multi-agent Incremental LEarning ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av.",
        "du pr´esident Kennedy, 75116 Paris Henry Soldano LIPN, UMR 7030 CNRS, University Paris-Nord, 99 Av.",
        "J-B Clement, 93430, Villetaneuse ABSTRACT This article deals with the problem of collaborative learning in a multi-agent system.",
        "Here each agent can update incrementally its beliefs B (the concept representation) so that it is in a way kept consistent with the whole set of information K (the examples) that he has received from the environment or other agents.",
        "We extend this notion of consistency (or soundness) to the whole MAS and discuss how to obtain that, at any moment, a same consistent concept representation is present in each agent.",
        "The corresponding protocol is applied to supervised concept learning.",
        "The resulting method SMILE (standing for Sound Multiagent Incremental LEarning) is described and experimented here.",
        "Surprisingly some difficult boolean formulas are better learned, given the same learning set, by a Multi agent system than by a single agent.",
        "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Concept learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent system General Terms Experimentation, Algorithms, Measurement, Performance 1.",
        "INTRODUCTION This article deals with the problem of collaborative concept learning in a multi-agent system. [6] introduces a characterisation of learning in multi-agent system according to the level of awareness of the agents.",
        "At level 1, agents learn ∗The primary author of this paper is a student. in the system without taking into account the presence of other agents, except through the modification brought upon the environment by their action.",
        "Level 2 implies direct interaction between the agents as they can exchange messages to improve their learning.",
        "Level 3 would require agents to take into account the competencies of other agents, and be able to learn from observation of the other agents behaviour (while considering them as independant entities and not indetermined part of the environment as in level 1).",
        "We focus in this paper on level 2, studying direct interaction between agents involved in a learning process.",
        "Each agent is assumed to be able to learn incrementally from the data he receives, meaning that each agent can update his belief set B to keep it consistent with the whole set of information K that he has received from the environment or from other agents.",
        "In such a case, we will say that he is a-consistent.",
        "Here, the belief set B represents hypothetical knowledge that can therefore be revised, whereas the set of information K represents certain knowledge, consisting of non revisable observations and facts.",
        "Moreover, we suppose that at least a part Bc of the beliefs of each agent is common to all agents and must stay that way.",
        "Therefore, an update of this common set Bc by agent r must provoke an update of Bc for the whole community of agents.",
        "It leads us to define what is the mas-consistency of an agent with respect to the community.",
        "The update process of the community beliefs when one of its members gets new information can then be defined as the consistency maintenance process ensuring that every agent in the community will stay masconsistent.",
        "This mas-consistency maintenance process of an agent getting new information gives him the role of a learner and implies communication with other agents acting as critics.",
        "However, agents are not specialised and can in turn be learners or critics, none of them being kept to a specific role.",
        "Pieces of information are distributed among the agents, but can be redundant.",
        "There is no central memory.",
        "The work described here has its origin in a former work concerning learning in an intentional multi-agent system using a BDI formalism [6].",
        "In that work, agents had plans, each of them being associated with a context defining in which conditions it can be triggered.",
        "Plans (each of them having its own context) were common to the whole set of agents in the community.",
        "Agents had to adapt their plan contexts depending on the failure or success of executed plans, using a learning mechanism and asking other agents for examples (plans successes or failures).",
        "However this work lacked a collective learning protocol enabling a real autonomy of the multi-agent system.",
        "The study of such a protocol is the object of the present paper.",
        "In section 2 we formally define the mas-consistency of an update mechanism for the whole MAS and we propose a generic update mechanism proved to be mas consistent.",
        "In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent update mechanism to collaborative concept learning.",
        "Section 4 describes various experiments on SMILE and discusses various issues including how the accuracy and the simplicity of the current hypothesis vary when comparing single agent learning and mas learning.",
        "In section 5 we briefly present some related works and then conclude in section 6 by discussing further investigations on mas consistent learning. 2.",
        "FORMAL MODEL 2.1 Definitions and framework In this section, we present a general formulation of collective incremental learning in a cognitive multi agent system.",
        "We represent a MAS as a set of agents r1, ..., rn.",
        "Each agent ri has a belief set Bi consisting of all the revisable knowledge he has.",
        "Part of these knowledges must be shared with other agents.",
        "The part of Bi that is common to all agents is denoted as BC .",
        "This common part provokes a dependency between the agents.",
        "If an agent ri updates his belief set Bi to Bi, changing in the process BC into BC , all other agents rk must then update their belief set Bk to Bk so that BC ⊆ Bk.",
        "Moreover, each agent ri has stored some certain information Ki.",
        "We suppose that some consistency property Cons(Bi, Ki) can be verified by the agent itself between its beliefs Bi and its information Ki.",
        "As said before, Bi represents knowledge that might be revised whereas Ki represents observed facts, taken as being true, and which can possibly contradict Bi.",
        "Definition 1. a-consistency of an agent An agent ri is a-consistent iff Cons(Bi, Ki) is true.",
        "Example 1.",
        "Agent r1 has a set of plans which are in the common part BC of B1.",
        "Each plan P has a triggering context d(P) (which acts as a pre-condition) and a body.",
        "Some piece of information k could be plan P, triggered in situation s, has failed in spite of s being an instance of d(P).",
        "If this piece of information is added to K1, then agent r1 is not a-consistent anymore: Cons(B1, K1 ∪ k) is false.",
        "We also want to define some notion of consistency for the whole MAS depending on the belief and information sets of its constituting elements.",
        "We will first define the consistency of an agent ri with respect to its belief set Bi and its own information set Ki together with all information sets K1...Kn from the other agents of the MAS.",
        "We will simply do that by considering what would be the a-consistency of the agent if he has the information of all the other agents.",
        "We call this notion the mas-consistency: Definition 2. mas-consistency of an agent An agent ri is mas-consistent iff Cons(Bi, Ki ∪ K) is true, where K = ∪j∈{1,..,n}−{i}Kj 1 is the set of all information from other agents of the MAS. 1 We will note this ∪ Kj when the context is similar.",
        "Example 2.",
        "Using the previous example, suppose that the piece of information k is included in the information K2 of agent r2.",
        "As long as the piece of information is not transmitted to r1, and so added to K1 , r1 remains a-consistent.",
        "However, r1 is not mas-consistent as k is in the set K of all information of the MAS.",
        "The global consistency of the MAS is then simply the mas-consistency of all its agents.",
        "Definition 3.",
        "Consistency of a MAS A MAS r1,...,rn is consistent iff all its agents ri are masconsistent.",
        "We now define the required properties for a revision mechanism M updating an agent ri when it gets a piece of information k. In the following, we will suppose that: • Update is always possible, that is, an agent can always modify its belief set Bi in order to regain its a-consistency.",
        "We will say that each agent is locally efficient. • Considering two sets of information Cons(Bi, K1) and Cons(Bi, K2), we also have Cons(Bi, K1 ∪ K2).",
        "That is, a-consistency of the agents is additive. • If a piece of information k concerning the common set BC is consistent with an agent, it is consistent with all agents: for all pair of agents (ri,rj) such that Cons(Bi, Ki) and Cons(Bj, Kj) are true, we have, for all piece of information k: Cons(Bi, Ki ∪ k) iff Cons(Bj, Kj ∪ k).",
        "In such a case, we will say that the MAS is coherent.",
        "This last condition simply means that the common belief set BC is independent of the possible differences between the belief sets Bi of each agent ri.",
        "In the simplest case, B1 = ... = Bn = BC .",
        "M will also be viewed as an incremental learning mechanism and represented as an application changing Bi in Bi.",
        "In the following, we shall note ri(Bi, Ki) for ri when it is useful.",
        "Definition 4. a-consistency of a revision An update mechanism M is a-consistent iff for any agent ri and any piece of information k reaching ri, the a-consistency of this agent is preserved.",
        "In other words, iff: ri(Bi, Ki) a-consistent ⇒ ri(Bi, Ki) a-consistent, where Bi = M(Bi) and Ki = Ki ∪ k is the set of all information from other agents of the MAS.",
        "In the same way, we define the mas-consistency of a revision mechanism as the a-consistency of this mechanism should the agents dispose of all information in the MAS.",
        "In the following, we shall note, if needed, ri(Bi, Ki, K) for the agent ri in MAS r1 . . . rn.",
        "Definition 5. mas-consistency of a revision An update mechanism Ms is mas-consistent iff for all agent ri and all pieces of information k reaching ri, the masconsistency of this agent is preserved.",
        "In other words, if: ri(Bi, Ki, K) mas-consistent ⇒ ri(Bi, Ki, K) mas-consistent, where Bi = Ms(Bi), Ki = Ki ∪ k, and K = ∪Kj is the set of all information from the MAS.",
        "The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 165 At last, when a mas-consistent mechanism is applied by an agent getting a new piece of information, a desirable sideeffect of the mechanism should be that all others agents remains mas-consistent after any modification of the common part BC , that is, the MAS itself should become consistent again.",
        "This property is defined as follows: Definition 6.",
        "Strong mas-consistency of a revision An update mechanism Ms is strongly mas-consistent iff - Ms is mas-consistent, and - the application of Ms by an agent preserves the consistency of the MAS. 2.2 A strongly mas-consistent update mechanism The general idea is that, since information is distributed among all the agents of the MAS, there must be some interaction between the learner agent and the other agents in a strongly mas-consistent update mechanism Ms.",
        "In order to ensure its mas-consistency, Ms will be constituted of reiterated applications by the learner agent ri of an internal a-consistent mechanism M, followed by some interactions between ri and the other agents, until ri regain its masconsistency.",
        "We describe below such a mechanism, first with a description of an interaction, then an iteration, and finally a statement of the termination condition of the mechanism.",
        "The mechanism is triggered by an agent ri upon receipt of a piece of information k disrupting the mas-consistency.",
        "We shall note M(Bi) the belief set of the learner agent ri after an update, BC the common part modified by ri, and Bj the belief set of another agent rj induced by the modification of its common part BC in BC .",
        "An interaction I(ri, rj) between the learner agent ri and another agent rj, acting as critic is constituted of the following steps: • agent ri sends the update BC of the common part of its beliefs.",
        "Having applied its update mechanism, ri is a-consistent. • agent rj checks the modification Bj of its beliefs induced by the update BC .",
        "If this modification preserve its a-consistency, rj adopts this modification. • agent rj sends either an acceptation of BC or a denial along with one (or more) piece(s) of information k such that Cons(Bj, k ) is false.",
        "An iteration of Ms will then be composed of: • the reception by the learner agent ri of a piece of information and the update M(Bi) restoring its aconsistency • a set of interactions I(ri, rj) (in which several critic agents can possibly participate).",
        "If at least one piece of information k is transmitted to ri, the addition of k will necessarily make ri a-inconsistent and a new iteration will then occur.",
        "This mechanism Ms ends when no agent can provide such a piece of information k .",
        "When it is the case, the masconsistency of the learner agent ri is restored.",
        "Proposition 1.",
        "Let r1,...,rn be a consistent MAS in which agent ri receives a piece of information k breaking its aconsistency, and M an a-consistent internal update mechanism.",
        "The update mechanism Ms described above is strongly mas-consistent.",
        "Proof.",
        "The proof directly derives from the mechanism description.",
        "This mechanism ensures that each time an agent receives an event, its mas-consistency will be restored.",
        "As the other agents all adopt the final update BC , they are all mas-consistent, and the MAS is consistent.",
        "Therefore Ms is a strongly consistent update mechanism.",
        "In the mechanism Ms described above, the learner agent is the only one that receives and memorizes information during the mechanism execution.",
        "It ensures that Ms terminates.",
        "The pieces of information transmitted by other agents and memorized by the learner agent are redundant as they are already present in the MAS, more precisely in the memory of the critic agents that transmitted them.",
        "Note that the mechanism Ms proposed here does not explicitly indicate the order nor the scope of the interactions.",
        "We will consider in the following that the modification proposal BC is sent sequentially to the different agents (synchronous mechanism).",
        "Moreover, the response of a critic agent will only contain one piece of information inconsistent with the proposed modification.",
        "We will say that the response of the agent is minimal.",
        "This mechanism Ms, being synchronous with minimal response, minimizes the amount of information transmitted by the agents.",
        "We will now illustrate it in the case of multi-agent concept learning. 3.",
        "SOUNDMULTI-AGENTINCREMENTAL LEARNING 3.1 The learning task We experiment the mechanism proposed above in the case of incremental MAS concept learning.",
        "We consider here a hypothesis language in which a hypothesis is a disjunction of terms.",
        "Each term is a conjunction of atoms from a set A.",
        "An example is represented by a tag + or − and a description 2 composed of a subset of atoms e ⊆ A.",
        "A term covers an example if its constituting atoms are included in the example.",
        "A hypothesis covers an example if one of its term covers it.",
        "This representation will be used below for learning boolean formulae.",
        "Negative literals are here represented by additional atoms, like not − a.",
        "The boolean formulae f =(a ∧ b) ∨ (b ∧ ¬c) will then be written (a ∧ b) ∨ (b ∧ not − c).",
        "A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 Incremental learning process The learning process is an update mechanism that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis.",
        "Before this update, the given hypothesis is complete, meaning that it covers all positive examples of E+ , and 2 When no confusion is possible, the word example will be used to refer to the pair (tag, description) as well as the description alone. 166 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) coherent, meaning that it does not cover any negative example of E− .",
        "After the update, the new hypothesis must be complete and coherent with the new memory state E ∪ {e}.",
        "We describe below our single agent update mechanism, inspired from a previous work on incremental learning[7].",
        "In the following, a hypothesis H for the target formula f is a list of terms h, each of them being a conjunction of atoms.",
        "H is coherent if all terms h are coherent, and H is complete if each element of E+ is covered by at least one term h of H. Each term is by construction the lgg (least general generalization) of a subset of positives instances {e1, ..., en}[5], that is the most specific term covering {e1, ..., en}.",
        "The lgg operator is defined by considering examples as terms, so we denote as lgg(e) the most specific term that covers e, and as lgg(h, e) the most specific term which is more general than h and that covers e. Restricting the term to lgg is the basis of a lot of Bottom-Up learning algorithms (for instance [5]).",
        "In the typology proposed by [9], our update mechanism is an incremental learner with full instance memory: learning is made by successive updates and all examples are stored.",
        "The update mechanism depends of the ongoing hypothesis H, the ongoing examples E+ and E− , and the new example e. There are three possible cases: • e is positive and H covers e, or e is negative and H does not cover e. No update is needed, H is already complete and coherent with E ∪ {e}. • e is positive and H does not cover e: e is denoted as a positive counterexample of H. Then we seek to generalize in turn the terms h of H. As soon as a correct generalization h = lgg(h, e) is found, h replaces h in H. If there is a term that is less general that h , it is discarded.",
        "If no generalization is correct (meaning here coherent), H ∪ lgg(e) replaces H. • e is negative and H covers e: e is denoted as a negative counterexample of H. Each term h covering e is then discarded from H and replaced by a set of terms {h1, ...., hn} that is, as a whole, coherent with E− ∪ {e} and that covers the examples of E+ uncovered by H − {h}.",
        "Terms of the final hypothesis H that are less general than others are discarded from H. We will now describe the case where e = e− is a covered negative example.",
        "The following functions are used here: • coveredOnlyBy(h, E+) gives the subset of E+ covered by h and no other term of H. • bestCover(h1, h2) gives h1 if h1 covers more examples from uncoveredPos than h2, otherwise it gives h2. • covered(h) gives the elements of uncoveredPos covered by h. // Specialization of each h covering e− for each h of H covering e− do H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= atoms that are neither in e− nor in h while (uncoveredPos = ∅) do // seeking the best specialization of h hc=h best=⊥ // ⊥ covers no example for each a of Ar do hc= h ∧ a best = bestCover(hc, best) endfor Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) endwhile endfor Terms of H that are less general than others are discarded.",
        "Note that this mechanism tends to both make a minimal update of the current hypothesis and minimize the number of terms in the hypothesis, in particular by discarding terms less general than other ones after updating a hypothesis. 3.3 Collective learning If H is the current hypothesis, Ei the current example memory of agent ri and E the set of all the examples received by the system, the notation of section 2 becomes Bi = BC = H, Ki = Ei and K = E. Cons(H, Ei) states that H is complete and coherent with Ei.",
        "In such a case, ri is a-consistent.",
        "The piece of information k received by agent ri is here simply an example e along with its tag.",
        "If e is such that the current hypothesis H is not complete or coherent with Ei ∪ {e}, e contradicts H: ri becomes a-inconsistent, and therefore the MAS is not consistent anymore.",
        "The update of a hypothesis when a new example arrives is an a- consistent mechanism.",
        "Following proposition 1 this mechanism can be used to produce a strong mas-consistent mechanism: upon reception of a new example in the MAS by an agent r, an update is possibly needed and, after a set of interactions between r and the other agents, results in a new hypothesis shared by all the agents and that restores the consistency of the MAS, that is which is complete and coherent with the set ES of all the examples present in the MAS.",
        "It is clear that by minimizing the number of hypothesis modifications, this synchronous and minimal mechanism minimize the number of examples received by the learner from other agents, and therefore, the total number of examples stored in the system. 4.",
        "EXPERIMENTS In the following, we will learn a boolean formula that is a difficult test for the learning method: the 11-multiplexer (see [4]).",
        "It concerns 3 address boolean attributes a0, a1, a2 and 8 data boolean attributes d0, ..., d7.",
        "Formulae f11 is satisfied if the number coded by the 3 address attributes is the number of a data attribute whose value is 1.",
        "Its formula is the following: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0).",
        "There are 2048 = 211 possible examples, half of whom are positive (meaning they satisfy f11) while the other half is negative.",
        "An experiment is typically composed of 50 trials.",
        "Each run corresponds to a sequence of 600 examples that are incrementally learned by a Multi Agent System with n agents The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 167 (n-MAS).",
        "A number of variables such as accuracy, (i.e. the frequency of correct classification of a set of unseen examples), hypothesis size (i.e. the number of terms in the current formula) or number of stored examples, is recorded each time 25 examples are received by the system during those runs.",
        "In the protocol that is used here, a new example is sent to a random agent when the MAS is consistent.",
        "The next example will be sent in turn to an other agent when the MAS consistency will have been restored.",
        "In such a way we simulate a kind of slow learning: the frequency of example arrivals is slow compared to the time taken by an update. 4.1 Efficiency of MAS concept learning 4.1.1 Execution time We briefly discuss here execution time of learning in the MAS.",
        "Note that the whole set of action and interaction in the MAS is simulated on a single processor.",
        "Figure 1 shows that time linearly depends on the number of agents.",
        "At the end of the most active part of learning (200 examples), a 16MAS has taken 4 times more learning time than a 4-MAS.",
        "This execution time represents the whole set of learning and Figure 1: Execution time of a n-MAS (from n = 2 at the bottom to n = 20 on the top). communication activity and hints at the cost of maintaining a consistent learning hypothesis in a MAS composed of autonomous agents. 4.1.2 Redundancy in the MAS memory We study now the distribution of the examples in the MAS memory.",
        "Redundancy is written RS = nS/ne, where nS is the total number of examples stored in the MAS, that is the sum of the sizes of agents examples memories Ei, and ne is the total number of examples received from the environment in the MAS.",
        "In figure 2, we compare redundancies in 2 to 20 agents MAS.",
        "There is a peak, slowly moving from 80 to 100 examples, that represents the number of examples for which the learning is most active.",
        "For 20 agents, maximal redundancy is no more than 6, which is far less than the maximal theoretical value of 20.",
        "Note that when learning becomes less active, redundancy tends towards its minimal value 1: when there is no more updates, examples are only Figure 2: Redundancy of examples stored in a nMAS (from n = 2 at the bottom to n = 20 on the top) . stored by the agent that receives them. 4.1.3 A n-MAS selects a simpler solution than a single agent The proposed mechanism tends to minimize the number of terms in the selected hypothesis.",
        "During learning, the size of the current hypothesis grows up beyond the optimum, and then decreases when the MAS converges.",
        "In the Multiplexer 11 testbed, the optimal number of terms is 8, but there also exist equivalent formulas with more terms.",
        "It is interesting to note that in this case the 10-MAS converges towards an exact solution closer to the optimal number of terms (here 8) (see Figure 3).",
        "After 1450 examples have been presented both 1-MAS and 10-MAS have exactly learned the concept (the respective accuracies are 0.9999 and 1) but the single agent expresses in average the result as a 11.0 terms DNF whereas the 10-MAS expresses it as a 8.8 terms DNF.",
        "However for some other boolean functions we found that during learning 1-MAS always produces larger hypotheses than 10-MAS but that both MAS converge to hypotheses with similar size results. 4.1.4 A n-MAS is more accurate than a single agent Figure 4 shows the improvement brought by a MAS with n agents compared to a single agent.",
        "This improvement was not especially expected, because whether we have one or n agents, when N examples are given to the MAS it has access to the same amount of information, maintains only on ongoing hypothesis and uses the same basic revision algorithm whenever an agent has to modify the current hypothesis.",
        "Note that if the accuracy of 1, 2, 4 and 10-MAS are significantly different, getting better as the number of agents increases, there is no clear difference beyond this point: the accuracy curve of the 100 agents MAS is very close to the one of the 10 agents MAS. 4.1.4.1 Boolean formulas.",
        "To evaluate this accuracy improvement, we have experimented our protocol on other problems of boolean function learning, As in the Multiplexer-11 case, these functions 168 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 3: Size of the hypothesis built by 1 and 10MAS: the M11 case.",
        "Figure 4: Accuracy of a n-MAS: the M11 case (from bottom to top, n = 1, 2, 4, 10, 100). are learnt in the form of more or less syntactically complex DNF3 (that is with more or less conjunctive terms in the DNF), but are also more or less difficult to learn as it can be difficult to get its way in the hypothesis space to reach them.",
        "Furthermore, the presence in the description of irrelevant attributes (that is attributes that does not belong to the target DNF) makes the problem more difficult.",
        "The following problems have been selected to experiment our protocol: (i) the multiplexer-11 with 9 irrelevant attributes: M11 9, (ii) the 20-multiplexer M20 (with 4 address bits and 16 data bits), (iii) a difficult parity problem (see [4]) the Xorp m: there must be an odd number of bits with value 1 in the p first attributes for the instance to be positive, the p others bits being irrelevant, and (iv) a simple DNF formula (a ∧ b ∧ c) ∨ (c ∧ d ∧ e)(e ∧ f ∧ g) ∧ (g ∧ h ∧ i) with 19 irrelevant attributes.",
        "The following table sums up some information about these problems, giving the total number of attributes including irrelevant ones, the number of irrelevant 3 Disjunctive Normal Forms attributes, the minimal number of terms of the corresponding DNF, and the number of learning examples used.",
        "Pb att. irre. att. terms ex.",
        "M11 11 0 8 200 M11 9 20 9 8 200 M20 20 0 16 450 Xor3 25 28 25 4 200 Xor5 5 10 5 16 180 Xor5 15 20 15 16 600 Simple4-9 19 28 19 4 200 Below are given the accuracy results of our learning mechanism with a single agent and a 10 agents MAS, along with the results of two standard algorithms implemented with the learning environment WEKA[16]: JRip (an implementation of RIPPER[2]) and Id3[12].",
        "For the experiments with JRip and Id3, we measured the mean accuracy on 50 trials, each time randomly separating examples in a learning set and a test set.",
        "JRip and Id3 parameters are default parameters, except that JRip is used without pruning.",
        "The following table shows the results: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 It is clear that difficult problems are better solved with more agents (see for instance xor5 15).",
        "We think that these benefits, which can be important with an increasing number of agents, are due to the fact that each agent really memorizes only part of the total number of examples, and this part is partly selected by other agents as counter examples, which cause a greater number of current hypothesis updates and therefore, a better exploration of the hypotheses space. 4.1.4.2 ML database problems.",
        "We did also experiments with some non boolean problems.",
        "We considered only two classes (positive/negative) problems, taken from the UCIs learning problems database[3].",
        "In all these problems, examples are described as a vector of couples (attribute, value).",
        "The value domains can be either boolean, numeric (wholly ordered set), or nominal (non-ordered set).",
        "An adequate set of atoms A must be constituted for each problem.",
        "For instance, if a is a numeric attribute, we define at most k threshold si, giving k+1 intervals of uniform density4 .",
        "Therefore, each distinct threshold si gives two atoms a ≤ si and a > si.",
        "In our experiments, we took a maximal number of threshold k = 8.",
        "For instance, in the iono problem case, there were 34 numeric attributes, and an instance is described with 506 atoms.",
        "Below are given the accuracy results of our system along with previous results.",
        "The column Nb ex. refer to the 4 The probability for the value of a to be in any interval is constant The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 169 number of examples used for learning5 .",
        "Column (1) represents minimal and maximal accuracy values for the thirty three classifiers tested in [8].",
        "Column (2) represents the results of [13], where various learning methods are compared to ensemble learning methods using weighted classifiers sets.",
        "Column S-1 and S-10 gives the accuracy of SMILE with respectively 1 and 10 agents.",
        "Pb Nb ex. (1) (2) S-1 S-10 ttt 862/574 // 76.2-99.7 99.7 99.9 kr-vs-kp 2876/958 // 91.4-99.4 96.8 97.3 iono 315 // 88.0-91.8 87.2 88.1 bupa 310 57-72 58-69.3 62.5 63.3 breastw 614 91-97 94.3-97.3 94.7 94.7 vote 391 94-96 95.3-96 91.9 92.6 pima 691 // 71.5- 73.4 65.0 65.0 heart 243 66-86 77.1-84.1 69.5 70.7 This table shows that the incremental algorithm corresponding to the single agent case, gives honorable results relatively to non-incremental classical methods using larger and more complex hypotheses.",
        "In some cases, there is an accuracy improvement with a 10 agents MAS.",
        "However, with such benchmarks data, which are often noisy, the difficulty does not really come from the way in which the search space is explored, and therefore the improvement observed is not always significant.",
        "The same kind of phenomenon have been observed with methods dedicated to hard boolean problems [4]. 4.2 MAS synchronization Here we consider that n single agents learn without interactions and at a given time start interacting thus forming a MAS.",
        "The purpose is to observe how the agents take advantage of collaboration when they start from different states of beliefs and memories.",
        "We compare in this section a 1-MAS, a 10-MAS (ref) and a 10-MAS (100sync) whose agents did not communicate during the arrival of the first 100 examples (10 by agents).",
        "The three accuracy curves are shown in figure 5.",
        "By comparing the single agent curve and the synchronized 10-MAS, we can observe that after the beginning of the synchronization, that is at 125 examples, accuracies are identical.",
        "This was expected since as soon as an example e received by the MAS contradicts the current hypothesis of the agent ra receiving it, this agent makes an update and its new hypothesis is proposed to the others agents for criticism.",
        "Therefore, this first contradictory example brings the MAS to reach consistency relatively to the whole set of examples present in agents memories.",
        "A higher accuracy, corresponding to a 10-MAS is obtained later, from the 175th example.",
        "In other words, the benefit of a better exploration of the research space is obtained slightly later in the learning process.",
        "Note that this synchronization happens naturally in all situations where agents have, for some reason, a divergence between their hypothesis and the system memory.",
        "This includes the fusion of two MAS into a single one or the arrival of new agents in an existing MAS. 4.3 Experiments on asynchronous learning: the effect of a large data stream 5 For ttt and kr-vs-kp, our protocol did not use more than respectively 574 and 958 learning examples, so we put another number in the column.",
        "Figure 5: Accuracies of a 1-MAS, a 10-MAS, and a 10-MAS synchronized after 100 examples.",
        "In this experiment we relax our slow learning mode: the examples are sent at a given rate to the MAS.",
        "The resulting example stream is measured in ms−1 , and represents the number of examples sent to the MAS each ms.",
        "Whenever the stream is too large, the MAS cannot reach MAS consistency on reception of an example from the environment before a new example arrives.",
        "This means that the update process, started by agent r0 as he received an example, may be unfinished when a new example is received by r0 or another agent r1.",
        "As a result, a critic agent may have at instant t to send counterexamples of hypotheses sent by various agents.",
        "However as far as the agents, in our setting, memorizes all the examples they receive whenever the stream ends, the MAS necessarily reaches MAS consistency with respect to all the examples received so far.",
        "In our experiments, though its learning curve is slowed down during the intense learning phase (corresponding to low accuracy of the current hypotheses), the MAS still reaches a satisfying hypothesis later on as there are less and less counterexamples in the example stream.",
        "In Figure 6 we compare the accuracies of two 11-MAS respectively submitted to example streams of different rates when learning the M11 formula.",
        "The learning curve of the MAS receiving an example at a 1/33 ms−1 rate is almost not altered (see Figure 4) whereas the 1/16 ms−1 MAS is first severely slowed down before catching up with the first one. 5.",
        "RELATED WORKS Since 96 [15], various work have been performed on learning in MAS, but rather few on concept learning.",
        "In [11] the MAS performs a form of ensemble learning in which the agents are lazy learners (no explicit representation is maintained) and sell useless examples to other agents.",
        "In [10] each agent observes all the examples but only perceive a part of their representation.",
        "In mutual online concept learning [14] the agents converge to a unique hypothesis, but each agent produces examples from its own concept representation, thus resulting in a kind of synchronization rather than in pure concept learning. 170 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 6: Accuracies of two asynchronous 11-MAS (1/33ms−1 and 1/16ms−1 example rates) . 6.",
        "CONCLUSION We have presented here and experimented a protocol for MAS online concept learning.",
        "The main feature of this collaborative learning mechanism is that it maintains a consistency property: though during the learning process each agent only receives and stores, with some limited redundancy, part of the examples received by the MAS, at any moment the current hypothesis is consistent with the whole set of examples.",
        "The hypotheses of our experiments do not address the issues of distributed MAS such as faults (for instance messages could be lost or corrupted) or other failures in general (crash, byzantine faults, etc.).",
        "Nevertheless, our framework is open, i.e., the agents can leave the system or enter it while the consistency mechanism is preserved.",
        "For instance if we introduce a timeout mechanism, even when a critic agent crashes or omits to answer, the consistency with the other critics (within the remaining agents) is entailed.",
        "In [1], a similar approach has been applied to MAS abduction problems: the hypotheses to maintain, given an incomplete information, are then facts or statements.",
        "Further work concerns first coupling induction and abduction in order to perform collaborative concept learning when examples are only partially observed by each agent, and second, investigating partial memory learning: how learning is preserved whenever one agent or the whole MAS forgets some selected examples.",
        "Aknowledgments We are very grateful to Dominique Bouthinon for implementing late modifications in SMILE, so much easing our experiments.",
        "Part of this work has been performed during the first authors visit to the Atelier De BioInformatique of Paris VI university, France. 7.",
        "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
        "When agents communicate hypotheses in critical situations.",
        "In DALT-2006, May 2006. [2] W. W. Cohen.",
        "Fast effective rule induction.",
        "In ICML, pages 115-123, 1995. [3] C. B. D.J.",
        "Newman, S. Hettich and C. Merz.",
        "UCI repository of machine learning databases, 1998. [4] S. Esmeir and S. Markovitch.",
        "Lookahead-based algorithms for anytime induction of decision trees.",
        "In ICMLO4, pages 257-264.",
        "Morgan Kaufmann, 2004. [5] J. F¨urnkranz.",
        "A pathology of bottom-up hill-climbing in inductive rule learning.",
        "In ALT, volume 2533 of LNCS, pages 263-277.",
        "Springer, 2002. [6] A. Guerra-Hern´andez, A. ElFallah-Seghrouchni, and H. Soldano.",
        "Learning in BDI multi-agent systems.",
        "In CLIMA IV, volume 3259, pages 218-233.",
        "Springer Verlag, 2004. [7] M. Henniche.",
        "Mgi: an incremental bottom-up algorithm.",
        "In IEEE Aust. and New Zealand Conference on Intelligent Information Systems, pages 347-351, 1994. [8] T.-S. Lim, W.-Y.",
        "Loh, and Y.-S. Shih.",
        "A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms.",
        "Machine Learning, 40(3):203-228, 2000. [9] M. A. Maloof and R. S. Michalski.",
        "Incremental learning with partial instance memory.",
        "Artif.",
        "Intell., 154(1-2):95-126, 2004. [10] P. J. Modi and W.-M. Shen.",
        "Collaborative multiagent learning for classification tasks.",
        "In AGENTS 01, pages 37-38.",
        "ACM Press, 2001. [11] S. Onta˜non and E. Plaza.",
        "Recycling data for multi-agent learning.",
        "In ICML 05, pages 633-640.",
        "ACM Press, 2005. [12] J. R. Quinlan.",
        "Induction of decision trees.",
        "Machine Learning, 1(1):81-106, 1986. [13] U. R¨uckert and S. Kramer.",
        "Towards tight bounds for rule learning.",
        "In ICML 04 (International conference on Machine learning), page 90, New York, NY, USA, 2004.",
        "ACM Press. [14] J. Wang and L. Gasser.",
        "Mutual online concept learning for multiple agents.",
        "In AAMAS, pages 362-369.",
        "ACM Press, 2002. [15] G. Weiß and S. Sen, editors.",
        "Adaption and Learning in Multi-Agent Systems, volume 1042 of Lecture Notes in Computer Science.",
        "Springer, 1996. [16] I. H. Witten and E. Frank.",
        "Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.",
        "Morgan Kaufmann, October 1999.",
        "The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 171"
    ],
    "translated_text_sentences": [
        "SMILE: Aprendizaje Incremental Multiagente de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av.",
        "del presidente Kennedy, 75116 París Henry Soldano LIPN, UMR 7030 CNRS, Universidad Paris-Norte, 99 Av.",
        "J-B Clement, 93430, Villetaneuse RESUMEN Este artículo trata sobre el problema del aprendizaje colaborativo en un sistema multiagente.",
        "Aquí cada agente puede actualizar de forma incremental sus creencias B (la representación del concepto) para que se mantenga consistente con el conjunto completo de información K (los ejemplos) que ha recibido del entorno u otros agentes.",
        "Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo lograr que, en cualquier momento, una misma representación conceptual consistente esté presente en cada agente.",
        "El protocolo correspondiente se aplica al aprendizaje supervisado de conceptos.",
        "El método resultante SMILE (que significa Sound Multiagent Incremental LEarning) se describe y experimenta aquí.",
        "Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de múltiples agentes que por un solo agente.",
        "Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de conceptos; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistema multiagente Términos Generales Experimentación, Algoritmos, Medición, Rendimiento 1.",
        "INTRODUCCIÓN Este artículo trata sobre el problema del aprendizaje colaborativo de conceptos en un sistema multiagente. [6] introduce una caracterización del aprendizaje en un sistema multiagente según el nivel de conciencia de los agentes.",
        "En el nivel 1, los agentes aprenden ∗El autor principal de este artículo es un estudiante. en el sistema sin tener en cuenta la presencia de otros agentes, excepto a través de la modificación que traen al entorno con sus acciones.",
        "El nivel 2 implica una interacción directa entre los agentes, ya que pueden intercambiar mensajes para mejorar su aprendizaje.",
        "El nivel 3 requeriría que los agentes tengan en cuenta las competencias de otros agentes y sean capaces de aprender observando el comportamiento de los otros agentes (considerándolos como entidades independientes y no como parte indeterminada del entorno como en el nivel 1).",
        "En este artículo nos enfocamos en el nivel 2, estudiando la interacción directa entre los agentes involucrados en un proceso de aprendizaje.",
        "Cada agente se asume capaz de aprender de forma incremental a partir de los datos que recibe, lo que significa que cada agente puede actualizar su conjunto de creencias B para mantenerlo consistente con el conjunto completo de información K que ha recibido del entorno o de otros agentes.",
        "En tal caso, diremos que es a-inconsistente.",
        "Aquí, el conjunto de creencias B representa conocimiento hipotético que por lo tanto puede ser revisado, mientras que el conjunto de información K representa conocimiento cierto, compuesto por observaciones y hechos no revisables.",
        "Además, suponemos que al menos una parte Bc de las creencias de cada agente es común a todos los agentes y debe mantenerse de esa manera.",
        "Por lo tanto, una actualización de este conjunto común Bc por parte del agente r debe provocar una actualización de Bc para toda la comunidad de agentes.",
        "Nos lleva a definir cuál es la mas-consistencia de un agente con respecto a la comunidad.",
        "El proceso de actualización de las creencias de la comunidad cuando uno de sus miembros recibe nueva información puede entonces definirse como el proceso de mantenimiento de la consistencia que garantiza que cada agente en la comunidad permanecerá más consistente.",
        "Este proceso de mantenimiento de la mas-consistencia de un agente al recibir nueva información le otorga el rol de aprendiz e implica la comunicación con otros agentes que actúan como críticos.",
        "Sin embargo, los agentes no están especializados y a su vez pueden ser aprendices o críticos, ninguno de ellos está limitado a un rol específico.",
        "Las piezas de información se distribuyen entre los agentes, pero pueden ser redundantes.",
        "No hay memoria central.",
        "El trabajo descrito aquí tiene su origen en un trabajo anterior sobre el aprendizaje en un sistema multiagente intencional utilizando un formalismo BDI [6].",
        "En ese trabajo, los agentes tenían planes, cada uno de ellos asociado con un contexto que define en qué condiciones puede ser activado.",
        "Los planes (cada uno con su propio contexto) eran comunes a todo el conjunto de agentes en la comunidad.",
        "Los agentes tuvieron que adaptar su plan en función del contexto, dependiendo del fracaso o éxito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo a otros agentes ejemplos (éxitos o fracasos de planes).",
        "Sin embargo, este trabajo carecía de un protocolo de aprendizaje colectivo que permitiera una verdadera autonomía del sistema multiagente.",
        "El estudio de dicho protocolo es el objeto del presente artículo.",
        "En la sección 2 definimos formalmente la mas-consistencia de un mecanismo de actualización para todo el MAS y proponemos un mecanismo de actualización genérico demostrado que es mas consistente.",
        "En la sección 3 describimos SMILE, un aprendiz de conceptos multiagente incremental que aplica nuestro mecanismo de actualización mas consistente para el aprendizaje colaborativo de conceptos.",
        "La sección 4 describe varios experimentos sobre SMILE y discute varios problemas, incluyendo cómo varían la precisión y la simplicidad de la hipótesis actual al comparar el aprendizaje de un solo agente y el aprendizaje de múltiples agentes.",
        "En la sección 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la sección 6 discutiendo investigaciones adicionales sobre el aprendizaje más consistente.",
        "MODELO FORMAL 2.1 Definiciones y marco En esta sección, presentamos una formulación general del aprendizaje incremental colectivo en un sistema cognitivo de múltiples agentes.",
        "Representamos un MAS como un conjunto de agentes r1, ..., rn.",
        "Cada agente ri tiene un conjunto de creencias Bi que consiste en todo el conocimiento revisable que posee.",
        "Parte de estos conocimientos deben ser compartidos con otros agentes.",
        "La parte de Bi que es común a todos los agentes se denota como BC.",
        "Esta parte común provoca una dependencia entre los agentes.",
        "Si un agente ri actualiza su conjunto de creencias Bi a Bi, cambiando en el proceso BC en BC, entonces todos los demás agentes rk deben actualizar su conjunto de creencias Bk a Bk para que BC ⊆ Bk.",
        "Además, cada agente ri ha almacenado cierta información Ki.",
        "Suponemos que alguna propiedad de consistencia Cons(Bi, Ki) puede ser verificada por el agente mismo entre sus creencias Bi y su información Ki.",
        "Como se dijo antes, Bi representa el conocimiento que podría ser revisado, mientras que Ki representa hechos observados, considerados verdaderos, y que posiblemente puedan contradecir a Bi.",
        "Definición 1. a-consistencia de un agente Un agente ri es a-consistente si Cons(Bi, Ki) es verdadero.",
        "Ejemplo 1.",
        "El agente r1 tiene un conjunto de planes que se encuentran en la parte común BC de B1.",
        "Cada plan P tiene un contexto desencadenante d(P) (que actúa como una precondición) y un cuerpo.",
        "Alguna pieza de información k podría ser el plan P, desencadenado en la situación s, ha fallado a pesar de que s es una instancia de d(P).",
        "Si esta pieza de información se agrega a K1, entonces el agente r1 ya no es a-consistente: Cons(B1, K1 ∪ k) es falso.",
        "También queremos definir alguna noción de consistencia para todo el MAS dependiendo de los conjuntos de creencias e información de sus elementos constituyentes.",
        "Primero definiremos la consistencia de un agente ri con respecto a su conjunto de creencias Bi y su propio conjunto de información Ki junto con todos los conjuntos de información K1...Kn de los otros agentes del MAS.",
        "Simplemente lo haremos considerando cuál sería la a-consistencia del agente si tuviera la información de todos los demás agentes.",
        "Llamamos a esta noción la mas-consistencia: Definición 2. Un agente ri es mas-consistente si Cons(Bi, Ki ∪ K) es verdadero, donde K = ∪j∈{1,..,n}−{i}Kj 1 es el conjunto de toda la información de los otros agentes del MAS. 1 Lo notaremos como ∪ Kj cuando el contexto sea similar.",
        "Ejemplo 2.",
        "Usando el ejemplo anterior, supongamos que la pieza de información k está incluida en la información K2 del agente r2.",
        "Si la pieza de información no se transmite a r1, y por lo tanto no se agrega a K1, r1 permanece a-consistente.",
        "Sin embargo, r1 no es tan consistente como k en el conjunto K de toda la información del MAS.",
        "La consistencia global del MAS es simplemente la mas-consistencia de todos sus agentes.",
        "Definición 3.",
        "La consistencia de un MAS A MAS r1,...,rn es consistente si todos sus agentes ri son masconsistentes.",
        "Ahora definimos las propiedades requeridas para un mecanismo de revisión M que actualiza a un agente ri cuando recibe una pieza de información k. En lo siguiente, supondremos que: • La actualización siempre es posible, es decir, un agente siempre puede modificar su conjunto de creencias Bi para recuperar su a-consistencia.",
        "Diremos que cada agente es localmente eficiente. • Considerando dos conjuntos de información Cons(Bi, K1) y Cons(Bi, K2), también tenemos Cons(Bi, K1 ∪ K2).",
        "Es decir, la a-consistencia de los agentes es aditiva. • Si una pieza de información k relacionada con el conjunto común BC es consistente con un agente, es consistente con todos los agentes: para todos los pares de agentes (ri, rj) tales que Cons(Bi, Ki) y Cons(Bj, Kj) son verdaderos, tenemos, para toda pieza de información k: Cons(Bi, Ki ∪ k) si y solo si Cons(Bj, Kj ∪ k).",
        "En tal caso, diremos que el MAS es coherente.",
        "Esta última condición simplemente significa que el conjunto de creencias común BC es independiente de las posibles diferencias entre los conjuntos de creencias Bi de cada agente ri.",
        "En el caso más simple, B1 = ... = Bn = BC.",
        "M también será visto como un mecanismo de aprendizaje incremental y representado como una aplicación que cambia Bi en Bi.",
        "En lo siguiente, anotaremos ri(Bi, Ki) para ri cuando sea útil.",
        "Definición 4. a-consistencia de una revisión Un mecanismo de actualización M es a-consistente si, para cualquier agente ri y cualquier pieza de información k que llegue a ri, la a-consistencia de este agente se conserva.",
        "En otras palabras, si: ri(Bi, Ki) a-consistente ⇒ ri(Bi, Ki) a-consistente, donde Bi = M(Bi) y Ki = Ki ∪ k es el conjunto de toda la información de otros agentes del MAS.",
        "De la misma manera, definimos la mas-consistencia de un mecanismo de revisión como la a-consistencia de este mecanismo si los agentes disponen de toda la información en el MAS.",
        "En lo siguiente, anotaremos, si es necesario, ri(Bi, Ki, K) para el agente ri en el MAS r1 . . . rn.",
        "Definición 5. mas-consistencia de una revisión Un mecanismo de actualización Ms es mas-consistente si para todo agente ri y toda pieza de información k que llega a ri, la mas-consistencia de este agente se conserva.",
        "En otras palabras, si: ri(Bi, Ki, K) más-consistente ⇒ ri(Bi, Ki, K) más-consistente, donde Bi = Ms(Bi), Ki = Ki ∪ k, y K = ∪Kj es el conjunto de toda la información del MAS.",
        "El Sexto Internacional.",
        "En última instancia, cuando un agente aplica un mecanismo mas-consistente al recibir una nueva pieza de información, un efecto secundario deseable del mecanismo debería ser que todos los demás agentes permanezcan mas-consistentes después de cualquier modificación de la parte común BC, es decir, el MAS en sí mismo debería volver a ser consistente.",
        "Esta propiedad se define de la siguiente manera: Definición 6.",
        "La fuerte mas-consistencia de un mecanismo de actualización. Un mecanismo de actualización Ms es fuertemente mas-consistente si - Ms es mas-consistente, y - la aplicación de Ms por un agente preserva la consistencia del MAS. 2.2 Un mecanismo de actualización fuertemente mas-consistente. La idea general es que, dado que la información está distribuida entre todos los agentes del MAS, debe haber alguna interacción entre el agente aprendiz y los demás agentes en un mecanismo de actualización fuertemente mas-consistente Ms.",
        "Para garantizar su mas-consistencia, Ms estará constituido por aplicaciones reiteradas por parte del agente aprendiz ri de un mecanismo interno a-consistente M, seguido por algunas interacciones entre ri y los otros agentes, hasta que ri recupere su mas-consistencia.",
        "Describimos a continuación un mecanismo, primero con una descripción de una interacción, luego una iteración y finalmente una declaración de la condición de terminación del mecanismo.",
        "El mecanismo es activado por un agente ri al recibir una pieza de información k que interrumpe la mas-consistencia.",
        "Tomaremos M(Bi) como el conjunto de creencias del agente aprendiz ri después de una actualización, BC la parte común modificada por ri, y Bj el conjunto de creencias de otro agente rj inducido por la modificación de su parte común BC en BC.",
        "Una interacción I(ri, rj) entre el agente aprendiz ri y otro agente rj, actuando como crítico, está constituida por los siguientes pasos: • el agente ri envía la actualización BC de la parte común de sus creencias.",
        "Habiendo aplicado su mecanismo de actualización, ri es a-consistente. • El agente rj verifica la modificación Bj de sus creencias inducida por la actualización BC.",
        "Si esta modificación conserva su a-consistencia, rj adopta esta modificación. El agente rj envía ya sea una aceptación de BC o una negación junto con una (o más) pieza(s) de información k tal que Cons(Bj, k) es falso.",
        "Una iteración de Ms estará compuesta por: • la recepción por parte del agente aprendiz ri de una pieza de información y la actualización M(Bi) restaurando su consistencia • un conjunto de interacciones I(ri, rj) (en las cuales varios agentes críticos posiblemente puedan participar).",
        "Si al menos una pieza de información k es transmitida a ri, la adición de k necesariamente hará que ri sea inconsistente y entonces ocurrirá una nueva iteración.",
        "Este mecanismo termina cuando ningún agente puede proporcionar tal pieza de información k.",
        "Cuando es el caso, se restaura la masconsistencia del agente aprendiz ri.",
        "Proposición 1.",
        "Dejen que r1,...,rn sea un MAS consistente en el que el agente ri recibe una pieza de información k que rompe su consistencia, y M sea un mecanismo interno de actualización a-consistente.",
        "El mecanismo de actualización descrito anteriormente por Ms es altamente mas-consistente.",
        "Prueba.",
        "La prueba se deriva directamente de la descripción del mecanismo.",
        "Este mecanismo asegura que cada vez que un agente recibe un evento, su mas-consistencia será restaurada.",
        "Como los otros agentes adoptan la actualización final BC, todos son mas-coherentes y el MAS es coherente.",
        "Por lo tanto, Ms es un mecanismo de actualización fuertemente consistente.",
        "En el mecanismo descrito anteriormente, el agente aprendiz es el único que recibe y memoriza información durante la ejecución del mecanismo.",
        "Se asegura de que Ms termine.",
        "Las piezas de información transmitidas por otros agentes y memorizadas por el agente aprendiz son redundantes, ya que ya están presentes en el MAS, más precisamente en la memoria de los agentes críticos que las transmitieron.",
        "Se debe tener en cuenta que el mecanismo propuesto por la Sra. aquí no indica explícitamente el orden ni el alcance de las interacciones.",
        "Consideraremos en lo siguiente que la propuesta de modificación BC se envía secuencialmente a los diferentes agentes (mecanismo síncrono).",
        "Además, la respuesta de un agente crítico solo contendrá una pieza de información inconsistente con la modificación propuesta.",
        "Diremos que la respuesta del agente es mínima.",
        "Este mecanismo, siendo sincrónico con una respuesta mínima, minimiza la cantidad de información transmitida por los agentes.",
        "Ahora lo ilustraremos en el caso del aprendizaje de conceptos multiagente. 3.",
        "APRENDIZAJE INCREMENTAL DE MÚLTIPLES AGENTES 3.1 La tarea de aprendizaje Experimentamos el mecanismo propuesto anteriormente en el caso del aprendizaje conceptual MAS incremental.",
        "Aquí consideramos un lenguaje de hipótesis en el cual una hipótesis es una disyunción de términos.",
        "Cada término es una conjunción de átomos de un conjunto A.",
        "Un ejemplo está representado por una etiqueta + o − y una descripción 2 compuesta por un subconjunto de átomos e ⊆ A.",
        "Un término abarca un ejemplo si sus átomos constituyentes están incluidos en el ejemplo.",
        "Una hipótesis abarca un ejemplo si uno de sus términos lo abarca.",
        "Esta representación se utilizará a continuación para aprender fórmulas booleanas.",
        "Los literales negativos se representan aquí mediante átomos adicionales, como not − a.",
        "La fórmula booleana f = (a ∧ b) ∨ (b ∧ ¬c) se escribirá entonces como (a ∧ b) ∨ (b ∧ no − c).",
        "Un ejemplo positivo de f, como {no − a, b, no − c}, representa un modelo para f. 3.2 Proceso de aprendizaje incremental El proceso de aprendizaje es un mecanismo de actualización que, dado una hipótesis actual H, una memoria E = E+ ∪ E− llenada con los ejemplos recibidos previamente, y un nuevo ejemplo positivo o negativo e, produce una nueva hipótesis actualizada.",
        "Antes de esta actualización, la hipótesis dada es completa, lo que significa que cubre todos los ejemplos positivos de E+, y 2 Cuando no haya posibilidad de confusión, la palabra ejemplo se utilizará para referirse al par (etiqueta, descripción) así como a la descripción sola. 166 La Sexta Conferencia Internacional.",
        "La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) es coherente, lo que significa que no cubre ningún ejemplo negativo de E−.",
        "Después de la actualización, la nueva hipótesis debe ser completa y coherente con el nuevo estado de memoria E ∪ {e}.",
        "Describimos a continuación nuestro mecanismo de actualización de agente único, inspirado en un trabajo previo sobre aprendizaje incremental[7].",
        "En lo siguiente, una hipótesis H para la fórmula objetivo f es una lista de términos h, cada uno de ellos siendo una conjunción de átomos.",
        "H es coherente si todos los términos h son coherentes, y H es completo si cada elemento de E+ está cubierto por al menos un término h de H. Cada término es, por construcción, la lgg (generalización general menos general) de un subconjunto de instancias positivas {e1, ..., en}, es decir, el término más específico que cubre {e1, ..., en}.",
        "El operador lgg se define considerando ejemplos como términos, por lo que denotamos como lgg(e) al término más específico que cubre e, y como lgg(h, e) al término más específico que es más general que h y que cubre e. Restringir el término a lgg es la base de muchos algoritmos de aprendizaje de abajo hacia arriba (por ejemplo [5]).",
        "En la tipología propuesta por [9], nuestro mecanismo de actualización es un aprendiz incremental con memoria completa de instancias: el aprendizaje se realiza mediante actualizaciones sucesivas y se almacenan todos los ejemplos.",
        "El mecanismo de actualización depende de la hipótesis en curso H, los ejemplos en curso E+ y E−, y el nuevo ejemplo e. Hay tres casos posibles: • e es positivo y H cubre e, o e es negativo y H no cubre e. No se necesita actualización, H ya es completo y coherente con E ∪ {e}. • e es positivo y H no cubre e: e se denota como un contraejemplo positivo de H. Luego buscamos generalizar a su vez los términos h de H. Tan pronto como se encuentre una generalización correcta h = lgg(h, e), h reemplaza a h en H. Si hay un término que es menos general que h, se descarta.",
        "Si ninguna generalización es correcta (es decir, coherente), H ∪ lgg(e) reemplaza a H. • e es negativo y H cubre e: e se denota como un contraejemplo negativo de H. Cada término h que cubre e es entonces descartado de H y reemplazado por un conjunto de términos {h1, ...., hn} que, en su totalidad, es coherente con E− ∪ {e} y que cubre los ejemplos de E+ no cubiertos por H − {h}.",
        "Los términos de la hipótesis final H que son menos generales que otros son descartados de H. Ahora describiremos el caso en el que e = e− es un ejemplo negativo cubierto.",
        "Las siguientes funciones se utilizan aquí: • coveredOnlyBy(h, E+) da el subconjunto de E+ cubierto por h y ningún otro término de H. • bestCover(h1, h2) da h1 si h1 cubre más ejemplos de uncoveredPos que h2, de lo contrario da h2. • covered(h) da los elementos de uncoveredPos cubiertos por h. // Especialización de cada h cubriendo e− para cada h de H cubriendo e− hacer H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= átomos que no están ni en e− ni en h mientras (uncoveredPos = ∅) hacer // buscando la mejor especialización de h hc=h best=⊥ // ⊥ no cubre ningún ejemplo para cada a de Ar hacer hc= h ∧ a best = bestCover(hc, best) finpara Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) finmientras finpara Los términos de H que son menos generales que otros son descartados.",
        "Ten en cuenta que este mecanismo tiende tanto a hacer una actualización mínima de la hipótesis actual como a minimizar el número de términos en la hipótesis, en particular descartando términos menos generales que otros después de actualizar una hipótesis. 3.3 Aprendizaje colectivo Si H es la hipótesis actual, Ei es la memoria actual de ejemplos del agente ri y E es el conjunto de todos los ejemplos recibidos por el sistema, la notación de la sección 2 se convierte en Bi = BC = H, Ki = Ei y K = E. Cons(H, Ei) establece que H es completo y coherente con Ei.",
        "En tal caso, ri es a-consistente.",
        "La pieza de información k recibida por el agente ri es aquí simplemente un ejemplo e junto con su etiqueta.",
        "Si e es tal que la hipótesis actual H no es completa ni coherente con Ei ∪ {e}, e contradice a H: ri se vuelve a-inconsistente, y por lo tanto el MAS ya no es consistente.",
        "La actualización de una hipótesis cuando llega un nuevo ejemplo es un mecanismo a-consistente.",
        "Siguiendo la proposición 1, este mecanismo puede ser utilizado para producir un mecanismo fuerte mas-consistente: al recibir un nuevo ejemplo en el MAS por un agente r, posiblemente se necesite una actualización y, después de un conjunto de interacciones entre r y los otros agentes, resulta en una nueva hipótesis compartida por todos los agentes y que restaura la consistencia del MAS, es decir, que es completa y coherente con el conjunto ES de todos los ejemplos presentes en el MAS.",
        "Es claro que al minimizar el número de modificaciones de hipótesis, este mecanismo sincrónico y minimalista reduce el número de ejemplos recibidos por el aprendiz de otros agentes, y por ende, el número total de ejemplos almacenados en el sistema. 4.",
        "EXPERIMENTOS En lo siguiente, aprenderemos una fórmula booleana que es una prueba difícil para el método de aprendizaje: el 11-multiplexor (ver [4]).",
        "Se refiere a 3 atributos booleanos de dirección a0, a1, a2 y 8 atributos booleanos de datos d0, ..., d7.",
        "La fórmula f11 se cumple si el número codificado por los 3 atributos de dirección es el número de un atributo de datos cuyo valor es 1.",
        "Su fórmula es la siguiente: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0).",
        "Hay 2048 = 211 posibles ejemplos, la mitad de los cuales son positivos (lo que significa que satisfacen f11) mientras que la otra mitad es negativa.",
        "Un experimento suele estar compuesto por 50 pruebas.",
        "Cada ejecución corresponde a una secuencia de 600 ejemplos que son aprendidos de forma incremental por un Sistema Multiagente con n agentes.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 167 (n-MAS).",
        "Un número de variables como la precisión (es decir, la frecuencia de clasificación correcta de un conjunto de ejemplos no vistos), el tamaño de la hipótesis (es decir, el número de términos en la fórmula actual) o el número de ejemplos almacenados, se registra cada vez que el sistema recibe 25 ejemplos durante esas ejecuciones.",
        "En el protocolo que se utiliza aquí, un nuevo ejemplo se envía a un agente aleatorio cuando el MAS es consistente.",
        "El siguiente ejemplo será enviado a su vez a otro agente cuando la consistencia del MAS haya sido restaurada.",
        "De esta manera simulamos una especie de aprendizaje lento: la frecuencia de llegada de ejemplos es lenta en comparación con el tiempo que lleva una actualización. 4.1 Eficiencia del aprendizaje conceptual en MAS 4.1.1 Tiempo de ejecución Discutimos brevemente aquí el tiempo de ejecución del aprendizaje en el MAS.",
        "Se debe tener en cuenta que todo el conjunto de acciones e interacciones en el MAS se simula en un solo procesador.",
        "La Figura 1 muestra que el tiempo depende linealmente del número de agentes.",
        "Al final de la parte más activa del aprendizaje (200 ejemplos), un 16MAS ha tomado 4 veces más tiempo de aprendizaje que un 4-MAS.",
        "Este tiempo de ejecución representa el conjunto completo de aprendizaje y la Figura 1: Tiempo de ejecución de un n-MAS (desde n = 2 en la parte inferior hasta n = 20 en la parte superior). actividad de comunicación y sugiere el costo de mantener una hipótesis de aprendizaje consistente en un MAS compuesto por agentes autónomos. 4.1.2 Redundancia en la memoria del MAS Estudiamos ahora la distribución de los ejemplos en la memoria del MAS.",
        "La redundancia se escribe RS = nS/ne, donde nS es el número total de ejemplos almacenados en el MAS, que es la suma de los tamaños de las memorias de ejemplos de los agentes Ei, y ne es el número total de ejemplos recibidos del entorno en el MAS.",
        "En la figura 2, comparamos las redundancias en MAS de 2 a 20 agentes.",
        "Hay un pico que se mueve lentamente de 80 a 100 ejemplos, que representa la cantidad de ejemplos para los cuales el aprendizaje es más activo.",
        "Para 20 agentes, la redundancia máxima no es más de 6, lo cual es mucho menor que el valor teórico máximo de 20.",
        "Ten en cuenta que cuando el aprendizaje se vuelve menos activo, la redundancia tiende hacia su valor mínimo 1: cuando ya no hay más actualizaciones, los ejemplos son solo la Figura 2: Redundancia de ejemplos almacenados en un nMAS (de n = 2 en la parte inferior a n = 20 en la parte superior) almacenados por el agente que los recibe. Un n-MAS selecciona una solución más simple que un solo agente. El mecanismo propuesto tiende a minimizar el número de términos en la hipótesis seleccionada.",
        "Durante el aprendizaje, el tamaño de la hipótesis actual crece más allá del óptimo, y luego disminuye cuando el MAS converge.",
        "En el banco de pruebas Multiplexer 11, el número óptimo de términos es 8, pero también existen fórmulas equivalentes con más términos.",
        "Es interesante notar que en este caso el 10-MAS converge hacia una solución exacta más cercana al número óptimo de términos (en este caso 8) (ver Figura 3).",
        "Después de haber presentado 1450 ejemplos, tanto el 1-MAS como el 10-MAS han aprendido exactamente el concepto (las precisiones respectivas son 0.9999 y 1), pero el agente individual expresa en promedio el resultado como una DNF de 11.0 términos, mientras que el 10-MAS lo expresa como una DNF de 8.8 términos.",
        "Sin embargo, para algunas otras funciones booleanas encontramos que durante el aprendizaje, 1-MAS siempre produce hipótesis más grandes que 10-MAS, pero que ambos MAS convergen a hipótesis con resultados de tamaño similar. 4.1.4 Un n-MAS es más preciso que un agente único. La Figura 4 muestra la mejora proporcionada por un MAS con n agentes en comparación con un agente único.",
        "Esta mejora no era especialmente esperada, porque ya sea que tengamos uno o n agentes, cuando se le dan N ejemplos al MAS, tiene acceso a la misma cantidad de información, mantiene solo una hipótesis en curso y utiliza el mismo algoritmo básico de revisión cada vez que un agente tiene que modificar la hipótesis actual.",
        "Ten en cuenta que si la precisión de los MAS de 1, 2, 4 y 10 es significativamente diferente, mejorando a medida que aumenta el número de agentes, no hay una diferencia clara más allá de este punto: la curva de precisión de los MAS de 100 agentes es muy similar a la de los MAS de 10 agentes. 4.1.4.1 Fórmulas booleanas.",
        "Para evaluar esta mejora de precisión, hemos experimentado nuestro protocolo en otros problemas de aprendizaje de funciones booleanas. Como en el caso del Multiplexor-11, estas funciones 168 The Sixth Intl.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 3: Tamaño de la hipótesis construida por 1 y 10MAS: el caso M11.",
        "Figura 4: Precisión de un n-MAS: el caso M11 (de abajo hacia arriba, n = 1, 2, 4, 10, 100). Se aprenden en forma de DNF3 más o menos sintácticamente complejos (es decir, con más o menos términos conjuntivos en la DNF), pero también son más o menos difíciles de aprender, ya que puede ser difícil encontrar su camino en el espacio de hipótesis para alcanzarlos.",
        "Además, la presencia en la descripción de atributos irrelevantes (es decir, atributos que no pertenecen al DNF objetivo) hace que el problema sea más difícil.",
        "Los siguientes problemas han sido seleccionados para experimentar con nuestro protocolo: (i) el multiplexor-11 con 9 atributos irrelevantes: M11 9, (ii) el multiplexor-20 M20 (con 4 bits de dirección y 16 bits de datos), (iii) un problema de paridad difícil (ver [4]) el Xorp m: debe haber un número impar de bits con valor 1 en los primeros p atributos para que la instancia sea positiva, los p bits restantes son irrelevantes, y (iv) una fórmula DNF simple (a ∧ b ∧ c) ∨ (c ∧ d ∧ e) ∨ (e ∧ f ∧ g) ∧ (g ∧ h ∧ i) con 19 atributos irrelevantes.",
        "La siguiente tabla resume alguna información sobre estos problemas, proporcionando el número total de atributos, incluidos los irrelevantes, el número de atributos irrelevantes en Forma Normal Disyuntiva 3, el número mínimo de términos de la DNF correspondiente, y el número de ejemplos de aprendizaje utilizados.",
        "Pb att. irre. att. términos ex.",
        "A continuación se presentan los resultados de precisión de nuestro mecanismo de aprendizaje con un solo agente y un MAS de 10 agentes, junto con los resultados de dos algoritmos estándar implementados con el entorno de aprendizaje WEKA[16]: JRip (una implementación de RIPPER[2]) e Id3[12].",
        "Para los experimentos con JRip e Id3, medimos la precisión media en 50 pruebas, separando aleatoriamente los ejemplos en un conjunto de aprendizaje y un conjunto de prueba cada vez.",
        "Los parámetros de JRip e Id3 son los predeterminados, excepto que JRip se utiliza sin poda.",
        "La siguiente tabla muestra los resultados: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 Es claro que los problemas difíciles se resuelven mejor con más agentes (ver por ejemplo xor5 15).",
        "Creemos que estos beneficios, que pueden ser importantes con un número creciente de agentes, se deben al hecho de que cada agente realmente memoriza solo parte del número total de ejemplos, y esta parte es seleccionada en parte por otros agentes como contraejemplos, lo que provoca un mayor número de actualizaciones de hipótesis actuales y, por lo tanto, una mejor exploración del espacio de hipótesis. 4.1.4.2 Problemas de base de datos de ML.",
        "También realizamos experimentos con algunos problemas no booleanos.",
        "Consideramos solo problemas de dos clases (positivo/negativo), tomados de la base de datos de problemas de aprendizaje de UCIs.",
        "En todos estos problemas, los ejemplos se describen como un vector de pares (atributo, valor).",
        "Los dominios de valor pueden ser booleanos, numéricos (conjunto totalmente ordenado) o nominales (conjunto no ordenado).",
        "Un conjunto adecuado de átomos A debe ser constituido para cada problema.",
        "Por ejemplo, si a es un atributo numérico, definimos como máximo k umbrales si, dando k+1 intervalos de densidad uniforme.",
        "Por lo tanto, cada umbral distintivo si da dos átomos, uno ≤ si y otro > si.",
        "En nuestros experimentos, tomamos un número máximo de umbral k = 8.",
        "Por ejemplo, en el caso del problema de iono, había 34 atributos numéricos, y una instancia se describe con 506 átomos.",
        "A continuación se presentan los resultados de precisión de nuestro sistema junto con los resultados anteriores.",
        "La columna Nb ex. se refiere al 4. La probabilidad de que el valor de a esté en cualquier intervalo es constante. El Sexto Congreso Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 169 número de ejemplos utilizados para el aprendizaje5.",
        "La columna (1) representa los valores de precisión mínima y máxima para los treinta y tres clasificadores probados en [8].",
        "La columna (2) representa los resultados de [13], donde se comparan varios métodos de aprendizaje con métodos de aprendizaje en conjunto utilizando conjuntos de clasificadores ponderados.",
        "La columna S-1 y S-10 dan la precisión de SMILE con 1 y 10 agentes, respectivamente.",
        "Esta tabla muestra que el algoritmo incremental correspondiente al caso de un solo agente, proporciona resultados honorables en relación a los métodos clásicos no incrementales que utilizan hipótesis más grandes y complejas.",
        "En algunos casos, hay una mejora en la precisión con un MAS de 10 agentes.",
        "Sin embargo, con datos de referencia de este tipo, que suelen ser ruidosos, la dificultad no radica realmente en la forma en que se explora el espacio de búsqueda, por lo que la mejora observada no siempre es significativa.",
        "El mismo tipo de fenómeno se ha observado con métodos dedicados a problemas booleanos difíciles [4]. 4.2 Sincronización de MAS En este caso consideramos que n agentes individuales aprenden sin interacciones y en un momento dado comienzan a interactuar, formando así un MAS.",
        "El propósito es observar cómo los agentes aprovechan la colaboración cuando parten de diferentes estados de creencias y memorias.",
        "En esta sección comparamos un 1-MAS, un 10-MAS (ref) y un 10-MAS (100sync) cuyos agentes no se comunicaron durante la llegada de los primeros 100 ejemplos (10 por agentes).",
        "Las tres curvas de precisión se muestran en la figura 5.",
        "Al comparar la curva del agente individual con la del 10-MAS sincronizado, podemos observar que después del inicio de la sincronización, es decir, en 125 ejemplos, las precisiones son idénticas.",
        "Esto era esperado ya que tan pronto como un ejemplo e recibido por el MAS contradice la hipótesis actual del agente ra que lo recibe, este agente realiza una actualización y su nueva hipótesis es propuesta a los otros agentes para su crítica.",
        "Por lo tanto, este primer ejemplo contradictorio lleva al MAS a alcanzar coherencia en relación con todo el conjunto de ejemplos presentes en la memoria de los agentes.",
        "Una mayor precisión, correspondiente a un 10-MAS, se obtiene más tarde, a partir del ejemplo 175.",
        "En otras palabras, el beneficio de una mejor exploración del espacio de investigación se obtiene ligeramente más tarde en el proceso de aprendizaje.",
        "Ten en cuenta que esta sincronización ocurre de forma natural en todas las situaciones en las que los agentes tienen, por alguna razón, una divergencia entre su hipótesis y la memoria del sistema.",
        "Esto incluye la fusión de dos MAS en una sola o la llegada de nuevos agentes en un MAS existente. 4.3 Experimentos sobre el aprendizaje asincrónico: el efecto de un gran flujo de datos. Para ttt y kr-vs-kp, nuestro protocolo no utilizó más de 574 y 958 ejemplos de aprendizaje respectivamente, por lo que colocamos otro número en la columna.",
        "Figura 5: Precisión de un 1-MAS, un 10-MAS y un 10-MAS sincronizado después de 100 ejemplos.",
        "En este experimento relajamos nuestro modo de aprendizaje lento: los ejemplos se envían a una velocidad determinada al MAS.",
        "El flujo de ejemplos resultante se mide en ms−1, y representa la cantidad de ejemplos enviados al MAS cada milisegundo.",
        "Cuando el flujo es demasiado grande, el MAS no puede alcanzar la consistencia del MAS al recibir un ejemplo del entorno antes de que llegue un nuevo ejemplo.",
        "Esto significa que el proceso de actualización, iniciado por el agente r0 al recibir un ejemplo, puede estar incompleto cuando un nuevo ejemplo es recibido por r0 u otro agente r1.",
        "Como resultado, un agente crítico puede tener que enviar contraejemplos de hipótesis enviadas por varios agentes en el instante t.",
        "Sin embargo, en nuestro entorno, a medida que los agentes memorizan todos los ejemplos que reciben cuando finaliza el flujo, el MAS alcanza necesariamente consistencia MAS con respecto a todos los ejemplos recibidos hasta el momento.",
        "En nuestros experimentos, aunque la curva de aprendizaje se ralentiza durante la fase intensa de aprendizaje (correspondiente a una baja precisión de las hipótesis actuales), el MAS aún logra alcanzar una hipótesis satisfactoria más adelante, ya que hay menos contraejemplos en el flujo de ejemplos.",
        "En la Figura 6 comparamos las precisiones de dos 11-MAS respectivamente sometidos a flujos de ejemplos de diferentes tasas al aprender la fórmula M11.",
        "La curva de aprendizaje del MAS al recibir un ejemplo a una velocidad de 1/33 ms−1 casi no se ve alterada (ver Figura 4), mientras que el MAS a 1/16 ms−1 primero se ralentiza severamente antes de alcanzar al primero. 5.",
        "TRABAJOS RELACIONADOS Desde el 96 [15], se han realizado varios trabajos sobre el aprendizaje en Sistemas Multiagente, pero muy pocos sobre el aprendizaje de conceptos.",
        "En [11] el MAS realiza una forma de aprendizaje en conjunto en la que los agentes son aprendices perezosos (no se mantiene una representación explícita) y venden ejemplos inútiles a otros agentes.",
        "En [10] cada agente observa todos los ejemplos pero solo percibe una parte de su representación.",
        "En el aprendizaje de conceptos en línea mutuo, los agentes convergen hacia una hipótesis única, pero cada agente produce ejemplos desde su propia representación del concepto, lo que resulta en una especie de sincronización en lugar de un aprendizaje de conceptos puro. 170 The Sixth Intl.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Precisión de dos sistemas multiagente asincrónicos de 11 agentes (tasas de ejemplo de 1/33ms−1 y 1/16ms−1). 6.",
        "CONCLUSIÓN Hemos presentado y experimentado un protocolo para el aprendizaje de conceptos en línea de MAS.",
        "La característica principal de este mecanismo de aprendizaje colaborativo es que mantiene una propiedad de consistencia: aunque durante el proceso de aprendizaje cada agente solo recibe y almacena, con cierta redundancia limitada, parte de los ejemplos recibidos por el MAS, en cualquier momento la hipótesis actual es consistente con todo el conjunto de ejemplos.",
        "Las hipótesis de nuestros experimentos no abordan los problemas de los MAS distribuidos, como fallos (por ejemplo, mensajes perdidos o corruptos) u otras fallas en general (crash, fallos bizantinos, etc.).",
        "Sin embargo, nuestro marco de trabajo es abierto, es decir, los agentes pueden salir del sistema o ingresar a él mientras se preserva el mecanismo de consistencia.",
        "Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente crítico se bloquea o no responde, se garantiza la consistencia con los otros críticos (dentro de los agentes restantes).",
        "En [1], se ha aplicado un enfoque similar a los problemas de abducción en MAS: las hipótesis a mantener, dada una información incompleta, son entonces hechos o afirmaciones.",
        "El trabajo adicional se refiere en primer lugar a acoplar la inducción y la abducción para realizar un aprendizaje colaborativo de conceptos cuando los ejemplos son solo parcialmente observados por cada agente, y en segundo lugar, a investigar el aprendizaje de memoria parcial: cómo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados.",
        "Agradecimientos Estamos muy agradecidos a Dominique Bouthinon por implementar las modificaciones tardías en SMILE, facilitando mucho nuestros experimentos.",
        "Parte de este trabajo se realizó durante la visita del primer autor al Atelier De BioInformatique de la Universidad Paris VI, Francia. 7.",
        "REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson.",
        "Cuando los agentes comunican hipótesis en situaciones críticas.",
        "En DALT-2006, mayo de 2006. [2] W. W. Cohen.",
        "Inducción de reglas rápida y efectiva.",
        "En ICML, páginas 115-123, 1995. [3] C. B. D.J.",
        "Newman, S. Hettich y C. Merz.",
        "Repositorio de bases de datos de aprendizaje automático de UCI, 1998. [4] S. Esmeir y S. Markovitch.",
        "Algoritmos basados en anticipación para la inducción en cualquier momento de árboles de decisión.",
        "En ICMLO4, páginas 257-264.",
        "Morgan Kaufmann, 2004. [5] J. F¨urnkranz. \n\nMorgan Kaufmann, 2004. [5] J. F¨urnkranz.",
        "Una patología de la escalada de colina de abajo hacia arriba en el aprendizaje inductivo de reglas.",
        "En ALT, volumen 2533 de LNCS, páginas 263-277.",
        "Springer, 2002. [6] A. Guerra-Hernández, A. ElFallah-Seghrouchni y H. Soldano.",
        "Aprendizaje en sistemas multiagente BDI.",
        "En CLIMA IV, volumen 3259, páginas 218-233.",
        "Springer Verlag, 2004. [7] M. Henniche. \n\nSpringer Verlag, 2004. [7] M. Henniche.",
        "Mgi: un algoritmo incremental de abajo hacia arriba.",
        "En la Conferencia IEEE de Australia y Nueva Zelanda sobre Sistemas de Información Inteligente, páginas 347-351, 1994. [8] T.-S. Lim, W.-Y.",
        "Loh, y Y.-S. Shih.",
        "Una comparación de la precisión de predicción, complejidad y tiempo de entrenamiento de treinta y tres algoritmos de clasificación antiguos y nuevos.",
        "Aprendizaje automático, 40(3):203-228, 2000. [9] M. A. Maloof y R. S. Michalski.",
        "Aprendizaje incremental con memoria parcial de instancias.",
        "I'm sorry, but the sentence \"Artif.\" is not a complete sentence. Can you provide more context or a complete sentence for me to translate to Spanish?",
        "Intell., 154(1-2):95-126, 2004. [10] P. J. Modi y W.-M. Shen.",
        "Aprendizaje colaborativo multiagente para tareas de clasificación.",
        "En AGENTS 01, páginas 37-38.",
        "ACM Press, 2001. [11] S. Onta˜non y E. Plaza.",
        "Reciclaje de datos para el aprendizaje multiagente.",
        "En ICML 05, páginas 633-640.",
        "ACM Press, 2005. [12] J. R. Quinlan. \n\nACM Press, 2005. [12] J. R. Quinlan.",
        "Inducción de árboles de decisión.",
        "Aprendizaje automático, 1(1):81-106, 1986. [13] U. R¨uckert y S. Kramer.",
        "Hacia límites ajustados para el aprendizaje de reglas.",
        "En ICML 04 (Conferencia Internacional sobre Aprendizaje Automático), página 90, Nueva York, NY, EE. UU., 2004.",
        "ACM Press. [14] J. Wang y L. Gasser.",
        "Aprendizaje de conceptos en línea mutuo para múltiples agentes.",
        "En AAMAS, páginas 362-369.",
        "ACM Press, 2002. [15] G. Weiß y S. Sen, editores.",
        "Adaptación y Aprendizaje en Sistemas Multiagente, volumen 1042 de las Notas de Conferencia en Ciencias de la Computación.",
        "Springer, 1996. [16] I. H. Witten y E. Frank.",
        "Minería de datos: Herramientas y técnicas prácticas de aprendizaje automático con implementaciones en Java.",
        "Morgan Kaufmann, octubre de 1999.",
        "La Sexta Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 171"
    ],
    "error_count": 0,
    "keys": {
        "multi-agent learning": {
            "translated_key": "aprendizaje multiagente",
            "is_in_text": true,
            "original_annotated_sentences": [
                "SMILE: Sound Multi-agent Incremental LEarning ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av.",
                "du pr´esident Kennedy, 75116 Paris Henry Soldano LIPN, UMR 7030 CNRS, University Paris-Nord, 99 Av.",
                "J-B Clement, 93430, Villetaneuse ABSTRACT This article deals with the problem of collaborative learning in a multi-agent system.",
                "Here each agent can update incrementally its beliefs B (the concept representation) so that it is in a way kept consistent with the whole set of information K (the examples) that he has received from the environment or other agents.",
                "We extend this notion of consistency (or soundness) to the whole MAS and discuss how to obtain that, at any moment, a same consistent concept representation is present in each agent.",
                "The corresponding protocol is applied to supervised concept learning.",
                "The resulting method SMILE (standing for Sound Multiagent Incremental LEarning) is described and experimented here.",
                "Surprisingly some difficult boolean formulas are better learned, given the same learning set, by a Multi agent system than by a single agent.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Concept learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent system General Terms Experimentation, Algorithms, Measurement, Performance 1.",
                "INTRODUCTION This article deals with the problem of collaborative concept learning in a multi-agent system. [6] introduces a characterisation of learning in multi-agent system according to the level of awareness of the agents.",
                "At level 1, agents learn ∗The primary author of this paper is a student. in the system without taking into account the presence of other agents, except through the modification brought upon the environment by their action.",
                "Level 2 implies direct interaction between the agents as they can exchange messages to improve their learning.",
                "Level 3 would require agents to take into account the competencies of other agents, and be able to learn from observation of the other agents behaviour (while considering them as independant entities and not indetermined part of the environment as in level 1).",
                "We focus in this paper on level 2, studying direct interaction between agents involved in a learning process.",
                "Each agent is assumed to be able to learn incrementally from the data he receives, meaning that each agent can update his belief set B to keep it consistent with the whole set of information K that he has received from the environment or from other agents.",
                "In such a case, we will say that he is a-consistent.",
                "Here, the belief set B represents hypothetical knowledge that can therefore be revised, whereas the set of information K represents certain knowledge, consisting of non revisable observations and facts.",
                "Moreover, we suppose that at least a part Bc of the beliefs of each agent is common to all agents and must stay that way.",
                "Therefore, an update of this common set Bc by agent r must provoke an update of Bc for the whole community of agents.",
                "It leads us to define what is the mas-consistency of an agent with respect to the community.",
                "The update process of the community beliefs when one of its members gets new information can then be defined as the consistency maintenance process ensuring that every agent in the community will stay masconsistent.",
                "This mas-consistency maintenance process of an agent getting new information gives him the role of a learner and implies communication with other agents acting as critics.",
                "However, agents are not specialised and can in turn be learners or critics, none of them being kept to a specific role.",
                "Pieces of information are distributed among the agents, but can be redundant.",
                "There is no central memory.",
                "The work described here has its origin in a former work concerning learning in an intentional multi-agent system using a BDI formalism [6].",
                "In that work, agents had plans, each of them being associated with a context defining in which conditions it can be triggered.",
                "Plans (each of them having its own context) were common to the whole set of agents in the community.",
                "Agents had to adapt their plan contexts depending on the failure or success of executed plans, using a learning mechanism and asking other agents for examples (plans successes or failures).",
                "However this work lacked a collective learning protocol enabling a real autonomy of the multi-agent system.",
                "The study of such a protocol is the object of the present paper.",
                "In section 2 we formally define the mas-consistency of an update mechanism for the whole MAS and we propose a generic update mechanism proved to be mas consistent.",
                "In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent update mechanism to collaborative concept learning.",
                "Section 4 describes various experiments on SMILE and discusses various issues including how the accuracy and the simplicity of the current hypothesis vary when comparing single agent learning and mas learning.",
                "In section 5 we briefly present some related works and then conclude in section 6 by discussing further investigations on mas consistent learning. 2.",
                "FORMAL MODEL 2.1 Definitions and framework In this section, we present a general formulation of collective incremental learning in a cognitive multi agent system.",
                "We represent a MAS as a set of agents r1, ..., rn.",
                "Each agent ri has a belief set Bi consisting of all the revisable knowledge he has.",
                "Part of these knowledges must be shared with other agents.",
                "The part of Bi that is common to all agents is denoted as BC .",
                "This common part provokes a dependency between the agents.",
                "If an agent ri updates his belief set Bi to Bi, changing in the process BC into BC , all other agents rk must then update their belief set Bk to Bk so that BC ⊆ Bk.",
                "Moreover, each agent ri has stored some certain information Ki.",
                "We suppose that some consistency property Cons(Bi, Ki) can be verified by the agent itself between its beliefs Bi and its information Ki.",
                "As said before, Bi represents knowledge that might be revised whereas Ki represents observed facts, taken as being true, and which can possibly contradict Bi.",
                "Definition 1. a-consistency of an agent An agent ri is a-consistent iff Cons(Bi, Ki) is true.",
                "Example 1.",
                "Agent r1 has a set of plans which are in the common part BC of B1.",
                "Each plan P has a triggering context d(P) (which acts as a pre-condition) and a body.",
                "Some piece of information k could be plan P, triggered in situation s, has failed in spite of s being an instance of d(P).",
                "If this piece of information is added to K1, then agent r1 is not a-consistent anymore: Cons(B1, K1 ∪ k) is false.",
                "We also want to define some notion of consistency for the whole MAS depending on the belief and information sets of its constituting elements.",
                "We will first define the consistency of an agent ri with respect to its belief set Bi and its own information set Ki together with all information sets K1...Kn from the other agents of the MAS.",
                "We will simply do that by considering what would be the a-consistency of the agent if he has the information of all the other agents.",
                "We call this notion the mas-consistency: Definition 2. mas-consistency of an agent An agent ri is mas-consistent iff Cons(Bi, Ki ∪ K) is true, where K = ∪j∈{1,..,n}−{i}Kj 1 is the set of all information from other agents of the MAS. 1 We will note this ∪ Kj when the context is similar.",
                "Example 2.",
                "Using the previous example, suppose that the piece of information k is included in the information K2 of agent r2.",
                "As long as the piece of information is not transmitted to r1, and so added to K1 , r1 remains a-consistent.",
                "However, r1 is not mas-consistent as k is in the set K of all information of the MAS.",
                "The global consistency of the MAS is then simply the mas-consistency of all its agents.",
                "Definition 3.",
                "Consistency of a MAS A MAS r1,...,rn is consistent iff all its agents ri are masconsistent.",
                "We now define the required properties for a revision mechanism M updating an agent ri when it gets a piece of information k. In the following, we will suppose that: • Update is always possible, that is, an agent can always modify its belief set Bi in order to regain its a-consistency.",
                "We will say that each agent is locally efficient. • Considering two sets of information Cons(Bi, K1) and Cons(Bi, K2), we also have Cons(Bi, K1 ∪ K2).",
                "That is, a-consistency of the agents is additive. • If a piece of information k concerning the common set BC is consistent with an agent, it is consistent with all agents: for all pair of agents (ri,rj) such that Cons(Bi, Ki) and Cons(Bj, Kj) are true, we have, for all piece of information k: Cons(Bi, Ki ∪ k) iff Cons(Bj, Kj ∪ k).",
                "In such a case, we will say that the MAS is coherent.",
                "This last condition simply means that the common belief set BC is independent of the possible differences between the belief sets Bi of each agent ri.",
                "In the simplest case, B1 = ... = Bn = BC .",
                "M will also be viewed as an incremental learning mechanism and represented as an application changing Bi in Bi.",
                "In the following, we shall note ri(Bi, Ki) for ri when it is useful.",
                "Definition 4. a-consistency of a revision An update mechanism M is a-consistent iff for any agent ri and any piece of information k reaching ri, the a-consistency of this agent is preserved.",
                "In other words, iff: ri(Bi, Ki) a-consistent ⇒ ri(Bi, Ki) a-consistent, where Bi = M(Bi) and Ki = Ki ∪ k is the set of all information from other agents of the MAS.",
                "In the same way, we define the mas-consistency of a revision mechanism as the a-consistency of this mechanism should the agents dispose of all information in the MAS.",
                "In the following, we shall note, if needed, ri(Bi, Ki, K) for the agent ri in MAS r1 . . . rn.",
                "Definition 5. mas-consistency of a revision An update mechanism Ms is mas-consistent iff for all agent ri and all pieces of information k reaching ri, the masconsistency of this agent is preserved.",
                "In other words, if: ri(Bi, Ki, K) mas-consistent ⇒ ri(Bi, Ki, K) mas-consistent, where Bi = Ms(Bi), Ki = Ki ∪ k, and K = ∪Kj is the set of all information from the MAS.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 165 At last, when a mas-consistent mechanism is applied by an agent getting a new piece of information, a desirable sideeffect of the mechanism should be that all others agents remains mas-consistent after any modification of the common part BC , that is, the MAS itself should become consistent again.",
                "This property is defined as follows: Definition 6.",
                "Strong mas-consistency of a revision An update mechanism Ms is strongly mas-consistent iff - Ms is mas-consistent, and - the application of Ms by an agent preserves the consistency of the MAS. 2.2 A strongly mas-consistent update mechanism The general idea is that, since information is distributed among all the agents of the MAS, there must be some interaction between the learner agent and the other agents in a strongly mas-consistent update mechanism Ms.",
                "In order to ensure its mas-consistency, Ms will be constituted of reiterated applications by the learner agent ri of an internal a-consistent mechanism M, followed by some interactions between ri and the other agents, until ri regain its masconsistency.",
                "We describe below such a mechanism, first with a description of an interaction, then an iteration, and finally a statement of the termination condition of the mechanism.",
                "The mechanism is triggered by an agent ri upon receipt of a piece of information k disrupting the mas-consistency.",
                "We shall note M(Bi) the belief set of the learner agent ri after an update, BC the common part modified by ri, and Bj the belief set of another agent rj induced by the modification of its common part BC in BC .",
                "An interaction I(ri, rj) between the learner agent ri and another agent rj, acting as critic is constituted of the following steps: • agent ri sends the update BC of the common part of its beliefs.",
                "Having applied its update mechanism, ri is a-consistent. • agent rj checks the modification Bj of its beliefs induced by the update BC .",
                "If this modification preserve its a-consistency, rj adopts this modification. • agent rj sends either an acceptation of BC or a denial along with one (or more) piece(s) of information k such that Cons(Bj, k ) is false.",
                "An iteration of Ms will then be composed of: • the reception by the learner agent ri of a piece of information and the update M(Bi) restoring its aconsistency • a set of interactions I(ri, rj) (in which several critic agents can possibly participate).",
                "If at least one piece of information k is transmitted to ri, the addition of k will necessarily make ri a-inconsistent and a new iteration will then occur.",
                "This mechanism Ms ends when no agent can provide such a piece of information k .",
                "When it is the case, the masconsistency of the learner agent ri is restored.",
                "Proposition 1.",
                "Let r1,...,rn be a consistent MAS in which agent ri receives a piece of information k breaking its aconsistency, and M an a-consistent internal update mechanism.",
                "The update mechanism Ms described above is strongly mas-consistent.",
                "Proof.",
                "The proof directly derives from the mechanism description.",
                "This mechanism ensures that each time an agent receives an event, its mas-consistency will be restored.",
                "As the other agents all adopt the final update BC , they are all mas-consistent, and the MAS is consistent.",
                "Therefore Ms is a strongly consistent update mechanism.",
                "In the mechanism Ms described above, the learner agent is the only one that receives and memorizes information during the mechanism execution.",
                "It ensures that Ms terminates.",
                "The pieces of information transmitted by other agents and memorized by the learner agent are redundant as they are already present in the MAS, more precisely in the memory of the critic agents that transmitted them.",
                "Note that the mechanism Ms proposed here does not explicitly indicate the order nor the scope of the interactions.",
                "We will consider in the following that the modification proposal BC is sent sequentially to the different agents (synchronous mechanism).",
                "Moreover, the response of a critic agent will only contain one piece of information inconsistent with the proposed modification.",
                "We will say that the response of the agent is minimal.",
                "This mechanism Ms, being synchronous with minimal response, minimizes the amount of information transmitted by the agents.",
                "We will now illustrate it in the case of multi-agent concept learning. 3.",
                "SOUNDMULTI-AGENTINCREMENTAL LEARNING 3.1 The learning task We experiment the mechanism proposed above in the case of incremental MAS concept learning.",
                "We consider here a hypothesis language in which a hypothesis is a disjunction of terms.",
                "Each term is a conjunction of atoms from a set A.",
                "An example is represented by a tag + or − and a description 2 composed of a subset of atoms e ⊆ A.",
                "A term covers an example if its constituting atoms are included in the example.",
                "A hypothesis covers an example if one of its term covers it.",
                "This representation will be used below for learning boolean formulae.",
                "Negative literals are here represented by additional atoms, like not − a.",
                "The boolean formulae f =(a ∧ b) ∨ (b ∧ ¬c) will then be written (a ∧ b) ∨ (b ∧ not − c).",
                "A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 Incremental learning process The learning process is an update mechanism that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis.",
                "Before this update, the given hypothesis is complete, meaning that it covers all positive examples of E+ , and 2 When no confusion is possible, the word example will be used to refer to the pair (tag, description) as well as the description alone. 166 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) coherent, meaning that it does not cover any negative example of E− .",
                "After the update, the new hypothesis must be complete and coherent with the new memory state E ∪ {e}.",
                "We describe below our single agent update mechanism, inspired from a previous work on incremental learning[7].",
                "In the following, a hypothesis H for the target formula f is a list of terms h, each of them being a conjunction of atoms.",
                "H is coherent if all terms h are coherent, and H is complete if each element of E+ is covered by at least one term h of H. Each term is by construction the lgg (least general generalization) of a subset of positives instances {e1, ..., en}[5], that is the most specific term covering {e1, ..., en}.",
                "The lgg operator is defined by considering examples as terms, so we denote as lgg(e) the most specific term that covers e, and as lgg(h, e) the most specific term which is more general than h and that covers e. Restricting the term to lgg is the basis of a lot of Bottom-Up learning algorithms (for instance [5]).",
                "In the typology proposed by [9], our update mechanism is an incremental learner with full instance memory: learning is made by successive updates and all examples are stored.",
                "The update mechanism depends of the ongoing hypothesis H, the ongoing examples E+ and E− , and the new example e. There are three possible cases: • e is positive and H covers e, or e is negative and H does not cover e. No update is needed, H is already complete and coherent with E ∪ {e}. • e is positive and H does not cover e: e is denoted as a positive counterexample of H. Then we seek to generalize in turn the terms h of H. As soon as a correct generalization h = lgg(h, e) is found, h replaces h in H. If there is a term that is less general that h , it is discarded.",
                "If no generalization is correct (meaning here coherent), H ∪ lgg(e) replaces H. • e is negative and H covers e: e is denoted as a negative counterexample of H. Each term h covering e is then discarded from H and replaced by a set of terms {h1, ...., hn} that is, as a whole, coherent with E− ∪ {e} and that covers the examples of E+ uncovered by H − {h}.",
                "Terms of the final hypothesis H that are less general than others are discarded from H. We will now describe the case where e = e− is a covered negative example.",
                "The following functions are used here: • coveredOnlyBy(h, E+) gives the subset of E+ covered by h and no other term of H. • bestCover(h1, h2) gives h1 if h1 covers more examples from uncoveredPos than h2, otherwise it gives h2. • covered(h) gives the elements of uncoveredPos covered by h. // Specialization of each h covering e− for each h of H covering e− do H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= atoms that are neither in e− nor in h while (uncoveredPos = ∅) do // seeking the best specialization of h hc=h best=⊥ // ⊥ covers no example for each a of Ar do hc= h ∧ a best = bestCover(hc, best) endfor Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) endwhile endfor Terms of H that are less general than others are discarded.",
                "Note that this mechanism tends to both make a minimal update of the current hypothesis and minimize the number of terms in the hypothesis, in particular by discarding terms less general than other ones after updating a hypothesis. 3.3 Collective learning If H is the current hypothesis, Ei the current example memory of agent ri and E the set of all the examples received by the system, the notation of section 2 becomes Bi = BC = H, Ki = Ei and K = E. Cons(H, Ei) states that H is complete and coherent with Ei.",
                "In such a case, ri is a-consistent.",
                "The piece of information k received by agent ri is here simply an example e along with its tag.",
                "If e is such that the current hypothesis H is not complete or coherent with Ei ∪ {e}, e contradicts H: ri becomes a-inconsistent, and therefore the MAS is not consistent anymore.",
                "The update of a hypothesis when a new example arrives is an a- consistent mechanism.",
                "Following proposition 1 this mechanism can be used to produce a strong mas-consistent mechanism: upon reception of a new example in the MAS by an agent r, an update is possibly needed and, after a set of interactions between r and the other agents, results in a new hypothesis shared by all the agents and that restores the consistency of the MAS, that is which is complete and coherent with the set ES of all the examples present in the MAS.",
                "It is clear that by minimizing the number of hypothesis modifications, this synchronous and minimal mechanism minimize the number of examples received by the learner from other agents, and therefore, the total number of examples stored in the system. 4.",
                "EXPERIMENTS In the following, we will learn a boolean formula that is a difficult test for the learning method: the 11-multiplexer (see [4]).",
                "It concerns 3 address boolean attributes a0, a1, a2 and 8 data boolean attributes d0, ..., d7.",
                "Formulae f11 is satisfied if the number coded by the 3 address attributes is the number of a data attribute whose value is 1.",
                "Its formula is the following: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0).",
                "There are 2048 = 211 possible examples, half of whom are positive (meaning they satisfy f11) while the other half is negative.",
                "An experiment is typically composed of 50 trials.",
                "Each run corresponds to a sequence of 600 examples that are incrementally learned by a Multi Agent System with n agents The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 167 (n-MAS).",
                "A number of variables such as accuracy, (i.e. the frequency of correct classification of a set of unseen examples), hypothesis size (i.e. the number of terms in the current formula) or number of stored examples, is recorded each time 25 examples are received by the system during those runs.",
                "In the protocol that is used here, a new example is sent to a random agent when the MAS is consistent.",
                "The next example will be sent in turn to an other agent when the MAS consistency will have been restored.",
                "In such a way we simulate a kind of slow learning: the frequency of example arrivals is slow compared to the time taken by an update. 4.1 Efficiency of MAS concept learning 4.1.1 Execution time We briefly discuss here execution time of learning in the MAS.",
                "Note that the whole set of action and interaction in the MAS is simulated on a single processor.",
                "Figure 1 shows that time linearly depends on the number of agents.",
                "At the end of the most active part of learning (200 examples), a 16MAS has taken 4 times more learning time than a 4-MAS.",
                "This execution time represents the whole set of learning and Figure 1: Execution time of a n-MAS (from n = 2 at the bottom to n = 20 on the top). communication activity and hints at the cost of maintaining a consistent learning hypothesis in a MAS composed of autonomous agents. 4.1.2 Redundancy in the MAS memory We study now the distribution of the examples in the MAS memory.",
                "Redundancy is written RS = nS/ne, where nS is the total number of examples stored in the MAS, that is the sum of the sizes of agents examples memories Ei, and ne is the total number of examples received from the environment in the MAS.",
                "In figure 2, we compare redundancies in 2 to 20 agents MAS.",
                "There is a peak, slowly moving from 80 to 100 examples, that represents the number of examples for which the learning is most active.",
                "For 20 agents, maximal redundancy is no more than 6, which is far less than the maximal theoretical value of 20.",
                "Note that when learning becomes less active, redundancy tends towards its minimal value 1: when there is no more updates, examples are only Figure 2: Redundancy of examples stored in a nMAS (from n = 2 at the bottom to n = 20 on the top) . stored by the agent that receives them. 4.1.3 A n-MAS selects a simpler solution than a single agent The proposed mechanism tends to minimize the number of terms in the selected hypothesis.",
                "During learning, the size of the current hypothesis grows up beyond the optimum, and then decreases when the MAS converges.",
                "In the Multiplexer 11 testbed, the optimal number of terms is 8, but there also exist equivalent formulas with more terms.",
                "It is interesting to note that in this case the 10-MAS converges towards an exact solution closer to the optimal number of terms (here 8) (see Figure 3).",
                "After 1450 examples have been presented both 1-MAS and 10-MAS have exactly learned the concept (the respective accuracies are 0.9999 and 1) but the single agent expresses in average the result as a 11.0 terms DNF whereas the 10-MAS expresses it as a 8.8 terms DNF.",
                "However for some other boolean functions we found that during learning 1-MAS always produces larger hypotheses than 10-MAS but that both MAS converge to hypotheses with similar size results. 4.1.4 A n-MAS is more accurate than a single agent Figure 4 shows the improvement brought by a MAS with n agents compared to a single agent.",
                "This improvement was not especially expected, because whether we have one or n agents, when N examples are given to the MAS it has access to the same amount of information, maintains only on ongoing hypothesis and uses the same basic revision algorithm whenever an agent has to modify the current hypothesis.",
                "Note that if the accuracy of 1, 2, 4 and 10-MAS are significantly different, getting better as the number of agents increases, there is no clear difference beyond this point: the accuracy curve of the 100 agents MAS is very close to the one of the 10 agents MAS. 4.1.4.1 Boolean formulas.",
                "To evaluate this accuracy improvement, we have experimented our protocol on other problems of boolean function learning, As in the Multiplexer-11 case, these functions 168 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 3: Size of the hypothesis built by 1 and 10MAS: the M11 case.",
                "Figure 4: Accuracy of a n-MAS: the M11 case (from bottom to top, n = 1, 2, 4, 10, 100). are learnt in the form of more or less syntactically complex DNF3 (that is with more or less conjunctive terms in the DNF), but are also more or less difficult to learn as it can be difficult to get its way in the hypothesis space to reach them.",
                "Furthermore, the presence in the description of irrelevant attributes (that is attributes that does not belong to the target DNF) makes the problem more difficult.",
                "The following problems have been selected to experiment our protocol: (i) the multiplexer-11 with 9 irrelevant attributes: M11 9, (ii) the 20-multiplexer M20 (with 4 address bits and 16 data bits), (iii) a difficult parity problem (see [4]) the Xorp m: there must be an odd number of bits with value 1 in the p first attributes for the instance to be positive, the p others bits being irrelevant, and (iv) a simple DNF formula (a ∧ b ∧ c) ∨ (c ∧ d ∧ e)(e ∧ f ∧ g) ∧ (g ∧ h ∧ i) with 19 irrelevant attributes.",
                "The following table sums up some information about these problems, giving the total number of attributes including irrelevant ones, the number of irrelevant 3 Disjunctive Normal Forms attributes, the minimal number of terms of the corresponding DNF, and the number of learning examples used.",
                "Pb att. irre. att. terms ex.",
                "M11 11 0 8 200 M11 9 20 9 8 200 M20 20 0 16 450 Xor3 25 28 25 4 200 Xor5 5 10 5 16 180 Xor5 15 20 15 16 600 Simple4-9 19 28 19 4 200 Below are given the accuracy results of our learning mechanism with a single agent and a 10 agents MAS, along with the results of two standard algorithms implemented with the learning environment WEKA[16]: JRip (an implementation of RIPPER[2]) and Id3[12].",
                "For the experiments with JRip and Id3, we measured the mean accuracy on 50 trials, each time randomly separating examples in a learning set and a test set.",
                "JRip and Id3 parameters are default parameters, except that JRip is used without pruning.",
                "The following table shows the results: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 It is clear that difficult problems are better solved with more agents (see for instance xor5 15).",
                "We think that these benefits, which can be important with an increasing number of agents, are due to the fact that each agent really memorizes only part of the total number of examples, and this part is partly selected by other agents as counter examples, which cause a greater number of current hypothesis updates and therefore, a better exploration of the hypotheses space. 4.1.4.2 ML database problems.",
                "We did also experiments with some non boolean problems.",
                "We considered only two classes (positive/negative) problems, taken from the UCIs learning problems database[3].",
                "In all these problems, examples are described as a vector of couples (attribute, value).",
                "The value domains can be either boolean, numeric (wholly ordered set), or nominal (non-ordered set).",
                "An adequate set of atoms A must be constituted for each problem.",
                "For instance, if a is a numeric attribute, we define at most k threshold si, giving k+1 intervals of uniform density4 .",
                "Therefore, each distinct threshold si gives two atoms a ≤ si and a > si.",
                "In our experiments, we took a maximal number of threshold k = 8.",
                "For instance, in the iono problem case, there were 34 numeric attributes, and an instance is described with 506 atoms.",
                "Below are given the accuracy results of our system along with previous results.",
                "The column Nb ex. refer to the 4 The probability for the value of a to be in any interval is constant The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 169 number of examples used for learning5 .",
                "Column (1) represents minimal and maximal accuracy values for the thirty three classifiers tested in [8].",
                "Column (2) represents the results of [13], where various learning methods are compared to ensemble learning methods using weighted classifiers sets.",
                "Column S-1 and S-10 gives the accuracy of SMILE with respectively 1 and 10 agents.",
                "Pb Nb ex. (1) (2) S-1 S-10 ttt 862/574 // 76.2-99.7 99.7 99.9 kr-vs-kp 2876/958 // 91.4-99.4 96.8 97.3 iono 315 // 88.0-91.8 87.2 88.1 bupa 310 57-72 58-69.3 62.5 63.3 breastw 614 91-97 94.3-97.3 94.7 94.7 vote 391 94-96 95.3-96 91.9 92.6 pima 691 // 71.5- 73.4 65.0 65.0 heart 243 66-86 77.1-84.1 69.5 70.7 This table shows that the incremental algorithm corresponding to the single agent case, gives honorable results relatively to non-incremental classical methods using larger and more complex hypotheses.",
                "In some cases, there is an accuracy improvement with a 10 agents MAS.",
                "However, with such benchmarks data, which are often noisy, the difficulty does not really come from the way in which the search space is explored, and therefore the improvement observed is not always significant.",
                "The same kind of phenomenon have been observed with methods dedicated to hard boolean problems [4]. 4.2 MAS synchronization Here we consider that n single agents learn without interactions and at a given time start interacting thus forming a MAS.",
                "The purpose is to observe how the agents take advantage of collaboration when they start from different states of beliefs and memories.",
                "We compare in this section a 1-MAS, a 10-MAS (ref) and a 10-MAS (100sync) whose agents did not communicate during the arrival of the first 100 examples (10 by agents).",
                "The three accuracy curves are shown in figure 5.",
                "By comparing the single agent curve and the synchronized 10-MAS, we can observe that after the beginning of the synchronization, that is at 125 examples, accuracies are identical.",
                "This was expected since as soon as an example e received by the MAS contradicts the current hypothesis of the agent ra receiving it, this agent makes an update and its new hypothesis is proposed to the others agents for criticism.",
                "Therefore, this first contradictory example brings the MAS to reach consistency relatively to the whole set of examples present in agents memories.",
                "A higher accuracy, corresponding to a 10-MAS is obtained later, from the 175th example.",
                "In other words, the benefit of a better exploration of the research space is obtained slightly later in the learning process.",
                "Note that this synchronization happens naturally in all situations where agents have, for some reason, a divergence between their hypothesis and the system memory.",
                "This includes the fusion of two MAS into a single one or the arrival of new agents in an existing MAS. 4.3 Experiments on asynchronous learning: the effect of a large data stream 5 For ttt and kr-vs-kp, our protocol did not use more than respectively 574 and 958 learning examples, so we put another number in the column.",
                "Figure 5: Accuracies of a 1-MAS, a 10-MAS, and a 10-MAS synchronized after 100 examples.",
                "In this experiment we relax our slow learning mode: the examples are sent at a given rate to the MAS.",
                "The resulting example stream is measured in ms−1 , and represents the number of examples sent to the MAS each ms.",
                "Whenever the stream is too large, the MAS cannot reach MAS consistency on reception of an example from the environment before a new example arrives.",
                "This means that the update process, started by agent r0 as he received an example, may be unfinished when a new example is received by r0 or another agent r1.",
                "As a result, a critic agent may have at instant t to send counterexamples of hypotheses sent by various agents.",
                "However as far as the agents, in our setting, memorizes all the examples they receive whenever the stream ends, the MAS necessarily reaches MAS consistency with respect to all the examples received so far.",
                "In our experiments, though its learning curve is slowed down during the intense learning phase (corresponding to low accuracy of the current hypotheses), the MAS still reaches a satisfying hypothesis later on as there are less and less counterexamples in the example stream.",
                "In Figure 6 we compare the accuracies of two 11-MAS respectively submitted to example streams of different rates when learning the M11 formula.",
                "The learning curve of the MAS receiving an example at a 1/33 ms−1 rate is almost not altered (see Figure 4) whereas the 1/16 ms−1 MAS is first severely slowed down before catching up with the first one. 5.",
                "RELATED WORKS Since 96 [15], various work have been performed on learning in MAS, but rather few on concept learning.",
                "In [11] the MAS performs a form of ensemble learning in which the agents are lazy learners (no explicit representation is maintained) and sell useless examples to other agents.",
                "In [10] each agent observes all the examples but only perceive a part of their representation.",
                "In mutual online concept learning [14] the agents converge to a unique hypothesis, but each agent produces examples from its own concept representation, thus resulting in a kind of synchronization rather than in pure concept learning. 170 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 6: Accuracies of two asynchronous 11-MAS (1/33ms−1 and 1/16ms−1 example rates) . 6.",
                "CONCLUSION We have presented here and experimented a protocol for MAS online concept learning.",
                "The main feature of this collaborative learning mechanism is that it maintains a consistency property: though during the learning process each agent only receives and stores, with some limited redundancy, part of the examples received by the MAS, at any moment the current hypothesis is consistent with the whole set of examples.",
                "The hypotheses of our experiments do not address the issues of distributed MAS such as faults (for instance messages could be lost or corrupted) or other failures in general (crash, byzantine faults, etc.).",
                "Nevertheless, our framework is open, i.e., the agents can leave the system or enter it while the consistency mechanism is preserved.",
                "For instance if we introduce a timeout mechanism, even when a critic agent crashes or omits to answer, the consistency with the other critics (within the remaining agents) is entailed.",
                "In [1], a similar approach has been applied to MAS abduction problems: the hypotheses to maintain, given an incomplete information, are then facts or statements.",
                "Further work concerns first coupling induction and abduction in order to perform collaborative concept learning when examples are only partially observed by each agent, and second, investigating partial memory learning: how learning is preserved whenever one agent or the whole MAS forgets some selected examples.",
                "Aknowledgments We are very grateful to Dominique Bouthinon for implementing late modifications in SMILE, so much easing our experiments.",
                "Part of this work has been performed during the first authors visit to the Atelier De BioInformatique of Paris VI university, France. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In DALT-2006, May 2006. [2] W. W. Cohen.",
                "Fast effective rule induction.",
                "In ICML, pages 115-123, 1995. [3] C. B. D.J.",
                "Newman, S. Hettich and C. Merz.",
                "UCI repository of machine learning databases, 1998. [4] S. Esmeir and S. Markovitch.",
                "Lookahead-based algorithms for anytime induction of decision trees.",
                "In ICMLO4, pages 257-264.",
                "Morgan Kaufmann, 2004. [5] J. F¨urnkranz.",
                "A pathology of bottom-up hill-climbing in inductive rule learning.",
                "In ALT, volume 2533 of LNCS, pages 263-277.",
                "Springer, 2002. [6] A. Guerra-Hern´andez, A. ElFallah-Seghrouchni, and H. Soldano.",
                "Learning in BDI multi-agent systems.",
                "In CLIMA IV, volume 3259, pages 218-233.",
                "Springer Verlag, 2004. [7] M. Henniche.",
                "Mgi: an incremental bottom-up algorithm.",
                "In IEEE Aust. and New Zealand Conference on Intelligent Information Systems, pages 347-351, 1994. [8] T.-S. Lim, W.-Y.",
                "Loh, and Y.-S. Shih.",
                "A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms.",
                "Machine Learning, 40(3):203-228, 2000. [9] M. A. Maloof and R. S. Michalski.",
                "Incremental learning with partial instance memory.",
                "Artif.",
                "Intell., 154(1-2):95-126, 2004. [10] P. J. Modi and W.-M. Shen.",
                "Collaborative multiagent learning for classification tasks.",
                "In AGENTS 01, pages 37-38.",
                "ACM Press, 2001. [11] S. Onta˜non and E. Plaza.",
                "Recycling data for <br>multi-agent learning</br>.",
                "In ICML 05, pages 633-640.",
                "ACM Press, 2005. [12] J. R. Quinlan.",
                "Induction of decision trees.",
                "Machine Learning, 1(1):81-106, 1986. [13] U. R¨uckert and S. Kramer.",
                "Towards tight bounds for rule learning.",
                "In ICML 04 (International conference on Machine learning), page 90, New York, NY, USA, 2004.",
                "ACM Press. [14] J. Wang and L. Gasser.",
                "Mutual online concept learning for multiple agents.",
                "In AAMAS, pages 362-369.",
                "ACM Press, 2002. [15] G. Weiß and S. Sen, editors.",
                "Adaption and Learning in Multi-Agent Systems, volume 1042 of Lecture Notes in Computer Science.",
                "Springer, 1996. [16] I. H. Witten and E. Frank.",
                "Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.",
                "Morgan Kaufmann, October 1999.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 171"
            ],
            "original_annotated_samples": [
                "Recycling data for <br>multi-agent learning</br>."
            ],
            "translated_annotated_samples": [
                "Reciclaje de datos para el <br>aprendizaje multiagente</br>."
            ],
            "translated_text": "SMILE: Aprendizaje Incremental Multiagente de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av. del presidente Kennedy, 75116 París Henry Soldano LIPN, UMR 7030 CNRS, Universidad Paris-Norte, 99 Av. J-B Clement, 93430, Villetaneuse RESUMEN Este artículo trata sobre el problema del aprendizaje colaborativo en un sistema multiagente. Aquí cada agente puede actualizar de forma incremental sus creencias B (la representación del concepto) para que se mantenga consistente con el conjunto completo de información K (los ejemplos) que ha recibido del entorno u otros agentes. Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo lograr que, en cualquier momento, una misma representación conceptual consistente esté presente en cada agente. El protocolo correspondiente se aplica al aprendizaje supervisado de conceptos. El método resultante SMILE (que significa Sound Multiagent Incremental LEarning) se describe y experimenta aquí. Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de múltiples agentes que por un solo agente. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de conceptos; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistema multiagente Términos Generales Experimentación, Algoritmos, Medición, Rendimiento 1. INTRODUCCIÓN Este artículo trata sobre el problema del aprendizaje colaborativo de conceptos en un sistema multiagente. [6] introduce una caracterización del aprendizaje en un sistema multiagente según el nivel de conciencia de los agentes. En el nivel 1, los agentes aprenden ∗El autor principal de este artículo es un estudiante. en el sistema sin tener en cuenta la presencia de otros agentes, excepto a través de la modificación que traen al entorno con sus acciones. El nivel 2 implica una interacción directa entre los agentes, ya que pueden intercambiar mensajes para mejorar su aprendizaje. El nivel 3 requeriría que los agentes tengan en cuenta las competencias de otros agentes y sean capaces de aprender observando el comportamiento de los otros agentes (considerándolos como entidades independientes y no como parte indeterminada del entorno como en el nivel 1). En este artículo nos enfocamos en el nivel 2, estudiando la interacción directa entre los agentes involucrados en un proceso de aprendizaje. Cada agente se asume capaz de aprender de forma incremental a partir de los datos que recibe, lo que significa que cada agente puede actualizar su conjunto de creencias B para mantenerlo consistente con el conjunto completo de información K que ha recibido del entorno o de otros agentes. En tal caso, diremos que es a-inconsistente. Aquí, el conjunto de creencias B representa conocimiento hipotético que por lo tanto puede ser revisado, mientras que el conjunto de información K representa conocimiento cierto, compuesto por observaciones y hechos no revisables. Además, suponemos que al menos una parte Bc de las creencias de cada agente es común a todos los agentes y debe mantenerse de esa manera. Por lo tanto, una actualización de este conjunto común Bc por parte del agente r debe provocar una actualización de Bc para toda la comunidad de agentes. Nos lleva a definir cuál es la mas-consistencia de un agente con respecto a la comunidad. El proceso de actualización de las creencias de la comunidad cuando uno de sus miembros recibe nueva información puede entonces definirse como el proceso de mantenimiento de la consistencia que garantiza que cada agente en la comunidad permanecerá más consistente. Este proceso de mantenimiento de la mas-consistencia de un agente al recibir nueva información le otorga el rol de aprendiz e implica la comunicación con otros agentes que actúan como críticos. Sin embargo, los agentes no están especializados y a su vez pueden ser aprendices o críticos, ninguno de ellos está limitado a un rol específico. Las piezas de información se distribuyen entre los agentes, pero pueden ser redundantes. No hay memoria central. El trabajo descrito aquí tiene su origen en un trabajo anterior sobre el aprendizaje en un sistema multiagente intencional utilizando un formalismo BDI [6]. En ese trabajo, los agentes tenían planes, cada uno de ellos asociado con un contexto que define en qué condiciones puede ser activado. Los planes (cada uno con su propio contexto) eran comunes a todo el conjunto de agentes en la comunidad. Los agentes tuvieron que adaptar su plan en función del contexto, dependiendo del fracaso o éxito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo a otros agentes ejemplos (éxitos o fracasos de planes). Sin embargo, este trabajo carecía de un protocolo de aprendizaje colectivo que permitiera una verdadera autonomía del sistema multiagente. El estudio de dicho protocolo es el objeto del presente artículo. En la sección 2 definimos formalmente la mas-consistencia de un mecanismo de actualización para todo el MAS y proponemos un mecanismo de actualización genérico demostrado que es mas consistente. En la sección 3 describimos SMILE, un aprendiz de conceptos multiagente incremental que aplica nuestro mecanismo de actualización mas consistente para el aprendizaje colaborativo de conceptos. La sección 4 describe varios experimentos sobre SMILE y discute varios problemas, incluyendo cómo varían la precisión y la simplicidad de la hipótesis actual al comparar el aprendizaje de un solo agente y el aprendizaje de múltiples agentes. En la sección 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la sección 6 discutiendo investigaciones adicionales sobre el aprendizaje más consistente. MODELO FORMAL 2.1 Definiciones y marco En esta sección, presentamos una formulación general del aprendizaje incremental colectivo en un sistema cognitivo de múltiples agentes. Representamos un MAS como un conjunto de agentes r1, ..., rn. Cada agente ri tiene un conjunto de creencias Bi que consiste en todo el conocimiento revisable que posee. Parte de estos conocimientos deben ser compartidos con otros agentes. La parte de Bi que es común a todos los agentes se denota como BC. Esta parte común provoca una dependencia entre los agentes. Si un agente ri actualiza su conjunto de creencias Bi a Bi, cambiando en el proceso BC en BC, entonces todos los demás agentes rk deben actualizar su conjunto de creencias Bk a Bk para que BC ⊆ Bk. Además, cada agente ri ha almacenado cierta información Ki. Suponemos que alguna propiedad de consistencia Cons(Bi, Ki) puede ser verificada por el agente mismo entre sus creencias Bi y su información Ki. Como se dijo antes, Bi representa el conocimiento que podría ser revisado, mientras que Ki representa hechos observados, considerados verdaderos, y que posiblemente puedan contradecir a Bi. Definición 1. a-consistencia de un agente Un agente ri es a-consistente si Cons(Bi, Ki) es verdadero. Ejemplo 1. El agente r1 tiene un conjunto de planes que se encuentran en la parte común BC de B1. Cada plan P tiene un contexto desencadenante d(P) (que actúa como una precondición) y un cuerpo. Alguna pieza de información k podría ser el plan P, desencadenado en la situación s, ha fallado a pesar de que s es una instancia de d(P). Si esta pieza de información se agrega a K1, entonces el agente r1 ya no es a-consistente: Cons(B1, K1 ∪ k) es falso. También queremos definir alguna noción de consistencia para todo el MAS dependiendo de los conjuntos de creencias e información de sus elementos constituyentes. Primero definiremos la consistencia de un agente ri con respecto a su conjunto de creencias Bi y su propio conjunto de información Ki junto con todos los conjuntos de información K1...Kn de los otros agentes del MAS. Simplemente lo haremos considerando cuál sería la a-consistencia del agente si tuviera la información de todos los demás agentes. Llamamos a esta noción la mas-consistencia: Definición 2. Un agente ri es mas-consistente si Cons(Bi, Ki ∪ K) es verdadero, donde K = ∪j∈{1,..,n}−{i}Kj 1 es el conjunto de toda la información de los otros agentes del MAS. 1 Lo notaremos como ∪ Kj cuando el contexto sea similar. Ejemplo 2. Usando el ejemplo anterior, supongamos que la pieza de información k está incluida en la información K2 del agente r2. Si la pieza de información no se transmite a r1, y por lo tanto no se agrega a K1, r1 permanece a-consistente. Sin embargo, r1 no es tan consistente como k en el conjunto K de toda la información del MAS. La consistencia global del MAS es simplemente la mas-consistencia de todos sus agentes. Definición 3. La consistencia de un MAS A MAS r1,...,rn es consistente si todos sus agentes ri son masconsistentes. Ahora definimos las propiedades requeridas para un mecanismo de revisión M que actualiza a un agente ri cuando recibe una pieza de información k. En lo siguiente, supondremos que: • La actualización siempre es posible, es decir, un agente siempre puede modificar su conjunto de creencias Bi para recuperar su a-consistencia. Diremos que cada agente es localmente eficiente. • Considerando dos conjuntos de información Cons(Bi, K1) y Cons(Bi, K2), también tenemos Cons(Bi, K1 ∪ K2). Es decir, la a-consistencia de los agentes es aditiva. • Si una pieza de información k relacionada con el conjunto común BC es consistente con un agente, es consistente con todos los agentes: para todos los pares de agentes (ri, rj) tales que Cons(Bi, Ki) y Cons(Bj, Kj) son verdaderos, tenemos, para toda pieza de información k: Cons(Bi, Ki ∪ k) si y solo si Cons(Bj, Kj ∪ k). En tal caso, diremos que el MAS es coherente. Esta última condición simplemente significa que el conjunto de creencias común BC es independiente de las posibles diferencias entre los conjuntos de creencias Bi de cada agente ri. En el caso más simple, B1 = ... = Bn = BC. M también será visto como un mecanismo de aprendizaje incremental y representado como una aplicación que cambia Bi en Bi. En lo siguiente, anotaremos ri(Bi, Ki) para ri cuando sea útil. Definición 4. a-consistencia de una revisión Un mecanismo de actualización M es a-consistente si, para cualquier agente ri y cualquier pieza de información k que llegue a ri, la a-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki) a-consistente ⇒ ri(Bi, Ki) a-consistente, donde Bi = M(Bi) y Ki = Ki ∪ k es el conjunto de toda la información de otros agentes del MAS. De la misma manera, definimos la mas-consistencia de un mecanismo de revisión como la a-consistencia de este mecanismo si los agentes disponen de toda la información en el MAS. En lo siguiente, anotaremos, si es necesario, ri(Bi, Ki, K) para el agente ri en el MAS r1 . . . rn. Definición 5. mas-consistencia de una revisión Un mecanismo de actualización Ms es mas-consistente si para todo agente ri y toda pieza de información k que llega a ri, la mas-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki, K) más-consistente ⇒ ri(Bi, Ki, K) más-consistente, donde Bi = Ms(Bi), Ki = Ki ∪ k, y K = ∪Kj es el conjunto de toda la información del MAS. El Sexto Internacional. En última instancia, cuando un agente aplica un mecanismo mas-consistente al recibir una nueva pieza de información, un efecto secundario deseable del mecanismo debería ser que todos los demás agentes permanezcan mas-consistentes después de cualquier modificación de la parte común BC, es decir, el MAS en sí mismo debería volver a ser consistente. Esta propiedad se define de la siguiente manera: Definición 6. La fuerte mas-consistencia de un mecanismo de actualización. Un mecanismo de actualización Ms es fuertemente mas-consistente si - Ms es mas-consistente, y - la aplicación de Ms por un agente preserva la consistencia del MAS. 2.2 Un mecanismo de actualización fuertemente mas-consistente. La idea general es que, dado que la información está distribuida entre todos los agentes del MAS, debe haber alguna interacción entre el agente aprendiz y los demás agentes en un mecanismo de actualización fuertemente mas-consistente Ms. Para garantizar su mas-consistencia, Ms estará constituido por aplicaciones reiteradas por parte del agente aprendiz ri de un mecanismo interno a-consistente M, seguido por algunas interacciones entre ri y los otros agentes, hasta que ri recupere su mas-consistencia. Describimos a continuación un mecanismo, primero con una descripción de una interacción, luego una iteración y finalmente una declaración de la condición de terminación del mecanismo. El mecanismo es activado por un agente ri al recibir una pieza de información k que interrumpe la mas-consistencia. Tomaremos M(Bi) como el conjunto de creencias del agente aprendiz ri después de una actualización, BC la parte común modificada por ri, y Bj el conjunto de creencias de otro agente rj inducido por la modificación de su parte común BC en BC. Una interacción I(ri, rj) entre el agente aprendiz ri y otro agente rj, actuando como crítico, está constituida por los siguientes pasos: • el agente ri envía la actualización BC de la parte común de sus creencias. Habiendo aplicado su mecanismo de actualización, ri es a-consistente. • El agente rj verifica la modificación Bj de sus creencias inducida por la actualización BC. Si esta modificación conserva su a-consistencia, rj adopta esta modificación. El agente rj envía ya sea una aceptación de BC o una negación junto con una (o más) pieza(s) de información k tal que Cons(Bj, k) es falso. Una iteración de Ms estará compuesta por: • la recepción por parte del agente aprendiz ri de una pieza de información y la actualización M(Bi) restaurando su consistencia • un conjunto de interacciones I(ri, rj) (en las cuales varios agentes críticos posiblemente puedan participar). Si al menos una pieza de información k es transmitida a ri, la adición de k necesariamente hará que ri sea inconsistente y entonces ocurrirá una nueva iteración. Este mecanismo termina cuando ningún agente puede proporcionar tal pieza de información k. Cuando es el caso, se restaura la masconsistencia del agente aprendiz ri. Proposición 1. Dejen que r1,...,rn sea un MAS consistente en el que el agente ri recibe una pieza de información k que rompe su consistencia, y M sea un mecanismo interno de actualización a-consistente. El mecanismo de actualización descrito anteriormente por Ms es altamente mas-consistente. Prueba. La prueba se deriva directamente de la descripción del mecanismo. Este mecanismo asegura que cada vez que un agente recibe un evento, su mas-consistencia será restaurada. Como los otros agentes adoptan la actualización final BC, todos son mas-coherentes y el MAS es coherente. Por lo tanto, Ms es un mecanismo de actualización fuertemente consistente. En el mecanismo descrito anteriormente, el agente aprendiz es el único que recibe y memoriza información durante la ejecución del mecanismo. Se asegura de que Ms termine. Las piezas de información transmitidas por otros agentes y memorizadas por el agente aprendiz son redundantes, ya que ya están presentes en el MAS, más precisamente en la memoria de los agentes críticos que las transmitieron. Se debe tener en cuenta que el mecanismo propuesto por la Sra. aquí no indica explícitamente el orden ni el alcance de las interacciones. Consideraremos en lo siguiente que la propuesta de modificación BC se envía secuencialmente a los diferentes agentes (mecanismo síncrono). Además, la respuesta de un agente crítico solo contendrá una pieza de información inconsistente con la modificación propuesta. Diremos que la respuesta del agente es mínima. Este mecanismo, siendo sincrónico con una respuesta mínima, minimiza la cantidad de información transmitida por los agentes. Ahora lo ilustraremos en el caso del aprendizaje de conceptos multiagente. 3. APRENDIZAJE INCREMENTAL DE MÚLTIPLES AGENTES 3.1 La tarea de aprendizaje Experimentamos el mecanismo propuesto anteriormente en el caso del aprendizaje conceptual MAS incremental. Aquí consideramos un lenguaje de hipótesis en el cual una hipótesis es una disyunción de términos. Cada término es una conjunción de átomos de un conjunto A. Un ejemplo está representado por una etiqueta + o − y una descripción 2 compuesta por un subconjunto de átomos e ⊆ A. Un término abarca un ejemplo si sus átomos constituyentes están incluidos en el ejemplo. Una hipótesis abarca un ejemplo si uno de sus términos lo abarca. Esta representación se utilizará a continuación para aprender fórmulas booleanas. Los literales negativos se representan aquí mediante átomos adicionales, como not − a. La fórmula booleana f = (a ∧ b) ∨ (b ∧ ¬c) se escribirá entonces como (a ∧ b) ∨ (b ∧ no − c). Un ejemplo positivo de f, como {no − a, b, no − c}, representa un modelo para f. 3.2 Proceso de aprendizaje incremental El proceso de aprendizaje es un mecanismo de actualización que, dado una hipótesis actual H, una memoria E = E+ ∪ E− llenada con los ejemplos recibidos previamente, y un nuevo ejemplo positivo o negativo e, produce una nueva hipótesis actualizada. Antes de esta actualización, la hipótesis dada es completa, lo que significa que cubre todos los ejemplos positivos de E+, y 2 Cuando no haya posibilidad de confusión, la palabra ejemplo se utilizará para referirse al par (etiqueta, descripción) así como a la descripción sola. 166 La Sexta Conferencia Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) es coherente, lo que significa que no cubre ningún ejemplo negativo de E−. Después de la actualización, la nueva hipótesis debe ser completa y coherente con el nuevo estado de memoria E ∪ {e}. Describimos a continuación nuestro mecanismo de actualización de agente único, inspirado en un trabajo previo sobre aprendizaje incremental[7]. En lo siguiente, una hipótesis H para la fórmula objetivo f es una lista de términos h, cada uno de ellos siendo una conjunción de átomos. H es coherente si todos los términos h son coherentes, y H es completo si cada elemento de E+ está cubierto por al menos un término h de H. Cada término es, por construcción, la lgg (generalización general menos general) de un subconjunto de instancias positivas {e1, ..., en}, es decir, el término más específico que cubre {e1, ..., en}. El operador lgg se define considerando ejemplos como términos, por lo que denotamos como lgg(e) al término más específico que cubre e, y como lgg(h, e) al término más específico que es más general que h y que cubre e. Restringir el término a lgg es la base de muchos algoritmos de aprendizaje de abajo hacia arriba (por ejemplo [5]). En la tipología propuesta por [9], nuestro mecanismo de actualización es un aprendiz incremental con memoria completa de instancias: el aprendizaje se realiza mediante actualizaciones sucesivas y se almacenan todos los ejemplos. El mecanismo de actualización depende de la hipótesis en curso H, los ejemplos en curso E+ y E−, y el nuevo ejemplo e. Hay tres casos posibles: • e es positivo y H cubre e, o e es negativo y H no cubre e. No se necesita actualización, H ya es completo y coherente con E ∪ {e}. • e es positivo y H no cubre e: e se denota como un contraejemplo positivo de H. Luego buscamos generalizar a su vez los términos h de H. Tan pronto como se encuentre una generalización correcta h = lgg(h, e), h reemplaza a h en H. Si hay un término que es menos general que h, se descarta. Si ninguna generalización es correcta (es decir, coherente), H ∪ lgg(e) reemplaza a H. • e es negativo y H cubre e: e se denota como un contraejemplo negativo de H. Cada término h que cubre e es entonces descartado de H y reemplazado por un conjunto de términos {h1, ...., hn} que, en su totalidad, es coherente con E− ∪ {e} y que cubre los ejemplos de E+ no cubiertos por H − {h}. Los términos de la hipótesis final H que son menos generales que otros son descartados de H. Ahora describiremos el caso en el que e = e− es un ejemplo negativo cubierto. Las siguientes funciones se utilizan aquí: • coveredOnlyBy(h, E+) da el subconjunto de E+ cubierto por h y ningún otro término de H. • bestCover(h1, h2) da h1 si h1 cubre más ejemplos de uncoveredPos que h2, de lo contrario da h2. • covered(h) da los elementos de uncoveredPos cubiertos por h. // Especialización de cada h cubriendo e− para cada h de H cubriendo e− hacer H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= átomos que no están ni en e− ni en h mientras (uncoveredPos = ∅) hacer // buscando la mejor especialización de h hc=h best=⊥ // ⊥ no cubre ningún ejemplo para cada a de Ar hacer hc= h ∧ a best = bestCover(hc, best) finpara Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) finmientras finpara Los términos de H que son menos generales que otros son descartados. Ten en cuenta que este mecanismo tiende tanto a hacer una actualización mínima de la hipótesis actual como a minimizar el número de términos en la hipótesis, en particular descartando términos menos generales que otros después de actualizar una hipótesis. 3.3 Aprendizaje colectivo Si H es la hipótesis actual, Ei es la memoria actual de ejemplos del agente ri y E es el conjunto de todos los ejemplos recibidos por el sistema, la notación de la sección 2 se convierte en Bi = BC = H, Ki = Ei y K = E. Cons(H, Ei) establece que H es completo y coherente con Ei. En tal caso, ri es a-consistente. La pieza de información k recibida por el agente ri es aquí simplemente un ejemplo e junto con su etiqueta. Si e es tal que la hipótesis actual H no es completa ni coherente con Ei ∪ {e}, e contradice a H: ri se vuelve a-inconsistente, y por lo tanto el MAS ya no es consistente. La actualización de una hipótesis cuando llega un nuevo ejemplo es un mecanismo a-consistente. Siguiendo la proposición 1, este mecanismo puede ser utilizado para producir un mecanismo fuerte mas-consistente: al recibir un nuevo ejemplo en el MAS por un agente r, posiblemente se necesite una actualización y, después de un conjunto de interacciones entre r y los otros agentes, resulta en una nueva hipótesis compartida por todos los agentes y que restaura la consistencia del MAS, es decir, que es completa y coherente con el conjunto ES de todos los ejemplos presentes en el MAS. Es claro que al minimizar el número de modificaciones de hipótesis, este mecanismo sincrónico y minimalista reduce el número de ejemplos recibidos por el aprendiz de otros agentes, y por ende, el número total de ejemplos almacenados en el sistema. 4. EXPERIMENTOS En lo siguiente, aprenderemos una fórmula booleana que es una prueba difícil para el método de aprendizaje: el 11-multiplexor (ver [4]). Se refiere a 3 atributos booleanos de dirección a0, a1, a2 y 8 atributos booleanos de datos d0, ..., d7. La fórmula f11 se cumple si el número codificado por los 3 atributos de dirección es el número de un atributo de datos cuyo valor es 1. Su fórmula es la siguiente: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0). Hay 2048 = 211 posibles ejemplos, la mitad de los cuales son positivos (lo que significa que satisfacen f11) mientras que la otra mitad es negativa. Un experimento suele estar compuesto por 50 pruebas. Cada ejecución corresponde a una secuencia de 600 ejemplos que son aprendidos de forma incremental por un Sistema Multiagente con n agentes. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 167 (n-MAS). Un número de variables como la precisión (es decir, la frecuencia de clasificación correcta de un conjunto de ejemplos no vistos), el tamaño de la hipótesis (es decir, el número de términos en la fórmula actual) o el número de ejemplos almacenados, se registra cada vez que el sistema recibe 25 ejemplos durante esas ejecuciones. En el protocolo que se utiliza aquí, un nuevo ejemplo se envía a un agente aleatorio cuando el MAS es consistente. El siguiente ejemplo será enviado a su vez a otro agente cuando la consistencia del MAS haya sido restaurada. De esta manera simulamos una especie de aprendizaje lento: la frecuencia de llegada de ejemplos es lenta en comparación con el tiempo que lleva una actualización. 4.1 Eficiencia del aprendizaje conceptual en MAS 4.1.1 Tiempo de ejecución Discutimos brevemente aquí el tiempo de ejecución del aprendizaje en el MAS. Se debe tener en cuenta que todo el conjunto de acciones e interacciones en el MAS se simula en un solo procesador. La Figura 1 muestra que el tiempo depende linealmente del número de agentes. Al final de la parte más activa del aprendizaje (200 ejemplos), un 16MAS ha tomado 4 veces más tiempo de aprendizaje que un 4-MAS. Este tiempo de ejecución representa el conjunto completo de aprendizaje y la Figura 1: Tiempo de ejecución de un n-MAS (desde n = 2 en la parte inferior hasta n = 20 en la parte superior). actividad de comunicación y sugiere el costo de mantener una hipótesis de aprendizaje consistente en un MAS compuesto por agentes autónomos. 4.1.2 Redundancia en la memoria del MAS Estudiamos ahora la distribución de los ejemplos en la memoria del MAS. La redundancia se escribe RS = nS/ne, donde nS es el número total de ejemplos almacenados en el MAS, que es la suma de los tamaños de las memorias de ejemplos de los agentes Ei, y ne es el número total de ejemplos recibidos del entorno en el MAS. En la figura 2, comparamos las redundancias en MAS de 2 a 20 agentes. Hay un pico que se mueve lentamente de 80 a 100 ejemplos, que representa la cantidad de ejemplos para los cuales el aprendizaje es más activo. Para 20 agentes, la redundancia máxima no es más de 6, lo cual es mucho menor que el valor teórico máximo de 20. Ten en cuenta que cuando el aprendizaje se vuelve menos activo, la redundancia tiende hacia su valor mínimo 1: cuando ya no hay más actualizaciones, los ejemplos son solo la Figura 2: Redundancia de ejemplos almacenados en un nMAS (de n = 2 en la parte inferior a n = 20 en la parte superior) almacenados por el agente que los recibe. Un n-MAS selecciona una solución más simple que un solo agente. El mecanismo propuesto tiende a minimizar el número de términos en la hipótesis seleccionada. Durante el aprendizaje, el tamaño de la hipótesis actual crece más allá del óptimo, y luego disminuye cuando el MAS converge. En el banco de pruebas Multiplexer 11, el número óptimo de términos es 8, pero también existen fórmulas equivalentes con más términos. Es interesante notar que en este caso el 10-MAS converge hacia una solución exacta más cercana al número óptimo de términos (en este caso 8) (ver Figura 3). Después de haber presentado 1450 ejemplos, tanto el 1-MAS como el 10-MAS han aprendido exactamente el concepto (las precisiones respectivas son 0.9999 y 1), pero el agente individual expresa en promedio el resultado como una DNF de 11.0 términos, mientras que el 10-MAS lo expresa como una DNF de 8.8 términos. Sin embargo, para algunas otras funciones booleanas encontramos que durante el aprendizaje, 1-MAS siempre produce hipótesis más grandes que 10-MAS, pero que ambos MAS convergen a hipótesis con resultados de tamaño similar. 4.1.4 Un n-MAS es más preciso que un agente único. La Figura 4 muestra la mejora proporcionada por un MAS con n agentes en comparación con un agente único. Esta mejora no era especialmente esperada, porque ya sea que tengamos uno o n agentes, cuando se le dan N ejemplos al MAS, tiene acceso a la misma cantidad de información, mantiene solo una hipótesis en curso y utiliza el mismo algoritmo básico de revisión cada vez que un agente tiene que modificar la hipótesis actual. Ten en cuenta que si la precisión de los MAS de 1, 2, 4 y 10 es significativamente diferente, mejorando a medida que aumenta el número de agentes, no hay una diferencia clara más allá de este punto: la curva de precisión de los MAS de 100 agentes es muy similar a la de los MAS de 10 agentes. 4.1.4.1 Fórmulas booleanas. Para evaluar esta mejora de precisión, hemos experimentado nuestro protocolo en otros problemas de aprendizaje de funciones booleanas. Como en el caso del Multiplexor-11, estas funciones 168 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 3: Tamaño de la hipótesis construida por 1 y 10MAS: el caso M11. Figura 4: Precisión de un n-MAS: el caso M11 (de abajo hacia arriba, n = 1, 2, 4, 10, 100). Se aprenden en forma de DNF3 más o menos sintácticamente complejos (es decir, con más o menos términos conjuntivos en la DNF), pero también son más o menos difíciles de aprender, ya que puede ser difícil encontrar su camino en el espacio de hipótesis para alcanzarlos. Además, la presencia en la descripción de atributos irrelevantes (es decir, atributos que no pertenecen al DNF objetivo) hace que el problema sea más difícil. Los siguientes problemas han sido seleccionados para experimentar con nuestro protocolo: (i) el multiplexor-11 con 9 atributos irrelevantes: M11 9, (ii) el multiplexor-20 M20 (con 4 bits de dirección y 16 bits de datos), (iii) un problema de paridad difícil (ver [4]) el Xorp m: debe haber un número impar de bits con valor 1 en los primeros p atributos para que la instancia sea positiva, los p bits restantes son irrelevantes, y (iv) una fórmula DNF simple (a ∧ b ∧ c) ∨ (c ∧ d ∧ e) ∨ (e ∧ f ∧ g) ∧ (g ∧ h ∧ i) con 19 atributos irrelevantes. La siguiente tabla resume alguna información sobre estos problemas, proporcionando el número total de atributos, incluidos los irrelevantes, el número de atributos irrelevantes en Forma Normal Disyuntiva 3, el número mínimo de términos de la DNF correspondiente, y el número de ejemplos de aprendizaje utilizados. Pb att. irre. att. términos ex. A continuación se presentan los resultados de precisión de nuestro mecanismo de aprendizaje con un solo agente y un MAS de 10 agentes, junto con los resultados de dos algoritmos estándar implementados con el entorno de aprendizaje WEKA[16]: JRip (una implementación de RIPPER[2]) e Id3[12]. Para los experimentos con JRip e Id3, medimos la precisión media en 50 pruebas, separando aleatoriamente los ejemplos en un conjunto de aprendizaje y un conjunto de prueba cada vez. Los parámetros de JRip e Id3 son los predeterminados, excepto que JRip se utiliza sin poda. La siguiente tabla muestra los resultados: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 Es claro que los problemas difíciles se resuelven mejor con más agentes (ver por ejemplo xor5 15). Creemos que estos beneficios, que pueden ser importantes con un número creciente de agentes, se deben al hecho de que cada agente realmente memoriza solo parte del número total de ejemplos, y esta parte es seleccionada en parte por otros agentes como contraejemplos, lo que provoca un mayor número de actualizaciones de hipótesis actuales y, por lo tanto, una mejor exploración del espacio de hipótesis. 4.1.4.2 Problemas de base de datos de ML. También realizamos experimentos con algunos problemas no booleanos. Consideramos solo problemas de dos clases (positivo/negativo), tomados de la base de datos de problemas de aprendizaje de UCIs. En todos estos problemas, los ejemplos se describen como un vector de pares (atributo, valor). Los dominios de valor pueden ser booleanos, numéricos (conjunto totalmente ordenado) o nominales (conjunto no ordenado). Un conjunto adecuado de átomos A debe ser constituido para cada problema. Por ejemplo, si a es un atributo numérico, definimos como máximo k umbrales si, dando k+1 intervalos de densidad uniforme. Por lo tanto, cada umbral distintivo si da dos átomos, uno ≤ si y otro > si. En nuestros experimentos, tomamos un número máximo de umbral k = 8. Por ejemplo, en el caso del problema de iono, había 34 atributos numéricos, y una instancia se describe con 506 átomos. A continuación se presentan los resultados de precisión de nuestro sistema junto con los resultados anteriores. La columna Nb ex. se refiere al 4. La probabilidad de que el valor de a esté en cualquier intervalo es constante. El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 169 número de ejemplos utilizados para el aprendizaje5. La columna (1) representa los valores de precisión mínima y máxima para los treinta y tres clasificadores probados en [8]. La columna (2) representa los resultados de [13], donde se comparan varios métodos de aprendizaje con métodos de aprendizaje en conjunto utilizando conjuntos de clasificadores ponderados. La columna S-1 y S-10 dan la precisión de SMILE con 1 y 10 agentes, respectivamente. Esta tabla muestra que el algoritmo incremental correspondiente al caso de un solo agente, proporciona resultados honorables en relación a los métodos clásicos no incrementales que utilizan hipótesis más grandes y complejas. En algunos casos, hay una mejora en la precisión con un MAS de 10 agentes. Sin embargo, con datos de referencia de este tipo, que suelen ser ruidosos, la dificultad no radica realmente en la forma en que se explora el espacio de búsqueda, por lo que la mejora observada no siempre es significativa. El mismo tipo de fenómeno se ha observado con métodos dedicados a problemas booleanos difíciles [4]. 4.2 Sincronización de MAS En este caso consideramos que n agentes individuales aprenden sin interacciones y en un momento dado comienzan a interactuar, formando así un MAS. El propósito es observar cómo los agentes aprovechan la colaboración cuando parten de diferentes estados de creencias y memorias. En esta sección comparamos un 1-MAS, un 10-MAS (ref) y un 10-MAS (100sync) cuyos agentes no se comunicaron durante la llegada de los primeros 100 ejemplos (10 por agentes). Las tres curvas de precisión se muestran en la figura 5. Al comparar la curva del agente individual con la del 10-MAS sincronizado, podemos observar que después del inicio de la sincronización, es decir, en 125 ejemplos, las precisiones son idénticas. Esto era esperado ya que tan pronto como un ejemplo e recibido por el MAS contradice la hipótesis actual del agente ra que lo recibe, este agente realiza una actualización y su nueva hipótesis es propuesta a los otros agentes para su crítica. Por lo tanto, este primer ejemplo contradictorio lleva al MAS a alcanzar coherencia en relación con todo el conjunto de ejemplos presentes en la memoria de los agentes. Una mayor precisión, correspondiente a un 10-MAS, se obtiene más tarde, a partir del ejemplo 175. En otras palabras, el beneficio de una mejor exploración del espacio de investigación se obtiene ligeramente más tarde en el proceso de aprendizaje. Ten en cuenta que esta sincronización ocurre de forma natural en todas las situaciones en las que los agentes tienen, por alguna razón, una divergencia entre su hipótesis y la memoria del sistema. Esto incluye la fusión de dos MAS en una sola o la llegada de nuevos agentes en un MAS existente. 4.3 Experimentos sobre el aprendizaje asincrónico: el efecto de un gran flujo de datos. Para ttt y kr-vs-kp, nuestro protocolo no utilizó más de 574 y 958 ejemplos de aprendizaje respectivamente, por lo que colocamos otro número en la columna. Figura 5: Precisión de un 1-MAS, un 10-MAS y un 10-MAS sincronizado después de 100 ejemplos. En este experimento relajamos nuestro modo de aprendizaje lento: los ejemplos se envían a una velocidad determinada al MAS. El flujo de ejemplos resultante se mide en ms−1, y representa la cantidad de ejemplos enviados al MAS cada milisegundo. Cuando el flujo es demasiado grande, el MAS no puede alcanzar la consistencia del MAS al recibir un ejemplo del entorno antes de que llegue un nuevo ejemplo. Esto significa que el proceso de actualización, iniciado por el agente r0 al recibir un ejemplo, puede estar incompleto cuando un nuevo ejemplo es recibido por r0 u otro agente r1. Como resultado, un agente crítico puede tener que enviar contraejemplos de hipótesis enviadas por varios agentes en el instante t. Sin embargo, en nuestro entorno, a medida que los agentes memorizan todos los ejemplos que reciben cuando finaliza el flujo, el MAS alcanza necesariamente consistencia MAS con respecto a todos los ejemplos recibidos hasta el momento. En nuestros experimentos, aunque la curva de aprendizaje se ralentiza durante la fase intensa de aprendizaje (correspondiente a una baja precisión de las hipótesis actuales), el MAS aún logra alcanzar una hipótesis satisfactoria más adelante, ya que hay menos contraejemplos en el flujo de ejemplos. En la Figura 6 comparamos las precisiones de dos 11-MAS respectivamente sometidos a flujos de ejemplos de diferentes tasas al aprender la fórmula M11. La curva de aprendizaje del MAS al recibir un ejemplo a una velocidad de 1/33 ms−1 casi no se ve alterada (ver Figura 4), mientras que el MAS a 1/16 ms−1 primero se ralentiza severamente antes de alcanzar al primero. 5. TRABAJOS RELACIONADOS Desde el 96 [15], se han realizado varios trabajos sobre el aprendizaje en Sistemas Multiagente, pero muy pocos sobre el aprendizaje de conceptos. En [11] el MAS realiza una forma de aprendizaje en conjunto en la que los agentes son aprendices perezosos (no se mantiene una representación explícita) y venden ejemplos inútiles a otros agentes. En [10] cada agente observa todos los ejemplos pero solo percibe una parte de su representación. En el aprendizaje de conceptos en línea mutuo, los agentes convergen hacia una hipótesis única, pero cada agente produce ejemplos desde su propia representación del concepto, lo que resulta en una especie de sincronización en lugar de un aprendizaje de conceptos puro. 170 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Precisión de dos sistemas multiagente asincrónicos de 11 agentes (tasas de ejemplo de 1/33ms−1 y 1/16ms−1). 6. CONCLUSIÓN Hemos presentado y experimentado un protocolo para el aprendizaje de conceptos en línea de MAS. La característica principal de este mecanismo de aprendizaje colaborativo es que mantiene una propiedad de consistencia: aunque durante el proceso de aprendizaje cada agente solo recibe y almacena, con cierta redundancia limitada, parte de los ejemplos recibidos por el MAS, en cualquier momento la hipótesis actual es consistente con todo el conjunto de ejemplos. Las hipótesis de nuestros experimentos no abordan los problemas de los MAS distribuidos, como fallos (por ejemplo, mensajes perdidos o corruptos) u otras fallas en general (crash, fallos bizantinos, etc.). Sin embargo, nuestro marco de trabajo es abierto, es decir, los agentes pueden salir del sistema o ingresar a él mientras se preserva el mecanismo de consistencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente crítico se bloquea o no responde, se garantiza la consistencia con los otros críticos (dentro de los agentes restantes). En [1], se ha aplicado un enfoque similar a los problemas de abducción en MAS: las hipótesis a mantener, dada una información incompleta, son entonces hechos o afirmaciones. El trabajo adicional se refiere en primer lugar a acoplar la inducción y la abducción para realizar un aprendizaje colaborativo de conceptos cuando los ejemplos son solo parcialmente observados por cada agente, y en segundo lugar, a investigar el aprendizaje de memoria parcial: cómo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados. Agradecimientos Estamos muy agradecidos a Dominique Bouthinon por implementar las modificaciones tardías en SMILE, facilitando mucho nuestros experimentos. Parte de este trabajo se realizó durante la visita del primer autor al Atelier De BioInformatique de la Universidad Paris VI, Francia. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En DALT-2006, mayo de 2006. [2] W. W. Cohen. Inducción de reglas rápida y efectiva. En ICML, páginas 115-123, 1995. [3] C. B. D.J. Newman, S. Hettich y C. Merz. Repositorio de bases de datos de aprendizaje automático de UCI, 1998. [4] S. Esmeir y S. Markovitch. Algoritmos basados en anticipación para la inducción en cualquier momento de árboles de decisión. En ICMLO4, páginas 257-264. Morgan Kaufmann, 2004. [5] J. F¨urnkranz. \n\nMorgan Kaufmann, 2004. [5] J. F¨urnkranz. Una patología de la escalada de colina de abajo hacia arriba en el aprendizaje inductivo de reglas. En ALT, volumen 2533 de LNCS, páginas 263-277. Springer, 2002. [6] A. Guerra-Hernández, A. ElFallah-Seghrouchni y H. Soldano. Aprendizaje en sistemas multiagente BDI. En CLIMA IV, volumen 3259, páginas 218-233. Springer Verlag, 2004. [7] M. Henniche. \n\nSpringer Verlag, 2004. [7] M. Henniche. Mgi: un algoritmo incremental de abajo hacia arriba. En la Conferencia IEEE de Australia y Nueva Zelanda sobre Sistemas de Información Inteligente, páginas 347-351, 1994. [8] T.-S. Lim, W.-Y. Loh, y Y.-S. Shih. Una comparación de la precisión de predicción, complejidad y tiempo de entrenamiento de treinta y tres algoritmos de clasificación antiguos y nuevos. Aprendizaje automático, 40(3):203-228, 2000. [9] M. A. Maloof y R. S. Michalski. Aprendizaje incremental con memoria parcial de instancias. I'm sorry, but the sentence \"Artif.\" is not a complete sentence. Can you provide more context or a complete sentence for me to translate to Spanish? Intell., 154(1-2):95-126, 2004. [10] P. J. Modi y W.-M. Shen. Aprendizaje colaborativo multiagente para tareas de clasificación. En AGENTS 01, páginas 37-38. ACM Press, 2001. [11] S. Onta˜non y E. Plaza. Reciclaje de datos para el <br>aprendizaje multiagente</br>. En ICML 05, páginas 633-640. ACM Press, 2005. [12] J. R. Quinlan. \n\nACM Press, 2005. [12] J. R. Quinlan. Inducción de árboles de decisión. Aprendizaje automático, 1(1):81-106, 1986. [13] U. R¨uckert y S. Kramer. Hacia límites ajustados para el aprendizaje de reglas. En ICML 04 (Conferencia Internacional sobre Aprendizaje Automático), página 90, Nueva York, NY, EE. UU., 2004. ACM Press. [14] J. Wang y L. Gasser. Aprendizaje de conceptos en línea mutuo para múltiples agentes. En AAMAS, páginas 362-369. ACM Press, 2002. [15] G. Weiß y S. Sen, editores. Adaptación y Aprendizaje en Sistemas Multiagente, volumen 1042 de las Notas de Conferencia en Ciencias de la Computación. Springer, 1996. [16] I. H. Witten y E. Frank. Minería de datos: Herramientas y técnicas prácticas de aprendizaje automático con implementaciones en Java. Morgan Kaufmann, octubre de 1999. La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 171 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "collaborative concept learning": {
            "translated_key": "aprendizaje colaborativo de conceptos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "SMILE: Sound Multi-agent Incremental LEarning ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av.",
                "du pr´esident Kennedy, 75116 Paris Henry Soldano LIPN, UMR 7030 CNRS, University Paris-Nord, 99 Av.",
                "J-B Clement, 93430, Villetaneuse ABSTRACT This article deals with the problem of collaborative learning in a multi-agent system.",
                "Here each agent can update incrementally its beliefs B (the concept representation) so that it is in a way kept consistent with the whole set of information K (the examples) that he has received from the environment or other agents.",
                "We extend this notion of consistency (or soundness) to the whole MAS and discuss how to obtain that, at any moment, a same consistent concept representation is present in each agent.",
                "The corresponding protocol is applied to supervised concept learning.",
                "The resulting method SMILE (standing for Sound Multiagent Incremental LEarning) is described and experimented here.",
                "Surprisingly some difficult boolean formulas are better learned, given the same learning set, by a Multi agent system than by a single agent.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Concept learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent system General Terms Experimentation, Algorithms, Measurement, Performance 1.",
                "INTRODUCTION This article deals with the problem of <br>collaborative concept learning</br> in a multi-agent system. [6] introduces a characterisation of learning in multi-agent system according to the level of awareness of the agents.",
                "At level 1, agents learn ∗The primary author of this paper is a student. in the system without taking into account the presence of other agents, except through the modification brought upon the environment by their action.",
                "Level 2 implies direct interaction between the agents as they can exchange messages to improve their learning.",
                "Level 3 would require agents to take into account the competencies of other agents, and be able to learn from observation of the other agents behaviour (while considering them as independant entities and not indetermined part of the environment as in level 1).",
                "We focus in this paper on level 2, studying direct interaction between agents involved in a learning process.",
                "Each agent is assumed to be able to learn incrementally from the data he receives, meaning that each agent can update his belief set B to keep it consistent with the whole set of information K that he has received from the environment or from other agents.",
                "In such a case, we will say that he is a-consistent.",
                "Here, the belief set B represents hypothetical knowledge that can therefore be revised, whereas the set of information K represents certain knowledge, consisting of non revisable observations and facts.",
                "Moreover, we suppose that at least a part Bc of the beliefs of each agent is common to all agents and must stay that way.",
                "Therefore, an update of this common set Bc by agent r must provoke an update of Bc for the whole community of agents.",
                "It leads us to define what is the mas-consistency of an agent with respect to the community.",
                "The update process of the community beliefs when one of its members gets new information can then be defined as the consistency maintenance process ensuring that every agent in the community will stay masconsistent.",
                "This mas-consistency maintenance process of an agent getting new information gives him the role of a learner and implies communication with other agents acting as critics.",
                "However, agents are not specialised and can in turn be learners or critics, none of them being kept to a specific role.",
                "Pieces of information are distributed among the agents, but can be redundant.",
                "There is no central memory.",
                "The work described here has its origin in a former work concerning learning in an intentional multi-agent system using a BDI formalism [6].",
                "In that work, agents had plans, each of them being associated with a context defining in which conditions it can be triggered.",
                "Plans (each of them having its own context) were common to the whole set of agents in the community.",
                "Agents had to adapt their plan contexts depending on the failure or success of executed plans, using a learning mechanism and asking other agents for examples (plans successes or failures).",
                "However this work lacked a collective learning protocol enabling a real autonomy of the multi-agent system.",
                "The study of such a protocol is the object of the present paper.",
                "In section 2 we formally define the mas-consistency of an update mechanism for the whole MAS and we propose a generic update mechanism proved to be mas consistent.",
                "In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent update mechanism to <br>collaborative concept learning</br>.",
                "Section 4 describes various experiments on SMILE and discusses various issues including how the accuracy and the simplicity of the current hypothesis vary when comparing single agent learning and mas learning.",
                "In section 5 we briefly present some related works and then conclude in section 6 by discussing further investigations on mas consistent learning. 2.",
                "FORMAL MODEL 2.1 Definitions and framework In this section, we present a general formulation of collective incremental learning in a cognitive multi agent system.",
                "We represent a MAS as a set of agents r1, ..., rn.",
                "Each agent ri has a belief set Bi consisting of all the revisable knowledge he has.",
                "Part of these knowledges must be shared with other agents.",
                "The part of Bi that is common to all agents is denoted as BC .",
                "This common part provokes a dependency between the agents.",
                "If an agent ri updates his belief set Bi to Bi, changing in the process BC into BC , all other agents rk must then update their belief set Bk to Bk so that BC ⊆ Bk.",
                "Moreover, each agent ri has stored some certain information Ki.",
                "We suppose that some consistency property Cons(Bi, Ki) can be verified by the agent itself between its beliefs Bi and its information Ki.",
                "As said before, Bi represents knowledge that might be revised whereas Ki represents observed facts, taken as being true, and which can possibly contradict Bi.",
                "Definition 1. a-consistency of an agent An agent ri is a-consistent iff Cons(Bi, Ki) is true.",
                "Example 1.",
                "Agent r1 has a set of plans which are in the common part BC of B1.",
                "Each plan P has a triggering context d(P) (which acts as a pre-condition) and a body.",
                "Some piece of information k could be plan P, triggered in situation s, has failed in spite of s being an instance of d(P).",
                "If this piece of information is added to K1, then agent r1 is not a-consistent anymore: Cons(B1, K1 ∪ k) is false.",
                "We also want to define some notion of consistency for the whole MAS depending on the belief and information sets of its constituting elements.",
                "We will first define the consistency of an agent ri with respect to its belief set Bi and its own information set Ki together with all information sets K1...Kn from the other agents of the MAS.",
                "We will simply do that by considering what would be the a-consistency of the agent if he has the information of all the other agents.",
                "We call this notion the mas-consistency: Definition 2. mas-consistency of an agent An agent ri is mas-consistent iff Cons(Bi, Ki ∪ K) is true, where K = ∪j∈{1,..,n}−{i}Kj 1 is the set of all information from other agents of the MAS. 1 We will note this ∪ Kj when the context is similar.",
                "Example 2.",
                "Using the previous example, suppose that the piece of information k is included in the information K2 of agent r2.",
                "As long as the piece of information is not transmitted to r1, and so added to K1 , r1 remains a-consistent.",
                "However, r1 is not mas-consistent as k is in the set K of all information of the MAS.",
                "The global consistency of the MAS is then simply the mas-consistency of all its agents.",
                "Definition 3.",
                "Consistency of a MAS A MAS r1,...,rn is consistent iff all its agents ri are masconsistent.",
                "We now define the required properties for a revision mechanism M updating an agent ri when it gets a piece of information k. In the following, we will suppose that: • Update is always possible, that is, an agent can always modify its belief set Bi in order to regain its a-consistency.",
                "We will say that each agent is locally efficient. • Considering two sets of information Cons(Bi, K1) and Cons(Bi, K2), we also have Cons(Bi, K1 ∪ K2).",
                "That is, a-consistency of the agents is additive. • If a piece of information k concerning the common set BC is consistent with an agent, it is consistent with all agents: for all pair of agents (ri,rj) such that Cons(Bi, Ki) and Cons(Bj, Kj) are true, we have, for all piece of information k: Cons(Bi, Ki ∪ k) iff Cons(Bj, Kj ∪ k).",
                "In such a case, we will say that the MAS is coherent.",
                "This last condition simply means that the common belief set BC is independent of the possible differences between the belief sets Bi of each agent ri.",
                "In the simplest case, B1 = ... = Bn = BC .",
                "M will also be viewed as an incremental learning mechanism and represented as an application changing Bi in Bi.",
                "In the following, we shall note ri(Bi, Ki) for ri when it is useful.",
                "Definition 4. a-consistency of a revision An update mechanism M is a-consistent iff for any agent ri and any piece of information k reaching ri, the a-consistency of this agent is preserved.",
                "In other words, iff: ri(Bi, Ki) a-consistent ⇒ ri(Bi, Ki) a-consistent, where Bi = M(Bi) and Ki = Ki ∪ k is the set of all information from other agents of the MAS.",
                "In the same way, we define the mas-consistency of a revision mechanism as the a-consistency of this mechanism should the agents dispose of all information in the MAS.",
                "In the following, we shall note, if needed, ri(Bi, Ki, K) for the agent ri in MAS r1 . . . rn.",
                "Definition 5. mas-consistency of a revision An update mechanism Ms is mas-consistent iff for all agent ri and all pieces of information k reaching ri, the masconsistency of this agent is preserved.",
                "In other words, if: ri(Bi, Ki, K) mas-consistent ⇒ ri(Bi, Ki, K) mas-consistent, where Bi = Ms(Bi), Ki = Ki ∪ k, and K = ∪Kj is the set of all information from the MAS.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 165 At last, when a mas-consistent mechanism is applied by an agent getting a new piece of information, a desirable sideeffect of the mechanism should be that all others agents remains mas-consistent after any modification of the common part BC , that is, the MAS itself should become consistent again.",
                "This property is defined as follows: Definition 6.",
                "Strong mas-consistency of a revision An update mechanism Ms is strongly mas-consistent iff - Ms is mas-consistent, and - the application of Ms by an agent preserves the consistency of the MAS. 2.2 A strongly mas-consistent update mechanism The general idea is that, since information is distributed among all the agents of the MAS, there must be some interaction between the learner agent and the other agents in a strongly mas-consistent update mechanism Ms.",
                "In order to ensure its mas-consistency, Ms will be constituted of reiterated applications by the learner agent ri of an internal a-consistent mechanism M, followed by some interactions between ri and the other agents, until ri regain its masconsistency.",
                "We describe below such a mechanism, first with a description of an interaction, then an iteration, and finally a statement of the termination condition of the mechanism.",
                "The mechanism is triggered by an agent ri upon receipt of a piece of information k disrupting the mas-consistency.",
                "We shall note M(Bi) the belief set of the learner agent ri after an update, BC the common part modified by ri, and Bj the belief set of another agent rj induced by the modification of its common part BC in BC .",
                "An interaction I(ri, rj) between the learner agent ri and another agent rj, acting as critic is constituted of the following steps: • agent ri sends the update BC of the common part of its beliefs.",
                "Having applied its update mechanism, ri is a-consistent. • agent rj checks the modification Bj of its beliefs induced by the update BC .",
                "If this modification preserve its a-consistency, rj adopts this modification. • agent rj sends either an acceptation of BC or a denial along with one (or more) piece(s) of information k such that Cons(Bj, k ) is false.",
                "An iteration of Ms will then be composed of: • the reception by the learner agent ri of a piece of information and the update M(Bi) restoring its aconsistency • a set of interactions I(ri, rj) (in which several critic agents can possibly participate).",
                "If at least one piece of information k is transmitted to ri, the addition of k will necessarily make ri a-inconsistent and a new iteration will then occur.",
                "This mechanism Ms ends when no agent can provide such a piece of information k .",
                "When it is the case, the masconsistency of the learner agent ri is restored.",
                "Proposition 1.",
                "Let r1,...,rn be a consistent MAS in which agent ri receives a piece of information k breaking its aconsistency, and M an a-consistent internal update mechanism.",
                "The update mechanism Ms described above is strongly mas-consistent.",
                "Proof.",
                "The proof directly derives from the mechanism description.",
                "This mechanism ensures that each time an agent receives an event, its mas-consistency will be restored.",
                "As the other agents all adopt the final update BC , they are all mas-consistent, and the MAS is consistent.",
                "Therefore Ms is a strongly consistent update mechanism.",
                "In the mechanism Ms described above, the learner agent is the only one that receives and memorizes information during the mechanism execution.",
                "It ensures that Ms terminates.",
                "The pieces of information transmitted by other agents and memorized by the learner agent are redundant as they are already present in the MAS, more precisely in the memory of the critic agents that transmitted them.",
                "Note that the mechanism Ms proposed here does not explicitly indicate the order nor the scope of the interactions.",
                "We will consider in the following that the modification proposal BC is sent sequentially to the different agents (synchronous mechanism).",
                "Moreover, the response of a critic agent will only contain one piece of information inconsistent with the proposed modification.",
                "We will say that the response of the agent is minimal.",
                "This mechanism Ms, being synchronous with minimal response, minimizes the amount of information transmitted by the agents.",
                "We will now illustrate it in the case of multi-agent concept learning. 3.",
                "SOUNDMULTI-AGENTINCREMENTAL LEARNING 3.1 The learning task We experiment the mechanism proposed above in the case of incremental MAS concept learning.",
                "We consider here a hypothesis language in which a hypothesis is a disjunction of terms.",
                "Each term is a conjunction of atoms from a set A.",
                "An example is represented by a tag + or − and a description 2 composed of a subset of atoms e ⊆ A.",
                "A term covers an example if its constituting atoms are included in the example.",
                "A hypothesis covers an example if one of its term covers it.",
                "This representation will be used below for learning boolean formulae.",
                "Negative literals are here represented by additional atoms, like not − a.",
                "The boolean formulae f =(a ∧ b) ∨ (b ∧ ¬c) will then be written (a ∧ b) ∨ (b ∧ not − c).",
                "A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 Incremental learning process The learning process is an update mechanism that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis.",
                "Before this update, the given hypothesis is complete, meaning that it covers all positive examples of E+ , and 2 When no confusion is possible, the word example will be used to refer to the pair (tag, description) as well as the description alone. 166 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) coherent, meaning that it does not cover any negative example of E− .",
                "After the update, the new hypothesis must be complete and coherent with the new memory state E ∪ {e}.",
                "We describe below our single agent update mechanism, inspired from a previous work on incremental learning[7].",
                "In the following, a hypothesis H for the target formula f is a list of terms h, each of them being a conjunction of atoms.",
                "H is coherent if all terms h are coherent, and H is complete if each element of E+ is covered by at least one term h of H. Each term is by construction the lgg (least general generalization) of a subset of positives instances {e1, ..., en}[5], that is the most specific term covering {e1, ..., en}.",
                "The lgg operator is defined by considering examples as terms, so we denote as lgg(e) the most specific term that covers e, and as lgg(h, e) the most specific term which is more general than h and that covers e. Restricting the term to lgg is the basis of a lot of Bottom-Up learning algorithms (for instance [5]).",
                "In the typology proposed by [9], our update mechanism is an incremental learner with full instance memory: learning is made by successive updates and all examples are stored.",
                "The update mechanism depends of the ongoing hypothesis H, the ongoing examples E+ and E− , and the new example e. There are three possible cases: • e is positive and H covers e, or e is negative and H does not cover e. No update is needed, H is already complete and coherent with E ∪ {e}. • e is positive and H does not cover e: e is denoted as a positive counterexample of H. Then we seek to generalize in turn the terms h of H. As soon as a correct generalization h = lgg(h, e) is found, h replaces h in H. If there is a term that is less general that h , it is discarded.",
                "If no generalization is correct (meaning here coherent), H ∪ lgg(e) replaces H. • e is negative and H covers e: e is denoted as a negative counterexample of H. Each term h covering e is then discarded from H and replaced by a set of terms {h1, ...., hn} that is, as a whole, coherent with E− ∪ {e} and that covers the examples of E+ uncovered by H − {h}.",
                "Terms of the final hypothesis H that are less general than others are discarded from H. We will now describe the case where e = e− is a covered negative example.",
                "The following functions are used here: • coveredOnlyBy(h, E+) gives the subset of E+ covered by h and no other term of H. • bestCover(h1, h2) gives h1 if h1 covers more examples from uncoveredPos than h2, otherwise it gives h2. • covered(h) gives the elements of uncoveredPos covered by h. // Specialization of each h covering e− for each h of H covering e− do H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= atoms that are neither in e− nor in h while (uncoveredPos = ∅) do // seeking the best specialization of h hc=h best=⊥ // ⊥ covers no example for each a of Ar do hc= h ∧ a best = bestCover(hc, best) endfor Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) endwhile endfor Terms of H that are less general than others are discarded.",
                "Note that this mechanism tends to both make a minimal update of the current hypothesis and minimize the number of terms in the hypothesis, in particular by discarding terms less general than other ones after updating a hypothesis. 3.3 Collective learning If H is the current hypothesis, Ei the current example memory of agent ri and E the set of all the examples received by the system, the notation of section 2 becomes Bi = BC = H, Ki = Ei and K = E. Cons(H, Ei) states that H is complete and coherent with Ei.",
                "In such a case, ri is a-consistent.",
                "The piece of information k received by agent ri is here simply an example e along with its tag.",
                "If e is such that the current hypothesis H is not complete or coherent with Ei ∪ {e}, e contradicts H: ri becomes a-inconsistent, and therefore the MAS is not consistent anymore.",
                "The update of a hypothesis when a new example arrives is an a- consistent mechanism.",
                "Following proposition 1 this mechanism can be used to produce a strong mas-consistent mechanism: upon reception of a new example in the MAS by an agent r, an update is possibly needed and, after a set of interactions between r and the other agents, results in a new hypothesis shared by all the agents and that restores the consistency of the MAS, that is which is complete and coherent with the set ES of all the examples present in the MAS.",
                "It is clear that by minimizing the number of hypothesis modifications, this synchronous and minimal mechanism minimize the number of examples received by the learner from other agents, and therefore, the total number of examples stored in the system. 4.",
                "EXPERIMENTS In the following, we will learn a boolean formula that is a difficult test for the learning method: the 11-multiplexer (see [4]).",
                "It concerns 3 address boolean attributes a0, a1, a2 and 8 data boolean attributes d0, ..., d7.",
                "Formulae f11 is satisfied if the number coded by the 3 address attributes is the number of a data attribute whose value is 1.",
                "Its formula is the following: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0).",
                "There are 2048 = 211 possible examples, half of whom are positive (meaning they satisfy f11) while the other half is negative.",
                "An experiment is typically composed of 50 trials.",
                "Each run corresponds to a sequence of 600 examples that are incrementally learned by a Multi Agent System with n agents The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 167 (n-MAS).",
                "A number of variables such as accuracy, (i.e. the frequency of correct classification of a set of unseen examples), hypothesis size (i.e. the number of terms in the current formula) or number of stored examples, is recorded each time 25 examples are received by the system during those runs.",
                "In the protocol that is used here, a new example is sent to a random agent when the MAS is consistent.",
                "The next example will be sent in turn to an other agent when the MAS consistency will have been restored.",
                "In such a way we simulate a kind of slow learning: the frequency of example arrivals is slow compared to the time taken by an update. 4.1 Efficiency of MAS concept learning 4.1.1 Execution time We briefly discuss here execution time of learning in the MAS.",
                "Note that the whole set of action and interaction in the MAS is simulated on a single processor.",
                "Figure 1 shows that time linearly depends on the number of agents.",
                "At the end of the most active part of learning (200 examples), a 16MAS has taken 4 times more learning time than a 4-MAS.",
                "This execution time represents the whole set of learning and Figure 1: Execution time of a n-MAS (from n = 2 at the bottom to n = 20 on the top). communication activity and hints at the cost of maintaining a consistent learning hypothesis in a MAS composed of autonomous agents. 4.1.2 Redundancy in the MAS memory We study now the distribution of the examples in the MAS memory.",
                "Redundancy is written RS = nS/ne, where nS is the total number of examples stored in the MAS, that is the sum of the sizes of agents examples memories Ei, and ne is the total number of examples received from the environment in the MAS.",
                "In figure 2, we compare redundancies in 2 to 20 agents MAS.",
                "There is a peak, slowly moving from 80 to 100 examples, that represents the number of examples for which the learning is most active.",
                "For 20 agents, maximal redundancy is no more than 6, which is far less than the maximal theoretical value of 20.",
                "Note that when learning becomes less active, redundancy tends towards its minimal value 1: when there is no more updates, examples are only Figure 2: Redundancy of examples stored in a nMAS (from n = 2 at the bottom to n = 20 on the top) . stored by the agent that receives them. 4.1.3 A n-MAS selects a simpler solution than a single agent The proposed mechanism tends to minimize the number of terms in the selected hypothesis.",
                "During learning, the size of the current hypothesis grows up beyond the optimum, and then decreases when the MAS converges.",
                "In the Multiplexer 11 testbed, the optimal number of terms is 8, but there also exist equivalent formulas with more terms.",
                "It is interesting to note that in this case the 10-MAS converges towards an exact solution closer to the optimal number of terms (here 8) (see Figure 3).",
                "After 1450 examples have been presented both 1-MAS and 10-MAS have exactly learned the concept (the respective accuracies are 0.9999 and 1) but the single agent expresses in average the result as a 11.0 terms DNF whereas the 10-MAS expresses it as a 8.8 terms DNF.",
                "However for some other boolean functions we found that during learning 1-MAS always produces larger hypotheses than 10-MAS but that both MAS converge to hypotheses with similar size results. 4.1.4 A n-MAS is more accurate than a single agent Figure 4 shows the improvement brought by a MAS with n agents compared to a single agent.",
                "This improvement was not especially expected, because whether we have one or n agents, when N examples are given to the MAS it has access to the same amount of information, maintains only on ongoing hypothesis and uses the same basic revision algorithm whenever an agent has to modify the current hypothesis.",
                "Note that if the accuracy of 1, 2, 4 and 10-MAS are significantly different, getting better as the number of agents increases, there is no clear difference beyond this point: the accuracy curve of the 100 agents MAS is very close to the one of the 10 agents MAS. 4.1.4.1 Boolean formulas.",
                "To evaluate this accuracy improvement, we have experimented our protocol on other problems of boolean function learning, As in the Multiplexer-11 case, these functions 168 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 3: Size of the hypothesis built by 1 and 10MAS: the M11 case.",
                "Figure 4: Accuracy of a n-MAS: the M11 case (from bottom to top, n = 1, 2, 4, 10, 100). are learnt in the form of more or less syntactically complex DNF3 (that is with more or less conjunctive terms in the DNF), but are also more or less difficult to learn as it can be difficult to get its way in the hypothesis space to reach them.",
                "Furthermore, the presence in the description of irrelevant attributes (that is attributes that does not belong to the target DNF) makes the problem more difficult.",
                "The following problems have been selected to experiment our protocol: (i) the multiplexer-11 with 9 irrelevant attributes: M11 9, (ii) the 20-multiplexer M20 (with 4 address bits and 16 data bits), (iii) a difficult parity problem (see [4]) the Xorp m: there must be an odd number of bits with value 1 in the p first attributes for the instance to be positive, the p others bits being irrelevant, and (iv) a simple DNF formula (a ∧ b ∧ c) ∨ (c ∧ d ∧ e)(e ∧ f ∧ g) ∧ (g ∧ h ∧ i) with 19 irrelevant attributes.",
                "The following table sums up some information about these problems, giving the total number of attributes including irrelevant ones, the number of irrelevant 3 Disjunctive Normal Forms attributes, the minimal number of terms of the corresponding DNF, and the number of learning examples used.",
                "Pb att. irre. att. terms ex.",
                "M11 11 0 8 200 M11 9 20 9 8 200 M20 20 0 16 450 Xor3 25 28 25 4 200 Xor5 5 10 5 16 180 Xor5 15 20 15 16 600 Simple4-9 19 28 19 4 200 Below are given the accuracy results of our learning mechanism with a single agent and a 10 agents MAS, along with the results of two standard algorithms implemented with the learning environment WEKA[16]: JRip (an implementation of RIPPER[2]) and Id3[12].",
                "For the experiments with JRip and Id3, we measured the mean accuracy on 50 trials, each time randomly separating examples in a learning set and a test set.",
                "JRip and Id3 parameters are default parameters, except that JRip is used without pruning.",
                "The following table shows the results: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 It is clear that difficult problems are better solved with more agents (see for instance xor5 15).",
                "We think that these benefits, which can be important with an increasing number of agents, are due to the fact that each agent really memorizes only part of the total number of examples, and this part is partly selected by other agents as counter examples, which cause a greater number of current hypothesis updates and therefore, a better exploration of the hypotheses space. 4.1.4.2 ML database problems.",
                "We did also experiments with some non boolean problems.",
                "We considered only two classes (positive/negative) problems, taken from the UCIs learning problems database[3].",
                "In all these problems, examples are described as a vector of couples (attribute, value).",
                "The value domains can be either boolean, numeric (wholly ordered set), or nominal (non-ordered set).",
                "An adequate set of atoms A must be constituted for each problem.",
                "For instance, if a is a numeric attribute, we define at most k threshold si, giving k+1 intervals of uniform density4 .",
                "Therefore, each distinct threshold si gives two atoms a ≤ si and a > si.",
                "In our experiments, we took a maximal number of threshold k = 8.",
                "For instance, in the iono problem case, there were 34 numeric attributes, and an instance is described with 506 atoms.",
                "Below are given the accuracy results of our system along with previous results.",
                "The column Nb ex. refer to the 4 The probability for the value of a to be in any interval is constant The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 169 number of examples used for learning5 .",
                "Column (1) represents minimal and maximal accuracy values for the thirty three classifiers tested in [8].",
                "Column (2) represents the results of [13], where various learning methods are compared to ensemble learning methods using weighted classifiers sets.",
                "Column S-1 and S-10 gives the accuracy of SMILE with respectively 1 and 10 agents.",
                "Pb Nb ex. (1) (2) S-1 S-10 ttt 862/574 // 76.2-99.7 99.7 99.9 kr-vs-kp 2876/958 // 91.4-99.4 96.8 97.3 iono 315 // 88.0-91.8 87.2 88.1 bupa 310 57-72 58-69.3 62.5 63.3 breastw 614 91-97 94.3-97.3 94.7 94.7 vote 391 94-96 95.3-96 91.9 92.6 pima 691 // 71.5- 73.4 65.0 65.0 heart 243 66-86 77.1-84.1 69.5 70.7 This table shows that the incremental algorithm corresponding to the single agent case, gives honorable results relatively to non-incremental classical methods using larger and more complex hypotheses.",
                "In some cases, there is an accuracy improvement with a 10 agents MAS.",
                "However, with such benchmarks data, which are often noisy, the difficulty does not really come from the way in which the search space is explored, and therefore the improvement observed is not always significant.",
                "The same kind of phenomenon have been observed with methods dedicated to hard boolean problems [4]. 4.2 MAS synchronization Here we consider that n single agents learn without interactions and at a given time start interacting thus forming a MAS.",
                "The purpose is to observe how the agents take advantage of collaboration when they start from different states of beliefs and memories.",
                "We compare in this section a 1-MAS, a 10-MAS (ref) and a 10-MAS (100sync) whose agents did not communicate during the arrival of the first 100 examples (10 by agents).",
                "The three accuracy curves are shown in figure 5.",
                "By comparing the single agent curve and the synchronized 10-MAS, we can observe that after the beginning of the synchronization, that is at 125 examples, accuracies are identical.",
                "This was expected since as soon as an example e received by the MAS contradicts the current hypothesis of the agent ra receiving it, this agent makes an update and its new hypothesis is proposed to the others agents for criticism.",
                "Therefore, this first contradictory example brings the MAS to reach consistency relatively to the whole set of examples present in agents memories.",
                "A higher accuracy, corresponding to a 10-MAS is obtained later, from the 175th example.",
                "In other words, the benefit of a better exploration of the research space is obtained slightly later in the learning process.",
                "Note that this synchronization happens naturally in all situations where agents have, for some reason, a divergence between their hypothesis and the system memory.",
                "This includes the fusion of two MAS into a single one or the arrival of new agents in an existing MAS. 4.3 Experiments on asynchronous learning: the effect of a large data stream 5 For ttt and kr-vs-kp, our protocol did not use more than respectively 574 and 958 learning examples, so we put another number in the column.",
                "Figure 5: Accuracies of a 1-MAS, a 10-MAS, and a 10-MAS synchronized after 100 examples.",
                "In this experiment we relax our slow learning mode: the examples are sent at a given rate to the MAS.",
                "The resulting example stream is measured in ms−1 , and represents the number of examples sent to the MAS each ms.",
                "Whenever the stream is too large, the MAS cannot reach MAS consistency on reception of an example from the environment before a new example arrives.",
                "This means that the update process, started by agent r0 as he received an example, may be unfinished when a new example is received by r0 or another agent r1.",
                "As a result, a critic agent may have at instant t to send counterexamples of hypotheses sent by various agents.",
                "However as far as the agents, in our setting, memorizes all the examples they receive whenever the stream ends, the MAS necessarily reaches MAS consistency with respect to all the examples received so far.",
                "In our experiments, though its learning curve is slowed down during the intense learning phase (corresponding to low accuracy of the current hypotheses), the MAS still reaches a satisfying hypothesis later on as there are less and less counterexamples in the example stream.",
                "In Figure 6 we compare the accuracies of two 11-MAS respectively submitted to example streams of different rates when learning the M11 formula.",
                "The learning curve of the MAS receiving an example at a 1/33 ms−1 rate is almost not altered (see Figure 4) whereas the 1/16 ms−1 MAS is first severely slowed down before catching up with the first one. 5.",
                "RELATED WORKS Since 96 [15], various work have been performed on learning in MAS, but rather few on concept learning.",
                "In [11] the MAS performs a form of ensemble learning in which the agents are lazy learners (no explicit representation is maintained) and sell useless examples to other agents.",
                "In [10] each agent observes all the examples but only perceive a part of their representation.",
                "In mutual online concept learning [14] the agents converge to a unique hypothesis, but each agent produces examples from its own concept representation, thus resulting in a kind of synchronization rather than in pure concept learning. 170 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 6: Accuracies of two asynchronous 11-MAS (1/33ms−1 and 1/16ms−1 example rates) . 6.",
                "CONCLUSION We have presented here and experimented a protocol for MAS online concept learning.",
                "The main feature of this collaborative learning mechanism is that it maintains a consistency property: though during the learning process each agent only receives and stores, with some limited redundancy, part of the examples received by the MAS, at any moment the current hypothesis is consistent with the whole set of examples.",
                "The hypotheses of our experiments do not address the issues of distributed MAS such as faults (for instance messages could be lost or corrupted) or other failures in general (crash, byzantine faults, etc.).",
                "Nevertheless, our framework is open, i.e., the agents can leave the system or enter it while the consistency mechanism is preserved.",
                "For instance if we introduce a timeout mechanism, even when a critic agent crashes or omits to answer, the consistency with the other critics (within the remaining agents) is entailed.",
                "In [1], a similar approach has been applied to MAS abduction problems: the hypotheses to maintain, given an incomplete information, are then facts or statements.",
                "Further work concerns first coupling induction and abduction in order to perform <br>collaborative concept learning</br> when examples are only partially observed by each agent, and second, investigating partial memory learning: how learning is preserved whenever one agent or the whole MAS forgets some selected examples.",
                "Aknowledgments We are very grateful to Dominique Bouthinon for implementing late modifications in SMILE, so much easing our experiments.",
                "Part of this work has been performed during the first authors visit to the Atelier De BioInformatique of Paris VI university, France. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In DALT-2006, May 2006. [2] W. W. Cohen.",
                "Fast effective rule induction.",
                "In ICML, pages 115-123, 1995. [3] C. B. D.J.",
                "Newman, S. Hettich and C. Merz.",
                "UCI repository of machine learning databases, 1998. [4] S. Esmeir and S. Markovitch.",
                "Lookahead-based algorithms for anytime induction of decision trees.",
                "In ICMLO4, pages 257-264.",
                "Morgan Kaufmann, 2004. [5] J. F¨urnkranz.",
                "A pathology of bottom-up hill-climbing in inductive rule learning.",
                "In ALT, volume 2533 of LNCS, pages 263-277.",
                "Springer, 2002. [6] A. Guerra-Hern´andez, A. ElFallah-Seghrouchni, and H. Soldano.",
                "Learning in BDI multi-agent systems.",
                "In CLIMA IV, volume 3259, pages 218-233.",
                "Springer Verlag, 2004. [7] M. Henniche.",
                "Mgi: an incremental bottom-up algorithm.",
                "In IEEE Aust. and New Zealand Conference on Intelligent Information Systems, pages 347-351, 1994. [8] T.-S. Lim, W.-Y.",
                "Loh, and Y.-S. Shih.",
                "A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms.",
                "Machine Learning, 40(3):203-228, 2000. [9] M. A. Maloof and R. S. Michalski.",
                "Incremental learning with partial instance memory.",
                "Artif.",
                "Intell., 154(1-2):95-126, 2004. [10] P. J. Modi and W.-M. Shen.",
                "Collaborative multiagent learning for classification tasks.",
                "In AGENTS 01, pages 37-38.",
                "ACM Press, 2001. [11] S. Onta˜non and E. Plaza.",
                "Recycling data for multi-agent learning.",
                "In ICML 05, pages 633-640.",
                "ACM Press, 2005. [12] J. R. Quinlan.",
                "Induction of decision trees.",
                "Machine Learning, 1(1):81-106, 1986. [13] U. R¨uckert and S. Kramer.",
                "Towards tight bounds for rule learning.",
                "In ICML 04 (International conference on Machine learning), page 90, New York, NY, USA, 2004.",
                "ACM Press. [14] J. Wang and L. Gasser.",
                "Mutual online concept learning for multiple agents.",
                "In AAMAS, pages 362-369.",
                "ACM Press, 2002. [15] G. Weiß and S. Sen, editors.",
                "Adaption and Learning in Multi-Agent Systems, volume 1042 of Lecture Notes in Computer Science.",
                "Springer, 1996. [16] I. H. Witten and E. Frank.",
                "Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.",
                "Morgan Kaufmann, October 1999.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 171"
            ],
            "original_annotated_samples": [
                "INTRODUCTION This article deals with the problem of <br>collaborative concept learning</br> in a multi-agent system. [6] introduces a characterisation of learning in multi-agent system according to the level of awareness of the agents.",
                "In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent update mechanism to <br>collaborative concept learning</br>.",
                "Further work concerns first coupling induction and abduction in order to perform <br>collaborative concept learning</br> when examples are only partially observed by each agent, and second, investigating partial memory learning: how learning is preserved whenever one agent or the whole MAS forgets some selected examples."
            ],
            "translated_annotated_samples": [
                "INTRODUCCIÓN Este artículo trata sobre el problema del <br>aprendizaje colaborativo de conceptos</br> en un sistema multiagente. [6] introduce una caracterización del aprendizaje en un sistema multiagente según el nivel de conciencia de los agentes.",
                "En la sección 3 describimos SMILE, un aprendiz de conceptos multiagente incremental que aplica nuestro mecanismo de actualización mas consistente para el <br>aprendizaje colaborativo de conceptos</br>.",
                "El trabajo adicional se refiere en primer lugar a acoplar la inducción y la abducción para realizar un <br>aprendizaje colaborativo de conceptos</br> cuando los ejemplos son solo parcialmente observados por cada agente, y en segundo lugar, a investigar el aprendizaje de memoria parcial: cómo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados."
            ],
            "translated_text": "SMILE: Aprendizaje Incremental Multiagente de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av. del presidente Kennedy, 75116 París Henry Soldano LIPN, UMR 7030 CNRS, Universidad Paris-Norte, 99 Av. J-B Clement, 93430, Villetaneuse RESUMEN Este artículo trata sobre el problema del aprendizaje colaborativo en un sistema multiagente. Aquí cada agente puede actualizar de forma incremental sus creencias B (la representación del concepto) para que se mantenga consistente con el conjunto completo de información K (los ejemplos) que ha recibido del entorno u otros agentes. Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo lograr que, en cualquier momento, una misma representación conceptual consistente esté presente en cada agente. El protocolo correspondiente se aplica al aprendizaje supervisado de conceptos. El método resultante SMILE (que significa Sound Multiagent Incremental LEarning) se describe y experimenta aquí. Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de múltiples agentes que por un solo agente. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de conceptos; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistema multiagente Términos Generales Experimentación, Algoritmos, Medición, Rendimiento 1. INTRODUCCIÓN Este artículo trata sobre el problema del <br>aprendizaje colaborativo de conceptos</br> en un sistema multiagente. [6] introduce una caracterización del aprendizaje en un sistema multiagente según el nivel de conciencia de los agentes. En el nivel 1, los agentes aprenden ∗El autor principal de este artículo es un estudiante. en el sistema sin tener en cuenta la presencia de otros agentes, excepto a través de la modificación que traen al entorno con sus acciones. El nivel 2 implica una interacción directa entre los agentes, ya que pueden intercambiar mensajes para mejorar su aprendizaje. El nivel 3 requeriría que los agentes tengan en cuenta las competencias de otros agentes y sean capaces de aprender observando el comportamiento de los otros agentes (considerándolos como entidades independientes y no como parte indeterminada del entorno como en el nivel 1). En este artículo nos enfocamos en el nivel 2, estudiando la interacción directa entre los agentes involucrados en un proceso de aprendizaje. Cada agente se asume capaz de aprender de forma incremental a partir de los datos que recibe, lo que significa que cada agente puede actualizar su conjunto de creencias B para mantenerlo consistente con el conjunto completo de información K que ha recibido del entorno o de otros agentes. En tal caso, diremos que es a-inconsistente. Aquí, el conjunto de creencias B representa conocimiento hipotético que por lo tanto puede ser revisado, mientras que el conjunto de información K representa conocimiento cierto, compuesto por observaciones y hechos no revisables. Además, suponemos que al menos una parte Bc de las creencias de cada agente es común a todos los agentes y debe mantenerse de esa manera. Por lo tanto, una actualización de este conjunto común Bc por parte del agente r debe provocar una actualización de Bc para toda la comunidad de agentes. Nos lleva a definir cuál es la mas-consistencia de un agente con respecto a la comunidad. El proceso de actualización de las creencias de la comunidad cuando uno de sus miembros recibe nueva información puede entonces definirse como el proceso de mantenimiento de la consistencia que garantiza que cada agente en la comunidad permanecerá más consistente. Este proceso de mantenimiento de la mas-consistencia de un agente al recibir nueva información le otorga el rol de aprendiz e implica la comunicación con otros agentes que actúan como críticos. Sin embargo, los agentes no están especializados y a su vez pueden ser aprendices o críticos, ninguno de ellos está limitado a un rol específico. Las piezas de información se distribuyen entre los agentes, pero pueden ser redundantes. No hay memoria central. El trabajo descrito aquí tiene su origen en un trabajo anterior sobre el aprendizaje en un sistema multiagente intencional utilizando un formalismo BDI [6]. En ese trabajo, los agentes tenían planes, cada uno de ellos asociado con un contexto que define en qué condiciones puede ser activado. Los planes (cada uno con su propio contexto) eran comunes a todo el conjunto de agentes en la comunidad. Los agentes tuvieron que adaptar su plan en función del contexto, dependiendo del fracaso o éxito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo a otros agentes ejemplos (éxitos o fracasos de planes). Sin embargo, este trabajo carecía de un protocolo de aprendizaje colectivo que permitiera una verdadera autonomía del sistema multiagente. El estudio de dicho protocolo es el objeto del presente artículo. En la sección 2 definimos formalmente la mas-consistencia de un mecanismo de actualización para todo el MAS y proponemos un mecanismo de actualización genérico demostrado que es mas consistente. En la sección 3 describimos SMILE, un aprendiz de conceptos multiagente incremental que aplica nuestro mecanismo de actualización mas consistente para el <br>aprendizaje colaborativo de conceptos</br>. La sección 4 describe varios experimentos sobre SMILE y discute varios problemas, incluyendo cómo varían la precisión y la simplicidad de la hipótesis actual al comparar el aprendizaje de un solo agente y el aprendizaje de múltiples agentes. En la sección 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la sección 6 discutiendo investigaciones adicionales sobre el aprendizaje más consistente. MODELO FORMAL 2.1 Definiciones y marco En esta sección, presentamos una formulación general del aprendizaje incremental colectivo en un sistema cognitivo de múltiples agentes. Representamos un MAS como un conjunto de agentes r1, ..., rn. Cada agente ri tiene un conjunto de creencias Bi que consiste en todo el conocimiento revisable que posee. Parte de estos conocimientos deben ser compartidos con otros agentes. La parte de Bi que es común a todos los agentes se denota como BC. Esta parte común provoca una dependencia entre los agentes. Si un agente ri actualiza su conjunto de creencias Bi a Bi, cambiando en el proceso BC en BC, entonces todos los demás agentes rk deben actualizar su conjunto de creencias Bk a Bk para que BC ⊆ Bk. Además, cada agente ri ha almacenado cierta información Ki. Suponemos que alguna propiedad de consistencia Cons(Bi, Ki) puede ser verificada por el agente mismo entre sus creencias Bi y su información Ki. Como se dijo antes, Bi representa el conocimiento que podría ser revisado, mientras que Ki representa hechos observados, considerados verdaderos, y que posiblemente puedan contradecir a Bi. Definición 1. a-consistencia de un agente Un agente ri es a-consistente si Cons(Bi, Ki) es verdadero. Ejemplo 1. El agente r1 tiene un conjunto de planes que se encuentran en la parte común BC de B1. Cada plan P tiene un contexto desencadenante d(P) (que actúa como una precondición) y un cuerpo. Alguna pieza de información k podría ser el plan P, desencadenado en la situación s, ha fallado a pesar de que s es una instancia de d(P). Si esta pieza de información se agrega a K1, entonces el agente r1 ya no es a-consistente: Cons(B1, K1 ∪ k) es falso. También queremos definir alguna noción de consistencia para todo el MAS dependiendo de los conjuntos de creencias e información de sus elementos constituyentes. Primero definiremos la consistencia de un agente ri con respecto a su conjunto de creencias Bi y su propio conjunto de información Ki junto con todos los conjuntos de información K1...Kn de los otros agentes del MAS. Simplemente lo haremos considerando cuál sería la a-consistencia del agente si tuviera la información de todos los demás agentes. Llamamos a esta noción la mas-consistencia: Definición 2. Un agente ri es mas-consistente si Cons(Bi, Ki ∪ K) es verdadero, donde K = ∪j∈{1,..,n}−{i}Kj 1 es el conjunto de toda la información de los otros agentes del MAS. 1 Lo notaremos como ∪ Kj cuando el contexto sea similar. Ejemplo 2. Usando el ejemplo anterior, supongamos que la pieza de información k está incluida en la información K2 del agente r2. Si la pieza de información no se transmite a r1, y por lo tanto no se agrega a K1, r1 permanece a-consistente. Sin embargo, r1 no es tan consistente como k en el conjunto K de toda la información del MAS. La consistencia global del MAS es simplemente la mas-consistencia de todos sus agentes. Definición 3. La consistencia de un MAS A MAS r1,...,rn es consistente si todos sus agentes ri son masconsistentes. Ahora definimos las propiedades requeridas para un mecanismo de revisión M que actualiza a un agente ri cuando recibe una pieza de información k. En lo siguiente, supondremos que: • La actualización siempre es posible, es decir, un agente siempre puede modificar su conjunto de creencias Bi para recuperar su a-consistencia. Diremos que cada agente es localmente eficiente. • Considerando dos conjuntos de información Cons(Bi, K1) y Cons(Bi, K2), también tenemos Cons(Bi, K1 ∪ K2). Es decir, la a-consistencia de los agentes es aditiva. • Si una pieza de información k relacionada con el conjunto común BC es consistente con un agente, es consistente con todos los agentes: para todos los pares de agentes (ri, rj) tales que Cons(Bi, Ki) y Cons(Bj, Kj) son verdaderos, tenemos, para toda pieza de información k: Cons(Bi, Ki ∪ k) si y solo si Cons(Bj, Kj ∪ k). En tal caso, diremos que el MAS es coherente. Esta última condición simplemente significa que el conjunto de creencias común BC es independiente de las posibles diferencias entre los conjuntos de creencias Bi de cada agente ri. En el caso más simple, B1 = ... = Bn = BC. M también será visto como un mecanismo de aprendizaje incremental y representado como una aplicación que cambia Bi en Bi. En lo siguiente, anotaremos ri(Bi, Ki) para ri cuando sea útil. Definición 4. a-consistencia de una revisión Un mecanismo de actualización M es a-consistente si, para cualquier agente ri y cualquier pieza de información k que llegue a ri, la a-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki) a-consistente ⇒ ri(Bi, Ki) a-consistente, donde Bi = M(Bi) y Ki = Ki ∪ k es el conjunto de toda la información de otros agentes del MAS. De la misma manera, definimos la mas-consistencia de un mecanismo de revisión como la a-consistencia de este mecanismo si los agentes disponen de toda la información en el MAS. En lo siguiente, anotaremos, si es necesario, ri(Bi, Ki, K) para el agente ri en el MAS r1 . . . rn. Definición 5. mas-consistencia de una revisión Un mecanismo de actualización Ms es mas-consistente si para todo agente ri y toda pieza de información k que llega a ri, la mas-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki, K) más-consistente ⇒ ri(Bi, Ki, K) más-consistente, donde Bi = Ms(Bi), Ki = Ki ∪ k, y K = ∪Kj es el conjunto de toda la información del MAS. El Sexto Internacional. En última instancia, cuando un agente aplica un mecanismo mas-consistente al recibir una nueva pieza de información, un efecto secundario deseable del mecanismo debería ser que todos los demás agentes permanezcan mas-consistentes después de cualquier modificación de la parte común BC, es decir, el MAS en sí mismo debería volver a ser consistente. Esta propiedad se define de la siguiente manera: Definición 6. La fuerte mas-consistencia de un mecanismo de actualización. Un mecanismo de actualización Ms es fuertemente mas-consistente si - Ms es mas-consistente, y - la aplicación de Ms por un agente preserva la consistencia del MAS. 2.2 Un mecanismo de actualización fuertemente mas-consistente. La idea general es que, dado que la información está distribuida entre todos los agentes del MAS, debe haber alguna interacción entre el agente aprendiz y los demás agentes en un mecanismo de actualización fuertemente mas-consistente Ms. Para garantizar su mas-consistencia, Ms estará constituido por aplicaciones reiteradas por parte del agente aprendiz ri de un mecanismo interno a-consistente M, seguido por algunas interacciones entre ri y los otros agentes, hasta que ri recupere su mas-consistencia. Describimos a continuación un mecanismo, primero con una descripción de una interacción, luego una iteración y finalmente una declaración de la condición de terminación del mecanismo. El mecanismo es activado por un agente ri al recibir una pieza de información k que interrumpe la mas-consistencia. Tomaremos M(Bi) como el conjunto de creencias del agente aprendiz ri después de una actualización, BC la parte común modificada por ri, y Bj el conjunto de creencias de otro agente rj inducido por la modificación de su parte común BC en BC. Una interacción I(ri, rj) entre el agente aprendiz ri y otro agente rj, actuando como crítico, está constituida por los siguientes pasos: • el agente ri envía la actualización BC de la parte común de sus creencias. Habiendo aplicado su mecanismo de actualización, ri es a-consistente. • El agente rj verifica la modificación Bj de sus creencias inducida por la actualización BC. Si esta modificación conserva su a-consistencia, rj adopta esta modificación. El agente rj envía ya sea una aceptación de BC o una negación junto con una (o más) pieza(s) de información k tal que Cons(Bj, k) es falso. Una iteración de Ms estará compuesta por: • la recepción por parte del agente aprendiz ri de una pieza de información y la actualización M(Bi) restaurando su consistencia • un conjunto de interacciones I(ri, rj) (en las cuales varios agentes críticos posiblemente puedan participar). Si al menos una pieza de información k es transmitida a ri, la adición de k necesariamente hará que ri sea inconsistente y entonces ocurrirá una nueva iteración. Este mecanismo termina cuando ningún agente puede proporcionar tal pieza de información k. Cuando es el caso, se restaura la masconsistencia del agente aprendiz ri. Proposición 1. Dejen que r1,...,rn sea un MAS consistente en el que el agente ri recibe una pieza de información k que rompe su consistencia, y M sea un mecanismo interno de actualización a-consistente. El mecanismo de actualización descrito anteriormente por Ms es altamente mas-consistente. Prueba. La prueba se deriva directamente de la descripción del mecanismo. Este mecanismo asegura que cada vez que un agente recibe un evento, su mas-consistencia será restaurada. Como los otros agentes adoptan la actualización final BC, todos son mas-coherentes y el MAS es coherente. Por lo tanto, Ms es un mecanismo de actualización fuertemente consistente. En el mecanismo descrito anteriormente, el agente aprendiz es el único que recibe y memoriza información durante la ejecución del mecanismo. Se asegura de que Ms termine. Las piezas de información transmitidas por otros agentes y memorizadas por el agente aprendiz son redundantes, ya que ya están presentes en el MAS, más precisamente en la memoria de los agentes críticos que las transmitieron. Se debe tener en cuenta que el mecanismo propuesto por la Sra. aquí no indica explícitamente el orden ni el alcance de las interacciones. Consideraremos en lo siguiente que la propuesta de modificación BC se envía secuencialmente a los diferentes agentes (mecanismo síncrono). Además, la respuesta de un agente crítico solo contendrá una pieza de información inconsistente con la modificación propuesta. Diremos que la respuesta del agente es mínima. Este mecanismo, siendo sincrónico con una respuesta mínima, minimiza la cantidad de información transmitida por los agentes. Ahora lo ilustraremos en el caso del aprendizaje de conceptos multiagente. 3. APRENDIZAJE INCREMENTAL DE MÚLTIPLES AGENTES 3.1 La tarea de aprendizaje Experimentamos el mecanismo propuesto anteriormente en el caso del aprendizaje conceptual MAS incremental. Aquí consideramos un lenguaje de hipótesis en el cual una hipótesis es una disyunción de términos. Cada término es una conjunción de átomos de un conjunto A. Un ejemplo está representado por una etiqueta + o − y una descripción 2 compuesta por un subconjunto de átomos e ⊆ A. Un término abarca un ejemplo si sus átomos constituyentes están incluidos en el ejemplo. Una hipótesis abarca un ejemplo si uno de sus términos lo abarca. Esta representación se utilizará a continuación para aprender fórmulas booleanas. Los literales negativos se representan aquí mediante átomos adicionales, como not − a. La fórmula booleana f = (a ∧ b) ∨ (b ∧ ¬c) se escribirá entonces como (a ∧ b) ∨ (b ∧ no − c). Un ejemplo positivo de f, como {no − a, b, no − c}, representa un modelo para f. 3.2 Proceso de aprendizaje incremental El proceso de aprendizaje es un mecanismo de actualización que, dado una hipótesis actual H, una memoria E = E+ ∪ E− llenada con los ejemplos recibidos previamente, y un nuevo ejemplo positivo o negativo e, produce una nueva hipótesis actualizada. Antes de esta actualización, la hipótesis dada es completa, lo que significa que cubre todos los ejemplos positivos de E+, y 2 Cuando no haya posibilidad de confusión, la palabra ejemplo se utilizará para referirse al par (etiqueta, descripción) así como a la descripción sola. 166 La Sexta Conferencia Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) es coherente, lo que significa que no cubre ningún ejemplo negativo de E−. Después de la actualización, la nueva hipótesis debe ser completa y coherente con el nuevo estado de memoria E ∪ {e}. Describimos a continuación nuestro mecanismo de actualización de agente único, inspirado en un trabajo previo sobre aprendizaje incremental[7]. En lo siguiente, una hipótesis H para la fórmula objetivo f es una lista de términos h, cada uno de ellos siendo una conjunción de átomos. H es coherente si todos los términos h son coherentes, y H es completo si cada elemento de E+ está cubierto por al menos un término h de H. Cada término es, por construcción, la lgg (generalización general menos general) de un subconjunto de instancias positivas {e1, ..., en}, es decir, el término más específico que cubre {e1, ..., en}. El operador lgg se define considerando ejemplos como términos, por lo que denotamos como lgg(e) al término más específico que cubre e, y como lgg(h, e) al término más específico que es más general que h y que cubre e. Restringir el término a lgg es la base de muchos algoritmos de aprendizaje de abajo hacia arriba (por ejemplo [5]). En la tipología propuesta por [9], nuestro mecanismo de actualización es un aprendiz incremental con memoria completa de instancias: el aprendizaje se realiza mediante actualizaciones sucesivas y se almacenan todos los ejemplos. El mecanismo de actualización depende de la hipótesis en curso H, los ejemplos en curso E+ y E−, y el nuevo ejemplo e. Hay tres casos posibles: • e es positivo y H cubre e, o e es negativo y H no cubre e. No se necesita actualización, H ya es completo y coherente con E ∪ {e}. • e es positivo y H no cubre e: e se denota como un contraejemplo positivo de H. Luego buscamos generalizar a su vez los términos h de H. Tan pronto como se encuentre una generalización correcta h = lgg(h, e), h reemplaza a h en H. Si hay un término que es menos general que h, se descarta. Si ninguna generalización es correcta (es decir, coherente), H ∪ lgg(e) reemplaza a H. • e es negativo y H cubre e: e se denota como un contraejemplo negativo de H. Cada término h que cubre e es entonces descartado de H y reemplazado por un conjunto de términos {h1, ...., hn} que, en su totalidad, es coherente con E− ∪ {e} y que cubre los ejemplos de E+ no cubiertos por H − {h}. Los términos de la hipótesis final H que son menos generales que otros son descartados de H. Ahora describiremos el caso en el que e = e− es un ejemplo negativo cubierto. Las siguientes funciones se utilizan aquí: • coveredOnlyBy(h, E+) da el subconjunto de E+ cubierto por h y ningún otro término de H. • bestCover(h1, h2) da h1 si h1 cubre más ejemplos de uncoveredPos que h2, de lo contrario da h2. • covered(h) da los elementos de uncoveredPos cubiertos por h. // Especialización de cada h cubriendo e− para cada h de H cubriendo e− hacer H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= átomos que no están ni en e− ni en h mientras (uncoveredPos = ∅) hacer // buscando la mejor especialización de h hc=h best=⊥ // ⊥ no cubre ningún ejemplo para cada a de Ar hacer hc= h ∧ a best = bestCover(hc, best) finpara Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) finmientras finpara Los términos de H que son menos generales que otros son descartados. Ten en cuenta que este mecanismo tiende tanto a hacer una actualización mínima de la hipótesis actual como a minimizar el número de términos en la hipótesis, en particular descartando términos menos generales que otros después de actualizar una hipótesis. 3.3 Aprendizaje colectivo Si H es la hipótesis actual, Ei es la memoria actual de ejemplos del agente ri y E es el conjunto de todos los ejemplos recibidos por el sistema, la notación de la sección 2 se convierte en Bi = BC = H, Ki = Ei y K = E. Cons(H, Ei) establece que H es completo y coherente con Ei. En tal caso, ri es a-consistente. La pieza de información k recibida por el agente ri es aquí simplemente un ejemplo e junto con su etiqueta. Si e es tal que la hipótesis actual H no es completa ni coherente con Ei ∪ {e}, e contradice a H: ri se vuelve a-inconsistente, y por lo tanto el MAS ya no es consistente. La actualización de una hipótesis cuando llega un nuevo ejemplo es un mecanismo a-consistente. Siguiendo la proposición 1, este mecanismo puede ser utilizado para producir un mecanismo fuerte mas-consistente: al recibir un nuevo ejemplo en el MAS por un agente r, posiblemente se necesite una actualización y, después de un conjunto de interacciones entre r y los otros agentes, resulta en una nueva hipótesis compartida por todos los agentes y que restaura la consistencia del MAS, es decir, que es completa y coherente con el conjunto ES de todos los ejemplos presentes en el MAS. Es claro que al minimizar el número de modificaciones de hipótesis, este mecanismo sincrónico y minimalista reduce el número de ejemplos recibidos por el aprendiz de otros agentes, y por ende, el número total de ejemplos almacenados en el sistema. 4. EXPERIMENTOS En lo siguiente, aprenderemos una fórmula booleana que es una prueba difícil para el método de aprendizaje: el 11-multiplexor (ver [4]). Se refiere a 3 atributos booleanos de dirección a0, a1, a2 y 8 atributos booleanos de datos d0, ..., d7. La fórmula f11 se cumple si el número codificado por los 3 atributos de dirección es el número de un atributo de datos cuyo valor es 1. Su fórmula es la siguiente: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0). Hay 2048 = 211 posibles ejemplos, la mitad de los cuales son positivos (lo que significa que satisfacen f11) mientras que la otra mitad es negativa. Un experimento suele estar compuesto por 50 pruebas. Cada ejecución corresponde a una secuencia de 600 ejemplos que son aprendidos de forma incremental por un Sistema Multiagente con n agentes. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 167 (n-MAS). Un número de variables como la precisión (es decir, la frecuencia de clasificación correcta de un conjunto de ejemplos no vistos), el tamaño de la hipótesis (es decir, el número de términos en la fórmula actual) o el número de ejemplos almacenados, se registra cada vez que el sistema recibe 25 ejemplos durante esas ejecuciones. En el protocolo que se utiliza aquí, un nuevo ejemplo se envía a un agente aleatorio cuando el MAS es consistente. El siguiente ejemplo será enviado a su vez a otro agente cuando la consistencia del MAS haya sido restaurada. De esta manera simulamos una especie de aprendizaje lento: la frecuencia de llegada de ejemplos es lenta en comparación con el tiempo que lleva una actualización. 4.1 Eficiencia del aprendizaje conceptual en MAS 4.1.1 Tiempo de ejecución Discutimos brevemente aquí el tiempo de ejecución del aprendizaje en el MAS. Se debe tener en cuenta que todo el conjunto de acciones e interacciones en el MAS se simula en un solo procesador. La Figura 1 muestra que el tiempo depende linealmente del número de agentes. Al final de la parte más activa del aprendizaje (200 ejemplos), un 16MAS ha tomado 4 veces más tiempo de aprendizaje que un 4-MAS. Este tiempo de ejecución representa el conjunto completo de aprendizaje y la Figura 1: Tiempo de ejecución de un n-MAS (desde n = 2 en la parte inferior hasta n = 20 en la parte superior). actividad de comunicación y sugiere el costo de mantener una hipótesis de aprendizaje consistente en un MAS compuesto por agentes autónomos. 4.1.2 Redundancia en la memoria del MAS Estudiamos ahora la distribución de los ejemplos en la memoria del MAS. La redundancia se escribe RS = nS/ne, donde nS es el número total de ejemplos almacenados en el MAS, que es la suma de los tamaños de las memorias de ejemplos de los agentes Ei, y ne es el número total de ejemplos recibidos del entorno en el MAS. En la figura 2, comparamos las redundancias en MAS de 2 a 20 agentes. Hay un pico que se mueve lentamente de 80 a 100 ejemplos, que representa la cantidad de ejemplos para los cuales el aprendizaje es más activo. Para 20 agentes, la redundancia máxima no es más de 6, lo cual es mucho menor que el valor teórico máximo de 20. Ten en cuenta que cuando el aprendizaje se vuelve menos activo, la redundancia tiende hacia su valor mínimo 1: cuando ya no hay más actualizaciones, los ejemplos son solo la Figura 2: Redundancia de ejemplos almacenados en un nMAS (de n = 2 en la parte inferior a n = 20 en la parte superior) almacenados por el agente que los recibe. Un n-MAS selecciona una solución más simple que un solo agente. El mecanismo propuesto tiende a minimizar el número de términos en la hipótesis seleccionada. Durante el aprendizaje, el tamaño de la hipótesis actual crece más allá del óptimo, y luego disminuye cuando el MAS converge. En el banco de pruebas Multiplexer 11, el número óptimo de términos es 8, pero también existen fórmulas equivalentes con más términos. Es interesante notar que en este caso el 10-MAS converge hacia una solución exacta más cercana al número óptimo de términos (en este caso 8) (ver Figura 3). Después de haber presentado 1450 ejemplos, tanto el 1-MAS como el 10-MAS han aprendido exactamente el concepto (las precisiones respectivas son 0.9999 y 1), pero el agente individual expresa en promedio el resultado como una DNF de 11.0 términos, mientras que el 10-MAS lo expresa como una DNF de 8.8 términos. Sin embargo, para algunas otras funciones booleanas encontramos que durante el aprendizaje, 1-MAS siempre produce hipótesis más grandes que 10-MAS, pero que ambos MAS convergen a hipótesis con resultados de tamaño similar. 4.1.4 Un n-MAS es más preciso que un agente único. La Figura 4 muestra la mejora proporcionada por un MAS con n agentes en comparación con un agente único. Esta mejora no era especialmente esperada, porque ya sea que tengamos uno o n agentes, cuando se le dan N ejemplos al MAS, tiene acceso a la misma cantidad de información, mantiene solo una hipótesis en curso y utiliza el mismo algoritmo básico de revisión cada vez que un agente tiene que modificar la hipótesis actual. Ten en cuenta que si la precisión de los MAS de 1, 2, 4 y 10 es significativamente diferente, mejorando a medida que aumenta el número de agentes, no hay una diferencia clara más allá de este punto: la curva de precisión de los MAS de 100 agentes es muy similar a la de los MAS de 10 agentes. 4.1.4.1 Fórmulas booleanas. Para evaluar esta mejora de precisión, hemos experimentado nuestro protocolo en otros problemas de aprendizaje de funciones booleanas. Como en el caso del Multiplexor-11, estas funciones 168 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 3: Tamaño de la hipótesis construida por 1 y 10MAS: el caso M11. Figura 4: Precisión de un n-MAS: el caso M11 (de abajo hacia arriba, n = 1, 2, 4, 10, 100). Se aprenden en forma de DNF3 más o menos sintácticamente complejos (es decir, con más o menos términos conjuntivos en la DNF), pero también son más o menos difíciles de aprender, ya que puede ser difícil encontrar su camino en el espacio de hipótesis para alcanzarlos. Además, la presencia en la descripción de atributos irrelevantes (es decir, atributos que no pertenecen al DNF objetivo) hace que el problema sea más difícil. Los siguientes problemas han sido seleccionados para experimentar con nuestro protocolo: (i) el multiplexor-11 con 9 atributos irrelevantes: M11 9, (ii) el multiplexor-20 M20 (con 4 bits de dirección y 16 bits de datos), (iii) un problema de paridad difícil (ver [4]) el Xorp m: debe haber un número impar de bits con valor 1 en los primeros p atributos para que la instancia sea positiva, los p bits restantes son irrelevantes, y (iv) una fórmula DNF simple (a ∧ b ∧ c) ∨ (c ∧ d ∧ e) ∨ (e ∧ f ∧ g) ∧ (g ∧ h ∧ i) con 19 atributos irrelevantes. La siguiente tabla resume alguna información sobre estos problemas, proporcionando el número total de atributos, incluidos los irrelevantes, el número de atributos irrelevantes en Forma Normal Disyuntiva 3, el número mínimo de términos de la DNF correspondiente, y el número de ejemplos de aprendizaje utilizados. Pb att. irre. att. términos ex. A continuación se presentan los resultados de precisión de nuestro mecanismo de aprendizaje con un solo agente y un MAS de 10 agentes, junto con los resultados de dos algoritmos estándar implementados con el entorno de aprendizaje WEKA[16]: JRip (una implementación de RIPPER[2]) e Id3[12]. Para los experimentos con JRip e Id3, medimos la precisión media en 50 pruebas, separando aleatoriamente los ejemplos en un conjunto de aprendizaje y un conjunto de prueba cada vez. Los parámetros de JRip e Id3 son los predeterminados, excepto que JRip se utiliza sin poda. La siguiente tabla muestra los resultados: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 Es claro que los problemas difíciles se resuelven mejor con más agentes (ver por ejemplo xor5 15). Creemos que estos beneficios, que pueden ser importantes con un número creciente de agentes, se deben al hecho de que cada agente realmente memoriza solo parte del número total de ejemplos, y esta parte es seleccionada en parte por otros agentes como contraejemplos, lo que provoca un mayor número de actualizaciones de hipótesis actuales y, por lo tanto, una mejor exploración del espacio de hipótesis. 4.1.4.2 Problemas de base de datos de ML. También realizamos experimentos con algunos problemas no booleanos. Consideramos solo problemas de dos clases (positivo/negativo), tomados de la base de datos de problemas de aprendizaje de UCIs. En todos estos problemas, los ejemplos se describen como un vector de pares (atributo, valor). Los dominios de valor pueden ser booleanos, numéricos (conjunto totalmente ordenado) o nominales (conjunto no ordenado). Un conjunto adecuado de átomos A debe ser constituido para cada problema. Por ejemplo, si a es un atributo numérico, definimos como máximo k umbrales si, dando k+1 intervalos de densidad uniforme. Por lo tanto, cada umbral distintivo si da dos átomos, uno ≤ si y otro > si. En nuestros experimentos, tomamos un número máximo de umbral k = 8. Por ejemplo, en el caso del problema de iono, había 34 atributos numéricos, y una instancia se describe con 506 átomos. A continuación se presentan los resultados de precisión de nuestro sistema junto con los resultados anteriores. La columna Nb ex. se refiere al 4. La probabilidad de que el valor de a esté en cualquier intervalo es constante. El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 169 número de ejemplos utilizados para el aprendizaje5. La columna (1) representa los valores de precisión mínima y máxima para los treinta y tres clasificadores probados en [8]. La columna (2) representa los resultados de [13], donde se comparan varios métodos de aprendizaje con métodos de aprendizaje en conjunto utilizando conjuntos de clasificadores ponderados. La columna S-1 y S-10 dan la precisión de SMILE con 1 y 10 agentes, respectivamente. Esta tabla muestra que el algoritmo incremental correspondiente al caso de un solo agente, proporciona resultados honorables en relación a los métodos clásicos no incrementales que utilizan hipótesis más grandes y complejas. En algunos casos, hay una mejora en la precisión con un MAS de 10 agentes. Sin embargo, con datos de referencia de este tipo, que suelen ser ruidosos, la dificultad no radica realmente en la forma en que se explora el espacio de búsqueda, por lo que la mejora observada no siempre es significativa. El mismo tipo de fenómeno se ha observado con métodos dedicados a problemas booleanos difíciles [4]. 4.2 Sincronización de MAS En este caso consideramos que n agentes individuales aprenden sin interacciones y en un momento dado comienzan a interactuar, formando así un MAS. El propósito es observar cómo los agentes aprovechan la colaboración cuando parten de diferentes estados de creencias y memorias. En esta sección comparamos un 1-MAS, un 10-MAS (ref) y un 10-MAS (100sync) cuyos agentes no se comunicaron durante la llegada de los primeros 100 ejemplos (10 por agentes). Las tres curvas de precisión se muestran en la figura 5. Al comparar la curva del agente individual con la del 10-MAS sincronizado, podemos observar que después del inicio de la sincronización, es decir, en 125 ejemplos, las precisiones son idénticas. Esto era esperado ya que tan pronto como un ejemplo e recibido por el MAS contradice la hipótesis actual del agente ra que lo recibe, este agente realiza una actualización y su nueva hipótesis es propuesta a los otros agentes para su crítica. Por lo tanto, este primer ejemplo contradictorio lleva al MAS a alcanzar coherencia en relación con todo el conjunto de ejemplos presentes en la memoria de los agentes. Una mayor precisión, correspondiente a un 10-MAS, se obtiene más tarde, a partir del ejemplo 175. En otras palabras, el beneficio de una mejor exploración del espacio de investigación se obtiene ligeramente más tarde en el proceso de aprendizaje. Ten en cuenta que esta sincronización ocurre de forma natural en todas las situaciones en las que los agentes tienen, por alguna razón, una divergencia entre su hipótesis y la memoria del sistema. Esto incluye la fusión de dos MAS en una sola o la llegada de nuevos agentes en un MAS existente. 4.3 Experimentos sobre el aprendizaje asincrónico: el efecto de un gran flujo de datos. Para ttt y kr-vs-kp, nuestro protocolo no utilizó más de 574 y 958 ejemplos de aprendizaje respectivamente, por lo que colocamos otro número en la columna. Figura 5: Precisión de un 1-MAS, un 10-MAS y un 10-MAS sincronizado después de 100 ejemplos. En este experimento relajamos nuestro modo de aprendizaje lento: los ejemplos se envían a una velocidad determinada al MAS. El flujo de ejemplos resultante se mide en ms−1, y representa la cantidad de ejemplos enviados al MAS cada milisegundo. Cuando el flujo es demasiado grande, el MAS no puede alcanzar la consistencia del MAS al recibir un ejemplo del entorno antes de que llegue un nuevo ejemplo. Esto significa que el proceso de actualización, iniciado por el agente r0 al recibir un ejemplo, puede estar incompleto cuando un nuevo ejemplo es recibido por r0 u otro agente r1. Como resultado, un agente crítico puede tener que enviar contraejemplos de hipótesis enviadas por varios agentes en el instante t. Sin embargo, en nuestro entorno, a medida que los agentes memorizan todos los ejemplos que reciben cuando finaliza el flujo, el MAS alcanza necesariamente consistencia MAS con respecto a todos los ejemplos recibidos hasta el momento. En nuestros experimentos, aunque la curva de aprendizaje se ralentiza durante la fase intensa de aprendizaje (correspondiente a una baja precisión de las hipótesis actuales), el MAS aún logra alcanzar una hipótesis satisfactoria más adelante, ya que hay menos contraejemplos en el flujo de ejemplos. En la Figura 6 comparamos las precisiones de dos 11-MAS respectivamente sometidos a flujos de ejemplos de diferentes tasas al aprender la fórmula M11. La curva de aprendizaje del MAS al recibir un ejemplo a una velocidad de 1/33 ms−1 casi no se ve alterada (ver Figura 4), mientras que el MAS a 1/16 ms−1 primero se ralentiza severamente antes de alcanzar al primero. 5. TRABAJOS RELACIONADOS Desde el 96 [15], se han realizado varios trabajos sobre el aprendizaje en Sistemas Multiagente, pero muy pocos sobre el aprendizaje de conceptos. En [11] el MAS realiza una forma de aprendizaje en conjunto en la que los agentes son aprendices perezosos (no se mantiene una representación explícita) y venden ejemplos inútiles a otros agentes. En [10] cada agente observa todos los ejemplos pero solo percibe una parte de su representación. En el aprendizaje de conceptos en línea mutuo, los agentes convergen hacia una hipótesis única, pero cada agente produce ejemplos desde su propia representación del concepto, lo que resulta en una especie de sincronización en lugar de un aprendizaje de conceptos puro. 170 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Precisión de dos sistemas multiagente asincrónicos de 11 agentes (tasas de ejemplo de 1/33ms−1 y 1/16ms−1). 6. CONCLUSIÓN Hemos presentado y experimentado un protocolo para el aprendizaje de conceptos en línea de MAS. La característica principal de este mecanismo de aprendizaje colaborativo es que mantiene una propiedad de consistencia: aunque durante el proceso de aprendizaje cada agente solo recibe y almacena, con cierta redundancia limitada, parte de los ejemplos recibidos por el MAS, en cualquier momento la hipótesis actual es consistente con todo el conjunto de ejemplos. Las hipótesis de nuestros experimentos no abordan los problemas de los MAS distribuidos, como fallos (por ejemplo, mensajes perdidos o corruptos) u otras fallas en general (crash, fallos bizantinos, etc.). Sin embargo, nuestro marco de trabajo es abierto, es decir, los agentes pueden salir del sistema o ingresar a él mientras se preserva el mecanismo de consistencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente crítico se bloquea o no responde, se garantiza la consistencia con los otros críticos (dentro de los agentes restantes). En [1], se ha aplicado un enfoque similar a los problemas de abducción en MAS: las hipótesis a mantener, dada una información incompleta, son entonces hechos o afirmaciones. El trabajo adicional se refiere en primer lugar a acoplar la inducción y la abducción para realizar un <br>aprendizaje colaborativo de conceptos</br> cuando los ejemplos son solo parcialmente observados por cada agente, y en segundo lugar, a investigar el aprendizaje de memoria parcial: cómo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados. Agradecimientos Estamos muy agradecidos a Dominique Bouthinon por implementar las modificaciones tardías en SMILE, facilitando mucho nuestros experimentos. Parte de este trabajo se realizó durante la visita del primer autor al Atelier De BioInformatique de la Universidad Paris VI, Francia. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En DALT-2006, mayo de 2006. [2] W. W. Cohen. Inducción de reglas rápida y efectiva. En ICML, páginas 115-123, 1995. [3] C. B. D.J. Newman, S. Hettich y C. Merz. Repositorio de bases de datos de aprendizaje automático de UCI, 1998. [4] S. Esmeir y S. Markovitch. Algoritmos basados en anticipación para la inducción en cualquier momento de árboles de decisión. En ICMLO4, páginas 257-264. Morgan Kaufmann, 2004. [5] J. F¨urnkranz. \n\nMorgan Kaufmann, 2004. [5] J. F¨urnkranz. Una patología de la escalada de colina de abajo hacia arriba en el aprendizaje inductivo de reglas. En ALT, volumen 2533 de LNCS, páginas 263-277. Springer, 2002. [6] A. Guerra-Hernández, A. ElFallah-Seghrouchni y H. Soldano. Aprendizaje en sistemas multiagente BDI. En CLIMA IV, volumen 3259, páginas 218-233. Springer Verlag, 2004. [7] M. Henniche. \n\nSpringer Verlag, 2004. [7] M. Henniche. Mgi: un algoritmo incremental de abajo hacia arriba. En la Conferencia IEEE de Australia y Nueva Zelanda sobre Sistemas de Información Inteligente, páginas 347-351, 1994. [8] T.-S. Lim, W.-Y. Loh, y Y.-S. Shih. Una comparación de la precisión de predicción, complejidad y tiempo de entrenamiento de treinta y tres algoritmos de clasificación antiguos y nuevos. Aprendizaje automático, 40(3):203-228, 2000. [9] M. A. Maloof y R. S. Michalski. Aprendizaje incremental con memoria parcial de instancias. I'm sorry, but the sentence \"Artif.\" is not a complete sentence. Can you provide more context or a complete sentence for me to translate to Spanish? Intell., 154(1-2):95-126, 2004. [10] P. J. Modi y W.-M. Shen. Aprendizaje colaborativo multiagente para tareas de clasificación. En AGENTS 01, páginas 37-38. ACM Press, 2001. [11] S. Onta˜non y E. Plaza. Reciclaje de datos para el aprendizaje multiagente. En ICML 05, páginas 633-640. ACM Press, 2005. [12] J. R. Quinlan. \n\nACM Press, 2005. [12] J. R. Quinlan. Inducción de árboles de decisión. Aprendizaje automático, 1(1):81-106, 1986. [13] U. R¨uckert y S. Kramer. Hacia límites ajustados para el aprendizaje de reglas. En ICML 04 (Conferencia Internacional sobre Aprendizaje Automático), página 90, Nueva York, NY, EE. UU., 2004. ACM Press. [14] J. Wang y L. Gasser. Aprendizaje de conceptos en línea mutuo para múltiples agentes. En AAMAS, páginas 362-369. ACM Press, 2002. [15] G. Weiß y S. Sen, editores. Adaptación y Aprendizaje en Sistemas Multiagente, volumen 1042 de las Notas de Conferencia en Ciencias de la Computación. Springer, 1996. [16] I. H. Witten y E. Frank. Minería de datos: Herramientas y técnicas prácticas de aprendizaje automático con implementaciones en Java. Morgan Kaufmann, octubre de 1999. La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 171 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "learning process": {
            "translated_key": "proceso de aprendizaje",
            "is_in_text": true,
            "original_annotated_sentences": [
                "SMILE: Sound Multi-agent Incremental LEarning ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av.",
                "du pr´esident Kennedy, 75116 Paris Henry Soldano LIPN, UMR 7030 CNRS, University Paris-Nord, 99 Av.",
                "J-B Clement, 93430, Villetaneuse ABSTRACT This article deals with the problem of collaborative learning in a multi-agent system.",
                "Here each agent can update incrementally its beliefs B (the concept representation) so that it is in a way kept consistent with the whole set of information K (the examples) that he has received from the environment or other agents.",
                "We extend this notion of consistency (or soundness) to the whole MAS and discuss how to obtain that, at any moment, a same consistent concept representation is present in each agent.",
                "The corresponding protocol is applied to supervised concept learning.",
                "The resulting method SMILE (standing for Sound Multiagent Incremental LEarning) is described and experimented here.",
                "Surprisingly some difficult boolean formulas are better learned, given the same learning set, by a Multi agent system than by a single agent.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Concept learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent system General Terms Experimentation, Algorithms, Measurement, Performance 1.",
                "INTRODUCTION This article deals with the problem of collaborative concept learning in a multi-agent system. [6] introduces a characterisation of learning in multi-agent system according to the level of awareness of the agents.",
                "At level 1, agents learn ∗The primary author of this paper is a student. in the system without taking into account the presence of other agents, except through the modification brought upon the environment by their action.",
                "Level 2 implies direct interaction between the agents as they can exchange messages to improve their learning.",
                "Level 3 would require agents to take into account the competencies of other agents, and be able to learn from observation of the other agents behaviour (while considering them as independant entities and not indetermined part of the environment as in level 1).",
                "We focus in this paper on level 2, studying direct interaction between agents involved in a <br>learning process</br>.",
                "Each agent is assumed to be able to learn incrementally from the data he receives, meaning that each agent can update his belief set B to keep it consistent with the whole set of information K that he has received from the environment or from other agents.",
                "In such a case, we will say that he is a-consistent.",
                "Here, the belief set B represents hypothetical knowledge that can therefore be revised, whereas the set of information K represents certain knowledge, consisting of non revisable observations and facts.",
                "Moreover, we suppose that at least a part Bc of the beliefs of each agent is common to all agents and must stay that way.",
                "Therefore, an update of this common set Bc by agent r must provoke an update of Bc for the whole community of agents.",
                "It leads us to define what is the mas-consistency of an agent with respect to the community.",
                "The update process of the community beliefs when one of its members gets new information can then be defined as the consistency maintenance process ensuring that every agent in the community will stay masconsistent.",
                "This mas-consistency maintenance process of an agent getting new information gives him the role of a learner and implies communication with other agents acting as critics.",
                "However, agents are not specialised and can in turn be learners or critics, none of them being kept to a specific role.",
                "Pieces of information are distributed among the agents, but can be redundant.",
                "There is no central memory.",
                "The work described here has its origin in a former work concerning learning in an intentional multi-agent system using a BDI formalism [6].",
                "In that work, agents had plans, each of them being associated with a context defining in which conditions it can be triggered.",
                "Plans (each of them having its own context) were common to the whole set of agents in the community.",
                "Agents had to adapt their plan contexts depending on the failure or success of executed plans, using a learning mechanism and asking other agents for examples (plans successes or failures).",
                "However this work lacked a collective learning protocol enabling a real autonomy of the multi-agent system.",
                "The study of such a protocol is the object of the present paper.",
                "In section 2 we formally define the mas-consistency of an update mechanism for the whole MAS and we propose a generic update mechanism proved to be mas consistent.",
                "In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent update mechanism to collaborative concept learning.",
                "Section 4 describes various experiments on SMILE and discusses various issues including how the accuracy and the simplicity of the current hypothesis vary when comparing single agent learning and mas learning.",
                "In section 5 we briefly present some related works and then conclude in section 6 by discussing further investigations on mas consistent learning. 2.",
                "FORMAL MODEL 2.1 Definitions and framework In this section, we present a general formulation of collective incremental learning in a cognitive multi agent system.",
                "We represent a MAS as a set of agents r1, ..., rn.",
                "Each agent ri has a belief set Bi consisting of all the revisable knowledge he has.",
                "Part of these knowledges must be shared with other agents.",
                "The part of Bi that is common to all agents is denoted as BC .",
                "This common part provokes a dependency between the agents.",
                "If an agent ri updates his belief set Bi to Bi, changing in the process BC into BC , all other agents rk must then update their belief set Bk to Bk so that BC ⊆ Bk.",
                "Moreover, each agent ri has stored some certain information Ki.",
                "We suppose that some consistency property Cons(Bi, Ki) can be verified by the agent itself between its beliefs Bi and its information Ki.",
                "As said before, Bi represents knowledge that might be revised whereas Ki represents observed facts, taken as being true, and which can possibly contradict Bi.",
                "Definition 1. a-consistency of an agent An agent ri is a-consistent iff Cons(Bi, Ki) is true.",
                "Example 1.",
                "Agent r1 has a set of plans which are in the common part BC of B1.",
                "Each plan P has a triggering context d(P) (which acts as a pre-condition) and a body.",
                "Some piece of information k could be plan P, triggered in situation s, has failed in spite of s being an instance of d(P).",
                "If this piece of information is added to K1, then agent r1 is not a-consistent anymore: Cons(B1, K1 ∪ k) is false.",
                "We also want to define some notion of consistency for the whole MAS depending on the belief and information sets of its constituting elements.",
                "We will first define the consistency of an agent ri with respect to its belief set Bi and its own information set Ki together with all information sets K1...Kn from the other agents of the MAS.",
                "We will simply do that by considering what would be the a-consistency of the agent if he has the information of all the other agents.",
                "We call this notion the mas-consistency: Definition 2. mas-consistency of an agent An agent ri is mas-consistent iff Cons(Bi, Ki ∪ K) is true, where K = ∪j∈{1,..,n}−{i}Kj 1 is the set of all information from other agents of the MAS. 1 We will note this ∪ Kj when the context is similar.",
                "Example 2.",
                "Using the previous example, suppose that the piece of information k is included in the information K2 of agent r2.",
                "As long as the piece of information is not transmitted to r1, and so added to K1 , r1 remains a-consistent.",
                "However, r1 is not mas-consistent as k is in the set K of all information of the MAS.",
                "The global consistency of the MAS is then simply the mas-consistency of all its agents.",
                "Definition 3.",
                "Consistency of a MAS A MAS r1,...,rn is consistent iff all its agents ri are masconsistent.",
                "We now define the required properties for a revision mechanism M updating an agent ri when it gets a piece of information k. In the following, we will suppose that: • Update is always possible, that is, an agent can always modify its belief set Bi in order to regain its a-consistency.",
                "We will say that each agent is locally efficient. • Considering two sets of information Cons(Bi, K1) and Cons(Bi, K2), we also have Cons(Bi, K1 ∪ K2).",
                "That is, a-consistency of the agents is additive. • If a piece of information k concerning the common set BC is consistent with an agent, it is consistent with all agents: for all pair of agents (ri,rj) such that Cons(Bi, Ki) and Cons(Bj, Kj) are true, we have, for all piece of information k: Cons(Bi, Ki ∪ k) iff Cons(Bj, Kj ∪ k).",
                "In such a case, we will say that the MAS is coherent.",
                "This last condition simply means that the common belief set BC is independent of the possible differences between the belief sets Bi of each agent ri.",
                "In the simplest case, B1 = ... = Bn = BC .",
                "M will also be viewed as an incremental learning mechanism and represented as an application changing Bi in Bi.",
                "In the following, we shall note ri(Bi, Ki) for ri when it is useful.",
                "Definition 4. a-consistency of a revision An update mechanism M is a-consistent iff for any agent ri and any piece of information k reaching ri, the a-consistency of this agent is preserved.",
                "In other words, iff: ri(Bi, Ki) a-consistent ⇒ ri(Bi, Ki) a-consistent, where Bi = M(Bi) and Ki = Ki ∪ k is the set of all information from other agents of the MAS.",
                "In the same way, we define the mas-consistency of a revision mechanism as the a-consistency of this mechanism should the agents dispose of all information in the MAS.",
                "In the following, we shall note, if needed, ri(Bi, Ki, K) for the agent ri in MAS r1 . . . rn.",
                "Definition 5. mas-consistency of a revision An update mechanism Ms is mas-consistent iff for all agent ri and all pieces of information k reaching ri, the masconsistency of this agent is preserved.",
                "In other words, if: ri(Bi, Ki, K) mas-consistent ⇒ ri(Bi, Ki, K) mas-consistent, where Bi = Ms(Bi), Ki = Ki ∪ k, and K = ∪Kj is the set of all information from the MAS.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 165 At last, when a mas-consistent mechanism is applied by an agent getting a new piece of information, a desirable sideeffect of the mechanism should be that all others agents remains mas-consistent after any modification of the common part BC , that is, the MAS itself should become consistent again.",
                "This property is defined as follows: Definition 6.",
                "Strong mas-consistency of a revision An update mechanism Ms is strongly mas-consistent iff - Ms is mas-consistent, and - the application of Ms by an agent preserves the consistency of the MAS. 2.2 A strongly mas-consistent update mechanism The general idea is that, since information is distributed among all the agents of the MAS, there must be some interaction between the learner agent and the other agents in a strongly mas-consistent update mechanism Ms.",
                "In order to ensure its mas-consistency, Ms will be constituted of reiterated applications by the learner agent ri of an internal a-consistent mechanism M, followed by some interactions between ri and the other agents, until ri regain its masconsistency.",
                "We describe below such a mechanism, first with a description of an interaction, then an iteration, and finally a statement of the termination condition of the mechanism.",
                "The mechanism is triggered by an agent ri upon receipt of a piece of information k disrupting the mas-consistency.",
                "We shall note M(Bi) the belief set of the learner agent ri after an update, BC the common part modified by ri, and Bj the belief set of another agent rj induced by the modification of its common part BC in BC .",
                "An interaction I(ri, rj) between the learner agent ri and another agent rj, acting as critic is constituted of the following steps: • agent ri sends the update BC of the common part of its beliefs.",
                "Having applied its update mechanism, ri is a-consistent. • agent rj checks the modification Bj of its beliefs induced by the update BC .",
                "If this modification preserve its a-consistency, rj adopts this modification. • agent rj sends either an acceptation of BC or a denial along with one (or more) piece(s) of information k such that Cons(Bj, k ) is false.",
                "An iteration of Ms will then be composed of: • the reception by the learner agent ri of a piece of information and the update M(Bi) restoring its aconsistency • a set of interactions I(ri, rj) (in which several critic agents can possibly participate).",
                "If at least one piece of information k is transmitted to ri, the addition of k will necessarily make ri a-inconsistent and a new iteration will then occur.",
                "This mechanism Ms ends when no agent can provide such a piece of information k .",
                "When it is the case, the masconsistency of the learner agent ri is restored.",
                "Proposition 1.",
                "Let r1,...,rn be a consistent MAS in which agent ri receives a piece of information k breaking its aconsistency, and M an a-consistent internal update mechanism.",
                "The update mechanism Ms described above is strongly mas-consistent.",
                "Proof.",
                "The proof directly derives from the mechanism description.",
                "This mechanism ensures that each time an agent receives an event, its mas-consistency will be restored.",
                "As the other agents all adopt the final update BC , they are all mas-consistent, and the MAS is consistent.",
                "Therefore Ms is a strongly consistent update mechanism.",
                "In the mechanism Ms described above, the learner agent is the only one that receives and memorizes information during the mechanism execution.",
                "It ensures that Ms terminates.",
                "The pieces of information transmitted by other agents and memorized by the learner agent are redundant as they are already present in the MAS, more precisely in the memory of the critic agents that transmitted them.",
                "Note that the mechanism Ms proposed here does not explicitly indicate the order nor the scope of the interactions.",
                "We will consider in the following that the modification proposal BC is sent sequentially to the different agents (synchronous mechanism).",
                "Moreover, the response of a critic agent will only contain one piece of information inconsistent with the proposed modification.",
                "We will say that the response of the agent is minimal.",
                "This mechanism Ms, being synchronous with minimal response, minimizes the amount of information transmitted by the agents.",
                "We will now illustrate it in the case of multi-agent concept learning. 3.",
                "SOUNDMULTI-AGENTINCREMENTAL LEARNING 3.1 The learning task We experiment the mechanism proposed above in the case of incremental MAS concept learning.",
                "We consider here a hypothesis language in which a hypothesis is a disjunction of terms.",
                "Each term is a conjunction of atoms from a set A.",
                "An example is represented by a tag + or − and a description 2 composed of a subset of atoms e ⊆ A.",
                "A term covers an example if its constituting atoms are included in the example.",
                "A hypothesis covers an example if one of its term covers it.",
                "This representation will be used below for learning boolean formulae.",
                "Negative literals are here represented by additional atoms, like not − a.",
                "The boolean formulae f =(a ∧ b) ∨ (b ∧ ¬c) will then be written (a ∧ b) ∨ (b ∧ not − c).",
                "A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 Incremental <br>learning process</br> The <br>learning process</br> is an update mechanism that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis.",
                "Before this update, the given hypothesis is complete, meaning that it covers all positive examples of E+ , and 2 When no confusion is possible, the word example will be used to refer to the pair (tag, description) as well as the description alone. 166 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) coherent, meaning that it does not cover any negative example of E− .",
                "After the update, the new hypothesis must be complete and coherent with the new memory state E ∪ {e}.",
                "We describe below our single agent update mechanism, inspired from a previous work on incremental learning[7].",
                "In the following, a hypothesis H for the target formula f is a list of terms h, each of them being a conjunction of atoms.",
                "H is coherent if all terms h are coherent, and H is complete if each element of E+ is covered by at least one term h of H. Each term is by construction the lgg (least general generalization) of a subset of positives instances {e1, ..., en}[5], that is the most specific term covering {e1, ..., en}.",
                "The lgg operator is defined by considering examples as terms, so we denote as lgg(e) the most specific term that covers e, and as lgg(h, e) the most specific term which is more general than h and that covers e. Restricting the term to lgg is the basis of a lot of Bottom-Up learning algorithms (for instance [5]).",
                "In the typology proposed by [9], our update mechanism is an incremental learner with full instance memory: learning is made by successive updates and all examples are stored.",
                "The update mechanism depends of the ongoing hypothesis H, the ongoing examples E+ and E− , and the new example e. There are three possible cases: • e is positive and H covers e, or e is negative and H does not cover e. No update is needed, H is already complete and coherent with E ∪ {e}. • e is positive and H does not cover e: e is denoted as a positive counterexample of H. Then we seek to generalize in turn the terms h of H. As soon as a correct generalization h = lgg(h, e) is found, h replaces h in H. If there is a term that is less general that h , it is discarded.",
                "If no generalization is correct (meaning here coherent), H ∪ lgg(e) replaces H. • e is negative and H covers e: e is denoted as a negative counterexample of H. Each term h covering e is then discarded from H and replaced by a set of terms {h1, ...., hn} that is, as a whole, coherent with E− ∪ {e} and that covers the examples of E+ uncovered by H − {h}.",
                "Terms of the final hypothesis H that are less general than others are discarded from H. We will now describe the case where e = e− is a covered negative example.",
                "The following functions are used here: • coveredOnlyBy(h, E+) gives the subset of E+ covered by h and no other term of H. • bestCover(h1, h2) gives h1 if h1 covers more examples from uncoveredPos than h2, otherwise it gives h2. • covered(h) gives the elements of uncoveredPos covered by h. // Specialization of each h covering e− for each h of H covering e− do H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= atoms that are neither in e− nor in h while (uncoveredPos = ∅) do // seeking the best specialization of h hc=h best=⊥ // ⊥ covers no example for each a of Ar do hc= h ∧ a best = bestCover(hc, best) endfor Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) endwhile endfor Terms of H that are less general than others are discarded.",
                "Note that this mechanism tends to both make a minimal update of the current hypothesis and minimize the number of terms in the hypothesis, in particular by discarding terms less general than other ones after updating a hypothesis. 3.3 Collective learning If H is the current hypothesis, Ei the current example memory of agent ri and E the set of all the examples received by the system, the notation of section 2 becomes Bi = BC = H, Ki = Ei and K = E. Cons(H, Ei) states that H is complete and coherent with Ei.",
                "In such a case, ri is a-consistent.",
                "The piece of information k received by agent ri is here simply an example e along with its tag.",
                "If e is such that the current hypothesis H is not complete or coherent with Ei ∪ {e}, e contradicts H: ri becomes a-inconsistent, and therefore the MAS is not consistent anymore.",
                "The update of a hypothesis when a new example arrives is an a- consistent mechanism.",
                "Following proposition 1 this mechanism can be used to produce a strong mas-consistent mechanism: upon reception of a new example in the MAS by an agent r, an update is possibly needed and, after a set of interactions between r and the other agents, results in a new hypothesis shared by all the agents and that restores the consistency of the MAS, that is which is complete and coherent with the set ES of all the examples present in the MAS.",
                "It is clear that by minimizing the number of hypothesis modifications, this synchronous and minimal mechanism minimize the number of examples received by the learner from other agents, and therefore, the total number of examples stored in the system. 4.",
                "EXPERIMENTS In the following, we will learn a boolean formula that is a difficult test for the learning method: the 11-multiplexer (see [4]).",
                "It concerns 3 address boolean attributes a0, a1, a2 and 8 data boolean attributes d0, ..., d7.",
                "Formulae f11 is satisfied if the number coded by the 3 address attributes is the number of a data attribute whose value is 1.",
                "Its formula is the following: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0).",
                "There are 2048 = 211 possible examples, half of whom are positive (meaning they satisfy f11) while the other half is negative.",
                "An experiment is typically composed of 50 trials.",
                "Each run corresponds to a sequence of 600 examples that are incrementally learned by a Multi Agent System with n agents The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 167 (n-MAS).",
                "A number of variables such as accuracy, (i.e. the frequency of correct classification of a set of unseen examples), hypothesis size (i.e. the number of terms in the current formula) or number of stored examples, is recorded each time 25 examples are received by the system during those runs.",
                "In the protocol that is used here, a new example is sent to a random agent when the MAS is consistent.",
                "The next example will be sent in turn to an other agent when the MAS consistency will have been restored.",
                "In such a way we simulate a kind of slow learning: the frequency of example arrivals is slow compared to the time taken by an update. 4.1 Efficiency of MAS concept learning 4.1.1 Execution time We briefly discuss here execution time of learning in the MAS.",
                "Note that the whole set of action and interaction in the MAS is simulated on a single processor.",
                "Figure 1 shows that time linearly depends on the number of agents.",
                "At the end of the most active part of learning (200 examples), a 16MAS has taken 4 times more learning time than a 4-MAS.",
                "This execution time represents the whole set of learning and Figure 1: Execution time of a n-MAS (from n = 2 at the bottom to n = 20 on the top). communication activity and hints at the cost of maintaining a consistent learning hypothesis in a MAS composed of autonomous agents. 4.1.2 Redundancy in the MAS memory We study now the distribution of the examples in the MAS memory.",
                "Redundancy is written RS = nS/ne, where nS is the total number of examples stored in the MAS, that is the sum of the sizes of agents examples memories Ei, and ne is the total number of examples received from the environment in the MAS.",
                "In figure 2, we compare redundancies in 2 to 20 agents MAS.",
                "There is a peak, slowly moving from 80 to 100 examples, that represents the number of examples for which the learning is most active.",
                "For 20 agents, maximal redundancy is no more than 6, which is far less than the maximal theoretical value of 20.",
                "Note that when learning becomes less active, redundancy tends towards its minimal value 1: when there is no more updates, examples are only Figure 2: Redundancy of examples stored in a nMAS (from n = 2 at the bottom to n = 20 on the top) . stored by the agent that receives them. 4.1.3 A n-MAS selects a simpler solution than a single agent The proposed mechanism tends to minimize the number of terms in the selected hypothesis.",
                "During learning, the size of the current hypothesis grows up beyond the optimum, and then decreases when the MAS converges.",
                "In the Multiplexer 11 testbed, the optimal number of terms is 8, but there also exist equivalent formulas with more terms.",
                "It is interesting to note that in this case the 10-MAS converges towards an exact solution closer to the optimal number of terms (here 8) (see Figure 3).",
                "After 1450 examples have been presented both 1-MAS and 10-MAS have exactly learned the concept (the respective accuracies are 0.9999 and 1) but the single agent expresses in average the result as a 11.0 terms DNF whereas the 10-MAS expresses it as a 8.8 terms DNF.",
                "However for some other boolean functions we found that during learning 1-MAS always produces larger hypotheses than 10-MAS but that both MAS converge to hypotheses with similar size results. 4.1.4 A n-MAS is more accurate than a single agent Figure 4 shows the improvement brought by a MAS with n agents compared to a single agent.",
                "This improvement was not especially expected, because whether we have one or n agents, when N examples are given to the MAS it has access to the same amount of information, maintains only on ongoing hypothesis and uses the same basic revision algorithm whenever an agent has to modify the current hypothesis.",
                "Note that if the accuracy of 1, 2, 4 and 10-MAS are significantly different, getting better as the number of agents increases, there is no clear difference beyond this point: the accuracy curve of the 100 agents MAS is very close to the one of the 10 agents MAS. 4.1.4.1 Boolean formulas.",
                "To evaluate this accuracy improvement, we have experimented our protocol on other problems of boolean function learning, As in the Multiplexer-11 case, these functions 168 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 3: Size of the hypothesis built by 1 and 10MAS: the M11 case.",
                "Figure 4: Accuracy of a n-MAS: the M11 case (from bottom to top, n = 1, 2, 4, 10, 100). are learnt in the form of more or less syntactically complex DNF3 (that is with more or less conjunctive terms in the DNF), but are also more or less difficult to learn as it can be difficult to get its way in the hypothesis space to reach them.",
                "Furthermore, the presence in the description of irrelevant attributes (that is attributes that does not belong to the target DNF) makes the problem more difficult.",
                "The following problems have been selected to experiment our protocol: (i) the multiplexer-11 with 9 irrelevant attributes: M11 9, (ii) the 20-multiplexer M20 (with 4 address bits and 16 data bits), (iii) a difficult parity problem (see [4]) the Xorp m: there must be an odd number of bits with value 1 in the p first attributes for the instance to be positive, the p others bits being irrelevant, and (iv) a simple DNF formula (a ∧ b ∧ c) ∨ (c ∧ d ∧ e)(e ∧ f ∧ g) ∧ (g ∧ h ∧ i) with 19 irrelevant attributes.",
                "The following table sums up some information about these problems, giving the total number of attributes including irrelevant ones, the number of irrelevant 3 Disjunctive Normal Forms attributes, the minimal number of terms of the corresponding DNF, and the number of learning examples used.",
                "Pb att. irre. att. terms ex.",
                "M11 11 0 8 200 M11 9 20 9 8 200 M20 20 0 16 450 Xor3 25 28 25 4 200 Xor5 5 10 5 16 180 Xor5 15 20 15 16 600 Simple4-9 19 28 19 4 200 Below are given the accuracy results of our learning mechanism with a single agent and a 10 agents MAS, along with the results of two standard algorithms implemented with the learning environment WEKA[16]: JRip (an implementation of RIPPER[2]) and Id3[12].",
                "For the experiments with JRip and Id3, we measured the mean accuracy on 50 trials, each time randomly separating examples in a learning set and a test set.",
                "JRip and Id3 parameters are default parameters, except that JRip is used without pruning.",
                "The following table shows the results: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 It is clear that difficult problems are better solved with more agents (see for instance xor5 15).",
                "We think that these benefits, which can be important with an increasing number of agents, are due to the fact that each agent really memorizes only part of the total number of examples, and this part is partly selected by other agents as counter examples, which cause a greater number of current hypothesis updates and therefore, a better exploration of the hypotheses space. 4.1.4.2 ML database problems.",
                "We did also experiments with some non boolean problems.",
                "We considered only two classes (positive/negative) problems, taken from the UCIs learning problems database[3].",
                "In all these problems, examples are described as a vector of couples (attribute, value).",
                "The value domains can be either boolean, numeric (wholly ordered set), or nominal (non-ordered set).",
                "An adequate set of atoms A must be constituted for each problem.",
                "For instance, if a is a numeric attribute, we define at most k threshold si, giving k+1 intervals of uniform density4 .",
                "Therefore, each distinct threshold si gives two atoms a ≤ si and a > si.",
                "In our experiments, we took a maximal number of threshold k = 8.",
                "For instance, in the iono problem case, there were 34 numeric attributes, and an instance is described with 506 atoms.",
                "Below are given the accuracy results of our system along with previous results.",
                "The column Nb ex. refer to the 4 The probability for the value of a to be in any interval is constant The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 169 number of examples used for learning5 .",
                "Column (1) represents minimal and maximal accuracy values for the thirty three classifiers tested in [8].",
                "Column (2) represents the results of [13], where various learning methods are compared to ensemble learning methods using weighted classifiers sets.",
                "Column S-1 and S-10 gives the accuracy of SMILE with respectively 1 and 10 agents.",
                "Pb Nb ex. (1) (2) S-1 S-10 ttt 862/574 // 76.2-99.7 99.7 99.9 kr-vs-kp 2876/958 // 91.4-99.4 96.8 97.3 iono 315 // 88.0-91.8 87.2 88.1 bupa 310 57-72 58-69.3 62.5 63.3 breastw 614 91-97 94.3-97.3 94.7 94.7 vote 391 94-96 95.3-96 91.9 92.6 pima 691 // 71.5- 73.4 65.0 65.0 heart 243 66-86 77.1-84.1 69.5 70.7 This table shows that the incremental algorithm corresponding to the single agent case, gives honorable results relatively to non-incremental classical methods using larger and more complex hypotheses.",
                "In some cases, there is an accuracy improvement with a 10 agents MAS.",
                "However, with such benchmarks data, which are often noisy, the difficulty does not really come from the way in which the search space is explored, and therefore the improvement observed is not always significant.",
                "The same kind of phenomenon have been observed with methods dedicated to hard boolean problems [4]. 4.2 MAS synchronization Here we consider that n single agents learn without interactions and at a given time start interacting thus forming a MAS.",
                "The purpose is to observe how the agents take advantage of collaboration when they start from different states of beliefs and memories.",
                "We compare in this section a 1-MAS, a 10-MAS (ref) and a 10-MAS (100sync) whose agents did not communicate during the arrival of the first 100 examples (10 by agents).",
                "The three accuracy curves are shown in figure 5.",
                "By comparing the single agent curve and the synchronized 10-MAS, we can observe that after the beginning of the synchronization, that is at 125 examples, accuracies are identical.",
                "This was expected since as soon as an example e received by the MAS contradicts the current hypothesis of the agent ra receiving it, this agent makes an update and its new hypothesis is proposed to the others agents for criticism.",
                "Therefore, this first contradictory example brings the MAS to reach consistency relatively to the whole set of examples present in agents memories.",
                "A higher accuracy, corresponding to a 10-MAS is obtained later, from the 175th example.",
                "In other words, the benefit of a better exploration of the research space is obtained slightly later in the <br>learning process</br>.",
                "Note that this synchronization happens naturally in all situations where agents have, for some reason, a divergence between their hypothesis and the system memory.",
                "This includes the fusion of two MAS into a single one or the arrival of new agents in an existing MAS. 4.3 Experiments on asynchronous learning: the effect of a large data stream 5 For ttt and kr-vs-kp, our protocol did not use more than respectively 574 and 958 learning examples, so we put another number in the column.",
                "Figure 5: Accuracies of a 1-MAS, a 10-MAS, and a 10-MAS synchronized after 100 examples.",
                "In this experiment we relax our slow learning mode: the examples are sent at a given rate to the MAS.",
                "The resulting example stream is measured in ms−1 , and represents the number of examples sent to the MAS each ms.",
                "Whenever the stream is too large, the MAS cannot reach MAS consistency on reception of an example from the environment before a new example arrives.",
                "This means that the update process, started by agent r0 as he received an example, may be unfinished when a new example is received by r0 or another agent r1.",
                "As a result, a critic agent may have at instant t to send counterexamples of hypotheses sent by various agents.",
                "However as far as the agents, in our setting, memorizes all the examples they receive whenever the stream ends, the MAS necessarily reaches MAS consistency with respect to all the examples received so far.",
                "In our experiments, though its learning curve is slowed down during the intense learning phase (corresponding to low accuracy of the current hypotheses), the MAS still reaches a satisfying hypothesis later on as there are less and less counterexamples in the example stream.",
                "In Figure 6 we compare the accuracies of two 11-MAS respectively submitted to example streams of different rates when learning the M11 formula.",
                "The learning curve of the MAS receiving an example at a 1/33 ms−1 rate is almost not altered (see Figure 4) whereas the 1/16 ms−1 MAS is first severely slowed down before catching up with the first one. 5.",
                "RELATED WORKS Since 96 [15], various work have been performed on learning in MAS, but rather few on concept learning.",
                "In [11] the MAS performs a form of ensemble learning in which the agents are lazy learners (no explicit representation is maintained) and sell useless examples to other agents.",
                "In [10] each agent observes all the examples but only perceive a part of their representation.",
                "In mutual online concept learning [14] the agents converge to a unique hypothesis, but each agent produces examples from its own concept representation, thus resulting in a kind of synchronization rather than in pure concept learning. 170 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 6: Accuracies of two asynchronous 11-MAS (1/33ms−1 and 1/16ms−1 example rates) . 6.",
                "CONCLUSION We have presented here and experimented a protocol for MAS online concept learning.",
                "The main feature of this collaborative learning mechanism is that it maintains a consistency property: though during the <br>learning process</br> each agent only receives and stores, with some limited redundancy, part of the examples received by the MAS, at any moment the current hypothesis is consistent with the whole set of examples.",
                "The hypotheses of our experiments do not address the issues of distributed MAS such as faults (for instance messages could be lost or corrupted) or other failures in general (crash, byzantine faults, etc.).",
                "Nevertheless, our framework is open, i.e., the agents can leave the system or enter it while the consistency mechanism is preserved.",
                "For instance if we introduce a timeout mechanism, even when a critic agent crashes or omits to answer, the consistency with the other critics (within the remaining agents) is entailed.",
                "In [1], a similar approach has been applied to MAS abduction problems: the hypotheses to maintain, given an incomplete information, are then facts or statements.",
                "Further work concerns first coupling induction and abduction in order to perform collaborative concept learning when examples are only partially observed by each agent, and second, investigating partial memory learning: how learning is preserved whenever one agent or the whole MAS forgets some selected examples.",
                "Aknowledgments We are very grateful to Dominique Bouthinon for implementing late modifications in SMILE, so much easing our experiments.",
                "Part of this work has been performed during the first authors visit to the Atelier De BioInformatique of Paris VI university, France. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In DALT-2006, May 2006. [2] W. W. Cohen.",
                "Fast effective rule induction.",
                "In ICML, pages 115-123, 1995. [3] C. B. D.J.",
                "Newman, S. Hettich and C. Merz.",
                "UCI repository of machine learning databases, 1998. [4] S. Esmeir and S. Markovitch.",
                "Lookahead-based algorithms for anytime induction of decision trees.",
                "In ICMLO4, pages 257-264.",
                "Morgan Kaufmann, 2004. [5] J. F¨urnkranz.",
                "A pathology of bottom-up hill-climbing in inductive rule learning.",
                "In ALT, volume 2533 of LNCS, pages 263-277.",
                "Springer, 2002. [6] A. Guerra-Hern´andez, A. ElFallah-Seghrouchni, and H. Soldano.",
                "Learning in BDI multi-agent systems.",
                "In CLIMA IV, volume 3259, pages 218-233.",
                "Springer Verlag, 2004. [7] M. Henniche.",
                "Mgi: an incremental bottom-up algorithm.",
                "In IEEE Aust. and New Zealand Conference on Intelligent Information Systems, pages 347-351, 1994. [8] T.-S. Lim, W.-Y.",
                "Loh, and Y.-S. Shih.",
                "A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms.",
                "Machine Learning, 40(3):203-228, 2000. [9] M. A. Maloof and R. S. Michalski.",
                "Incremental learning with partial instance memory.",
                "Artif.",
                "Intell., 154(1-2):95-126, 2004. [10] P. J. Modi and W.-M. Shen.",
                "Collaborative multiagent learning for classification tasks.",
                "In AGENTS 01, pages 37-38.",
                "ACM Press, 2001. [11] S. Onta˜non and E. Plaza.",
                "Recycling data for multi-agent learning.",
                "In ICML 05, pages 633-640.",
                "ACM Press, 2005. [12] J. R. Quinlan.",
                "Induction of decision trees.",
                "Machine Learning, 1(1):81-106, 1986. [13] U. R¨uckert and S. Kramer.",
                "Towards tight bounds for rule learning.",
                "In ICML 04 (International conference on Machine learning), page 90, New York, NY, USA, 2004.",
                "ACM Press. [14] J. Wang and L. Gasser.",
                "Mutual online concept learning for multiple agents.",
                "In AAMAS, pages 362-369.",
                "ACM Press, 2002. [15] G. Weiß and S. Sen, editors.",
                "Adaption and Learning in Multi-Agent Systems, volume 1042 of Lecture Notes in Computer Science.",
                "Springer, 1996. [16] I. H. Witten and E. Frank.",
                "Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.",
                "Morgan Kaufmann, October 1999.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 171"
            ],
            "original_annotated_samples": [
                "We focus in this paper on level 2, studying direct interaction between agents involved in a <br>learning process</br>.",
                "A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 Incremental <br>learning process</br> The <br>learning process</br> is an update mechanism that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis.",
                "In other words, the benefit of a better exploration of the research space is obtained slightly later in the <br>learning process</br>.",
                "The main feature of this collaborative learning mechanism is that it maintains a consistency property: though during the <br>learning process</br> each agent only receives and stores, with some limited redundancy, part of the examples received by the MAS, at any moment the current hypothesis is consistent with the whole set of examples."
            ],
            "translated_annotated_samples": [
                "En este artículo nos enfocamos en el nivel 2, estudiando la interacción directa entre los agentes involucrados en un <br>proceso de aprendizaje</br>.",
                "Un ejemplo positivo de f, como {no − a, b, no − c}, representa un modelo para f. 3.2 Proceso de aprendizaje incremental El <br>proceso de aprendizaje</br> es un mecanismo de actualización que, dado una hipótesis actual H, una memoria E = E+ ∪ E− llenada con los ejemplos recibidos previamente, y un nuevo ejemplo positivo o negativo e, produce una nueva hipótesis actualizada.",
                "En otras palabras, el beneficio de una mejor exploración del espacio de investigación se obtiene ligeramente más tarde en el <br>proceso de aprendizaje</br>.",
                "La característica principal de este mecanismo de aprendizaje colaborativo es que mantiene una propiedad de consistencia: aunque durante el <br>proceso de aprendizaje</br> cada agente solo recibe y almacena, con cierta redundancia limitada, parte de los ejemplos recibidos por el MAS, en cualquier momento la hipótesis actual es consistente con todo el conjunto de ejemplos."
            ],
            "translated_text": "SMILE: Aprendizaje Incremental Multiagente de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av. del presidente Kennedy, 75116 París Henry Soldano LIPN, UMR 7030 CNRS, Universidad Paris-Norte, 99 Av. J-B Clement, 93430, Villetaneuse RESUMEN Este artículo trata sobre el problema del aprendizaje colaborativo en un sistema multiagente. Aquí cada agente puede actualizar de forma incremental sus creencias B (la representación del concepto) para que se mantenga consistente con el conjunto completo de información K (los ejemplos) que ha recibido del entorno u otros agentes. Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo lograr que, en cualquier momento, una misma representación conceptual consistente esté presente en cada agente. El protocolo correspondiente se aplica al aprendizaje supervisado de conceptos. El método resultante SMILE (que significa Sound Multiagent Incremental LEarning) se describe y experimenta aquí. Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de múltiples agentes que por un solo agente. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de conceptos; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistema multiagente Términos Generales Experimentación, Algoritmos, Medición, Rendimiento 1. INTRODUCCIÓN Este artículo trata sobre el problema del aprendizaje colaborativo de conceptos en un sistema multiagente. [6] introduce una caracterización del aprendizaje en un sistema multiagente según el nivel de conciencia de los agentes. En el nivel 1, los agentes aprenden ∗El autor principal de este artículo es un estudiante. en el sistema sin tener en cuenta la presencia de otros agentes, excepto a través de la modificación que traen al entorno con sus acciones. El nivel 2 implica una interacción directa entre los agentes, ya que pueden intercambiar mensajes para mejorar su aprendizaje. El nivel 3 requeriría que los agentes tengan en cuenta las competencias de otros agentes y sean capaces de aprender observando el comportamiento de los otros agentes (considerándolos como entidades independientes y no como parte indeterminada del entorno como en el nivel 1). En este artículo nos enfocamos en el nivel 2, estudiando la interacción directa entre los agentes involucrados en un <br>proceso de aprendizaje</br>. Cada agente se asume capaz de aprender de forma incremental a partir de los datos que recibe, lo que significa que cada agente puede actualizar su conjunto de creencias B para mantenerlo consistente con el conjunto completo de información K que ha recibido del entorno o de otros agentes. En tal caso, diremos que es a-inconsistente. Aquí, el conjunto de creencias B representa conocimiento hipotético que por lo tanto puede ser revisado, mientras que el conjunto de información K representa conocimiento cierto, compuesto por observaciones y hechos no revisables. Además, suponemos que al menos una parte Bc de las creencias de cada agente es común a todos los agentes y debe mantenerse de esa manera. Por lo tanto, una actualización de este conjunto común Bc por parte del agente r debe provocar una actualización de Bc para toda la comunidad de agentes. Nos lleva a definir cuál es la mas-consistencia de un agente con respecto a la comunidad. El proceso de actualización de las creencias de la comunidad cuando uno de sus miembros recibe nueva información puede entonces definirse como el proceso de mantenimiento de la consistencia que garantiza que cada agente en la comunidad permanecerá más consistente. Este proceso de mantenimiento de la mas-consistencia de un agente al recibir nueva información le otorga el rol de aprendiz e implica la comunicación con otros agentes que actúan como críticos. Sin embargo, los agentes no están especializados y a su vez pueden ser aprendices o críticos, ninguno de ellos está limitado a un rol específico. Las piezas de información se distribuyen entre los agentes, pero pueden ser redundantes. No hay memoria central. El trabajo descrito aquí tiene su origen en un trabajo anterior sobre el aprendizaje en un sistema multiagente intencional utilizando un formalismo BDI [6]. En ese trabajo, los agentes tenían planes, cada uno de ellos asociado con un contexto que define en qué condiciones puede ser activado. Los planes (cada uno con su propio contexto) eran comunes a todo el conjunto de agentes en la comunidad. Los agentes tuvieron que adaptar su plan en función del contexto, dependiendo del fracaso o éxito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo a otros agentes ejemplos (éxitos o fracasos de planes). Sin embargo, este trabajo carecía de un protocolo de aprendizaje colectivo que permitiera una verdadera autonomía del sistema multiagente. El estudio de dicho protocolo es el objeto del presente artículo. En la sección 2 definimos formalmente la mas-consistencia de un mecanismo de actualización para todo el MAS y proponemos un mecanismo de actualización genérico demostrado que es mas consistente. En la sección 3 describimos SMILE, un aprendiz de conceptos multiagente incremental que aplica nuestro mecanismo de actualización mas consistente para el aprendizaje colaborativo de conceptos. La sección 4 describe varios experimentos sobre SMILE y discute varios problemas, incluyendo cómo varían la precisión y la simplicidad de la hipótesis actual al comparar el aprendizaje de un solo agente y el aprendizaje de múltiples agentes. En la sección 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la sección 6 discutiendo investigaciones adicionales sobre el aprendizaje más consistente. MODELO FORMAL 2.1 Definiciones y marco En esta sección, presentamos una formulación general del aprendizaje incremental colectivo en un sistema cognitivo de múltiples agentes. Representamos un MAS como un conjunto de agentes r1, ..., rn. Cada agente ri tiene un conjunto de creencias Bi que consiste en todo el conocimiento revisable que posee. Parte de estos conocimientos deben ser compartidos con otros agentes. La parte de Bi que es común a todos los agentes se denota como BC. Esta parte común provoca una dependencia entre los agentes. Si un agente ri actualiza su conjunto de creencias Bi a Bi, cambiando en el proceso BC en BC, entonces todos los demás agentes rk deben actualizar su conjunto de creencias Bk a Bk para que BC ⊆ Bk. Además, cada agente ri ha almacenado cierta información Ki. Suponemos que alguna propiedad de consistencia Cons(Bi, Ki) puede ser verificada por el agente mismo entre sus creencias Bi y su información Ki. Como se dijo antes, Bi representa el conocimiento que podría ser revisado, mientras que Ki representa hechos observados, considerados verdaderos, y que posiblemente puedan contradecir a Bi. Definición 1. a-consistencia de un agente Un agente ri es a-consistente si Cons(Bi, Ki) es verdadero. Ejemplo 1. El agente r1 tiene un conjunto de planes que se encuentran en la parte común BC de B1. Cada plan P tiene un contexto desencadenante d(P) (que actúa como una precondición) y un cuerpo. Alguna pieza de información k podría ser el plan P, desencadenado en la situación s, ha fallado a pesar de que s es una instancia de d(P). Si esta pieza de información se agrega a K1, entonces el agente r1 ya no es a-consistente: Cons(B1, K1 ∪ k) es falso. También queremos definir alguna noción de consistencia para todo el MAS dependiendo de los conjuntos de creencias e información de sus elementos constituyentes. Primero definiremos la consistencia de un agente ri con respecto a su conjunto de creencias Bi y su propio conjunto de información Ki junto con todos los conjuntos de información K1...Kn de los otros agentes del MAS. Simplemente lo haremos considerando cuál sería la a-consistencia del agente si tuviera la información de todos los demás agentes. Llamamos a esta noción la mas-consistencia: Definición 2. Un agente ri es mas-consistente si Cons(Bi, Ki ∪ K) es verdadero, donde K = ∪j∈{1,..,n}−{i}Kj 1 es el conjunto de toda la información de los otros agentes del MAS. 1 Lo notaremos como ∪ Kj cuando el contexto sea similar. Ejemplo 2. Usando el ejemplo anterior, supongamos que la pieza de información k está incluida en la información K2 del agente r2. Si la pieza de información no se transmite a r1, y por lo tanto no se agrega a K1, r1 permanece a-consistente. Sin embargo, r1 no es tan consistente como k en el conjunto K de toda la información del MAS. La consistencia global del MAS es simplemente la mas-consistencia de todos sus agentes. Definición 3. La consistencia de un MAS A MAS r1,...,rn es consistente si todos sus agentes ri son masconsistentes. Ahora definimos las propiedades requeridas para un mecanismo de revisión M que actualiza a un agente ri cuando recibe una pieza de información k. En lo siguiente, supondremos que: • La actualización siempre es posible, es decir, un agente siempre puede modificar su conjunto de creencias Bi para recuperar su a-consistencia. Diremos que cada agente es localmente eficiente. • Considerando dos conjuntos de información Cons(Bi, K1) y Cons(Bi, K2), también tenemos Cons(Bi, K1 ∪ K2). Es decir, la a-consistencia de los agentes es aditiva. • Si una pieza de información k relacionada con el conjunto común BC es consistente con un agente, es consistente con todos los agentes: para todos los pares de agentes (ri, rj) tales que Cons(Bi, Ki) y Cons(Bj, Kj) son verdaderos, tenemos, para toda pieza de información k: Cons(Bi, Ki ∪ k) si y solo si Cons(Bj, Kj ∪ k). En tal caso, diremos que el MAS es coherente. Esta última condición simplemente significa que el conjunto de creencias común BC es independiente de las posibles diferencias entre los conjuntos de creencias Bi de cada agente ri. En el caso más simple, B1 = ... = Bn = BC. M también será visto como un mecanismo de aprendizaje incremental y representado como una aplicación que cambia Bi en Bi. En lo siguiente, anotaremos ri(Bi, Ki) para ri cuando sea útil. Definición 4. a-consistencia de una revisión Un mecanismo de actualización M es a-consistente si, para cualquier agente ri y cualquier pieza de información k que llegue a ri, la a-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki) a-consistente ⇒ ri(Bi, Ki) a-consistente, donde Bi = M(Bi) y Ki = Ki ∪ k es el conjunto de toda la información de otros agentes del MAS. De la misma manera, definimos la mas-consistencia de un mecanismo de revisión como la a-consistencia de este mecanismo si los agentes disponen de toda la información en el MAS. En lo siguiente, anotaremos, si es necesario, ri(Bi, Ki, K) para el agente ri en el MAS r1 . . . rn. Definición 5. mas-consistencia de una revisión Un mecanismo de actualización Ms es mas-consistente si para todo agente ri y toda pieza de información k que llega a ri, la mas-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki, K) más-consistente ⇒ ri(Bi, Ki, K) más-consistente, donde Bi = Ms(Bi), Ki = Ki ∪ k, y K = ∪Kj es el conjunto de toda la información del MAS. El Sexto Internacional. En última instancia, cuando un agente aplica un mecanismo mas-consistente al recibir una nueva pieza de información, un efecto secundario deseable del mecanismo debería ser que todos los demás agentes permanezcan mas-consistentes después de cualquier modificación de la parte común BC, es decir, el MAS en sí mismo debería volver a ser consistente. Esta propiedad se define de la siguiente manera: Definición 6. La fuerte mas-consistencia de un mecanismo de actualización. Un mecanismo de actualización Ms es fuertemente mas-consistente si - Ms es mas-consistente, y - la aplicación de Ms por un agente preserva la consistencia del MAS. 2.2 Un mecanismo de actualización fuertemente mas-consistente. La idea general es que, dado que la información está distribuida entre todos los agentes del MAS, debe haber alguna interacción entre el agente aprendiz y los demás agentes en un mecanismo de actualización fuertemente mas-consistente Ms. Para garantizar su mas-consistencia, Ms estará constituido por aplicaciones reiteradas por parte del agente aprendiz ri de un mecanismo interno a-consistente M, seguido por algunas interacciones entre ri y los otros agentes, hasta que ri recupere su mas-consistencia. Describimos a continuación un mecanismo, primero con una descripción de una interacción, luego una iteración y finalmente una declaración de la condición de terminación del mecanismo. El mecanismo es activado por un agente ri al recibir una pieza de información k que interrumpe la mas-consistencia. Tomaremos M(Bi) como el conjunto de creencias del agente aprendiz ri después de una actualización, BC la parte común modificada por ri, y Bj el conjunto de creencias de otro agente rj inducido por la modificación de su parte común BC en BC. Una interacción I(ri, rj) entre el agente aprendiz ri y otro agente rj, actuando como crítico, está constituida por los siguientes pasos: • el agente ri envía la actualización BC de la parte común de sus creencias. Habiendo aplicado su mecanismo de actualización, ri es a-consistente. • El agente rj verifica la modificación Bj de sus creencias inducida por la actualización BC. Si esta modificación conserva su a-consistencia, rj adopta esta modificación. El agente rj envía ya sea una aceptación de BC o una negación junto con una (o más) pieza(s) de información k tal que Cons(Bj, k) es falso. Una iteración de Ms estará compuesta por: • la recepción por parte del agente aprendiz ri de una pieza de información y la actualización M(Bi) restaurando su consistencia • un conjunto de interacciones I(ri, rj) (en las cuales varios agentes críticos posiblemente puedan participar). Si al menos una pieza de información k es transmitida a ri, la adición de k necesariamente hará que ri sea inconsistente y entonces ocurrirá una nueva iteración. Este mecanismo termina cuando ningún agente puede proporcionar tal pieza de información k. Cuando es el caso, se restaura la masconsistencia del agente aprendiz ri. Proposición 1. Dejen que r1,...,rn sea un MAS consistente en el que el agente ri recibe una pieza de información k que rompe su consistencia, y M sea un mecanismo interno de actualización a-consistente. El mecanismo de actualización descrito anteriormente por Ms es altamente mas-consistente. Prueba. La prueba se deriva directamente de la descripción del mecanismo. Este mecanismo asegura que cada vez que un agente recibe un evento, su mas-consistencia será restaurada. Como los otros agentes adoptan la actualización final BC, todos son mas-coherentes y el MAS es coherente. Por lo tanto, Ms es un mecanismo de actualización fuertemente consistente. En el mecanismo descrito anteriormente, el agente aprendiz es el único que recibe y memoriza información durante la ejecución del mecanismo. Se asegura de que Ms termine. Las piezas de información transmitidas por otros agentes y memorizadas por el agente aprendiz son redundantes, ya que ya están presentes en el MAS, más precisamente en la memoria de los agentes críticos que las transmitieron. Se debe tener en cuenta que el mecanismo propuesto por la Sra. aquí no indica explícitamente el orden ni el alcance de las interacciones. Consideraremos en lo siguiente que la propuesta de modificación BC se envía secuencialmente a los diferentes agentes (mecanismo síncrono). Además, la respuesta de un agente crítico solo contendrá una pieza de información inconsistente con la modificación propuesta. Diremos que la respuesta del agente es mínima. Este mecanismo, siendo sincrónico con una respuesta mínima, minimiza la cantidad de información transmitida por los agentes. Ahora lo ilustraremos en el caso del aprendizaje de conceptos multiagente. 3. APRENDIZAJE INCREMENTAL DE MÚLTIPLES AGENTES 3.1 La tarea de aprendizaje Experimentamos el mecanismo propuesto anteriormente en el caso del aprendizaje conceptual MAS incremental. Aquí consideramos un lenguaje de hipótesis en el cual una hipótesis es una disyunción de términos. Cada término es una conjunción de átomos de un conjunto A. Un ejemplo está representado por una etiqueta + o − y una descripción 2 compuesta por un subconjunto de átomos e ⊆ A. Un término abarca un ejemplo si sus átomos constituyentes están incluidos en el ejemplo. Una hipótesis abarca un ejemplo si uno de sus términos lo abarca. Esta representación se utilizará a continuación para aprender fórmulas booleanas. Los literales negativos se representan aquí mediante átomos adicionales, como not − a. La fórmula booleana f = (a ∧ b) ∨ (b ∧ ¬c) se escribirá entonces como (a ∧ b) ∨ (b ∧ no − c). Un ejemplo positivo de f, como {no − a, b, no − c}, representa un modelo para f. 3.2 Proceso de aprendizaje incremental El <br>proceso de aprendizaje</br> es un mecanismo de actualización que, dado una hipótesis actual H, una memoria E = E+ ∪ E− llenada con los ejemplos recibidos previamente, y un nuevo ejemplo positivo o negativo e, produce una nueva hipótesis actualizada. Antes de esta actualización, la hipótesis dada es completa, lo que significa que cubre todos los ejemplos positivos de E+, y 2 Cuando no haya posibilidad de confusión, la palabra ejemplo se utilizará para referirse al par (etiqueta, descripción) así como a la descripción sola. 166 La Sexta Conferencia Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) es coherente, lo que significa que no cubre ningún ejemplo negativo de E−. Después de la actualización, la nueva hipótesis debe ser completa y coherente con el nuevo estado de memoria E ∪ {e}. Describimos a continuación nuestro mecanismo de actualización de agente único, inspirado en un trabajo previo sobre aprendizaje incremental[7]. En lo siguiente, una hipótesis H para la fórmula objetivo f es una lista de términos h, cada uno de ellos siendo una conjunción de átomos. H es coherente si todos los términos h son coherentes, y H es completo si cada elemento de E+ está cubierto por al menos un término h de H. Cada término es, por construcción, la lgg (generalización general menos general) de un subconjunto de instancias positivas {e1, ..., en}, es decir, el término más específico que cubre {e1, ..., en}. El operador lgg se define considerando ejemplos como términos, por lo que denotamos como lgg(e) al término más específico que cubre e, y como lgg(h, e) al término más específico que es más general que h y que cubre e. Restringir el término a lgg es la base de muchos algoritmos de aprendizaje de abajo hacia arriba (por ejemplo [5]). En la tipología propuesta por [9], nuestro mecanismo de actualización es un aprendiz incremental con memoria completa de instancias: el aprendizaje se realiza mediante actualizaciones sucesivas y se almacenan todos los ejemplos. El mecanismo de actualización depende de la hipótesis en curso H, los ejemplos en curso E+ y E−, y el nuevo ejemplo e. Hay tres casos posibles: • e es positivo y H cubre e, o e es negativo y H no cubre e. No se necesita actualización, H ya es completo y coherente con E ∪ {e}. • e es positivo y H no cubre e: e se denota como un contraejemplo positivo de H. Luego buscamos generalizar a su vez los términos h de H. Tan pronto como se encuentre una generalización correcta h = lgg(h, e), h reemplaza a h en H. Si hay un término que es menos general que h, se descarta. Si ninguna generalización es correcta (es decir, coherente), H ∪ lgg(e) reemplaza a H. • e es negativo y H cubre e: e se denota como un contraejemplo negativo de H. Cada término h que cubre e es entonces descartado de H y reemplazado por un conjunto de términos {h1, ...., hn} que, en su totalidad, es coherente con E− ∪ {e} y que cubre los ejemplos de E+ no cubiertos por H − {h}. Los términos de la hipótesis final H que son menos generales que otros son descartados de H. Ahora describiremos el caso en el que e = e− es un ejemplo negativo cubierto. Las siguientes funciones se utilizan aquí: • coveredOnlyBy(h, E+) da el subconjunto de E+ cubierto por h y ningún otro término de H. • bestCover(h1, h2) da h1 si h1 cubre más ejemplos de uncoveredPos que h2, de lo contrario da h2. • covered(h) da los elementos de uncoveredPos cubiertos por h. // Especialización de cada h cubriendo e− para cada h de H cubriendo e− hacer H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= átomos que no están ni en e− ni en h mientras (uncoveredPos = ∅) hacer // buscando la mejor especialización de h hc=h best=⊥ // ⊥ no cubre ningún ejemplo para cada a de Ar hacer hc= h ∧ a best = bestCover(hc, best) finpara Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) finmientras finpara Los términos de H que son menos generales que otros son descartados. Ten en cuenta que este mecanismo tiende tanto a hacer una actualización mínima de la hipótesis actual como a minimizar el número de términos en la hipótesis, en particular descartando términos menos generales que otros después de actualizar una hipótesis. 3.3 Aprendizaje colectivo Si H es la hipótesis actual, Ei es la memoria actual de ejemplos del agente ri y E es el conjunto de todos los ejemplos recibidos por el sistema, la notación de la sección 2 se convierte en Bi = BC = H, Ki = Ei y K = E. Cons(H, Ei) establece que H es completo y coherente con Ei. En tal caso, ri es a-consistente. La pieza de información k recibida por el agente ri es aquí simplemente un ejemplo e junto con su etiqueta. Si e es tal que la hipótesis actual H no es completa ni coherente con Ei ∪ {e}, e contradice a H: ri se vuelve a-inconsistente, y por lo tanto el MAS ya no es consistente. La actualización de una hipótesis cuando llega un nuevo ejemplo es un mecanismo a-consistente. Siguiendo la proposición 1, este mecanismo puede ser utilizado para producir un mecanismo fuerte mas-consistente: al recibir un nuevo ejemplo en el MAS por un agente r, posiblemente se necesite una actualización y, después de un conjunto de interacciones entre r y los otros agentes, resulta en una nueva hipótesis compartida por todos los agentes y que restaura la consistencia del MAS, es decir, que es completa y coherente con el conjunto ES de todos los ejemplos presentes en el MAS. Es claro que al minimizar el número de modificaciones de hipótesis, este mecanismo sincrónico y minimalista reduce el número de ejemplos recibidos por el aprendiz de otros agentes, y por ende, el número total de ejemplos almacenados en el sistema. 4. EXPERIMENTOS En lo siguiente, aprenderemos una fórmula booleana que es una prueba difícil para el método de aprendizaje: el 11-multiplexor (ver [4]). Se refiere a 3 atributos booleanos de dirección a0, a1, a2 y 8 atributos booleanos de datos d0, ..., d7. La fórmula f11 se cumple si el número codificado por los 3 atributos de dirección es el número de un atributo de datos cuyo valor es 1. Su fórmula es la siguiente: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0). Hay 2048 = 211 posibles ejemplos, la mitad de los cuales son positivos (lo que significa que satisfacen f11) mientras que la otra mitad es negativa. Un experimento suele estar compuesto por 50 pruebas. Cada ejecución corresponde a una secuencia de 600 ejemplos que son aprendidos de forma incremental por un Sistema Multiagente con n agentes. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 167 (n-MAS). Un número de variables como la precisión (es decir, la frecuencia de clasificación correcta de un conjunto de ejemplos no vistos), el tamaño de la hipótesis (es decir, el número de términos en la fórmula actual) o el número de ejemplos almacenados, se registra cada vez que el sistema recibe 25 ejemplos durante esas ejecuciones. En el protocolo que se utiliza aquí, un nuevo ejemplo se envía a un agente aleatorio cuando el MAS es consistente. El siguiente ejemplo será enviado a su vez a otro agente cuando la consistencia del MAS haya sido restaurada. De esta manera simulamos una especie de aprendizaje lento: la frecuencia de llegada de ejemplos es lenta en comparación con el tiempo que lleva una actualización. 4.1 Eficiencia del aprendizaje conceptual en MAS 4.1.1 Tiempo de ejecución Discutimos brevemente aquí el tiempo de ejecución del aprendizaje en el MAS. Se debe tener en cuenta que todo el conjunto de acciones e interacciones en el MAS se simula en un solo procesador. La Figura 1 muestra que el tiempo depende linealmente del número de agentes. Al final de la parte más activa del aprendizaje (200 ejemplos), un 16MAS ha tomado 4 veces más tiempo de aprendizaje que un 4-MAS. Este tiempo de ejecución representa el conjunto completo de aprendizaje y la Figura 1: Tiempo de ejecución de un n-MAS (desde n = 2 en la parte inferior hasta n = 20 en la parte superior). actividad de comunicación y sugiere el costo de mantener una hipótesis de aprendizaje consistente en un MAS compuesto por agentes autónomos. 4.1.2 Redundancia en la memoria del MAS Estudiamos ahora la distribución de los ejemplos en la memoria del MAS. La redundancia se escribe RS = nS/ne, donde nS es el número total de ejemplos almacenados en el MAS, que es la suma de los tamaños de las memorias de ejemplos de los agentes Ei, y ne es el número total de ejemplos recibidos del entorno en el MAS. En la figura 2, comparamos las redundancias en MAS de 2 a 20 agentes. Hay un pico que se mueve lentamente de 80 a 100 ejemplos, que representa la cantidad de ejemplos para los cuales el aprendizaje es más activo. Para 20 agentes, la redundancia máxima no es más de 6, lo cual es mucho menor que el valor teórico máximo de 20. Ten en cuenta que cuando el aprendizaje se vuelve menos activo, la redundancia tiende hacia su valor mínimo 1: cuando ya no hay más actualizaciones, los ejemplos son solo la Figura 2: Redundancia de ejemplos almacenados en un nMAS (de n = 2 en la parte inferior a n = 20 en la parte superior) almacenados por el agente que los recibe. Un n-MAS selecciona una solución más simple que un solo agente. El mecanismo propuesto tiende a minimizar el número de términos en la hipótesis seleccionada. Durante el aprendizaje, el tamaño de la hipótesis actual crece más allá del óptimo, y luego disminuye cuando el MAS converge. En el banco de pruebas Multiplexer 11, el número óptimo de términos es 8, pero también existen fórmulas equivalentes con más términos. Es interesante notar que en este caso el 10-MAS converge hacia una solución exacta más cercana al número óptimo de términos (en este caso 8) (ver Figura 3). Después de haber presentado 1450 ejemplos, tanto el 1-MAS como el 10-MAS han aprendido exactamente el concepto (las precisiones respectivas son 0.9999 y 1), pero el agente individual expresa en promedio el resultado como una DNF de 11.0 términos, mientras que el 10-MAS lo expresa como una DNF de 8.8 términos. Sin embargo, para algunas otras funciones booleanas encontramos que durante el aprendizaje, 1-MAS siempre produce hipótesis más grandes que 10-MAS, pero que ambos MAS convergen a hipótesis con resultados de tamaño similar. 4.1.4 Un n-MAS es más preciso que un agente único. La Figura 4 muestra la mejora proporcionada por un MAS con n agentes en comparación con un agente único. Esta mejora no era especialmente esperada, porque ya sea que tengamos uno o n agentes, cuando se le dan N ejemplos al MAS, tiene acceso a la misma cantidad de información, mantiene solo una hipótesis en curso y utiliza el mismo algoritmo básico de revisión cada vez que un agente tiene que modificar la hipótesis actual. Ten en cuenta que si la precisión de los MAS de 1, 2, 4 y 10 es significativamente diferente, mejorando a medida que aumenta el número de agentes, no hay una diferencia clara más allá de este punto: la curva de precisión de los MAS de 100 agentes es muy similar a la de los MAS de 10 agentes. 4.1.4.1 Fórmulas booleanas. Para evaluar esta mejora de precisión, hemos experimentado nuestro protocolo en otros problemas de aprendizaje de funciones booleanas. Como en el caso del Multiplexor-11, estas funciones 168 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 3: Tamaño de la hipótesis construida por 1 y 10MAS: el caso M11. Figura 4: Precisión de un n-MAS: el caso M11 (de abajo hacia arriba, n = 1, 2, 4, 10, 100). Se aprenden en forma de DNF3 más o menos sintácticamente complejos (es decir, con más o menos términos conjuntivos en la DNF), pero también son más o menos difíciles de aprender, ya que puede ser difícil encontrar su camino en el espacio de hipótesis para alcanzarlos. Además, la presencia en la descripción de atributos irrelevantes (es decir, atributos que no pertenecen al DNF objetivo) hace que el problema sea más difícil. Los siguientes problemas han sido seleccionados para experimentar con nuestro protocolo: (i) el multiplexor-11 con 9 atributos irrelevantes: M11 9, (ii) el multiplexor-20 M20 (con 4 bits de dirección y 16 bits de datos), (iii) un problema de paridad difícil (ver [4]) el Xorp m: debe haber un número impar de bits con valor 1 en los primeros p atributos para que la instancia sea positiva, los p bits restantes son irrelevantes, y (iv) una fórmula DNF simple (a ∧ b ∧ c) ∨ (c ∧ d ∧ e) ∨ (e ∧ f ∧ g) ∧ (g ∧ h ∧ i) con 19 atributos irrelevantes. La siguiente tabla resume alguna información sobre estos problemas, proporcionando el número total de atributos, incluidos los irrelevantes, el número de atributos irrelevantes en Forma Normal Disyuntiva 3, el número mínimo de términos de la DNF correspondiente, y el número de ejemplos de aprendizaje utilizados. Pb att. irre. att. términos ex. A continuación se presentan los resultados de precisión de nuestro mecanismo de aprendizaje con un solo agente y un MAS de 10 agentes, junto con los resultados de dos algoritmos estándar implementados con el entorno de aprendizaje WEKA[16]: JRip (una implementación de RIPPER[2]) e Id3[12]. Para los experimentos con JRip e Id3, medimos la precisión media en 50 pruebas, separando aleatoriamente los ejemplos en un conjunto de aprendizaje y un conjunto de prueba cada vez. Los parámetros de JRip e Id3 son los predeterminados, excepto que JRip se utiliza sin poda. La siguiente tabla muestra los resultados: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 Es claro que los problemas difíciles se resuelven mejor con más agentes (ver por ejemplo xor5 15). Creemos que estos beneficios, que pueden ser importantes con un número creciente de agentes, se deben al hecho de que cada agente realmente memoriza solo parte del número total de ejemplos, y esta parte es seleccionada en parte por otros agentes como contraejemplos, lo que provoca un mayor número de actualizaciones de hipótesis actuales y, por lo tanto, una mejor exploración del espacio de hipótesis. 4.1.4.2 Problemas de base de datos de ML. También realizamos experimentos con algunos problemas no booleanos. Consideramos solo problemas de dos clases (positivo/negativo), tomados de la base de datos de problemas de aprendizaje de UCIs. En todos estos problemas, los ejemplos se describen como un vector de pares (atributo, valor). Los dominios de valor pueden ser booleanos, numéricos (conjunto totalmente ordenado) o nominales (conjunto no ordenado). Un conjunto adecuado de átomos A debe ser constituido para cada problema. Por ejemplo, si a es un atributo numérico, definimos como máximo k umbrales si, dando k+1 intervalos de densidad uniforme. Por lo tanto, cada umbral distintivo si da dos átomos, uno ≤ si y otro > si. En nuestros experimentos, tomamos un número máximo de umbral k = 8. Por ejemplo, en el caso del problema de iono, había 34 atributos numéricos, y una instancia se describe con 506 átomos. A continuación se presentan los resultados de precisión de nuestro sistema junto con los resultados anteriores. La columna Nb ex. se refiere al 4. La probabilidad de que el valor de a esté en cualquier intervalo es constante. El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 169 número de ejemplos utilizados para el aprendizaje5. La columna (1) representa los valores de precisión mínima y máxima para los treinta y tres clasificadores probados en [8]. La columna (2) representa los resultados de [13], donde se comparan varios métodos de aprendizaje con métodos de aprendizaje en conjunto utilizando conjuntos de clasificadores ponderados. La columna S-1 y S-10 dan la precisión de SMILE con 1 y 10 agentes, respectivamente. Esta tabla muestra que el algoritmo incremental correspondiente al caso de un solo agente, proporciona resultados honorables en relación a los métodos clásicos no incrementales que utilizan hipótesis más grandes y complejas. En algunos casos, hay una mejora en la precisión con un MAS de 10 agentes. Sin embargo, con datos de referencia de este tipo, que suelen ser ruidosos, la dificultad no radica realmente en la forma en que se explora el espacio de búsqueda, por lo que la mejora observada no siempre es significativa. El mismo tipo de fenómeno se ha observado con métodos dedicados a problemas booleanos difíciles [4]. 4.2 Sincronización de MAS En este caso consideramos que n agentes individuales aprenden sin interacciones y en un momento dado comienzan a interactuar, formando así un MAS. El propósito es observar cómo los agentes aprovechan la colaboración cuando parten de diferentes estados de creencias y memorias. En esta sección comparamos un 1-MAS, un 10-MAS (ref) y un 10-MAS (100sync) cuyos agentes no se comunicaron durante la llegada de los primeros 100 ejemplos (10 por agentes). Las tres curvas de precisión se muestran en la figura 5. Al comparar la curva del agente individual con la del 10-MAS sincronizado, podemos observar que después del inicio de la sincronización, es decir, en 125 ejemplos, las precisiones son idénticas. Esto era esperado ya que tan pronto como un ejemplo e recibido por el MAS contradice la hipótesis actual del agente ra que lo recibe, este agente realiza una actualización y su nueva hipótesis es propuesta a los otros agentes para su crítica. Por lo tanto, este primer ejemplo contradictorio lleva al MAS a alcanzar coherencia en relación con todo el conjunto de ejemplos presentes en la memoria de los agentes. Una mayor precisión, correspondiente a un 10-MAS, se obtiene más tarde, a partir del ejemplo 175. En otras palabras, el beneficio de una mejor exploración del espacio de investigación se obtiene ligeramente más tarde en el <br>proceso de aprendizaje</br>. Ten en cuenta que esta sincronización ocurre de forma natural en todas las situaciones en las que los agentes tienen, por alguna razón, una divergencia entre su hipótesis y la memoria del sistema. Esto incluye la fusión de dos MAS en una sola o la llegada de nuevos agentes en un MAS existente. 4.3 Experimentos sobre el aprendizaje asincrónico: el efecto de un gran flujo de datos. Para ttt y kr-vs-kp, nuestro protocolo no utilizó más de 574 y 958 ejemplos de aprendizaje respectivamente, por lo que colocamos otro número en la columna. Figura 5: Precisión de un 1-MAS, un 10-MAS y un 10-MAS sincronizado después de 100 ejemplos. En este experimento relajamos nuestro modo de aprendizaje lento: los ejemplos se envían a una velocidad determinada al MAS. El flujo de ejemplos resultante se mide en ms−1, y representa la cantidad de ejemplos enviados al MAS cada milisegundo. Cuando el flujo es demasiado grande, el MAS no puede alcanzar la consistencia del MAS al recibir un ejemplo del entorno antes de que llegue un nuevo ejemplo. Esto significa que el proceso de actualización, iniciado por el agente r0 al recibir un ejemplo, puede estar incompleto cuando un nuevo ejemplo es recibido por r0 u otro agente r1. Como resultado, un agente crítico puede tener que enviar contraejemplos de hipótesis enviadas por varios agentes en el instante t. Sin embargo, en nuestro entorno, a medida que los agentes memorizan todos los ejemplos que reciben cuando finaliza el flujo, el MAS alcanza necesariamente consistencia MAS con respecto a todos los ejemplos recibidos hasta el momento. En nuestros experimentos, aunque la curva de aprendizaje se ralentiza durante la fase intensa de aprendizaje (correspondiente a una baja precisión de las hipótesis actuales), el MAS aún logra alcanzar una hipótesis satisfactoria más adelante, ya que hay menos contraejemplos en el flujo de ejemplos. En la Figura 6 comparamos las precisiones de dos 11-MAS respectivamente sometidos a flujos de ejemplos de diferentes tasas al aprender la fórmula M11. La curva de aprendizaje del MAS al recibir un ejemplo a una velocidad de 1/33 ms−1 casi no se ve alterada (ver Figura 4), mientras que el MAS a 1/16 ms−1 primero se ralentiza severamente antes de alcanzar al primero. 5. TRABAJOS RELACIONADOS Desde el 96 [15], se han realizado varios trabajos sobre el aprendizaje en Sistemas Multiagente, pero muy pocos sobre el aprendizaje de conceptos. En [11] el MAS realiza una forma de aprendizaje en conjunto en la que los agentes son aprendices perezosos (no se mantiene una representación explícita) y venden ejemplos inútiles a otros agentes. En [10] cada agente observa todos los ejemplos pero solo percibe una parte de su representación. En el aprendizaje de conceptos en línea mutuo, los agentes convergen hacia una hipótesis única, pero cada agente produce ejemplos desde su propia representación del concepto, lo que resulta en una especie de sincronización en lugar de un aprendizaje de conceptos puro. 170 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Precisión de dos sistemas multiagente asincrónicos de 11 agentes (tasas de ejemplo de 1/33ms−1 y 1/16ms−1). 6. CONCLUSIÓN Hemos presentado y experimentado un protocolo para el aprendizaje de conceptos en línea de MAS. La característica principal de este mecanismo de aprendizaje colaborativo es que mantiene una propiedad de consistencia: aunque durante el <br>proceso de aprendizaje</br> cada agente solo recibe y almacena, con cierta redundancia limitada, parte de los ejemplos recibidos por el MAS, en cualquier momento la hipótesis actual es consistente con todo el conjunto de ejemplos. Las hipótesis de nuestros experimentos no abordan los problemas de los MAS distribuidos, como fallos (por ejemplo, mensajes perdidos o corruptos) u otras fallas en general (crash, fallos bizantinos, etc.). Sin embargo, nuestro marco de trabajo es abierto, es decir, los agentes pueden salir del sistema o ingresar a él mientras se preserva el mecanismo de consistencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente crítico se bloquea o no responde, se garantiza la consistencia con los otros críticos (dentro de los agentes restantes). En [1], se ha aplicado un enfoque similar a los problemas de abducción en MAS: las hipótesis a mantener, dada una información incompleta, son entonces hechos o afirmaciones. El trabajo adicional se refiere en primer lugar a acoplar la inducción y la abducción para realizar un aprendizaje colaborativo de conceptos cuando los ejemplos son solo parcialmente observados por cada agente, y en segundo lugar, a investigar el aprendizaje de memoria parcial: cómo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados. Agradecimientos Estamos muy agradecidos a Dominique Bouthinon por implementar las modificaciones tardías en SMILE, facilitando mucho nuestros experimentos. Parte de este trabajo se realizó durante la visita del primer autor al Atelier De BioInformatique de la Universidad Paris VI, Francia. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En DALT-2006, mayo de 2006. [2] W. W. Cohen. Inducción de reglas rápida y efectiva. En ICML, páginas 115-123, 1995. [3] C. B. D.J. Newman, S. Hettich y C. Merz. Repositorio de bases de datos de aprendizaje automático de UCI, 1998. [4] S. Esmeir y S. Markovitch. Algoritmos basados en anticipación para la inducción en cualquier momento de árboles de decisión. En ICMLO4, páginas 257-264. Morgan Kaufmann, 2004. [5] J. F¨urnkranz. \n\nMorgan Kaufmann, 2004. [5] J. F¨urnkranz. Una patología de la escalada de colina de abajo hacia arriba en el aprendizaje inductivo de reglas. En ALT, volumen 2533 de LNCS, páginas 263-277. Springer, 2002. [6] A. Guerra-Hernández, A. ElFallah-Seghrouchni y H. Soldano. Aprendizaje en sistemas multiagente BDI. En CLIMA IV, volumen 3259, páginas 218-233. Springer Verlag, 2004. [7] M. Henniche. \n\nSpringer Verlag, 2004. [7] M. Henniche. Mgi: un algoritmo incremental de abajo hacia arriba. En la Conferencia IEEE de Australia y Nueva Zelanda sobre Sistemas de Información Inteligente, páginas 347-351, 1994. [8] T.-S. Lim, W.-Y. Loh, y Y.-S. Shih. Una comparación de la precisión de predicción, complejidad y tiempo de entrenamiento de treinta y tres algoritmos de clasificación antiguos y nuevos. Aprendizaje automático, 40(3):203-228, 2000. [9] M. A. Maloof y R. S. Michalski. Aprendizaje incremental con memoria parcial de instancias. I'm sorry, but the sentence \"Artif.\" is not a complete sentence. Can you provide more context or a complete sentence for me to translate to Spanish? Intell., 154(1-2):95-126, 2004. [10] P. J. Modi y W.-M. Shen. Aprendizaje colaborativo multiagente para tareas de clasificación. En AGENTS 01, páginas 37-38. ACM Press, 2001. [11] S. Onta˜non y E. Plaza. Reciclaje de datos para el aprendizaje multiagente. En ICML 05, páginas 633-640. ACM Press, 2005. [12] J. R. Quinlan. \n\nACM Press, 2005. [12] J. R. Quinlan. Inducción de árboles de decisión. Aprendizaje automático, 1(1):81-106, 1986. [13] U. R¨uckert y S. Kramer. Hacia límites ajustados para el aprendizaje de reglas. En ICML 04 (Conferencia Internacional sobre Aprendizaje Automático), página 90, Nueva York, NY, EE. UU., 2004. ACM Press. [14] J. Wang y L. Gasser. Aprendizaje de conceptos en línea mutuo para múltiples agentes. En AAMAS, páginas 362-369. ACM Press, 2002. [15] G. Weiß y S. Sen, editores. Adaptación y Aprendizaje en Sistemas Multiagente, volumen 1042 de las Notas de Conferencia en Ciencias de la Computación. Springer, 1996. [16] I. H. Witten y E. Frank. Minería de datos: Herramientas y técnicas prácticas de aprendizaje automático con implementaciones en Java. Morgan Kaufmann, octubre de 1999. La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 171 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "knowledge": {
            "translated_key": "conocimiento",
            "is_in_text": true,
            "original_annotated_sentences": [
                "SMILE: Sound Multi-agent Incremental LEarning ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av.",
                "du pr´esident Kennedy, 75116 Paris Henry Soldano LIPN, UMR 7030 CNRS, University Paris-Nord, 99 Av.",
                "J-B Clement, 93430, Villetaneuse ABSTRACT This article deals with the problem of collaborative learning in a multi-agent system.",
                "Here each agent can update incrementally its beliefs B (the concept representation) so that it is in a way kept consistent with the whole set of information K (the examples) that he has received from the environment or other agents.",
                "We extend this notion of consistency (or soundness) to the whole MAS and discuss how to obtain that, at any moment, a same consistent concept representation is present in each agent.",
                "The corresponding protocol is applied to supervised concept learning.",
                "The resulting method SMILE (standing for Sound Multiagent Incremental LEarning) is described and experimented here.",
                "Surprisingly some difficult boolean formulas are better learned, given the same learning set, by a Multi agent system than by a single agent.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Concept learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent system General Terms Experimentation, Algorithms, Measurement, Performance 1.",
                "INTRODUCTION This article deals with the problem of collaborative concept learning in a multi-agent system. [6] introduces a characterisation of learning in multi-agent system according to the level of awareness of the agents.",
                "At level 1, agents learn ∗The primary author of this paper is a student. in the system without taking into account the presence of other agents, except through the modification brought upon the environment by their action.",
                "Level 2 implies direct interaction between the agents as they can exchange messages to improve their learning.",
                "Level 3 would require agents to take into account the competencies of other agents, and be able to learn from observation of the other agents behaviour (while considering them as independant entities and not indetermined part of the environment as in level 1).",
                "We focus in this paper on level 2, studying direct interaction between agents involved in a learning process.",
                "Each agent is assumed to be able to learn incrementally from the data he receives, meaning that each agent can update his belief set B to keep it consistent with the whole set of information K that he has received from the environment or from other agents.",
                "In such a case, we will say that he is a-consistent.",
                "Here, the belief set B represents hypothetical <br>knowledge</br> that can therefore be revised, whereas the set of information K represents certain <br>knowledge</br>, consisting of non revisable observations and facts.",
                "Moreover, we suppose that at least a part Bc of the beliefs of each agent is common to all agents and must stay that way.",
                "Therefore, an update of this common set Bc by agent r must provoke an update of Bc for the whole community of agents.",
                "It leads us to define what is the mas-consistency of an agent with respect to the community.",
                "The update process of the community beliefs when one of its members gets new information can then be defined as the consistency maintenance process ensuring that every agent in the community will stay masconsistent.",
                "This mas-consistency maintenance process of an agent getting new information gives him the role of a learner and implies communication with other agents acting as critics.",
                "However, agents are not specialised and can in turn be learners or critics, none of them being kept to a specific role.",
                "Pieces of information are distributed among the agents, but can be redundant.",
                "There is no central memory.",
                "The work described here has its origin in a former work concerning learning in an intentional multi-agent system using a BDI formalism [6].",
                "In that work, agents had plans, each of them being associated with a context defining in which conditions it can be triggered.",
                "Plans (each of them having its own context) were common to the whole set of agents in the community.",
                "Agents had to adapt their plan contexts depending on the failure or success of executed plans, using a learning mechanism and asking other agents for examples (plans successes or failures).",
                "However this work lacked a collective learning protocol enabling a real autonomy of the multi-agent system.",
                "The study of such a protocol is the object of the present paper.",
                "In section 2 we formally define the mas-consistency of an update mechanism for the whole MAS and we propose a generic update mechanism proved to be mas consistent.",
                "In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent update mechanism to collaborative concept learning.",
                "Section 4 describes various experiments on SMILE and discusses various issues including how the accuracy and the simplicity of the current hypothesis vary when comparing single agent learning and mas learning.",
                "In section 5 we briefly present some related works and then conclude in section 6 by discussing further investigations on mas consistent learning. 2.",
                "FORMAL MODEL 2.1 Definitions and framework In this section, we present a general formulation of collective incremental learning in a cognitive multi agent system.",
                "We represent a MAS as a set of agents r1, ..., rn.",
                "Each agent ri has a belief set Bi consisting of all the revisable <br>knowledge</br> he has.",
                "Part of these knowledges must be shared with other agents.",
                "The part of Bi that is common to all agents is denoted as BC .",
                "This common part provokes a dependency between the agents.",
                "If an agent ri updates his belief set Bi to Bi, changing in the process BC into BC , all other agents rk must then update their belief set Bk to Bk so that BC ⊆ Bk.",
                "Moreover, each agent ri has stored some certain information Ki.",
                "We suppose that some consistency property Cons(Bi, Ki) can be verified by the agent itself between its beliefs Bi and its information Ki.",
                "As said before, Bi represents <br>knowledge</br> that might be revised whereas Ki represents observed facts, taken as being true, and which can possibly contradict Bi.",
                "Definition 1. a-consistency of an agent An agent ri is a-consistent iff Cons(Bi, Ki) is true.",
                "Example 1.",
                "Agent r1 has a set of plans which are in the common part BC of B1.",
                "Each plan P has a triggering context d(P) (which acts as a pre-condition) and a body.",
                "Some piece of information k could be plan P, triggered in situation s, has failed in spite of s being an instance of d(P).",
                "If this piece of information is added to K1, then agent r1 is not a-consistent anymore: Cons(B1, K1 ∪ k) is false.",
                "We also want to define some notion of consistency for the whole MAS depending on the belief and information sets of its constituting elements.",
                "We will first define the consistency of an agent ri with respect to its belief set Bi and its own information set Ki together with all information sets K1...Kn from the other agents of the MAS.",
                "We will simply do that by considering what would be the a-consistency of the agent if he has the information of all the other agents.",
                "We call this notion the mas-consistency: Definition 2. mas-consistency of an agent An agent ri is mas-consistent iff Cons(Bi, Ki ∪ K) is true, where K = ∪j∈{1,..,n}−{i}Kj 1 is the set of all information from other agents of the MAS. 1 We will note this ∪ Kj when the context is similar.",
                "Example 2.",
                "Using the previous example, suppose that the piece of information k is included in the information K2 of agent r2.",
                "As long as the piece of information is not transmitted to r1, and so added to K1 , r1 remains a-consistent.",
                "However, r1 is not mas-consistent as k is in the set K of all information of the MAS.",
                "The global consistency of the MAS is then simply the mas-consistency of all its agents.",
                "Definition 3.",
                "Consistency of a MAS A MAS r1,...,rn is consistent iff all its agents ri are masconsistent.",
                "We now define the required properties for a revision mechanism M updating an agent ri when it gets a piece of information k. In the following, we will suppose that: • Update is always possible, that is, an agent can always modify its belief set Bi in order to regain its a-consistency.",
                "We will say that each agent is locally efficient. • Considering two sets of information Cons(Bi, K1) and Cons(Bi, K2), we also have Cons(Bi, K1 ∪ K2).",
                "That is, a-consistency of the agents is additive. • If a piece of information k concerning the common set BC is consistent with an agent, it is consistent with all agents: for all pair of agents (ri,rj) such that Cons(Bi, Ki) and Cons(Bj, Kj) are true, we have, for all piece of information k: Cons(Bi, Ki ∪ k) iff Cons(Bj, Kj ∪ k).",
                "In such a case, we will say that the MAS is coherent.",
                "This last condition simply means that the common belief set BC is independent of the possible differences between the belief sets Bi of each agent ri.",
                "In the simplest case, B1 = ... = Bn = BC .",
                "M will also be viewed as an incremental learning mechanism and represented as an application changing Bi in Bi.",
                "In the following, we shall note ri(Bi, Ki) for ri when it is useful.",
                "Definition 4. a-consistency of a revision An update mechanism M is a-consistent iff for any agent ri and any piece of information k reaching ri, the a-consistency of this agent is preserved.",
                "In other words, iff: ri(Bi, Ki) a-consistent ⇒ ri(Bi, Ki) a-consistent, where Bi = M(Bi) and Ki = Ki ∪ k is the set of all information from other agents of the MAS.",
                "In the same way, we define the mas-consistency of a revision mechanism as the a-consistency of this mechanism should the agents dispose of all information in the MAS.",
                "In the following, we shall note, if needed, ri(Bi, Ki, K) for the agent ri in MAS r1 . . . rn.",
                "Definition 5. mas-consistency of a revision An update mechanism Ms is mas-consistent iff for all agent ri and all pieces of information k reaching ri, the masconsistency of this agent is preserved.",
                "In other words, if: ri(Bi, Ki, K) mas-consistent ⇒ ri(Bi, Ki, K) mas-consistent, where Bi = Ms(Bi), Ki = Ki ∪ k, and K = ∪Kj is the set of all information from the MAS.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 165 At last, when a mas-consistent mechanism is applied by an agent getting a new piece of information, a desirable sideeffect of the mechanism should be that all others agents remains mas-consistent after any modification of the common part BC , that is, the MAS itself should become consistent again.",
                "This property is defined as follows: Definition 6.",
                "Strong mas-consistency of a revision An update mechanism Ms is strongly mas-consistent iff - Ms is mas-consistent, and - the application of Ms by an agent preserves the consistency of the MAS. 2.2 A strongly mas-consistent update mechanism The general idea is that, since information is distributed among all the agents of the MAS, there must be some interaction between the learner agent and the other agents in a strongly mas-consistent update mechanism Ms.",
                "In order to ensure its mas-consistency, Ms will be constituted of reiterated applications by the learner agent ri of an internal a-consistent mechanism M, followed by some interactions between ri and the other agents, until ri regain its masconsistency.",
                "We describe below such a mechanism, first with a description of an interaction, then an iteration, and finally a statement of the termination condition of the mechanism.",
                "The mechanism is triggered by an agent ri upon receipt of a piece of information k disrupting the mas-consistency.",
                "We shall note M(Bi) the belief set of the learner agent ri after an update, BC the common part modified by ri, and Bj the belief set of another agent rj induced by the modification of its common part BC in BC .",
                "An interaction I(ri, rj) between the learner agent ri and another agent rj, acting as critic is constituted of the following steps: • agent ri sends the update BC of the common part of its beliefs.",
                "Having applied its update mechanism, ri is a-consistent. • agent rj checks the modification Bj of its beliefs induced by the update BC .",
                "If this modification preserve its a-consistency, rj adopts this modification. • agent rj sends either an acceptation of BC or a denial along with one (or more) piece(s) of information k such that Cons(Bj, k ) is false.",
                "An iteration of Ms will then be composed of: • the reception by the learner agent ri of a piece of information and the update M(Bi) restoring its aconsistency • a set of interactions I(ri, rj) (in which several critic agents can possibly participate).",
                "If at least one piece of information k is transmitted to ri, the addition of k will necessarily make ri a-inconsistent and a new iteration will then occur.",
                "This mechanism Ms ends when no agent can provide such a piece of information k .",
                "When it is the case, the masconsistency of the learner agent ri is restored.",
                "Proposition 1.",
                "Let r1,...,rn be a consistent MAS in which agent ri receives a piece of information k breaking its aconsistency, and M an a-consistent internal update mechanism.",
                "The update mechanism Ms described above is strongly mas-consistent.",
                "Proof.",
                "The proof directly derives from the mechanism description.",
                "This mechanism ensures that each time an agent receives an event, its mas-consistency will be restored.",
                "As the other agents all adopt the final update BC , they are all mas-consistent, and the MAS is consistent.",
                "Therefore Ms is a strongly consistent update mechanism.",
                "In the mechanism Ms described above, the learner agent is the only one that receives and memorizes information during the mechanism execution.",
                "It ensures that Ms terminates.",
                "The pieces of information transmitted by other agents and memorized by the learner agent are redundant as they are already present in the MAS, more precisely in the memory of the critic agents that transmitted them.",
                "Note that the mechanism Ms proposed here does not explicitly indicate the order nor the scope of the interactions.",
                "We will consider in the following that the modification proposal BC is sent sequentially to the different agents (synchronous mechanism).",
                "Moreover, the response of a critic agent will only contain one piece of information inconsistent with the proposed modification.",
                "We will say that the response of the agent is minimal.",
                "This mechanism Ms, being synchronous with minimal response, minimizes the amount of information transmitted by the agents.",
                "We will now illustrate it in the case of multi-agent concept learning. 3.",
                "SOUNDMULTI-AGENTINCREMENTAL LEARNING 3.1 The learning task We experiment the mechanism proposed above in the case of incremental MAS concept learning.",
                "We consider here a hypothesis language in which a hypothesis is a disjunction of terms.",
                "Each term is a conjunction of atoms from a set A.",
                "An example is represented by a tag + or − and a description 2 composed of a subset of atoms e ⊆ A.",
                "A term covers an example if its constituting atoms are included in the example.",
                "A hypothesis covers an example if one of its term covers it.",
                "This representation will be used below for learning boolean formulae.",
                "Negative literals are here represented by additional atoms, like not − a.",
                "The boolean formulae f =(a ∧ b) ∨ (b ∧ ¬c) will then be written (a ∧ b) ∨ (b ∧ not − c).",
                "A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 Incremental learning process The learning process is an update mechanism that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis.",
                "Before this update, the given hypothesis is complete, meaning that it covers all positive examples of E+ , and 2 When no confusion is possible, the word example will be used to refer to the pair (tag, description) as well as the description alone. 166 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) coherent, meaning that it does not cover any negative example of E− .",
                "After the update, the new hypothesis must be complete and coherent with the new memory state E ∪ {e}.",
                "We describe below our single agent update mechanism, inspired from a previous work on incremental learning[7].",
                "In the following, a hypothesis H for the target formula f is a list of terms h, each of them being a conjunction of atoms.",
                "H is coherent if all terms h are coherent, and H is complete if each element of E+ is covered by at least one term h of H. Each term is by construction the lgg (least general generalization) of a subset of positives instances {e1, ..., en}[5], that is the most specific term covering {e1, ..., en}.",
                "The lgg operator is defined by considering examples as terms, so we denote as lgg(e) the most specific term that covers e, and as lgg(h, e) the most specific term which is more general than h and that covers e. Restricting the term to lgg is the basis of a lot of Bottom-Up learning algorithms (for instance [5]).",
                "In the typology proposed by [9], our update mechanism is an incremental learner with full instance memory: learning is made by successive updates and all examples are stored.",
                "The update mechanism depends of the ongoing hypothesis H, the ongoing examples E+ and E− , and the new example e. There are three possible cases: • e is positive and H covers e, or e is negative and H does not cover e. No update is needed, H is already complete and coherent with E ∪ {e}. • e is positive and H does not cover e: e is denoted as a positive counterexample of H. Then we seek to generalize in turn the terms h of H. As soon as a correct generalization h = lgg(h, e) is found, h replaces h in H. If there is a term that is less general that h , it is discarded.",
                "If no generalization is correct (meaning here coherent), H ∪ lgg(e) replaces H. • e is negative and H covers e: e is denoted as a negative counterexample of H. Each term h covering e is then discarded from H and replaced by a set of terms {h1, ...., hn} that is, as a whole, coherent with E− ∪ {e} and that covers the examples of E+ uncovered by H − {h}.",
                "Terms of the final hypothesis H that are less general than others are discarded from H. We will now describe the case where e = e− is a covered negative example.",
                "The following functions are used here: • coveredOnlyBy(h, E+) gives the subset of E+ covered by h and no other term of H. • bestCover(h1, h2) gives h1 if h1 covers more examples from uncoveredPos than h2, otherwise it gives h2. • covered(h) gives the elements of uncoveredPos covered by h. // Specialization of each h covering e− for each h of H covering e− do H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= atoms that are neither in e− nor in h while (uncoveredPos = ∅) do // seeking the best specialization of h hc=h best=⊥ // ⊥ covers no example for each a of Ar do hc= h ∧ a best = bestCover(hc, best) endfor Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) endwhile endfor Terms of H that are less general than others are discarded.",
                "Note that this mechanism tends to both make a minimal update of the current hypothesis and minimize the number of terms in the hypothesis, in particular by discarding terms less general than other ones after updating a hypothesis. 3.3 Collective learning If H is the current hypothesis, Ei the current example memory of agent ri and E the set of all the examples received by the system, the notation of section 2 becomes Bi = BC = H, Ki = Ei and K = E. Cons(H, Ei) states that H is complete and coherent with Ei.",
                "In such a case, ri is a-consistent.",
                "The piece of information k received by agent ri is here simply an example e along with its tag.",
                "If e is such that the current hypothesis H is not complete or coherent with Ei ∪ {e}, e contradicts H: ri becomes a-inconsistent, and therefore the MAS is not consistent anymore.",
                "The update of a hypothesis when a new example arrives is an a- consistent mechanism.",
                "Following proposition 1 this mechanism can be used to produce a strong mas-consistent mechanism: upon reception of a new example in the MAS by an agent r, an update is possibly needed and, after a set of interactions between r and the other agents, results in a new hypothesis shared by all the agents and that restores the consistency of the MAS, that is which is complete and coherent with the set ES of all the examples present in the MAS.",
                "It is clear that by minimizing the number of hypothesis modifications, this synchronous and minimal mechanism minimize the number of examples received by the learner from other agents, and therefore, the total number of examples stored in the system. 4.",
                "EXPERIMENTS In the following, we will learn a boolean formula that is a difficult test for the learning method: the 11-multiplexer (see [4]).",
                "It concerns 3 address boolean attributes a0, a1, a2 and 8 data boolean attributes d0, ..., d7.",
                "Formulae f11 is satisfied if the number coded by the 3 address attributes is the number of a data attribute whose value is 1.",
                "Its formula is the following: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0).",
                "There are 2048 = 211 possible examples, half of whom are positive (meaning they satisfy f11) while the other half is negative.",
                "An experiment is typically composed of 50 trials.",
                "Each run corresponds to a sequence of 600 examples that are incrementally learned by a Multi Agent System with n agents The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 167 (n-MAS).",
                "A number of variables such as accuracy, (i.e. the frequency of correct classification of a set of unseen examples), hypothesis size (i.e. the number of terms in the current formula) or number of stored examples, is recorded each time 25 examples are received by the system during those runs.",
                "In the protocol that is used here, a new example is sent to a random agent when the MAS is consistent.",
                "The next example will be sent in turn to an other agent when the MAS consistency will have been restored.",
                "In such a way we simulate a kind of slow learning: the frequency of example arrivals is slow compared to the time taken by an update. 4.1 Efficiency of MAS concept learning 4.1.1 Execution time We briefly discuss here execution time of learning in the MAS.",
                "Note that the whole set of action and interaction in the MAS is simulated on a single processor.",
                "Figure 1 shows that time linearly depends on the number of agents.",
                "At the end of the most active part of learning (200 examples), a 16MAS has taken 4 times more learning time than a 4-MAS.",
                "This execution time represents the whole set of learning and Figure 1: Execution time of a n-MAS (from n = 2 at the bottom to n = 20 on the top). communication activity and hints at the cost of maintaining a consistent learning hypothesis in a MAS composed of autonomous agents. 4.1.2 Redundancy in the MAS memory We study now the distribution of the examples in the MAS memory.",
                "Redundancy is written RS = nS/ne, where nS is the total number of examples stored in the MAS, that is the sum of the sizes of agents examples memories Ei, and ne is the total number of examples received from the environment in the MAS.",
                "In figure 2, we compare redundancies in 2 to 20 agents MAS.",
                "There is a peak, slowly moving from 80 to 100 examples, that represents the number of examples for which the learning is most active.",
                "For 20 agents, maximal redundancy is no more than 6, which is far less than the maximal theoretical value of 20.",
                "Note that when learning becomes less active, redundancy tends towards its minimal value 1: when there is no more updates, examples are only Figure 2: Redundancy of examples stored in a nMAS (from n = 2 at the bottom to n = 20 on the top) . stored by the agent that receives them. 4.1.3 A n-MAS selects a simpler solution than a single agent The proposed mechanism tends to minimize the number of terms in the selected hypothesis.",
                "During learning, the size of the current hypothesis grows up beyond the optimum, and then decreases when the MAS converges.",
                "In the Multiplexer 11 testbed, the optimal number of terms is 8, but there also exist equivalent formulas with more terms.",
                "It is interesting to note that in this case the 10-MAS converges towards an exact solution closer to the optimal number of terms (here 8) (see Figure 3).",
                "After 1450 examples have been presented both 1-MAS and 10-MAS have exactly learned the concept (the respective accuracies are 0.9999 and 1) but the single agent expresses in average the result as a 11.0 terms DNF whereas the 10-MAS expresses it as a 8.8 terms DNF.",
                "However for some other boolean functions we found that during learning 1-MAS always produces larger hypotheses than 10-MAS but that both MAS converge to hypotheses with similar size results. 4.1.4 A n-MAS is more accurate than a single agent Figure 4 shows the improvement brought by a MAS with n agents compared to a single agent.",
                "This improvement was not especially expected, because whether we have one or n agents, when N examples are given to the MAS it has access to the same amount of information, maintains only on ongoing hypothesis and uses the same basic revision algorithm whenever an agent has to modify the current hypothesis.",
                "Note that if the accuracy of 1, 2, 4 and 10-MAS are significantly different, getting better as the number of agents increases, there is no clear difference beyond this point: the accuracy curve of the 100 agents MAS is very close to the one of the 10 agents MAS. 4.1.4.1 Boolean formulas.",
                "To evaluate this accuracy improvement, we have experimented our protocol on other problems of boolean function learning, As in the Multiplexer-11 case, these functions 168 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 3: Size of the hypothesis built by 1 and 10MAS: the M11 case.",
                "Figure 4: Accuracy of a n-MAS: the M11 case (from bottom to top, n = 1, 2, 4, 10, 100). are learnt in the form of more or less syntactically complex DNF3 (that is with more or less conjunctive terms in the DNF), but are also more or less difficult to learn as it can be difficult to get its way in the hypothesis space to reach them.",
                "Furthermore, the presence in the description of irrelevant attributes (that is attributes that does not belong to the target DNF) makes the problem more difficult.",
                "The following problems have been selected to experiment our protocol: (i) the multiplexer-11 with 9 irrelevant attributes: M11 9, (ii) the 20-multiplexer M20 (with 4 address bits and 16 data bits), (iii) a difficult parity problem (see [4]) the Xorp m: there must be an odd number of bits with value 1 in the p first attributes for the instance to be positive, the p others bits being irrelevant, and (iv) a simple DNF formula (a ∧ b ∧ c) ∨ (c ∧ d ∧ e)(e ∧ f ∧ g) ∧ (g ∧ h ∧ i) with 19 irrelevant attributes.",
                "The following table sums up some information about these problems, giving the total number of attributes including irrelevant ones, the number of irrelevant 3 Disjunctive Normal Forms attributes, the minimal number of terms of the corresponding DNF, and the number of learning examples used.",
                "Pb att. irre. att. terms ex.",
                "M11 11 0 8 200 M11 9 20 9 8 200 M20 20 0 16 450 Xor3 25 28 25 4 200 Xor5 5 10 5 16 180 Xor5 15 20 15 16 600 Simple4-9 19 28 19 4 200 Below are given the accuracy results of our learning mechanism with a single agent and a 10 agents MAS, along with the results of two standard algorithms implemented with the learning environment WEKA[16]: JRip (an implementation of RIPPER[2]) and Id3[12].",
                "For the experiments with JRip and Id3, we measured the mean accuracy on 50 trials, each time randomly separating examples in a learning set and a test set.",
                "JRip and Id3 parameters are default parameters, except that JRip is used without pruning.",
                "The following table shows the results: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 It is clear that difficult problems are better solved with more agents (see for instance xor5 15).",
                "We think that these benefits, which can be important with an increasing number of agents, are due to the fact that each agent really memorizes only part of the total number of examples, and this part is partly selected by other agents as counter examples, which cause a greater number of current hypothesis updates and therefore, a better exploration of the hypotheses space. 4.1.4.2 ML database problems.",
                "We did also experiments with some non boolean problems.",
                "We considered only two classes (positive/negative) problems, taken from the UCIs learning problems database[3].",
                "In all these problems, examples are described as a vector of couples (attribute, value).",
                "The value domains can be either boolean, numeric (wholly ordered set), or nominal (non-ordered set).",
                "An adequate set of atoms A must be constituted for each problem.",
                "For instance, if a is a numeric attribute, we define at most k threshold si, giving k+1 intervals of uniform density4 .",
                "Therefore, each distinct threshold si gives two atoms a ≤ si and a > si.",
                "In our experiments, we took a maximal number of threshold k = 8.",
                "For instance, in the iono problem case, there were 34 numeric attributes, and an instance is described with 506 atoms.",
                "Below are given the accuracy results of our system along with previous results.",
                "The column Nb ex. refer to the 4 The probability for the value of a to be in any interval is constant The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 169 number of examples used for learning5 .",
                "Column (1) represents minimal and maximal accuracy values for the thirty three classifiers tested in [8].",
                "Column (2) represents the results of [13], where various learning methods are compared to ensemble learning methods using weighted classifiers sets.",
                "Column S-1 and S-10 gives the accuracy of SMILE with respectively 1 and 10 agents.",
                "Pb Nb ex. (1) (2) S-1 S-10 ttt 862/574 // 76.2-99.7 99.7 99.9 kr-vs-kp 2876/958 // 91.4-99.4 96.8 97.3 iono 315 // 88.0-91.8 87.2 88.1 bupa 310 57-72 58-69.3 62.5 63.3 breastw 614 91-97 94.3-97.3 94.7 94.7 vote 391 94-96 95.3-96 91.9 92.6 pima 691 // 71.5- 73.4 65.0 65.0 heart 243 66-86 77.1-84.1 69.5 70.7 This table shows that the incremental algorithm corresponding to the single agent case, gives honorable results relatively to non-incremental classical methods using larger and more complex hypotheses.",
                "In some cases, there is an accuracy improvement with a 10 agents MAS.",
                "However, with such benchmarks data, which are often noisy, the difficulty does not really come from the way in which the search space is explored, and therefore the improvement observed is not always significant.",
                "The same kind of phenomenon have been observed with methods dedicated to hard boolean problems [4]. 4.2 MAS synchronization Here we consider that n single agents learn without interactions and at a given time start interacting thus forming a MAS.",
                "The purpose is to observe how the agents take advantage of collaboration when they start from different states of beliefs and memories.",
                "We compare in this section a 1-MAS, a 10-MAS (ref) and a 10-MAS (100sync) whose agents did not communicate during the arrival of the first 100 examples (10 by agents).",
                "The three accuracy curves are shown in figure 5.",
                "By comparing the single agent curve and the synchronized 10-MAS, we can observe that after the beginning of the synchronization, that is at 125 examples, accuracies are identical.",
                "This was expected since as soon as an example e received by the MAS contradicts the current hypothesis of the agent ra receiving it, this agent makes an update and its new hypothesis is proposed to the others agents for criticism.",
                "Therefore, this first contradictory example brings the MAS to reach consistency relatively to the whole set of examples present in agents memories.",
                "A higher accuracy, corresponding to a 10-MAS is obtained later, from the 175th example.",
                "In other words, the benefit of a better exploration of the research space is obtained slightly later in the learning process.",
                "Note that this synchronization happens naturally in all situations where agents have, for some reason, a divergence between their hypothesis and the system memory.",
                "This includes the fusion of two MAS into a single one or the arrival of new agents in an existing MAS. 4.3 Experiments on asynchronous learning: the effect of a large data stream 5 For ttt and kr-vs-kp, our protocol did not use more than respectively 574 and 958 learning examples, so we put another number in the column.",
                "Figure 5: Accuracies of a 1-MAS, a 10-MAS, and a 10-MAS synchronized after 100 examples.",
                "In this experiment we relax our slow learning mode: the examples are sent at a given rate to the MAS.",
                "The resulting example stream is measured in ms−1 , and represents the number of examples sent to the MAS each ms.",
                "Whenever the stream is too large, the MAS cannot reach MAS consistency on reception of an example from the environment before a new example arrives.",
                "This means that the update process, started by agent r0 as he received an example, may be unfinished when a new example is received by r0 or another agent r1.",
                "As a result, a critic agent may have at instant t to send counterexamples of hypotheses sent by various agents.",
                "However as far as the agents, in our setting, memorizes all the examples they receive whenever the stream ends, the MAS necessarily reaches MAS consistency with respect to all the examples received so far.",
                "In our experiments, though its learning curve is slowed down during the intense learning phase (corresponding to low accuracy of the current hypotheses), the MAS still reaches a satisfying hypothesis later on as there are less and less counterexamples in the example stream.",
                "In Figure 6 we compare the accuracies of two 11-MAS respectively submitted to example streams of different rates when learning the M11 formula.",
                "The learning curve of the MAS receiving an example at a 1/33 ms−1 rate is almost not altered (see Figure 4) whereas the 1/16 ms−1 MAS is first severely slowed down before catching up with the first one. 5.",
                "RELATED WORKS Since 96 [15], various work have been performed on learning in MAS, but rather few on concept learning.",
                "In [11] the MAS performs a form of ensemble learning in which the agents are lazy learners (no explicit representation is maintained) and sell useless examples to other agents.",
                "In [10] each agent observes all the examples but only perceive a part of their representation.",
                "In mutual online concept learning [14] the agents converge to a unique hypothesis, but each agent produces examples from its own concept representation, thus resulting in a kind of synchronization rather than in pure concept learning. 170 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 6: Accuracies of two asynchronous 11-MAS (1/33ms−1 and 1/16ms−1 example rates) . 6.",
                "CONCLUSION We have presented here and experimented a protocol for MAS online concept learning.",
                "The main feature of this collaborative learning mechanism is that it maintains a consistency property: though during the learning process each agent only receives and stores, with some limited redundancy, part of the examples received by the MAS, at any moment the current hypothesis is consistent with the whole set of examples.",
                "The hypotheses of our experiments do not address the issues of distributed MAS such as faults (for instance messages could be lost or corrupted) or other failures in general (crash, byzantine faults, etc.).",
                "Nevertheless, our framework is open, i.e., the agents can leave the system or enter it while the consistency mechanism is preserved.",
                "For instance if we introduce a timeout mechanism, even when a critic agent crashes or omits to answer, the consistency with the other critics (within the remaining agents) is entailed.",
                "In [1], a similar approach has been applied to MAS abduction problems: the hypotheses to maintain, given an incomplete information, are then facts or statements.",
                "Further work concerns first coupling induction and abduction in order to perform collaborative concept learning when examples are only partially observed by each agent, and second, investigating partial memory learning: how learning is preserved whenever one agent or the whole MAS forgets some selected examples.",
                "Aknowledgments We are very grateful to Dominique Bouthinon for implementing late modifications in SMILE, so much easing our experiments.",
                "Part of this work has been performed during the first authors visit to the Atelier De BioInformatique of Paris VI university, France. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In DALT-2006, May 2006. [2] W. W. Cohen.",
                "Fast effective rule induction.",
                "In ICML, pages 115-123, 1995. [3] C. B. D.J.",
                "Newman, S. Hettich and C. Merz.",
                "UCI repository of machine learning databases, 1998. [4] S. Esmeir and S. Markovitch.",
                "Lookahead-based algorithms for anytime induction of decision trees.",
                "In ICMLO4, pages 257-264.",
                "Morgan Kaufmann, 2004. [5] J. F¨urnkranz.",
                "A pathology of bottom-up hill-climbing in inductive rule learning.",
                "In ALT, volume 2533 of LNCS, pages 263-277.",
                "Springer, 2002. [6] A. Guerra-Hern´andez, A. ElFallah-Seghrouchni, and H. Soldano.",
                "Learning in BDI multi-agent systems.",
                "In CLIMA IV, volume 3259, pages 218-233.",
                "Springer Verlag, 2004. [7] M. Henniche.",
                "Mgi: an incremental bottom-up algorithm.",
                "In IEEE Aust. and New Zealand Conference on Intelligent Information Systems, pages 347-351, 1994. [8] T.-S. Lim, W.-Y.",
                "Loh, and Y.-S. Shih.",
                "A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms.",
                "Machine Learning, 40(3):203-228, 2000. [9] M. A. Maloof and R. S. Michalski.",
                "Incremental learning with partial instance memory.",
                "Artif.",
                "Intell., 154(1-2):95-126, 2004. [10] P. J. Modi and W.-M. Shen.",
                "Collaborative multiagent learning for classification tasks.",
                "In AGENTS 01, pages 37-38.",
                "ACM Press, 2001. [11] S. Onta˜non and E. Plaza.",
                "Recycling data for multi-agent learning.",
                "In ICML 05, pages 633-640.",
                "ACM Press, 2005. [12] J. R. Quinlan.",
                "Induction of decision trees.",
                "Machine Learning, 1(1):81-106, 1986. [13] U. R¨uckert and S. Kramer.",
                "Towards tight bounds for rule learning.",
                "In ICML 04 (International conference on Machine learning), page 90, New York, NY, USA, 2004.",
                "ACM Press. [14] J. Wang and L. Gasser.",
                "Mutual online concept learning for multiple agents.",
                "In AAMAS, pages 362-369.",
                "ACM Press, 2002. [15] G. Weiß and S. Sen, editors.",
                "Adaption and Learning in Multi-Agent Systems, volume 1042 of Lecture Notes in Computer Science.",
                "Springer, 1996. [16] I. H. Witten and E. Frank.",
                "Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.",
                "Morgan Kaufmann, October 1999.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 171"
            ],
            "original_annotated_samples": [
                "Here, the belief set B represents hypothetical <br>knowledge</br> that can therefore be revised, whereas the set of information K represents certain <br>knowledge</br>, consisting of non revisable observations and facts.",
                "Each agent ri has a belief set Bi consisting of all the revisable <br>knowledge</br> he has.",
                "As said before, Bi represents <br>knowledge</br> that might be revised whereas Ki represents observed facts, taken as being true, and which can possibly contradict Bi."
            ],
            "translated_annotated_samples": [
                "Aquí, el conjunto de creencias B representa conocimiento hipotético que por lo tanto puede ser revisado, mientras que el conjunto de información K representa conocimiento cierto, compuesto por observaciones y hechos no revisables.",
                "Cada agente ri tiene un conjunto de creencias Bi que consiste en todo el <br>conocimiento</br> revisable que posee.",
                "Como se dijo antes, Bi representa el <br>conocimiento</br> que podría ser revisado, mientras que Ki representa hechos observados, considerados verdaderos, y que posiblemente puedan contradecir a Bi."
            ],
            "translated_text": "SMILE: Aprendizaje Incremental Multiagente de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av. del presidente Kennedy, 75116 París Henry Soldano LIPN, UMR 7030 CNRS, Universidad Paris-Norte, 99 Av. J-B Clement, 93430, Villetaneuse RESUMEN Este artículo trata sobre el problema del aprendizaje colaborativo en un sistema multiagente. Aquí cada agente puede actualizar de forma incremental sus creencias B (la representación del concepto) para que se mantenga consistente con el conjunto completo de información K (los ejemplos) que ha recibido del entorno u otros agentes. Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo lograr que, en cualquier momento, una misma representación conceptual consistente esté presente en cada agente. El protocolo correspondiente se aplica al aprendizaje supervisado de conceptos. El método resultante SMILE (que significa Sound Multiagent Incremental LEarning) se describe y experimenta aquí. Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de múltiples agentes que por un solo agente. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de conceptos; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistema multiagente Términos Generales Experimentación, Algoritmos, Medición, Rendimiento 1. INTRODUCCIÓN Este artículo trata sobre el problema del aprendizaje colaborativo de conceptos en un sistema multiagente. [6] introduce una caracterización del aprendizaje en un sistema multiagente según el nivel de conciencia de los agentes. En el nivel 1, los agentes aprenden ∗El autor principal de este artículo es un estudiante. en el sistema sin tener en cuenta la presencia de otros agentes, excepto a través de la modificación que traen al entorno con sus acciones. El nivel 2 implica una interacción directa entre los agentes, ya que pueden intercambiar mensajes para mejorar su aprendizaje. El nivel 3 requeriría que los agentes tengan en cuenta las competencias de otros agentes y sean capaces de aprender observando el comportamiento de los otros agentes (considerándolos como entidades independientes y no como parte indeterminada del entorno como en el nivel 1). En este artículo nos enfocamos en el nivel 2, estudiando la interacción directa entre los agentes involucrados en un proceso de aprendizaje. Cada agente se asume capaz de aprender de forma incremental a partir de los datos que recibe, lo que significa que cada agente puede actualizar su conjunto de creencias B para mantenerlo consistente con el conjunto completo de información K que ha recibido del entorno o de otros agentes. En tal caso, diremos que es a-inconsistente. Aquí, el conjunto de creencias B representa conocimiento hipotético que por lo tanto puede ser revisado, mientras que el conjunto de información K representa conocimiento cierto, compuesto por observaciones y hechos no revisables. Además, suponemos que al menos una parte Bc de las creencias de cada agente es común a todos los agentes y debe mantenerse de esa manera. Por lo tanto, una actualización de este conjunto común Bc por parte del agente r debe provocar una actualización de Bc para toda la comunidad de agentes. Nos lleva a definir cuál es la mas-consistencia de un agente con respecto a la comunidad. El proceso de actualización de las creencias de la comunidad cuando uno de sus miembros recibe nueva información puede entonces definirse como el proceso de mantenimiento de la consistencia que garantiza que cada agente en la comunidad permanecerá más consistente. Este proceso de mantenimiento de la mas-consistencia de un agente al recibir nueva información le otorga el rol de aprendiz e implica la comunicación con otros agentes que actúan como críticos. Sin embargo, los agentes no están especializados y a su vez pueden ser aprendices o críticos, ninguno de ellos está limitado a un rol específico. Las piezas de información se distribuyen entre los agentes, pero pueden ser redundantes. No hay memoria central. El trabajo descrito aquí tiene su origen en un trabajo anterior sobre el aprendizaje en un sistema multiagente intencional utilizando un formalismo BDI [6]. En ese trabajo, los agentes tenían planes, cada uno de ellos asociado con un contexto que define en qué condiciones puede ser activado. Los planes (cada uno con su propio contexto) eran comunes a todo el conjunto de agentes en la comunidad. Los agentes tuvieron que adaptar su plan en función del contexto, dependiendo del fracaso o éxito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo a otros agentes ejemplos (éxitos o fracasos de planes). Sin embargo, este trabajo carecía de un protocolo de aprendizaje colectivo que permitiera una verdadera autonomía del sistema multiagente. El estudio de dicho protocolo es el objeto del presente artículo. En la sección 2 definimos formalmente la mas-consistencia de un mecanismo de actualización para todo el MAS y proponemos un mecanismo de actualización genérico demostrado que es mas consistente. En la sección 3 describimos SMILE, un aprendiz de conceptos multiagente incremental que aplica nuestro mecanismo de actualización mas consistente para el aprendizaje colaborativo de conceptos. La sección 4 describe varios experimentos sobre SMILE y discute varios problemas, incluyendo cómo varían la precisión y la simplicidad de la hipótesis actual al comparar el aprendizaje de un solo agente y el aprendizaje de múltiples agentes. En la sección 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la sección 6 discutiendo investigaciones adicionales sobre el aprendizaje más consistente. MODELO FORMAL 2.1 Definiciones y marco En esta sección, presentamos una formulación general del aprendizaje incremental colectivo en un sistema cognitivo de múltiples agentes. Representamos un MAS como un conjunto de agentes r1, ..., rn. Cada agente ri tiene un conjunto de creencias Bi que consiste en todo el <br>conocimiento</br> revisable que posee. Parte de estos conocimientos deben ser compartidos con otros agentes. La parte de Bi que es común a todos los agentes se denota como BC. Esta parte común provoca una dependencia entre los agentes. Si un agente ri actualiza su conjunto de creencias Bi a Bi, cambiando en el proceso BC en BC, entonces todos los demás agentes rk deben actualizar su conjunto de creencias Bk a Bk para que BC ⊆ Bk. Además, cada agente ri ha almacenado cierta información Ki. Suponemos que alguna propiedad de consistencia Cons(Bi, Ki) puede ser verificada por el agente mismo entre sus creencias Bi y su información Ki. Como se dijo antes, Bi representa el <br>conocimiento</br> que podría ser revisado, mientras que Ki representa hechos observados, considerados verdaderos, y que posiblemente puedan contradecir a Bi. Definición 1. a-consistencia de un agente Un agente ri es a-consistente si Cons(Bi, Ki) es verdadero. Ejemplo 1. El agente r1 tiene un conjunto de planes que se encuentran en la parte común BC de B1. Cada plan P tiene un contexto desencadenante d(P) (que actúa como una precondición) y un cuerpo. Alguna pieza de información k podría ser el plan P, desencadenado en la situación s, ha fallado a pesar de que s es una instancia de d(P). Si esta pieza de información se agrega a K1, entonces el agente r1 ya no es a-consistente: Cons(B1, K1 ∪ k) es falso. También queremos definir alguna noción de consistencia para todo el MAS dependiendo de los conjuntos de creencias e información de sus elementos constituyentes. Primero definiremos la consistencia de un agente ri con respecto a su conjunto de creencias Bi y su propio conjunto de información Ki junto con todos los conjuntos de información K1...Kn de los otros agentes del MAS. Simplemente lo haremos considerando cuál sería la a-consistencia del agente si tuviera la información de todos los demás agentes. Llamamos a esta noción la mas-consistencia: Definición 2. Un agente ri es mas-consistente si Cons(Bi, Ki ∪ K) es verdadero, donde K = ∪j∈{1,..,n}−{i}Kj 1 es el conjunto de toda la información de los otros agentes del MAS. 1 Lo notaremos como ∪ Kj cuando el contexto sea similar. Ejemplo 2. Usando el ejemplo anterior, supongamos que la pieza de información k está incluida en la información K2 del agente r2. Si la pieza de información no se transmite a r1, y por lo tanto no se agrega a K1, r1 permanece a-consistente. Sin embargo, r1 no es tan consistente como k en el conjunto K de toda la información del MAS. La consistencia global del MAS es simplemente la mas-consistencia de todos sus agentes. Definición 3. La consistencia de un MAS A MAS r1,...,rn es consistente si todos sus agentes ri son masconsistentes. Ahora definimos las propiedades requeridas para un mecanismo de revisión M que actualiza a un agente ri cuando recibe una pieza de información k. En lo siguiente, supondremos que: • La actualización siempre es posible, es decir, un agente siempre puede modificar su conjunto de creencias Bi para recuperar su a-consistencia. Diremos que cada agente es localmente eficiente. • Considerando dos conjuntos de información Cons(Bi, K1) y Cons(Bi, K2), también tenemos Cons(Bi, K1 ∪ K2). Es decir, la a-consistencia de los agentes es aditiva. • Si una pieza de información k relacionada con el conjunto común BC es consistente con un agente, es consistente con todos los agentes: para todos los pares de agentes (ri, rj) tales que Cons(Bi, Ki) y Cons(Bj, Kj) son verdaderos, tenemos, para toda pieza de información k: Cons(Bi, Ki ∪ k) si y solo si Cons(Bj, Kj ∪ k). En tal caso, diremos que el MAS es coherente. Esta última condición simplemente significa que el conjunto de creencias común BC es independiente de las posibles diferencias entre los conjuntos de creencias Bi de cada agente ri. En el caso más simple, B1 = ... = Bn = BC. M también será visto como un mecanismo de aprendizaje incremental y representado como una aplicación que cambia Bi en Bi. En lo siguiente, anotaremos ri(Bi, Ki) para ri cuando sea útil. Definición 4. a-consistencia de una revisión Un mecanismo de actualización M es a-consistente si, para cualquier agente ri y cualquier pieza de información k que llegue a ri, la a-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki) a-consistente ⇒ ri(Bi, Ki) a-consistente, donde Bi = M(Bi) y Ki = Ki ∪ k es el conjunto de toda la información de otros agentes del MAS. De la misma manera, definimos la mas-consistencia de un mecanismo de revisión como la a-consistencia de este mecanismo si los agentes disponen de toda la información en el MAS. En lo siguiente, anotaremos, si es necesario, ri(Bi, Ki, K) para el agente ri en el MAS r1 . . . rn. Definición 5. mas-consistencia de una revisión Un mecanismo de actualización Ms es mas-consistente si para todo agente ri y toda pieza de información k que llega a ri, la mas-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki, K) más-consistente ⇒ ri(Bi, Ki, K) más-consistente, donde Bi = Ms(Bi), Ki = Ki ∪ k, y K = ∪Kj es el conjunto de toda la información del MAS. El Sexto Internacional. En última instancia, cuando un agente aplica un mecanismo mas-consistente al recibir una nueva pieza de información, un efecto secundario deseable del mecanismo debería ser que todos los demás agentes permanezcan mas-consistentes después de cualquier modificación de la parte común BC, es decir, el MAS en sí mismo debería volver a ser consistente. Esta propiedad se define de la siguiente manera: Definición 6. La fuerte mas-consistencia de un mecanismo de actualización. Un mecanismo de actualización Ms es fuertemente mas-consistente si - Ms es mas-consistente, y - la aplicación de Ms por un agente preserva la consistencia del MAS. 2.2 Un mecanismo de actualización fuertemente mas-consistente. La idea general es que, dado que la información está distribuida entre todos los agentes del MAS, debe haber alguna interacción entre el agente aprendiz y los demás agentes en un mecanismo de actualización fuertemente mas-consistente Ms. Para garantizar su mas-consistencia, Ms estará constituido por aplicaciones reiteradas por parte del agente aprendiz ri de un mecanismo interno a-consistente M, seguido por algunas interacciones entre ri y los otros agentes, hasta que ri recupere su mas-consistencia. Describimos a continuación un mecanismo, primero con una descripción de una interacción, luego una iteración y finalmente una declaración de la condición de terminación del mecanismo. El mecanismo es activado por un agente ri al recibir una pieza de información k que interrumpe la mas-consistencia. Tomaremos M(Bi) como el conjunto de creencias del agente aprendiz ri después de una actualización, BC la parte común modificada por ri, y Bj el conjunto de creencias de otro agente rj inducido por la modificación de su parte común BC en BC. Una interacción I(ri, rj) entre el agente aprendiz ri y otro agente rj, actuando como crítico, está constituida por los siguientes pasos: • el agente ri envía la actualización BC de la parte común de sus creencias. Habiendo aplicado su mecanismo de actualización, ri es a-consistente. • El agente rj verifica la modificación Bj de sus creencias inducida por la actualización BC. Si esta modificación conserva su a-consistencia, rj adopta esta modificación. El agente rj envía ya sea una aceptación de BC o una negación junto con una (o más) pieza(s) de información k tal que Cons(Bj, k) es falso. Una iteración de Ms estará compuesta por: • la recepción por parte del agente aprendiz ri de una pieza de información y la actualización M(Bi) restaurando su consistencia • un conjunto de interacciones I(ri, rj) (en las cuales varios agentes críticos posiblemente puedan participar). Si al menos una pieza de información k es transmitida a ri, la adición de k necesariamente hará que ri sea inconsistente y entonces ocurrirá una nueva iteración. Este mecanismo termina cuando ningún agente puede proporcionar tal pieza de información k. Cuando es el caso, se restaura la masconsistencia del agente aprendiz ri. Proposición 1. Dejen que r1,...,rn sea un MAS consistente en el que el agente ri recibe una pieza de información k que rompe su consistencia, y M sea un mecanismo interno de actualización a-consistente. El mecanismo de actualización descrito anteriormente por Ms es altamente mas-consistente. Prueba. La prueba se deriva directamente de la descripción del mecanismo. Este mecanismo asegura que cada vez que un agente recibe un evento, su mas-consistencia será restaurada. Como los otros agentes adoptan la actualización final BC, todos son mas-coherentes y el MAS es coherente. Por lo tanto, Ms es un mecanismo de actualización fuertemente consistente. En el mecanismo descrito anteriormente, el agente aprendiz es el único que recibe y memoriza información durante la ejecución del mecanismo. Se asegura de que Ms termine. Las piezas de información transmitidas por otros agentes y memorizadas por el agente aprendiz son redundantes, ya que ya están presentes en el MAS, más precisamente en la memoria de los agentes críticos que las transmitieron. Se debe tener en cuenta que el mecanismo propuesto por la Sra. aquí no indica explícitamente el orden ni el alcance de las interacciones. Consideraremos en lo siguiente que la propuesta de modificación BC se envía secuencialmente a los diferentes agentes (mecanismo síncrono). Además, la respuesta de un agente crítico solo contendrá una pieza de información inconsistente con la modificación propuesta. Diremos que la respuesta del agente es mínima. Este mecanismo, siendo sincrónico con una respuesta mínima, minimiza la cantidad de información transmitida por los agentes. Ahora lo ilustraremos en el caso del aprendizaje de conceptos multiagente. 3. APRENDIZAJE INCREMENTAL DE MÚLTIPLES AGENTES 3.1 La tarea de aprendizaje Experimentamos el mecanismo propuesto anteriormente en el caso del aprendizaje conceptual MAS incremental. Aquí consideramos un lenguaje de hipótesis en el cual una hipótesis es una disyunción de términos. Cada término es una conjunción de átomos de un conjunto A. Un ejemplo está representado por una etiqueta + o − y una descripción 2 compuesta por un subconjunto de átomos e ⊆ A. Un término abarca un ejemplo si sus átomos constituyentes están incluidos en el ejemplo. Una hipótesis abarca un ejemplo si uno de sus términos lo abarca. Esta representación se utilizará a continuación para aprender fórmulas booleanas. Los literales negativos se representan aquí mediante átomos adicionales, como not − a. La fórmula booleana f = (a ∧ b) ∨ (b ∧ ¬c) se escribirá entonces como (a ∧ b) ∨ (b ∧ no − c). Un ejemplo positivo de f, como {no − a, b, no − c}, representa un modelo para f. 3.2 Proceso de aprendizaje incremental El proceso de aprendizaje es un mecanismo de actualización que, dado una hipótesis actual H, una memoria E = E+ ∪ E− llenada con los ejemplos recibidos previamente, y un nuevo ejemplo positivo o negativo e, produce una nueva hipótesis actualizada. Antes de esta actualización, la hipótesis dada es completa, lo que significa que cubre todos los ejemplos positivos de E+, y 2 Cuando no haya posibilidad de confusión, la palabra ejemplo se utilizará para referirse al par (etiqueta, descripción) así como a la descripción sola. 166 La Sexta Conferencia Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) es coherente, lo que significa que no cubre ningún ejemplo negativo de E−. Después de la actualización, la nueva hipótesis debe ser completa y coherente con el nuevo estado de memoria E ∪ {e}. Describimos a continuación nuestro mecanismo de actualización de agente único, inspirado en un trabajo previo sobre aprendizaje incremental[7]. En lo siguiente, una hipótesis H para la fórmula objetivo f es una lista de términos h, cada uno de ellos siendo una conjunción de átomos. H es coherente si todos los términos h son coherentes, y H es completo si cada elemento de E+ está cubierto por al menos un término h de H. Cada término es, por construcción, la lgg (generalización general menos general) de un subconjunto de instancias positivas {e1, ..., en}, es decir, el término más específico que cubre {e1, ..., en}. El operador lgg se define considerando ejemplos como términos, por lo que denotamos como lgg(e) al término más específico que cubre e, y como lgg(h, e) al término más específico que es más general que h y que cubre e. Restringir el término a lgg es la base de muchos algoritmos de aprendizaje de abajo hacia arriba (por ejemplo [5]). En la tipología propuesta por [9], nuestro mecanismo de actualización es un aprendiz incremental con memoria completa de instancias: el aprendizaje se realiza mediante actualizaciones sucesivas y se almacenan todos los ejemplos. El mecanismo de actualización depende de la hipótesis en curso H, los ejemplos en curso E+ y E−, y el nuevo ejemplo e. Hay tres casos posibles: • e es positivo y H cubre e, o e es negativo y H no cubre e. No se necesita actualización, H ya es completo y coherente con E ∪ {e}. • e es positivo y H no cubre e: e se denota como un contraejemplo positivo de H. Luego buscamos generalizar a su vez los términos h de H. Tan pronto como se encuentre una generalización correcta h = lgg(h, e), h reemplaza a h en H. Si hay un término que es menos general que h, se descarta. Si ninguna generalización es correcta (es decir, coherente), H ∪ lgg(e) reemplaza a H. • e es negativo y H cubre e: e se denota como un contraejemplo negativo de H. Cada término h que cubre e es entonces descartado de H y reemplazado por un conjunto de términos {h1, ...., hn} que, en su totalidad, es coherente con E− ∪ {e} y que cubre los ejemplos de E+ no cubiertos por H − {h}. Los términos de la hipótesis final H que son menos generales que otros son descartados de H. Ahora describiremos el caso en el que e = e− es un ejemplo negativo cubierto. Las siguientes funciones se utilizan aquí: • coveredOnlyBy(h, E+) da el subconjunto de E+ cubierto por h y ningún otro término de H. • bestCover(h1, h2) da h1 si h1 cubre más ejemplos de uncoveredPos que h2, de lo contrario da h2. • covered(h) da los elementos de uncoveredPos cubiertos por h. // Especialización de cada h cubriendo e− para cada h de H cubriendo e− hacer H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= átomos que no están ni en e− ni en h mientras (uncoveredPos = ∅) hacer // buscando la mejor especialización de h hc=h best=⊥ // ⊥ no cubre ningún ejemplo para cada a de Ar hacer hc= h ∧ a best = bestCover(hc, best) finpara Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) finmientras finpara Los términos de H que son menos generales que otros son descartados. Ten en cuenta que este mecanismo tiende tanto a hacer una actualización mínima de la hipótesis actual como a minimizar el número de términos en la hipótesis, en particular descartando términos menos generales que otros después de actualizar una hipótesis. 3.3 Aprendizaje colectivo Si H es la hipótesis actual, Ei es la memoria actual de ejemplos del agente ri y E es el conjunto de todos los ejemplos recibidos por el sistema, la notación de la sección 2 se convierte en Bi = BC = H, Ki = Ei y K = E. Cons(H, Ei) establece que H es completo y coherente con Ei. En tal caso, ri es a-consistente. La pieza de información k recibida por el agente ri es aquí simplemente un ejemplo e junto con su etiqueta. Si e es tal que la hipótesis actual H no es completa ni coherente con Ei ∪ {e}, e contradice a H: ri se vuelve a-inconsistente, y por lo tanto el MAS ya no es consistente. La actualización de una hipótesis cuando llega un nuevo ejemplo es un mecanismo a-consistente. Siguiendo la proposición 1, este mecanismo puede ser utilizado para producir un mecanismo fuerte mas-consistente: al recibir un nuevo ejemplo en el MAS por un agente r, posiblemente se necesite una actualización y, después de un conjunto de interacciones entre r y los otros agentes, resulta en una nueva hipótesis compartida por todos los agentes y que restaura la consistencia del MAS, es decir, que es completa y coherente con el conjunto ES de todos los ejemplos presentes en el MAS. Es claro que al minimizar el número de modificaciones de hipótesis, este mecanismo sincrónico y minimalista reduce el número de ejemplos recibidos por el aprendiz de otros agentes, y por ende, el número total de ejemplos almacenados en el sistema. 4. EXPERIMENTOS En lo siguiente, aprenderemos una fórmula booleana que es una prueba difícil para el método de aprendizaje: el 11-multiplexor (ver [4]). Se refiere a 3 atributos booleanos de dirección a0, a1, a2 y 8 atributos booleanos de datos d0, ..., d7. La fórmula f11 se cumple si el número codificado por los 3 atributos de dirección es el número de un atributo de datos cuyo valor es 1. Su fórmula es la siguiente: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0). Hay 2048 = 211 posibles ejemplos, la mitad de los cuales son positivos (lo que significa que satisfacen f11) mientras que la otra mitad es negativa. Un experimento suele estar compuesto por 50 pruebas. Cada ejecución corresponde a una secuencia de 600 ejemplos que son aprendidos de forma incremental por un Sistema Multiagente con n agentes. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 167 (n-MAS). Un número de variables como la precisión (es decir, la frecuencia de clasificación correcta de un conjunto de ejemplos no vistos), el tamaño de la hipótesis (es decir, el número de términos en la fórmula actual) o el número de ejemplos almacenados, se registra cada vez que el sistema recibe 25 ejemplos durante esas ejecuciones. En el protocolo que se utiliza aquí, un nuevo ejemplo se envía a un agente aleatorio cuando el MAS es consistente. El siguiente ejemplo será enviado a su vez a otro agente cuando la consistencia del MAS haya sido restaurada. De esta manera simulamos una especie de aprendizaje lento: la frecuencia de llegada de ejemplos es lenta en comparación con el tiempo que lleva una actualización. 4.1 Eficiencia del aprendizaje conceptual en MAS 4.1.1 Tiempo de ejecución Discutimos brevemente aquí el tiempo de ejecución del aprendizaje en el MAS. Se debe tener en cuenta que todo el conjunto de acciones e interacciones en el MAS se simula en un solo procesador. La Figura 1 muestra que el tiempo depende linealmente del número de agentes. Al final de la parte más activa del aprendizaje (200 ejemplos), un 16MAS ha tomado 4 veces más tiempo de aprendizaje que un 4-MAS. Este tiempo de ejecución representa el conjunto completo de aprendizaje y la Figura 1: Tiempo de ejecución de un n-MAS (desde n = 2 en la parte inferior hasta n = 20 en la parte superior). actividad de comunicación y sugiere el costo de mantener una hipótesis de aprendizaje consistente en un MAS compuesto por agentes autónomos. 4.1.2 Redundancia en la memoria del MAS Estudiamos ahora la distribución de los ejemplos en la memoria del MAS. La redundancia se escribe RS = nS/ne, donde nS es el número total de ejemplos almacenados en el MAS, que es la suma de los tamaños de las memorias de ejemplos de los agentes Ei, y ne es el número total de ejemplos recibidos del entorno en el MAS. En la figura 2, comparamos las redundancias en MAS de 2 a 20 agentes. Hay un pico que se mueve lentamente de 80 a 100 ejemplos, que representa la cantidad de ejemplos para los cuales el aprendizaje es más activo. Para 20 agentes, la redundancia máxima no es más de 6, lo cual es mucho menor que el valor teórico máximo de 20. Ten en cuenta que cuando el aprendizaje se vuelve menos activo, la redundancia tiende hacia su valor mínimo 1: cuando ya no hay más actualizaciones, los ejemplos son solo la Figura 2: Redundancia de ejemplos almacenados en un nMAS (de n = 2 en la parte inferior a n = 20 en la parte superior) almacenados por el agente que los recibe. Un n-MAS selecciona una solución más simple que un solo agente. El mecanismo propuesto tiende a minimizar el número de términos en la hipótesis seleccionada. Durante el aprendizaje, el tamaño de la hipótesis actual crece más allá del óptimo, y luego disminuye cuando el MAS converge. En el banco de pruebas Multiplexer 11, el número óptimo de términos es 8, pero también existen fórmulas equivalentes con más términos. Es interesante notar que en este caso el 10-MAS converge hacia una solución exacta más cercana al número óptimo de términos (en este caso 8) (ver Figura 3). Después de haber presentado 1450 ejemplos, tanto el 1-MAS como el 10-MAS han aprendido exactamente el concepto (las precisiones respectivas son 0.9999 y 1), pero el agente individual expresa en promedio el resultado como una DNF de 11.0 términos, mientras que el 10-MAS lo expresa como una DNF de 8.8 términos. Sin embargo, para algunas otras funciones booleanas encontramos que durante el aprendizaje, 1-MAS siempre produce hipótesis más grandes que 10-MAS, pero que ambos MAS convergen a hipótesis con resultados de tamaño similar. 4.1.4 Un n-MAS es más preciso que un agente único. La Figura 4 muestra la mejora proporcionada por un MAS con n agentes en comparación con un agente único. Esta mejora no era especialmente esperada, porque ya sea que tengamos uno o n agentes, cuando se le dan N ejemplos al MAS, tiene acceso a la misma cantidad de información, mantiene solo una hipótesis en curso y utiliza el mismo algoritmo básico de revisión cada vez que un agente tiene que modificar la hipótesis actual. Ten en cuenta que si la precisión de los MAS de 1, 2, 4 y 10 es significativamente diferente, mejorando a medida que aumenta el número de agentes, no hay una diferencia clara más allá de este punto: la curva de precisión de los MAS de 100 agentes es muy similar a la de los MAS de 10 agentes. 4.1.4.1 Fórmulas booleanas. Para evaluar esta mejora de precisión, hemos experimentado nuestro protocolo en otros problemas de aprendizaje de funciones booleanas. Como en el caso del Multiplexor-11, estas funciones 168 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 3: Tamaño de la hipótesis construida por 1 y 10MAS: el caso M11. Figura 4: Precisión de un n-MAS: el caso M11 (de abajo hacia arriba, n = 1, 2, 4, 10, 100). Se aprenden en forma de DNF3 más o menos sintácticamente complejos (es decir, con más o menos términos conjuntivos en la DNF), pero también son más o menos difíciles de aprender, ya que puede ser difícil encontrar su camino en el espacio de hipótesis para alcanzarlos. Además, la presencia en la descripción de atributos irrelevantes (es decir, atributos que no pertenecen al DNF objetivo) hace que el problema sea más difícil. Los siguientes problemas han sido seleccionados para experimentar con nuestro protocolo: (i) el multiplexor-11 con 9 atributos irrelevantes: M11 9, (ii) el multiplexor-20 M20 (con 4 bits de dirección y 16 bits de datos), (iii) un problema de paridad difícil (ver [4]) el Xorp m: debe haber un número impar de bits con valor 1 en los primeros p atributos para que la instancia sea positiva, los p bits restantes son irrelevantes, y (iv) una fórmula DNF simple (a ∧ b ∧ c) ∨ (c ∧ d ∧ e) ∨ (e ∧ f ∧ g) ∧ (g ∧ h ∧ i) con 19 atributos irrelevantes. La siguiente tabla resume alguna información sobre estos problemas, proporcionando el número total de atributos, incluidos los irrelevantes, el número de atributos irrelevantes en Forma Normal Disyuntiva 3, el número mínimo de términos de la DNF correspondiente, y el número de ejemplos de aprendizaje utilizados. Pb att. irre. att. términos ex. A continuación se presentan los resultados de precisión de nuestro mecanismo de aprendizaje con un solo agente y un MAS de 10 agentes, junto con los resultados de dos algoritmos estándar implementados con el entorno de aprendizaje WEKA[16]: JRip (una implementación de RIPPER[2]) e Id3[12]. Para los experimentos con JRip e Id3, medimos la precisión media en 50 pruebas, separando aleatoriamente los ejemplos en un conjunto de aprendizaje y un conjunto de prueba cada vez. Los parámetros de JRip e Id3 son los predeterminados, excepto que JRip se utiliza sin poda. La siguiente tabla muestra los resultados: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 Es claro que los problemas difíciles se resuelven mejor con más agentes (ver por ejemplo xor5 15). Creemos que estos beneficios, que pueden ser importantes con un número creciente de agentes, se deben al hecho de que cada agente realmente memoriza solo parte del número total de ejemplos, y esta parte es seleccionada en parte por otros agentes como contraejemplos, lo que provoca un mayor número de actualizaciones de hipótesis actuales y, por lo tanto, una mejor exploración del espacio de hipótesis. 4.1.4.2 Problemas de base de datos de ML. También realizamos experimentos con algunos problemas no booleanos. Consideramos solo problemas de dos clases (positivo/negativo), tomados de la base de datos de problemas de aprendizaje de UCIs. En todos estos problemas, los ejemplos se describen como un vector de pares (atributo, valor). Los dominios de valor pueden ser booleanos, numéricos (conjunto totalmente ordenado) o nominales (conjunto no ordenado). Un conjunto adecuado de átomos A debe ser constituido para cada problema. Por ejemplo, si a es un atributo numérico, definimos como máximo k umbrales si, dando k+1 intervalos de densidad uniforme. Por lo tanto, cada umbral distintivo si da dos átomos, uno ≤ si y otro > si. En nuestros experimentos, tomamos un número máximo de umbral k = 8. Por ejemplo, en el caso del problema de iono, había 34 atributos numéricos, y una instancia se describe con 506 átomos. A continuación se presentan los resultados de precisión de nuestro sistema junto con los resultados anteriores. La columna Nb ex. se refiere al 4. La probabilidad de que el valor de a esté en cualquier intervalo es constante. El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 169 número de ejemplos utilizados para el aprendizaje5. La columna (1) representa los valores de precisión mínima y máxima para los treinta y tres clasificadores probados en [8]. La columna (2) representa los resultados de [13], donde se comparan varios métodos de aprendizaje con métodos de aprendizaje en conjunto utilizando conjuntos de clasificadores ponderados. La columna S-1 y S-10 dan la precisión de SMILE con 1 y 10 agentes, respectivamente. Esta tabla muestra que el algoritmo incremental correspondiente al caso de un solo agente, proporciona resultados honorables en relación a los métodos clásicos no incrementales que utilizan hipótesis más grandes y complejas. En algunos casos, hay una mejora en la precisión con un MAS de 10 agentes. Sin embargo, con datos de referencia de este tipo, que suelen ser ruidosos, la dificultad no radica realmente en la forma en que se explora el espacio de búsqueda, por lo que la mejora observada no siempre es significativa. El mismo tipo de fenómeno se ha observado con métodos dedicados a problemas booleanos difíciles [4]. 4.2 Sincronización de MAS En este caso consideramos que n agentes individuales aprenden sin interacciones y en un momento dado comienzan a interactuar, formando así un MAS. El propósito es observar cómo los agentes aprovechan la colaboración cuando parten de diferentes estados de creencias y memorias. En esta sección comparamos un 1-MAS, un 10-MAS (ref) y un 10-MAS (100sync) cuyos agentes no se comunicaron durante la llegada de los primeros 100 ejemplos (10 por agentes). Las tres curvas de precisión se muestran en la figura 5. Al comparar la curva del agente individual con la del 10-MAS sincronizado, podemos observar que después del inicio de la sincronización, es decir, en 125 ejemplos, las precisiones son idénticas. Esto era esperado ya que tan pronto como un ejemplo e recibido por el MAS contradice la hipótesis actual del agente ra que lo recibe, este agente realiza una actualización y su nueva hipótesis es propuesta a los otros agentes para su crítica. Por lo tanto, este primer ejemplo contradictorio lleva al MAS a alcanzar coherencia en relación con todo el conjunto de ejemplos presentes en la memoria de los agentes. Una mayor precisión, correspondiente a un 10-MAS, se obtiene más tarde, a partir del ejemplo 175. En otras palabras, el beneficio de una mejor exploración del espacio de investigación se obtiene ligeramente más tarde en el proceso de aprendizaje. Ten en cuenta que esta sincronización ocurre de forma natural en todas las situaciones en las que los agentes tienen, por alguna razón, una divergencia entre su hipótesis y la memoria del sistema. Esto incluye la fusión de dos MAS en una sola o la llegada de nuevos agentes en un MAS existente. 4.3 Experimentos sobre el aprendizaje asincrónico: el efecto de un gran flujo de datos. Para ttt y kr-vs-kp, nuestro protocolo no utilizó más de 574 y 958 ejemplos de aprendizaje respectivamente, por lo que colocamos otro número en la columna. Figura 5: Precisión de un 1-MAS, un 10-MAS y un 10-MAS sincronizado después de 100 ejemplos. En este experimento relajamos nuestro modo de aprendizaje lento: los ejemplos se envían a una velocidad determinada al MAS. El flujo de ejemplos resultante se mide en ms−1, y representa la cantidad de ejemplos enviados al MAS cada milisegundo. Cuando el flujo es demasiado grande, el MAS no puede alcanzar la consistencia del MAS al recibir un ejemplo del entorno antes de que llegue un nuevo ejemplo. Esto significa que el proceso de actualización, iniciado por el agente r0 al recibir un ejemplo, puede estar incompleto cuando un nuevo ejemplo es recibido por r0 u otro agente r1. Como resultado, un agente crítico puede tener que enviar contraejemplos de hipótesis enviadas por varios agentes en el instante t. Sin embargo, en nuestro entorno, a medida que los agentes memorizan todos los ejemplos que reciben cuando finaliza el flujo, el MAS alcanza necesariamente consistencia MAS con respecto a todos los ejemplos recibidos hasta el momento. En nuestros experimentos, aunque la curva de aprendizaje se ralentiza durante la fase intensa de aprendizaje (correspondiente a una baja precisión de las hipótesis actuales), el MAS aún logra alcanzar una hipótesis satisfactoria más adelante, ya que hay menos contraejemplos en el flujo de ejemplos. En la Figura 6 comparamos las precisiones de dos 11-MAS respectivamente sometidos a flujos de ejemplos de diferentes tasas al aprender la fórmula M11. La curva de aprendizaje del MAS al recibir un ejemplo a una velocidad de 1/33 ms−1 casi no se ve alterada (ver Figura 4), mientras que el MAS a 1/16 ms−1 primero se ralentiza severamente antes de alcanzar al primero. 5. TRABAJOS RELACIONADOS Desde el 96 [15], se han realizado varios trabajos sobre el aprendizaje en Sistemas Multiagente, pero muy pocos sobre el aprendizaje de conceptos. En [11] el MAS realiza una forma de aprendizaje en conjunto en la que los agentes son aprendices perezosos (no se mantiene una representación explícita) y venden ejemplos inútiles a otros agentes. En [10] cada agente observa todos los ejemplos pero solo percibe una parte de su representación. En el aprendizaje de conceptos en línea mutuo, los agentes convergen hacia una hipótesis única, pero cada agente produce ejemplos desde su propia representación del concepto, lo que resulta en una especie de sincronización en lugar de un aprendizaje de conceptos puro. 170 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Precisión de dos sistemas multiagente asincrónicos de 11 agentes (tasas de ejemplo de 1/33ms−1 y 1/16ms−1). 6. CONCLUSIÓN Hemos presentado y experimentado un protocolo para el aprendizaje de conceptos en línea de MAS. La característica principal de este mecanismo de aprendizaje colaborativo es que mantiene una propiedad de consistencia: aunque durante el proceso de aprendizaje cada agente solo recibe y almacena, con cierta redundancia limitada, parte de los ejemplos recibidos por el MAS, en cualquier momento la hipótesis actual es consistente con todo el conjunto de ejemplos. Las hipótesis de nuestros experimentos no abordan los problemas de los MAS distribuidos, como fallos (por ejemplo, mensajes perdidos o corruptos) u otras fallas en general (crash, fallos bizantinos, etc.). Sin embargo, nuestro marco de trabajo es abierto, es decir, los agentes pueden salir del sistema o ingresar a él mientras se preserva el mecanismo de consistencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente crítico se bloquea o no responde, se garantiza la consistencia con los otros críticos (dentro de los agentes restantes). En [1], se ha aplicado un enfoque similar a los problemas de abducción en MAS: las hipótesis a mantener, dada una información incompleta, son entonces hechos o afirmaciones. El trabajo adicional se refiere en primer lugar a acoplar la inducción y la abducción para realizar un aprendizaje colaborativo de conceptos cuando los ejemplos son solo parcialmente observados por cada agente, y en segundo lugar, a investigar el aprendizaje de memoria parcial: cómo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados. Agradecimientos Estamos muy agradecidos a Dominique Bouthinon por implementar las modificaciones tardías en SMILE, facilitando mucho nuestros experimentos. Parte de este trabajo se realizó durante la visita del primer autor al Atelier De BioInformatique de la Universidad Paris VI, Francia. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En DALT-2006, mayo de 2006. [2] W. W. Cohen. Inducción de reglas rápida y efectiva. En ICML, páginas 115-123, 1995. [3] C. B. D.J. Newman, S. Hettich y C. Merz. Repositorio de bases de datos de aprendizaje automático de UCI, 1998. [4] S. Esmeir y S. Markovitch. Algoritmos basados en anticipación para la inducción en cualquier momento de árboles de decisión. En ICMLO4, páginas 257-264. Morgan Kaufmann, 2004. [5] J. F¨urnkranz. \n\nMorgan Kaufmann, 2004. [5] J. F¨urnkranz. Una patología de la escalada de colina de abajo hacia arriba en el aprendizaje inductivo de reglas. En ALT, volumen 2533 de LNCS, páginas 263-277. Springer, 2002. [6] A. Guerra-Hernández, A. ElFallah-Seghrouchni y H. Soldano. Aprendizaje en sistemas multiagente BDI. En CLIMA IV, volumen 3259, páginas 218-233. Springer Verlag, 2004. [7] M. Henniche. \n\nSpringer Verlag, 2004. [7] M. Henniche. Mgi: un algoritmo incremental de abajo hacia arriba. En la Conferencia IEEE de Australia y Nueva Zelanda sobre Sistemas de Información Inteligente, páginas 347-351, 1994. [8] T.-S. Lim, W.-Y. Loh, y Y.-S. Shih. Una comparación de la precisión de predicción, complejidad y tiempo de entrenamiento de treinta y tres algoritmos de clasificación antiguos y nuevos. Aprendizaje automático, 40(3):203-228, 2000. [9] M. A. Maloof y R. S. Michalski. Aprendizaje incremental con memoria parcial de instancias. I'm sorry, but the sentence \"Artif.\" is not a complete sentence. Can you provide more context or a complete sentence for me to translate to Spanish? Intell., 154(1-2):95-126, 2004. [10] P. J. Modi y W.-M. Shen. Aprendizaje colaborativo multiagente para tareas de clasificación. En AGENTS 01, páginas 37-38. ACM Press, 2001. [11] S. Onta˜non y E. Plaza. Reciclaje de datos para el aprendizaje multiagente. En ICML 05, páginas 633-640. ACM Press, 2005. [12] J. R. Quinlan. \n\nACM Press, 2005. [12] J. R. Quinlan. Inducción de árboles de decisión. Aprendizaje automático, 1(1):81-106, 1986. [13] U. R¨uckert y S. Kramer. Hacia límites ajustados para el aprendizaje de reglas. En ICML 04 (Conferencia Internacional sobre Aprendizaje Automático), página 90, Nueva York, NY, EE. UU., 2004. ACM Press. [14] J. Wang y L. Gasser. Aprendizaje de conceptos en línea mutuo para múltiples agentes. En AAMAS, páginas 362-369. ACM Press, 2002. [15] G. Weiß y S. Sen, editores. Adaptación y Aprendizaje en Sistemas Multiagente, volumen 1042 de las Notas de Conferencia en Ciencias de la Computación. Springer, 1996. [16] I. H. Witten y E. Frank. Minería de datos: Herramientas y técnicas prácticas de aprendizaje automático con implementaciones en Java. Morgan Kaufmann, octubre de 1999. La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 171 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "mas-consistency": {
            "translated_key": "mas-consistencia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "SMILE: Sound Multi-agent Incremental LEarning ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av.",
                "du pr´esident Kennedy, 75116 Paris Henry Soldano LIPN, UMR 7030 CNRS, University Paris-Nord, 99 Av.",
                "J-B Clement, 93430, Villetaneuse ABSTRACT This article deals with the problem of collaborative learning in a multi-agent system.",
                "Here each agent can update incrementally its beliefs B (the concept representation) so that it is in a way kept consistent with the whole set of information K (the examples) that he has received from the environment or other agents.",
                "We extend this notion of consistency (or soundness) to the whole MAS and discuss how to obtain that, at any moment, a same consistent concept representation is present in each agent.",
                "The corresponding protocol is applied to supervised concept learning.",
                "The resulting method SMILE (standing for Sound Multiagent Incremental LEarning) is described and experimented here.",
                "Surprisingly some difficult boolean formulas are better learned, given the same learning set, by a Multi agent system than by a single agent.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Concept learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent system General Terms Experimentation, Algorithms, Measurement, Performance 1.",
                "INTRODUCTION This article deals with the problem of collaborative concept learning in a multi-agent system. [6] introduces a characterisation of learning in multi-agent system according to the level of awareness of the agents.",
                "At level 1, agents learn ∗The primary author of this paper is a student. in the system without taking into account the presence of other agents, except through the modification brought upon the environment by their action.",
                "Level 2 implies direct interaction between the agents as they can exchange messages to improve their learning.",
                "Level 3 would require agents to take into account the competencies of other agents, and be able to learn from observation of the other agents behaviour (while considering them as independant entities and not indetermined part of the environment as in level 1).",
                "We focus in this paper on level 2, studying direct interaction between agents involved in a learning process.",
                "Each agent is assumed to be able to learn incrementally from the data he receives, meaning that each agent can update his belief set B to keep it consistent with the whole set of information K that he has received from the environment or from other agents.",
                "In such a case, we will say that he is a-consistent.",
                "Here, the belief set B represents hypothetical knowledge that can therefore be revised, whereas the set of information K represents certain knowledge, consisting of non revisable observations and facts.",
                "Moreover, we suppose that at least a part Bc of the beliefs of each agent is common to all agents and must stay that way.",
                "Therefore, an update of this common set Bc by agent r must provoke an update of Bc for the whole community of agents.",
                "It leads us to define what is the <br>mas-consistency</br> of an agent with respect to the community.",
                "The update process of the community beliefs when one of its members gets new information can then be defined as the consistency maintenance process ensuring that every agent in the community will stay masconsistent.",
                "This <br>mas-consistency</br> maintenance process of an agent getting new information gives him the role of a learner and implies communication with other agents acting as critics.",
                "However, agents are not specialised and can in turn be learners or critics, none of them being kept to a specific role.",
                "Pieces of information are distributed among the agents, but can be redundant.",
                "There is no central memory.",
                "The work described here has its origin in a former work concerning learning in an intentional multi-agent system using a BDI formalism [6].",
                "In that work, agents had plans, each of them being associated with a context defining in which conditions it can be triggered.",
                "Plans (each of them having its own context) were common to the whole set of agents in the community.",
                "Agents had to adapt their plan contexts depending on the failure or success of executed plans, using a learning mechanism and asking other agents for examples (plans successes or failures).",
                "However this work lacked a collective learning protocol enabling a real autonomy of the multi-agent system.",
                "The study of such a protocol is the object of the present paper.",
                "In section 2 we formally define the <br>mas-consistency</br> of an update mechanism for the whole MAS and we propose a generic update mechanism proved to be mas consistent.",
                "In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent update mechanism to collaborative concept learning.",
                "Section 4 describes various experiments on SMILE and discusses various issues including how the accuracy and the simplicity of the current hypothesis vary when comparing single agent learning and mas learning.",
                "In section 5 we briefly present some related works and then conclude in section 6 by discussing further investigations on mas consistent learning. 2.",
                "FORMAL MODEL 2.1 Definitions and framework In this section, we present a general formulation of collective incremental learning in a cognitive multi agent system.",
                "We represent a MAS as a set of agents r1, ..., rn.",
                "Each agent ri has a belief set Bi consisting of all the revisable knowledge he has.",
                "Part of these knowledges must be shared with other agents.",
                "The part of Bi that is common to all agents is denoted as BC .",
                "This common part provokes a dependency between the agents.",
                "If an agent ri updates his belief set Bi to Bi, changing in the process BC into BC , all other agents rk must then update their belief set Bk to Bk so that BC ⊆ Bk.",
                "Moreover, each agent ri has stored some certain information Ki.",
                "We suppose that some consistency property Cons(Bi, Ki) can be verified by the agent itself between its beliefs Bi and its information Ki.",
                "As said before, Bi represents knowledge that might be revised whereas Ki represents observed facts, taken as being true, and which can possibly contradict Bi.",
                "Definition 1. a-consistency of an agent An agent ri is a-consistent iff Cons(Bi, Ki) is true.",
                "Example 1.",
                "Agent r1 has a set of plans which are in the common part BC of B1.",
                "Each plan P has a triggering context d(P) (which acts as a pre-condition) and a body.",
                "Some piece of information k could be plan P, triggered in situation s, has failed in spite of s being an instance of d(P).",
                "If this piece of information is added to K1, then agent r1 is not a-consistent anymore: Cons(B1, K1 ∪ k) is false.",
                "We also want to define some notion of consistency for the whole MAS depending on the belief and information sets of its constituting elements.",
                "We will first define the consistency of an agent ri with respect to its belief set Bi and its own information set Ki together with all information sets K1...Kn from the other agents of the MAS.",
                "We will simply do that by considering what would be the a-consistency of the agent if he has the information of all the other agents.",
                "We call this notion the <br>mas-consistency</br>: Definition 2. <br>mas-consistency</br> of an agent An agent ri is mas-consistent iff Cons(Bi, Ki ∪ K) is true, where K = ∪j∈{1,..,n}−{i}Kj 1 is the set of all information from other agents of the MAS. 1 We will note this ∪ Kj when the context is similar.",
                "Example 2.",
                "Using the previous example, suppose that the piece of information k is included in the information K2 of agent r2.",
                "As long as the piece of information is not transmitted to r1, and so added to K1 , r1 remains a-consistent.",
                "However, r1 is not mas-consistent as k is in the set K of all information of the MAS.",
                "The global consistency of the MAS is then simply the <br>mas-consistency</br> of all its agents.",
                "Definition 3.",
                "Consistency of a MAS A MAS r1,...,rn is consistent iff all its agents ri are masconsistent.",
                "We now define the required properties for a revision mechanism M updating an agent ri when it gets a piece of information k. In the following, we will suppose that: • Update is always possible, that is, an agent can always modify its belief set Bi in order to regain its a-consistency.",
                "We will say that each agent is locally efficient. • Considering two sets of information Cons(Bi, K1) and Cons(Bi, K2), we also have Cons(Bi, K1 ∪ K2).",
                "That is, a-consistency of the agents is additive. • If a piece of information k concerning the common set BC is consistent with an agent, it is consistent with all agents: for all pair of agents (ri,rj) such that Cons(Bi, Ki) and Cons(Bj, Kj) are true, we have, for all piece of information k: Cons(Bi, Ki ∪ k) iff Cons(Bj, Kj ∪ k).",
                "In such a case, we will say that the MAS is coherent.",
                "This last condition simply means that the common belief set BC is independent of the possible differences between the belief sets Bi of each agent ri.",
                "In the simplest case, B1 = ... = Bn = BC .",
                "M will also be viewed as an incremental learning mechanism and represented as an application changing Bi in Bi.",
                "In the following, we shall note ri(Bi, Ki) for ri when it is useful.",
                "Definition 4. a-consistency of a revision An update mechanism M is a-consistent iff for any agent ri and any piece of information k reaching ri, the a-consistency of this agent is preserved.",
                "In other words, iff: ri(Bi, Ki) a-consistent ⇒ ri(Bi, Ki) a-consistent, where Bi = M(Bi) and Ki = Ki ∪ k is the set of all information from other agents of the MAS.",
                "In the same way, we define the <br>mas-consistency</br> of a revision mechanism as the a-consistency of this mechanism should the agents dispose of all information in the MAS.",
                "In the following, we shall note, if needed, ri(Bi, Ki, K) for the agent ri in MAS r1 . . . rn.",
                "Definition 5. <br>mas-consistency</br> of a revision An update mechanism Ms is mas-consistent iff for all agent ri and all pieces of information k reaching ri, the masconsistency of this agent is preserved.",
                "In other words, if: ri(Bi, Ki, K) mas-consistent ⇒ ri(Bi, Ki, K) mas-consistent, where Bi = Ms(Bi), Ki = Ki ∪ k, and K = ∪Kj is the set of all information from the MAS.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 165 At last, when a mas-consistent mechanism is applied by an agent getting a new piece of information, a desirable sideeffect of the mechanism should be that all others agents remains mas-consistent after any modification of the common part BC , that is, the MAS itself should become consistent again.",
                "This property is defined as follows: Definition 6.",
                "Strong <br>mas-consistency</br> of a revision An update mechanism Ms is strongly mas-consistent iff - Ms is mas-consistent, and - the application of Ms by an agent preserves the consistency of the MAS. 2.2 A strongly mas-consistent update mechanism The general idea is that, since information is distributed among all the agents of the MAS, there must be some interaction between the learner agent and the other agents in a strongly mas-consistent update mechanism Ms.",
                "In order to ensure its <br>mas-consistency</br>, Ms will be constituted of reiterated applications by the learner agent ri of an internal a-consistent mechanism M, followed by some interactions between ri and the other agents, until ri regain its masconsistency.",
                "We describe below such a mechanism, first with a description of an interaction, then an iteration, and finally a statement of the termination condition of the mechanism.",
                "The mechanism is triggered by an agent ri upon receipt of a piece of information k disrupting the <br>mas-consistency</br>.",
                "We shall note M(Bi) the belief set of the learner agent ri after an update, BC the common part modified by ri, and Bj the belief set of another agent rj induced by the modification of its common part BC in BC .",
                "An interaction I(ri, rj) between the learner agent ri and another agent rj, acting as critic is constituted of the following steps: • agent ri sends the update BC of the common part of its beliefs.",
                "Having applied its update mechanism, ri is a-consistent. • agent rj checks the modification Bj of its beliefs induced by the update BC .",
                "If this modification preserve its a-consistency, rj adopts this modification. • agent rj sends either an acceptation of BC or a denial along with one (or more) piece(s) of information k such that Cons(Bj, k ) is false.",
                "An iteration of Ms will then be composed of: • the reception by the learner agent ri of a piece of information and the update M(Bi) restoring its aconsistency • a set of interactions I(ri, rj) (in which several critic agents can possibly participate).",
                "If at least one piece of information k is transmitted to ri, the addition of k will necessarily make ri a-inconsistent and a new iteration will then occur.",
                "This mechanism Ms ends when no agent can provide such a piece of information k .",
                "When it is the case, the masconsistency of the learner agent ri is restored.",
                "Proposition 1.",
                "Let r1,...,rn be a consistent MAS in which agent ri receives a piece of information k breaking its aconsistency, and M an a-consistent internal update mechanism.",
                "The update mechanism Ms described above is strongly mas-consistent.",
                "Proof.",
                "The proof directly derives from the mechanism description.",
                "This mechanism ensures that each time an agent receives an event, its <br>mas-consistency</br> will be restored.",
                "As the other agents all adopt the final update BC , they are all mas-consistent, and the MAS is consistent.",
                "Therefore Ms is a strongly consistent update mechanism.",
                "In the mechanism Ms described above, the learner agent is the only one that receives and memorizes information during the mechanism execution.",
                "It ensures that Ms terminates.",
                "The pieces of information transmitted by other agents and memorized by the learner agent are redundant as they are already present in the MAS, more precisely in the memory of the critic agents that transmitted them.",
                "Note that the mechanism Ms proposed here does not explicitly indicate the order nor the scope of the interactions.",
                "We will consider in the following that the modification proposal BC is sent sequentially to the different agents (synchronous mechanism).",
                "Moreover, the response of a critic agent will only contain one piece of information inconsistent with the proposed modification.",
                "We will say that the response of the agent is minimal.",
                "This mechanism Ms, being synchronous with minimal response, minimizes the amount of information transmitted by the agents.",
                "We will now illustrate it in the case of multi-agent concept learning. 3.",
                "SOUNDMULTI-AGENTINCREMENTAL LEARNING 3.1 The learning task We experiment the mechanism proposed above in the case of incremental MAS concept learning.",
                "We consider here a hypothesis language in which a hypothesis is a disjunction of terms.",
                "Each term is a conjunction of atoms from a set A.",
                "An example is represented by a tag + or − and a description 2 composed of a subset of atoms e ⊆ A.",
                "A term covers an example if its constituting atoms are included in the example.",
                "A hypothesis covers an example if one of its term covers it.",
                "This representation will be used below for learning boolean formulae.",
                "Negative literals are here represented by additional atoms, like not − a.",
                "The boolean formulae f =(a ∧ b) ∨ (b ∧ ¬c) will then be written (a ∧ b) ∨ (b ∧ not − c).",
                "A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 Incremental learning process The learning process is an update mechanism that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis.",
                "Before this update, the given hypothesis is complete, meaning that it covers all positive examples of E+ , and 2 When no confusion is possible, the word example will be used to refer to the pair (tag, description) as well as the description alone. 166 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) coherent, meaning that it does not cover any negative example of E− .",
                "After the update, the new hypothesis must be complete and coherent with the new memory state E ∪ {e}.",
                "We describe below our single agent update mechanism, inspired from a previous work on incremental learning[7].",
                "In the following, a hypothesis H for the target formula f is a list of terms h, each of them being a conjunction of atoms.",
                "H is coherent if all terms h are coherent, and H is complete if each element of E+ is covered by at least one term h of H. Each term is by construction the lgg (least general generalization) of a subset of positives instances {e1, ..., en}[5], that is the most specific term covering {e1, ..., en}.",
                "The lgg operator is defined by considering examples as terms, so we denote as lgg(e) the most specific term that covers e, and as lgg(h, e) the most specific term which is more general than h and that covers e. Restricting the term to lgg is the basis of a lot of Bottom-Up learning algorithms (for instance [5]).",
                "In the typology proposed by [9], our update mechanism is an incremental learner with full instance memory: learning is made by successive updates and all examples are stored.",
                "The update mechanism depends of the ongoing hypothesis H, the ongoing examples E+ and E− , and the new example e. There are three possible cases: • e is positive and H covers e, or e is negative and H does not cover e. No update is needed, H is already complete and coherent with E ∪ {e}. • e is positive and H does not cover e: e is denoted as a positive counterexample of H. Then we seek to generalize in turn the terms h of H. As soon as a correct generalization h = lgg(h, e) is found, h replaces h in H. If there is a term that is less general that h , it is discarded.",
                "If no generalization is correct (meaning here coherent), H ∪ lgg(e) replaces H. • e is negative and H covers e: e is denoted as a negative counterexample of H. Each term h covering e is then discarded from H and replaced by a set of terms {h1, ...., hn} that is, as a whole, coherent with E− ∪ {e} and that covers the examples of E+ uncovered by H − {h}.",
                "Terms of the final hypothesis H that are less general than others are discarded from H. We will now describe the case where e = e− is a covered negative example.",
                "The following functions are used here: • coveredOnlyBy(h, E+) gives the subset of E+ covered by h and no other term of H. • bestCover(h1, h2) gives h1 if h1 covers more examples from uncoveredPos than h2, otherwise it gives h2. • covered(h) gives the elements of uncoveredPos covered by h. // Specialization of each h covering e− for each h of H covering e− do H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= atoms that are neither in e− nor in h while (uncoveredPos = ∅) do // seeking the best specialization of h hc=h best=⊥ // ⊥ covers no example for each a of Ar do hc= h ∧ a best = bestCover(hc, best) endfor Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) endwhile endfor Terms of H that are less general than others are discarded.",
                "Note that this mechanism tends to both make a minimal update of the current hypothesis and minimize the number of terms in the hypothesis, in particular by discarding terms less general than other ones after updating a hypothesis. 3.3 Collective learning If H is the current hypothesis, Ei the current example memory of agent ri and E the set of all the examples received by the system, the notation of section 2 becomes Bi = BC = H, Ki = Ei and K = E. Cons(H, Ei) states that H is complete and coherent with Ei.",
                "In such a case, ri is a-consistent.",
                "The piece of information k received by agent ri is here simply an example e along with its tag.",
                "If e is such that the current hypothesis H is not complete or coherent with Ei ∪ {e}, e contradicts H: ri becomes a-inconsistent, and therefore the MAS is not consistent anymore.",
                "The update of a hypothesis when a new example arrives is an a- consistent mechanism.",
                "Following proposition 1 this mechanism can be used to produce a strong mas-consistent mechanism: upon reception of a new example in the MAS by an agent r, an update is possibly needed and, after a set of interactions between r and the other agents, results in a new hypothesis shared by all the agents and that restores the consistency of the MAS, that is which is complete and coherent with the set ES of all the examples present in the MAS.",
                "It is clear that by minimizing the number of hypothesis modifications, this synchronous and minimal mechanism minimize the number of examples received by the learner from other agents, and therefore, the total number of examples stored in the system. 4.",
                "EXPERIMENTS In the following, we will learn a boolean formula that is a difficult test for the learning method: the 11-multiplexer (see [4]).",
                "It concerns 3 address boolean attributes a0, a1, a2 and 8 data boolean attributes d0, ..., d7.",
                "Formulae f11 is satisfied if the number coded by the 3 address attributes is the number of a data attribute whose value is 1.",
                "Its formula is the following: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0).",
                "There are 2048 = 211 possible examples, half of whom are positive (meaning they satisfy f11) while the other half is negative.",
                "An experiment is typically composed of 50 trials.",
                "Each run corresponds to a sequence of 600 examples that are incrementally learned by a Multi Agent System with n agents The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 167 (n-MAS).",
                "A number of variables such as accuracy, (i.e. the frequency of correct classification of a set of unseen examples), hypothesis size (i.e. the number of terms in the current formula) or number of stored examples, is recorded each time 25 examples are received by the system during those runs.",
                "In the protocol that is used here, a new example is sent to a random agent when the MAS is consistent.",
                "The next example will be sent in turn to an other agent when the MAS consistency will have been restored.",
                "In such a way we simulate a kind of slow learning: the frequency of example arrivals is slow compared to the time taken by an update. 4.1 Efficiency of MAS concept learning 4.1.1 Execution time We briefly discuss here execution time of learning in the MAS.",
                "Note that the whole set of action and interaction in the MAS is simulated on a single processor.",
                "Figure 1 shows that time linearly depends on the number of agents.",
                "At the end of the most active part of learning (200 examples), a 16MAS has taken 4 times more learning time than a 4-MAS.",
                "This execution time represents the whole set of learning and Figure 1: Execution time of a n-MAS (from n = 2 at the bottom to n = 20 on the top). communication activity and hints at the cost of maintaining a consistent learning hypothesis in a MAS composed of autonomous agents. 4.1.2 Redundancy in the MAS memory We study now the distribution of the examples in the MAS memory.",
                "Redundancy is written RS = nS/ne, where nS is the total number of examples stored in the MAS, that is the sum of the sizes of agents examples memories Ei, and ne is the total number of examples received from the environment in the MAS.",
                "In figure 2, we compare redundancies in 2 to 20 agents MAS.",
                "There is a peak, slowly moving from 80 to 100 examples, that represents the number of examples for which the learning is most active.",
                "For 20 agents, maximal redundancy is no more than 6, which is far less than the maximal theoretical value of 20.",
                "Note that when learning becomes less active, redundancy tends towards its minimal value 1: when there is no more updates, examples are only Figure 2: Redundancy of examples stored in a nMAS (from n = 2 at the bottom to n = 20 on the top) . stored by the agent that receives them. 4.1.3 A n-MAS selects a simpler solution than a single agent The proposed mechanism tends to minimize the number of terms in the selected hypothesis.",
                "During learning, the size of the current hypothesis grows up beyond the optimum, and then decreases when the MAS converges.",
                "In the Multiplexer 11 testbed, the optimal number of terms is 8, but there also exist equivalent formulas with more terms.",
                "It is interesting to note that in this case the 10-MAS converges towards an exact solution closer to the optimal number of terms (here 8) (see Figure 3).",
                "After 1450 examples have been presented both 1-MAS and 10-MAS have exactly learned the concept (the respective accuracies are 0.9999 and 1) but the single agent expresses in average the result as a 11.0 terms DNF whereas the 10-MAS expresses it as a 8.8 terms DNF.",
                "However for some other boolean functions we found that during learning 1-MAS always produces larger hypotheses than 10-MAS but that both MAS converge to hypotheses with similar size results. 4.1.4 A n-MAS is more accurate than a single agent Figure 4 shows the improvement brought by a MAS with n agents compared to a single agent.",
                "This improvement was not especially expected, because whether we have one or n agents, when N examples are given to the MAS it has access to the same amount of information, maintains only on ongoing hypothesis and uses the same basic revision algorithm whenever an agent has to modify the current hypothesis.",
                "Note that if the accuracy of 1, 2, 4 and 10-MAS are significantly different, getting better as the number of agents increases, there is no clear difference beyond this point: the accuracy curve of the 100 agents MAS is very close to the one of the 10 agents MAS. 4.1.4.1 Boolean formulas.",
                "To evaluate this accuracy improvement, we have experimented our protocol on other problems of boolean function learning, As in the Multiplexer-11 case, these functions 168 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 3: Size of the hypothesis built by 1 and 10MAS: the M11 case.",
                "Figure 4: Accuracy of a n-MAS: the M11 case (from bottom to top, n = 1, 2, 4, 10, 100). are learnt in the form of more or less syntactically complex DNF3 (that is with more or less conjunctive terms in the DNF), but are also more or less difficult to learn as it can be difficult to get its way in the hypothesis space to reach them.",
                "Furthermore, the presence in the description of irrelevant attributes (that is attributes that does not belong to the target DNF) makes the problem more difficult.",
                "The following problems have been selected to experiment our protocol: (i) the multiplexer-11 with 9 irrelevant attributes: M11 9, (ii) the 20-multiplexer M20 (with 4 address bits and 16 data bits), (iii) a difficult parity problem (see [4]) the Xorp m: there must be an odd number of bits with value 1 in the p first attributes for the instance to be positive, the p others bits being irrelevant, and (iv) a simple DNF formula (a ∧ b ∧ c) ∨ (c ∧ d ∧ e)(e ∧ f ∧ g) ∧ (g ∧ h ∧ i) with 19 irrelevant attributes.",
                "The following table sums up some information about these problems, giving the total number of attributes including irrelevant ones, the number of irrelevant 3 Disjunctive Normal Forms attributes, the minimal number of terms of the corresponding DNF, and the number of learning examples used.",
                "Pb att. irre. att. terms ex.",
                "M11 11 0 8 200 M11 9 20 9 8 200 M20 20 0 16 450 Xor3 25 28 25 4 200 Xor5 5 10 5 16 180 Xor5 15 20 15 16 600 Simple4-9 19 28 19 4 200 Below are given the accuracy results of our learning mechanism with a single agent and a 10 agents MAS, along with the results of two standard algorithms implemented with the learning environment WEKA[16]: JRip (an implementation of RIPPER[2]) and Id3[12].",
                "For the experiments with JRip and Id3, we measured the mean accuracy on 50 trials, each time randomly separating examples in a learning set and a test set.",
                "JRip and Id3 parameters are default parameters, except that JRip is used without pruning.",
                "The following table shows the results: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 It is clear that difficult problems are better solved with more agents (see for instance xor5 15).",
                "We think that these benefits, which can be important with an increasing number of agents, are due to the fact that each agent really memorizes only part of the total number of examples, and this part is partly selected by other agents as counter examples, which cause a greater number of current hypothesis updates and therefore, a better exploration of the hypotheses space. 4.1.4.2 ML database problems.",
                "We did also experiments with some non boolean problems.",
                "We considered only two classes (positive/negative) problems, taken from the UCIs learning problems database[3].",
                "In all these problems, examples are described as a vector of couples (attribute, value).",
                "The value domains can be either boolean, numeric (wholly ordered set), or nominal (non-ordered set).",
                "An adequate set of atoms A must be constituted for each problem.",
                "For instance, if a is a numeric attribute, we define at most k threshold si, giving k+1 intervals of uniform density4 .",
                "Therefore, each distinct threshold si gives two atoms a ≤ si and a > si.",
                "In our experiments, we took a maximal number of threshold k = 8.",
                "For instance, in the iono problem case, there were 34 numeric attributes, and an instance is described with 506 atoms.",
                "Below are given the accuracy results of our system along with previous results.",
                "The column Nb ex. refer to the 4 The probability for the value of a to be in any interval is constant The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 169 number of examples used for learning5 .",
                "Column (1) represents minimal and maximal accuracy values for the thirty three classifiers tested in [8].",
                "Column (2) represents the results of [13], where various learning methods are compared to ensemble learning methods using weighted classifiers sets.",
                "Column S-1 and S-10 gives the accuracy of SMILE with respectively 1 and 10 agents.",
                "Pb Nb ex. (1) (2) S-1 S-10 ttt 862/574 // 76.2-99.7 99.7 99.9 kr-vs-kp 2876/958 // 91.4-99.4 96.8 97.3 iono 315 // 88.0-91.8 87.2 88.1 bupa 310 57-72 58-69.3 62.5 63.3 breastw 614 91-97 94.3-97.3 94.7 94.7 vote 391 94-96 95.3-96 91.9 92.6 pima 691 // 71.5- 73.4 65.0 65.0 heart 243 66-86 77.1-84.1 69.5 70.7 This table shows that the incremental algorithm corresponding to the single agent case, gives honorable results relatively to non-incremental classical methods using larger and more complex hypotheses.",
                "In some cases, there is an accuracy improvement with a 10 agents MAS.",
                "However, with such benchmarks data, which are often noisy, the difficulty does not really come from the way in which the search space is explored, and therefore the improvement observed is not always significant.",
                "The same kind of phenomenon have been observed with methods dedicated to hard boolean problems [4]. 4.2 MAS synchronization Here we consider that n single agents learn without interactions and at a given time start interacting thus forming a MAS.",
                "The purpose is to observe how the agents take advantage of collaboration when they start from different states of beliefs and memories.",
                "We compare in this section a 1-MAS, a 10-MAS (ref) and a 10-MAS (100sync) whose agents did not communicate during the arrival of the first 100 examples (10 by agents).",
                "The three accuracy curves are shown in figure 5.",
                "By comparing the single agent curve and the synchronized 10-MAS, we can observe that after the beginning of the synchronization, that is at 125 examples, accuracies are identical.",
                "This was expected since as soon as an example e received by the MAS contradicts the current hypothesis of the agent ra receiving it, this agent makes an update and its new hypothesis is proposed to the others agents for criticism.",
                "Therefore, this first contradictory example brings the MAS to reach consistency relatively to the whole set of examples present in agents memories.",
                "A higher accuracy, corresponding to a 10-MAS is obtained later, from the 175th example.",
                "In other words, the benefit of a better exploration of the research space is obtained slightly later in the learning process.",
                "Note that this synchronization happens naturally in all situations where agents have, for some reason, a divergence between their hypothesis and the system memory.",
                "This includes the fusion of two MAS into a single one or the arrival of new agents in an existing MAS. 4.3 Experiments on asynchronous learning: the effect of a large data stream 5 For ttt and kr-vs-kp, our protocol did not use more than respectively 574 and 958 learning examples, so we put another number in the column.",
                "Figure 5: Accuracies of a 1-MAS, a 10-MAS, and a 10-MAS synchronized after 100 examples.",
                "In this experiment we relax our slow learning mode: the examples are sent at a given rate to the MAS.",
                "The resulting example stream is measured in ms−1 , and represents the number of examples sent to the MAS each ms.",
                "Whenever the stream is too large, the MAS cannot reach MAS consistency on reception of an example from the environment before a new example arrives.",
                "This means that the update process, started by agent r0 as he received an example, may be unfinished when a new example is received by r0 or another agent r1.",
                "As a result, a critic agent may have at instant t to send counterexamples of hypotheses sent by various agents.",
                "However as far as the agents, in our setting, memorizes all the examples they receive whenever the stream ends, the MAS necessarily reaches MAS consistency with respect to all the examples received so far.",
                "In our experiments, though its learning curve is slowed down during the intense learning phase (corresponding to low accuracy of the current hypotheses), the MAS still reaches a satisfying hypothesis later on as there are less and less counterexamples in the example stream.",
                "In Figure 6 we compare the accuracies of two 11-MAS respectively submitted to example streams of different rates when learning the M11 formula.",
                "The learning curve of the MAS receiving an example at a 1/33 ms−1 rate is almost not altered (see Figure 4) whereas the 1/16 ms−1 MAS is first severely slowed down before catching up with the first one. 5.",
                "RELATED WORKS Since 96 [15], various work have been performed on learning in MAS, but rather few on concept learning.",
                "In [11] the MAS performs a form of ensemble learning in which the agents are lazy learners (no explicit representation is maintained) and sell useless examples to other agents.",
                "In [10] each agent observes all the examples but only perceive a part of their representation.",
                "In mutual online concept learning [14] the agents converge to a unique hypothesis, but each agent produces examples from its own concept representation, thus resulting in a kind of synchronization rather than in pure concept learning. 170 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 6: Accuracies of two asynchronous 11-MAS (1/33ms−1 and 1/16ms−1 example rates) . 6.",
                "CONCLUSION We have presented here and experimented a protocol for MAS online concept learning.",
                "The main feature of this collaborative learning mechanism is that it maintains a consistency property: though during the learning process each agent only receives and stores, with some limited redundancy, part of the examples received by the MAS, at any moment the current hypothesis is consistent with the whole set of examples.",
                "The hypotheses of our experiments do not address the issues of distributed MAS such as faults (for instance messages could be lost or corrupted) or other failures in general (crash, byzantine faults, etc.).",
                "Nevertheless, our framework is open, i.e., the agents can leave the system or enter it while the consistency mechanism is preserved.",
                "For instance if we introduce a timeout mechanism, even when a critic agent crashes or omits to answer, the consistency with the other critics (within the remaining agents) is entailed.",
                "In [1], a similar approach has been applied to MAS abduction problems: the hypotheses to maintain, given an incomplete information, are then facts or statements.",
                "Further work concerns first coupling induction and abduction in order to perform collaborative concept learning when examples are only partially observed by each agent, and second, investigating partial memory learning: how learning is preserved whenever one agent or the whole MAS forgets some selected examples.",
                "Aknowledgments We are very grateful to Dominique Bouthinon for implementing late modifications in SMILE, so much easing our experiments.",
                "Part of this work has been performed during the first authors visit to the Atelier De BioInformatique of Paris VI university, France. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In DALT-2006, May 2006. [2] W. W. Cohen.",
                "Fast effective rule induction.",
                "In ICML, pages 115-123, 1995. [3] C. B. D.J.",
                "Newman, S. Hettich and C. Merz.",
                "UCI repository of machine learning databases, 1998. [4] S. Esmeir and S. Markovitch.",
                "Lookahead-based algorithms for anytime induction of decision trees.",
                "In ICMLO4, pages 257-264.",
                "Morgan Kaufmann, 2004. [5] J. F¨urnkranz.",
                "A pathology of bottom-up hill-climbing in inductive rule learning.",
                "In ALT, volume 2533 of LNCS, pages 263-277.",
                "Springer, 2002. [6] A. Guerra-Hern´andez, A. ElFallah-Seghrouchni, and H. Soldano.",
                "Learning in BDI multi-agent systems.",
                "In CLIMA IV, volume 3259, pages 218-233.",
                "Springer Verlag, 2004. [7] M. Henniche.",
                "Mgi: an incremental bottom-up algorithm.",
                "In IEEE Aust. and New Zealand Conference on Intelligent Information Systems, pages 347-351, 1994. [8] T.-S. Lim, W.-Y.",
                "Loh, and Y.-S. Shih.",
                "A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms.",
                "Machine Learning, 40(3):203-228, 2000. [9] M. A. Maloof and R. S. Michalski.",
                "Incremental learning with partial instance memory.",
                "Artif.",
                "Intell., 154(1-2):95-126, 2004. [10] P. J. Modi and W.-M. Shen.",
                "Collaborative multiagent learning for classification tasks.",
                "In AGENTS 01, pages 37-38.",
                "ACM Press, 2001. [11] S. Onta˜non and E. Plaza.",
                "Recycling data for multi-agent learning.",
                "In ICML 05, pages 633-640.",
                "ACM Press, 2005. [12] J. R. Quinlan.",
                "Induction of decision trees.",
                "Machine Learning, 1(1):81-106, 1986. [13] U. R¨uckert and S. Kramer.",
                "Towards tight bounds for rule learning.",
                "In ICML 04 (International conference on Machine learning), page 90, New York, NY, USA, 2004.",
                "ACM Press. [14] J. Wang and L. Gasser.",
                "Mutual online concept learning for multiple agents.",
                "In AAMAS, pages 362-369.",
                "ACM Press, 2002. [15] G. Weiß and S. Sen, editors.",
                "Adaption and Learning in Multi-Agent Systems, volume 1042 of Lecture Notes in Computer Science.",
                "Springer, 1996. [16] I. H. Witten and E. Frank.",
                "Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.",
                "Morgan Kaufmann, October 1999.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 171"
            ],
            "original_annotated_samples": [
                "It leads us to define what is the <br>mas-consistency</br> of an agent with respect to the community.",
                "This <br>mas-consistency</br> maintenance process of an agent getting new information gives him the role of a learner and implies communication with other agents acting as critics.",
                "In section 2 we formally define the <br>mas-consistency</br> of an update mechanism for the whole MAS and we propose a generic update mechanism proved to be mas consistent.",
                "We call this notion the <br>mas-consistency</br>: Definition 2. <br>mas-consistency</br> of an agent An agent ri is mas-consistent iff Cons(Bi, Ki ∪ K) is true, where K = ∪j∈{1,..,n}−{i}Kj 1 is the set of all information from other agents of the MAS. 1 We will note this ∪ Kj when the context is similar.",
                "The global consistency of the MAS is then simply the <br>mas-consistency</br> of all its agents."
            ],
            "translated_annotated_samples": [
                "Nos lleva a definir cuál es la <br>mas-consistencia</br> de un agente con respecto a la comunidad.",
                "Este proceso de mantenimiento de la <br>mas-consistencia</br> de un agente al recibir nueva información le otorga el rol de aprendiz e implica la comunicación con otros agentes que actúan como críticos.",
                "En la sección 2 definimos formalmente la <br>mas-consistencia</br> de un mecanismo de actualización para todo el MAS y proponemos un mecanismo de actualización genérico demostrado que es mas consistente.",
                "Llamamos a esta noción la <br>mas-consistencia</br>: Definición 2. Un agente ri es mas-consistente si Cons(Bi, Ki ∪ K) es verdadero, donde K = ∪j∈{1,..,n}−{i}Kj 1 es el conjunto de toda la información de los otros agentes del MAS. 1 Lo notaremos como ∪ Kj cuando el contexto sea similar.",
                "La consistencia global del MAS es simplemente la <br>mas-consistencia</br> de todos sus agentes."
            ],
            "translated_text": "SMILE: Aprendizaje Incremental Multiagente de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av. del presidente Kennedy, 75116 París Henry Soldano LIPN, UMR 7030 CNRS, Universidad Paris-Norte, 99 Av. J-B Clement, 93430, Villetaneuse RESUMEN Este artículo trata sobre el problema del aprendizaje colaborativo en un sistema multiagente. Aquí cada agente puede actualizar de forma incremental sus creencias B (la representación del concepto) para que se mantenga consistente con el conjunto completo de información K (los ejemplos) que ha recibido del entorno u otros agentes. Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo lograr que, en cualquier momento, una misma representación conceptual consistente esté presente en cada agente. El protocolo correspondiente se aplica al aprendizaje supervisado de conceptos. El método resultante SMILE (que significa Sound Multiagent Incremental LEarning) se describe y experimenta aquí. Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de múltiples agentes que por un solo agente. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de conceptos; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistema multiagente Términos Generales Experimentación, Algoritmos, Medición, Rendimiento 1. INTRODUCCIÓN Este artículo trata sobre el problema del aprendizaje colaborativo de conceptos en un sistema multiagente. [6] introduce una caracterización del aprendizaje en un sistema multiagente según el nivel de conciencia de los agentes. En el nivel 1, los agentes aprenden ∗El autor principal de este artículo es un estudiante. en el sistema sin tener en cuenta la presencia de otros agentes, excepto a través de la modificación que traen al entorno con sus acciones. El nivel 2 implica una interacción directa entre los agentes, ya que pueden intercambiar mensajes para mejorar su aprendizaje. El nivel 3 requeriría que los agentes tengan en cuenta las competencias de otros agentes y sean capaces de aprender observando el comportamiento de los otros agentes (considerándolos como entidades independientes y no como parte indeterminada del entorno como en el nivel 1). En este artículo nos enfocamos en el nivel 2, estudiando la interacción directa entre los agentes involucrados en un proceso de aprendizaje. Cada agente se asume capaz de aprender de forma incremental a partir de los datos que recibe, lo que significa que cada agente puede actualizar su conjunto de creencias B para mantenerlo consistente con el conjunto completo de información K que ha recibido del entorno o de otros agentes. En tal caso, diremos que es a-inconsistente. Aquí, el conjunto de creencias B representa conocimiento hipotético que por lo tanto puede ser revisado, mientras que el conjunto de información K representa conocimiento cierto, compuesto por observaciones y hechos no revisables. Además, suponemos que al menos una parte Bc de las creencias de cada agente es común a todos los agentes y debe mantenerse de esa manera. Por lo tanto, una actualización de este conjunto común Bc por parte del agente r debe provocar una actualización de Bc para toda la comunidad de agentes. Nos lleva a definir cuál es la <br>mas-consistencia</br> de un agente con respecto a la comunidad. El proceso de actualización de las creencias de la comunidad cuando uno de sus miembros recibe nueva información puede entonces definirse como el proceso de mantenimiento de la consistencia que garantiza que cada agente en la comunidad permanecerá más consistente. Este proceso de mantenimiento de la <br>mas-consistencia</br> de un agente al recibir nueva información le otorga el rol de aprendiz e implica la comunicación con otros agentes que actúan como críticos. Sin embargo, los agentes no están especializados y a su vez pueden ser aprendices o críticos, ninguno de ellos está limitado a un rol específico. Las piezas de información se distribuyen entre los agentes, pero pueden ser redundantes. No hay memoria central. El trabajo descrito aquí tiene su origen en un trabajo anterior sobre el aprendizaje en un sistema multiagente intencional utilizando un formalismo BDI [6]. En ese trabajo, los agentes tenían planes, cada uno de ellos asociado con un contexto que define en qué condiciones puede ser activado. Los planes (cada uno con su propio contexto) eran comunes a todo el conjunto de agentes en la comunidad. Los agentes tuvieron que adaptar su plan en función del contexto, dependiendo del fracaso o éxito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo a otros agentes ejemplos (éxitos o fracasos de planes). Sin embargo, este trabajo carecía de un protocolo de aprendizaje colectivo que permitiera una verdadera autonomía del sistema multiagente. El estudio de dicho protocolo es el objeto del presente artículo. En la sección 2 definimos formalmente la <br>mas-consistencia</br> de un mecanismo de actualización para todo el MAS y proponemos un mecanismo de actualización genérico demostrado que es mas consistente. En la sección 3 describimos SMILE, un aprendiz de conceptos multiagente incremental que aplica nuestro mecanismo de actualización mas consistente para el aprendizaje colaborativo de conceptos. La sección 4 describe varios experimentos sobre SMILE y discute varios problemas, incluyendo cómo varían la precisión y la simplicidad de la hipótesis actual al comparar el aprendizaje de un solo agente y el aprendizaje de múltiples agentes. En la sección 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la sección 6 discutiendo investigaciones adicionales sobre el aprendizaje más consistente. MODELO FORMAL 2.1 Definiciones y marco En esta sección, presentamos una formulación general del aprendizaje incremental colectivo en un sistema cognitivo de múltiples agentes. Representamos un MAS como un conjunto de agentes r1, ..., rn. Cada agente ri tiene un conjunto de creencias Bi que consiste en todo el conocimiento revisable que posee. Parte de estos conocimientos deben ser compartidos con otros agentes. La parte de Bi que es común a todos los agentes se denota como BC. Esta parte común provoca una dependencia entre los agentes. Si un agente ri actualiza su conjunto de creencias Bi a Bi, cambiando en el proceso BC en BC, entonces todos los demás agentes rk deben actualizar su conjunto de creencias Bk a Bk para que BC ⊆ Bk. Además, cada agente ri ha almacenado cierta información Ki. Suponemos que alguna propiedad de consistencia Cons(Bi, Ki) puede ser verificada por el agente mismo entre sus creencias Bi y su información Ki. Como se dijo antes, Bi representa el conocimiento que podría ser revisado, mientras que Ki representa hechos observados, considerados verdaderos, y que posiblemente puedan contradecir a Bi. Definición 1. a-consistencia de un agente Un agente ri es a-consistente si Cons(Bi, Ki) es verdadero. Ejemplo 1. El agente r1 tiene un conjunto de planes que se encuentran en la parte común BC de B1. Cada plan P tiene un contexto desencadenante d(P) (que actúa como una precondición) y un cuerpo. Alguna pieza de información k podría ser el plan P, desencadenado en la situación s, ha fallado a pesar de que s es una instancia de d(P). Si esta pieza de información se agrega a K1, entonces el agente r1 ya no es a-consistente: Cons(B1, K1 ∪ k) es falso. También queremos definir alguna noción de consistencia para todo el MAS dependiendo de los conjuntos de creencias e información de sus elementos constituyentes. Primero definiremos la consistencia de un agente ri con respecto a su conjunto de creencias Bi y su propio conjunto de información Ki junto con todos los conjuntos de información K1...Kn de los otros agentes del MAS. Simplemente lo haremos considerando cuál sería la a-consistencia del agente si tuviera la información de todos los demás agentes. Llamamos a esta noción la <br>mas-consistencia</br>: Definición 2. Un agente ri es mas-consistente si Cons(Bi, Ki ∪ K) es verdadero, donde K = ∪j∈{1,..,n}−{i}Kj 1 es el conjunto de toda la información de los otros agentes del MAS. 1 Lo notaremos como ∪ Kj cuando el contexto sea similar. Ejemplo 2. Usando el ejemplo anterior, supongamos que la pieza de información k está incluida en la información K2 del agente r2. Si la pieza de información no se transmite a r1, y por lo tanto no se agrega a K1, r1 permanece a-consistente. Sin embargo, r1 no es tan consistente como k en el conjunto K de toda la información del MAS. La consistencia global del MAS es simplemente la <br>mas-consistencia</br> de todos sus agentes. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "incremental learning": {
            "translated_key": "aprendizaje incremental",
            "is_in_text": true,
            "original_annotated_sentences": [
                "SMILE: Sound Multi-agent <br>incremental learning</br> ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av.",
                "du pr´esident Kennedy, 75116 Paris Henry Soldano LIPN, UMR 7030 CNRS, University Paris-Nord, 99 Av.",
                "J-B Clement, 93430, Villetaneuse ABSTRACT This article deals with the problem of collaborative learning in a multi-agent system.",
                "Here each agent can update incrementally its beliefs B (the concept representation) so that it is in a way kept consistent with the whole set of information K (the examples) that he has received from the environment or other agents.",
                "We extend this notion of consistency (or soundness) to the whole MAS and discuss how to obtain that, at any moment, a same consistent concept representation is present in each agent.",
                "The corresponding protocol is applied to supervised concept learning.",
                "The resulting method SMILE (standing for Sound Multiagent <br>incremental learning</br>) is described and experimented here.",
                "Surprisingly some difficult boolean formulas are better learned, given the same learning set, by a Multi agent system than by a single agent.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Concept learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent system General Terms Experimentation, Algorithms, Measurement, Performance 1.",
                "INTRODUCTION This article deals with the problem of collaborative concept learning in a multi-agent system. [6] introduces a characterisation of learning in multi-agent system according to the level of awareness of the agents.",
                "At level 1, agents learn ∗The primary author of this paper is a student. in the system without taking into account the presence of other agents, except through the modification brought upon the environment by their action.",
                "Level 2 implies direct interaction between the agents as they can exchange messages to improve their learning.",
                "Level 3 would require agents to take into account the competencies of other agents, and be able to learn from observation of the other agents behaviour (while considering them as independant entities and not indetermined part of the environment as in level 1).",
                "We focus in this paper on level 2, studying direct interaction between agents involved in a learning process.",
                "Each agent is assumed to be able to learn incrementally from the data he receives, meaning that each agent can update his belief set B to keep it consistent with the whole set of information K that he has received from the environment or from other agents.",
                "In such a case, we will say that he is a-consistent.",
                "Here, the belief set B represents hypothetical knowledge that can therefore be revised, whereas the set of information K represents certain knowledge, consisting of non revisable observations and facts.",
                "Moreover, we suppose that at least a part Bc of the beliefs of each agent is common to all agents and must stay that way.",
                "Therefore, an update of this common set Bc by agent r must provoke an update of Bc for the whole community of agents.",
                "It leads us to define what is the mas-consistency of an agent with respect to the community.",
                "The update process of the community beliefs when one of its members gets new information can then be defined as the consistency maintenance process ensuring that every agent in the community will stay masconsistent.",
                "This mas-consistency maintenance process of an agent getting new information gives him the role of a learner and implies communication with other agents acting as critics.",
                "However, agents are not specialised and can in turn be learners or critics, none of them being kept to a specific role.",
                "Pieces of information are distributed among the agents, but can be redundant.",
                "There is no central memory.",
                "The work described here has its origin in a former work concerning learning in an intentional multi-agent system using a BDI formalism [6].",
                "In that work, agents had plans, each of them being associated with a context defining in which conditions it can be triggered.",
                "Plans (each of them having its own context) were common to the whole set of agents in the community.",
                "Agents had to adapt their plan contexts depending on the failure or success of executed plans, using a learning mechanism and asking other agents for examples (plans successes or failures).",
                "However this work lacked a collective learning protocol enabling a real autonomy of the multi-agent system.",
                "The study of such a protocol is the object of the present paper.",
                "In section 2 we formally define the mas-consistency of an update mechanism for the whole MAS and we propose a generic update mechanism proved to be mas consistent.",
                "In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent update mechanism to collaborative concept learning.",
                "Section 4 describes various experiments on SMILE and discusses various issues including how the accuracy and the simplicity of the current hypothesis vary when comparing single agent learning and mas learning.",
                "In section 5 we briefly present some related works and then conclude in section 6 by discussing further investigations on mas consistent learning. 2.",
                "FORMAL MODEL 2.1 Definitions and framework In this section, we present a general formulation of collective <br>incremental learning</br> in a cognitive multi agent system.",
                "We represent a MAS as a set of agents r1, ..., rn.",
                "Each agent ri has a belief set Bi consisting of all the revisable knowledge he has.",
                "Part of these knowledges must be shared with other agents.",
                "The part of Bi that is common to all agents is denoted as BC .",
                "This common part provokes a dependency between the agents.",
                "If an agent ri updates his belief set Bi to Bi, changing in the process BC into BC , all other agents rk must then update their belief set Bk to Bk so that BC ⊆ Bk.",
                "Moreover, each agent ri has stored some certain information Ki.",
                "We suppose that some consistency property Cons(Bi, Ki) can be verified by the agent itself between its beliefs Bi and its information Ki.",
                "As said before, Bi represents knowledge that might be revised whereas Ki represents observed facts, taken as being true, and which can possibly contradict Bi.",
                "Definition 1. a-consistency of an agent An agent ri is a-consistent iff Cons(Bi, Ki) is true.",
                "Example 1.",
                "Agent r1 has a set of plans which are in the common part BC of B1.",
                "Each plan P has a triggering context d(P) (which acts as a pre-condition) and a body.",
                "Some piece of information k could be plan P, triggered in situation s, has failed in spite of s being an instance of d(P).",
                "If this piece of information is added to K1, then agent r1 is not a-consistent anymore: Cons(B1, K1 ∪ k) is false.",
                "We also want to define some notion of consistency for the whole MAS depending on the belief and information sets of its constituting elements.",
                "We will first define the consistency of an agent ri with respect to its belief set Bi and its own information set Ki together with all information sets K1...Kn from the other agents of the MAS.",
                "We will simply do that by considering what would be the a-consistency of the agent if he has the information of all the other agents.",
                "We call this notion the mas-consistency: Definition 2. mas-consistency of an agent An agent ri is mas-consistent iff Cons(Bi, Ki ∪ K) is true, where K = ∪j∈{1,..,n}−{i}Kj 1 is the set of all information from other agents of the MAS. 1 We will note this ∪ Kj when the context is similar.",
                "Example 2.",
                "Using the previous example, suppose that the piece of information k is included in the information K2 of agent r2.",
                "As long as the piece of information is not transmitted to r1, and so added to K1 , r1 remains a-consistent.",
                "However, r1 is not mas-consistent as k is in the set K of all information of the MAS.",
                "The global consistency of the MAS is then simply the mas-consistency of all its agents.",
                "Definition 3.",
                "Consistency of a MAS A MAS r1,...,rn is consistent iff all its agents ri are masconsistent.",
                "We now define the required properties for a revision mechanism M updating an agent ri when it gets a piece of information k. In the following, we will suppose that: • Update is always possible, that is, an agent can always modify its belief set Bi in order to regain its a-consistency.",
                "We will say that each agent is locally efficient. • Considering two sets of information Cons(Bi, K1) and Cons(Bi, K2), we also have Cons(Bi, K1 ∪ K2).",
                "That is, a-consistency of the agents is additive. • If a piece of information k concerning the common set BC is consistent with an agent, it is consistent with all agents: for all pair of agents (ri,rj) such that Cons(Bi, Ki) and Cons(Bj, Kj) are true, we have, for all piece of information k: Cons(Bi, Ki ∪ k) iff Cons(Bj, Kj ∪ k).",
                "In such a case, we will say that the MAS is coherent.",
                "This last condition simply means that the common belief set BC is independent of the possible differences between the belief sets Bi of each agent ri.",
                "In the simplest case, B1 = ... = Bn = BC .",
                "M will also be viewed as an <br>incremental learning</br> mechanism and represented as an application changing Bi in Bi.",
                "In the following, we shall note ri(Bi, Ki) for ri when it is useful.",
                "Definition 4. a-consistency of a revision An update mechanism M is a-consistent iff for any agent ri and any piece of information k reaching ri, the a-consistency of this agent is preserved.",
                "In other words, iff: ri(Bi, Ki) a-consistent ⇒ ri(Bi, Ki) a-consistent, where Bi = M(Bi) and Ki = Ki ∪ k is the set of all information from other agents of the MAS.",
                "In the same way, we define the mas-consistency of a revision mechanism as the a-consistency of this mechanism should the agents dispose of all information in the MAS.",
                "In the following, we shall note, if needed, ri(Bi, Ki, K) for the agent ri in MAS r1 . . . rn.",
                "Definition 5. mas-consistency of a revision An update mechanism Ms is mas-consistent iff for all agent ri and all pieces of information k reaching ri, the masconsistency of this agent is preserved.",
                "In other words, if: ri(Bi, Ki, K) mas-consistent ⇒ ri(Bi, Ki, K) mas-consistent, where Bi = Ms(Bi), Ki = Ki ∪ k, and K = ∪Kj is the set of all information from the MAS.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 165 At last, when a mas-consistent mechanism is applied by an agent getting a new piece of information, a desirable sideeffect of the mechanism should be that all others agents remains mas-consistent after any modification of the common part BC , that is, the MAS itself should become consistent again.",
                "This property is defined as follows: Definition 6.",
                "Strong mas-consistency of a revision An update mechanism Ms is strongly mas-consistent iff - Ms is mas-consistent, and - the application of Ms by an agent preserves the consistency of the MAS. 2.2 A strongly mas-consistent update mechanism The general idea is that, since information is distributed among all the agents of the MAS, there must be some interaction between the learner agent and the other agents in a strongly mas-consistent update mechanism Ms.",
                "In order to ensure its mas-consistency, Ms will be constituted of reiterated applications by the learner agent ri of an internal a-consistent mechanism M, followed by some interactions between ri and the other agents, until ri regain its masconsistency.",
                "We describe below such a mechanism, first with a description of an interaction, then an iteration, and finally a statement of the termination condition of the mechanism.",
                "The mechanism is triggered by an agent ri upon receipt of a piece of information k disrupting the mas-consistency.",
                "We shall note M(Bi) the belief set of the learner agent ri after an update, BC the common part modified by ri, and Bj the belief set of another agent rj induced by the modification of its common part BC in BC .",
                "An interaction I(ri, rj) between the learner agent ri and another agent rj, acting as critic is constituted of the following steps: • agent ri sends the update BC of the common part of its beliefs.",
                "Having applied its update mechanism, ri is a-consistent. • agent rj checks the modification Bj of its beliefs induced by the update BC .",
                "If this modification preserve its a-consistency, rj adopts this modification. • agent rj sends either an acceptation of BC or a denial along with one (or more) piece(s) of information k such that Cons(Bj, k ) is false.",
                "An iteration of Ms will then be composed of: • the reception by the learner agent ri of a piece of information and the update M(Bi) restoring its aconsistency • a set of interactions I(ri, rj) (in which several critic agents can possibly participate).",
                "If at least one piece of information k is transmitted to ri, the addition of k will necessarily make ri a-inconsistent and a new iteration will then occur.",
                "This mechanism Ms ends when no agent can provide such a piece of information k .",
                "When it is the case, the masconsistency of the learner agent ri is restored.",
                "Proposition 1.",
                "Let r1,...,rn be a consistent MAS in which agent ri receives a piece of information k breaking its aconsistency, and M an a-consistent internal update mechanism.",
                "The update mechanism Ms described above is strongly mas-consistent.",
                "Proof.",
                "The proof directly derives from the mechanism description.",
                "This mechanism ensures that each time an agent receives an event, its mas-consistency will be restored.",
                "As the other agents all adopt the final update BC , they are all mas-consistent, and the MAS is consistent.",
                "Therefore Ms is a strongly consistent update mechanism.",
                "In the mechanism Ms described above, the learner agent is the only one that receives and memorizes information during the mechanism execution.",
                "It ensures that Ms terminates.",
                "The pieces of information transmitted by other agents and memorized by the learner agent are redundant as they are already present in the MAS, more precisely in the memory of the critic agents that transmitted them.",
                "Note that the mechanism Ms proposed here does not explicitly indicate the order nor the scope of the interactions.",
                "We will consider in the following that the modification proposal BC is sent sequentially to the different agents (synchronous mechanism).",
                "Moreover, the response of a critic agent will only contain one piece of information inconsistent with the proposed modification.",
                "We will say that the response of the agent is minimal.",
                "This mechanism Ms, being synchronous with minimal response, minimizes the amount of information transmitted by the agents.",
                "We will now illustrate it in the case of multi-agent concept learning. 3.",
                "SOUNDMULTI-AGENTINCREMENTAL LEARNING 3.1 The learning task We experiment the mechanism proposed above in the case of incremental MAS concept learning.",
                "We consider here a hypothesis language in which a hypothesis is a disjunction of terms.",
                "Each term is a conjunction of atoms from a set A.",
                "An example is represented by a tag + or − and a description 2 composed of a subset of atoms e ⊆ A.",
                "A term covers an example if its constituting atoms are included in the example.",
                "A hypothesis covers an example if one of its term covers it.",
                "This representation will be used below for learning boolean formulae.",
                "Negative literals are here represented by additional atoms, like not − a.",
                "The boolean formulae f =(a ∧ b) ∨ (b ∧ ¬c) will then be written (a ∧ b) ∨ (b ∧ not − c).",
                "A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 <br>incremental learning</br> process The learning process is an update mechanism that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis.",
                "Before this update, the given hypothesis is complete, meaning that it covers all positive examples of E+ , and 2 When no confusion is possible, the word example will be used to refer to the pair (tag, description) as well as the description alone. 166 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) coherent, meaning that it does not cover any negative example of E− .",
                "After the update, the new hypothesis must be complete and coherent with the new memory state E ∪ {e}.",
                "We describe below our single agent update mechanism, inspired from a previous work on <br>incremental learning</br>[7].",
                "In the following, a hypothesis H for the target formula f is a list of terms h, each of them being a conjunction of atoms.",
                "H is coherent if all terms h are coherent, and H is complete if each element of E+ is covered by at least one term h of H. Each term is by construction the lgg (least general generalization) of a subset of positives instances {e1, ..., en}[5], that is the most specific term covering {e1, ..., en}.",
                "The lgg operator is defined by considering examples as terms, so we denote as lgg(e) the most specific term that covers e, and as lgg(h, e) the most specific term which is more general than h and that covers e. Restricting the term to lgg is the basis of a lot of Bottom-Up learning algorithms (for instance [5]).",
                "In the typology proposed by [9], our update mechanism is an incremental learner with full instance memory: learning is made by successive updates and all examples are stored.",
                "The update mechanism depends of the ongoing hypothesis H, the ongoing examples E+ and E− , and the new example e. There are three possible cases: • e is positive and H covers e, or e is negative and H does not cover e. No update is needed, H is already complete and coherent with E ∪ {e}. • e is positive and H does not cover e: e is denoted as a positive counterexample of H. Then we seek to generalize in turn the terms h of H. As soon as a correct generalization h = lgg(h, e) is found, h replaces h in H. If there is a term that is less general that h , it is discarded.",
                "If no generalization is correct (meaning here coherent), H ∪ lgg(e) replaces H. • e is negative and H covers e: e is denoted as a negative counterexample of H. Each term h covering e is then discarded from H and replaced by a set of terms {h1, ...., hn} that is, as a whole, coherent with E− ∪ {e} and that covers the examples of E+ uncovered by H − {h}.",
                "Terms of the final hypothesis H that are less general than others are discarded from H. We will now describe the case where e = e− is a covered negative example.",
                "The following functions are used here: • coveredOnlyBy(h, E+) gives the subset of E+ covered by h and no other term of H. • bestCover(h1, h2) gives h1 if h1 covers more examples from uncoveredPos than h2, otherwise it gives h2. • covered(h) gives the elements of uncoveredPos covered by h. // Specialization of each h covering e− for each h of H covering e− do H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= atoms that are neither in e− nor in h while (uncoveredPos = ∅) do // seeking the best specialization of h hc=h best=⊥ // ⊥ covers no example for each a of Ar do hc= h ∧ a best = bestCover(hc, best) endfor Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) endwhile endfor Terms of H that are less general than others are discarded.",
                "Note that this mechanism tends to both make a minimal update of the current hypothesis and minimize the number of terms in the hypothesis, in particular by discarding terms less general than other ones after updating a hypothesis. 3.3 Collective learning If H is the current hypothesis, Ei the current example memory of agent ri and E the set of all the examples received by the system, the notation of section 2 becomes Bi = BC = H, Ki = Ei and K = E. Cons(H, Ei) states that H is complete and coherent with Ei.",
                "In such a case, ri is a-consistent.",
                "The piece of information k received by agent ri is here simply an example e along with its tag.",
                "If e is such that the current hypothesis H is not complete or coherent with Ei ∪ {e}, e contradicts H: ri becomes a-inconsistent, and therefore the MAS is not consistent anymore.",
                "The update of a hypothesis when a new example arrives is an a- consistent mechanism.",
                "Following proposition 1 this mechanism can be used to produce a strong mas-consistent mechanism: upon reception of a new example in the MAS by an agent r, an update is possibly needed and, after a set of interactions between r and the other agents, results in a new hypothesis shared by all the agents and that restores the consistency of the MAS, that is which is complete and coherent with the set ES of all the examples present in the MAS.",
                "It is clear that by minimizing the number of hypothesis modifications, this synchronous and minimal mechanism minimize the number of examples received by the learner from other agents, and therefore, the total number of examples stored in the system. 4.",
                "EXPERIMENTS In the following, we will learn a boolean formula that is a difficult test for the learning method: the 11-multiplexer (see [4]).",
                "It concerns 3 address boolean attributes a0, a1, a2 and 8 data boolean attributes d0, ..., d7.",
                "Formulae f11 is satisfied if the number coded by the 3 address attributes is the number of a data attribute whose value is 1.",
                "Its formula is the following: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0).",
                "There are 2048 = 211 possible examples, half of whom are positive (meaning they satisfy f11) while the other half is negative.",
                "An experiment is typically composed of 50 trials.",
                "Each run corresponds to a sequence of 600 examples that are incrementally learned by a Multi Agent System with n agents The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 167 (n-MAS).",
                "A number of variables such as accuracy, (i.e. the frequency of correct classification of a set of unseen examples), hypothesis size (i.e. the number of terms in the current formula) or number of stored examples, is recorded each time 25 examples are received by the system during those runs.",
                "In the protocol that is used here, a new example is sent to a random agent when the MAS is consistent.",
                "The next example will be sent in turn to an other agent when the MAS consistency will have been restored.",
                "In such a way we simulate a kind of slow learning: the frequency of example arrivals is slow compared to the time taken by an update. 4.1 Efficiency of MAS concept learning 4.1.1 Execution time We briefly discuss here execution time of learning in the MAS.",
                "Note that the whole set of action and interaction in the MAS is simulated on a single processor.",
                "Figure 1 shows that time linearly depends on the number of agents.",
                "At the end of the most active part of learning (200 examples), a 16MAS has taken 4 times more learning time than a 4-MAS.",
                "This execution time represents the whole set of learning and Figure 1: Execution time of a n-MAS (from n = 2 at the bottom to n = 20 on the top). communication activity and hints at the cost of maintaining a consistent learning hypothesis in a MAS composed of autonomous agents. 4.1.2 Redundancy in the MAS memory We study now the distribution of the examples in the MAS memory.",
                "Redundancy is written RS = nS/ne, where nS is the total number of examples stored in the MAS, that is the sum of the sizes of agents examples memories Ei, and ne is the total number of examples received from the environment in the MAS.",
                "In figure 2, we compare redundancies in 2 to 20 agents MAS.",
                "There is a peak, slowly moving from 80 to 100 examples, that represents the number of examples for which the learning is most active.",
                "For 20 agents, maximal redundancy is no more than 6, which is far less than the maximal theoretical value of 20.",
                "Note that when learning becomes less active, redundancy tends towards its minimal value 1: when there is no more updates, examples are only Figure 2: Redundancy of examples stored in a nMAS (from n = 2 at the bottom to n = 20 on the top) . stored by the agent that receives them. 4.1.3 A n-MAS selects a simpler solution than a single agent The proposed mechanism tends to minimize the number of terms in the selected hypothesis.",
                "During learning, the size of the current hypothesis grows up beyond the optimum, and then decreases when the MAS converges.",
                "In the Multiplexer 11 testbed, the optimal number of terms is 8, but there also exist equivalent formulas with more terms.",
                "It is interesting to note that in this case the 10-MAS converges towards an exact solution closer to the optimal number of terms (here 8) (see Figure 3).",
                "After 1450 examples have been presented both 1-MAS and 10-MAS have exactly learned the concept (the respective accuracies are 0.9999 and 1) but the single agent expresses in average the result as a 11.0 terms DNF whereas the 10-MAS expresses it as a 8.8 terms DNF.",
                "However for some other boolean functions we found that during learning 1-MAS always produces larger hypotheses than 10-MAS but that both MAS converge to hypotheses with similar size results. 4.1.4 A n-MAS is more accurate than a single agent Figure 4 shows the improvement brought by a MAS with n agents compared to a single agent.",
                "This improvement was not especially expected, because whether we have one or n agents, when N examples are given to the MAS it has access to the same amount of information, maintains only on ongoing hypothesis and uses the same basic revision algorithm whenever an agent has to modify the current hypothesis.",
                "Note that if the accuracy of 1, 2, 4 and 10-MAS are significantly different, getting better as the number of agents increases, there is no clear difference beyond this point: the accuracy curve of the 100 agents MAS is very close to the one of the 10 agents MAS. 4.1.4.1 Boolean formulas.",
                "To evaluate this accuracy improvement, we have experimented our protocol on other problems of boolean function learning, As in the Multiplexer-11 case, these functions 168 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 3: Size of the hypothesis built by 1 and 10MAS: the M11 case.",
                "Figure 4: Accuracy of a n-MAS: the M11 case (from bottom to top, n = 1, 2, 4, 10, 100). are learnt in the form of more or less syntactically complex DNF3 (that is with more or less conjunctive terms in the DNF), but are also more or less difficult to learn as it can be difficult to get its way in the hypothesis space to reach them.",
                "Furthermore, the presence in the description of irrelevant attributes (that is attributes that does not belong to the target DNF) makes the problem more difficult.",
                "The following problems have been selected to experiment our protocol: (i) the multiplexer-11 with 9 irrelevant attributes: M11 9, (ii) the 20-multiplexer M20 (with 4 address bits and 16 data bits), (iii) a difficult parity problem (see [4]) the Xorp m: there must be an odd number of bits with value 1 in the p first attributes for the instance to be positive, the p others bits being irrelevant, and (iv) a simple DNF formula (a ∧ b ∧ c) ∨ (c ∧ d ∧ e)(e ∧ f ∧ g) ∧ (g ∧ h ∧ i) with 19 irrelevant attributes.",
                "The following table sums up some information about these problems, giving the total number of attributes including irrelevant ones, the number of irrelevant 3 Disjunctive Normal Forms attributes, the minimal number of terms of the corresponding DNF, and the number of learning examples used.",
                "Pb att. irre. att. terms ex.",
                "M11 11 0 8 200 M11 9 20 9 8 200 M20 20 0 16 450 Xor3 25 28 25 4 200 Xor5 5 10 5 16 180 Xor5 15 20 15 16 600 Simple4-9 19 28 19 4 200 Below are given the accuracy results of our learning mechanism with a single agent and a 10 agents MAS, along with the results of two standard algorithms implemented with the learning environment WEKA[16]: JRip (an implementation of RIPPER[2]) and Id3[12].",
                "For the experiments with JRip and Id3, we measured the mean accuracy on 50 trials, each time randomly separating examples in a learning set and a test set.",
                "JRip and Id3 parameters are default parameters, except that JRip is used without pruning.",
                "The following table shows the results: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 It is clear that difficult problems are better solved with more agents (see for instance xor5 15).",
                "We think that these benefits, which can be important with an increasing number of agents, are due to the fact that each agent really memorizes only part of the total number of examples, and this part is partly selected by other agents as counter examples, which cause a greater number of current hypothesis updates and therefore, a better exploration of the hypotheses space. 4.1.4.2 ML database problems.",
                "We did also experiments with some non boolean problems.",
                "We considered only two classes (positive/negative) problems, taken from the UCIs learning problems database[3].",
                "In all these problems, examples are described as a vector of couples (attribute, value).",
                "The value domains can be either boolean, numeric (wholly ordered set), or nominal (non-ordered set).",
                "An adequate set of atoms A must be constituted for each problem.",
                "For instance, if a is a numeric attribute, we define at most k threshold si, giving k+1 intervals of uniform density4 .",
                "Therefore, each distinct threshold si gives two atoms a ≤ si and a > si.",
                "In our experiments, we took a maximal number of threshold k = 8.",
                "For instance, in the iono problem case, there were 34 numeric attributes, and an instance is described with 506 atoms.",
                "Below are given the accuracy results of our system along with previous results.",
                "The column Nb ex. refer to the 4 The probability for the value of a to be in any interval is constant The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 169 number of examples used for learning5 .",
                "Column (1) represents minimal and maximal accuracy values for the thirty three classifiers tested in [8].",
                "Column (2) represents the results of [13], where various learning methods are compared to ensemble learning methods using weighted classifiers sets.",
                "Column S-1 and S-10 gives the accuracy of SMILE with respectively 1 and 10 agents.",
                "Pb Nb ex. (1) (2) S-1 S-10 ttt 862/574 // 76.2-99.7 99.7 99.9 kr-vs-kp 2876/958 // 91.4-99.4 96.8 97.3 iono 315 // 88.0-91.8 87.2 88.1 bupa 310 57-72 58-69.3 62.5 63.3 breastw 614 91-97 94.3-97.3 94.7 94.7 vote 391 94-96 95.3-96 91.9 92.6 pima 691 // 71.5- 73.4 65.0 65.0 heart 243 66-86 77.1-84.1 69.5 70.7 This table shows that the incremental algorithm corresponding to the single agent case, gives honorable results relatively to non-incremental classical methods using larger and more complex hypotheses.",
                "In some cases, there is an accuracy improvement with a 10 agents MAS.",
                "However, with such benchmarks data, which are often noisy, the difficulty does not really come from the way in which the search space is explored, and therefore the improvement observed is not always significant.",
                "The same kind of phenomenon have been observed with methods dedicated to hard boolean problems [4]. 4.2 MAS synchronization Here we consider that n single agents learn without interactions and at a given time start interacting thus forming a MAS.",
                "The purpose is to observe how the agents take advantage of collaboration when they start from different states of beliefs and memories.",
                "We compare in this section a 1-MAS, a 10-MAS (ref) and a 10-MAS (100sync) whose agents did not communicate during the arrival of the first 100 examples (10 by agents).",
                "The three accuracy curves are shown in figure 5.",
                "By comparing the single agent curve and the synchronized 10-MAS, we can observe that after the beginning of the synchronization, that is at 125 examples, accuracies are identical.",
                "This was expected since as soon as an example e received by the MAS contradicts the current hypothesis of the agent ra receiving it, this agent makes an update and its new hypothesis is proposed to the others agents for criticism.",
                "Therefore, this first contradictory example brings the MAS to reach consistency relatively to the whole set of examples present in agents memories.",
                "A higher accuracy, corresponding to a 10-MAS is obtained later, from the 175th example.",
                "In other words, the benefit of a better exploration of the research space is obtained slightly later in the learning process.",
                "Note that this synchronization happens naturally in all situations where agents have, for some reason, a divergence between their hypothesis and the system memory.",
                "This includes the fusion of two MAS into a single one or the arrival of new agents in an existing MAS. 4.3 Experiments on asynchronous learning: the effect of a large data stream 5 For ttt and kr-vs-kp, our protocol did not use more than respectively 574 and 958 learning examples, so we put another number in the column.",
                "Figure 5: Accuracies of a 1-MAS, a 10-MAS, and a 10-MAS synchronized after 100 examples.",
                "In this experiment we relax our slow learning mode: the examples are sent at a given rate to the MAS.",
                "The resulting example stream is measured in ms−1 , and represents the number of examples sent to the MAS each ms.",
                "Whenever the stream is too large, the MAS cannot reach MAS consistency on reception of an example from the environment before a new example arrives.",
                "This means that the update process, started by agent r0 as he received an example, may be unfinished when a new example is received by r0 or another agent r1.",
                "As a result, a critic agent may have at instant t to send counterexamples of hypotheses sent by various agents.",
                "However as far as the agents, in our setting, memorizes all the examples they receive whenever the stream ends, the MAS necessarily reaches MAS consistency with respect to all the examples received so far.",
                "In our experiments, though its learning curve is slowed down during the intense learning phase (corresponding to low accuracy of the current hypotheses), the MAS still reaches a satisfying hypothesis later on as there are less and less counterexamples in the example stream.",
                "In Figure 6 we compare the accuracies of two 11-MAS respectively submitted to example streams of different rates when learning the M11 formula.",
                "The learning curve of the MAS receiving an example at a 1/33 ms−1 rate is almost not altered (see Figure 4) whereas the 1/16 ms−1 MAS is first severely slowed down before catching up with the first one. 5.",
                "RELATED WORKS Since 96 [15], various work have been performed on learning in MAS, but rather few on concept learning.",
                "In [11] the MAS performs a form of ensemble learning in which the agents are lazy learners (no explicit representation is maintained) and sell useless examples to other agents.",
                "In [10] each agent observes all the examples but only perceive a part of their representation.",
                "In mutual online concept learning [14] the agents converge to a unique hypothesis, but each agent produces examples from its own concept representation, thus resulting in a kind of synchronization rather than in pure concept learning. 170 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 6: Accuracies of two asynchronous 11-MAS (1/33ms−1 and 1/16ms−1 example rates) . 6.",
                "CONCLUSION We have presented here and experimented a protocol for MAS online concept learning.",
                "The main feature of this collaborative learning mechanism is that it maintains a consistency property: though during the learning process each agent only receives and stores, with some limited redundancy, part of the examples received by the MAS, at any moment the current hypothesis is consistent with the whole set of examples.",
                "The hypotheses of our experiments do not address the issues of distributed MAS such as faults (for instance messages could be lost or corrupted) or other failures in general (crash, byzantine faults, etc.).",
                "Nevertheless, our framework is open, i.e., the agents can leave the system or enter it while the consistency mechanism is preserved.",
                "For instance if we introduce a timeout mechanism, even when a critic agent crashes or omits to answer, the consistency with the other critics (within the remaining agents) is entailed.",
                "In [1], a similar approach has been applied to MAS abduction problems: the hypotheses to maintain, given an incomplete information, are then facts or statements.",
                "Further work concerns first coupling induction and abduction in order to perform collaborative concept learning when examples are only partially observed by each agent, and second, investigating partial memory learning: how learning is preserved whenever one agent or the whole MAS forgets some selected examples.",
                "Aknowledgments We are very grateful to Dominique Bouthinon for implementing late modifications in SMILE, so much easing our experiments.",
                "Part of this work has been performed during the first authors visit to the Atelier De BioInformatique of Paris VI university, France. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In DALT-2006, May 2006. [2] W. W. Cohen.",
                "Fast effective rule induction.",
                "In ICML, pages 115-123, 1995. [3] C. B. D.J.",
                "Newman, S. Hettich and C. Merz.",
                "UCI repository of machine learning databases, 1998. [4] S. Esmeir and S. Markovitch.",
                "Lookahead-based algorithms for anytime induction of decision trees.",
                "In ICMLO4, pages 257-264.",
                "Morgan Kaufmann, 2004. [5] J. F¨urnkranz.",
                "A pathology of bottom-up hill-climbing in inductive rule learning.",
                "In ALT, volume 2533 of LNCS, pages 263-277.",
                "Springer, 2002. [6] A. Guerra-Hern´andez, A. ElFallah-Seghrouchni, and H. Soldano.",
                "Learning in BDI multi-agent systems.",
                "In CLIMA IV, volume 3259, pages 218-233.",
                "Springer Verlag, 2004. [7] M. Henniche.",
                "Mgi: an incremental bottom-up algorithm.",
                "In IEEE Aust. and New Zealand Conference on Intelligent Information Systems, pages 347-351, 1994. [8] T.-S. Lim, W.-Y.",
                "Loh, and Y.-S. Shih.",
                "A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms.",
                "Machine Learning, 40(3):203-228, 2000. [9] M. A. Maloof and R. S. Michalski.",
                "<br>incremental learning</br> with partial instance memory.",
                "Artif.",
                "Intell., 154(1-2):95-126, 2004. [10] P. J. Modi and W.-M. Shen.",
                "Collaborative multiagent learning for classification tasks.",
                "In AGENTS 01, pages 37-38.",
                "ACM Press, 2001. [11] S. Onta˜non and E. Plaza.",
                "Recycling data for multi-agent learning.",
                "In ICML 05, pages 633-640.",
                "ACM Press, 2005. [12] J. R. Quinlan.",
                "Induction of decision trees.",
                "Machine Learning, 1(1):81-106, 1986. [13] U. R¨uckert and S. Kramer.",
                "Towards tight bounds for rule learning.",
                "In ICML 04 (International conference on Machine learning), page 90, New York, NY, USA, 2004.",
                "ACM Press. [14] J. Wang and L. Gasser.",
                "Mutual online concept learning for multiple agents.",
                "In AAMAS, pages 362-369.",
                "ACM Press, 2002. [15] G. Weiß and S. Sen, editors.",
                "Adaption and Learning in Multi-Agent Systems, volume 1042 of Lecture Notes in Computer Science.",
                "Springer, 1996. [16] I. H. Witten and E. Frank.",
                "Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.",
                "Morgan Kaufmann, October 1999.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 171"
            ],
            "original_annotated_samples": [
                "SMILE: Sound Multi-agent <br>incremental learning</br> ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av.",
                "The resulting method SMILE (standing for Sound Multiagent <br>incremental learning</br>) is described and experimented here.",
                "FORMAL MODEL 2.1 Definitions and framework In this section, we present a general formulation of collective <br>incremental learning</br> in a cognitive multi agent system.",
                "M will also be viewed as an <br>incremental learning</br> mechanism and represented as an application changing Bi in Bi.",
                "A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 <br>incremental learning</br> process The learning process is an update mechanism that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis."
            ],
            "translated_annotated_samples": [
                "SMILE: Aprendizaje Incremental Multiagente de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av.",
                "El método resultante SMILE (que significa Sound Multiagent Incremental LEarning) se describe y experimenta aquí.",
                "MODELO FORMAL 2.1 Definiciones y marco En esta sección, presentamos una formulación general del <br>aprendizaje incremental</br> colectivo en un sistema cognitivo de múltiples agentes.",
                "M también será visto como un mecanismo de <br>aprendizaje incremental</br> y representado como una aplicación que cambia Bi en Bi.",
                "Un ejemplo positivo de f, como {no − a, b, no − c}, representa un modelo para f. 3.2 Proceso de aprendizaje incremental El proceso de aprendizaje es un mecanismo de actualización que, dado una hipótesis actual H, una memoria E = E+ ∪ E− llenada con los ejemplos recibidos previamente, y un nuevo ejemplo positivo o negativo e, produce una nueva hipótesis actualizada."
            ],
            "translated_text": "SMILE: Aprendizaje Incremental Multiagente de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av. del presidente Kennedy, 75116 París Henry Soldano LIPN, UMR 7030 CNRS, Universidad Paris-Norte, 99 Av. J-B Clement, 93430, Villetaneuse RESUMEN Este artículo trata sobre el problema del aprendizaje colaborativo en un sistema multiagente. Aquí cada agente puede actualizar de forma incremental sus creencias B (la representación del concepto) para que se mantenga consistente con el conjunto completo de información K (los ejemplos) que ha recibido del entorno u otros agentes. Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo lograr que, en cualquier momento, una misma representación conceptual consistente esté presente en cada agente. El protocolo correspondiente se aplica al aprendizaje supervisado de conceptos. El método resultante SMILE (que significa Sound Multiagent Incremental LEarning) se describe y experimenta aquí. Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de múltiples agentes que por un solo agente. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de conceptos; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistema multiagente Términos Generales Experimentación, Algoritmos, Medición, Rendimiento 1. INTRODUCCIÓN Este artículo trata sobre el problema del aprendizaje colaborativo de conceptos en un sistema multiagente. [6] introduce una caracterización del aprendizaje en un sistema multiagente según el nivel de conciencia de los agentes. En el nivel 1, los agentes aprenden ∗El autor principal de este artículo es un estudiante. en el sistema sin tener en cuenta la presencia de otros agentes, excepto a través de la modificación que traen al entorno con sus acciones. El nivel 2 implica una interacción directa entre los agentes, ya que pueden intercambiar mensajes para mejorar su aprendizaje. El nivel 3 requeriría que los agentes tengan en cuenta las competencias de otros agentes y sean capaces de aprender observando el comportamiento de los otros agentes (considerándolos como entidades independientes y no como parte indeterminada del entorno como en el nivel 1). En este artículo nos enfocamos en el nivel 2, estudiando la interacción directa entre los agentes involucrados en un proceso de aprendizaje. Cada agente se asume capaz de aprender de forma incremental a partir de los datos que recibe, lo que significa que cada agente puede actualizar su conjunto de creencias B para mantenerlo consistente con el conjunto completo de información K que ha recibido del entorno o de otros agentes. En tal caso, diremos que es a-inconsistente. Aquí, el conjunto de creencias B representa conocimiento hipotético que por lo tanto puede ser revisado, mientras que el conjunto de información K representa conocimiento cierto, compuesto por observaciones y hechos no revisables. Además, suponemos que al menos una parte Bc de las creencias de cada agente es común a todos los agentes y debe mantenerse de esa manera. Por lo tanto, una actualización de este conjunto común Bc por parte del agente r debe provocar una actualización de Bc para toda la comunidad de agentes. Nos lleva a definir cuál es la mas-consistencia de un agente con respecto a la comunidad. El proceso de actualización de las creencias de la comunidad cuando uno de sus miembros recibe nueva información puede entonces definirse como el proceso de mantenimiento de la consistencia que garantiza que cada agente en la comunidad permanecerá más consistente. Este proceso de mantenimiento de la mas-consistencia de un agente al recibir nueva información le otorga el rol de aprendiz e implica la comunicación con otros agentes que actúan como críticos. Sin embargo, los agentes no están especializados y a su vez pueden ser aprendices o críticos, ninguno de ellos está limitado a un rol específico. Las piezas de información se distribuyen entre los agentes, pero pueden ser redundantes. No hay memoria central. El trabajo descrito aquí tiene su origen en un trabajo anterior sobre el aprendizaje en un sistema multiagente intencional utilizando un formalismo BDI [6]. En ese trabajo, los agentes tenían planes, cada uno de ellos asociado con un contexto que define en qué condiciones puede ser activado. Los planes (cada uno con su propio contexto) eran comunes a todo el conjunto de agentes en la comunidad. Los agentes tuvieron que adaptar su plan en función del contexto, dependiendo del fracaso o éxito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo a otros agentes ejemplos (éxitos o fracasos de planes). Sin embargo, este trabajo carecía de un protocolo de aprendizaje colectivo que permitiera una verdadera autonomía del sistema multiagente. El estudio de dicho protocolo es el objeto del presente artículo. En la sección 2 definimos formalmente la mas-consistencia de un mecanismo de actualización para todo el MAS y proponemos un mecanismo de actualización genérico demostrado que es mas consistente. En la sección 3 describimos SMILE, un aprendiz de conceptos multiagente incremental que aplica nuestro mecanismo de actualización mas consistente para el aprendizaje colaborativo de conceptos. La sección 4 describe varios experimentos sobre SMILE y discute varios problemas, incluyendo cómo varían la precisión y la simplicidad de la hipótesis actual al comparar el aprendizaje de un solo agente y el aprendizaje de múltiples agentes. En la sección 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la sección 6 discutiendo investigaciones adicionales sobre el aprendizaje más consistente. MODELO FORMAL 2.1 Definiciones y marco En esta sección, presentamos una formulación general del <br>aprendizaje incremental</br> colectivo en un sistema cognitivo de múltiples agentes. Representamos un MAS como un conjunto de agentes r1, ..., rn. Cada agente ri tiene un conjunto de creencias Bi que consiste en todo el conocimiento revisable que posee. Parte de estos conocimientos deben ser compartidos con otros agentes. La parte de Bi que es común a todos los agentes se denota como BC. Esta parte común provoca una dependencia entre los agentes. Si un agente ri actualiza su conjunto de creencias Bi a Bi, cambiando en el proceso BC en BC, entonces todos los demás agentes rk deben actualizar su conjunto de creencias Bk a Bk para que BC ⊆ Bk. Además, cada agente ri ha almacenado cierta información Ki. Suponemos que alguna propiedad de consistencia Cons(Bi, Ki) puede ser verificada por el agente mismo entre sus creencias Bi y su información Ki. Como se dijo antes, Bi representa el conocimiento que podría ser revisado, mientras que Ki representa hechos observados, considerados verdaderos, y que posiblemente puedan contradecir a Bi. Definición 1. a-consistencia de un agente Un agente ri es a-consistente si Cons(Bi, Ki) es verdadero. Ejemplo 1. El agente r1 tiene un conjunto de planes que se encuentran en la parte común BC de B1. Cada plan P tiene un contexto desencadenante d(P) (que actúa como una precondición) y un cuerpo. Alguna pieza de información k podría ser el plan P, desencadenado en la situación s, ha fallado a pesar de que s es una instancia de d(P). Si esta pieza de información se agrega a K1, entonces el agente r1 ya no es a-consistente: Cons(B1, K1 ∪ k) es falso. También queremos definir alguna noción de consistencia para todo el MAS dependiendo de los conjuntos de creencias e información de sus elementos constituyentes. Primero definiremos la consistencia de un agente ri con respecto a su conjunto de creencias Bi y su propio conjunto de información Ki junto con todos los conjuntos de información K1...Kn de los otros agentes del MAS. Simplemente lo haremos considerando cuál sería la a-consistencia del agente si tuviera la información de todos los demás agentes. Llamamos a esta noción la mas-consistencia: Definición 2. Un agente ri es mas-consistente si Cons(Bi, Ki ∪ K) es verdadero, donde K = ∪j∈{1,..,n}−{i}Kj 1 es el conjunto de toda la información de los otros agentes del MAS. 1 Lo notaremos como ∪ Kj cuando el contexto sea similar. Ejemplo 2. Usando el ejemplo anterior, supongamos que la pieza de información k está incluida en la información K2 del agente r2. Si la pieza de información no se transmite a r1, y por lo tanto no se agrega a K1, r1 permanece a-consistente. Sin embargo, r1 no es tan consistente como k en el conjunto K de toda la información del MAS. La consistencia global del MAS es simplemente la mas-consistencia de todos sus agentes. Definición 3. La consistencia de un MAS A MAS r1,...,rn es consistente si todos sus agentes ri son masconsistentes. Ahora definimos las propiedades requeridas para un mecanismo de revisión M que actualiza a un agente ri cuando recibe una pieza de información k. En lo siguiente, supondremos que: • La actualización siempre es posible, es decir, un agente siempre puede modificar su conjunto de creencias Bi para recuperar su a-consistencia. Diremos que cada agente es localmente eficiente. • Considerando dos conjuntos de información Cons(Bi, K1) y Cons(Bi, K2), también tenemos Cons(Bi, K1 ∪ K2). Es decir, la a-consistencia de los agentes es aditiva. • Si una pieza de información k relacionada con el conjunto común BC es consistente con un agente, es consistente con todos los agentes: para todos los pares de agentes (ri, rj) tales que Cons(Bi, Ki) y Cons(Bj, Kj) son verdaderos, tenemos, para toda pieza de información k: Cons(Bi, Ki ∪ k) si y solo si Cons(Bj, Kj ∪ k). En tal caso, diremos que el MAS es coherente. Esta última condición simplemente significa que el conjunto de creencias común BC es independiente de las posibles diferencias entre los conjuntos de creencias Bi de cada agente ri. En el caso más simple, B1 = ... = Bn = BC. M también será visto como un mecanismo de <br>aprendizaje incremental</br> y representado como una aplicación que cambia Bi en Bi. En lo siguiente, anotaremos ri(Bi, Ki) para ri cuando sea útil. Definición 4. a-consistencia de una revisión Un mecanismo de actualización M es a-consistente si, para cualquier agente ri y cualquier pieza de información k que llegue a ri, la a-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki) a-consistente ⇒ ri(Bi, Ki) a-consistente, donde Bi = M(Bi) y Ki = Ki ∪ k es el conjunto de toda la información de otros agentes del MAS. De la misma manera, definimos la mas-consistencia de un mecanismo de revisión como la a-consistencia de este mecanismo si los agentes disponen de toda la información en el MAS. En lo siguiente, anotaremos, si es necesario, ri(Bi, Ki, K) para el agente ri en el MAS r1 . . . rn. Definición 5. mas-consistencia de una revisión Un mecanismo de actualización Ms es mas-consistente si para todo agente ri y toda pieza de información k que llega a ri, la mas-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki, K) más-consistente ⇒ ri(Bi, Ki, K) más-consistente, donde Bi = Ms(Bi), Ki = Ki ∪ k, y K = ∪Kj es el conjunto de toda la información del MAS. El Sexto Internacional. En última instancia, cuando un agente aplica un mecanismo mas-consistente al recibir una nueva pieza de información, un efecto secundario deseable del mecanismo debería ser que todos los demás agentes permanezcan mas-consistentes después de cualquier modificación de la parte común BC, es decir, el MAS en sí mismo debería volver a ser consistente. Esta propiedad se define de la siguiente manera: Definición 6. La fuerte mas-consistencia de un mecanismo de actualización. Un mecanismo de actualización Ms es fuertemente mas-consistente si - Ms es mas-consistente, y - la aplicación de Ms por un agente preserva la consistencia del MAS. 2.2 Un mecanismo de actualización fuertemente mas-consistente. La idea general es que, dado que la información está distribuida entre todos los agentes del MAS, debe haber alguna interacción entre el agente aprendiz y los demás agentes en un mecanismo de actualización fuertemente mas-consistente Ms. Para garantizar su mas-consistencia, Ms estará constituido por aplicaciones reiteradas por parte del agente aprendiz ri de un mecanismo interno a-consistente M, seguido por algunas interacciones entre ri y los otros agentes, hasta que ri recupere su mas-consistencia. Describimos a continuación un mecanismo, primero con una descripción de una interacción, luego una iteración y finalmente una declaración de la condición de terminación del mecanismo. El mecanismo es activado por un agente ri al recibir una pieza de información k que interrumpe la mas-consistencia. Tomaremos M(Bi) como el conjunto de creencias del agente aprendiz ri después de una actualización, BC la parte común modificada por ri, y Bj el conjunto de creencias de otro agente rj inducido por la modificación de su parte común BC en BC. Una interacción I(ri, rj) entre el agente aprendiz ri y otro agente rj, actuando como crítico, está constituida por los siguientes pasos: • el agente ri envía la actualización BC de la parte común de sus creencias. Habiendo aplicado su mecanismo de actualización, ri es a-consistente. • El agente rj verifica la modificación Bj de sus creencias inducida por la actualización BC. Si esta modificación conserva su a-consistencia, rj adopta esta modificación. El agente rj envía ya sea una aceptación de BC o una negación junto con una (o más) pieza(s) de información k tal que Cons(Bj, k) es falso. Una iteración de Ms estará compuesta por: • la recepción por parte del agente aprendiz ri de una pieza de información y la actualización M(Bi) restaurando su consistencia • un conjunto de interacciones I(ri, rj) (en las cuales varios agentes críticos posiblemente puedan participar). Si al menos una pieza de información k es transmitida a ri, la adición de k necesariamente hará que ri sea inconsistente y entonces ocurrirá una nueva iteración. Este mecanismo termina cuando ningún agente puede proporcionar tal pieza de información k. Cuando es el caso, se restaura la masconsistencia del agente aprendiz ri. Proposición 1. Dejen que r1,...,rn sea un MAS consistente en el que el agente ri recibe una pieza de información k que rompe su consistencia, y M sea un mecanismo interno de actualización a-consistente. El mecanismo de actualización descrito anteriormente por Ms es altamente mas-consistente. Prueba. La prueba se deriva directamente de la descripción del mecanismo. Este mecanismo asegura que cada vez que un agente recibe un evento, su mas-consistencia será restaurada. Como los otros agentes adoptan la actualización final BC, todos son mas-coherentes y el MAS es coherente. Por lo tanto, Ms es un mecanismo de actualización fuertemente consistente. En el mecanismo descrito anteriormente, el agente aprendiz es el único que recibe y memoriza información durante la ejecución del mecanismo. Se asegura de que Ms termine. Las piezas de información transmitidas por otros agentes y memorizadas por el agente aprendiz son redundantes, ya que ya están presentes en el MAS, más precisamente en la memoria de los agentes críticos que las transmitieron. Se debe tener en cuenta que el mecanismo propuesto por la Sra. aquí no indica explícitamente el orden ni el alcance de las interacciones. Consideraremos en lo siguiente que la propuesta de modificación BC se envía secuencialmente a los diferentes agentes (mecanismo síncrono). Además, la respuesta de un agente crítico solo contendrá una pieza de información inconsistente con la modificación propuesta. Diremos que la respuesta del agente es mínima. Este mecanismo, siendo sincrónico con una respuesta mínima, minimiza la cantidad de información transmitida por los agentes. Ahora lo ilustraremos en el caso del aprendizaje de conceptos multiagente. 3. APRENDIZAJE INCREMENTAL DE MÚLTIPLES AGENTES 3.1 La tarea de aprendizaje Experimentamos el mecanismo propuesto anteriormente en el caso del aprendizaje conceptual MAS incremental. Aquí consideramos un lenguaje de hipótesis en el cual una hipótesis es una disyunción de términos. Cada término es una conjunción de átomos de un conjunto A. Un ejemplo está representado por una etiqueta + o − y una descripción 2 compuesta por un subconjunto de átomos e ⊆ A. Un término abarca un ejemplo si sus átomos constituyentes están incluidos en el ejemplo. Una hipótesis abarca un ejemplo si uno de sus términos lo abarca. Esta representación se utilizará a continuación para aprender fórmulas booleanas. Los literales negativos se representan aquí mediante átomos adicionales, como not − a. La fórmula booleana f = (a ∧ b) ∨ (b ∧ ¬c) se escribirá entonces como (a ∧ b) ∨ (b ∧ no − c). Un ejemplo positivo de f, como {no − a, b, no − c}, representa un modelo para f. 3.2 Proceso de aprendizaje incremental El proceso de aprendizaje es un mecanismo de actualización que, dado una hipótesis actual H, una memoria E = E+ ∪ E− llenada con los ejemplos recibidos previamente, y un nuevo ejemplo positivo o negativo e, produce una nueva hipótesis actualizada. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "agent": {
            "translated_key": "agente",
            "is_in_text": true,
            "original_annotated_sentences": [
                "SMILE: Sound Multi-<br>agent</br> Incremental LEarning ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av.",
                "du pr´esident Kennedy, 75116 Paris Henry Soldano LIPN, UMR 7030 CNRS, University Paris-Nord, 99 Av.",
                "J-B Clement, 93430, Villetaneuse ABSTRACT This article deals with the problem of collaborative learning in a multi-<br>agent</br> system.",
                "Here each <br>agent</br> can update incrementally its beliefs B (the concept representation) so that it is in a way kept consistent with the whole set of information K (the examples) that he has received from the environment or other agents.",
                "We extend this notion of consistency (or soundness) to the whole MAS and discuss how to obtain that, at any moment, a same consistent concept representation is present in each <br>agent</br>.",
                "The corresponding protocol is applied to supervised concept learning.",
                "The resulting method SMILE (standing for Sound Multiagent Incremental LEarning) is described and experimented here.",
                "Surprisingly some difficult boolean formulas are better learned, given the same learning set, by a Multi <br>agent</br> system than by a single <br>agent</br>.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Concept learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent system General Terms Experimentation, Algorithms, Measurement, Performance 1.",
                "INTRODUCTION This article deals with the problem of collaborative concept learning in a multi-<br>agent</br> system. [6] introduces a characterisation of learning in multi-<br>agent</br> system according to the level of awareness of the agents.",
                "At level 1, agents learn ∗The primary author of this paper is a student. in the system without taking into account the presence of other agents, except through the modification brought upon the environment by their action.",
                "Level 2 implies direct interaction between the agents as they can exchange messages to improve their learning.",
                "Level 3 would require agents to take into account the competencies of other agents, and be able to learn from observation of the other agents behaviour (while considering them as independant entities and not indetermined part of the environment as in level 1).",
                "We focus in this paper on level 2, studying direct interaction between agents involved in a learning process.",
                "Each <br>agent</br> is assumed to be able to learn incrementally from the data he receives, meaning that each <br>agent</br> can update his belief set B to keep it consistent with the whole set of information K that he has received from the environment or from other agents.",
                "In such a case, we will say that he is a-consistent.",
                "Here, the belief set B represents hypothetical knowledge that can therefore be revised, whereas the set of information K represents certain knowledge, consisting of non revisable observations and facts.",
                "Moreover, we suppose that at least a part Bc of the beliefs of each <br>agent</br> is common to all agents and must stay that way.",
                "Therefore, an update of this common set Bc by <br>agent</br> r must provoke an update of Bc for the whole community of agents.",
                "It leads us to define what is the mas-consistency of an <br>agent</br> with respect to the community.",
                "The update process of the community beliefs when one of its members gets new information can then be defined as the consistency maintenance process ensuring that every <br>agent</br> in the community will stay masconsistent.",
                "This mas-consistency maintenance process of an <br>agent</br> getting new information gives him the role of a learner and implies communication with other agents acting as critics.",
                "However, agents are not specialised and can in turn be learners or critics, none of them being kept to a specific role.",
                "Pieces of information are distributed among the agents, but can be redundant.",
                "There is no central memory.",
                "The work described here has its origin in a former work concerning learning in an intentional multi-<br>agent</br> system using a BDI formalism [6].",
                "In that work, agents had plans, each of them being associated with a context defining in which conditions it can be triggered.",
                "Plans (each of them having its own context) were common to the whole set of agents in the community.",
                "Agents had to adapt their plan contexts depending on the failure or success of executed plans, using a learning mechanism and asking other agents for examples (plans successes or failures).",
                "However this work lacked a collective learning protocol enabling a real autonomy of the multi-<br>agent</br> system.",
                "The study of such a protocol is the object of the present paper.",
                "In section 2 we formally define the mas-consistency of an update mechanism for the whole MAS and we propose a generic update mechanism proved to be mas consistent.",
                "In section 3 we describe SMILE, an incremental multi <br>agent</br> concept learner applying our mas consistent update mechanism to collaborative concept learning.",
                "Section 4 describes various experiments on SMILE and discusses various issues including how the accuracy and the simplicity of the current hypothesis vary when comparing single <br>agent</br> learning and mas learning.",
                "In section 5 we briefly present some related works and then conclude in section 6 by discussing further investigations on mas consistent learning. 2.",
                "FORMAL MODEL 2.1 Definitions and framework In this section, we present a general formulation of collective incremental learning in a cognitive multi <br>agent</br> system.",
                "We represent a MAS as a set of agents r1, ..., rn.",
                "Each <br>agent</br> ri has a belief set Bi consisting of all the revisable knowledge he has.",
                "Part of these knowledges must be shared with other agents.",
                "The part of Bi that is common to all agents is denoted as BC .",
                "This common part provokes a dependency between the agents.",
                "If an <br>agent</br> ri updates his belief set Bi to Bi, changing in the process BC into BC , all other agents rk must then update their belief set Bk to Bk so that BC ⊆ Bk.",
                "Moreover, each <br>agent</br> ri has stored some certain information Ki.",
                "We suppose that some consistency property Cons(Bi, Ki) can be verified by the <br>agent</br> itself between its beliefs Bi and its information Ki.",
                "As said before, Bi represents knowledge that might be revised whereas Ki represents observed facts, taken as being true, and which can possibly contradict Bi.",
                "Definition 1. a-consistency of an <br>agent</br> An <br>agent</br> ri is a-consistent iff Cons(Bi, Ki) is true.",
                "Example 1.",
                "<br>agent</br> r1 has a set of plans which are in the common part BC of B1.",
                "Each plan P has a triggering context d(P) (which acts as a pre-condition) and a body.",
                "Some piece of information k could be plan P, triggered in situation s, has failed in spite of s being an instance of d(P).",
                "If this piece of information is added to K1, then <br>agent</br> r1 is not a-consistent anymore: Cons(B1, K1 ∪ k) is false.",
                "We also want to define some notion of consistency for the whole MAS depending on the belief and information sets of its constituting elements.",
                "We will first define the consistency of an <br>agent</br> ri with respect to its belief set Bi and its own information set Ki together with all information sets K1...Kn from the other agents of the MAS.",
                "We will simply do that by considering what would be the a-consistency of the <br>agent</br> if he has the information of all the other agents.",
                "We call this notion the mas-consistency: Definition 2. mas-consistency of an <br>agent</br> An <br>agent</br> ri is mas-consistent iff Cons(Bi, Ki ∪ K) is true, where K = ∪j∈{1,..,n}−{i}Kj 1 is the set of all information from other agents of the MAS. 1 We will note this ∪ Kj when the context is similar.",
                "Example 2.",
                "Using the previous example, suppose that the piece of information k is included in the information K2 of <br>agent</br> r2.",
                "As long as the piece of information is not transmitted to r1, and so added to K1 , r1 remains a-consistent.",
                "However, r1 is not mas-consistent as k is in the set K of all information of the MAS.",
                "The global consistency of the MAS is then simply the mas-consistency of all its agents.",
                "Definition 3.",
                "Consistency of a MAS A MAS r1,...,rn is consistent iff all its agents ri are masconsistent.",
                "We now define the required properties for a revision mechanism M updating an <br>agent</br> ri when it gets a piece of information k. In the following, we will suppose that: • Update is always possible, that is, an <br>agent</br> can always modify its belief set Bi in order to regain its a-consistency.",
                "We will say that each <br>agent</br> is locally efficient. • Considering two sets of information Cons(Bi, K1) and Cons(Bi, K2), we also have Cons(Bi, K1 ∪ K2).",
                "That is, a-consistency of the agents is additive. • If a piece of information k concerning the common set BC is consistent with an <br>agent</br>, it is consistent with all agents: for all pair of agents (ri,rj) such that Cons(Bi, Ki) and Cons(Bj, Kj) are true, we have, for all piece of information k: Cons(Bi, Ki ∪ k) iff Cons(Bj, Kj ∪ k).",
                "In such a case, we will say that the MAS is coherent.",
                "This last condition simply means that the common belief set BC is independent of the possible differences between the belief sets Bi of each <br>agent</br> ri.",
                "In the simplest case, B1 = ... = Bn = BC .",
                "M will also be viewed as an incremental learning mechanism and represented as an application changing Bi in Bi.",
                "In the following, we shall note ri(Bi, Ki) for ri when it is useful.",
                "Definition 4. a-consistency of a revision An update mechanism M is a-consistent iff for any <br>agent</br> ri and any piece of information k reaching ri, the a-consistency of this <br>agent</br> is preserved.",
                "In other words, iff: ri(Bi, Ki) a-consistent ⇒ ri(Bi, Ki) a-consistent, where Bi = M(Bi) and Ki = Ki ∪ k is the set of all information from other agents of the MAS.",
                "In the same way, we define the mas-consistency of a revision mechanism as the a-consistency of this mechanism should the agents dispose of all information in the MAS.",
                "In the following, we shall note, if needed, ri(Bi, Ki, K) for the <br>agent</br> ri in MAS r1 . . . rn.",
                "Definition 5. mas-consistency of a revision An update mechanism Ms is mas-consistent iff for all <br>agent</br> ri and all pieces of information k reaching ri, the masconsistency of this <br>agent</br> is preserved.",
                "In other words, if: ri(Bi, Ki, K) mas-consistent ⇒ ri(Bi, Ki, K) mas-consistent, where Bi = Ms(Bi), Ki = Ki ∪ k, and K = ∪Kj is the set of all information from the MAS.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) 165 At last, when a mas-consistent mechanism is applied by an <br>agent</br> getting a new piece of information, a desirable sideeffect of the mechanism should be that all others agents remains mas-consistent after any modification of the common part BC , that is, the MAS itself should become consistent again.",
                "This property is defined as follows: Definition 6.",
                "Strong mas-consistency of a revision An update mechanism Ms is strongly mas-consistent iff - Ms is mas-consistent, and - the application of Ms by an <br>agent</br> preserves the consistency of the MAS. 2.2 A strongly mas-consistent update mechanism The general idea is that, since information is distributed among all the agents of the MAS, there must be some interaction between the learner <br>agent</br> and the other agents in a strongly mas-consistent update mechanism Ms.",
                "In order to ensure its mas-consistency, Ms will be constituted of reiterated applications by the learner <br>agent</br> ri of an internal a-consistent mechanism M, followed by some interactions between ri and the other agents, until ri regain its masconsistency.",
                "We describe below such a mechanism, first with a description of an interaction, then an iteration, and finally a statement of the termination condition of the mechanism.",
                "The mechanism is triggered by an <br>agent</br> ri upon receipt of a piece of information k disrupting the mas-consistency.",
                "We shall note M(Bi) the belief set of the learner <br>agent</br> ri after an update, BC the common part modified by ri, and Bj the belief set of another <br>agent</br> rj induced by the modification of its common part BC in BC .",
                "An interaction I(ri, rj) between the learner <br>agent</br> ri and another <br>agent</br> rj, acting as critic is constituted of the following steps: • agent ri sends the update BC of the common part of its beliefs.",
                "Having applied its update mechanism, ri is a-consistent. • <br>agent</br> rj checks the modification Bj of its beliefs induced by the update BC .",
                "If this modification preserve its a-consistency, rj adopts this modification. • <br>agent</br> rj sends either an acceptation of BC or a denial along with one (or more) piece(s) of information k such that Cons(Bj, k ) is false.",
                "An iteration of Ms will then be composed of: • the reception by the learner <br>agent</br> ri of a piece of information and the update M(Bi) restoring its aconsistency • a set of interactions I(ri, rj) (in which several critic agents can possibly participate).",
                "If at least one piece of information k is transmitted to ri, the addition of k will necessarily make ri a-inconsistent and a new iteration will then occur.",
                "This mechanism Ms ends when no <br>agent</br> can provide such a piece of information k .",
                "When it is the case, the masconsistency of the learner <br>agent</br> ri is restored.",
                "Proposition 1.",
                "Let r1,...,rn be a consistent MAS in which <br>agent</br> ri receives a piece of information k breaking its aconsistency, and M an a-consistent internal update mechanism.",
                "The update mechanism Ms described above is strongly mas-consistent.",
                "Proof.",
                "The proof directly derives from the mechanism description.",
                "This mechanism ensures that each time an <br>agent</br> receives an event, its mas-consistency will be restored.",
                "As the other agents all adopt the final update BC , they are all mas-consistent, and the MAS is consistent.",
                "Therefore Ms is a strongly consistent update mechanism.",
                "In the mechanism Ms described above, the learner <br>agent</br> is the only one that receives and memorizes information during the mechanism execution.",
                "It ensures that Ms terminates.",
                "The pieces of information transmitted by other agents and memorized by the learner <br>agent</br> are redundant as they are already present in the MAS, more precisely in the memory of the critic agents that transmitted them.",
                "Note that the mechanism Ms proposed here does not explicitly indicate the order nor the scope of the interactions.",
                "We will consider in the following that the modification proposal BC is sent sequentially to the different agents (synchronous mechanism).",
                "Moreover, the response of a critic <br>agent</br> will only contain one piece of information inconsistent with the proposed modification.",
                "We will say that the response of the <br>agent</br> is minimal.",
                "This mechanism Ms, being synchronous with minimal response, minimizes the amount of information transmitted by the agents.",
                "We will now illustrate it in the case of multi-<br>agent</br> concept learning. 3.",
                "SOUNDMULTI-AGENTINCREMENTAL LEARNING 3.1 The learning task We experiment the mechanism proposed above in the case of incremental MAS concept learning.",
                "We consider here a hypothesis language in which a hypothesis is a disjunction of terms.",
                "Each term is a conjunction of atoms from a set A.",
                "An example is represented by a tag + or − and a description 2 composed of a subset of atoms e ⊆ A.",
                "A term covers an example if its constituting atoms are included in the example.",
                "A hypothesis covers an example if one of its term covers it.",
                "This representation will be used below for learning boolean formulae.",
                "Negative literals are here represented by additional atoms, like not − a.",
                "The boolean formulae f =(a ∧ b) ∨ (b ∧ ¬c) will then be written (a ∧ b) ∨ (b ∧ not − c).",
                "A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 Incremental learning process The learning process is an update mechanism that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis.",
                "Before this update, the given hypothesis is complete, meaning that it covers all positive examples of E+ , and 2 When no confusion is possible, the word example will be used to refer to the pair (tag, description) as well as the description alone. 166 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) coherent, meaning that it does not cover any negative example of E− .",
                "After the update, the new hypothesis must be complete and coherent with the new memory state E ∪ {e}.",
                "We describe below our single <br>agent</br> update mechanism, inspired from a previous work on incremental learning[7].",
                "In the following, a hypothesis H for the target formula f is a list of terms h, each of them being a conjunction of atoms.",
                "H is coherent if all terms h are coherent, and H is complete if each element of E+ is covered by at least one term h of H. Each term is by construction the lgg (least general generalization) of a subset of positives instances {e1, ..., en}[5], that is the most specific term covering {e1, ..., en}.",
                "The lgg operator is defined by considering examples as terms, so we denote as lgg(e) the most specific term that covers e, and as lgg(h, e) the most specific term which is more general than h and that covers e. Restricting the term to lgg is the basis of a lot of Bottom-Up learning algorithms (for instance [5]).",
                "In the typology proposed by [9], our update mechanism is an incremental learner with full instance memory: learning is made by successive updates and all examples are stored.",
                "The update mechanism depends of the ongoing hypothesis H, the ongoing examples E+ and E− , and the new example e. There are three possible cases: • e is positive and H covers e, or e is negative and H does not cover e. No update is needed, H is already complete and coherent with E ∪ {e}. • e is positive and H does not cover e: e is denoted as a positive counterexample of H. Then we seek to generalize in turn the terms h of H. As soon as a correct generalization h = lgg(h, e) is found, h replaces h in H. If there is a term that is less general that h , it is discarded.",
                "If no generalization is correct (meaning here coherent), H ∪ lgg(e) replaces H. • e is negative and H covers e: e is denoted as a negative counterexample of H. Each term h covering e is then discarded from H and replaced by a set of terms {h1, ...., hn} that is, as a whole, coherent with E− ∪ {e} and that covers the examples of E+ uncovered by H − {h}.",
                "Terms of the final hypothesis H that are less general than others are discarded from H. We will now describe the case where e = e− is a covered negative example.",
                "The following functions are used here: • coveredOnlyBy(h, E+) gives the subset of E+ covered by h and no other term of H. • bestCover(h1, h2) gives h1 if h1 covers more examples from uncoveredPos than h2, otherwise it gives h2. • covered(h) gives the elements of uncoveredPos covered by h. // Specialization of each h covering e− for each h of H covering e− do H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= atoms that are neither in e− nor in h while (uncoveredPos = ∅) do // seeking the best specialization of h hc=h best=⊥ // ⊥ covers no example for each a of Ar do hc= h ∧ a best = bestCover(hc, best) endfor Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) endwhile endfor Terms of H that are less general than others are discarded.",
                "Note that this mechanism tends to both make a minimal update of the current hypothesis and minimize the number of terms in the hypothesis, in particular by discarding terms less general than other ones after updating a hypothesis. 3.3 Collective learning If H is the current hypothesis, Ei the current example memory of <br>agent</br> ri and E the set of all the examples received by the system, the notation of section 2 becomes Bi = BC = H, Ki = Ei and K = E. Cons(H, Ei) states that H is complete and coherent with Ei.",
                "In such a case, ri is a-consistent.",
                "The piece of information k received by <br>agent</br> ri is here simply an example e along with its tag.",
                "If e is such that the current hypothesis H is not complete or coherent with Ei ∪ {e}, e contradicts H: ri becomes a-inconsistent, and therefore the MAS is not consistent anymore.",
                "The update of a hypothesis when a new example arrives is an a- consistent mechanism.",
                "Following proposition 1 this mechanism can be used to produce a strong mas-consistent mechanism: upon reception of a new example in the MAS by an <br>agent</br> r, an update is possibly needed and, after a set of interactions between r and the other agents, results in a new hypothesis shared by all the agents and that restores the consistency of the MAS, that is which is complete and coherent with the set ES of all the examples present in the MAS.",
                "It is clear that by minimizing the number of hypothesis modifications, this synchronous and minimal mechanism minimize the number of examples received by the learner from other agents, and therefore, the total number of examples stored in the system. 4.",
                "EXPERIMENTS In the following, we will learn a boolean formula that is a difficult test for the learning method: the 11-multiplexer (see [4]).",
                "It concerns 3 address boolean attributes a0, a1, a2 and 8 data boolean attributes d0, ..., d7.",
                "Formulae f11 is satisfied if the number coded by the 3 address attributes is the number of a data attribute whose value is 1.",
                "Its formula is the following: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0).",
                "There are 2048 = 211 possible examples, half of whom are positive (meaning they satisfy f11) while the other half is negative.",
                "An experiment is typically composed of 50 trials.",
                "Each run corresponds to a sequence of 600 examples that are incrementally learned by a Multi <br>agent</br> System with n agents The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) 167 (n-MAS).",
                "A number of variables such as accuracy, (i.e. the frequency of correct classification of a set of unseen examples), hypothesis size (i.e. the number of terms in the current formula) or number of stored examples, is recorded each time 25 examples are received by the system during those runs.",
                "In the protocol that is used here, a new example is sent to a random <br>agent</br> when the MAS is consistent.",
                "The next example will be sent in turn to an other <br>agent</br> when the MAS consistency will have been restored.",
                "In such a way we simulate a kind of slow learning: the frequency of example arrivals is slow compared to the time taken by an update. 4.1 Efficiency of MAS concept learning 4.1.1 Execution time We briefly discuss here execution time of learning in the MAS.",
                "Note that the whole set of action and interaction in the MAS is simulated on a single processor.",
                "Figure 1 shows that time linearly depends on the number of agents.",
                "At the end of the most active part of learning (200 examples), a 16MAS has taken 4 times more learning time than a 4-MAS.",
                "This execution time represents the whole set of learning and Figure 1: Execution time of a n-MAS (from n = 2 at the bottom to n = 20 on the top). communication activity and hints at the cost of maintaining a consistent learning hypothesis in a MAS composed of autonomous agents. 4.1.2 Redundancy in the MAS memory We study now the distribution of the examples in the MAS memory.",
                "Redundancy is written RS = nS/ne, where nS is the total number of examples stored in the MAS, that is the sum of the sizes of agents examples memories Ei, and ne is the total number of examples received from the environment in the MAS.",
                "In figure 2, we compare redundancies in 2 to 20 agents MAS.",
                "There is a peak, slowly moving from 80 to 100 examples, that represents the number of examples for which the learning is most active.",
                "For 20 agents, maximal redundancy is no more than 6, which is far less than the maximal theoretical value of 20.",
                "Note that when learning becomes less active, redundancy tends towards its minimal value 1: when there is no more updates, examples are only Figure 2: Redundancy of examples stored in a nMAS (from n = 2 at the bottom to n = 20 on the top) . stored by the <br>agent</br> that receives them. 4.1.3 A n-MAS selects a simpler solution than a single <br>agent</br> The proposed mechanism tends to minimize the number of terms in the selected hypothesis.",
                "During learning, the size of the current hypothesis grows up beyond the optimum, and then decreases when the MAS converges.",
                "In the Multiplexer 11 testbed, the optimal number of terms is 8, but there also exist equivalent formulas with more terms.",
                "It is interesting to note that in this case the 10-MAS converges towards an exact solution closer to the optimal number of terms (here 8) (see Figure 3).",
                "After 1450 examples have been presented both 1-MAS and 10-MAS have exactly learned the concept (the respective accuracies are 0.9999 and 1) but the single <br>agent</br> expresses in average the result as a 11.0 terms DNF whereas the 10-MAS expresses it as a 8.8 terms DNF.",
                "However for some other boolean functions we found that during learning 1-MAS always produces larger hypotheses than 10-MAS but that both MAS converge to hypotheses with similar size results. 4.1.4 A n-MAS is more accurate than a single <br>agent</br> Figure 4 shows the improvement brought by a MAS with n agents compared to a single <br>agent</br>.",
                "This improvement was not especially expected, because whether we have one or n agents, when N examples are given to the MAS it has access to the same amount of information, maintains only on ongoing hypothesis and uses the same basic revision algorithm whenever an <br>agent</br> has to modify the current hypothesis.",
                "Note that if the accuracy of 1, 2, 4 and 10-MAS are significantly different, getting better as the number of agents increases, there is no clear difference beyond this point: the accuracy curve of the 100 agents MAS is very close to the one of the 10 agents MAS. 4.1.4.1 Boolean formulas.",
                "To evaluate this accuracy improvement, we have experimented our protocol on other problems of boolean function learning, As in the Multiplexer-11 case, these functions 168 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) Figure 3: Size of the hypothesis built by 1 and 10MAS: the M11 case.",
                "Figure 4: Accuracy of a n-MAS: the M11 case (from bottom to top, n = 1, 2, 4, 10, 100). are learnt in the form of more or less syntactically complex DNF3 (that is with more or less conjunctive terms in the DNF), but are also more or less difficult to learn as it can be difficult to get its way in the hypothesis space to reach them.",
                "Furthermore, the presence in the description of irrelevant attributes (that is attributes that does not belong to the target DNF) makes the problem more difficult.",
                "The following problems have been selected to experiment our protocol: (i) the multiplexer-11 with 9 irrelevant attributes: M11 9, (ii) the 20-multiplexer M20 (with 4 address bits and 16 data bits), (iii) a difficult parity problem (see [4]) the Xorp m: there must be an odd number of bits with value 1 in the p first attributes for the instance to be positive, the p others bits being irrelevant, and (iv) a simple DNF formula (a ∧ b ∧ c) ∨ (c ∧ d ∧ e)(e ∧ f ∧ g) ∧ (g ∧ h ∧ i) with 19 irrelevant attributes.",
                "The following table sums up some information about these problems, giving the total number of attributes including irrelevant ones, the number of irrelevant 3 Disjunctive Normal Forms attributes, the minimal number of terms of the corresponding DNF, and the number of learning examples used.",
                "Pb att. irre. att. terms ex.",
                "M11 11 0 8 200 M11 9 20 9 8 200 M20 20 0 16 450 Xor3 25 28 25 4 200 Xor5 5 10 5 16 180 Xor5 15 20 15 16 600 Simple4-9 19 28 19 4 200 Below are given the accuracy results of our learning mechanism with a single <br>agent</br> and a 10 agents MAS, along with the results of two standard algorithms implemented with the learning environment WEKA[16]: JRip (an implementation of RIPPER[2]) and Id3[12].",
                "For the experiments with JRip and Id3, we measured the mean accuracy on 50 trials, each time randomly separating examples in a learning set and a test set.",
                "JRip and Id3 parameters are default parameters, except that JRip is used without pruning.",
                "The following table shows the results: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 It is clear that difficult problems are better solved with more agents (see for instance xor5 15).",
                "We think that these benefits, which can be important with an increasing number of agents, are due to the fact that each <br>agent</br> really memorizes only part of the total number of examples, and this part is partly selected by other agents as counter examples, which cause a greater number of current hypothesis updates and therefore, a better exploration of the hypotheses space. 4.1.4.2 ML database problems.",
                "We did also experiments with some non boolean problems.",
                "We considered only two classes (positive/negative) problems, taken from the UCIs learning problems database[3].",
                "In all these problems, examples are described as a vector of couples (attribute, value).",
                "The value domains can be either boolean, numeric (wholly ordered set), or nominal (non-ordered set).",
                "An adequate set of atoms A must be constituted for each problem.",
                "For instance, if a is a numeric attribute, we define at most k threshold si, giving k+1 intervals of uniform density4 .",
                "Therefore, each distinct threshold si gives two atoms a ≤ si and a > si.",
                "In our experiments, we took a maximal number of threshold k = 8.",
                "For instance, in the iono problem case, there were 34 numeric attributes, and an instance is described with 506 atoms.",
                "Below are given the accuracy results of our system along with previous results.",
                "The column Nb ex. refer to the 4 The probability for the value of a to be in any interval is constant The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) 169 number of examples used for learning5 .",
                "Column (1) represents minimal and maximal accuracy values for the thirty three classifiers tested in [8].",
                "Column (2) represents the results of [13], where various learning methods are compared to ensemble learning methods using weighted classifiers sets.",
                "Column S-1 and S-10 gives the accuracy of SMILE with respectively 1 and 10 agents.",
                "Pb Nb ex. (1) (2) S-1 S-10 ttt 862/574 // 76.2-99.7 99.7 99.9 kr-vs-kp 2876/958 // 91.4-99.4 96.8 97.3 iono 315 // 88.0-91.8 87.2 88.1 bupa 310 57-72 58-69.3 62.5 63.3 breastw 614 91-97 94.3-97.3 94.7 94.7 vote 391 94-96 95.3-96 91.9 92.6 pima 691 // 71.5- 73.4 65.0 65.0 heart 243 66-86 77.1-84.1 69.5 70.7 This table shows that the incremental algorithm corresponding to the single <br>agent</br> case, gives honorable results relatively to non-incremental classical methods using larger and more complex hypotheses.",
                "In some cases, there is an accuracy improvement with a 10 agents MAS.",
                "However, with such benchmarks data, which are often noisy, the difficulty does not really come from the way in which the search space is explored, and therefore the improvement observed is not always significant.",
                "The same kind of phenomenon have been observed with methods dedicated to hard boolean problems [4]. 4.2 MAS synchronization Here we consider that n single agents learn without interactions and at a given time start interacting thus forming a MAS.",
                "The purpose is to observe how the agents take advantage of collaboration when they start from different states of beliefs and memories.",
                "We compare in this section a 1-MAS, a 10-MAS (ref) and a 10-MAS (100sync) whose agents did not communicate during the arrival of the first 100 examples (10 by agents).",
                "The three accuracy curves are shown in figure 5.",
                "By comparing the single <br>agent</br> curve and the synchronized 10-MAS, we can observe that after the beginning of the synchronization, that is at 125 examples, accuracies are identical.",
                "This was expected since as soon as an example e received by the MAS contradicts the current hypothesis of the <br>agent</br> ra receiving it, this <br>agent</br> makes an update and its new hypothesis is proposed to the others agents for criticism.",
                "Therefore, this first contradictory example brings the MAS to reach consistency relatively to the whole set of examples present in agents memories.",
                "A higher accuracy, corresponding to a 10-MAS is obtained later, from the 175th example.",
                "In other words, the benefit of a better exploration of the research space is obtained slightly later in the learning process.",
                "Note that this synchronization happens naturally in all situations where agents have, for some reason, a divergence between their hypothesis and the system memory.",
                "This includes the fusion of two MAS into a single one or the arrival of new agents in an existing MAS. 4.3 Experiments on asynchronous learning: the effect of a large data stream 5 For ttt and kr-vs-kp, our protocol did not use more than respectively 574 and 958 learning examples, so we put another number in the column.",
                "Figure 5: Accuracies of a 1-MAS, a 10-MAS, and a 10-MAS synchronized after 100 examples.",
                "In this experiment we relax our slow learning mode: the examples are sent at a given rate to the MAS.",
                "The resulting example stream is measured in ms−1 , and represents the number of examples sent to the MAS each ms.",
                "Whenever the stream is too large, the MAS cannot reach MAS consistency on reception of an example from the environment before a new example arrives.",
                "This means that the update process, started by <br>agent</br> r0 as he received an example, may be unfinished when a new example is received by r0 or another <br>agent</br> r1.",
                "As a result, a critic <br>agent</br> may have at instant t to send counterexamples of hypotheses sent by various agents.",
                "However as far as the agents, in our setting, memorizes all the examples they receive whenever the stream ends, the MAS necessarily reaches MAS consistency with respect to all the examples received so far.",
                "In our experiments, though its learning curve is slowed down during the intense learning phase (corresponding to low accuracy of the current hypotheses), the MAS still reaches a satisfying hypothesis later on as there are less and less counterexamples in the example stream.",
                "In Figure 6 we compare the accuracies of two 11-MAS respectively submitted to example streams of different rates when learning the M11 formula.",
                "The learning curve of the MAS receiving an example at a 1/33 ms−1 rate is almost not altered (see Figure 4) whereas the 1/16 ms−1 MAS is first severely slowed down before catching up with the first one. 5.",
                "RELATED WORKS Since 96 [15], various work have been performed on learning in MAS, but rather few on concept learning.",
                "In [11] the MAS performs a form of ensemble learning in which the agents are lazy learners (no explicit representation is maintained) and sell useless examples to other agents.",
                "In [10] each <br>agent</br> observes all the examples but only perceive a part of their representation.",
                "In mutual online concept learning [14] the agents converge to a unique hypothesis, but each <br>agent</br> produces examples from its own concept representation, thus resulting in a kind of synchronization rather than in pure concept learning. 170 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) Figure 6: Accuracies of two asynchronous 11-MAS (1/33ms−1 and 1/16ms−1 example rates) . 6.",
                "CONCLUSION We have presented here and experimented a protocol for MAS online concept learning.",
                "The main feature of this collaborative learning mechanism is that it maintains a consistency property: though during the learning process each <br>agent</br> only receives and stores, with some limited redundancy, part of the examples received by the MAS, at any moment the current hypothesis is consistent with the whole set of examples.",
                "The hypotheses of our experiments do not address the issues of distributed MAS such as faults (for instance messages could be lost or corrupted) or other failures in general (crash, byzantine faults, etc.).",
                "Nevertheless, our framework is open, i.e., the agents can leave the system or enter it while the consistency mechanism is preserved.",
                "For instance if we introduce a timeout mechanism, even when a critic <br>agent</br> crashes or omits to answer, the consistency with the other critics (within the remaining agents) is entailed.",
                "In [1], a similar approach has been applied to MAS abduction problems: the hypotheses to maintain, given an incomplete information, are then facts or statements.",
                "Further work concerns first coupling induction and abduction in order to perform collaborative concept learning when examples are only partially observed by each <br>agent</br>, and second, investigating partial memory learning: how learning is preserved whenever one <br>agent</br> or the whole MAS forgets some selected examples.",
                "Aknowledgments We are very grateful to Dominique Bouthinon for implementing late modifications in SMILE, so much easing our experiments.",
                "Part of this work has been performed during the first authors visit to the Atelier De BioInformatique of Paris VI university, France. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In DALT-2006, May 2006. [2] W. W. Cohen.",
                "Fast effective rule induction.",
                "In ICML, pages 115-123, 1995. [3] C. B. D.J.",
                "Newman, S. Hettich and C. Merz.",
                "UCI repository of machine learning databases, 1998. [4] S. Esmeir and S. Markovitch.",
                "Lookahead-based algorithms for anytime induction of decision trees.",
                "In ICMLO4, pages 257-264.",
                "Morgan Kaufmann, 2004. [5] J. F¨urnkranz.",
                "A pathology of bottom-up hill-climbing in inductive rule learning.",
                "In ALT, volume 2533 of LNCS, pages 263-277.",
                "Springer, 2002. [6] A. Guerra-Hern´andez, A. ElFallah-Seghrouchni, and H. Soldano.",
                "Learning in BDI multi-<br>agent</br> systems.",
                "In CLIMA IV, volume 3259, pages 218-233.",
                "Springer Verlag, 2004. [7] M. Henniche.",
                "Mgi: an incremental bottom-up algorithm.",
                "In IEEE Aust. and New Zealand Conference on Intelligent Information Systems, pages 347-351, 1994. [8] T.-S. Lim, W.-Y.",
                "Loh, and Y.-S. Shih.",
                "A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms.",
                "Machine Learning, 40(3):203-228, 2000. [9] M. A. Maloof and R. S. Michalski.",
                "Incremental learning with partial instance memory.",
                "Artif.",
                "Intell., 154(1-2):95-126, 2004. [10] P. J. Modi and W.-M. Shen.",
                "Collaborative multiagent learning for classification tasks.",
                "In AGENTS 01, pages 37-38.",
                "ACM Press, 2001. [11] S. Onta˜non and E. Plaza.",
                "Recycling data for multi-<br>agent</br> learning.",
                "In ICML 05, pages 633-640.",
                "ACM Press, 2005. [12] J. R. Quinlan.",
                "Induction of decision trees.",
                "Machine Learning, 1(1):81-106, 1986. [13] U. R¨uckert and S. Kramer.",
                "Towards tight bounds for rule learning.",
                "In ICML 04 (International conference on Machine learning), page 90, New York, NY, USA, 2004.",
                "ACM Press. [14] J. Wang and L. Gasser.",
                "Mutual online concept learning for multiple agents.",
                "In AAMAS, pages 362-369.",
                "ACM Press, 2002. [15] G. Weiß and S. Sen, editors.",
                "Adaption and Learning in Multi-<br>agent</br> Systems, volume 1042 of Lecture Notes in Computer Science.",
                "Springer, 1996. [16] I. H. Witten and E. Frank.",
                "Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.",
                "Morgan Kaufmann, October 1999.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-<br>agent</br> Systems (AAMAS 07) 171"
            ],
            "original_annotated_samples": [
                "SMILE: Sound Multi-<br>agent</br> Incremental LEarning ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av.",
                "J-B Clement, 93430, Villetaneuse ABSTRACT This article deals with the problem of collaborative learning in a multi-<br>agent</br> system.",
                "Here each <br>agent</br> can update incrementally its beliefs B (the concept representation) so that it is in a way kept consistent with the whole set of information K (the examples) that he has received from the environment or other agents.",
                "We extend this notion of consistency (or soundness) to the whole MAS and discuss how to obtain that, at any moment, a same consistent concept representation is present in each <br>agent</br>.",
                "Surprisingly some difficult boolean formulas are better learned, given the same learning set, by a Multi <br>agent</br> system than by a single <br>agent</br>."
            ],
            "translated_annotated_samples": [
                "SMILE: Aprendizaje Incremental Multi<br>agente</br> de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av.",
                "J-B Clement, 93430, Villetaneuse RESUMEN Este artículo trata sobre el problema del aprendizaje colaborativo en un sistema multi<br>agente</br>.",
                "Aquí cada <br>agente</br> puede actualizar de forma incremental sus creencias B (la representación del concepto) para que se mantenga consistente con el conjunto completo de información K (los ejemplos) que ha recibido del entorno u otros <br>agente</br>s.",
                "Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo lograr que, en cualquier momento, una misma representación conceptual consistente esté presente en cada <br>agente</br>.",
                "Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de múltiples <br>agente</br>s que por un solo <br>agente</br>."
            ],
            "translated_text": "SMILE: Aprendizaje Incremental Multi<br>agente</br> de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av. del presidente Kennedy, 75116 París Henry Soldano LIPN, UMR 7030 CNRS, Universidad Paris-Norte, 99 Av. J-B Clement, 93430, Villetaneuse RESUMEN Este artículo trata sobre el problema del aprendizaje colaborativo en un sistema multi<br>agente</br>. Aquí cada <br>agente</br> puede actualizar de forma incremental sus creencias B (la representación del concepto) para que se mantenga consistente con el conjunto completo de información K (los ejemplos) que ha recibido del entorno u otros <br>agente</br>s. Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo lograr que, en cualquier momento, una misma representación conceptual consistente esté presente en cada <br>agente</br>. El protocolo correspondiente se aplica al aprendizaje supervisado de conceptos. El método resultante SMILE (que significa Sound Multiagent Incremental LEarning) se describe y experimenta aquí. Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de múltiples <br>agente</br>s que por un solo <br>agente</br>. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "update mechanism": {
            "translated_key": "mecanismo de actualización",
            "is_in_text": true,
            "original_annotated_sentences": [
                "SMILE: Sound Multi-agent Incremental LEarning ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av.",
                "du pr´esident Kennedy, 75116 Paris Henry Soldano LIPN, UMR 7030 CNRS, University Paris-Nord, 99 Av.",
                "J-B Clement, 93430, Villetaneuse ABSTRACT This article deals with the problem of collaborative learning in a multi-agent system.",
                "Here each agent can update incrementally its beliefs B (the concept representation) so that it is in a way kept consistent with the whole set of information K (the examples) that he has received from the environment or other agents.",
                "We extend this notion of consistency (or soundness) to the whole MAS and discuss how to obtain that, at any moment, a same consistent concept representation is present in each agent.",
                "The corresponding protocol is applied to supervised concept learning.",
                "The resulting method SMILE (standing for Sound Multiagent Incremental LEarning) is described and experimented here.",
                "Surprisingly some difficult boolean formulas are better learned, given the same learning set, by a Multi agent system than by a single agent.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Concept learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent system General Terms Experimentation, Algorithms, Measurement, Performance 1.",
                "INTRODUCTION This article deals with the problem of collaborative concept learning in a multi-agent system. [6] introduces a characterisation of learning in multi-agent system according to the level of awareness of the agents.",
                "At level 1, agents learn ∗The primary author of this paper is a student. in the system without taking into account the presence of other agents, except through the modification brought upon the environment by their action.",
                "Level 2 implies direct interaction between the agents as they can exchange messages to improve their learning.",
                "Level 3 would require agents to take into account the competencies of other agents, and be able to learn from observation of the other agents behaviour (while considering them as independant entities and not indetermined part of the environment as in level 1).",
                "We focus in this paper on level 2, studying direct interaction between agents involved in a learning process.",
                "Each agent is assumed to be able to learn incrementally from the data he receives, meaning that each agent can update his belief set B to keep it consistent with the whole set of information K that he has received from the environment or from other agents.",
                "In such a case, we will say that he is a-consistent.",
                "Here, the belief set B represents hypothetical knowledge that can therefore be revised, whereas the set of information K represents certain knowledge, consisting of non revisable observations and facts.",
                "Moreover, we suppose that at least a part Bc of the beliefs of each agent is common to all agents and must stay that way.",
                "Therefore, an update of this common set Bc by agent r must provoke an update of Bc for the whole community of agents.",
                "It leads us to define what is the mas-consistency of an agent with respect to the community.",
                "The update process of the community beliefs when one of its members gets new information can then be defined as the consistency maintenance process ensuring that every agent in the community will stay masconsistent.",
                "This mas-consistency maintenance process of an agent getting new information gives him the role of a learner and implies communication with other agents acting as critics.",
                "However, agents are not specialised and can in turn be learners or critics, none of them being kept to a specific role.",
                "Pieces of information are distributed among the agents, but can be redundant.",
                "There is no central memory.",
                "The work described here has its origin in a former work concerning learning in an intentional multi-agent system using a BDI formalism [6].",
                "In that work, agents had plans, each of them being associated with a context defining in which conditions it can be triggered.",
                "Plans (each of them having its own context) were common to the whole set of agents in the community.",
                "Agents had to adapt their plan contexts depending on the failure or success of executed plans, using a learning mechanism and asking other agents for examples (plans successes or failures).",
                "However this work lacked a collective learning protocol enabling a real autonomy of the multi-agent system.",
                "The study of such a protocol is the object of the present paper.",
                "In section 2 we formally define the mas-consistency of an <br>update mechanism</br> for the whole MAS and we propose a generic <br>update mechanism</br> proved to be mas consistent.",
                "In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent <br>update mechanism</br> to collaborative concept learning.",
                "Section 4 describes various experiments on SMILE and discusses various issues including how the accuracy and the simplicity of the current hypothesis vary when comparing single agent learning and mas learning.",
                "In section 5 we briefly present some related works and then conclude in section 6 by discussing further investigations on mas consistent learning. 2.",
                "FORMAL MODEL 2.1 Definitions and framework In this section, we present a general formulation of collective incremental learning in a cognitive multi agent system.",
                "We represent a MAS as a set of agents r1, ..., rn.",
                "Each agent ri has a belief set Bi consisting of all the revisable knowledge he has.",
                "Part of these knowledges must be shared with other agents.",
                "The part of Bi that is common to all agents is denoted as BC .",
                "This common part provokes a dependency between the agents.",
                "If an agent ri updates his belief set Bi to Bi, changing in the process BC into BC , all other agents rk must then update their belief set Bk to Bk so that BC ⊆ Bk.",
                "Moreover, each agent ri has stored some certain information Ki.",
                "We suppose that some consistency property Cons(Bi, Ki) can be verified by the agent itself between its beliefs Bi and its information Ki.",
                "As said before, Bi represents knowledge that might be revised whereas Ki represents observed facts, taken as being true, and which can possibly contradict Bi.",
                "Definition 1. a-consistency of an agent An agent ri is a-consistent iff Cons(Bi, Ki) is true.",
                "Example 1.",
                "Agent r1 has a set of plans which are in the common part BC of B1.",
                "Each plan P has a triggering context d(P) (which acts as a pre-condition) and a body.",
                "Some piece of information k could be plan P, triggered in situation s, has failed in spite of s being an instance of d(P).",
                "If this piece of information is added to K1, then agent r1 is not a-consistent anymore: Cons(B1, K1 ∪ k) is false.",
                "We also want to define some notion of consistency for the whole MAS depending on the belief and information sets of its constituting elements.",
                "We will first define the consistency of an agent ri with respect to its belief set Bi and its own information set Ki together with all information sets K1...Kn from the other agents of the MAS.",
                "We will simply do that by considering what would be the a-consistency of the agent if he has the information of all the other agents.",
                "We call this notion the mas-consistency: Definition 2. mas-consistency of an agent An agent ri is mas-consistent iff Cons(Bi, Ki ∪ K) is true, where K = ∪j∈{1,..,n}−{i}Kj 1 is the set of all information from other agents of the MAS. 1 We will note this ∪ Kj when the context is similar.",
                "Example 2.",
                "Using the previous example, suppose that the piece of information k is included in the information K2 of agent r2.",
                "As long as the piece of information is not transmitted to r1, and so added to K1 , r1 remains a-consistent.",
                "However, r1 is not mas-consistent as k is in the set K of all information of the MAS.",
                "The global consistency of the MAS is then simply the mas-consistency of all its agents.",
                "Definition 3.",
                "Consistency of a MAS A MAS r1,...,rn is consistent iff all its agents ri are masconsistent.",
                "We now define the required properties for a revision mechanism M updating an agent ri when it gets a piece of information k. In the following, we will suppose that: • Update is always possible, that is, an agent can always modify its belief set Bi in order to regain its a-consistency.",
                "We will say that each agent is locally efficient. • Considering two sets of information Cons(Bi, K1) and Cons(Bi, K2), we also have Cons(Bi, K1 ∪ K2).",
                "That is, a-consistency of the agents is additive. • If a piece of information k concerning the common set BC is consistent with an agent, it is consistent with all agents: for all pair of agents (ri,rj) such that Cons(Bi, Ki) and Cons(Bj, Kj) are true, we have, for all piece of information k: Cons(Bi, Ki ∪ k) iff Cons(Bj, Kj ∪ k).",
                "In such a case, we will say that the MAS is coherent.",
                "This last condition simply means that the common belief set BC is independent of the possible differences between the belief sets Bi of each agent ri.",
                "In the simplest case, B1 = ... = Bn = BC .",
                "M will also be viewed as an incremental learning mechanism and represented as an application changing Bi in Bi.",
                "In the following, we shall note ri(Bi, Ki) for ri when it is useful.",
                "Definition 4. a-consistency of a revision An <br>update mechanism</br> M is a-consistent iff for any agent ri and any piece of information k reaching ri, the a-consistency of this agent is preserved.",
                "In other words, iff: ri(Bi, Ki) a-consistent ⇒ ri(Bi, Ki) a-consistent, where Bi = M(Bi) and Ki = Ki ∪ k is the set of all information from other agents of the MAS.",
                "In the same way, we define the mas-consistency of a revision mechanism as the a-consistency of this mechanism should the agents dispose of all information in the MAS.",
                "In the following, we shall note, if needed, ri(Bi, Ki, K) for the agent ri in MAS r1 . . . rn.",
                "Definition 5. mas-consistency of a revision An <br>update mechanism</br> Ms is mas-consistent iff for all agent ri and all pieces of information k reaching ri, the masconsistency of this agent is preserved.",
                "In other words, if: ri(Bi, Ki, K) mas-consistent ⇒ ri(Bi, Ki, K) mas-consistent, where Bi = Ms(Bi), Ki = Ki ∪ k, and K = ∪Kj is the set of all information from the MAS.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 165 At last, when a mas-consistent mechanism is applied by an agent getting a new piece of information, a desirable sideeffect of the mechanism should be that all others agents remains mas-consistent after any modification of the common part BC , that is, the MAS itself should become consistent again.",
                "This property is defined as follows: Definition 6.",
                "Strong mas-consistency of a revision An <br>update mechanism</br> Ms is strongly mas-consistent iff - Ms is mas-consistent, and - the application of Ms by an agent preserves the consistency of the MAS. 2.2 A strongly mas-consistent <br>update mechanism</br> The general idea is that, since information is distributed among all the agents of the MAS, there must be some interaction between the learner agent and the other agents in a strongly mas-consistent update mechanism Ms.",
                "In order to ensure its mas-consistency, Ms will be constituted of reiterated applications by the learner agent ri of an internal a-consistent mechanism M, followed by some interactions between ri and the other agents, until ri regain its masconsistency.",
                "We describe below such a mechanism, first with a description of an interaction, then an iteration, and finally a statement of the termination condition of the mechanism.",
                "The mechanism is triggered by an agent ri upon receipt of a piece of information k disrupting the mas-consistency.",
                "We shall note M(Bi) the belief set of the learner agent ri after an update, BC the common part modified by ri, and Bj the belief set of another agent rj induced by the modification of its common part BC in BC .",
                "An interaction I(ri, rj) between the learner agent ri and another agent rj, acting as critic is constituted of the following steps: • agent ri sends the update BC of the common part of its beliefs.",
                "Having applied its <br>update mechanism</br>, ri is a-consistent. • agent rj checks the modification Bj of its beliefs induced by the update BC .",
                "If this modification preserve its a-consistency, rj adopts this modification. • agent rj sends either an acceptation of BC or a denial along with one (or more) piece(s) of information k such that Cons(Bj, k ) is false.",
                "An iteration of Ms will then be composed of: • the reception by the learner agent ri of a piece of information and the update M(Bi) restoring its aconsistency • a set of interactions I(ri, rj) (in which several critic agents can possibly participate).",
                "If at least one piece of information k is transmitted to ri, the addition of k will necessarily make ri a-inconsistent and a new iteration will then occur.",
                "This mechanism Ms ends when no agent can provide such a piece of information k .",
                "When it is the case, the masconsistency of the learner agent ri is restored.",
                "Proposition 1.",
                "Let r1,...,rn be a consistent MAS in which agent ri receives a piece of information k breaking its aconsistency, and M an a-consistent internal <br>update mechanism</br>.",
                "The <br>update mechanism</br> Ms described above is strongly mas-consistent.",
                "Proof.",
                "The proof directly derives from the mechanism description.",
                "This mechanism ensures that each time an agent receives an event, its mas-consistency will be restored.",
                "As the other agents all adopt the final update BC , they are all mas-consistent, and the MAS is consistent.",
                "Therefore Ms is a strongly consistent <br>update mechanism</br>.",
                "In the mechanism Ms described above, the learner agent is the only one that receives and memorizes information during the mechanism execution.",
                "It ensures that Ms terminates.",
                "The pieces of information transmitted by other agents and memorized by the learner agent are redundant as they are already present in the MAS, more precisely in the memory of the critic agents that transmitted them.",
                "Note that the mechanism Ms proposed here does not explicitly indicate the order nor the scope of the interactions.",
                "We will consider in the following that the modification proposal BC is sent sequentially to the different agents (synchronous mechanism).",
                "Moreover, the response of a critic agent will only contain one piece of information inconsistent with the proposed modification.",
                "We will say that the response of the agent is minimal.",
                "This mechanism Ms, being synchronous with minimal response, minimizes the amount of information transmitted by the agents.",
                "We will now illustrate it in the case of multi-agent concept learning. 3.",
                "SOUNDMULTI-AGENTINCREMENTAL LEARNING 3.1 The learning task We experiment the mechanism proposed above in the case of incremental MAS concept learning.",
                "We consider here a hypothesis language in which a hypothesis is a disjunction of terms.",
                "Each term is a conjunction of atoms from a set A.",
                "An example is represented by a tag + or − and a description 2 composed of a subset of atoms e ⊆ A.",
                "A term covers an example if its constituting atoms are included in the example.",
                "A hypothesis covers an example if one of its term covers it.",
                "This representation will be used below for learning boolean formulae.",
                "Negative literals are here represented by additional atoms, like not − a.",
                "The boolean formulae f =(a ∧ b) ∨ (b ∧ ¬c) will then be written (a ∧ b) ∨ (b ∧ not − c).",
                "A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 Incremental learning process The learning process is an <br>update mechanism</br> that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis.",
                "Before this update, the given hypothesis is complete, meaning that it covers all positive examples of E+ , and 2 When no confusion is possible, the word example will be used to refer to the pair (tag, description) as well as the description alone. 166 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) coherent, meaning that it does not cover any negative example of E− .",
                "After the update, the new hypothesis must be complete and coherent with the new memory state E ∪ {e}.",
                "We describe below our single agent <br>update mechanism</br>, inspired from a previous work on incremental learning[7].",
                "In the following, a hypothesis H for the target formula f is a list of terms h, each of them being a conjunction of atoms.",
                "H is coherent if all terms h are coherent, and H is complete if each element of E+ is covered by at least one term h of H. Each term is by construction the lgg (least general generalization) of a subset of positives instances {e1, ..., en}[5], that is the most specific term covering {e1, ..., en}.",
                "The lgg operator is defined by considering examples as terms, so we denote as lgg(e) the most specific term that covers e, and as lgg(h, e) the most specific term which is more general than h and that covers e. Restricting the term to lgg is the basis of a lot of Bottom-Up learning algorithms (for instance [5]).",
                "In the typology proposed by [9], our <br>update mechanism</br> is an incremental learner with full instance memory: learning is made by successive updates and all examples are stored.",
                "The <br>update mechanism</br> depends of the ongoing hypothesis H, the ongoing examples E+ and E− , and the new example e. There are three possible cases: • e is positive and H covers e, or e is negative and H does not cover e. No update is needed, H is already complete and coherent with E ∪ {e}. • e is positive and H does not cover e: e is denoted as a positive counterexample of H. Then we seek to generalize in turn the terms h of H. As soon as a correct generalization h = lgg(h, e) is found, h replaces h in H. If there is a term that is less general that h , it is discarded.",
                "If no generalization is correct (meaning here coherent), H ∪ lgg(e) replaces H. • e is negative and H covers e: e is denoted as a negative counterexample of H. Each term h covering e is then discarded from H and replaced by a set of terms {h1, ...., hn} that is, as a whole, coherent with E− ∪ {e} and that covers the examples of E+ uncovered by H − {h}.",
                "Terms of the final hypothesis H that are less general than others are discarded from H. We will now describe the case where e = e− is a covered negative example.",
                "The following functions are used here: • coveredOnlyBy(h, E+) gives the subset of E+ covered by h and no other term of H. • bestCover(h1, h2) gives h1 if h1 covers more examples from uncoveredPos than h2, otherwise it gives h2. • covered(h) gives the elements of uncoveredPos covered by h. // Specialization of each h covering e− for each h of H covering e− do H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= atoms that are neither in e− nor in h while (uncoveredPos = ∅) do // seeking the best specialization of h hc=h best=⊥ // ⊥ covers no example for each a of Ar do hc= h ∧ a best = bestCover(hc, best) endfor Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) endwhile endfor Terms of H that are less general than others are discarded.",
                "Note that this mechanism tends to both make a minimal update of the current hypothesis and minimize the number of terms in the hypothesis, in particular by discarding terms less general than other ones after updating a hypothesis. 3.3 Collective learning If H is the current hypothesis, Ei the current example memory of agent ri and E the set of all the examples received by the system, the notation of section 2 becomes Bi = BC = H, Ki = Ei and K = E. Cons(H, Ei) states that H is complete and coherent with Ei.",
                "In such a case, ri is a-consistent.",
                "The piece of information k received by agent ri is here simply an example e along with its tag.",
                "If e is such that the current hypothesis H is not complete or coherent with Ei ∪ {e}, e contradicts H: ri becomes a-inconsistent, and therefore the MAS is not consistent anymore.",
                "The update of a hypothesis when a new example arrives is an a- consistent mechanism.",
                "Following proposition 1 this mechanism can be used to produce a strong mas-consistent mechanism: upon reception of a new example in the MAS by an agent r, an update is possibly needed and, after a set of interactions between r and the other agents, results in a new hypothesis shared by all the agents and that restores the consistency of the MAS, that is which is complete and coherent with the set ES of all the examples present in the MAS.",
                "It is clear that by minimizing the number of hypothesis modifications, this synchronous and minimal mechanism minimize the number of examples received by the learner from other agents, and therefore, the total number of examples stored in the system. 4.",
                "EXPERIMENTS In the following, we will learn a boolean formula that is a difficult test for the learning method: the 11-multiplexer (see [4]).",
                "It concerns 3 address boolean attributes a0, a1, a2 and 8 data boolean attributes d0, ..., d7.",
                "Formulae f11 is satisfied if the number coded by the 3 address attributes is the number of a data attribute whose value is 1.",
                "Its formula is the following: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0).",
                "There are 2048 = 211 possible examples, half of whom are positive (meaning they satisfy f11) while the other half is negative.",
                "An experiment is typically composed of 50 trials.",
                "Each run corresponds to a sequence of 600 examples that are incrementally learned by a Multi Agent System with n agents The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 167 (n-MAS).",
                "A number of variables such as accuracy, (i.e. the frequency of correct classification of a set of unseen examples), hypothesis size (i.e. the number of terms in the current formula) or number of stored examples, is recorded each time 25 examples are received by the system during those runs.",
                "In the protocol that is used here, a new example is sent to a random agent when the MAS is consistent.",
                "The next example will be sent in turn to an other agent when the MAS consistency will have been restored.",
                "In such a way we simulate a kind of slow learning: the frequency of example arrivals is slow compared to the time taken by an update. 4.1 Efficiency of MAS concept learning 4.1.1 Execution time We briefly discuss here execution time of learning in the MAS.",
                "Note that the whole set of action and interaction in the MAS is simulated on a single processor.",
                "Figure 1 shows that time linearly depends on the number of agents.",
                "At the end of the most active part of learning (200 examples), a 16MAS has taken 4 times more learning time than a 4-MAS.",
                "This execution time represents the whole set of learning and Figure 1: Execution time of a n-MAS (from n = 2 at the bottom to n = 20 on the top). communication activity and hints at the cost of maintaining a consistent learning hypothesis in a MAS composed of autonomous agents. 4.1.2 Redundancy in the MAS memory We study now the distribution of the examples in the MAS memory.",
                "Redundancy is written RS = nS/ne, where nS is the total number of examples stored in the MAS, that is the sum of the sizes of agents examples memories Ei, and ne is the total number of examples received from the environment in the MAS.",
                "In figure 2, we compare redundancies in 2 to 20 agents MAS.",
                "There is a peak, slowly moving from 80 to 100 examples, that represents the number of examples for which the learning is most active.",
                "For 20 agents, maximal redundancy is no more than 6, which is far less than the maximal theoretical value of 20.",
                "Note that when learning becomes less active, redundancy tends towards its minimal value 1: when there is no more updates, examples are only Figure 2: Redundancy of examples stored in a nMAS (from n = 2 at the bottom to n = 20 on the top) . stored by the agent that receives them. 4.1.3 A n-MAS selects a simpler solution than a single agent The proposed mechanism tends to minimize the number of terms in the selected hypothesis.",
                "During learning, the size of the current hypothesis grows up beyond the optimum, and then decreases when the MAS converges.",
                "In the Multiplexer 11 testbed, the optimal number of terms is 8, but there also exist equivalent formulas with more terms.",
                "It is interesting to note that in this case the 10-MAS converges towards an exact solution closer to the optimal number of terms (here 8) (see Figure 3).",
                "After 1450 examples have been presented both 1-MAS and 10-MAS have exactly learned the concept (the respective accuracies are 0.9999 and 1) but the single agent expresses in average the result as a 11.0 terms DNF whereas the 10-MAS expresses it as a 8.8 terms DNF.",
                "However for some other boolean functions we found that during learning 1-MAS always produces larger hypotheses than 10-MAS but that both MAS converge to hypotheses with similar size results. 4.1.4 A n-MAS is more accurate than a single agent Figure 4 shows the improvement brought by a MAS with n agents compared to a single agent.",
                "This improvement was not especially expected, because whether we have one or n agents, when N examples are given to the MAS it has access to the same amount of information, maintains only on ongoing hypothesis and uses the same basic revision algorithm whenever an agent has to modify the current hypothesis.",
                "Note that if the accuracy of 1, 2, 4 and 10-MAS are significantly different, getting better as the number of agents increases, there is no clear difference beyond this point: the accuracy curve of the 100 agents MAS is very close to the one of the 10 agents MAS. 4.1.4.1 Boolean formulas.",
                "To evaluate this accuracy improvement, we have experimented our protocol on other problems of boolean function learning, As in the Multiplexer-11 case, these functions 168 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 3: Size of the hypothesis built by 1 and 10MAS: the M11 case.",
                "Figure 4: Accuracy of a n-MAS: the M11 case (from bottom to top, n = 1, 2, 4, 10, 100). are learnt in the form of more or less syntactically complex DNF3 (that is with more or less conjunctive terms in the DNF), but are also more or less difficult to learn as it can be difficult to get its way in the hypothesis space to reach them.",
                "Furthermore, the presence in the description of irrelevant attributes (that is attributes that does not belong to the target DNF) makes the problem more difficult.",
                "The following problems have been selected to experiment our protocol: (i) the multiplexer-11 with 9 irrelevant attributes: M11 9, (ii) the 20-multiplexer M20 (with 4 address bits and 16 data bits), (iii) a difficult parity problem (see [4]) the Xorp m: there must be an odd number of bits with value 1 in the p first attributes for the instance to be positive, the p others bits being irrelevant, and (iv) a simple DNF formula (a ∧ b ∧ c) ∨ (c ∧ d ∧ e)(e ∧ f ∧ g) ∧ (g ∧ h ∧ i) with 19 irrelevant attributes.",
                "The following table sums up some information about these problems, giving the total number of attributes including irrelevant ones, the number of irrelevant 3 Disjunctive Normal Forms attributes, the minimal number of terms of the corresponding DNF, and the number of learning examples used.",
                "Pb att. irre. att. terms ex.",
                "M11 11 0 8 200 M11 9 20 9 8 200 M20 20 0 16 450 Xor3 25 28 25 4 200 Xor5 5 10 5 16 180 Xor5 15 20 15 16 600 Simple4-9 19 28 19 4 200 Below are given the accuracy results of our learning mechanism with a single agent and a 10 agents MAS, along with the results of two standard algorithms implemented with the learning environment WEKA[16]: JRip (an implementation of RIPPER[2]) and Id3[12].",
                "For the experiments with JRip and Id3, we measured the mean accuracy on 50 trials, each time randomly separating examples in a learning set and a test set.",
                "JRip and Id3 parameters are default parameters, except that JRip is used without pruning.",
                "The following table shows the results: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 It is clear that difficult problems are better solved with more agents (see for instance xor5 15).",
                "We think that these benefits, which can be important with an increasing number of agents, are due to the fact that each agent really memorizes only part of the total number of examples, and this part is partly selected by other agents as counter examples, which cause a greater number of current hypothesis updates and therefore, a better exploration of the hypotheses space. 4.1.4.2 ML database problems.",
                "We did also experiments with some non boolean problems.",
                "We considered only two classes (positive/negative) problems, taken from the UCIs learning problems database[3].",
                "In all these problems, examples are described as a vector of couples (attribute, value).",
                "The value domains can be either boolean, numeric (wholly ordered set), or nominal (non-ordered set).",
                "An adequate set of atoms A must be constituted for each problem.",
                "For instance, if a is a numeric attribute, we define at most k threshold si, giving k+1 intervals of uniform density4 .",
                "Therefore, each distinct threshold si gives two atoms a ≤ si and a > si.",
                "In our experiments, we took a maximal number of threshold k = 8.",
                "For instance, in the iono problem case, there were 34 numeric attributes, and an instance is described with 506 atoms.",
                "Below are given the accuracy results of our system along with previous results.",
                "The column Nb ex. refer to the 4 The probability for the value of a to be in any interval is constant The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 169 number of examples used for learning5 .",
                "Column (1) represents minimal and maximal accuracy values for the thirty three classifiers tested in [8].",
                "Column (2) represents the results of [13], where various learning methods are compared to ensemble learning methods using weighted classifiers sets.",
                "Column S-1 and S-10 gives the accuracy of SMILE with respectively 1 and 10 agents.",
                "Pb Nb ex. (1) (2) S-1 S-10 ttt 862/574 // 76.2-99.7 99.7 99.9 kr-vs-kp 2876/958 // 91.4-99.4 96.8 97.3 iono 315 // 88.0-91.8 87.2 88.1 bupa 310 57-72 58-69.3 62.5 63.3 breastw 614 91-97 94.3-97.3 94.7 94.7 vote 391 94-96 95.3-96 91.9 92.6 pima 691 // 71.5- 73.4 65.0 65.0 heart 243 66-86 77.1-84.1 69.5 70.7 This table shows that the incremental algorithm corresponding to the single agent case, gives honorable results relatively to non-incremental classical methods using larger and more complex hypotheses.",
                "In some cases, there is an accuracy improvement with a 10 agents MAS.",
                "However, with such benchmarks data, which are often noisy, the difficulty does not really come from the way in which the search space is explored, and therefore the improvement observed is not always significant.",
                "The same kind of phenomenon have been observed with methods dedicated to hard boolean problems [4]. 4.2 MAS synchronization Here we consider that n single agents learn without interactions and at a given time start interacting thus forming a MAS.",
                "The purpose is to observe how the agents take advantage of collaboration when they start from different states of beliefs and memories.",
                "We compare in this section a 1-MAS, a 10-MAS (ref) and a 10-MAS (100sync) whose agents did not communicate during the arrival of the first 100 examples (10 by agents).",
                "The three accuracy curves are shown in figure 5.",
                "By comparing the single agent curve and the synchronized 10-MAS, we can observe that after the beginning of the synchronization, that is at 125 examples, accuracies are identical.",
                "This was expected since as soon as an example e received by the MAS contradicts the current hypothesis of the agent ra receiving it, this agent makes an update and its new hypothesis is proposed to the others agents for criticism.",
                "Therefore, this first contradictory example brings the MAS to reach consistency relatively to the whole set of examples present in agents memories.",
                "A higher accuracy, corresponding to a 10-MAS is obtained later, from the 175th example.",
                "In other words, the benefit of a better exploration of the research space is obtained slightly later in the learning process.",
                "Note that this synchronization happens naturally in all situations where agents have, for some reason, a divergence between their hypothesis and the system memory.",
                "This includes the fusion of two MAS into a single one or the arrival of new agents in an existing MAS. 4.3 Experiments on asynchronous learning: the effect of a large data stream 5 For ttt and kr-vs-kp, our protocol did not use more than respectively 574 and 958 learning examples, so we put another number in the column.",
                "Figure 5: Accuracies of a 1-MAS, a 10-MAS, and a 10-MAS synchronized after 100 examples.",
                "In this experiment we relax our slow learning mode: the examples are sent at a given rate to the MAS.",
                "The resulting example stream is measured in ms−1 , and represents the number of examples sent to the MAS each ms.",
                "Whenever the stream is too large, the MAS cannot reach MAS consistency on reception of an example from the environment before a new example arrives.",
                "This means that the update process, started by agent r0 as he received an example, may be unfinished when a new example is received by r0 or another agent r1.",
                "As a result, a critic agent may have at instant t to send counterexamples of hypotheses sent by various agents.",
                "However as far as the agents, in our setting, memorizes all the examples they receive whenever the stream ends, the MAS necessarily reaches MAS consistency with respect to all the examples received so far.",
                "In our experiments, though its learning curve is slowed down during the intense learning phase (corresponding to low accuracy of the current hypotheses), the MAS still reaches a satisfying hypothesis later on as there are less and less counterexamples in the example stream.",
                "In Figure 6 we compare the accuracies of two 11-MAS respectively submitted to example streams of different rates when learning the M11 formula.",
                "The learning curve of the MAS receiving an example at a 1/33 ms−1 rate is almost not altered (see Figure 4) whereas the 1/16 ms−1 MAS is first severely slowed down before catching up with the first one. 5.",
                "RELATED WORKS Since 96 [15], various work have been performed on learning in MAS, but rather few on concept learning.",
                "In [11] the MAS performs a form of ensemble learning in which the agents are lazy learners (no explicit representation is maintained) and sell useless examples to other agents.",
                "In [10] each agent observes all the examples but only perceive a part of their representation.",
                "In mutual online concept learning [14] the agents converge to a unique hypothesis, but each agent produces examples from its own concept representation, thus resulting in a kind of synchronization rather than in pure concept learning. 170 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 6: Accuracies of two asynchronous 11-MAS (1/33ms−1 and 1/16ms−1 example rates) . 6.",
                "CONCLUSION We have presented here and experimented a protocol for MAS online concept learning.",
                "The main feature of this collaborative learning mechanism is that it maintains a consistency property: though during the learning process each agent only receives and stores, with some limited redundancy, part of the examples received by the MAS, at any moment the current hypothesis is consistent with the whole set of examples.",
                "The hypotheses of our experiments do not address the issues of distributed MAS such as faults (for instance messages could be lost or corrupted) or other failures in general (crash, byzantine faults, etc.).",
                "Nevertheless, our framework is open, i.e., the agents can leave the system or enter it while the consistency mechanism is preserved.",
                "For instance if we introduce a timeout mechanism, even when a critic agent crashes or omits to answer, the consistency with the other critics (within the remaining agents) is entailed.",
                "In [1], a similar approach has been applied to MAS abduction problems: the hypotheses to maintain, given an incomplete information, are then facts or statements.",
                "Further work concerns first coupling induction and abduction in order to perform collaborative concept learning when examples are only partially observed by each agent, and second, investigating partial memory learning: how learning is preserved whenever one agent or the whole MAS forgets some selected examples.",
                "Aknowledgments We are very grateful to Dominique Bouthinon for implementing late modifications in SMILE, so much easing our experiments.",
                "Part of this work has been performed during the first authors visit to the Atelier De BioInformatique of Paris VI university, France. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In DALT-2006, May 2006. [2] W. W. Cohen.",
                "Fast effective rule induction.",
                "In ICML, pages 115-123, 1995. [3] C. B. D.J.",
                "Newman, S. Hettich and C. Merz.",
                "UCI repository of machine learning databases, 1998. [4] S. Esmeir and S. Markovitch.",
                "Lookahead-based algorithms for anytime induction of decision trees.",
                "In ICMLO4, pages 257-264.",
                "Morgan Kaufmann, 2004. [5] J. F¨urnkranz.",
                "A pathology of bottom-up hill-climbing in inductive rule learning.",
                "In ALT, volume 2533 of LNCS, pages 263-277.",
                "Springer, 2002. [6] A. Guerra-Hern´andez, A. ElFallah-Seghrouchni, and H. Soldano.",
                "Learning in BDI multi-agent systems.",
                "In CLIMA IV, volume 3259, pages 218-233.",
                "Springer Verlag, 2004. [7] M. Henniche.",
                "Mgi: an incremental bottom-up algorithm.",
                "In IEEE Aust. and New Zealand Conference on Intelligent Information Systems, pages 347-351, 1994. [8] T.-S. Lim, W.-Y.",
                "Loh, and Y.-S. Shih.",
                "A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms.",
                "Machine Learning, 40(3):203-228, 2000. [9] M. A. Maloof and R. S. Michalski.",
                "Incremental learning with partial instance memory.",
                "Artif.",
                "Intell., 154(1-2):95-126, 2004. [10] P. J. Modi and W.-M. Shen.",
                "Collaborative multiagent learning for classification tasks.",
                "In AGENTS 01, pages 37-38.",
                "ACM Press, 2001. [11] S. Onta˜non and E. Plaza.",
                "Recycling data for multi-agent learning.",
                "In ICML 05, pages 633-640.",
                "ACM Press, 2005. [12] J. R. Quinlan.",
                "Induction of decision trees.",
                "Machine Learning, 1(1):81-106, 1986. [13] U. R¨uckert and S. Kramer.",
                "Towards tight bounds for rule learning.",
                "In ICML 04 (International conference on Machine learning), page 90, New York, NY, USA, 2004.",
                "ACM Press. [14] J. Wang and L. Gasser.",
                "Mutual online concept learning for multiple agents.",
                "In AAMAS, pages 362-369.",
                "ACM Press, 2002. [15] G. Weiß and S. Sen, editors.",
                "Adaption and Learning in Multi-Agent Systems, volume 1042 of Lecture Notes in Computer Science.",
                "Springer, 1996. [16] I. H. Witten and E. Frank.",
                "Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.",
                "Morgan Kaufmann, October 1999.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 171"
            ],
            "original_annotated_samples": [
                "In section 2 we formally define the mas-consistency of an <br>update mechanism</br> for the whole MAS and we propose a generic <br>update mechanism</br> proved to be mas consistent.",
                "In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent <br>update mechanism</br> to collaborative concept learning.",
                "Definition 4. a-consistency of a revision An <br>update mechanism</br> M is a-consistent iff for any agent ri and any piece of information k reaching ri, the a-consistency of this agent is preserved.",
                "Definition 5. mas-consistency of a revision An <br>update mechanism</br> Ms is mas-consistent iff for all agent ri and all pieces of information k reaching ri, the masconsistency of this agent is preserved.",
                "Strong mas-consistency of a revision An <br>update mechanism</br> Ms is strongly mas-consistent iff - Ms is mas-consistent, and - the application of Ms by an agent preserves the consistency of the MAS. 2.2 A strongly mas-consistent <br>update mechanism</br> The general idea is that, since information is distributed among all the agents of the MAS, there must be some interaction between the learner agent and the other agents in a strongly mas-consistent update mechanism Ms."
            ],
            "translated_annotated_samples": [
                "En la sección 2 definimos formalmente la mas-consistencia de un <br>mecanismo de actualización</br> para todo el MAS y proponemos un <br>mecanismo de actualización</br> genérico demostrado que es mas consistente.",
                "En la sección 3 describimos SMILE, un aprendiz de conceptos multiagente incremental que aplica nuestro <br>mecanismo de actualización</br> mas consistente para el aprendizaje colaborativo de conceptos.",
                "Definición 4. a-consistencia de una revisión Un <br>mecanismo de actualización</br> M es a-consistente si, para cualquier agente ri y cualquier pieza de información k que llegue a ri, la a-consistencia de este agente se conserva.",
                "Definición 5. mas-consistencia de una revisión Un <br>mecanismo de actualización</br> Ms es mas-consistente si para todo agente ri y toda pieza de información k que llega a ri, la mas-consistencia de este agente se conserva.",
                "La fuerte mas-consistencia de un <br>mecanismo de actualización</br>. Un <br>mecanismo de actualización</br> Ms es fuertemente mas-consistente si - Ms es mas-consistente, y - la aplicación de Ms por un agente preserva la consistencia del MAS. 2.2 Un mecanismo de actualización fuertemente mas-consistente. La idea general es que, dado que la información está distribuida entre todos los agentes del MAS, debe haber alguna interacción entre el agente aprendiz y los demás agentes en un mecanismo de actualización fuertemente mas-consistente Ms."
            ],
            "translated_text": "SMILE: Aprendizaje Incremental Multiagente de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av. del presidente Kennedy, 75116 París Henry Soldano LIPN, UMR 7030 CNRS, Universidad Paris-Norte, 99 Av. J-B Clement, 93430, Villetaneuse RESUMEN Este artículo trata sobre el problema del aprendizaje colaborativo en un sistema multiagente. Aquí cada agente puede actualizar de forma incremental sus creencias B (la representación del concepto) para que se mantenga consistente con el conjunto completo de información K (los ejemplos) que ha recibido del entorno u otros agentes. Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo lograr que, en cualquier momento, una misma representación conceptual consistente esté presente en cada agente. El protocolo correspondiente se aplica al aprendizaje supervisado de conceptos. El método resultante SMILE (que significa Sound Multiagent Incremental LEarning) se describe y experimenta aquí. Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de múltiples agentes que por un solo agente. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de conceptos; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistema multiagente Términos Generales Experimentación, Algoritmos, Medición, Rendimiento 1. INTRODUCCIÓN Este artículo trata sobre el problema del aprendizaje colaborativo de conceptos en un sistema multiagente. [6] introduce una caracterización del aprendizaje en un sistema multiagente según el nivel de conciencia de los agentes. En el nivel 1, los agentes aprenden ∗El autor principal de este artículo es un estudiante. en el sistema sin tener en cuenta la presencia de otros agentes, excepto a través de la modificación que traen al entorno con sus acciones. El nivel 2 implica una interacción directa entre los agentes, ya que pueden intercambiar mensajes para mejorar su aprendizaje. El nivel 3 requeriría que los agentes tengan en cuenta las competencias de otros agentes y sean capaces de aprender observando el comportamiento de los otros agentes (considerándolos como entidades independientes y no como parte indeterminada del entorno como en el nivel 1). En este artículo nos enfocamos en el nivel 2, estudiando la interacción directa entre los agentes involucrados en un proceso de aprendizaje. Cada agente se asume capaz de aprender de forma incremental a partir de los datos que recibe, lo que significa que cada agente puede actualizar su conjunto de creencias B para mantenerlo consistente con el conjunto completo de información K que ha recibido del entorno o de otros agentes. En tal caso, diremos que es a-inconsistente. Aquí, el conjunto de creencias B representa conocimiento hipotético que por lo tanto puede ser revisado, mientras que el conjunto de información K representa conocimiento cierto, compuesto por observaciones y hechos no revisables. Además, suponemos que al menos una parte Bc de las creencias de cada agente es común a todos los agentes y debe mantenerse de esa manera. Por lo tanto, una actualización de este conjunto común Bc por parte del agente r debe provocar una actualización de Bc para toda la comunidad de agentes. Nos lleva a definir cuál es la mas-consistencia de un agente con respecto a la comunidad. El proceso de actualización de las creencias de la comunidad cuando uno de sus miembros recibe nueva información puede entonces definirse como el proceso de mantenimiento de la consistencia que garantiza que cada agente en la comunidad permanecerá más consistente. Este proceso de mantenimiento de la mas-consistencia de un agente al recibir nueva información le otorga el rol de aprendiz e implica la comunicación con otros agentes que actúan como críticos. Sin embargo, los agentes no están especializados y a su vez pueden ser aprendices o críticos, ninguno de ellos está limitado a un rol específico. Las piezas de información se distribuyen entre los agentes, pero pueden ser redundantes. No hay memoria central. El trabajo descrito aquí tiene su origen en un trabajo anterior sobre el aprendizaje en un sistema multiagente intencional utilizando un formalismo BDI [6]. En ese trabajo, los agentes tenían planes, cada uno de ellos asociado con un contexto que define en qué condiciones puede ser activado. Los planes (cada uno con su propio contexto) eran comunes a todo el conjunto de agentes en la comunidad. Los agentes tuvieron que adaptar su plan en función del contexto, dependiendo del fracaso o éxito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo a otros agentes ejemplos (éxitos o fracasos de planes). Sin embargo, este trabajo carecía de un protocolo de aprendizaje colectivo que permitiera una verdadera autonomía del sistema multiagente. El estudio de dicho protocolo es el objeto del presente artículo. En la sección 2 definimos formalmente la mas-consistencia de un <br>mecanismo de actualización</br> para todo el MAS y proponemos un <br>mecanismo de actualización</br> genérico demostrado que es mas consistente. En la sección 3 describimos SMILE, un aprendiz de conceptos multiagente incremental que aplica nuestro <br>mecanismo de actualización</br> mas consistente para el aprendizaje colaborativo de conceptos. La sección 4 describe varios experimentos sobre SMILE y discute varios problemas, incluyendo cómo varían la precisión y la simplicidad de la hipótesis actual al comparar el aprendizaje de un solo agente y el aprendizaje de múltiples agentes. En la sección 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la sección 6 discutiendo investigaciones adicionales sobre el aprendizaje más consistente. MODELO FORMAL 2.1 Definiciones y marco En esta sección, presentamos una formulación general del aprendizaje incremental colectivo en un sistema cognitivo de múltiples agentes. Representamos un MAS como un conjunto de agentes r1, ..., rn. Cada agente ri tiene un conjunto de creencias Bi que consiste en todo el conocimiento revisable que posee. Parte de estos conocimientos deben ser compartidos con otros agentes. La parte de Bi que es común a todos los agentes se denota como BC. Esta parte común provoca una dependencia entre los agentes. Si un agente ri actualiza su conjunto de creencias Bi a Bi, cambiando en el proceso BC en BC, entonces todos los demás agentes rk deben actualizar su conjunto de creencias Bk a Bk para que BC ⊆ Bk. Además, cada agente ri ha almacenado cierta información Ki. Suponemos que alguna propiedad de consistencia Cons(Bi, Ki) puede ser verificada por el agente mismo entre sus creencias Bi y su información Ki. Como se dijo antes, Bi representa el conocimiento que podría ser revisado, mientras que Ki representa hechos observados, considerados verdaderos, y que posiblemente puedan contradecir a Bi. Definición 1. a-consistencia de un agente Un agente ri es a-consistente si Cons(Bi, Ki) es verdadero. Ejemplo 1. El agente r1 tiene un conjunto de planes que se encuentran en la parte común BC de B1. Cada plan P tiene un contexto desencadenante d(P) (que actúa como una precondición) y un cuerpo. Alguna pieza de información k podría ser el plan P, desencadenado en la situación s, ha fallado a pesar de que s es una instancia de d(P). Si esta pieza de información se agrega a K1, entonces el agente r1 ya no es a-consistente: Cons(B1, K1 ∪ k) es falso. También queremos definir alguna noción de consistencia para todo el MAS dependiendo de los conjuntos de creencias e información de sus elementos constituyentes. Primero definiremos la consistencia de un agente ri con respecto a su conjunto de creencias Bi y su propio conjunto de información Ki junto con todos los conjuntos de información K1...Kn de los otros agentes del MAS. Simplemente lo haremos considerando cuál sería la a-consistencia del agente si tuviera la información de todos los demás agentes. Llamamos a esta noción la mas-consistencia: Definición 2. Un agente ri es mas-consistente si Cons(Bi, Ki ∪ K) es verdadero, donde K = ∪j∈{1,..,n}−{i}Kj 1 es el conjunto de toda la información de los otros agentes del MAS. 1 Lo notaremos como ∪ Kj cuando el contexto sea similar. Ejemplo 2. Usando el ejemplo anterior, supongamos que la pieza de información k está incluida en la información K2 del agente r2. Si la pieza de información no se transmite a r1, y por lo tanto no se agrega a K1, r1 permanece a-consistente. Sin embargo, r1 no es tan consistente como k en el conjunto K de toda la información del MAS. La consistencia global del MAS es simplemente la mas-consistencia de todos sus agentes. Definición 3. La consistencia de un MAS A MAS r1,...,rn es consistente si todos sus agentes ri son masconsistentes. Ahora definimos las propiedades requeridas para un mecanismo de revisión M que actualiza a un agente ri cuando recibe una pieza de información k. En lo siguiente, supondremos que: • La actualización siempre es posible, es decir, un agente siempre puede modificar su conjunto de creencias Bi para recuperar su a-consistencia. Diremos que cada agente es localmente eficiente. • Considerando dos conjuntos de información Cons(Bi, K1) y Cons(Bi, K2), también tenemos Cons(Bi, K1 ∪ K2). Es decir, la a-consistencia de los agentes es aditiva. • Si una pieza de información k relacionada con el conjunto común BC es consistente con un agente, es consistente con todos los agentes: para todos los pares de agentes (ri, rj) tales que Cons(Bi, Ki) y Cons(Bj, Kj) son verdaderos, tenemos, para toda pieza de información k: Cons(Bi, Ki ∪ k) si y solo si Cons(Bj, Kj ∪ k). En tal caso, diremos que el MAS es coherente. Esta última condición simplemente significa que el conjunto de creencias común BC es independiente de las posibles diferencias entre los conjuntos de creencias Bi de cada agente ri. En el caso más simple, B1 = ... = Bn = BC. M también será visto como un mecanismo de aprendizaje incremental y representado como una aplicación que cambia Bi en Bi. En lo siguiente, anotaremos ri(Bi, Ki) para ri cuando sea útil. Definición 4. a-consistencia de una revisión Un <br>mecanismo de actualización</br> M es a-consistente si, para cualquier agente ri y cualquier pieza de información k que llegue a ri, la a-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki) a-consistente ⇒ ri(Bi, Ki) a-consistente, donde Bi = M(Bi) y Ki = Ki ∪ k es el conjunto de toda la información de otros agentes del MAS. De la misma manera, definimos la mas-consistencia de un mecanismo de revisión como la a-consistencia de este mecanismo si los agentes disponen de toda la información en el MAS. En lo siguiente, anotaremos, si es necesario, ri(Bi, Ki, K) para el agente ri en el MAS r1 . . . rn. Definición 5. mas-consistencia de una revisión Un <br>mecanismo de actualización</br> Ms es mas-consistente si para todo agente ri y toda pieza de información k que llega a ri, la mas-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki, K) más-consistente ⇒ ri(Bi, Ki, K) más-consistente, donde Bi = Ms(Bi), Ki = Ki ∪ k, y K = ∪Kj es el conjunto de toda la información del MAS. El Sexto Internacional. En última instancia, cuando un agente aplica un mecanismo mas-consistente al recibir una nueva pieza de información, un efecto secundario deseable del mecanismo debería ser que todos los demás agentes permanezcan mas-consistentes después de cualquier modificación de la parte común BC, es decir, el MAS en sí mismo debería volver a ser consistente. Esta propiedad se define de la siguiente manera: Definición 6. La fuerte mas-consistencia de un <br>mecanismo de actualización</br>. Un <br>mecanismo de actualización</br> Ms es fuertemente mas-consistente si - Ms es mas-consistente, y - la aplicación de Ms por un agente preserva la consistencia del MAS. 2.2 Un mecanismo de actualización fuertemente mas-consistente. La idea general es que, dado que la información está distribuida entre todos los agentes del MAS, debe haber alguna interacción entre el agente aprendiz y los demás agentes en un mecanismo de actualización fuertemente mas-consistente Ms. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "synchronization": {
            "translated_key": "sincronización",
            "is_in_text": true,
            "original_annotated_sentences": [
                "SMILE: Sound Multi-agent Incremental LEarning ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av.",
                "du pr´esident Kennedy, 75116 Paris Henry Soldano LIPN, UMR 7030 CNRS, University Paris-Nord, 99 Av.",
                "J-B Clement, 93430, Villetaneuse ABSTRACT This article deals with the problem of collaborative learning in a multi-agent system.",
                "Here each agent can update incrementally its beliefs B (the concept representation) so that it is in a way kept consistent with the whole set of information K (the examples) that he has received from the environment or other agents.",
                "We extend this notion of consistency (or soundness) to the whole MAS and discuss how to obtain that, at any moment, a same consistent concept representation is present in each agent.",
                "The corresponding protocol is applied to supervised concept learning.",
                "The resulting method SMILE (standing for Sound Multiagent Incremental LEarning) is described and experimented here.",
                "Surprisingly some difficult boolean formulas are better learned, given the same learning set, by a Multi agent system than by a single agent.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Concept learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent system General Terms Experimentation, Algorithms, Measurement, Performance 1.",
                "INTRODUCTION This article deals with the problem of collaborative concept learning in a multi-agent system. [6] introduces a characterisation of learning in multi-agent system according to the level of awareness of the agents.",
                "At level 1, agents learn ∗The primary author of this paper is a student. in the system without taking into account the presence of other agents, except through the modification brought upon the environment by their action.",
                "Level 2 implies direct interaction between the agents as they can exchange messages to improve their learning.",
                "Level 3 would require agents to take into account the competencies of other agents, and be able to learn from observation of the other agents behaviour (while considering them as independant entities and not indetermined part of the environment as in level 1).",
                "We focus in this paper on level 2, studying direct interaction between agents involved in a learning process.",
                "Each agent is assumed to be able to learn incrementally from the data he receives, meaning that each agent can update his belief set B to keep it consistent with the whole set of information K that he has received from the environment or from other agents.",
                "In such a case, we will say that he is a-consistent.",
                "Here, the belief set B represents hypothetical knowledge that can therefore be revised, whereas the set of information K represents certain knowledge, consisting of non revisable observations and facts.",
                "Moreover, we suppose that at least a part Bc of the beliefs of each agent is common to all agents and must stay that way.",
                "Therefore, an update of this common set Bc by agent r must provoke an update of Bc for the whole community of agents.",
                "It leads us to define what is the mas-consistency of an agent with respect to the community.",
                "The update process of the community beliefs when one of its members gets new information can then be defined as the consistency maintenance process ensuring that every agent in the community will stay masconsistent.",
                "This mas-consistency maintenance process of an agent getting new information gives him the role of a learner and implies communication with other agents acting as critics.",
                "However, agents are not specialised and can in turn be learners or critics, none of them being kept to a specific role.",
                "Pieces of information are distributed among the agents, but can be redundant.",
                "There is no central memory.",
                "The work described here has its origin in a former work concerning learning in an intentional multi-agent system using a BDI formalism [6].",
                "In that work, agents had plans, each of them being associated with a context defining in which conditions it can be triggered.",
                "Plans (each of them having its own context) were common to the whole set of agents in the community.",
                "Agents had to adapt their plan contexts depending on the failure or success of executed plans, using a learning mechanism and asking other agents for examples (plans successes or failures).",
                "However this work lacked a collective learning protocol enabling a real autonomy of the multi-agent system.",
                "The study of such a protocol is the object of the present paper.",
                "In section 2 we formally define the mas-consistency of an update mechanism for the whole MAS and we propose a generic update mechanism proved to be mas consistent.",
                "In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent update mechanism to collaborative concept learning.",
                "Section 4 describes various experiments on SMILE and discusses various issues including how the accuracy and the simplicity of the current hypothesis vary when comparing single agent learning and mas learning.",
                "In section 5 we briefly present some related works and then conclude in section 6 by discussing further investigations on mas consistent learning. 2.",
                "FORMAL MODEL 2.1 Definitions and framework In this section, we present a general formulation of collective incremental learning in a cognitive multi agent system.",
                "We represent a MAS as a set of agents r1, ..., rn.",
                "Each agent ri has a belief set Bi consisting of all the revisable knowledge he has.",
                "Part of these knowledges must be shared with other agents.",
                "The part of Bi that is common to all agents is denoted as BC .",
                "This common part provokes a dependency between the agents.",
                "If an agent ri updates his belief set Bi to Bi, changing in the process BC into BC , all other agents rk must then update their belief set Bk to Bk so that BC ⊆ Bk.",
                "Moreover, each agent ri has stored some certain information Ki.",
                "We suppose that some consistency property Cons(Bi, Ki) can be verified by the agent itself between its beliefs Bi and its information Ki.",
                "As said before, Bi represents knowledge that might be revised whereas Ki represents observed facts, taken as being true, and which can possibly contradict Bi.",
                "Definition 1. a-consistency of an agent An agent ri is a-consistent iff Cons(Bi, Ki) is true.",
                "Example 1.",
                "Agent r1 has a set of plans which are in the common part BC of B1.",
                "Each plan P has a triggering context d(P) (which acts as a pre-condition) and a body.",
                "Some piece of information k could be plan P, triggered in situation s, has failed in spite of s being an instance of d(P).",
                "If this piece of information is added to K1, then agent r1 is not a-consistent anymore: Cons(B1, K1 ∪ k) is false.",
                "We also want to define some notion of consistency for the whole MAS depending on the belief and information sets of its constituting elements.",
                "We will first define the consistency of an agent ri with respect to its belief set Bi and its own information set Ki together with all information sets K1...Kn from the other agents of the MAS.",
                "We will simply do that by considering what would be the a-consistency of the agent if he has the information of all the other agents.",
                "We call this notion the mas-consistency: Definition 2. mas-consistency of an agent An agent ri is mas-consistent iff Cons(Bi, Ki ∪ K) is true, where K = ∪j∈{1,..,n}−{i}Kj 1 is the set of all information from other agents of the MAS. 1 We will note this ∪ Kj when the context is similar.",
                "Example 2.",
                "Using the previous example, suppose that the piece of information k is included in the information K2 of agent r2.",
                "As long as the piece of information is not transmitted to r1, and so added to K1 , r1 remains a-consistent.",
                "However, r1 is not mas-consistent as k is in the set K of all information of the MAS.",
                "The global consistency of the MAS is then simply the mas-consistency of all its agents.",
                "Definition 3.",
                "Consistency of a MAS A MAS r1,...,rn is consistent iff all its agents ri are masconsistent.",
                "We now define the required properties for a revision mechanism M updating an agent ri when it gets a piece of information k. In the following, we will suppose that: • Update is always possible, that is, an agent can always modify its belief set Bi in order to regain its a-consistency.",
                "We will say that each agent is locally efficient. • Considering two sets of information Cons(Bi, K1) and Cons(Bi, K2), we also have Cons(Bi, K1 ∪ K2).",
                "That is, a-consistency of the agents is additive. • If a piece of information k concerning the common set BC is consistent with an agent, it is consistent with all agents: for all pair of agents (ri,rj) such that Cons(Bi, Ki) and Cons(Bj, Kj) are true, we have, for all piece of information k: Cons(Bi, Ki ∪ k) iff Cons(Bj, Kj ∪ k).",
                "In such a case, we will say that the MAS is coherent.",
                "This last condition simply means that the common belief set BC is independent of the possible differences between the belief sets Bi of each agent ri.",
                "In the simplest case, B1 = ... = Bn = BC .",
                "M will also be viewed as an incremental learning mechanism and represented as an application changing Bi in Bi.",
                "In the following, we shall note ri(Bi, Ki) for ri when it is useful.",
                "Definition 4. a-consistency of a revision An update mechanism M is a-consistent iff for any agent ri and any piece of information k reaching ri, the a-consistency of this agent is preserved.",
                "In other words, iff: ri(Bi, Ki) a-consistent ⇒ ri(Bi, Ki) a-consistent, where Bi = M(Bi) and Ki = Ki ∪ k is the set of all information from other agents of the MAS.",
                "In the same way, we define the mas-consistency of a revision mechanism as the a-consistency of this mechanism should the agents dispose of all information in the MAS.",
                "In the following, we shall note, if needed, ri(Bi, Ki, K) for the agent ri in MAS r1 . . . rn.",
                "Definition 5. mas-consistency of a revision An update mechanism Ms is mas-consistent iff for all agent ri and all pieces of information k reaching ri, the masconsistency of this agent is preserved.",
                "In other words, if: ri(Bi, Ki, K) mas-consistent ⇒ ri(Bi, Ki, K) mas-consistent, where Bi = Ms(Bi), Ki = Ki ∪ k, and K = ∪Kj is the set of all information from the MAS.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 165 At last, when a mas-consistent mechanism is applied by an agent getting a new piece of information, a desirable sideeffect of the mechanism should be that all others agents remains mas-consistent after any modification of the common part BC , that is, the MAS itself should become consistent again.",
                "This property is defined as follows: Definition 6.",
                "Strong mas-consistency of a revision An update mechanism Ms is strongly mas-consistent iff - Ms is mas-consistent, and - the application of Ms by an agent preserves the consistency of the MAS. 2.2 A strongly mas-consistent update mechanism The general idea is that, since information is distributed among all the agents of the MAS, there must be some interaction between the learner agent and the other agents in a strongly mas-consistent update mechanism Ms.",
                "In order to ensure its mas-consistency, Ms will be constituted of reiterated applications by the learner agent ri of an internal a-consistent mechanism M, followed by some interactions between ri and the other agents, until ri regain its masconsistency.",
                "We describe below such a mechanism, first with a description of an interaction, then an iteration, and finally a statement of the termination condition of the mechanism.",
                "The mechanism is triggered by an agent ri upon receipt of a piece of information k disrupting the mas-consistency.",
                "We shall note M(Bi) the belief set of the learner agent ri after an update, BC the common part modified by ri, and Bj the belief set of another agent rj induced by the modification of its common part BC in BC .",
                "An interaction I(ri, rj) between the learner agent ri and another agent rj, acting as critic is constituted of the following steps: • agent ri sends the update BC of the common part of its beliefs.",
                "Having applied its update mechanism, ri is a-consistent. • agent rj checks the modification Bj of its beliefs induced by the update BC .",
                "If this modification preserve its a-consistency, rj adopts this modification. • agent rj sends either an acceptation of BC or a denial along with one (or more) piece(s) of information k such that Cons(Bj, k ) is false.",
                "An iteration of Ms will then be composed of: • the reception by the learner agent ri of a piece of information and the update M(Bi) restoring its aconsistency • a set of interactions I(ri, rj) (in which several critic agents can possibly participate).",
                "If at least one piece of information k is transmitted to ri, the addition of k will necessarily make ri a-inconsistent and a new iteration will then occur.",
                "This mechanism Ms ends when no agent can provide such a piece of information k .",
                "When it is the case, the masconsistency of the learner agent ri is restored.",
                "Proposition 1.",
                "Let r1,...,rn be a consistent MAS in which agent ri receives a piece of information k breaking its aconsistency, and M an a-consistent internal update mechanism.",
                "The update mechanism Ms described above is strongly mas-consistent.",
                "Proof.",
                "The proof directly derives from the mechanism description.",
                "This mechanism ensures that each time an agent receives an event, its mas-consistency will be restored.",
                "As the other agents all adopt the final update BC , they are all mas-consistent, and the MAS is consistent.",
                "Therefore Ms is a strongly consistent update mechanism.",
                "In the mechanism Ms described above, the learner agent is the only one that receives and memorizes information during the mechanism execution.",
                "It ensures that Ms terminates.",
                "The pieces of information transmitted by other agents and memorized by the learner agent are redundant as they are already present in the MAS, more precisely in the memory of the critic agents that transmitted them.",
                "Note that the mechanism Ms proposed here does not explicitly indicate the order nor the scope of the interactions.",
                "We will consider in the following that the modification proposal BC is sent sequentially to the different agents (synchronous mechanism).",
                "Moreover, the response of a critic agent will only contain one piece of information inconsistent with the proposed modification.",
                "We will say that the response of the agent is minimal.",
                "This mechanism Ms, being synchronous with minimal response, minimizes the amount of information transmitted by the agents.",
                "We will now illustrate it in the case of multi-agent concept learning. 3.",
                "SOUNDMULTI-AGENTINCREMENTAL LEARNING 3.1 The learning task We experiment the mechanism proposed above in the case of incremental MAS concept learning.",
                "We consider here a hypothesis language in which a hypothesis is a disjunction of terms.",
                "Each term is a conjunction of atoms from a set A.",
                "An example is represented by a tag + or − and a description 2 composed of a subset of atoms e ⊆ A.",
                "A term covers an example if its constituting atoms are included in the example.",
                "A hypothesis covers an example if one of its term covers it.",
                "This representation will be used below for learning boolean formulae.",
                "Negative literals are here represented by additional atoms, like not − a.",
                "The boolean formulae f =(a ∧ b) ∨ (b ∧ ¬c) will then be written (a ∧ b) ∨ (b ∧ not − c).",
                "A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 Incremental learning process The learning process is an update mechanism that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis.",
                "Before this update, the given hypothesis is complete, meaning that it covers all positive examples of E+ , and 2 When no confusion is possible, the word example will be used to refer to the pair (tag, description) as well as the description alone. 166 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) coherent, meaning that it does not cover any negative example of E− .",
                "After the update, the new hypothesis must be complete and coherent with the new memory state E ∪ {e}.",
                "We describe below our single agent update mechanism, inspired from a previous work on incremental learning[7].",
                "In the following, a hypothesis H for the target formula f is a list of terms h, each of them being a conjunction of atoms.",
                "H is coherent if all terms h are coherent, and H is complete if each element of E+ is covered by at least one term h of H. Each term is by construction the lgg (least general generalization) of a subset of positives instances {e1, ..., en}[5], that is the most specific term covering {e1, ..., en}.",
                "The lgg operator is defined by considering examples as terms, so we denote as lgg(e) the most specific term that covers e, and as lgg(h, e) the most specific term which is more general than h and that covers e. Restricting the term to lgg is the basis of a lot of Bottom-Up learning algorithms (for instance [5]).",
                "In the typology proposed by [9], our update mechanism is an incremental learner with full instance memory: learning is made by successive updates and all examples are stored.",
                "The update mechanism depends of the ongoing hypothesis H, the ongoing examples E+ and E− , and the new example e. There are three possible cases: • e is positive and H covers e, or e is negative and H does not cover e. No update is needed, H is already complete and coherent with E ∪ {e}. • e is positive and H does not cover e: e is denoted as a positive counterexample of H. Then we seek to generalize in turn the terms h of H. As soon as a correct generalization h = lgg(h, e) is found, h replaces h in H. If there is a term that is less general that h , it is discarded.",
                "If no generalization is correct (meaning here coherent), H ∪ lgg(e) replaces H. • e is negative and H covers e: e is denoted as a negative counterexample of H. Each term h covering e is then discarded from H and replaced by a set of terms {h1, ...., hn} that is, as a whole, coherent with E− ∪ {e} and that covers the examples of E+ uncovered by H − {h}.",
                "Terms of the final hypothesis H that are less general than others are discarded from H. We will now describe the case where e = e− is a covered negative example.",
                "The following functions are used here: • coveredOnlyBy(h, E+) gives the subset of E+ covered by h and no other term of H. • bestCover(h1, h2) gives h1 if h1 covers more examples from uncoveredPos than h2, otherwise it gives h2. • covered(h) gives the elements of uncoveredPos covered by h. // Specialization of each h covering e− for each h of H covering e− do H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= atoms that are neither in e− nor in h while (uncoveredPos = ∅) do // seeking the best specialization of h hc=h best=⊥ // ⊥ covers no example for each a of Ar do hc= h ∧ a best = bestCover(hc, best) endfor Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) endwhile endfor Terms of H that are less general than others are discarded.",
                "Note that this mechanism tends to both make a minimal update of the current hypothesis and minimize the number of terms in the hypothesis, in particular by discarding terms less general than other ones after updating a hypothesis. 3.3 Collective learning If H is the current hypothesis, Ei the current example memory of agent ri and E the set of all the examples received by the system, the notation of section 2 becomes Bi = BC = H, Ki = Ei and K = E. Cons(H, Ei) states that H is complete and coherent with Ei.",
                "In such a case, ri is a-consistent.",
                "The piece of information k received by agent ri is here simply an example e along with its tag.",
                "If e is such that the current hypothesis H is not complete or coherent with Ei ∪ {e}, e contradicts H: ri becomes a-inconsistent, and therefore the MAS is not consistent anymore.",
                "The update of a hypothesis when a new example arrives is an a- consistent mechanism.",
                "Following proposition 1 this mechanism can be used to produce a strong mas-consistent mechanism: upon reception of a new example in the MAS by an agent r, an update is possibly needed and, after a set of interactions between r and the other agents, results in a new hypothesis shared by all the agents and that restores the consistency of the MAS, that is which is complete and coherent with the set ES of all the examples present in the MAS.",
                "It is clear that by minimizing the number of hypothesis modifications, this synchronous and minimal mechanism minimize the number of examples received by the learner from other agents, and therefore, the total number of examples stored in the system. 4.",
                "EXPERIMENTS In the following, we will learn a boolean formula that is a difficult test for the learning method: the 11-multiplexer (see [4]).",
                "It concerns 3 address boolean attributes a0, a1, a2 and 8 data boolean attributes d0, ..., d7.",
                "Formulae f11 is satisfied if the number coded by the 3 address attributes is the number of a data attribute whose value is 1.",
                "Its formula is the following: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0).",
                "There are 2048 = 211 possible examples, half of whom are positive (meaning they satisfy f11) while the other half is negative.",
                "An experiment is typically composed of 50 trials.",
                "Each run corresponds to a sequence of 600 examples that are incrementally learned by a Multi Agent System with n agents The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 167 (n-MAS).",
                "A number of variables such as accuracy, (i.e. the frequency of correct classification of a set of unseen examples), hypothesis size (i.e. the number of terms in the current formula) or number of stored examples, is recorded each time 25 examples are received by the system during those runs.",
                "In the protocol that is used here, a new example is sent to a random agent when the MAS is consistent.",
                "The next example will be sent in turn to an other agent when the MAS consistency will have been restored.",
                "In such a way we simulate a kind of slow learning: the frequency of example arrivals is slow compared to the time taken by an update. 4.1 Efficiency of MAS concept learning 4.1.1 Execution time We briefly discuss here execution time of learning in the MAS.",
                "Note that the whole set of action and interaction in the MAS is simulated on a single processor.",
                "Figure 1 shows that time linearly depends on the number of agents.",
                "At the end of the most active part of learning (200 examples), a 16MAS has taken 4 times more learning time than a 4-MAS.",
                "This execution time represents the whole set of learning and Figure 1: Execution time of a n-MAS (from n = 2 at the bottom to n = 20 on the top). communication activity and hints at the cost of maintaining a consistent learning hypothesis in a MAS composed of autonomous agents. 4.1.2 Redundancy in the MAS memory We study now the distribution of the examples in the MAS memory.",
                "Redundancy is written RS = nS/ne, where nS is the total number of examples stored in the MAS, that is the sum of the sizes of agents examples memories Ei, and ne is the total number of examples received from the environment in the MAS.",
                "In figure 2, we compare redundancies in 2 to 20 agents MAS.",
                "There is a peak, slowly moving from 80 to 100 examples, that represents the number of examples for which the learning is most active.",
                "For 20 agents, maximal redundancy is no more than 6, which is far less than the maximal theoretical value of 20.",
                "Note that when learning becomes less active, redundancy tends towards its minimal value 1: when there is no more updates, examples are only Figure 2: Redundancy of examples stored in a nMAS (from n = 2 at the bottom to n = 20 on the top) . stored by the agent that receives them. 4.1.3 A n-MAS selects a simpler solution than a single agent The proposed mechanism tends to minimize the number of terms in the selected hypothesis.",
                "During learning, the size of the current hypothesis grows up beyond the optimum, and then decreases when the MAS converges.",
                "In the Multiplexer 11 testbed, the optimal number of terms is 8, but there also exist equivalent formulas with more terms.",
                "It is interesting to note that in this case the 10-MAS converges towards an exact solution closer to the optimal number of terms (here 8) (see Figure 3).",
                "After 1450 examples have been presented both 1-MAS and 10-MAS have exactly learned the concept (the respective accuracies are 0.9999 and 1) but the single agent expresses in average the result as a 11.0 terms DNF whereas the 10-MAS expresses it as a 8.8 terms DNF.",
                "However for some other boolean functions we found that during learning 1-MAS always produces larger hypotheses than 10-MAS but that both MAS converge to hypotheses with similar size results. 4.1.4 A n-MAS is more accurate than a single agent Figure 4 shows the improvement brought by a MAS with n agents compared to a single agent.",
                "This improvement was not especially expected, because whether we have one or n agents, when N examples are given to the MAS it has access to the same amount of information, maintains only on ongoing hypothesis and uses the same basic revision algorithm whenever an agent has to modify the current hypothesis.",
                "Note that if the accuracy of 1, 2, 4 and 10-MAS are significantly different, getting better as the number of agents increases, there is no clear difference beyond this point: the accuracy curve of the 100 agents MAS is very close to the one of the 10 agents MAS. 4.1.4.1 Boolean formulas.",
                "To evaluate this accuracy improvement, we have experimented our protocol on other problems of boolean function learning, As in the Multiplexer-11 case, these functions 168 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 3: Size of the hypothesis built by 1 and 10MAS: the M11 case.",
                "Figure 4: Accuracy of a n-MAS: the M11 case (from bottom to top, n = 1, 2, 4, 10, 100). are learnt in the form of more or less syntactically complex DNF3 (that is with more or less conjunctive terms in the DNF), but are also more or less difficult to learn as it can be difficult to get its way in the hypothesis space to reach them.",
                "Furthermore, the presence in the description of irrelevant attributes (that is attributes that does not belong to the target DNF) makes the problem more difficult.",
                "The following problems have been selected to experiment our protocol: (i) the multiplexer-11 with 9 irrelevant attributes: M11 9, (ii) the 20-multiplexer M20 (with 4 address bits and 16 data bits), (iii) a difficult parity problem (see [4]) the Xorp m: there must be an odd number of bits with value 1 in the p first attributes for the instance to be positive, the p others bits being irrelevant, and (iv) a simple DNF formula (a ∧ b ∧ c) ∨ (c ∧ d ∧ e)(e ∧ f ∧ g) ∧ (g ∧ h ∧ i) with 19 irrelevant attributes.",
                "The following table sums up some information about these problems, giving the total number of attributes including irrelevant ones, the number of irrelevant 3 Disjunctive Normal Forms attributes, the minimal number of terms of the corresponding DNF, and the number of learning examples used.",
                "Pb att. irre. att. terms ex.",
                "M11 11 0 8 200 M11 9 20 9 8 200 M20 20 0 16 450 Xor3 25 28 25 4 200 Xor5 5 10 5 16 180 Xor5 15 20 15 16 600 Simple4-9 19 28 19 4 200 Below are given the accuracy results of our learning mechanism with a single agent and a 10 agents MAS, along with the results of two standard algorithms implemented with the learning environment WEKA[16]: JRip (an implementation of RIPPER[2]) and Id3[12].",
                "For the experiments with JRip and Id3, we measured the mean accuracy on 50 trials, each time randomly separating examples in a learning set and a test set.",
                "JRip and Id3 parameters are default parameters, except that JRip is used without pruning.",
                "The following table shows the results: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 It is clear that difficult problems are better solved with more agents (see for instance xor5 15).",
                "We think that these benefits, which can be important with an increasing number of agents, are due to the fact that each agent really memorizes only part of the total number of examples, and this part is partly selected by other agents as counter examples, which cause a greater number of current hypothesis updates and therefore, a better exploration of the hypotheses space. 4.1.4.2 ML database problems.",
                "We did also experiments with some non boolean problems.",
                "We considered only two classes (positive/negative) problems, taken from the UCIs learning problems database[3].",
                "In all these problems, examples are described as a vector of couples (attribute, value).",
                "The value domains can be either boolean, numeric (wholly ordered set), or nominal (non-ordered set).",
                "An adequate set of atoms A must be constituted for each problem.",
                "For instance, if a is a numeric attribute, we define at most k threshold si, giving k+1 intervals of uniform density4 .",
                "Therefore, each distinct threshold si gives two atoms a ≤ si and a > si.",
                "In our experiments, we took a maximal number of threshold k = 8.",
                "For instance, in the iono problem case, there were 34 numeric attributes, and an instance is described with 506 atoms.",
                "Below are given the accuracy results of our system along with previous results.",
                "The column Nb ex. refer to the 4 The probability for the value of a to be in any interval is constant The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 169 number of examples used for learning5 .",
                "Column (1) represents minimal and maximal accuracy values for the thirty three classifiers tested in [8].",
                "Column (2) represents the results of [13], where various learning methods are compared to ensemble learning methods using weighted classifiers sets.",
                "Column S-1 and S-10 gives the accuracy of SMILE with respectively 1 and 10 agents.",
                "Pb Nb ex. (1) (2) S-1 S-10 ttt 862/574 // 76.2-99.7 99.7 99.9 kr-vs-kp 2876/958 // 91.4-99.4 96.8 97.3 iono 315 // 88.0-91.8 87.2 88.1 bupa 310 57-72 58-69.3 62.5 63.3 breastw 614 91-97 94.3-97.3 94.7 94.7 vote 391 94-96 95.3-96 91.9 92.6 pima 691 // 71.5- 73.4 65.0 65.0 heart 243 66-86 77.1-84.1 69.5 70.7 This table shows that the incremental algorithm corresponding to the single agent case, gives honorable results relatively to non-incremental classical methods using larger and more complex hypotheses.",
                "In some cases, there is an accuracy improvement with a 10 agents MAS.",
                "However, with such benchmarks data, which are often noisy, the difficulty does not really come from the way in which the search space is explored, and therefore the improvement observed is not always significant.",
                "The same kind of phenomenon have been observed with methods dedicated to hard boolean problems [4]. 4.2 MAS <br>synchronization</br> Here we consider that n single agents learn without interactions and at a given time start interacting thus forming a MAS.",
                "The purpose is to observe how the agents take advantage of collaboration when they start from different states of beliefs and memories.",
                "We compare in this section a 1-MAS, a 10-MAS (ref) and a 10-MAS (100sync) whose agents did not communicate during the arrival of the first 100 examples (10 by agents).",
                "The three accuracy curves are shown in figure 5.",
                "By comparing the single agent curve and the synchronized 10-MAS, we can observe that after the beginning of the <br>synchronization</br>, that is at 125 examples, accuracies are identical.",
                "This was expected since as soon as an example e received by the MAS contradicts the current hypothesis of the agent ra receiving it, this agent makes an update and its new hypothesis is proposed to the others agents for criticism.",
                "Therefore, this first contradictory example brings the MAS to reach consistency relatively to the whole set of examples present in agents memories.",
                "A higher accuracy, corresponding to a 10-MAS is obtained later, from the 175th example.",
                "In other words, the benefit of a better exploration of the research space is obtained slightly later in the learning process.",
                "Note that this <br>synchronization</br> happens naturally in all situations where agents have, for some reason, a divergence between their hypothesis and the system memory.",
                "This includes the fusion of two MAS into a single one or the arrival of new agents in an existing MAS. 4.3 Experiments on asynchronous learning: the effect of a large data stream 5 For ttt and kr-vs-kp, our protocol did not use more than respectively 574 and 958 learning examples, so we put another number in the column.",
                "Figure 5: Accuracies of a 1-MAS, a 10-MAS, and a 10-MAS synchronized after 100 examples.",
                "In this experiment we relax our slow learning mode: the examples are sent at a given rate to the MAS.",
                "The resulting example stream is measured in ms−1 , and represents the number of examples sent to the MAS each ms.",
                "Whenever the stream is too large, the MAS cannot reach MAS consistency on reception of an example from the environment before a new example arrives.",
                "This means that the update process, started by agent r0 as he received an example, may be unfinished when a new example is received by r0 or another agent r1.",
                "As a result, a critic agent may have at instant t to send counterexamples of hypotheses sent by various agents.",
                "However as far as the agents, in our setting, memorizes all the examples they receive whenever the stream ends, the MAS necessarily reaches MAS consistency with respect to all the examples received so far.",
                "In our experiments, though its learning curve is slowed down during the intense learning phase (corresponding to low accuracy of the current hypotheses), the MAS still reaches a satisfying hypothesis later on as there are less and less counterexamples in the example stream.",
                "In Figure 6 we compare the accuracies of two 11-MAS respectively submitted to example streams of different rates when learning the M11 formula.",
                "The learning curve of the MAS receiving an example at a 1/33 ms−1 rate is almost not altered (see Figure 4) whereas the 1/16 ms−1 MAS is first severely slowed down before catching up with the first one. 5.",
                "RELATED WORKS Since 96 [15], various work have been performed on learning in MAS, but rather few on concept learning.",
                "In [11] the MAS performs a form of ensemble learning in which the agents are lazy learners (no explicit representation is maintained) and sell useless examples to other agents.",
                "In [10] each agent observes all the examples but only perceive a part of their representation.",
                "In mutual online concept learning [14] the agents converge to a unique hypothesis, but each agent produces examples from its own concept representation, thus resulting in a kind of <br>synchronization</br> rather than in pure concept learning. 170 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 6: Accuracies of two asynchronous 11-MAS (1/33ms−1 and 1/16ms−1 example rates) . 6.",
                "CONCLUSION We have presented here and experimented a protocol for MAS online concept learning.",
                "The main feature of this collaborative learning mechanism is that it maintains a consistency property: though during the learning process each agent only receives and stores, with some limited redundancy, part of the examples received by the MAS, at any moment the current hypothesis is consistent with the whole set of examples.",
                "The hypotheses of our experiments do not address the issues of distributed MAS such as faults (for instance messages could be lost or corrupted) or other failures in general (crash, byzantine faults, etc.).",
                "Nevertheless, our framework is open, i.e., the agents can leave the system or enter it while the consistency mechanism is preserved.",
                "For instance if we introduce a timeout mechanism, even when a critic agent crashes or omits to answer, the consistency with the other critics (within the remaining agents) is entailed.",
                "In [1], a similar approach has been applied to MAS abduction problems: the hypotheses to maintain, given an incomplete information, are then facts or statements.",
                "Further work concerns first coupling induction and abduction in order to perform collaborative concept learning when examples are only partially observed by each agent, and second, investigating partial memory learning: how learning is preserved whenever one agent or the whole MAS forgets some selected examples.",
                "Aknowledgments We are very grateful to Dominique Bouthinon for implementing late modifications in SMILE, so much easing our experiments.",
                "Part of this work has been performed during the first authors visit to the Atelier De BioInformatique of Paris VI university, France. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In DALT-2006, May 2006. [2] W. W. Cohen.",
                "Fast effective rule induction.",
                "In ICML, pages 115-123, 1995. [3] C. B. D.J.",
                "Newman, S. Hettich and C. Merz.",
                "UCI repository of machine learning databases, 1998. [4] S. Esmeir and S. Markovitch.",
                "Lookahead-based algorithms for anytime induction of decision trees.",
                "In ICMLO4, pages 257-264.",
                "Morgan Kaufmann, 2004. [5] J. F¨urnkranz.",
                "A pathology of bottom-up hill-climbing in inductive rule learning.",
                "In ALT, volume 2533 of LNCS, pages 263-277.",
                "Springer, 2002. [6] A. Guerra-Hern´andez, A. ElFallah-Seghrouchni, and H. Soldano.",
                "Learning in BDI multi-agent systems.",
                "In CLIMA IV, volume 3259, pages 218-233.",
                "Springer Verlag, 2004. [7] M. Henniche.",
                "Mgi: an incremental bottom-up algorithm.",
                "In IEEE Aust. and New Zealand Conference on Intelligent Information Systems, pages 347-351, 1994. [8] T.-S. Lim, W.-Y.",
                "Loh, and Y.-S. Shih.",
                "A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms.",
                "Machine Learning, 40(3):203-228, 2000. [9] M. A. Maloof and R. S. Michalski.",
                "Incremental learning with partial instance memory.",
                "Artif.",
                "Intell., 154(1-2):95-126, 2004. [10] P. J. Modi and W.-M. Shen.",
                "Collaborative multiagent learning for classification tasks.",
                "In AGENTS 01, pages 37-38.",
                "ACM Press, 2001. [11] S. Onta˜non and E. Plaza.",
                "Recycling data for multi-agent learning.",
                "In ICML 05, pages 633-640.",
                "ACM Press, 2005. [12] J. R. Quinlan.",
                "Induction of decision trees.",
                "Machine Learning, 1(1):81-106, 1986. [13] U. R¨uckert and S. Kramer.",
                "Towards tight bounds for rule learning.",
                "In ICML 04 (International conference on Machine learning), page 90, New York, NY, USA, 2004.",
                "ACM Press. [14] J. Wang and L. Gasser.",
                "Mutual online concept learning for multiple agents.",
                "In AAMAS, pages 362-369.",
                "ACM Press, 2002. [15] G. Weiß and S. Sen, editors.",
                "Adaption and Learning in Multi-Agent Systems, volume 1042 of Lecture Notes in Computer Science.",
                "Springer, 1996. [16] I. H. Witten and E. Frank.",
                "Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.",
                "Morgan Kaufmann, October 1999.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 171"
            ],
            "original_annotated_samples": [
                "The same kind of phenomenon have been observed with methods dedicated to hard boolean problems [4]. 4.2 MAS <br>synchronization</br> Here we consider that n single agents learn without interactions and at a given time start interacting thus forming a MAS.",
                "By comparing the single agent curve and the synchronized 10-MAS, we can observe that after the beginning of the <br>synchronization</br>, that is at 125 examples, accuracies are identical.",
                "Note that this <br>synchronization</br> happens naturally in all situations where agents have, for some reason, a divergence between their hypothesis and the system memory.",
                "In mutual online concept learning [14] the agents converge to a unique hypothesis, but each agent produces examples from its own concept representation, thus resulting in a kind of <br>synchronization</br> rather than in pure concept learning. 170 The Sixth Intl."
            ],
            "translated_annotated_samples": [
                "El mismo tipo de fenómeno se ha observado con métodos dedicados a problemas booleanos difíciles [4]. 4.2 Sincronización de MAS En este caso consideramos que n agentes individuales aprenden sin interacciones y en un momento dado comienzan a interactuar, formando así un MAS.",
                "Al comparar la curva del agente individual con la del 10-MAS sincronizado, podemos observar que después del inicio de la <br>sincronización</br>, es decir, en 125 ejemplos, las precisiones son idénticas.",
                "Ten en cuenta que esta <br>sincronización</br> ocurre de forma natural en todas las situaciones en las que los agentes tienen, por alguna razón, una divergencia entre su hipótesis y la memoria del sistema.",
                "En el aprendizaje de conceptos en línea mutuo, los agentes convergen hacia una hipótesis única, pero cada agente produce ejemplos desde su propia representación del concepto, lo que resulta en una especie de <br>sincronización</br> en lugar de un aprendizaje de conceptos puro. 170 The Sixth Intl."
            ],
            "translated_text": "SMILE: Aprendizaje Incremental Multiagente de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av. del presidente Kennedy, 75116 París Henry Soldano LIPN, UMR 7030 CNRS, Universidad Paris-Norte, 99 Av. J-B Clement, 93430, Villetaneuse RESUMEN Este artículo trata sobre el problema del aprendizaje colaborativo en un sistema multiagente. Aquí cada agente puede actualizar de forma incremental sus creencias B (la representación del concepto) para que se mantenga consistente con el conjunto completo de información K (los ejemplos) que ha recibido del entorno u otros agentes. Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo lograr que, en cualquier momento, una misma representación conceptual consistente esté presente en cada agente. El protocolo correspondiente se aplica al aprendizaje supervisado de conceptos. El método resultante SMILE (que significa Sound Multiagent Incremental LEarning) se describe y experimenta aquí. Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de múltiples agentes que por un solo agente. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de conceptos; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistema multiagente Términos Generales Experimentación, Algoritmos, Medición, Rendimiento 1. INTRODUCCIÓN Este artículo trata sobre el problema del aprendizaje colaborativo de conceptos en un sistema multiagente. [6] introduce una caracterización del aprendizaje en un sistema multiagente según el nivel de conciencia de los agentes. En el nivel 1, los agentes aprenden ∗El autor principal de este artículo es un estudiante. en el sistema sin tener en cuenta la presencia de otros agentes, excepto a través de la modificación que traen al entorno con sus acciones. El nivel 2 implica una interacción directa entre los agentes, ya que pueden intercambiar mensajes para mejorar su aprendizaje. El nivel 3 requeriría que los agentes tengan en cuenta las competencias de otros agentes y sean capaces de aprender observando el comportamiento de los otros agentes (considerándolos como entidades independientes y no como parte indeterminada del entorno como en el nivel 1). En este artículo nos enfocamos en el nivel 2, estudiando la interacción directa entre los agentes involucrados en un proceso de aprendizaje. Cada agente se asume capaz de aprender de forma incremental a partir de los datos que recibe, lo que significa que cada agente puede actualizar su conjunto de creencias B para mantenerlo consistente con el conjunto completo de información K que ha recibido del entorno o de otros agentes. En tal caso, diremos que es a-inconsistente. Aquí, el conjunto de creencias B representa conocimiento hipotético que por lo tanto puede ser revisado, mientras que el conjunto de información K representa conocimiento cierto, compuesto por observaciones y hechos no revisables. Además, suponemos que al menos una parte Bc de las creencias de cada agente es común a todos los agentes y debe mantenerse de esa manera. Por lo tanto, una actualización de este conjunto común Bc por parte del agente r debe provocar una actualización de Bc para toda la comunidad de agentes. Nos lleva a definir cuál es la mas-consistencia de un agente con respecto a la comunidad. El proceso de actualización de las creencias de la comunidad cuando uno de sus miembros recibe nueva información puede entonces definirse como el proceso de mantenimiento de la consistencia que garantiza que cada agente en la comunidad permanecerá más consistente. Este proceso de mantenimiento de la mas-consistencia de un agente al recibir nueva información le otorga el rol de aprendiz e implica la comunicación con otros agentes que actúan como críticos. Sin embargo, los agentes no están especializados y a su vez pueden ser aprendices o críticos, ninguno de ellos está limitado a un rol específico. Las piezas de información se distribuyen entre los agentes, pero pueden ser redundantes. No hay memoria central. El trabajo descrito aquí tiene su origen en un trabajo anterior sobre el aprendizaje en un sistema multiagente intencional utilizando un formalismo BDI [6]. En ese trabajo, los agentes tenían planes, cada uno de ellos asociado con un contexto que define en qué condiciones puede ser activado. Los planes (cada uno con su propio contexto) eran comunes a todo el conjunto de agentes en la comunidad. Los agentes tuvieron que adaptar su plan en función del contexto, dependiendo del fracaso o éxito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo a otros agentes ejemplos (éxitos o fracasos de planes). Sin embargo, este trabajo carecía de un protocolo de aprendizaje colectivo que permitiera una verdadera autonomía del sistema multiagente. El estudio de dicho protocolo es el objeto del presente artículo. En la sección 2 definimos formalmente la mas-consistencia de un mecanismo de actualización para todo el MAS y proponemos un mecanismo de actualización genérico demostrado que es mas consistente. En la sección 3 describimos SMILE, un aprendiz de conceptos multiagente incremental que aplica nuestro mecanismo de actualización mas consistente para el aprendizaje colaborativo de conceptos. La sección 4 describe varios experimentos sobre SMILE y discute varios problemas, incluyendo cómo varían la precisión y la simplicidad de la hipótesis actual al comparar el aprendizaje de un solo agente y el aprendizaje de múltiples agentes. En la sección 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la sección 6 discutiendo investigaciones adicionales sobre el aprendizaje más consistente. MODELO FORMAL 2.1 Definiciones y marco En esta sección, presentamos una formulación general del aprendizaje incremental colectivo en un sistema cognitivo de múltiples agentes. Representamos un MAS como un conjunto de agentes r1, ..., rn. Cada agente ri tiene un conjunto de creencias Bi que consiste en todo el conocimiento revisable que posee. Parte de estos conocimientos deben ser compartidos con otros agentes. La parte de Bi que es común a todos los agentes se denota como BC. Esta parte común provoca una dependencia entre los agentes. Si un agente ri actualiza su conjunto de creencias Bi a Bi, cambiando en el proceso BC en BC, entonces todos los demás agentes rk deben actualizar su conjunto de creencias Bk a Bk para que BC ⊆ Bk. Además, cada agente ri ha almacenado cierta información Ki. Suponemos que alguna propiedad de consistencia Cons(Bi, Ki) puede ser verificada por el agente mismo entre sus creencias Bi y su información Ki. Como se dijo antes, Bi representa el conocimiento que podría ser revisado, mientras que Ki representa hechos observados, considerados verdaderos, y que posiblemente puedan contradecir a Bi. Definición 1. a-consistencia de un agente Un agente ri es a-consistente si Cons(Bi, Ki) es verdadero. Ejemplo 1. El agente r1 tiene un conjunto de planes que se encuentran en la parte común BC de B1. Cada plan P tiene un contexto desencadenante d(P) (que actúa como una precondición) y un cuerpo. Alguna pieza de información k podría ser el plan P, desencadenado en la situación s, ha fallado a pesar de que s es una instancia de d(P). Si esta pieza de información se agrega a K1, entonces el agente r1 ya no es a-consistente: Cons(B1, K1 ∪ k) es falso. También queremos definir alguna noción de consistencia para todo el MAS dependiendo de los conjuntos de creencias e información de sus elementos constituyentes. Primero definiremos la consistencia de un agente ri con respecto a su conjunto de creencias Bi y su propio conjunto de información Ki junto con todos los conjuntos de información K1...Kn de los otros agentes del MAS. Simplemente lo haremos considerando cuál sería la a-consistencia del agente si tuviera la información de todos los demás agentes. Llamamos a esta noción la mas-consistencia: Definición 2. Un agente ri es mas-consistente si Cons(Bi, Ki ∪ K) es verdadero, donde K = ∪j∈{1,..,n}−{i}Kj 1 es el conjunto de toda la información de los otros agentes del MAS. 1 Lo notaremos como ∪ Kj cuando el contexto sea similar. Ejemplo 2. Usando el ejemplo anterior, supongamos que la pieza de información k está incluida en la información K2 del agente r2. Si la pieza de información no se transmite a r1, y por lo tanto no se agrega a K1, r1 permanece a-consistente. Sin embargo, r1 no es tan consistente como k en el conjunto K de toda la información del MAS. La consistencia global del MAS es simplemente la mas-consistencia de todos sus agentes. Definición 3. La consistencia de un MAS A MAS r1,...,rn es consistente si todos sus agentes ri son masconsistentes. Ahora definimos las propiedades requeridas para un mecanismo de revisión M que actualiza a un agente ri cuando recibe una pieza de información k. En lo siguiente, supondremos que: • La actualización siempre es posible, es decir, un agente siempre puede modificar su conjunto de creencias Bi para recuperar su a-consistencia. Diremos que cada agente es localmente eficiente. • Considerando dos conjuntos de información Cons(Bi, K1) y Cons(Bi, K2), también tenemos Cons(Bi, K1 ∪ K2). Es decir, la a-consistencia de los agentes es aditiva. • Si una pieza de información k relacionada con el conjunto común BC es consistente con un agente, es consistente con todos los agentes: para todos los pares de agentes (ri, rj) tales que Cons(Bi, Ki) y Cons(Bj, Kj) son verdaderos, tenemos, para toda pieza de información k: Cons(Bi, Ki ∪ k) si y solo si Cons(Bj, Kj ∪ k). En tal caso, diremos que el MAS es coherente. Esta última condición simplemente significa que el conjunto de creencias común BC es independiente de las posibles diferencias entre los conjuntos de creencias Bi de cada agente ri. En el caso más simple, B1 = ... = Bn = BC. M también será visto como un mecanismo de aprendizaje incremental y representado como una aplicación que cambia Bi en Bi. En lo siguiente, anotaremos ri(Bi, Ki) para ri cuando sea útil. Definición 4. a-consistencia de una revisión Un mecanismo de actualización M es a-consistente si, para cualquier agente ri y cualquier pieza de información k que llegue a ri, la a-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki) a-consistente ⇒ ri(Bi, Ki) a-consistente, donde Bi = M(Bi) y Ki = Ki ∪ k es el conjunto de toda la información de otros agentes del MAS. De la misma manera, definimos la mas-consistencia de un mecanismo de revisión como la a-consistencia de este mecanismo si los agentes disponen de toda la información en el MAS. En lo siguiente, anotaremos, si es necesario, ri(Bi, Ki, K) para el agente ri en el MAS r1 . . . rn. Definición 5. mas-consistencia de una revisión Un mecanismo de actualización Ms es mas-consistente si para todo agente ri y toda pieza de información k que llega a ri, la mas-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki, K) más-consistente ⇒ ri(Bi, Ki, K) más-consistente, donde Bi = Ms(Bi), Ki = Ki ∪ k, y K = ∪Kj es el conjunto de toda la información del MAS. El Sexto Internacional. En última instancia, cuando un agente aplica un mecanismo mas-consistente al recibir una nueva pieza de información, un efecto secundario deseable del mecanismo debería ser que todos los demás agentes permanezcan mas-consistentes después de cualquier modificación de la parte común BC, es decir, el MAS en sí mismo debería volver a ser consistente. Esta propiedad se define de la siguiente manera: Definición 6. La fuerte mas-consistencia de un mecanismo de actualización. Un mecanismo de actualización Ms es fuertemente mas-consistente si - Ms es mas-consistente, y - la aplicación de Ms por un agente preserva la consistencia del MAS. 2.2 Un mecanismo de actualización fuertemente mas-consistente. La idea general es que, dado que la información está distribuida entre todos los agentes del MAS, debe haber alguna interacción entre el agente aprendiz y los demás agentes en un mecanismo de actualización fuertemente mas-consistente Ms. Para garantizar su mas-consistencia, Ms estará constituido por aplicaciones reiteradas por parte del agente aprendiz ri de un mecanismo interno a-consistente M, seguido por algunas interacciones entre ri y los otros agentes, hasta que ri recupere su mas-consistencia. Describimos a continuación un mecanismo, primero con una descripción de una interacción, luego una iteración y finalmente una declaración de la condición de terminación del mecanismo. El mecanismo es activado por un agente ri al recibir una pieza de información k que interrumpe la mas-consistencia. Tomaremos M(Bi) como el conjunto de creencias del agente aprendiz ri después de una actualización, BC la parte común modificada por ri, y Bj el conjunto de creencias de otro agente rj inducido por la modificación de su parte común BC en BC. Una interacción I(ri, rj) entre el agente aprendiz ri y otro agente rj, actuando como crítico, está constituida por los siguientes pasos: • el agente ri envía la actualización BC de la parte común de sus creencias. Habiendo aplicado su mecanismo de actualización, ri es a-consistente. • El agente rj verifica la modificación Bj de sus creencias inducida por la actualización BC. Si esta modificación conserva su a-consistencia, rj adopta esta modificación. El agente rj envía ya sea una aceptación de BC o una negación junto con una (o más) pieza(s) de información k tal que Cons(Bj, k) es falso. Una iteración de Ms estará compuesta por: • la recepción por parte del agente aprendiz ri de una pieza de información y la actualización M(Bi) restaurando su consistencia • un conjunto de interacciones I(ri, rj) (en las cuales varios agentes críticos posiblemente puedan participar). Si al menos una pieza de información k es transmitida a ri, la adición de k necesariamente hará que ri sea inconsistente y entonces ocurrirá una nueva iteración. Este mecanismo termina cuando ningún agente puede proporcionar tal pieza de información k. Cuando es el caso, se restaura la masconsistencia del agente aprendiz ri. Proposición 1. Dejen que r1,...,rn sea un MAS consistente en el que el agente ri recibe una pieza de información k que rompe su consistencia, y M sea un mecanismo interno de actualización a-consistente. El mecanismo de actualización descrito anteriormente por Ms es altamente mas-consistente. Prueba. La prueba se deriva directamente de la descripción del mecanismo. Este mecanismo asegura que cada vez que un agente recibe un evento, su mas-consistencia será restaurada. Como los otros agentes adoptan la actualización final BC, todos son mas-coherentes y el MAS es coherente. Por lo tanto, Ms es un mecanismo de actualización fuertemente consistente. En el mecanismo descrito anteriormente, el agente aprendiz es el único que recibe y memoriza información durante la ejecución del mecanismo. Se asegura de que Ms termine. Las piezas de información transmitidas por otros agentes y memorizadas por el agente aprendiz son redundantes, ya que ya están presentes en el MAS, más precisamente en la memoria de los agentes críticos que las transmitieron. Se debe tener en cuenta que el mecanismo propuesto por la Sra. aquí no indica explícitamente el orden ni el alcance de las interacciones. Consideraremos en lo siguiente que la propuesta de modificación BC se envía secuencialmente a los diferentes agentes (mecanismo síncrono). Además, la respuesta de un agente crítico solo contendrá una pieza de información inconsistente con la modificación propuesta. Diremos que la respuesta del agente es mínima. Este mecanismo, siendo sincrónico con una respuesta mínima, minimiza la cantidad de información transmitida por los agentes. Ahora lo ilustraremos en el caso del aprendizaje de conceptos multiagente. 3. APRENDIZAJE INCREMENTAL DE MÚLTIPLES AGENTES 3.1 La tarea de aprendizaje Experimentamos el mecanismo propuesto anteriormente en el caso del aprendizaje conceptual MAS incremental. Aquí consideramos un lenguaje de hipótesis en el cual una hipótesis es una disyunción de términos. Cada término es una conjunción de átomos de un conjunto A. Un ejemplo está representado por una etiqueta + o − y una descripción 2 compuesta por un subconjunto de átomos e ⊆ A. Un término abarca un ejemplo si sus átomos constituyentes están incluidos en el ejemplo. Una hipótesis abarca un ejemplo si uno de sus términos lo abarca. Esta representación se utilizará a continuación para aprender fórmulas booleanas. Los literales negativos se representan aquí mediante átomos adicionales, como not − a. La fórmula booleana f = (a ∧ b) ∨ (b ∧ ¬c) se escribirá entonces como (a ∧ b) ∨ (b ∧ no − c). Un ejemplo positivo de f, como {no − a, b, no − c}, representa un modelo para f. 3.2 Proceso de aprendizaje incremental El proceso de aprendizaje es un mecanismo de actualización que, dado una hipótesis actual H, una memoria E = E+ ∪ E− llenada con los ejemplos recibidos previamente, y un nuevo ejemplo positivo o negativo e, produce una nueva hipótesis actualizada. Antes de esta actualización, la hipótesis dada es completa, lo que significa que cubre todos los ejemplos positivos de E+, y 2 Cuando no haya posibilidad de confusión, la palabra ejemplo se utilizará para referirse al par (etiqueta, descripción) así como a la descripción sola. 166 La Sexta Conferencia Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) es coherente, lo que significa que no cubre ningún ejemplo negativo de E−. Después de la actualización, la nueva hipótesis debe ser completa y coherente con el nuevo estado de memoria E ∪ {e}. Describimos a continuación nuestro mecanismo de actualización de agente único, inspirado en un trabajo previo sobre aprendizaje incremental[7]. En lo siguiente, una hipótesis H para la fórmula objetivo f es una lista de términos h, cada uno de ellos siendo una conjunción de átomos. H es coherente si todos los términos h son coherentes, y H es completo si cada elemento de E+ está cubierto por al menos un término h de H. Cada término es, por construcción, la lgg (generalización general menos general) de un subconjunto de instancias positivas {e1, ..., en}, es decir, el término más específico que cubre {e1, ..., en}. El operador lgg se define considerando ejemplos como términos, por lo que denotamos como lgg(e) al término más específico que cubre e, y como lgg(h, e) al término más específico que es más general que h y que cubre e. Restringir el término a lgg es la base de muchos algoritmos de aprendizaje de abajo hacia arriba (por ejemplo [5]). En la tipología propuesta por [9], nuestro mecanismo de actualización es un aprendiz incremental con memoria completa de instancias: el aprendizaje se realiza mediante actualizaciones sucesivas y se almacenan todos los ejemplos. El mecanismo de actualización depende de la hipótesis en curso H, los ejemplos en curso E+ y E−, y el nuevo ejemplo e. Hay tres casos posibles: • e es positivo y H cubre e, o e es negativo y H no cubre e. No se necesita actualización, H ya es completo y coherente con E ∪ {e}. • e es positivo y H no cubre e: e se denota como un contraejemplo positivo de H. Luego buscamos generalizar a su vez los términos h de H. Tan pronto como se encuentre una generalización correcta h = lgg(h, e), h reemplaza a h en H. Si hay un término que es menos general que h, se descarta. Si ninguna generalización es correcta (es decir, coherente), H ∪ lgg(e) reemplaza a H. • e es negativo y H cubre e: e se denota como un contraejemplo negativo de H. Cada término h que cubre e es entonces descartado de H y reemplazado por un conjunto de términos {h1, ...., hn} que, en su totalidad, es coherente con E− ∪ {e} y que cubre los ejemplos de E+ no cubiertos por H − {h}. Los términos de la hipótesis final H que son menos generales que otros son descartados de H. Ahora describiremos el caso en el que e = e− es un ejemplo negativo cubierto. Las siguientes funciones se utilizan aquí: • coveredOnlyBy(h, E+) da el subconjunto de E+ cubierto por h y ningún otro término de H. • bestCover(h1, h2) da h1 si h1 cubre más ejemplos de uncoveredPos que h2, de lo contrario da h2. • covered(h) da los elementos de uncoveredPos cubiertos por h. // Especialización de cada h cubriendo e− para cada h de H cubriendo e− hacer H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= átomos que no están ni en e− ni en h mientras (uncoveredPos = ∅) hacer // buscando la mejor especialización de h hc=h best=⊥ // ⊥ no cubre ningún ejemplo para cada a de Ar hacer hc= h ∧ a best = bestCover(hc, best) finpara Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) finmientras finpara Los términos de H que son menos generales que otros son descartados. Ten en cuenta que este mecanismo tiende tanto a hacer una actualización mínima de la hipótesis actual como a minimizar el número de términos en la hipótesis, en particular descartando términos menos generales que otros después de actualizar una hipótesis. 3.3 Aprendizaje colectivo Si H es la hipótesis actual, Ei es la memoria actual de ejemplos del agente ri y E es el conjunto de todos los ejemplos recibidos por el sistema, la notación de la sección 2 se convierte en Bi = BC = H, Ki = Ei y K = E. Cons(H, Ei) establece que H es completo y coherente con Ei. En tal caso, ri es a-consistente. La pieza de información k recibida por el agente ri es aquí simplemente un ejemplo e junto con su etiqueta. Si e es tal que la hipótesis actual H no es completa ni coherente con Ei ∪ {e}, e contradice a H: ri se vuelve a-inconsistente, y por lo tanto el MAS ya no es consistente. La actualización de una hipótesis cuando llega un nuevo ejemplo es un mecanismo a-consistente. Siguiendo la proposición 1, este mecanismo puede ser utilizado para producir un mecanismo fuerte mas-consistente: al recibir un nuevo ejemplo en el MAS por un agente r, posiblemente se necesite una actualización y, después de un conjunto de interacciones entre r y los otros agentes, resulta en una nueva hipótesis compartida por todos los agentes y que restaura la consistencia del MAS, es decir, que es completa y coherente con el conjunto ES de todos los ejemplos presentes en el MAS. Es claro que al minimizar el número de modificaciones de hipótesis, este mecanismo sincrónico y minimalista reduce el número de ejemplos recibidos por el aprendiz de otros agentes, y por ende, el número total de ejemplos almacenados en el sistema. 4. EXPERIMENTOS En lo siguiente, aprenderemos una fórmula booleana que es una prueba difícil para el método de aprendizaje: el 11-multiplexor (ver [4]). Se refiere a 3 atributos booleanos de dirección a0, a1, a2 y 8 atributos booleanos de datos d0, ..., d7. La fórmula f11 se cumple si el número codificado por los 3 atributos de dirección es el número de un atributo de datos cuyo valor es 1. Su fórmula es la siguiente: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0). Hay 2048 = 211 posibles ejemplos, la mitad de los cuales son positivos (lo que significa que satisfacen f11) mientras que la otra mitad es negativa. Un experimento suele estar compuesto por 50 pruebas. Cada ejecución corresponde a una secuencia de 600 ejemplos que son aprendidos de forma incremental por un Sistema Multiagente con n agentes. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 167 (n-MAS). Un número de variables como la precisión (es decir, la frecuencia de clasificación correcta de un conjunto de ejemplos no vistos), el tamaño de la hipótesis (es decir, el número de términos en la fórmula actual) o el número de ejemplos almacenados, se registra cada vez que el sistema recibe 25 ejemplos durante esas ejecuciones. En el protocolo que se utiliza aquí, un nuevo ejemplo se envía a un agente aleatorio cuando el MAS es consistente. El siguiente ejemplo será enviado a su vez a otro agente cuando la consistencia del MAS haya sido restaurada. De esta manera simulamos una especie de aprendizaje lento: la frecuencia de llegada de ejemplos es lenta en comparación con el tiempo que lleva una actualización. 4.1 Eficiencia del aprendizaje conceptual en MAS 4.1.1 Tiempo de ejecución Discutimos brevemente aquí el tiempo de ejecución del aprendizaje en el MAS. Se debe tener en cuenta que todo el conjunto de acciones e interacciones en el MAS se simula en un solo procesador. La Figura 1 muestra que el tiempo depende linealmente del número de agentes. Al final de la parte más activa del aprendizaje (200 ejemplos), un 16MAS ha tomado 4 veces más tiempo de aprendizaje que un 4-MAS. Este tiempo de ejecución representa el conjunto completo de aprendizaje y la Figura 1: Tiempo de ejecución de un n-MAS (desde n = 2 en la parte inferior hasta n = 20 en la parte superior). actividad de comunicación y sugiere el costo de mantener una hipótesis de aprendizaje consistente en un MAS compuesto por agentes autónomos. 4.1.2 Redundancia en la memoria del MAS Estudiamos ahora la distribución de los ejemplos en la memoria del MAS. La redundancia se escribe RS = nS/ne, donde nS es el número total de ejemplos almacenados en el MAS, que es la suma de los tamaños de las memorias de ejemplos de los agentes Ei, y ne es el número total de ejemplos recibidos del entorno en el MAS. En la figura 2, comparamos las redundancias en MAS de 2 a 20 agentes. Hay un pico que se mueve lentamente de 80 a 100 ejemplos, que representa la cantidad de ejemplos para los cuales el aprendizaje es más activo. Para 20 agentes, la redundancia máxima no es más de 6, lo cual es mucho menor que el valor teórico máximo de 20. Ten en cuenta que cuando el aprendizaje se vuelve menos activo, la redundancia tiende hacia su valor mínimo 1: cuando ya no hay más actualizaciones, los ejemplos son solo la Figura 2: Redundancia de ejemplos almacenados en un nMAS (de n = 2 en la parte inferior a n = 20 en la parte superior) almacenados por el agente que los recibe. Un n-MAS selecciona una solución más simple que un solo agente. El mecanismo propuesto tiende a minimizar el número de términos en la hipótesis seleccionada. Durante el aprendizaje, el tamaño de la hipótesis actual crece más allá del óptimo, y luego disminuye cuando el MAS converge. En el banco de pruebas Multiplexer 11, el número óptimo de términos es 8, pero también existen fórmulas equivalentes con más términos. Es interesante notar que en este caso el 10-MAS converge hacia una solución exacta más cercana al número óptimo de términos (en este caso 8) (ver Figura 3). Después de haber presentado 1450 ejemplos, tanto el 1-MAS como el 10-MAS han aprendido exactamente el concepto (las precisiones respectivas son 0.9999 y 1), pero el agente individual expresa en promedio el resultado como una DNF de 11.0 términos, mientras que el 10-MAS lo expresa como una DNF de 8.8 términos. Sin embargo, para algunas otras funciones booleanas encontramos que durante el aprendizaje, 1-MAS siempre produce hipótesis más grandes que 10-MAS, pero que ambos MAS convergen a hipótesis con resultados de tamaño similar. 4.1.4 Un n-MAS es más preciso que un agente único. La Figura 4 muestra la mejora proporcionada por un MAS con n agentes en comparación con un agente único. Esta mejora no era especialmente esperada, porque ya sea que tengamos uno o n agentes, cuando se le dan N ejemplos al MAS, tiene acceso a la misma cantidad de información, mantiene solo una hipótesis en curso y utiliza el mismo algoritmo básico de revisión cada vez que un agente tiene que modificar la hipótesis actual. Ten en cuenta que si la precisión de los MAS de 1, 2, 4 y 10 es significativamente diferente, mejorando a medida que aumenta el número de agentes, no hay una diferencia clara más allá de este punto: la curva de precisión de los MAS de 100 agentes es muy similar a la de los MAS de 10 agentes. 4.1.4.1 Fórmulas booleanas. Para evaluar esta mejora de precisión, hemos experimentado nuestro protocolo en otros problemas de aprendizaje de funciones booleanas. Como en el caso del Multiplexor-11, estas funciones 168 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 3: Tamaño de la hipótesis construida por 1 y 10MAS: el caso M11. Figura 4: Precisión de un n-MAS: el caso M11 (de abajo hacia arriba, n = 1, 2, 4, 10, 100). Se aprenden en forma de DNF3 más o menos sintácticamente complejos (es decir, con más o menos términos conjuntivos en la DNF), pero también son más o menos difíciles de aprender, ya que puede ser difícil encontrar su camino en el espacio de hipótesis para alcanzarlos. Además, la presencia en la descripción de atributos irrelevantes (es decir, atributos que no pertenecen al DNF objetivo) hace que el problema sea más difícil. Los siguientes problemas han sido seleccionados para experimentar con nuestro protocolo: (i) el multiplexor-11 con 9 atributos irrelevantes: M11 9, (ii) el multiplexor-20 M20 (con 4 bits de dirección y 16 bits de datos), (iii) un problema de paridad difícil (ver [4]) el Xorp m: debe haber un número impar de bits con valor 1 en los primeros p atributos para que la instancia sea positiva, los p bits restantes son irrelevantes, y (iv) una fórmula DNF simple (a ∧ b ∧ c) ∨ (c ∧ d ∧ e) ∨ (e ∧ f ∧ g) ∧ (g ∧ h ∧ i) con 19 atributos irrelevantes. La siguiente tabla resume alguna información sobre estos problemas, proporcionando el número total de atributos, incluidos los irrelevantes, el número de atributos irrelevantes en Forma Normal Disyuntiva 3, el número mínimo de términos de la DNF correspondiente, y el número de ejemplos de aprendizaje utilizados. Pb att. irre. att. términos ex. A continuación se presentan los resultados de precisión de nuestro mecanismo de aprendizaje con un solo agente y un MAS de 10 agentes, junto con los resultados de dos algoritmos estándar implementados con el entorno de aprendizaje WEKA[16]: JRip (una implementación de RIPPER[2]) e Id3[12]. Para los experimentos con JRip e Id3, medimos la precisión media en 50 pruebas, separando aleatoriamente los ejemplos en un conjunto de aprendizaje y un conjunto de prueba cada vez. Los parámetros de JRip e Id3 son los predeterminados, excepto que JRip se utiliza sin poda. La siguiente tabla muestra los resultados: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 Es claro que los problemas difíciles se resuelven mejor con más agentes (ver por ejemplo xor5 15). Creemos que estos beneficios, que pueden ser importantes con un número creciente de agentes, se deben al hecho de que cada agente realmente memoriza solo parte del número total de ejemplos, y esta parte es seleccionada en parte por otros agentes como contraejemplos, lo que provoca un mayor número de actualizaciones de hipótesis actuales y, por lo tanto, una mejor exploración del espacio de hipótesis. 4.1.4.2 Problemas de base de datos de ML. También realizamos experimentos con algunos problemas no booleanos. Consideramos solo problemas de dos clases (positivo/negativo), tomados de la base de datos de problemas de aprendizaje de UCIs. En todos estos problemas, los ejemplos se describen como un vector de pares (atributo, valor). Los dominios de valor pueden ser booleanos, numéricos (conjunto totalmente ordenado) o nominales (conjunto no ordenado). Un conjunto adecuado de átomos A debe ser constituido para cada problema. Por ejemplo, si a es un atributo numérico, definimos como máximo k umbrales si, dando k+1 intervalos de densidad uniforme. Por lo tanto, cada umbral distintivo si da dos átomos, uno ≤ si y otro > si. En nuestros experimentos, tomamos un número máximo de umbral k = 8. Por ejemplo, en el caso del problema de iono, había 34 atributos numéricos, y una instancia se describe con 506 átomos. A continuación se presentan los resultados de precisión de nuestro sistema junto con los resultados anteriores. La columna Nb ex. se refiere al 4. La probabilidad de que el valor de a esté en cualquier intervalo es constante. El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 169 número de ejemplos utilizados para el aprendizaje5. La columna (1) representa los valores de precisión mínima y máxima para los treinta y tres clasificadores probados en [8]. La columna (2) representa los resultados de [13], donde se comparan varios métodos de aprendizaje con métodos de aprendizaje en conjunto utilizando conjuntos de clasificadores ponderados. La columna S-1 y S-10 dan la precisión de SMILE con 1 y 10 agentes, respectivamente. Esta tabla muestra que el algoritmo incremental correspondiente al caso de un solo agente, proporciona resultados honorables en relación a los métodos clásicos no incrementales que utilizan hipótesis más grandes y complejas. En algunos casos, hay una mejora en la precisión con un MAS de 10 agentes. Sin embargo, con datos de referencia de este tipo, que suelen ser ruidosos, la dificultad no radica realmente en la forma en que se explora el espacio de búsqueda, por lo que la mejora observada no siempre es significativa. El mismo tipo de fenómeno se ha observado con métodos dedicados a problemas booleanos difíciles [4]. 4.2 Sincronización de MAS En este caso consideramos que n agentes individuales aprenden sin interacciones y en un momento dado comienzan a interactuar, formando así un MAS. El propósito es observar cómo los agentes aprovechan la colaboración cuando parten de diferentes estados de creencias y memorias. En esta sección comparamos un 1-MAS, un 10-MAS (ref) y un 10-MAS (100sync) cuyos agentes no se comunicaron durante la llegada de los primeros 100 ejemplos (10 por agentes). Las tres curvas de precisión se muestran en la figura 5. Al comparar la curva del agente individual con la del 10-MAS sincronizado, podemos observar que después del inicio de la <br>sincronización</br>, es decir, en 125 ejemplos, las precisiones son idénticas. Esto era esperado ya que tan pronto como un ejemplo e recibido por el MAS contradice la hipótesis actual del agente ra que lo recibe, este agente realiza una actualización y su nueva hipótesis es propuesta a los otros agentes para su crítica. Por lo tanto, este primer ejemplo contradictorio lleva al MAS a alcanzar coherencia en relación con todo el conjunto de ejemplos presentes en la memoria de los agentes. Una mayor precisión, correspondiente a un 10-MAS, se obtiene más tarde, a partir del ejemplo 175. En otras palabras, el beneficio de una mejor exploración del espacio de investigación se obtiene ligeramente más tarde en el proceso de aprendizaje. Ten en cuenta que esta <br>sincronización</br> ocurre de forma natural en todas las situaciones en las que los agentes tienen, por alguna razón, una divergencia entre su hipótesis y la memoria del sistema. Esto incluye la fusión de dos MAS en una sola o la llegada de nuevos agentes en un MAS existente. 4.3 Experimentos sobre el aprendizaje asincrónico: el efecto de un gran flujo de datos. Para ttt y kr-vs-kp, nuestro protocolo no utilizó más de 574 y 958 ejemplos de aprendizaje respectivamente, por lo que colocamos otro número en la columna. Figura 5: Precisión de un 1-MAS, un 10-MAS y un 10-MAS sincronizado después de 100 ejemplos. En este experimento relajamos nuestro modo de aprendizaje lento: los ejemplos se envían a una velocidad determinada al MAS. El flujo de ejemplos resultante se mide en ms−1, y representa la cantidad de ejemplos enviados al MAS cada milisegundo. Cuando el flujo es demasiado grande, el MAS no puede alcanzar la consistencia del MAS al recibir un ejemplo del entorno antes de que llegue un nuevo ejemplo. Esto significa que el proceso de actualización, iniciado por el agente r0 al recibir un ejemplo, puede estar incompleto cuando un nuevo ejemplo es recibido por r0 u otro agente r1. Como resultado, un agente crítico puede tener que enviar contraejemplos de hipótesis enviadas por varios agentes en el instante t. Sin embargo, en nuestro entorno, a medida que los agentes memorizan todos los ejemplos que reciben cuando finaliza el flujo, el MAS alcanza necesariamente consistencia MAS con respecto a todos los ejemplos recibidos hasta el momento. En nuestros experimentos, aunque la curva de aprendizaje se ralentiza durante la fase intensa de aprendizaje (correspondiente a una baja precisión de las hipótesis actuales), el MAS aún logra alcanzar una hipótesis satisfactoria más adelante, ya que hay menos contraejemplos en el flujo de ejemplos. En la Figura 6 comparamos las precisiones de dos 11-MAS respectivamente sometidos a flujos de ejemplos de diferentes tasas al aprender la fórmula M11. La curva de aprendizaje del MAS al recibir un ejemplo a una velocidad de 1/33 ms−1 casi no se ve alterada (ver Figura 4), mientras que el MAS a 1/16 ms−1 primero se ralentiza severamente antes de alcanzar al primero. 5. TRABAJOS RELACIONADOS Desde el 96 [15], se han realizado varios trabajos sobre el aprendizaje en Sistemas Multiagente, pero muy pocos sobre el aprendizaje de conceptos. En [11] el MAS realiza una forma de aprendizaje en conjunto en la que los agentes son aprendices perezosos (no se mantiene una representación explícita) y venden ejemplos inútiles a otros agentes. En [10] cada agente observa todos los ejemplos pero solo percibe una parte de su representación. En el aprendizaje de conceptos en línea mutuo, los agentes convergen hacia una hipótesis única, pero cada agente produce ejemplos desde su propia representación del concepto, lo que resulta en una especie de <br>sincronización</br> en lugar de un aprendizaje de conceptos puro. 170 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Precisión de dos sistemas multiagente asincrónicos de 11 agentes (tasas de ejemplo de 1/33ms−1 y 1/16ms−1). 6. CONCLUSIÓN Hemos presentado y experimentado un protocolo para el aprendizaje de conceptos en línea de MAS. La característica principal de este mecanismo de aprendizaje colaborativo es que mantiene una propiedad de consistencia: aunque durante el proceso de aprendizaje cada agente solo recibe y almacena, con cierta redundancia limitada, parte de los ejemplos recibidos por el MAS, en cualquier momento la hipótesis actual es consistente con todo el conjunto de ejemplos. Las hipótesis de nuestros experimentos no abordan los problemas de los MAS distribuidos, como fallos (por ejemplo, mensajes perdidos o corruptos) u otras fallas en general (crash, fallos bizantinos, etc.). Sin embargo, nuestro marco de trabajo es abierto, es decir, los agentes pueden salir del sistema o ingresar a él mientras se preserva el mecanismo de consistencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente crítico se bloquea o no responde, se garantiza la consistencia con los otros críticos (dentro de los agentes restantes). En [1], se ha aplicado un enfoque similar a los problemas de abducción en MAS: las hipótesis a mantener, dada una información incompleta, son entonces hechos o afirmaciones. El trabajo adicional se refiere en primer lugar a acoplar la inducción y la abducción para realizar un aprendizaje colaborativo de conceptos cuando los ejemplos son solo parcialmente observados por cada agente, y en segundo lugar, a investigar el aprendizaje de memoria parcial: cómo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados. Agradecimientos Estamos muy agradecidos a Dominique Bouthinon por implementar las modificaciones tardías en SMILE, facilitando mucho nuestros experimentos. Parte de este trabajo se realizó durante la visita del primer autor al Atelier De BioInformatique de la Universidad Paris VI, Francia. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En DALT-2006, mayo de 2006. [2] W. W. Cohen. Inducción de reglas rápida y efectiva. En ICML, páginas 115-123, 1995. [3] C. B. D.J. Newman, S. Hettich y C. Merz. Repositorio de bases de datos de aprendizaje automático de UCI, 1998. [4] S. Esmeir y S. Markovitch. Algoritmos basados en anticipación para la inducción en cualquier momento de árboles de decisión. En ICMLO4, páginas 257-264. Morgan Kaufmann, 2004. [5] J. F¨urnkranz. \n\nMorgan Kaufmann, 2004. [5] J. F¨urnkranz. Una patología de la escalada de colina de abajo hacia arriba en el aprendizaje inductivo de reglas. En ALT, volumen 2533 de LNCS, páginas 263-277. Springer, 2002. [6] A. Guerra-Hernández, A. ElFallah-Seghrouchni y H. Soldano. Aprendizaje en sistemas multiagente BDI. En CLIMA IV, volumen 3259, páginas 218-233. Springer Verlag, 2004. [7] M. Henniche. \n\nSpringer Verlag, 2004. [7] M. Henniche. Mgi: un algoritmo incremental de abajo hacia arriba. En la Conferencia IEEE de Australia y Nueva Zelanda sobre Sistemas de Información Inteligente, páginas 347-351, 1994. [8] T.-S. Lim, W.-Y. Loh, y Y.-S. Shih. Una comparación de la precisión de predicción, complejidad y tiempo de entrenamiento de treinta y tres algoritmos de clasificación antiguos y nuevos. Aprendizaje automático, 40(3):203-228, 2000. [9] M. A. Maloof y R. S. Michalski. Aprendizaje incremental con memoria parcial de instancias. I'm sorry, but the sentence \"Artif.\" is not a complete sentence. Can you provide more context or a complete sentence for me to translate to Spanish? Intell., 154(1-2):95-126, 2004. [10] P. J. Modi y W.-M. Shen. Aprendizaje colaborativo multiagente para tareas de clasificación. En AGENTS 01, páginas 37-38. ACM Press, 2001. [11] S. Onta˜non y E. Plaza. Reciclaje de datos para el aprendizaje multiagente. En ICML 05, páginas 633-640. ACM Press, 2005. [12] J. R. Quinlan. \n\nACM Press, 2005. [12] J. R. Quinlan. Inducción de árboles de decisión. Aprendizaje automático, 1(1):81-106, 1986. [13] U. R¨uckert y S. Kramer. Hacia límites ajustados para el aprendizaje de reglas. En ICML 04 (Conferencia Internacional sobre Aprendizaje Automático), página 90, Nueva York, NY, EE. UU., 2004. ACM Press. [14] J. Wang y L. Gasser. Aprendizaje de conceptos en línea mutuo para múltiples agentes. En AAMAS, páginas 362-369. ACM Press, 2002. [15] G. Weiß y S. Sen, editores. Adaptación y Aprendizaje en Sistemas Multiagente, volumen 1042 de las Notas de Conferencia en Ciencias de la Computación. Springer, 1996. [16] I. H. Witten y E. Frank. Minería de datos: Herramientas y técnicas prácticas de aprendizaje automático con implementaciones en Java. Morgan Kaufmann, octubre de 1999. La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 171 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "multi-agent learn": {
            "translated_key": "aprendizaje multiagente",
            "is_in_text": true,
            "original_annotated_sentences": [
                "SMILE: Sound Multi-agent Incremental LEarning ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, University Paris 6, 104, Av.",
                "du pr´esident Kennedy, 75116 Paris Henry Soldano LIPN, UMR 7030 CNRS, University Paris-Nord, 99 Av.",
                "J-B Clement, 93430, Villetaneuse ABSTRACT This article deals with the problem of collaborative learning in a multi-agent system.",
                "Here each agent can update incrementally its beliefs B (the concept representation) so that it is in a way kept consistent with the whole set of information K (the examples) that he has received from the environment or other agents.",
                "We extend this notion of consistency (or soundness) to the whole MAS and discuss how to obtain that, at any moment, a same consistent concept representation is present in each agent.",
                "The corresponding protocol is applied to supervised concept learning.",
                "The resulting method SMILE (standing for Sound Multiagent Incremental LEarning) is described and experimented here.",
                "Surprisingly some difficult boolean formulas are better learned, given the same learning set, by a Multi agent system than by a single agent.",
                "Categories and Subject Descriptors I.2.6 [Artificial Intelligence]: Learning-Concept learning; I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent system General Terms Experimentation, Algorithms, Measurement, Performance 1.",
                "INTRODUCTION This article deals with the problem of collaborative concept learning in a multi-agent system. [6] introduces a characterisation of learning in multi-agent system according to the level of awareness of the agents.",
                "At level 1, agents learn ∗The primary author of this paper is a student. in the system without taking into account the presence of other agents, except through the modification brought upon the environment by their action.",
                "Level 2 implies direct interaction between the agents as they can exchange messages to improve their learning.",
                "Level 3 would require agents to take into account the competencies of other agents, and be able to learn from observation of the other agents behaviour (while considering them as independant entities and not indetermined part of the environment as in level 1).",
                "We focus in this paper on level 2, studying direct interaction between agents involved in a learning process.",
                "Each agent is assumed to be able to learn incrementally from the data he receives, meaning that each agent can update his belief set B to keep it consistent with the whole set of information K that he has received from the environment or from other agents.",
                "In such a case, we will say that he is a-consistent.",
                "Here, the belief set B represents hypothetical knowledge that can therefore be revised, whereas the set of information K represents certain knowledge, consisting of non revisable observations and facts.",
                "Moreover, we suppose that at least a part Bc of the beliefs of each agent is common to all agents and must stay that way.",
                "Therefore, an update of this common set Bc by agent r must provoke an update of Bc for the whole community of agents.",
                "It leads us to define what is the mas-consistency of an agent with respect to the community.",
                "The update process of the community beliefs when one of its members gets new information can then be defined as the consistency maintenance process ensuring that every agent in the community will stay masconsistent.",
                "This mas-consistency maintenance process of an agent getting new information gives him the role of a learner and implies communication with other agents acting as critics.",
                "However, agents are not specialised and can in turn be learners or critics, none of them being kept to a specific role.",
                "Pieces of information are distributed among the agents, but can be redundant.",
                "There is no central memory.",
                "The work described here has its origin in a former work concerning learning in an intentional multi-agent system using a BDI formalism [6].",
                "In that work, agents had plans, each of them being associated with a context defining in which conditions it can be triggered.",
                "Plans (each of them having its own context) were common to the whole set of agents in the community.",
                "Agents had to adapt their plan contexts depending on the failure or success of executed plans, using a learning mechanism and asking other agents for examples (plans successes or failures).",
                "However this work lacked a collective learning protocol enabling a real autonomy of the multi-agent system.",
                "The study of such a protocol is the object of the present paper.",
                "In section 2 we formally define the mas-consistency of an update mechanism for the whole MAS and we propose a generic update mechanism proved to be mas consistent.",
                "In section 3 we describe SMILE, an incremental multi agent concept learner applying our mas consistent update mechanism to collaborative concept learning.",
                "Section 4 describes various experiments on SMILE and discusses various issues including how the accuracy and the simplicity of the current hypothesis vary when comparing single agent learning and mas learning.",
                "In section 5 we briefly present some related works and then conclude in section 6 by discussing further investigations on mas consistent learning. 2.",
                "FORMAL MODEL 2.1 Definitions and framework In this section, we present a general formulation of collective incremental learning in a cognitive multi agent system.",
                "We represent a MAS as a set of agents r1, ..., rn.",
                "Each agent ri has a belief set Bi consisting of all the revisable knowledge he has.",
                "Part of these knowledges must be shared with other agents.",
                "The part of Bi that is common to all agents is denoted as BC .",
                "This common part provokes a dependency between the agents.",
                "If an agent ri updates his belief set Bi to Bi, changing in the process BC into BC , all other agents rk must then update their belief set Bk to Bk so that BC ⊆ Bk.",
                "Moreover, each agent ri has stored some certain information Ki.",
                "We suppose that some consistency property Cons(Bi, Ki) can be verified by the agent itself between its beliefs Bi and its information Ki.",
                "As said before, Bi represents knowledge that might be revised whereas Ki represents observed facts, taken as being true, and which can possibly contradict Bi.",
                "Definition 1. a-consistency of an agent An agent ri is a-consistent iff Cons(Bi, Ki) is true.",
                "Example 1.",
                "Agent r1 has a set of plans which are in the common part BC of B1.",
                "Each plan P has a triggering context d(P) (which acts as a pre-condition) and a body.",
                "Some piece of information k could be plan P, triggered in situation s, has failed in spite of s being an instance of d(P).",
                "If this piece of information is added to K1, then agent r1 is not a-consistent anymore: Cons(B1, K1 ∪ k) is false.",
                "We also want to define some notion of consistency for the whole MAS depending on the belief and information sets of its constituting elements.",
                "We will first define the consistency of an agent ri with respect to its belief set Bi and its own information set Ki together with all information sets K1...Kn from the other agents of the MAS.",
                "We will simply do that by considering what would be the a-consistency of the agent if he has the information of all the other agents.",
                "We call this notion the mas-consistency: Definition 2. mas-consistency of an agent An agent ri is mas-consistent iff Cons(Bi, Ki ∪ K) is true, where K = ∪j∈{1,..,n}−{i}Kj 1 is the set of all information from other agents of the MAS. 1 We will note this ∪ Kj when the context is similar.",
                "Example 2.",
                "Using the previous example, suppose that the piece of information k is included in the information K2 of agent r2.",
                "As long as the piece of information is not transmitted to r1, and so added to K1 , r1 remains a-consistent.",
                "However, r1 is not mas-consistent as k is in the set K of all information of the MAS.",
                "The global consistency of the MAS is then simply the mas-consistency of all its agents.",
                "Definition 3.",
                "Consistency of a MAS A MAS r1,...,rn is consistent iff all its agents ri are masconsistent.",
                "We now define the required properties for a revision mechanism M updating an agent ri when it gets a piece of information k. In the following, we will suppose that: • Update is always possible, that is, an agent can always modify its belief set Bi in order to regain its a-consistency.",
                "We will say that each agent is locally efficient. • Considering two sets of information Cons(Bi, K1) and Cons(Bi, K2), we also have Cons(Bi, K1 ∪ K2).",
                "That is, a-consistency of the agents is additive. • If a piece of information k concerning the common set BC is consistent with an agent, it is consistent with all agents: for all pair of agents (ri,rj) such that Cons(Bi, Ki) and Cons(Bj, Kj) are true, we have, for all piece of information k: Cons(Bi, Ki ∪ k) iff Cons(Bj, Kj ∪ k).",
                "In such a case, we will say that the MAS is coherent.",
                "This last condition simply means that the common belief set BC is independent of the possible differences between the belief sets Bi of each agent ri.",
                "In the simplest case, B1 = ... = Bn = BC .",
                "M will also be viewed as an incremental learning mechanism and represented as an application changing Bi in Bi.",
                "In the following, we shall note ri(Bi, Ki) for ri when it is useful.",
                "Definition 4. a-consistency of a revision An update mechanism M is a-consistent iff for any agent ri and any piece of information k reaching ri, the a-consistency of this agent is preserved.",
                "In other words, iff: ri(Bi, Ki) a-consistent ⇒ ri(Bi, Ki) a-consistent, where Bi = M(Bi) and Ki = Ki ∪ k is the set of all information from other agents of the MAS.",
                "In the same way, we define the mas-consistency of a revision mechanism as the a-consistency of this mechanism should the agents dispose of all information in the MAS.",
                "In the following, we shall note, if needed, ri(Bi, Ki, K) for the agent ri in MAS r1 . . . rn.",
                "Definition 5. mas-consistency of a revision An update mechanism Ms is mas-consistent iff for all agent ri and all pieces of information k reaching ri, the masconsistency of this agent is preserved.",
                "In other words, if: ri(Bi, Ki, K) mas-consistent ⇒ ri(Bi, Ki, K) mas-consistent, where Bi = Ms(Bi), Ki = Ki ∪ k, and K = ∪Kj is the set of all information from the MAS.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 165 At last, when a mas-consistent mechanism is applied by an agent getting a new piece of information, a desirable sideeffect of the mechanism should be that all others agents remains mas-consistent after any modification of the common part BC , that is, the MAS itself should become consistent again.",
                "This property is defined as follows: Definition 6.",
                "Strong mas-consistency of a revision An update mechanism Ms is strongly mas-consistent iff - Ms is mas-consistent, and - the application of Ms by an agent preserves the consistency of the MAS. 2.2 A strongly mas-consistent update mechanism The general idea is that, since information is distributed among all the agents of the MAS, there must be some interaction between the learner agent and the other agents in a strongly mas-consistent update mechanism Ms.",
                "In order to ensure its mas-consistency, Ms will be constituted of reiterated applications by the learner agent ri of an internal a-consistent mechanism M, followed by some interactions between ri and the other agents, until ri regain its masconsistency.",
                "We describe below such a mechanism, first with a description of an interaction, then an iteration, and finally a statement of the termination condition of the mechanism.",
                "The mechanism is triggered by an agent ri upon receipt of a piece of information k disrupting the mas-consistency.",
                "We shall note M(Bi) the belief set of the learner agent ri after an update, BC the common part modified by ri, and Bj the belief set of another agent rj induced by the modification of its common part BC in BC .",
                "An interaction I(ri, rj) between the learner agent ri and another agent rj, acting as critic is constituted of the following steps: • agent ri sends the update BC of the common part of its beliefs.",
                "Having applied its update mechanism, ri is a-consistent. • agent rj checks the modification Bj of its beliefs induced by the update BC .",
                "If this modification preserve its a-consistency, rj adopts this modification. • agent rj sends either an acceptation of BC or a denial along with one (or more) piece(s) of information k such that Cons(Bj, k ) is false.",
                "An iteration of Ms will then be composed of: • the reception by the learner agent ri of a piece of information and the update M(Bi) restoring its aconsistency • a set of interactions I(ri, rj) (in which several critic agents can possibly participate).",
                "If at least one piece of information k is transmitted to ri, the addition of k will necessarily make ri a-inconsistent and a new iteration will then occur.",
                "This mechanism Ms ends when no agent can provide such a piece of information k .",
                "When it is the case, the masconsistency of the learner agent ri is restored.",
                "Proposition 1.",
                "Let r1,...,rn be a consistent MAS in which agent ri receives a piece of information k breaking its aconsistency, and M an a-consistent internal update mechanism.",
                "The update mechanism Ms described above is strongly mas-consistent.",
                "Proof.",
                "The proof directly derives from the mechanism description.",
                "This mechanism ensures that each time an agent receives an event, its mas-consistency will be restored.",
                "As the other agents all adopt the final update BC , they are all mas-consistent, and the MAS is consistent.",
                "Therefore Ms is a strongly consistent update mechanism.",
                "In the mechanism Ms described above, the learner agent is the only one that receives and memorizes information during the mechanism execution.",
                "It ensures that Ms terminates.",
                "The pieces of information transmitted by other agents and memorized by the learner agent are redundant as they are already present in the MAS, more precisely in the memory of the critic agents that transmitted them.",
                "Note that the mechanism Ms proposed here does not explicitly indicate the order nor the scope of the interactions.",
                "We will consider in the following that the modification proposal BC is sent sequentially to the different agents (synchronous mechanism).",
                "Moreover, the response of a critic agent will only contain one piece of information inconsistent with the proposed modification.",
                "We will say that the response of the agent is minimal.",
                "This mechanism Ms, being synchronous with minimal response, minimizes the amount of information transmitted by the agents.",
                "We will now illustrate it in the case of multi-agent concept learning. 3.",
                "SOUNDMULTI-AGENTINCREMENTAL LEARNING 3.1 The learning task We experiment the mechanism proposed above in the case of incremental MAS concept learning.",
                "We consider here a hypothesis language in which a hypothesis is a disjunction of terms.",
                "Each term is a conjunction of atoms from a set A.",
                "An example is represented by a tag + or − and a description 2 composed of a subset of atoms e ⊆ A.",
                "A term covers an example if its constituting atoms are included in the example.",
                "A hypothesis covers an example if one of its term covers it.",
                "This representation will be used below for learning boolean formulae.",
                "Negative literals are here represented by additional atoms, like not − a.",
                "The boolean formulae f =(a ∧ b) ∨ (b ∧ ¬c) will then be written (a ∧ b) ∨ (b ∧ not − c).",
                "A positive example of f, like {not − a, b, not − c}, represents a model for f. 3.2 Incremental learning process The learning process is an update mechanism that, given a current hypothesis H, a memory E = E+ ∪ E− filled with the previously received examples, and a new positive or negative example e, produces a new updated hypothesis.",
                "Before this update, the given hypothesis is complete, meaning that it covers all positive examples of E+ , and 2 When no confusion is possible, the word example will be used to refer to the pair (tag, description) as well as the description alone. 166 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) coherent, meaning that it does not cover any negative example of E− .",
                "After the update, the new hypothesis must be complete and coherent with the new memory state E ∪ {e}.",
                "We describe below our single agent update mechanism, inspired from a previous work on incremental learning[7].",
                "In the following, a hypothesis H for the target formula f is a list of terms h, each of them being a conjunction of atoms.",
                "H is coherent if all terms h are coherent, and H is complete if each element of E+ is covered by at least one term h of H. Each term is by construction the lgg (least general generalization) of a subset of positives instances {e1, ..., en}[5], that is the most specific term covering {e1, ..., en}.",
                "The lgg operator is defined by considering examples as terms, so we denote as lgg(e) the most specific term that covers e, and as lgg(h, e) the most specific term which is more general than h and that covers e. Restricting the term to lgg is the basis of a lot of Bottom-Up learning algorithms (for instance [5]).",
                "In the typology proposed by [9], our update mechanism is an incremental learner with full instance memory: learning is made by successive updates and all examples are stored.",
                "The update mechanism depends of the ongoing hypothesis H, the ongoing examples E+ and E− , and the new example e. There are three possible cases: • e is positive and H covers e, or e is negative and H does not cover e. No update is needed, H is already complete and coherent with E ∪ {e}. • e is positive and H does not cover e: e is denoted as a positive counterexample of H. Then we seek to generalize in turn the terms h of H. As soon as a correct generalization h = lgg(h, e) is found, h replaces h in H. If there is a term that is less general that h , it is discarded.",
                "If no generalization is correct (meaning here coherent), H ∪ lgg(e) replaces H. • e is negative and H covers e: e is denoted as a negative counterexample of H. Each term h covering e is then discarded from H and replaced by a set of terms {h1, ...., hn} that is, as a whole, coherent with E− ∪ {e} and that covers the examples of E+ uncovered by H − {h}.",
                "Terms of the final hypothesis H that are less general than others are discarded from H. We will now describe the case where e = e− is a covered negative example.",
                "The following functions are used here: • coveredOnlyBy(h, E+) gives the subset of E+ covered by h and no other term of H. • bestCover(h1, h2) gives h1 if h1 covers more examples from uncoveredPos than h2, otherwise it gives h2. • covered(h) gives the elements of uncoveredPos covered by h. // Specialization of each h covering e− for each h of H covering e− do H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= atoms that are neither in e− nor in h while (uncoveredPos = ∅) do // seeking the best specialization of h hc=h best=⊥ // ⊥ covers no example for each a of Ar do hc= h ∧ a best = bestCover(hc, best) endfor Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) endwhile endfor Terms of H that are less general than others are discarded.",
                "Note that this mechanism tends to both make a minimal update of the current hypothesis and minimize the number of terms in the hypothesis, in particular by discarding terms less general than other ones after updating a hypothesis. 3.3 Collective learning If H is the current hypothesis, Ei the current example memory of agent ri and E the set of all the examples received by the system, the notation of section 2 becomes Bi = BC = H, Ki = Ei and K = E. Cons(H, Ei) states that H is complete and coherent with Ei.",
                "In such a case, ri is a-consistent.",
                "The piece of information k received by agent ri is here simply an example e along with its tag.",
                "If e is such that the current hypothesis H is not complete or coherent with Ei ∪ {e}, e contradicts H: ri becomes a-inconsistent, and therefore the MAS is not consistent anymore.",
                "The update of a hypothesis when a new example arrives is an a- consistent mechanism.",
                "Following proposition 1 this mechanism can be used to produce a strong mas-consistent mechanism: upon reception of a new example in the MAS by an agent r, an update is possibly needed and, after a set of interactions between r and the other agents, results in a new hypothesis shared by all the agents and that restores the consistency of the MAS, that is which is complete and coherent with the set ES of all the examples present in the MAS.",
                "It is clear that by minimizing the number of hypothesis modifications, this synchronous and minimal mechanism minimize the number of examples received by the learner from other agents, and therefore, the total number of examples stored in the system. 4.",
                "EXPERIMENTS In the following, we will learn a boolean formula that is a difficult test for the learning method: the 11-multiplexer (see [4]).",
                "It concerns 3 address boolean attributes a0, a1, a2 and 8 data boolean attributes d0, ..., d7.",
                "Formulae f11 is satisfied if the number coded by the 3 address attributes is the number of a data attribute whose value is 1.",
                "Its formula is the following: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0).",
                "There are 2048 = 211 possible examples, half of whom are positive (meaning they satisfy f11) while the other half is negative.",
                "An experiment is typically composed of 50 trials.",
                "Each run corresponds to a sequence of 600 examples that are incrementally learned by a Multi Agent System with n agents The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 167 (n-MAS).",
                "A number of variables such as accuracy, (i.e. the frequency of correct classification of a set of unseen examples), hypothesis size (i.e. the number of terms in the current formula) or number of stored examples, is recorded each time 25 examples are received by the system during those runs.",
                "In the protocol that is used here, a new example is sent to a random agent when the MAS is consistent.",
                "The next example will be sent in turn to an other agent when the MAS consistency will have been restored.",
                "In such a way we simulate a kind of slow learning: the frequency of example arrivals is slow compared to the time taken by an update. 4.1 Efficiency of MAS concept learning 4.1.1 Execution time We briefly discuss here execution time of learning in the MAS.",
                "Note that the whole set of action and interaction in the MAS is simulated on a single processor.",
                "Figure 1 shows that time linearly depends on the number of agents.",
                "At the end of the most active part of learning (200 examples), a 16MAS has taken 4 times more learning time than a 4-MAS.",
                "This execution time represents the whole set of learning and Figure 1: Execution time of a n-MAS (from n = 2 at the bottom to n = 20 on the top). communication activity and hints at the cost of maintaining a consistent learning hypothesis in a MAS composed of autonomous agents. 4.1.2 Redundancy in the MAS memory We study now the distribution of the examples in the MAS memory.",
                "Redundancy is written RS = nS/ne, where nS is the total number of examples stored in the MAS, that is the sum of the sizes of agents examples memories Ei, and ne is the total number of examples received from the environment in the MAS.",
                "In figure 2, we compare redundancies in 2 to 20 agents MAS.",
                "There is a peak, slowly moving from 80 to 100 examples, that represents the number of examples for which the learning is most active.",
                "For 20 agents, maximal redundancy is no more than 6, which is far less than the maximal theoretical value of 20.",
                "Note that when learning becomes less active, redundancy tends towards its minimal value 1: when there is no more updates, examples are only Figure 2: Redundancy of examples stored in a nMAS (from n = 2 at the bottom to n = 20 on the top) . stored by the agent that receives them. 4.1.3 A n-MAS selects a simpler solution than a single agent The proposed mechanism tends to minimize the number of terms in the selected hypothesis.",
                "During learning, the size of the current hypothesis grows up beyond the optimum, and then decreases when the MAS converges.",
                "In the Multiplexer 11 testbed, the optimal number of terms is 8, but there also exist equivalent formulas with more terms.",
                "It is interesting to note that in this case the 10-MAS converges towards an exact solution closer to the optimal number of terms (here 8) (see Figure 3).",
                "After 1450 examples have been presented both 1-MAS and 10-MAS have exactly learned the concept (the respective accuracies are 0.9999 and 1) but the single agent expresses in average the result as a 11.0 terms DNF whereas the 10-MAS expresses it as a 8.8 terms DNF.",
                "However for some other boolean functions we found that during learning 1-MAS always produces larger hypotheses than 10-MAS but that both MAS converge to hypotheses with similar size results. 4.1.4 A n-MAS is more accurate than a single agent Figure 4 shows the improvement brought by a MAS with n agents compared to a single agent.",
                "This improvement was not especially expected, because whether we have one or n agents, when N examples are given to the MAS it has access to the same amount of information, maintains only on ongoing hypothesis and uses the same basic revision algorithm whenever an agent has to modify the current hypothesis.",
                "Note that if the accuracy of 1, 2, 4 and 10-MAS are significantly different, getting better as the number of agents increases, there is no clear difference beyond this point: the accuracy curve of the 100 agents MAS is very close to the one of the 10 agents MAS. 4.1.4.1 Boolean formulas.",
                "To evaluate this accuracy improvement, we have experimented our protocol on other problems of boolean function learning, As in the Multiplexer-11 case, these functions 168 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 3: Size of the hypothesis built by 1 and 10MAS: the M11 case.",
                "Figure 4: Accuracy of a n-MAS: the M11 case (from bottom to top, n = 1, 2, 4, 10, 100). are learnt in the form of more or less syntactically complex DNF3 (that is with more or less conjunctive terms in the DNF), but are also more or less difficult to learn as it can be difficult to get its way in the hypothesis space to reach them.",
                "Furthermore, the presence in the description of irrelevant attributes (that is attributes that does not belong to the target DNF) makes the problem more difficult.",
                "The following problems have been selected to experiment our protocol: (i) the multiplexer-11 with 9 irrelevant attributes: M11 9, (ii) the 20-multiplexer M20 (with 4 address bits and 16 data bits), (iii) a difficult parity problem (see [4]) the Xorp m: there must be an odd number of bits with value 1 in the p first attributes for the instance to be positive, the p others bits being irrelevant, and (iv) a simple DNF formula (a ∧ b ∧ c) ∨ (c ∧ d ∧ e)(e ∧ f ∧ g) ∧ (g ∧ h ∧ i) with 19 irrelevant attributes.",
                "The following table sums up some information about these problems, giving the total number of attributes including irrelevant ones, the number of irrelevant 3 Disjunctive Normal Forms attributes, the minimal number of terms of the corresponding DNF, and the number of learning examples used.",
                "Pb att. irre. att. terms ex.",
                "M11 11 0 8 200 M11 9 20 9 8 200 M20 20 0 16 450 Xor3 25 28 25 4 200 Xor5 5 10 5 16 180 Xor5 15 20 15 16 600 Simple4-9 19 28 19 4 200 Below are given the accuracy results of our learning mechanism with a single agent and a 10 agents MAS, along with the results of two standard algorithms implemented with the learning environment WEKA[16]: JRip (an implementation of RIPPER[2]) and Id3[12].",
                "For the experiments with JRip and Id3, we measured the mean accuracy on 50 trials, each time randomly separating examples in a learning set and a test set.",
                "JRip and Id3 parameters are default parameters, except that JRip is used without pruning.",
                "The following table shows the results: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 It is clear that difficult problems are better solved with more agents (see for instance xor5 15).",
                "We think that these benefits, which can be important with an increasing number of agents, are due to the fact that each agent really memorizes only part of the total number of examples, and this part is partly selected by other agents as counter examples, which cause a greater number of current hypothesis updates and therefore, a better exploration of the hypotheses space. 4.1.4.2 ML database problems.",
                "We did also experiments with some non boolean problems.",
                "We considered only two classes (positive/negative) problems, taken from the UCIs learning problems database[3].",
                "In all these problems, examples are described as a vector of couples (attribute, value).",
                "The value domains can be either boolean, numeric (wholly ordered set), or nominal (non-ordered set).",
                "An adequate set of atoms A must be constituted for each problem.",
                "For instance, if a is a numeric attribute, we define at most k threshold si, giving k+1 intervals of uniform density4 .",
                "Therefore, each distinct threshold si gives two atoms a ≤ si and a > si.",
                "In our experiments, we took a maximal number of threshold k = 8.",
                "For instance, in the iono problem case, there were 34 numeric attributes, and an instance is described with 506 atoms.",
                "Below are given the accuracy results of our system along with previous results.",
                "The column Nb ex. refer to the 4 The probability for the value of a to be in any interval is constant The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 169 number of examples used for learning5 .",
                "Column (1) represents minimal and maximal accuracy values for the thirty three classifiers tested in [8].",
                "Column (2) represents the results of [13], where various learning methods are compared to ensemble learning methods using weighted classifiers sets.",
                "Column S-1 and S-10 gives the accuracy of SMILE with respectively 1 and 10 agents.",
                "Pb Nb ex. (1) (2) S-1 S-10 ttt 862/574 // 76.2-99.7 99.7 99.9 kr-vs-kp 2876/958 // 91.4-99.4 96.8 97.3 iono 315 // 88.0-91.8 87.2 88.1 bupa 310 57-72 58-69.3 62.5 63.3 breastw 614 91-97 94.3-97.3 94.7 94.7 vote 391 94-96 95.3-96 91.9 92.6 pima 691 // 71.5- 73.4 65.0 65.0 heart 243 66-86 77.1-84.1 69.5 70.7 This table shows that the incremental algorithm corresponding to the single agent case, gives honorable results relatively to non-incremental classical methods using larger and more complex hypotheses.",
                "In some cases, there is an accuracy improvement with a 10 agents MAS.",
                "However, with such benchmarks data, which are often noisy, the difficulty does not really come from the way in which the search space is explored, and therefore the improvement observed is not always significant.",
                "The same kind of phenomenon have been observed with methods dedicated to hard boolean problems [4]. 4.2 MAS synchronization Here we consider that n single agents learn without interactions and at a given time start interacting thus forming a MAS.",
                "The purpose is to observe how the agents take advantage of collaboration when they start from different states of beliefs and memories.",
                "We compare in this section a 1-MAS, a 10-MAS (ref) and a 10-MAS (100sync) whose agents did not communicate during the arrival of the first 100 examples (10 by agents).",
                "The three accuracy curves are shown in figure 5.",
                "By comparing the single agent curve and the synchronized 10-MAS, we can observe that after the beginning of the synchronization, that is at 125 examples, accuracies are identical.",
                "This was expected since as soon as an example e received by the MAS contradicts the current hypothesis of the agent ra receiving it, this agent makes an update and its new hypothesis is proposed to the others agents for criticism.",
                "Therefore, this first contradictory example brings the MAS to reach consistency relatively to the whole set of examples present in agents memories.",
                "A higher accuracy, corresponding to a 10-MAS is obtained later, from the 175th example.",
                "In other words, the benefit of a better exploration of the research space is obtained slightly later in the learning process.",
                "Note that this synchronization happens naturally in all situations where agents have, for some reason, a divergence between their hypothesis and the system memory.",
                "This includes the fusion of two MAS into a single one or the arrival of new agents in an existing MAS. 4.3 Experiments on asynchronous learning: the effect of a large data stream 5 For ttt and kr-vs-kp, our protocol did not use more than respectively 574 and 958 learning examples, so we put another number in the column.",
                "Figure 5: Accuracies of a 1-MAS, a 10-MAS, and a 10-MAS synchronized after 100 examples.",
                "In this experiment we relax our slow learning mode: the examples are sent at a given rate to the MAS.",
                "The resulting example stream is measured in ms−1 , and represents the number of examples sent to the MAS each ms.",
                "Whenever the stream is too large, the MAS cannot reach MAS consistency on reception of an example from the environment before a new example arrives.",
                "This means that the update process, started by agent r0 as he received an example, may be unfinished when a new example is received by r0 or another agent r1.",
                "As a result, a critic agent may have at instant t to send counterexamples of hypotheses sent by various agents.",
                "However as far as the agents, in our setting, memorizes all the examples they receive whenever the stream ends, the MAS necessarily reaches MAS consistency with respect to all the examples received so far.",
                "In our experiments, though its learning curve is slowed down during the intense learning phase (corresponding to low accuracy of the current hypotheses), the MAS still reaches a satisfying hypothesis later on as there are less and less counterexamples in the example stream.",
                "In Figure 6 we compare the accuracies of two 11-MAS respectively submitted to example streams of different rates when learning the M11 formula.",
                "The learning curve of the MAS receiving an example at a 1/33 ms−1 rate is almost not altered (see Figure 4) whereas the 1/16 ms−1 MAS is first severely slowed down before catching up with the first one. 5.",
                "RELATED WORKS Since 96 [15], various work have been performed on learning in MAS, but rather few on concept learning.",
                "In [11] the MAS performs a form of ensemble learning in which the agents are lazy learners (no explicit representation is maintained) and sell useless examples to other agents.",
                "In [10] each agent observes all the examples but only perceive a part of their representation.",
                "In mutual online concept learning [14] the agents converge to a unique hypothesis, but each agent produces examples from its own concept representation, thus resulting in a kind of synchronization rather than in pure concept learning. 170 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) Figure 6: Accuracies of two asynchronous 11-MAS (1/33ms−1 and 1/16ms−1 example rates) . 6.",
                "CONCLUSION We have presented here and experimented a protocol for MAS online concept learning.",
                "The main feature of this collaborative learning mechanism is that it maintains a consistency property: though during the learning process each agent only receives and stores, with some limited redundancy, part of the examples received by the MAS, at any moment the current hypothesis is consistent with the whole set of examples.",
                "The hypotheses of our experiments do not address the issues of distributed MAS such as faults (for instance messages could be lost or corrupted) or other failures in general (crash, byzantine faults, etc.).",
                "Nevertheless, our framework is open, i.e., the agents can leave the system or enter it while the consistency mechanism is preserved.",
                "For instance if we introduce a timeout mechanism, even when a critic agent crashes or omits to answer, the consistency with the other critics (within the remaining agents) is entailed.",
                "In [1], a similar approach has been applied to MAS abduction problems: the hypotheses to maintain, given an incomplete information, are then facts or statements.",
                "Further work concerns first coupling induction and abduction in order to perform collaborative concept learning when examples are only partially observed by each agent, and second, investigating partial memory learning: how learning is preserved whenever one agent or the whole MAS forgets some selected examples.",
                "Aknowledgments We are very grateful to Dominique Bouthinon for implementing late modifications in SMILE, so much easing our experiments.",
                "Part of this work has been performed during the first authors visit to the Atelier De BioInformatique of Paris VI university, France. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In DALT-2006, May 2006. [2] W. W. Cohen.",
                "Fast effective rule induction.",
                "In ICML, pages 115-123, 1995. [3] C. B. D.J.",
                "Newman, S. Hettich and C. Merz.",
                "UCI repository of machine learning databases, 1998. [4] S. Esmeir and S. Markovitch.",
                "Lookahead-based algorithms for anytime induction of decision trees.",
                "In ICMLO4, pages 257-264.",
                "Morgan Kaufmann, 2004. [5] J. F¨urnkranz.",
                "A pathology of bottom-up hill-climbing in inductive rule learning.",
                "In ALT, volume 2533 of LNCS, pages 263-277.",
                "Springer, 2002. [6] A. Guerra-Hern´andez, A. ElFallah-Seghrouchni, and H. Soldano.",
                "Learning in BDI multi-agent systems.",
                "In CLIMA IV, volume 3259, pages 218-233.",
                "Springer Verlag, 2004. [7] M. Henniche.",
                "Mgi: an incremental bottom-up algorithm.",
                "In IEEE Aust. and New Zealand Conference on Intelligent Information Systems, pages 347-351, 1994. [8] T.-S. Lim, W.-Y.",
                "Loh, and Y.-S. Shih.",
                "A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms.",
                "Machine Learning, 40(3):203-228, 2000. [9] M. A. Maloof and R. S. Michalski.",
                "Incremental learning with partial instance memory.",
                "Artif.",
                "Intell., 154(1-2):95-126, 2004. [10] P. J. Modi and W.-M. Shen.",
                "Collaborative multiagent learning for classification tasks.",
                "In AGENTS 01, pages 37-38.",
                "ACM Press, 2001. [11] S. Onta˜non and E. Plaza.",
                "Recycling data for <br>multi-agent learn</br>ing.",
                "In ICML 05, pages 633-640.",
                "ACM Press, 2005. [12] J. R. Quinlan.",
                "Induction of decision trees.",
                "Machine Learning, 1(1):81-106, 1986. [13] U. R¨uckert and S. Kramer.",
                "Towards tight bounds for rule learning.",
                "In ICML 04 (International conference on Machine learning), page 90, New York, NY, USA, 2004.",
                "ACM Press. [14] J. Wang and L. Gasser.",
                "Mutual online concept learning for multiple agents.",
                "In AAMAS, pages 362-369.",
                "ACM Press, 2002. [15] G. Weiß and S. Sen, editors.",
                "Adaption and Learning in Multi-Agent Systems, volume 1042 of Lecture Notes in Computer Science.",
                "Springer, 1996. [16] I. H. Witten and E. Frank.",
                "Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.",
                "Morgan Kaufmann, October 1999.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 171"
            ],
            "original_annotated_samples": [
                "Recycling data for <br>multi-agent learn</br>ing."
            ],
            "translated_annotated_samples": [
                "Reciclaje de datos para el <br>aprendizaje multiagente</br>."
            ],
            "translated_text": "SMILE: Aprendizaje Incremental Multiagente de Sonido ;-)∗ Gauvain Bourgne LAMSADE, UMR 7024 CNRS, Universidad Paris-Dauphine, 75775 París Cedex 16 Amal El Fallah Segrouchni LIP6, UMR 7606 CNRS, Universidad Paris 6, 104, Av. del presidente Kennedy, 75116 París Henry Soldano LIPN, UMR 7030 CNRS, Universidad Paris-Norte, 99 Av. J-B Clement, 93430, Villetaneuse RESUMEN Este artículo trata sobre el problema del aprendizaje colaborativo en un sistema multiagente. Aquí cada agente puede actualizar de forma incremental sus creencias B (la representación del concepto) para que se mantenga consistente con el conjunto completo de información K (los ejemplos) que ha recibido del entorno u otros agentes. Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo lograr que, en cualquier momento, una misma representación conceptual consistente esté presente en cada agente. El protocolo correspondiente se aplica al aprendizaje supervisado de conceptos. El método resultante SMILE (que significa Sound Multiagent Incremental LEarning) se describe y experimenta aquí. Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de múltiples agentes que por un solo agente. Categorías y Descriptores de Asignaturas I.2.6 [Inteligencia Artificial]: Aprendizaje-Aprendizaje de conceptos; I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistema multiagente Términos Generales Experimentación, Algoritmos, Medición, Rendimiento 1. INTRODUCCIÓN Este artículo trata sobre el problema del aprendizaje colaborativo de conceptos en un sistema multiagente. [6] introduce una caracterización del aprendizaje en un sistema multiagente según el nivel de conciencia de los agentes. En el nivel 1, los agentes aprenden ∗El autor principal de este artículo es un estudiante. en el sistema sin tener en cuenta la presencia de otros agentes, excepto a través de la modificación que traen al entorno con sus acciones. El nivel 2 implica una interacción directa entre los agentes, ya que pueden intercambiar mensajes para mejorar su aprendizaje. El nivel 3 requeriría que los agentes tengan en cuenta las competencias de otros agentes y sean capaces de aprender observando el comportamiento de los otros agentes (considerándolos como entidades independientes y no como parte indeterminada del entorno como en el nivel 1). En este artículo nos enfocamos en el nivel 2, estudiando la interacción directa entre los agentes involucrados en un proceso de aprendizaje. Cada agente se asume capaz de aprender de forma incremental a partir de los datos que recibe, lo que significa que cada agente puede actualizar su conjunto de creencias B para mantenerlo consistente con el conjunto completo de información K que ha recibido del entorno o de otros agentes. En tal caso, diremos que es a-inconsistente. Aquí, el conjunto de creencias B representa conocimiento hipotético que por lo tanto puede ser revisado, mientras que el conjunto de información K representa conocimiento cierto, compuesto por observaciones y hechos no revisables. Además, suponemos que al menos una parte Bc de las creencias de cada agente es común a todos los agentes y debe mantenerse de esa manera. Por lo tanto, una actualización de este conjunto común Bc por parte del agente r debe provocar una actualización de Bc para toda la comunidad de agentes. Nos lleva a definir cuál es la mas-consistencia de un agente con respecto a la comunidad. El proceso de actualización de las creencias de la comunidad cuando uno de sus miembros recibe nueva información puede entonces definirse como el proceso de mantenimiento de la consistencia que garantiza que cada agente en la comunidad permanecerá más consistente. Este proceso de mantenimiento de la mas-consistencia de un agente al recibir nueva información le otorga el rol de aprendiz e implica la comunicación con otros agentes que actúan como críticos. Sin embargo, los agentes no están especializados y a su vez pueden ser aprendices o críticos, ninguno de ellos está limitado a un rol específico. Las piezas de información se distribuyen entre los agentes, pero pueden ser redundantes. No hay memoria central. El trabajo descrito aquí tiene su origen en un trabajo anterior sobre el aprendizaje en un sistema multiagente intencional utilizando un formalismo BDI [6]. En ese trabajo, los agentes tenían planes, cada uno de ellos asociado con un contexto que define en qué condiciones puede ser activado. Los planes (cada uno con su propio contexto) eran comunes a todo el conjunto de agentes en la comunidad. Los agentes tuvieron que adaptar su plan en función del contexto, dependiendo del fracaso o éxito de los planes ejecutados, utilizando un mecanismo de aprendizaje y pidiendo a otros agentes ejemplos (éxitos o fracasos de planes). Sin embargo, este trabajo carecía de un protocolo de aprendizaje colectivo que permitiera una verdadera autonomía del sistema multiagente. El estudio de dicho protocolo es el objeto del presente artículo. En la sección 2 definimos formalmente la mas-consistencia de un mecanismo de actualización para todo el MAS y proponemos un mecanismo de actualización genérico demostrado que es mas consistente. En la sección 3 describimos SMILE, un aprendiz de conceptos multiagente incremental que aplica nuestro mecanismo de actualización mas consistente para el aprendizaje colaborativo de conceptos. La sección 4 describe varios experimentos sobre SMILE y discute varios problemas, incluyendo cómo varían la precisión y la simplicidad de la hipótesis actual al comparar el aprendizaje de un solo agente y el aprendizaje de múltiples agentes. En la sección 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la sección 6 discutiendo investigaciones adicionales sobre el aprendizaje más consistente. MODELO FORMAL 2.1 Definiciones y marco En esta sección, presentamos una formulación general del aprendizaje incremental colectivo en un sistema cognitivo de múltiples agentes. Representamos un MAS como un conjunto de agentes r1, ..., rn. Cada agente ri tiene un conjunto de creencias Bi que consiste en todo el conocimiento revisable que posee. Parte de estos conocimientos deben ser compartidos con otros agentes. La parte de Bi que es común a todos los agentes se denota como BC. Esta parte común provoca una dependencia entre los agentes. Si un agente ri actualiza su conjunto de creencias Bi a Bi, cambiando en el proceso BC en BC, entonces todos los demás agentes rk deben actualizar su conjunto de creencias Bk a Bk para que BC ⊆ Bk. Además, cada agente ri ha almacenado cierta información Ki. Suponemos que alguna propiedad de consistencia Cons(Bi, Ki) puede ser verificada por el agente mismo entre sus creencias Bi y su información Ki. Como se dijo antes, Bi representa el conocimiento que podría ser revisado, mientras que Ki representa hechos observados, considerados verdaderos, y que posiblemente puedan contradecir a Bi. Definición 1. a-consistencia de un agente Un agente ri es a-consistente si Cons(Bi, Ki) es verdadero. Ejemplo 1. El agente r1 tiene un conjunto de planes que se encuentran en la parte común BC de B1. Cada plan P tiene un contexto desencadenante d(P) (que actúa como una precondición) y un cuerpo. Alguna pieza de información k podría ser el plan P, desencadenado en la situación s, ha fallado a pesar de que s es una instancia de d(P). Si esta pieza de información se agrega a K1, entonces el agente r1 ya no es a-consistente: Cons(B1, K1 ∪ k) es falso. También queremos definir alguna noción de consistencia para todo el MAS dependiendo de los conjuntos de creencias e información de sus elementos constituyentes. Primero definiremos la consistencia de un agente ri con respecto a su conjunto de creencias Bi y su propio conjunto de información Ki junto con todos los conjuntos de información K1...Kn de los otros agentes del MAS. Simplemente lo haremos considerando cuál sería la a-consistencia del agente si tuviera la información de todos los demás agentes. Llamamos a esta noción la mas-consistencia: Definición 2. Un agente ri es mas-consistente si Cons(Bi, Ki ∪ K) es verdadero, donde K = ∪j∈{1,..,n}−{i}Kj 1 es el conjunto de toda la información de los otros agentes del MAS. 1 Lo notaremos como ∪ Kj cuando el contexto sea similar. Ejemplo 2. Usando el ejemplo anterior, supongamos que la pieza de información k está incluida en la información K2 del agente r2. Si la pieza de información no se transmite a r1, y por lo tanto no se agrega a K1, r1 permanece a-consistente. Sin embargo, r1 no es tan consistente como k en el conjunto K de toda la información del MAS. La consistencia global del MAS es simplemente la mas-consistencia de todos sus agentes. Definición 3. La consistencia de un MAS A MAS r1,...,rn es consistente si todos sus agentes ri son masconsistentes. Ahora definimos las propiedades requeridas para un mecanismo de revisión M que actualiza a un agente ri cuando recibe una pieza de información k. En lo siguiente, supondremos que: • La actualización siempre es posible, es decir, un agente siempre puede modificar su conjunto de creencias Bi para recuperar su a-consistencia. Diremos que cada agente es localmente eficiente. • Considerando dos conjuntos de información Cons(Bi, K1) y Cons(Bi, K2), también tenemos Cons(Bi, K1 ∪ K2). Es decir, la a-consistencia de los agentes es aditiva. • Si una pieza de información k relacionada con el conjunto común BC es consistente con un agente, es consistente con todos los agentes: para todos los pares de agentes (ri, rj) tales que Cons(Bi, Ki) y Cons(Bj, Kj) son verdaderos, tenemos, para toda pieza de información k: Cons(Bi, Ki ∪ k) si y solo si Cons(Bj, Kj ∪ k). En tal caso, diremos que el MAS es coherente. Esta última condición simplemente significa que el conjunto de creencias común BC es independiente de las posibles diferencias entre los conjuntos de creencias Bi de cada agente ri. En el caso más simple, B1 = ... = Bn = BC. M también será visto como un mecanismo de aprendizaje incremental y representado como una aplicación que cambia Bi en Bi. En lo siguiente, anotaremos ri(Bi, Ki) para ri cuando sea útil. Definición 4. a-consistencia de una revisión Un mecanismo de actualización M es a-consistente si, para cualquier agente ri y cualquier pieza de información k que llegue a ri, la a-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki) a-consistente ⇒ ri(Bi, Ki) a-consistente, donde Bi = M(Bi) y Ki = Ki ∪ k es el conjunto de toda la información de otros agentes del MAS. De la misma manera, definimos la mas-consistencia de un mecanismo de revisión como la a-consistencia de este mecanismo si los agentes disponen de toda la información en el MAS. En lo siguiente, anotaremos, si es necesario, ri(Bi, Ki, K) para el agente ri en el MAS r1 . . . rn. Definición 5. mas-consistencia de una revisión Un mecanismo de actualización Ms es mas-consistente si para todo agente ri y toda pieza de información k que llega a ri, la mas-consistencia de este agente se conserva. En otras palabras, si: ri(Bi, Ki, K) más-consistente ⇒ ri(Bi, Ki, K) más-consistente, donde Bi = Ms(Bi), Ki = Ki ∪ k, y K = ∪Kj es el conjunto de toda la información del MAS. El Sexto Internacional. En última instancia, cuando un agente aplica un mecanismo mas-consistente al recibir una nueva pieza de información, un efecto secundario deseable del mecanismo debería ser que todos los demás agentes permanezcan mas-consistentes después de cualquier modificación de la parte común BC, es decir, el MAS en sí mismo debería volver a ser consistente. Esta propiedad se define de la siguiente manera: Definición 6. La fuerte mas-consistencia de un mecanismo de actualización. Un mecanismo de actualización Ms es fuertemente mas-consistente si - Ms es mas-consistente, y - la aplicación de Ms por un agente preserva la consistencia del MAS. 2.2 Un mecanismo de actualización fuertemente mas-consistente. La idea general es que, dado que la información está distribuida entre todos los agentes del MAS, debe haber alguna interacción entre el agente aprendiz y los demás agentes en un mecanismo de actualización fuertemente mas-consistente Ms. Para garantizar su mas-consistencia, Ms estará constituido por aplicaciones reiteradas por parte del agente aprendiz ri de un mecanismo interno a-consistente M, seguido por algunas interacciones entre ri y los otros agentes, hasta que ri recupere su mas-consistencia. Describimos a continuación un mecanismo, primero con una descripción de una interacción, luego una iteración y finalmente una declaración de la condición de terminación del mecanismo. El mecanismo es activado por un agente ri al recibir una pieza de información k que interrumpe la mas-consistencia. Tomaremos M(Bi) como el conjunto de creencias del agente aprendiz ri después de una actualización, BC la parte común modificada por ri, y Bj el conjunto de creencias de otro agente rj inducido por la modificación de su parte común BC en BC. Una interacción I(ri, rj) entre el agente aprendiz ri y otro agente rj, actuando como crítico, está constituida por los siguientes pasos: • el agente ri envía la actualización BC de la parte común de sus creencias. Habiendo aplicado su mecanismo de actualización, ri es a-consistente. • El agente rj verifica la modificación Bj de sus creencias inducida por la actualización BC. Si esta modificación conserva su a-consistencia, rj adopta esta modificación. El agente rj envía ya sea una aceptación de BC o una negación junto con una (o más) pieza(s) de información k tal que Cons(Bj, k) es falso. Una iteración de Ms estará compuesta por: • la recepción por parte del agente aprendiz ri de una pieza de información y la actualización M(Bi) restaurando su consistencia • un conjunto de interacciones I(ri, rj) (en las cuales varios agentes críticos posiblemente puedan participar). Si al menos una pieza de información k es transmitida a ri, la adición de k necesariamente hará que ri sea inconsistente y entonces ocurrirá una nueva iteración. Este mecanismo termina cuando ningún agente puede proporcionar tal pieza de información k. Cuando es el caso, se restaura la masconsistencia del agente aprendiz ri. Proposición 1. Dejen que r1,...,rn sea un MAS consistente en el que el agente ri recibe una pieza de información k que rompe su consistencia, y M sea un mecanismo interno de actualización a-consistente. El mecanismo de actualización descrito anteriormente por Ms es altamente mas-consistente. Prueba. La prueba se deriva directamente de la descripción del mecanismo. Este mecanismo asegura que cada vez que un agente recibe un evento, su mas-consistencia será restaurada. Como los otros agentes adoptan la actualización final BC, todos son mas-coherentes y el MAS es coherente. Por lo tanto, Ms es un mecanismo de actualización fuertemente consistente. En el mecanismo descrito anteriormente, el agente aprendiz es el único que recibe y memoriza información durante la ejecución del mecanismo. Se asegura de que Ms termine. Las piezas de información transmitidas por otros agentes y memorizadas por el agente aprendiz son redundantes, ya que ya están presentes en el MAS, más precisamente en la memoria de los agentes críticos que las transmitieron. Se debe tener en cuenta que el mecanismo propuesto por la Sra. aquí no indica explícitamente el orden ni el alcance de las interacciones. Consideraremos en lo siguiente que la propuesta de modificación BC se envía secuencialmente a los diferentes agentes (mecanismo síncrono). Además, la respuesta de un agente crítico solo contendrá una pieza de información inconsistente con la modificación propuesta. Diremos que la respuesta del agente es mínima. Este mecanismo, siendo sincrónico con una respuesta mínima, minimiza la cantidad de información transmitida por los agentes. Ahora lo ilustraremos en el caso del aprendizaje de conceptos multiagente. 3. APRENDIZAJE INCREMENTAL DE MÚLTIPLES AGENTES 3.1 La tarea de aprendizaje Experimentamos el mecanismo propuesto anteriormente en el caso del aprendizaje conceptual MAS incremental. Aquí consideramos un lenguaje de hipótesis en el cual una hipótesis es una disyunción de términos. Cada término es una conjunción de átomos de un conjunto A. Un ejemplo está representado por una etiqueta + o − y una descripción 2 compuesta por un subconjunto de átomos e ⊆ A. Un término abarca un ejemplo si sus átomos constituyentes están incluidos en el ejemplo. Una hipótesis abarca un ejemplo si uno de sus términos lo abarca. Esta representación se utilizará a continuación para aprender fórmulas booleanas. Los literales negativos se representan aquí mediante átomos adicionales, como not − a. La fórmula booleana f = (a ∧ b) ∨ (b ∧ ¬c) se escribirá entonces como (a ∧ b) ∨ (b ∧ no − c). Un ejemplo positivo de f, como {no − a, b, no − c}, representa un modelo para f. 3.2 Proceso de aprendizaje incremental El proceso de aprendizaje es un mecanismo de actualización que, dado una hipótesis actual H, una memoria E = E+ ∪ E− llenada con los ejemplos recibidos previamente, y un nuevo ejemplo positivo o negativo e, produce una nueva hipótesis actualizada. Antes de esta actualización, la hipótesis dada es completa, lo que significa que cubre todos los ejemplos positivos de E+, y 2 Cuando no haya posibilidad de confusión, la palabra ejemplo se utilizará para referirse al par (etiqueta, descripción) así como a la descripción sola. 166 La Sexta Conferencia Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) es coherente, lo que significa que no cubre ningún ejemplo negativo de E−. Después de la actualización, la nueva hipótesis debe ser completa y coherente con el nuevo estado de memoria E ∪ {e}. Describimos a continuación nuestro mecanismo de actualización de agente único, inspirado en un trabajo previo sobre aprendizaje incremental[7]. En lo siguiente, una hipótesis H para la fórmula objetivo f es una lista de términos h, cada uno de ellos siendo una conjunción de átomos. H es coherente si todos los términos h son coherentes, y H es completo si cada elemento de E+ está cubierto por al menos un término h de H. Cada término es, por construcción, la lgg (generalización general menos general) de un subconjunto de instancias positivas {e1, ..., en}, es decir, el término más específico que cubre {e1, ..., en}. El operador lgg se define considerando ejemplos como términos, por lo que denotamos como lgg(e) al término más específico que cubre e, y como lgg(h, e) al término más específico que es más general que h y que cubre e. Restringir el término a lgg es la base de muchos algoritmos de aprendizaje de abajo hacia arriba (por ejemplo [5]). En la tipología propuesta por [9], nuestro mecanismo de actualización es un aprendiz incremental con memoria completa de instancias: el aprendizaje se realiza mediante actualizaciones sucesivas y se almacenan todos los ejemplos. El mecanismo de actualización depende de la hipótesis en curso H, los ejemplos en curso E+ y E−, y el nuevo ejemplo e. Hay tres casos posibles: • e es positivo y H cubre e, o e es negativo y H no cubre e. No se necesita actualización, H ya es completo y coherente con E ∪ {e}. • e es positivo y H no cubre e: e se denota como un contraejemplo positivo de H. Luego buscamos generalizar a su vez los términos h de H. Tan pronto como se encuentre una generalización correcta h = lgg(h, e), h reemplaza a h en H. Si hay un término que es menos general que h, se descarta. Si ninguna generalización es correcta (es decir, coherente), H ∪ lgg(e) reemplaza a H. • e es negativo y H cubre e: e se denota como un contraejemplo negativo de H. Cada término h que cubre e es entonces descartado de H y reemplazado por un conjunto de términos {h1, ...., hn} que, en su totalidad, es coherente con E− ∪ {e} y que cubre los ejemplos de E+ no cubiertos por H − {h}. Los términos de la hipótesis final H que son menos generales que otros son descartados de H. Ahora describiremos el caso en el que e = e− es un ejemplo negativo cubierto. Las siguientes funciones se utilizan aquí: • coveredOnlyBy(h, E+) da el subconjunto de E+ cubierto por h y ningún otro término de H. • bestCover(h1, h2) da h1 si h1 cubre más ejemplos de uncoveredPos que h2, de lo contrario da h2. • covered(h) da los elementos de uncoveredPos cubiertos por h. // Especialización de cada h cubriendo e− para cada h de H cubriendo e− hacer H = H − {h} uncoveredPos = coveredOnlyBy(h, E+ ) Ar= átomos que no están ni en e− ni en h mientras (uncoveredPos = ∅) hacer // buscando la mejor especialización de h hc=h best=⊥ // ⊥ no cubre ningún ejemplo para cada a de Ar hacer hc= h ∧ a best = bestCover(hc, best) finpara Ar=Ar−{best} hi=lgg(covered(best)) H = H ∪ {hi} uncoveredPos=uncoveredPos - covered(best) finmientras finpara Los términos de H que son menos generales que otros son descartados. Ten en cuenta que este mecanismo tiende tanto a hacer una actualización mínima de la hipótesis actual como a minimizar el número de términos en la hipótesis, en particular descartando términos menos generales que otros después de actualizar una hipótesis. 3.3 Aprendizaje colectivo Si H es la hipótesis actual, Ei es la memoria actual de ejemplos del agente ri y E es el conjunto de todos los ejemplos recibidos por el sistema, la notación de la sección 2 se convierte en Bi = BC = H, Ki = Ei y K = E. Cons(H, Ei) establece que H es completo y coherente con Ei. En tal caso, ri es a-consistente. La pieza de información k recibida por el agente ri es aquí simplemente un ejemplo e junto con su etiqueta. Si e es tal que la hipótesis actual H no es completa ni coherente con Ei ∪ {e}, e contradice a H: ri se vuelve a-inconsistente, y por lo tanto el MAS ya no es consistente. La actualización de una hipótesis cuando llega un nuevo ejemplo es un mecanismo a-consistente. Siguiendo la proposición 1, este mecanismo puede ser utilizado para producir un mecanismo fuerte mas-consistente: al recibir un nuevo ejemplo en el MAS por un agente r, posiblemente se necesite una actualización y, después de un conjunto de interacciones entre r y los otros agentes, resulta en una nueva hipótesis compartida por todos los agentes y que restaura la consistencia del MAS, es decir, que es completa y coherente con el conjunto ES de todos los ejemplos presentes en el MAS. Es claro que al minimizar el número de modificaciones de hipótesis, este mecanismo sincrónico y minimalista reduce el número de ejemplos recibidos por el aprendiz de otros agentes, y por ende, el número total de ejemplos almacenados en el sistema. 4. EXPERIMENTOS En lo siguiente, aprenderemos una fórmula booleana que es una prueba difícil para el método de aprendizaje: el 11-multiplexor (ver [4]). Se refiere a 3 atributos booleanos de dirección a0, a1, a2 y 8 atributos booleanos de datos d0, ..., d7. La fórmula f11 se cumple si el número codificado por los 3 atributos de dirección es el número de un atributo de datos cuyo valor es 1. Su fórmula es la siguiente: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0). Hay 2048 = 211 posibles ejemplos, la mitad de los cuales son positivos (lo que significa que satisfacen f11) mientras que la otra mitad es negativa. Un experimento suele estar compuesto por 50 pruebas. Cada ejecución corresponde a una secuencia de 600 ejemplos que son aprendidos de forma incremental por un Sistema Multiagente con n agentes. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 167 (n-MAS). Un número de variables como la precisión (es decir, la frecuencia de clasificación correcta de un conjunto de ejemplos no vistos), el tamaño de la hipótesis (es decir, el número de términos en la fórmula actual) o el número de ejemplos almacenados, se registra cada vez que el sistema recibe 25 ejemplos durante esas ejecuciones. En el protocolo que se utiliza aquí, un nuevo ejemplo se envía a un agente aleatorio cuando el MAS es consistente. El siguiente ejemplo será enviado a su vez a otro agente cuando la consistencia del MAS haya sido restaurada. De esta manera simulamos una especie de aprendizaje lento: la frecuencia de llegada de ejemplos es lenta en comparación con el tiempo que lleva una actualización. 4.1 Eficiencia del aprendizaje conceptual en MAS 4.1.1 Tiempo de ejecución Discutimos brevemente aquí el tiempo de ejecución del aprendizaje en el MAS. Se debe tener en cuenta que todo el conjunto de acciones e interacciones en el MAS se simula en un solo procesador. La Figura 1 muestra que el tiempo depende linealmente del número de agentes. Al final de la parte más activa del aprendizaje (200 ejemplos), un 16MAS ha tomado 4 veces más tiempo de aprendizaje que un 4-MAS. Este tiempo de ejecución representa el conjunto completo de aprendizaje y la Figura 1: Tiempo de ejecución de un n-MAS (desde n = 2 en la parte inferior hasta n = 20 en la parte superior). actividad de comunicación y sugiere el costo de mantener una hipótesis de aprendizaje consistente en un MAS compuesto por agentes autónomos. 4.1.2 Redundancia en la memoria del MAS Estudiamos ahora la distribución de los ejemplos en la memoria del MAS. La redundancia se escribe RS = nS/ne, donde nS es el número total de ejemplos almacenados en el MAS, que es la suma de los tamaños de las memorias de ejemplos de los agentes Ei, y ne es el número total de ejemplos recibidos del entorno en el MAS. En la figura 2, comparamos las redundancias en MAS de 2 a 20 agentes. Hay un pico que se mueve lentamente de 80 a 100 ejemplos, que representa la cantidad de ejemplos para los cuales el aprendizaje es más activo. Para 20 agentes, la redundancia máxima no es más de 6, lo cual es mucho menor que el valor teórico máximo de 20. Ten en cuenta que cuando el aprendizaje se vuelve menos activo, la redundancia tiende hacia su valor mínimo 1: cuando ya no hay más actualizaciones, los ejemplos son solo la Figura 2: Redundancia de ejemplos almacenados en un nMAS (de n = 2 en la parte inferior a n = 20 en la parte superior) almacenados por el agente que los recibe. Un n-MAS selecciona una solución más simple que un solo agente. El mecanismo propuesto tiende a minimizar el número de términos en la hipótesis seleccionada. Durante el aprendizaje, el tamaño de la hipótesis actual crece más allá del óptimo, y luego disminuye cuando el MAS converge. En el banco de pruebas Multiplexer 11, el número óptimo de términos es 8, pero también existen fórmulas equivalentes con más términos. Es interesante notar que en este caso el 10-MAS converge hacia una solución exacta más cercana al número óptimo de términos (en este caso 8) (ver Figura 3). Después de haber presentado 1450 ejemplos, tanto el 1-MAS como el 10-MAS han aprendido exactamente el concepto (las precisiones respectivas son 0.9999 y 1), pero el agente individual expresa en promedio el resultado como una DNF de 11.0 términos, mientras que el 10-MAS lo expresa como una DNF de 8.8 términos. Sin embargo, para algunas otras funciones booleanas encontramos que durante el aprendizaje, 1-MAS siempre produce hipótesis más grandes que 10-MAS, pero que ambos MAS convergen a hipótesis con resultados de tamaño similar. 4.1.4 Un n-MAS es más preciso que un agente único. La Figura 4 muestra la mejora proporcionada por un MAS con n agentes en comparación con un agente único. Esta mejora no era especialmente esperada, porque ya sea que tengamos uno o n agentes, cuando se le dan N ejemplos al MAS, tiene acceso a la misma cantidad de información, mantiene solo una hipótesis en curso y utiliza el mismo algoritmo básico de revisión cada vez que un agente tiene que modificar la hipótesis actual. Ten en cuenta que si la precisión de los MAS de 1, 2, 4 y 10 es significativamente diferente, mejorando a medida que aumenta el número de agentes, no hay una diferencia clara más allá de este punto: la curva de precisión de los MAS de 100 agentes es muy similar a la de los MAS de 10 agentes. 4.1.4.1 Fórmulas booleanas. Para evaluar esta mejora de precisión, hemos experimentado nuestro protocolo en otros problemas de aprendizaje de funciones booleanas. Como en el caso del Multiplexor-11, estas funciones 168 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 3: Tamaño de la hipótesis construida por 1 y 10MAS: el caso M11. Figura 4: Precisión de un n-MAS: el caso M11 (de abajo hacia arriba, n = 1, 2, 4, 10, 100). Se aprenden en forma de DNF3 más o menos sintácticamente complejos (es decir, con más o menos términos conjuntivos en la DNF), pero también son más o menos difíciles de aprender, ya que puede ser difícil encontrar su camino en el espacio de hipótesis para alcanzarlos. Además, la presencia en la descripción de atributos irrelevantes (es decir, atributos que no pertenecen al DNF objetivo) hace que el problema sea más difícil. Los siguientes problemas han sido seleccionados para experimentar con nuestro protocolo: (i) el multiplexor-11 con 9 atributos irrelevantes: M11 9, (ii) el multiplexor-20 M20 (con 4 bits de dirección y 16 bits de datos), (iii) un problema de paridad difícil (ver [4]) el Xorp m: debe haber un número impar de bits con valor 1 en los primeros p atributos para que la instancia sea positiva, los p bits restantes son irrelevantes, y (iv) una fórmula DNF simple (a ∧ b ∧ c) ∨ (c ∧ d ∧ e) ∨ (e ∧ f ∧ g) ∧ (g ∧ h ∧ i) con 19 atributos irrelevantes. La siguiente tabla resume alguna información sobre estos problemas, proporcionando el número total de atributos, incluidos los irrelevantes, el número de atributos irrelevantes en Forma Normal Disyuntiva 3, el número mínimo de términos de la DNF correspondiente, y el número de ejemplos de aprendizaje utilizados. Pb att. irre. att. términos ex. A continuación se presentan los resultados de precisión de nuestro mecanismo de aprendizaje con un solo agente y un MAS de 10 agentes, junto con los resultados de dos algoritmos estándar implementados con el entorno de aprendizaje WEKA[16]: JRip (una implementación de RIPPER[2]) e Id3[12]. Para los experimentos con JRip e Id3, medimos la precisión media en 50 pruebas, separando aleatoriamente los ejemplos en un conjunto de aprendizaje y un conjunto de prueba cada vez. Los parámetros de JRip e Id3 son los predeterminados, excepto que JRip se utiliza sin poda. La siguiente tabla muestra los resultados: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 Es claro que los problemas difíciles se resuelven mejor con más agentes (ver por ejemplo xor5 15). Creemos que estos beneficios, que pueden ser importantes con un número creciente de agentes, se deben al hecho de que cada agente realmente memoriza solo parte del número total de ejemplos, y esta parte es seleccionada en parte por otros agentes como contraejemplos, lo que provoca un mayor número de actualizaciones de hipótesis actuales y, por lo tanto, una mejor exploración del espacio de hipótesis. 4.1.4.2 Problemas de base de datos de ML. También realizamos experimentos con algunos problemas no booleanos. Consideramos solo problemas de dos clases (positivo/negativo), tomados de la base de datos de problemas de aprendizaje de UCIs. En todos estos problemas, los ejemplos se describen como un vector de pares (atributo, valor). Los dominios de valor pueden ser booleanos, numéricos (conjunto totalmente ordenado) o nominales (conjunto no ordenado). Un conjunto adecuado de átomos A debe ser constituido para cada problema. Por ejemplo, si a es un atributo numérico, definimos como máximo k umbrales si, dando k+1 intervalos de densidad uniforme. Por lo tanto, cada umbral distintivo si da dos átomos, uno ≤ si y otro > si. En nuestros experimentos, tomamos un número máximo de umbral k = 8. Por ejemplo, en el caso del problema de iono, había 34 atributos numéricos, y una instancia se describe con 506 átomos. A continuación se presentan los resultados de precisión de nuestro sistema junto con los resultados anteriores. La columna Nb ex. se refiere al 4. La probabilidad de que el valor de a esté en cualquier intervalo es constante. El Sexto Congreso Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 169 número de ejemplos utilizados para el aprendizaje5. La columna (1) representa los valores de precisión mínima y máxima para los treinta y tres clasificadores probados en [8]. La columna (2) representa los resultados de [13], donde se comparan varios métodos de aprendizaje con métodos de aprendizaje en conjunto utilizando conjuntos de clasificadores ponderados. La columna S-1 y S-10 dan la precisión de SMILE con 1 y 10 agentes, respectivamente. Esta tabla muestra que el algoritmo incremental correspondiente al caso de un solo agente, proporciona resultados honorables en relación a los métodos clásicos no incrementales que utilizan hipótesis más grandes y complejas. En algunos casos, hay una mejora en la precisión con un MAS de 10 agentes. Sin embargo, con datos de referencia de este tipo, que suelen ser ruidosos, la dificultad no radica realmente en la forma en que se explora el espacio de búsqueda, por lo que la mejora observada no siempre es significativa. El mismo tipo de fenómeno se ha observado con métodos dedicados a problemas booleanos difíciles [4]. 4.2 Sincronización de MAS En este caso consideramos que n agentes individuales aprenden sin interacciones y en un momento dado comienzan a interactuar, formando así un MAS. El propósito es observar cómo los agentes aprovechan la colaboración cuando parten de diferentes estados de creencias y memorias. En esta sección comparamos un 1-MAS, un 10-MAS (ref) y un 10-MAS (100sync) cuyos agentes no se comunicaron durante la llegada de los primeros 100 ejemplos (10 por agentes). Las tres curvas de precisión se muestran en la figura 5. Al comparar la curva del agente individual con la del 10-MAS sincronizado, podemos observar que después del inicio de la sincronización, es decir, en 125 ejemplos, las precisiones son idénticas. Esto era esperado ya que tan pronto como un ejemplo e recibido por el MAS contradice la hipótesis actual del agente ra que lo recibe, este agente realiza una actualización y su nueva hipótesis es propuesta a los otros agentes para su crítica. Por lo tanto, este primer ejemplo contradictorio lleva al MAS a alcanzar coherencia en relación con todo el conjunto de ejemplos presentes en la memoria de los agentes. Una mayor precisión, correspondiente a un 10-MAS, se obtiene más tarde, a partir del ejemplo 175. En otras palabras, el beneficio de una mejor exploración del espacio de investigación se obtiene ligeramente más tarde en el proceso de aprendizaje. Ten en cuenta que esta sincronización ocurre de forma natural en todas las situaciones en las que los agentes tienen, por alguna razón, una divergencia entre su hipótesis y la memoria del sistema. Esto incluye la fusión de dos MAS en una sola o la llegada de nuevos agentes en un MAS existente. 4.3 Experimentos sobre el aprendizaje asincrónico: el efecto de un gran flujo de datos. Para ttt y kr-vs-kp, nuestro protocolo no utilizó más de 574 y 958 ejemplos de aprendizaje respectivamente, por lo que colocamos otro número en la columna. Figura 5: Precisión de un 1-MAS, un 10-MAS y un 10-MAS sincronizado después de 100 ejemplos. En este experimento relajamos nuestro modo de aprendizaje lento: los ejemplos se envían a una velocidad determinada al MAS. El flujo de ejemplos resultante se mide en ms−1, y representa la cantidad de ejemplos enviados al MAS cada milisegundo. Cuando el flujo es demasiado grande, el MAS no puede alcanzar la consistencia del MAS al recibir un ejemplo del entorno antes de que llegue un nuevo ejemplo. Esto significa que el proceso de actualización, iniciado por el agente r0 al recibir un ejemplo, puede estar incompleto cuando un nuevo ejemplo es recibido por r0 u otro agente r1. Como resultado, un agente crítico puede tener que enviar contraejemplos de hipótesis enviadas por varios agentes en el instante t. Sin embargo, en nuestro entorno, a medida que los agentes memorizan todos los ejemplos que reciben cuando finaliza el flujo, el MAS alcanza necesariamente consistencia MAS con respecto a todos los ejemplos recibidos hasta el momento. En nuestros experimentos, aunque la curva de aprendizaje se ralentiza durante la fase intensa de aprendizaje (correspondiente a una baja precisión de las hipótesis actuales), el MAS aún logra alcanzar una hipótesis satisfactoria más adelante, ya que hay menos contraejemplos en el flujo de ejemplos. En la Figura 6 comparamos las precisiones de dos 11-MAS respectivamente sometidos a flujos de ejemplos de diferentes tasas al aprender la fórmula M11. La curva de aprendizaje del MAS al recibir un ejemplo a una velocidad de 1/33 ms−1 casi no se ve alterada (ver Figura 4), mientras que el MAS a 1/16 ms−1 primero se ralentiza severamente antes de alcanzar al primero. 5. TRABAJOS RELACIONADOS Desde el 96 [15], se han realizado varios trabajos sobre el aprendizaje en Sistemas Multiagente, pero muy pocos sobre el aprendizaje de conceptos. En [11] el MAS realiza una forma de aprendizaje en conjunto en la que los agentes son aprendices perezosos (no se mantiene una representación explícita) y venden ejemplos inútiles a otros agentes. En [10] cada agente observa todos los ejemplos pero solo percibe una parte de su representación. En el aprendizaje de conceptos en línea mutuo, los agentes convergen hacia una hipótesis única, pero cada agente produce ejemplos desde su propia representación del concepto, lo que resulta en una especie de sincronización en lugar de un aprendizaje de conceptos puro. 170 The Sixth Intl. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) Figura 6: Precisión de dos sistemas multiagente asincrónicos de 11 agentes (tasas de ejemplo de 1/33ms−1 y 1/16ms−1). 6. CONCLUSIÓN Hemos presentado y experimentado un protocolo para el aprendizaje de conceptos en línea de MAS. La característica principal de este mecanismo de aprendizaje colaborativo es que mantiene una propiedad de consistencia: aunque durante el proceso de aprendizaje cada agente solo recibe y almacena, con cierta redundancia limitada, parte de los ejemplos recibidos por el MAS, en cualquier momento la hipótesis actual es consistente con todo el conjunto de ejemplos. Las hipótesis de nuestros experimentos no abordan los problemas de los MAS distribuidos, como fallos (por ejemplo, mensajes perdidos o corruptos) u otras fallas en general (crash, fallos bizantinos, etc.). Sin embargo, nuestro marco de trabajo es abierto, es decir, los agentes pueden salir del sistema o ingresar a él mientras se preserva el mecanismo de consistencia. Por ejemplo, si introducimos un mecanismo de tiempo de espera, incluso cuando un agente crítico se bloquea o no responde, se garantiza la consistencia con los otros críticos (dentro de los agentes restantes). En [1], se ha aplicado un enfoque similar a los problemas de abducción en MAS: las hipótesis a mantener, dada una información incompleta, son entonces hechos o afirmaciones. El trabajo adicional se refiere en primer lugar a acoplar la inducción y la abducción para realizar un aprendizaje colaborativo de conceptos cuando los ejemplos son solo parcialmente observados por cada agente, y en segundo lugar, a investigar el aprendizaje de memoria parcial: cómo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados. Agradecimientos Estamos muy agradecidos a Dominique Bouthinon por implementar las modificaciones tardías en SMILE, facilitando mucho nuestros experimentos. Parte de este trabajo se realizó durante la visita del primer autor al Atelier De BioInformatique de la Universidad Paris VI, Francia. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En DALT-2006, mayo de 2006. [2] W. W. Cohen. Inducción de reglas rápida y efectiva. En ICML, páginas 115-123, 1995. [3] C. B. D.J. Newman, S. Hettich y C. Merz. Repositorio de bases de datos de aprendizaje automático de UCI, 1998. [4] S. Esmeir y S. Markovitch. Algoritmos basados en anticipación para la inducción en cualquier momento de árboles de decisión. En ICMLO4, páginas 257-264. Morgan Kaufmann, 2004. [5] J. F¨urnkranz. \n\nMorgan Kaufmann, 2004. [5] J. F¨urnkranz. Una patología de la escalada de colina de abajo hacia arriba en el aprendizaje inductivo de reglas. En ALT, volumen 2533 de LNCS, páginas 263-277. Springer, 2002. [6] A. Guerra-Hernández, A. ElFallah-Seghrouchni y H. Soldano. Aprendizaje en sistemas multiagente BDI. En CLIMA IV, volumen 3259, páginas 218-233. Springer Verlag, 2004. [7] M. Henniche. \n\nSpringer Verlag, 2004. [7] M. Henniche. Mgi: un algoritmo incremental de abajo hacia arriba. En la Conferencia IEEE de Australia y Nueva Zelanda sobre Sistemas de Información Inteligente, páginas 347-351, 1994. [8] T.-S. Lim, W.-Y. Loh, y Y.-S. Shih. Una comparación de la precisión de predicción, complejidad y tiempo de entrenamiento de treinta y tres algoritmos de clasificación antiguos y nuevos. Aprendizaje automático, 40(3):203-228, 2000. [9] M. A. Maloof y R. S. Michalski. Aprendizaje incremental con memoria parcial de instancias. I'm sorry, but the sentence \"Artif.\" is not a complete sentence. Can you provide more context or a complete sentence for me to translate to Spanish? Intell., 154(1-2):95-126, 2004. [10] P. J. Modi y W.-M. Shen. Aprendizaje colaborativo multiagente para tareas de clasificación. En AGENTS 01, páginas 37-38. ACM Press, 2001. [11] S. Onta˜non y E. Plaza. Reciclaje de datos para el <br>aprendizaje multiagente</br>. En ICML 05, páginas 633-640. ACM Press, 2005. [12] J. R. Quinlan. \n\nACM Press, 2005. [12] J. R. Quinlan. Inducción de árboles de decisión. Aprendizaje automático, 1(1):81-106, 1986. [13] U. R¨uckert y S. Kramer. Hacia límites ajustados para el aprendizaje de reglas. En ICML 04 (Conferencia Internacional sobre Aprendizaje Automático), página 90, Nueva York, NY, EE. UU., 2004. ACM Press. [14] J. Wang y L. Gasser. Aprendizaje de conceptos en línea mutuo para múltiples agentes. En AAMAS, páginas 362-369. ACM Press, 2002. [15] G. Weiß y S. Sen, editores. Adaptación y Aprendizaje en Sistemas Multiagente, volumen 1042 de las Notas de Conferencia en Ciencias de la Computación. Springer, 1996. [16] I. H. Witten y E. Frank. Minería de datos: Herramientas y técnicas prácticas de aprendizaje automático con implementaciones en Java. Morgan Kaufmann, octubre de 1999. La Sexta Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 171 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}