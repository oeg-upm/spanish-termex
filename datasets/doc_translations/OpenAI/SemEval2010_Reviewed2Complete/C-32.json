{
    "id": "C-32",
    "original_text": "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task. They require strong consistency for shared persistent data and efficient access to fine-grained objects. These properties are difficult to provide in wide-area networks because of high network latency. BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments. The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers. We have implemented a BuddyCache prototype and evaluated its performance. Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly. Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1. INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go. Nevertheless, distributed applications may perform poorly in wide-area network environments. Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited. BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment. Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project. Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data. Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24]. For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22]. Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics. If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened. Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server. Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings. However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects. Cooperative object caching systems [2] provide these properties. However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page. Interaction with the server increases latency. The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments. Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site. The engineers use a collaborative CAD application to revise and update complex project design documents. The shared documents are stored in transactional repository servers at the company home site. The engineers use workstations running repository clients. The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow. To improve access latency, clients fetch objects from repository servers and cache and access them locally. A coherence protocol ensures that client caches remain consistent when objects are modified. The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects. With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group. BuddyCache presents two main technical challenges. One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system. The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes. BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11]. A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers. If the client request can not be served locally, the redirector forwards it to a remote server. When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients. BuddyCache redirects subsequent requests for this object to the caching client. Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members. BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group. Nevertheless, in a transactional system, redirection interferes with shared object availability. Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently. A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information. Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease? We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements. We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency. Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly. These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2. RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network. These techniques use the server to provide redirection and do not consider issues of high network latency. Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail. Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes. This work does not consider issues of consistent concurrent updates to shared fine-grained objects. Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache. This multicast transport level solution is geared to the single writer semantics of web objects. In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects. Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27]. The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing. Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme. The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions. The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme. In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system. Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations. Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels. The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems. Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache. BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3. BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment. This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions. We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks. Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects. The servers provide disk storage for the persistent objects. A persistent object is owned by a single server. Objects may be small (order of 100 bytes for programming language objects [23]). To amortize the cost of disk and network transfer objects are grouped into physical pages. To improve object access latency, clients fetch the objects from the servers and cache and access them locally. A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified. The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects. BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers. The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers. If the client request can be served locally, the interaction with the server is avoided. If the client request can not be served locally, redirector forwards it to a remote server. Redirection approach has been used to improve the performance of web caching protocols. BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19]. The correctness property ensures onecopy serializability of the objects committed by the client transactions. The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects. The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information. BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group. The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures. Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object. In addition, redirector manages cache coherence. Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems. Protocols make different choices in granularity of data transfers and granularity of cache consistency. The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts. The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache. The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category. We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol. We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation. We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol. Below we outline the OCC protocol [3]. The OCC protocol uses object-level coherence. When a client requests a missing object, the server transfers the containing page. Transaction can read and update locally cached objects without server intervention. However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction. If validation fails, the transaction is aborted. To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages. When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this. Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects. An unacknowledged invalidation indicates a stale object may have been accessed in the client cache. The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding. The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers. Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small. An important BuddyCache design goal is to maintain this benefit. Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client. Redirector keeps track of pages cached in each client in a group. Servers send to the redirector invalidations for pages cached in the entire group. The redirector propagates invalidations from servers to affected clients. When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members. The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system. The two possible approaches to deal with stale data are cache invalidations and cache updates. Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation. The studies show the Committing Client Server Redirector x2. Store x 6. Update x 3. Commit x 4. Commit OK 5. Commit OK1. Commit x Figure 3: Peer update. benefits are strongly workload-dependent. In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages. Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes. Larger caches are likely to contain much more data than is actively used. Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful. Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member. With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server. BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments. It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group. This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors. As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems. The peer update works as follows. An update commit request from a client arriving at the redirector contains the object updates. Redirector retains the updates and propagates the request to the coordinating server. After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group. The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3). Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data. The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction. E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server. Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1. If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client). Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing. The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3]. Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client. Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations. The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers. The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date. Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23]. Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions. A page version number is incremented at a server when at transaction that modifies objects on the page commits. Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number. Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers. If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version. The page version numbers enable independent commits but page version checks only detect page-level conflicts. To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations. Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups. Potentially, it may be faster to access data cached in another peer group than to access a remote server. In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile. We have not pursued this possibility for several reasons. In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30]. In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur. Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast. We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow. As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now. To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure. Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache. From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4. IMPLEMENTATION In this section we provide the details of the BuddyCache implementation. We have implemented BuddyCache in the Thor client/server object-oriented database [23]. Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects. Applications run at the clients and interact with the system by making calls on methods of cached objects. All method calls occur within atomic transactions. Clients communicate with servers to fetch pages or to commit a transaction. The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory. The disk is organized as a collection of pages which are the units of disk access. The stable log holds commit information and object modifications for committed transactions. The server memory contains cache directory and a recoverable modified object cache called the MOB. The directory keeps track of which pages are cached by which clients. The MOB holds recently modified objects that have not yet been written back to their pages on disk. As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1. We provide some of the relevant OCC protocol implementation details. The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction. The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers. If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB. The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log. Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects. Servers will abort a transaction that used obsolete objects. However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send. Invalidation messages are small because they simply identify obsolete objects. Furthermore, they are sent in the background, batched and piggybacked on other messages. When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them. The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects. Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses. Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1. Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients. When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure. It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches. To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector. To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages. A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid. Only complete pages are used by the peer fetch. The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4. When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client. In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3). The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows. An update commit request from a client arriving at the redirector contains the object updates. Redirector retains the updates and propagates the request to the coordinator server. After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group. The redirector forwards the reply to the committing client. It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.) Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group). The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data. In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server. Within the committing client group, the arriving invalidations are not propagated. Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server. An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete. In contrast, an update of a complete page preserves the complete page status. As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing. That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch. Therefore, the effect of peer update is similar to eager fragment reconstruction [2]. We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members. As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects. Clients use page version numbers to provide this extra coherence information. That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server. Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects. The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion). The main implementation issue is concerned with maintaining this mapping efficiently. At the server side, when modifications commit, servers associate page version numbers with the invalidations. At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation. We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed. The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations. We now describe how the client manages the mapping ObjectToVersion. The client maintains a page version number for each cached page. The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page. The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page. Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5). The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number. That is, obsolete updates or invalidations received out of sequence do not affect the value of an object. To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled. When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced. The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows. If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object. If the object is not present in the vcache, its version number is equal the version number of its containing cached page. Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache. Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache. However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5. BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently. The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects. Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact. We have designed a failover protocols for BuddyCache but have not implemented it yet. The appendix outlines the protocol. 6. PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding. Is the cure worse then the disease? To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions. This section presents a simple analytical performance model for this benefit. The avoided server interactions correspond to different types of client cache misses. These can be cold misses, invalidation misses and capacity misses. Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses. Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited. The client cache misses are determined by several variables, including the workload and the cache configuration. Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments. To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses). We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache. We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base). To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses). In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects. Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols. In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols. Technology trends indicate that both benefits will remain important in the foreseeable future. The trend toward increase in available network bandwidth decreases the cost of the update-only protocols. However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive. To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations. One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group. Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently. We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses. Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base. Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base). For simplicity, our model assumes the fetch and commit times are constant. In general they may vary with the server load, e.g. they depend on the total number of clients in the system. The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data. In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated). Consider an execution with cold misses. A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions. We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages. In BC, r cold misses for page P reach the redirector. The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected. Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses. A client starts with a hot cache containing the working set of N pages. We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload. In a group containing the writer (BCW ), peer update eliminates all invalidation misses. In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses. Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected. Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch. Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected. Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems. Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S). We compute the completion times derived using the above model and derive the benefits. We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup. We use two systems in our experiments. The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers. The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover. Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application. We use OO7 because it is a standard benchmark for measuring object storage system performance. The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects. Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections. We use a medium database that has 200 atomic parts per composite part. The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients. We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache. Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only. This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses. To keep the length of our experiments reasonable, we use small caches. The OO7 benchmark generates database modules of predefined size. In our implementation of OO7, the private module size is about 38MB. To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client. The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above. The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests. We consider two types of transaction workloads in our analysis, read-only and read-write. In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph. Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite. A single transaction includes one traversal and there is no sleep time between transactions. Both read-only and read-write transactions always work with data from the same module. Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions. The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates. In Base system clients connect directly to the database. In Buddy system clients connect to the redirector that connects to the database. We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy. The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2. They were connected by a 100Mb/s Ethernet. The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache. The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system. For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server. We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system. Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network. All the numbers were computed by averaging measured request latency over 1000 requests. The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network. The commit cost increases with the number of clients since commits are processed sequentially. The fetch cost does not increase as much because the server cache reduces this cost. In a large system with many groups, however, the server cache becomes less efficient. To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs. In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page. We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request. Table 2 summarizes the latencies that allows us to break down the peer fetch costs. CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector. AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client. The local network latency is fixed and less than 0.1 ms. The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time. This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply. This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer. The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time. The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time. The version cache has an entry only when invalidations or updates arrive out of order. This may happen when a transaction accesses objects in multiple servers. Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below. To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations. The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates. It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion. The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms. The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance. We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems. We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network. Figures 7 and 8 show the overall time to complete 1000 cold cache transactions. The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group. The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case. The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests. In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches. In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches. Figure 8 shows the overall time and cost break down in the 80 ms network. The BuddyCache provides similar performance improvements as with the 40ms network. Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times. Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load. The cost of the extra mechanism dominates BuddyCache benefit when network latency is low. At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement. Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values. The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations. One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group. In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers). Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group. Buddy system with one group containing a single writer and another group running three readers models the Reader group. In Base, one writer and three readers access the server directly. This simple configuration is sufficient to show the impact of BuddyCache techniques. Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions. We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions. Here again, the reported numbers are derived from the local area network experiment results. The results show that the BuddyCache reduces significantly the completion time compared to the Base system. In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base. This benefit is due to peer update that avoids all misses due to updates. The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server. The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol. Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group. This difference is similar in 80ms network. Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load. The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range. The figure includes both the measured improvement and the improvement derived using the analytical model. As in cold cache experiments, here the analytical results predict the measured improvement closely. The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments). As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7. CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task. They require strong consistency for shared persistent data and efficient access to fine-grained objects. These properties are difficult to provide in wide-area network because of high network latency. This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments. The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients. BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group. Redirection, however, can interfere with object availability. Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers. It provides fine-grained validation using inexpensive coarse-grain version information. We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies. Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly. The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8. ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed. We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9. REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira. Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System. Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari. Efficient optimistic concurrencty control using loosely synchronized clocks. In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel. Treadmarks: Shared memory computing on networks of workstations. IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin. Two Adaptive Hybrid Cache Coherency Protocols. In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker. Fast Crash Recovery in Distributed File Systems. PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu. Maintaining Strong Cache Consistency in the World Wide Web. In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton. A Status Report on the OO7 OODBMS Benchmarking Effort. In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels. A Hierarchical Internet Object Cache. In USENIX Annual Technical Conference, January 1995. [10] J. Chase, S. Gadde, and M. Rabinovich. Directory Structures for Scalable Internet Caches. Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J. Chase, S. Gadde, and M. Rabinovich. Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network. In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li. Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson. Cooperative caching: Using remote client memory to improve file system performance. Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony, and W. Zwaenepoel. Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory. In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder. Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol. In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy. Implementing Global Memory Management in a Workstation Cluster. Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy. Integrating Coherency and Recoverablity in Distributed Systems. In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al. PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store. In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny. Transactional Client-Server Cache Consistency: Alternatives and Performance. In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny. Global Memory Management for Client-Server DBMS Architectures. In Proceedings of the 19th Intl. Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat. The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases. PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif. Replicated document management in a group communication system. In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya. Providing Persistent Objects in Distributed Systems. In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres. A Low-bandwidth Network File System. In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov. Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems. In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira. Opportunistic Log: Efficient Installation Reads in a Reliable Object Server. In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma. ALMI: An Application Level Multicast Infrastructure. In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman. Efficient Cooperative Caching Using Hints. In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson. WebFS: A Global Cache Coherent File System. Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy. On the Scale and Performance of Cooperative Web Proxy Caching. In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin. Hierarchical Cache Consistency in a WAN. In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin. Volume Leases for Consistency in Large-Scale Systems. IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin. Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach. ACM Transactions on Database Systems, 22:570-627, December 1997. 10. APPENDIX This appendix outlines the BuddyCache failover protocol. To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group. The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures. A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol. The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol. The group reconfiguration protocol is similar to the one presented in [25]. Here we describe how the failover manages the BuddyCache state. To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches. In the case of a client failure, the failover removes the crashed client pages from the directory. Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages. In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6]. The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete. Requests outstanding at the redirector at the time of the crash may be lost. A lost fetch request will time out at the client and will be retransmitted. A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol. A client will restart the transaction and the commit request will be retransmitted after the failover. Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients. Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies. Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded. Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure. Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data. The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant. When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o. Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures. Now consider the validation using version numbers. The transaction commit record contains a version number for each object read by the transaction. The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client. The invariant holds since the client never applies an earlier modification after a later modification has been received. Retransmition of invalidations and updates maintains this invariant. The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation. It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure. The failover protocol has not been implemented yet. 39",
    "original_translation": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la transacción se cancela. Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de búsqueda de pares envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados. Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente. El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente. El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños. Un objetivo importante del diseño de BuddyCache es mantener este beneficio. Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo. Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché. Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. Almacén x 6. Actualización x 3. Comprométete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes. Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente. Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una red de área amplia serían derrochadores. Sin embargo, los protocolos de coherencia basados en invalidación pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interés para otro miembro del grupo. Con un protocolo basado en invalidación, la actualización de un miembro invalidará la copia en caché de otro miembro, lo que provocará que este último realice una recuperación de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualización e invalidación en entornos de redes de área amplia. Evita la penalización de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalización de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusión localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en caché anteriores. La actualización entre pares funciona de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que la transacción se confirma, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación, y también propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmación. 3.3 Confirmación individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminación de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en caché transaccional, ya que un cliente que es lento para reconocer una invalidación o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacción. Por ejemplo, un ingeniero que realiza una revisión repetida al mismo objeto de diseño compartido (y por lo tanto tiene la última versión del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situación representada en la figura 4 donde el Cliente1 realiza una transacción T que lee la última versión de un objeto x en la página P recientemente modificada por el Cliente1. Si la solicitud de confirmación para T llega al servidor antes de que la confirmación colectiva de Cliente2 por la última modificación de x llegue al servidor, el procedimiento de validación de OCC considera que x está obsoleto y aborta T (porque, como se explicó anteriormente, una invalidación no reconocida por un cliente actúa como indicación para el servidor de que el valor del objeto en caché está obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la corrección del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asíncronas son una parte importante de la razón por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasión de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envían y procesan de forma asíncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devolución de llamada jerárquica [32], pero la naturaleza asincrónica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrónicas. El protocolo de validación de confirmación en solitario permite a un cliente con objetos actualizados confirmar una transacción incluso si la confirmación del grupo se retrasa debido a pares lentos o caídos. El protocolo requiere que los clientes incluyan información adicional con los conjuntos de lectura de transacciones en el mensaje de confirmación, para indicar al servidor que los objetos leídos por la transacción están actualizados. Los números de versión de los objetos podrían proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionó anteriormente, mantener números de versión por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaño de directorio) en todo el sistema de objetos cuando los objetos son pequeños [23]. En cambio, solo utiliza números de versión de página de grano grueso para identificar versiones de objetos de grano fino. El número de versión de una página se incrementa en un servidor cuando una transacción que modifica objetos en la página se confirma. Las actualizaciones realizadas por una única transacción y las invalidaciones correspondientes son identificadas de manera única por el número de versión de la página modificada. Los números de versión de la página se propagan a los clientes en respuestas de recuperación, respuestas de confirmación y con invalidaciones, y los clientes incluyen los números de versión de la página en las solicitudes de confirmación enviadas a los servidores. Si una transacción falla en la validación debido a la falta de reconocimiento de grupo, el servidor verifica los números de versión de página de los objetos en el conjunto de lectura de la transacción y permite que la transacción se confirme si el cliente ha leído desde la última versión de la página. Los números de versión de la página permiten confirmaciones independientes, pero las verificaciones de versión de página solo detectan conflictos a nivel de página. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes. Potencialmente, puede ser más rápido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podría ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en caché de pares de múltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en caché web, simplemente aumentar la población de clientes en una caché proxy a menudo aumenta la tasa general de aciertos en la caché [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacción explícita entre clientes y la colaboración, lo que sugiere que es poco probable que ocurra la recuperación entre grupos. Además, las mediciones de sistemas de almacenamiento en caché web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexión de red entre los grupos de pares sea muy rápida. Estamos principalmente interesados en entornos donde compañeros que colaboran estrechamente tienen una conectividad rápida a corta distancia, pero la conexión entre grupos de compañeros puede ser lenta. Como resultado, decidimos que el soporte para la recuperación entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compañeros con recursos heterogéneos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compañeros o, cuando esté disponible, en un nodo separado dentro de la infraestructura del sitio. Además, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una caché de pares en espera para recibir páginas recuperadas por otros pares, emulando una caché central algo similar a una caché de proxy web regional. Desde el punto de vista del protocolo de coherencia de caché BuddyCache, sin embargo, un caché de compañero en espera es equivalente a un caché de compañero regular y, por lo tanto, no consideramos este caso por separado en la discusión de este documento. 4. En esta sección proporcionamos los detalles de la implementación de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en caché de estos objetos. Las aplicaciones se ejecutan en los clientes e interactúan con el sistema realizando llamadas a métodos de objetos en caché. Todas las llamadas a métodos ocurren dentro de transacciones atómicas. Los clientes se comunican con los servidores para obtener páginas o realizar una transacción. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volátil. El disco está organizado como una colección de páginas que son las unidades de acceso al disco. El registro estable guarda la información de confirmación y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de caché y una caché de objetos modificados recuperable llamada MOB. El directorio lleva un registro de qué páginas están almacenadas en caché por qué clientes. El MOB contiene objetos recientemente modificados que aún no han sido escritos de vuelta en sus páginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de caché base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la Sección 3.1. Proporcionamos algunos de los detalles relevantes de la implementación del protocolo OCC. El cliente lleva un registro de los objetos que son leídos y modificados por su transacción; envía esta información, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacción. Los servidores determinan si la confirmación es posible, utilizando un protocolo de confirmación de dos fases si la transacción utilizó objetos en múltiples servidores. Si la transacción se lleva a cabo, las nuevas copias de los objetos modificados se añaden al registro y también se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperación escaneando el registro. Dado que los objetos no están bloqueados antes de ser utilizados, una confirmación de transacción puede hacer que las cachés contengan objetos obsoletos. Los servidores abortarán una transacción que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviándoles mensajes de invalidación; un servidor utiliza su directorio y la información sobre la transacción de confirmación para determinar qué mensajes de invalidación enviar. Los mensajes de invalidación son pequeños porque simplemente identifican objetos obsoletos. Además, se envían en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidación, elimina los objetos obsoletos de su caché y aborta la transacción actual si los utilizó. El cliente sigue conservando páginas que contienen objetos invalidados; estas páginas ahora están incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidación de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener páginas incompletas en la caché del cliente significa que el falso intercambio no conduce a fallos innecesarios en la caché. Los clientes reconocen las invalidaciones para indicar la eliminación de datos obsoletos, como se explica en la Sección 3.1. Los mensajes de invalidación evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo así el desperdicio de trabajo y trasladando la detección de abortos de los servidores a los clientes. Cuando una transacción se aborta, su cliente restaura las copias en caché de los objetos modificados al estado que tenían antes de que la transacción comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacción. 4.3 Redirección El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de páginas disponibles en el grupo de pares y proporciona una redirección rápida y centralizada de recuperación (ver figura 2) entre las cachés de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan páginas u objetos al incluir esa información en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la caché de grupo, el redireccionador realiza un seguimiento del estado de las páginas. Una página en caché está completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una página están marcados como inválidos. Solo se utilizan páginas completas por el proceso de recuperación de pares. El protocolo para mantener el estado de la página cuando las páginas son actualizadas e invalidadas se describe en la Sección 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una página solicitada completa no está disponible en el grupo de pares o si un par necesita confirmar una transacción, el redireccionador actúa como un proxy de servidor: reenvía la solicitud al servidor y luego reenvía la respuesta de vuelta al cliente. Además, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualización o información de invalidación a los clientes que tienen en caché la página modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la caché de grupo de pares combinada está desempeñando el papel de una única caché de cliente en el sistema base. 4.4 Actualización de pares La actualización de pares se implementa de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que una transacción se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacción generan invalidaciones de objetos para cada grupo de caché que almacena páginas que contienen los objetos modificados (incluido el grupo que realiza la confirmación). Las invalidaciones se envían de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en caché los objetos modificados se deshagan de los datos obsoletos. En grupos de caché distintos al grupo de confirmación, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en caché las páginas modificadas, recopilan las confirmaciones de los clientes y, después de completar la recopilación, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacción, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envían a los clientes que almacenan en caché esas páginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmación colectiva se propaga al servidor. Una invalidación hace que una página en caché no esté disponible para la recuperación de pares, cambiando el estado de una página completa p a incompleta. Por el contrario, una actualización de una página completa conserva el estado completo de la página. Como se muestra en los estudios de la reconstrucción de fragmentos 31 [2], esta propagación de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la recuperación entre pares. Por lo tanto, el efecto de la actualización de pares es similar a la reconstrucción de fragmentos ansiosa [2]. También hemos considerado la posibilidad de permitir que un compañero recupere una página incompleta (con objetos inválidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos inválidos. 4.5 Vcache El protocolo de validación de confirmación en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo más lentos (o fallidos). Como se explica en la Sección 3.3, el protocolo de commit único permite que una transacción T pase la validación si la información adicional de coherencia proporcionada por el cliente indica que la transacción T ha leído objetos actualizados. Los clientes utilizan los números de versión de la página para proporcionar esta información adicional de coherencia. Es decir, un cliente incluye el número de versión de la página correspondiente a cada objeto en el conjunto de objetos leídos enviado en la solicitud de confirmación al servidor. Dado que a cada actualización de objeto comprometido le corresponde un número de versión de página único, el número de versión de página asociado con un objeto permite que el procedimiento de validación en el servidor verifique si la transacción del cliente ha leído objetos actualizados. El uso de versiones de página de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeños, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en caché a la versión de página identificadora (ObjectToVersion). El principal problema de implementación se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian números de versión de página con las invalidaciones. En el momento de la validación, si hay una invalidación no reconocida pendiente para un objeto x leído por una transacción T, el procedimiento de validación verifica si el número de versión de x en el conjunto de lectura de Ts coincide con el número de versión de la invalidación pendiente más alta para x, en cuyo caso el valor del objeto está actualizado, de lo contrario, T falla en la validación. Observamos nuevamente que las verificaciones basadas en el número de versión de la página y las verificaciones basadas en el reconocimiento de invalidación son complementarias en la validación de confirmación individual y ambas son necesarias. La verificación del número de versión de la página permite que la validación avance antes de que lleguen las confirmaciones de invalidación, pero por sí sola, una verificación del número de versión de la página detecta conflictos a nivel de página y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cómo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un número de versión de la página para cada página en caché. El número de versión satisface la siguiente invariante V P sobre el estado de los objetos en una página: si una página en caché P tiene un número de versión v, entonces el valor de un objeto o en la página en caché P es inválido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacción que estableció el número de versión de P en v. Los nuevos valores de objetos y los nuevos números de versión de página llegan cuando un cliente obtiene una página o cuando llega una respuesta de confirmación o invalidaciones para esta página. Los nuevos valores del objeto modifican la página y, por lo tanto, el número de versión de la página necesita ser actualizado para mantener la invariante V P. Un número de versión de página que llega cuando un cliente obtiene una página, reemplaza la Versión del Objeto x 8 Servidor de Redirección 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el número de versión de la página para esta página. Tal actualización preserva el invariante V P. De manera similar, un número de versión de página en secuencia que llega al cliente en un mensaje de confirmación o invalidación avanza el número de versión para toda la página en caché, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus números de versión de página correspondientes también pueden llegar al cliente fuera de secuencia, en cuyo caso la actualización del número de versión de la página podría violar V P. Por ejemplo, una respuesta de confirmación para una transacción que actualiza el objeto x en la página P en el servidor S1, y el objeto y en la página Q en el servidor S2, puede entregar un nuevo número de versión para P desde el coordinador de transacciones S1 antes de que llegue una invalidación generada para una transacción anterior que ha modificado el objeto r en la página P desde S1 (como se muestra en la figura 5). El protocolo de actualización de caché garantiza que el valor de cualquier objeto o en una página en caché P refleje la actualización o invalidación con el número de versión observado más alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de números de versión de página, el cliente gestiona una pequeña caché de números de versión vcache que mantiene el mapeo de un objeto a su número de versión de página correspondiente para todas las actualizaciones de números de versión reordenadas hasta que se ensamble una secuencia completa de números de versión de página. Cuando llegan los números de versión faltantes para la página y completan una secuencia, el número de versión de toda la página se avanza. El mapeo de ObjectToVersion, incluyendo los números de versión de vcache y página, se utiliza en el momento de la confirmación de la transacción para proporcionar números de versión para el conjunto de objetos leídos de la siguiente manera. Si el objeto leído tiene una entrada en la vcache, su número de versión es igual al número de versión más alto en la vcache para este objeto. Si el objeto no está presente en la vcache, su número de versión es igual al número de versión de la página en caché que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la caché del cliente, incluyendo los números de versión de las páginas y la vcache. El cliente puede limitar el tamaño de la caché virtual según sea necesario, ya que volver a cargar una página elimina todos los números de versión de página reordenados de la caché virtual. Sin embargo, esperamos que la reorganización de números de versión sea poco común y, por lo tanto, esperamos que la vcache sea muy pequeña. 5. Un grupo de clientes contiene múltiples nodos de cliente y un objeto de página de versión redi32 VCache Cliente Caché Cliente Página Caché Figura 6: Mapa de Objeto a Versión con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutación por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. Además, el fallo del redireccionador debería permitir que los clientes no afectados mantengan sus cachés intactas. Hemos diseñado un protocolo de conmutación por error para BuddyCache pero aún no lo hemos implementado. El apéndice describe el protocolo. 6. La redirección de BuddyCache en la evaluación de rendimiento respalda los beneficios de evitar la comunicación con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes. ¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la recuperación entre pares y la actualización entre pares se deben a la evitación de interacciones con el servidor. Esta sección presenta un modelo de rendimiento analítico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la caché del cliente. Estos pueden ser fallos fríos, fallos de invalidación y fallos de capacidad. Nuestro análisis se centra en los fallos por frío y los fallos por invalidación, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frío. Además, las tendencias tecnológicas indican que la capacidad de memoria y almacenamiento seguirá creciendo y, por lo tanto, es probable que una configuración típica de BuddyCache no esté limitada por la caché. Los fallos de caché del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuración de caché. Nuestro análisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validación. Para estudiar el beneficio de evitar fallos en frío, consideramos el rendimiento de la caché en frío en una carga de trabajo de solo lectura (sin fallos de invalidación). Esperamos que la recuperación entre pares mejore el costo de latencia para las solicitudes de caché fría del cliente al recuperar objetos de la caché cercana. Evaluamos cómo el costo de redirección afecta este beneficio al comparar y analizar el rendimiento de una aplicación que se ejecuta en un sistema de almacenamiento con BuddyCache y sin él (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidación, consideramos el rendimiento de la caché caliente en una carga de trabajo con modificaciones (sin fallos en frío). En las cachés calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualización entre pares permite que un cliente acceda a un objeto modificado por un compañero colaborador cercano sin el retraso impuesto por los protocolos de invalidación únicamente. En grupos donde los compañeros comparten un interés de solo lectura en los objetos modificados, la recuperación entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compañero colaborador lo tenga, lo que evita el retraso de la recuperación del servidor sin el alto costo impuesto por los protocolos de solo actualización. Las tendencias tecnológicas indican que ambos beneficios seguirán siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualización únicamente. Sin embargo, la tendencia hacia cachés cada vez más grandes, que se actualizan cuando los objetos en caché son modificados, hace que los protocolos basados en invalidación sean más atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicación que se ejecuta sin BuddyCache y una aplicación que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compañero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compañero fuera del grupo. La actualización entre pares también puede evitar fallos de invalidación debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma página de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseño del objeto, y también porque este beneficio se puede derivar dado el índice de aciertos en caché y la contención de la carga de trabajo. 6.1.1 El Modelo El modelo considera cómo el tiempo para completar una ejecución con y sin BuddyCache se ve afectado por los fallos de invalidación y los fallos en frío. Considerando k clientes ejecutándose concurrentemente accediendo de manera uniforme a un conjunto compartido de N páginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacción y realizar cálculos en una transacción, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin él (Base). Para simplificar, nuestro modelo asume que los tiempos de búsqueda y confirmación son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del número total de clientes en el sistema. El número de fallos evitados por la recuperación entre pares depende de k, el número de clientes en la BuddyCache, y del interés conjunto de los clientes en los datos compartidos. En una ejecución específica de BuddyCache, se modela mediante la variable r, definida como el número de solicitudes que llegan al redireccionador para una versión dada de la página P (es decir, hasta que un objeto en la página se invalida). Considera una ejecución con fallos en frío. Un cliente comienza con una caché fría y ejecuta una carga de trabajo de solo lectura hasta que accede a las N páginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la caché del cliente es lo suficientemente grande como para contener N páginas. En BC, los fríos fallos para la página P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consideremos a continuación una ejecución con fallos de invalidación. Un cliente comienza con una caché caliente que contiene el conjunto de trabajo de N páginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualización entre pares elimina todos los fallos de invalidación. En un grupo que contiene solo lectores (BCR), durante una ejecución en estado estable con actualizaciones uniformes, una transacción del cliente tiene fallos de invalidación faltantes. Considera la secuencia de r fallos de cliente en la página P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la página P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frío, r ≤ k porque la segunda invalidación deshabilita la redirección para P hasta que el próximo fallo en P provoque una recuperación del servidor. Suponiendo un acceso uniforme, un fallo de invalidación del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperación del servidor), y una probabilidad de (1 − 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacción única en los sistemas Base, BCR y BCW. En los experimentos descritos a continuación, medimos los parámetros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalización derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalización y beneficios medidos directamente en los experimentos. 6.2 Configuración Experimental Antes de presentar nuestros resultados, describimos nuestra configuración experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectándose directamente a los servidores. El sistema Buddy ejecuta nuestra implementación del prototipo de BuddyCache en Thor, admitiendo la recuperación de pares, la actualización de pares y la confirmación en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark está diseñado para capturar las características de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicación específica. Utilizamos OO7 porque es un punto de referencia estándar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un árbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un gráfico de partes atómicas vinculadas por objetos de conexión; cada parte atómica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atómicas por parte compuesta. La base de datos multiusuario asigna a cada cliente un módulo privado que consiste en un árbol de objetos de ensamblaje, y agrega un módulo compartido adicional que escala proporcionalmente al número de clientes. Esperamos que una configuración típica de BuddyCache no esté limitada por la caché y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la caché. Dado que el objetivo de nuestro estudio es evaluar qué tan efectivamente nuestras técnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras técnicas tienen en los fallos de caché frío y de consistencia de caché, y aislar tanto como sea posible el efecto de los fallos de capacidad de caché. Para mantener la duración de nuestros experimentos razonable, utilizamos cachés pequeños. El benchmark OO7 genera módulos de base de datos de tamaño predefinido. En nuestra implementación de OO7, el tamaño del módulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la caché, utilizamos un único módulo privado y elegimos un tamaño de caché de 40MB para cada cliente. La base de datos OO7 se genera con módulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos están agrupados en páginas de 8K, que también son la unidad de transferencia en las solicitudes de recuperación. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro análisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idéntico a T1 excepto que modifica todas las partes atómicas en un solo compuesto. Una transacción única incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo módulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacción, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de búsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una caché de 50MB (de los cuales 6MB se utilizaron para el búfer de objetos modificados), el cliente tenía una caché de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos básicos Esta sección analiza el costo básico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 Redirección Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtención del servidor), el costo adicional de la redirección incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperación o confirmación del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmación y recuperación del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de área rápida. Todos los números fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirección al cruzar el redireccionador no es muy alto, incluso en una red de área local. El costo de la confirmación aumenta con el número de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperación no aumenta tanto porque la caché del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la caché del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperación entre pares, medimos la latencia de la recuperación entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperación entre pares, el costo de la redirección incluye, además del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este último incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la página solicitada. Medimos directamente el tiempo para copiar y desenrollar la página solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperación de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador más un viaje de ida y vuelta a través de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud más un viaje de ida y vuelta a través de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando está bloqueado esperando una respuesta de búsqueda o confirmación. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podría ser mitigado por una implementación multi-hilo en un sistema con programación preemptiva. 6.3.2 Versión de Caché El commit en solitario permite que un cliente rápido que modifica un objeto haga un commit de forma independiente a un compañero lento. El mecanismo de confirmación única introduce un procesamiento adicional en el servidor durante la validación de la transacción, y un procesamiento adicional en el cliente durante la confirmación de la transacción y en el momento del procesamiento de actualización o invalidación. Los gastos generales del lado del servidor son mínimos y consisten en una actualización del número de versión de la página en el momento de la confirmación, y una comparación del número de versión en el momento de la validación de la transacción. La caché de versión tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacción accede a objetos en múltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor único y, por lo tanto, el tiempo de confirmación adicional de la gestión de la caché de versiones en el cliente no contribuye a los resultados presentados en la sección a continuación. Para medir estos costos adicionales del lado del cliente en un sistema de múltiples servidores, instrumentamos la implementación de la caché de versiones para ejecutarse con una traza de carga de trabajo que incluía invalidaciones reordenadas y cronometramos las operaciones básicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operación de búsqueda de caché de versión para cada objeto leído por la transacción en el momento de preparación de la solicitud de compromiso, y una operación de inserción de caché de versión para cada objeto actualizado por una transacción en el momento de procesamiento de la respuesta de compromiso, pero solo si la página actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmación se mantengan al mínimo, ya que el cliente está esperando de forma síncrona la finalización de la confirmación. Las mediciones muestran que en el peor de los casos, cuando llega un gran número de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en páginas reordenadas, el costo de actualizar la caché de versión es de 0.6 ms. El costo de tiempo de invalidación es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementación de la caché de versiones para reducir aún más estos costos. 6.4 Rendimiento general Esta sección examina las mejoras de rendimiento observadas por una aplicación que ejecuta el benchmark OO7 con un BuddyCache en una red de área amplia. 6.4.1 Fallos en frío Para evaluar las mejoras de rendimiento al evitar fallos en frío, comparamos el rendimiento de la caché en frío del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecución de los sistemas en el entorno de la red de área local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de área amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en caché fría. Los números fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frío solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frío solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparación con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cálculos para el cliente, solicitudes de recuperación directa, recuperaciones de pares y solicitudes de confirmación. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperación entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperación del servidor para cada cliente individual disminuye porque, con más clientes accediendo a un módulo compartido de tamaño fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperación de pares en comparación con la recuperación directa, pero este beneficio se ve contrarrestado por los tiempos de confirmación aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relación con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de caché 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT función de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias típicas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Sorprendentemente, los resultados analíticos predicen la mejora medida muy de cerca, aunque son ligeramente más altos que los valores empíricos. La razón principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidación evitados, comparamos el rendimiento de caché caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interés de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un único cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compañeros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compañeros con un grupo que contiene un único escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuración simple es suficiente para mostrar el impacto de las técnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de caché caliente de OO7. Obtenemos los números ejecutando 2000 transacciones para filtrar los fallos en frío y luego medimos el tiempo de las siguientes 1000 transacciones. Aquí nuevamente, los números reportados se derivan de los resultados del experimento de la red de área local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalización en comparación con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparación con la Base. Este beneficio se debe a la actualización entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperación entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperación local evitando el retraso de la recuperación desde el servidor. El último es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperación de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperación de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualización de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relación con Base, y Buddy Writer y Base en relación con Base) en un experimento de caché activa en función del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualización entre pares domina el gasto general en la configuración de Writer incluso en redes de baja latencia (la actualización entre pares incurre en un gasto mínimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Como en experimentos de caché fría, aquí los resultados analíticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pérdida de invalidación es mínimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de caché fría). Como en el caso de caché fría, la razón por la que el modelo analítico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÓN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en una red de área extensa debido a la alta latencia de red. Este artículo describe BuddyCache, una nueva técnica de almacenamiento en caché cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La técnica mejora el rendimiento y proporciona propiedades sólidas de corrección y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirección para obtener objetos faltantes directamente de las cachés de los miembros del grupo, y para admitir la actualización entre pares, una nueva técnica de multidifusión a nivel de aplicación ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirección puede interferir con la disponibilidad del objeto. Solo commit es una nueva técnica de validación que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validación detallada utilizando información de versión de grano grueso económica. Hemos diseñado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analíticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Las principales contribuciones del artículo son: 1. extender las técnicas de almacenamiento en caché cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementación del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluación del rendimiento basada en análisis y mediciones de los costos y beneficios de las nuevas técnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. También agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios útiles que mejoraron este artículo. 9. REFERENCIAS [1] emulab.net, la Instalación de Emulación de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. Reconstrucción de fragmentos: Proporcionando coherencia de caché global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de Computación Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre Gestión de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: Computación en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de caché híbridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. Recuperación rápida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de caché en la World Wide Web. En la 17ª Conferencia Internacional sobre Sistemas de Computación Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluación del rendimiento del sistema de gestión de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una caché de objetos jerárquica en Internet. En la Conferencia Técnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachés de Internet escalables. Informe Técnico CS-1997-18, Departamento de Ciencias de la Computación, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: Caché de proxy cooperativa en una red de área amplia. En el Tercer Taller Internacional de Caché de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. Caché web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2º Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. Caché cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilación y en tiempo de ejecución para una memoria compartida distribuida eficiente. En Actas de IEEE, Edición Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la caché: un protocolo de intercambio de caché web escalable de área amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. Implementación de Gestión Global de Memoria en un Clúster de Estaciones de Trabajo. Actas del 15º Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: Diseño, Implementación y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de caché transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, páginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. Gestión global de memoria para arquitecturas de sistemas de gestión de bases de datos cliente-servidor. En Actas del 19º Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El Búfer de Objeto Modificado: Una Técnica de Gestión de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto Tecnológico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. Gestión de documentos replicados en un sistema de comunicación grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13ª Conferencia Europea sobre Programación Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18º Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. Replicación con marca de vista: un nuevo método de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de Computación Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalación eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de Multidifusión a Nivel de Aplicación. En el 3er Simposio USENIX sobre Tecnologías y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de caché cooperativa utilizando pistas. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en Caché Global. Informe técnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del Caché de Proxies Web Cooperativos. En el 17º Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerárquica de caché en una WAN. En el Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. Compartición adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÉNDICE Este apéndice describe el protocolo de conmutación por error de BuddyCache. Para dar cabida a clientes heterogéneos, incluidos los dispositivos portátiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseño de BuddyCache asume que las cachés del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresía detecta el fallo de un cliente o un redireccionador intercambiando mensajes periódicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutación por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuración y reinicia el protocolo. El protocolo de reconfiguración del grupo es similar al presentado en [25]. Aquí describimos cómo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de páginas redireccionadas y el reenvío de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachés. En caso de un fallo del cliente, el failover elimina las páginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmación, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en caché las páginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutación por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de páginas utilizando un protocolo similar al descrito en [6]. El redireccionador recién reiniciado solicita a los miembros activos del grupo la lista de páginas que están almacenando en caché y el estado de estas páginas, es decir, si las páginas están completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperación perdida expirará en el cliente y será retransmitida. Una transacción que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma después del cambio se trata como una transacción regular; una transacción que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciará la transacción y la solicitud de confirmación será retransmitida después del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caído podrían evitar la recolección de basura de las invalidaciones pendientes en los servidores o la caché virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los números de versión únicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validación de transacciones depende del protocolo de coherencia de caché para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutación por error de BuddyCache no compromete la corrección del procedimiento de validación. Recuerda que la validación de transacciones de BuddyCache utiliza dos mecanismos complementarios, números de versión de página y confirmaciones de invalidación de los clientes, para verificar que una transacción ha leído datos actualizados. La propagación de la confirmación de invalidación (y actualización) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmación de una modificación (invalidación o actualización) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en caché el objeto o bien ha instalado el valor más reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmación de un cliente para una transacción T que lee un objeto o después de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidación no confirmada para o pendiente para este grupo, la versión del objeto leída por la transacción T está actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validación utilizando números de versión. El registro de confirmación de transacción contiene un número de versión para cada objeto leído por la transacción. El protocolo de número de versión mantiene la invariante V P que garantiza que el valor del objeto o leído por la transacción corresponda al número de versión más alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificación anterior después de haber recibido una modificación posterior. La retransmisión de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validación verifica que el número de versión en el registro de confirmación coincida con el número de versión en la invalidación pendiente no reconocida. Es fácil ver que, dado que esta comprobación es una comprobación cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutación por error aún no ha sido implementado.",
    "original_sentences": [
        "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
        "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
        "These properties are difficult to provide in wide-area networks because of high network latency.",
        "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
        "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
        "We have implemented a BuddyCache prototype and evaluated its performance.",
        "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
        "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
        "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
        "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
        "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
        "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
        "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
        "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
        "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
        "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
        "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
        "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
        "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
        "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
        "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
        "Cooperative object caching systems [2] provide these properties.",
        "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
        "Interaction with the server increases latency.",
        "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
        "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
        "The engineers use a collaborative CAD application to revise and update complex project design documents.",
        "The shared documents are stored in transactional repository servers at the company home site.",
        "The engineers use workstations running repository clients.",
        "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
        "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
        "A coherence protocol ensures that client caches remain consistent when objects are modified.",
        "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
        "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
        "BuddyCache presents two main technical challenges.",
        "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
        "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
        "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
        "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
        "If the client request can not be served locally, the redirector forwards it to a remote server.",
        "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
        "BuddyCache redirects subsequent requests for this object to the caching client.",
        "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
        "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
        "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
        "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
        "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
        "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
        "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
        "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
        "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
        "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
        "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
        "These techniques use the server to provide redirection and do not consider issues of high network latency.",
        "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
        "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
        "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
        "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
        "This multicast transport level solution is geared to the single writer semantics of web objects.",
        "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
        "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
        "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
        "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
        "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
        "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
        "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
        "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
        "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
        "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
        "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
        "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
        "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
        "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
        "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
        "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
        "The servers provide disk storage for the persistent objects.",
        "A persistent object is owned by a single server.",
        "Objects may be small (order of 100 bytes for programming language objects [23]).",
        "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
        "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
        "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
        "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
        "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
        "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
        "If the client request can be served locally, the interaction with the server is avoided.",
        "If the client request can not be served locally, redirector forwards it to a remote server.",
        "Redirection approach has been used to improve the performance of web caching protocols.",
        "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
        "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
        "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
        "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
        "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
        "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
        "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
        "In addition, redirector manages cache coherence.",
        "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
        "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
        "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
        "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
        "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
        "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
        "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
        "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
        "Below we outline the OCC protocol [3].",
        "The OCC protocol uses object-level coherence.",
        "When a client requests a missing object, the server transfers the containing page.",
        "Transaction can read and update locally cached objects without server intervention.",
        "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
        "If validation fails, the transaction is aborted.",
        "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
        "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
        "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
        "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
        "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
        "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
        "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
        "An important BuddyCache design goal is to maintain this benefit.",
        "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
        "Redirector keeps track of pages cached in each client in a group.",
        "Servers send to the redirector invalidations for pages cached in the entire group.",
        "The redirector propagates invalidations from servers to affected clients.",
        "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
        "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
        "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
        "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
        "The studies show the Committing Client Server Redirector x2.",
        "Store x 6.",
        "Update x 3.",
        "Commit x 4.",
        "Commit OK 5.",
        "Commit OK1.",
        "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
        "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
        "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
        "Larger caches are likely to contain much more data than is actively used.",
        "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
        "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
        "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
        "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
        "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
        "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
        "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
        "The peer update works as follows.",
        "An update commit request from a client arriving at the redirector contains the object updates.",
        "Redirector retains the updates and propagates the request to the coordinating server.",
        "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
        "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
        "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
        "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
        "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
        "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
        "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
        "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
        "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
        "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
        "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
        "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
        "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
        "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
        "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
        "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
        "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
        "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
        "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
        "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
        "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
        "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
        "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
        "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
        "We have not pursued this possibility for several reasons.",
        "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
        "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
        "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
        "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
        "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
        "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
        "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
        "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
        "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
        "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
        "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
        "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
        "All method calls occur within atomic transactions.",
        "Clients communicate with servers to fetch pages or to commit a transaction.",
        "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
        "The disk is organized as a collection of pages which are the units of disk access.",
        "The stable log holds commit information and object modifications for committed transactions.",
        "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
        "The directory keeps track of which pages are cached by which clients.",
        "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
        "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
        "We provide some of the relevant OCC protocol implementation details.",
        "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
        "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
        "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
        "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
        "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
        "Servers will abort a transaction that used obsolete objects.",
        "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
        "Invalidation messages are small because they simply identify obsolete objects.",
        "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
        "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
        "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
        "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
        "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
        "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
        "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
        "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
        "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
        "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
        "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
        "Only complete pages are used by the peer fetch.",
        "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
        "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
        "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
        "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
        "An update commit request from a client arriving at the redirector contains the object updates.",
        "Redirector retains the updates and propagates the request to the coordinator server.",
        "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
        "The redirector forwards the reply to the committing client.",
        "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
        "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
        "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
        "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
        "Within the committing client group, the arriving invalidations are not propagated.",
        "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
        "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
        "In contrast, an update of a complete page preserves the complete page status.",
        "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
        "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
        "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
        "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
        "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
        "Clients use page version numbers to provide this extra coherence information.",
        "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
        "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
        "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
        "The main implementation issue is concerned with maintaining this mapping efficiently.",
        "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
        "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
        "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
        "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
        "We now describe how the client manages the mapping ObjectToVersion.",
        "The client maintains a page version number for each cached page.",
        "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
        "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
        "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
        "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
        "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
        "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
        "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
        "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
        "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
        "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
        "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
        "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
        "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
        "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
        "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
        "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
        "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
        "The appendix outlines the protocol. 6.",
        "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
        "Is the cure worse then the disease?",
        "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
        "This section presents a simple analytical performance model for this benefit.",
        "The avoided server interactions correspond to different types of client cache misses.",
        "These can be cold misses, invalidation misses and capacity misses.",
        "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
        "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
        "The client cache misses are determined by several variables, including the workload and the cache configuration.",
        "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
        "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
        "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
        "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
        "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
        "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
        "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
        "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
        "Technology trends indicate that both benefits will remain important in the foreseeable future.",
        "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
        "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
        "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
        "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
        "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
        "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
        "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
        "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
        "For simplicity, our model assumes the fetch and commit times are constant.",
        "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
        "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
        "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
        "Consider an execution with cold misses.",
        "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
        "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
        "In BC, r cold misses for page P reach the redirector.",
        "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
        "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
        "A client starts with a hot cache containing the working set of N pages.",
        "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
        "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
        "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
        "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
        "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
        "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
        "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
        "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
        "We compute the completion times derived using the above model and derive the benefits.",
        "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
        "We use two systems in our experiments.",
        "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
        "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
        "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
        "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
        "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
        "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
        "We use a medium database that has 200 atomic parts per composite part.",
        "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
        "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
        "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
        "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
        "To keep the length of our experiments reasonable, we use small caches.",
        "The OO7 benchmark generates database modules of predefined size.",
        "In our implementation of OO7, the private module size is about 38MB.",
        "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
        "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
        "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
        "We consider two types of transaction workloads in our analysis, read-only and read-write.",
        "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
        "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
        "A single transaction includes one traversal and there is no sleep time between transactions.",
        "Both read-only and read-write transactions always work with data from the same module.",
        "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
        "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
        "In Base system clients connect directly to the database.",
        "In Buddy system clients connect to the redirector that connects to the database.",
        "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
        "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
        "They were connected by a 100Mb/s Ethernet.",
        "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
        "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
        "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
        "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
        "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
        "All the numbers were computed by averaging measured request latency over 1000 requests.",
        "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
        "The commit cost increases with the number of clients since commits are processed sequentially.",
        "The fetch cost does not increase as much because the server cache reduces this cost.",
        "In a large system with many groups, however, the server cache becomes less efficient.",
        "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
        "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
        "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
        "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
        "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
        "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
        "The local network latency is fixed and less than 0.1 ms.",
        "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
        "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
        "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
        "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
        "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
        "The version cache has an entry only when invalidations or updates arrive out of order.",
        "This may happen when a transaction accesses objects in multiple servers.",
        "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
        "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
        "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
        "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
        "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
        "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
        "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
        "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
        "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
        "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
        "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
        "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
        "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
        "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
        "Figure 8 shows the overall time and cost break down in the 80 ms network.",
        "The BuddyCache provides similar performance improvements as with the 40ms network.",
        "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
        "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
        "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
        "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
        "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
        "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
        "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
        "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
        "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
        "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
        "In Base, one writer and three readers access the server directly.",
        "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
        "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
        "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
        "Here again, the reported numbers are derived from the local area network experiment results.",
        "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
        "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
        "This benefit is due to peer update that avoids all misses due to updates.",
        "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
        "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
        "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
        "This difference is similar in 80ms network.",
        "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
        "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
        "The figure includes both the measured improvement and the improvement derived using the analytical model.",
        "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
        "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
        "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
        "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
        "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
        "These properties are difficult to provide in wide-area network because of high network latency.",
        "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
        "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
        "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
        "Redirection, however, can interfere with object availability.",
        "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
        "It provides fine-grained validation using inexpensive coarse-grain version information.",
        "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
        "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
        "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
        "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
        "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
        "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
        "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
        "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
        "Efficient optimistic concurrencty control using loosely synchronized clocks.",
        "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
        "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
        "Treadmarks: Shared memory computing on networks of workstations.",
        "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
        "Two Adaptive Hybrid Cache Coherency Protocols.",
        "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
        "Fast Crash Recovery in Distributed File Systems.",
        "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
        "Maintaining Strong Cache Consistency in the World Wide Web.",
        "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
        "A Status Report on the OO7 OODBMS Benchmarking Effort.",
        "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
        "A Hierarchical Internet Object Cache.",
        "In USENIX Annual Technical Conference, January 1995. [10] J.",
        "Chase, S. Gadde, and M. Rabinovich.",
        "Directory Structures for Scalable Internet Caches.",
        "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
        "Chase, S. Gadde, and M. Rabinovich.",
        "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
        "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
        "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
        "Cooperative caching: Using remote client memory to improve file system performance.",
        "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
        "Cox, R. Rajamony, and W. Zwaenepoel.",
        "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
        "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
        "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
        "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
        "Implementing Global Memory Management in a Workstation Cluster.",
        "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
        "Integrating Coherency and Recoverablity in Distributed Systems.",
        "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
        "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
        "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
        "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
        "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
        "Global Memory Management for Client-Server DBMS Architectures.",
        "In Proceedings of the 19th Intl.",
        "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
        "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
        "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
        "Replicated document management in a group communication system.",
        "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
        "Providing Persistent Objects in Distributed Systems.",
        "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
        "A Low-bandwidth Network File System.",
        "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
        "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
        "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
        "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
        "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
        "ALMI: An Application Level Multicast Infrastructure.",
        "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
        "Efficient Cooperative Caching Using Hints.",
        "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
        "WebFS: A Global Cache Coherent File System.",
        "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
        "On the Scale and Performance of Cooperative Web Proxy Caching.",
        "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
        "Hierarchical Cache Consistency in a WAN.",
        "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
        "Volume Leases for Consistency in Large-Scale Systems.",
        "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
        "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
        "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
        "APPENDIX This appendix outlines the BuddyCache failover protocol.",
        "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
        "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
        "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
        "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
        "The group reconfiguration protocol is similar to the one presented in [25].",
        "Here we describe how the failover manages the BuddyCache state.",
        "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
        "In the case of a client failure, the failover removes the crashed client pages from the directory.",
        "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
        "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
        "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
        "Requests outstanding at the redirector at the time of the crash may be lost.",
        "A lost fetch request will time out at the client and will be retransmitted.",
        "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
        "A client will restart the transaction and the commit request will be retransmitted after the failover.",
        "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
        "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
        "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
        "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
        "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
        "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
        "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
        "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
        "Now consider the validation using version numbers.",
        "The transaction commit record contains a version number for each object read by the transaction.",
        "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
        "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
        "Retransmition of invalidations and updates maintains this invariant.",
        "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
        "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
        "The failover protocol has not been implemented yet. 39"
    ],
    "translated_text_sentences": [
        "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común.",
        "Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino.",
        "Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red.",
        "BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia.",
        "El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos.",
        "Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento.",
        "Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos.",
        "Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1.",
        "INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan.",
        "Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia.",
        "Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada.",
        "BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia.",
        "Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción.",
        "Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos.",
        "Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24].",
        "Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil.",
        "Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente.",
        "Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte.",
        "El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor.",
        "Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos.",
        "Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina.",
        "Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades.",
        "Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física.",
        "La interacción con el servidor aumenta la latencia.",
        "La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia.",
        "Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción.",
        "Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos.",
        "Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa.",
        "Los ingenieros utilizan estaciones de trabajo con clientes de repositorio.",
        "Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta.",
        "Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente.",
        "Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados.",
        "El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos.",
        "Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo.",
        "BuddyCache presenta dos desafíos técnicos principales.",
        "Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché.",
        "El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos.",
        "BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11].",
        "Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos.",
        "Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto.",
        "Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten.",
        "BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché.",
        "De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo.",
        "BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo.",
        "Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos.",
        "Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente.",
        "Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica.",
        "Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad?",
        "Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema.",
        "Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red.",
        "Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio.",
        "Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia.",
        "El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida.",
        "Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red.",
        "Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan.",
        "Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché.",
        "Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina.",
        "Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache.",
        "Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web.",
        "Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales.",
        "La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27].",
        "El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada.",
        "Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN.",
        "El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento.",
        "El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación.",
        "Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista.",
        "Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo.",
        "Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales.",
        "El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos.",
        "Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local.",
        "BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3.",
        "La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia.",
        "Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño.",
        "Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad.",
        "Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos.",
        "Los servidores proporcionan almacenamiento en disco para los objetos persistentes.",
        "Un objeto persistente es propiedad de un único servidor.",
        "Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]).",
        "Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas.",
        "Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente.",
        "Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos.",
        "El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos.",
        "La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos.",
        "El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos.",
        "Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor.",
        "Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto.",
        "El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web.",
        "El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en caché transaccional [19].",
        "La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente.",
        "Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes.",
        "Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché.",
        "BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador.",
        "El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador.",
        "La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado.",
        "Además, el redireccionador gestiona la coherencia de la caché.",
        "Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes.",
        "Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché.",
        "Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página).",
        "La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente.",
        "El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría.",
        "Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual.",
        "Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación.",
        "Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento.",
        "A continuación, detallamos el protocolo OCC [3].",
        "El protocolo OCC utiliza coherencia a nivel de objeto.",
        "Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene.",
        "La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor.",
        "Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada.",
        "Si la validación falla, la transacción se cancela.",
        "Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de búsqueda de pares envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen.",
        "Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto.",
        "Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados.",
        "Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente.",
        "El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente.",
        "El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto.",
        "Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños.",
        "Un objetivo importante del diseño de BuddyCache es mantener este beneficio.",
        "Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente.",
        "El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo.",
        "Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo.",
        "El redireccionador propaga invalidaciones desde los servidores a los clientes afectados.",
        "Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo.",
        "El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento.",
        "Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché.",
        "Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación.",
        "Los estudios muestran el redireccionador del servidor del cliente comprometido x2.",
        "Almacén x 6.",
        "Actualización x 3.",
        "Comprométete x 4.",
        "Compromiso OK 5.",
        "Comprometer OK1.",
        "La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo.",
        "En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes.",
        "Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente.",
        "Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente.",
        "Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una red de área amplia serían derrochadores.",
        "Sin embargo, los protocolos de coherencia basados en invalidación pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interés para otro miembro del grupo.",
        "Con un protocolo basado en invalidación, la actualización de un miembro invalidará la copia en caché de otro miembro, lo que provocará que este último realice una recuperación de alto retardo del nuevo valor desde el servidor.",
        "BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualización e invalidación en entornos de redes de área amplia.",
        "Evita la penalización de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo.",
        "Esto evita la penalización de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores.",
        "Hasta donde sabemos, este uso de multidifusión localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en caché anteriores.",
        "La actualización entre pares funciona de la siguiente manera.",
        "Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto.",
        "El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador.",
        "Después de que la transacción se confirma, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando.",
        "El redireccionador reenvía la respuesta al cliente que realiza la confirmación, y también propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en caché las páginas modificadas (ver figura 3).",
        "Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmación. 3.3 Confirmación individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminación de datos obsoletos.",
        "El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en caché transaccional, ya que un cliente que es lento para reconocer una invalidación o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacción.",
        "Por ejemplo, un ingeniero que realiza una revisión repetida al mismo objeto de diseño compartido (y por lo tanto tiene la última versión del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor.",
        "Considera una situación representada en la figura 4 donde el Cliente1 realiza una transacción T que lee la última versión de un objeto x en la página P recientemente modificada por el Cliente1.",
        "Si la solicitud de confirmación para T llega al servidor antes de que la confirmación colectiva de Cliente2 por la última modificación de x llegue al servidor, el procedimiento de validación de OCC considera que x está obsoleto y aborta T (porque, como se explicó anteriormente, una invalidación no reconocida por un cliente actúa como indicación para el servidor de que el valor del objeto en caché está obsoleto en el cliente).",
        "Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la corrección del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos.",
        "Las invalidaciones asíncronas son una parte importante de la razón por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasión de mejor rendimiento [3].",
        "Sin embargo, dado que las invalidaciones se envían y procesan de forma asíncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente.",
        "Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devolución de llamada jerárquica [32], pero la naturaleza asincrónica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrónicas.",
        "El protocolo de validación de confirmación en solitario permite a un cliente con objetos actualizados confirmar una transacción incluso si la confirmación del grupo se retrasa debido a pares lentos o caídos.",
        "El protocolo requiere que los clientes incluyan información adicional con los conjuntos de lectura de transacciones en el mensaje de confirmación, para indicar al servidor que los objetos leídos por la transacción están actualizados.",
        "Los números de versión de los objetos podrían proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionó anteriormente, mantener números de versión por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaño de directorio) en todo el sistema de objetos cuando los objetos son pequeños [23].",
        "En cambio, solo utiliza números de versión de página de grano grueso para identificar versiones de objetos de grano fino.",
        "El número de versión de una página se incrementa en un servidor cuando una transacción que modifica objetos en la página se confirma.",
        "Las actualizaciones realizadas por una única transacción y las invalidaciones correspondientes son identificadas de manera única por el número de versión de la página modificada.",
        "Los números de versión de la página se propagan a los clientes en respuestas de recuperación, respuestas de confirmación y con invalidaciones, y los clientes incluyen los números de versión de la página en las solicitudes de confirmación enviadas a los servidores.",
        "Si una transacción falla en la validación debido a la falta de reconocimiento de grupo, el servidor verifica los números de versión de página de los objetos en el conjunto de lectura de la transacción y permite que la transacción se confirme si el cliente ha leído desde la última versión de la página.",
        "Los números de versión de la página permiten confirmaciones independientes, pero las verificaciones de versión de página solo detectan conflictos a nivel de página.",
        "Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas.",
        "La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes.",
        "Potencialmente, puede ser más rápido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto.",
        "En tal caso, podría ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en caché de pares de múltiples niveles.",
        "No hemos seguido esta posibilidad por varias razones.",
        "En las cargas de trabajo de almacenamiento en caché web, simplemente aumentar la población de clientes en una caché proxy a menudo aumenta la tasa general de aciertos en la caché [30].",
        "En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacción explícita entre clientes y la colaboración, lo que sugiere que es poco probable que ocurra la recuperación entre grupos.",
        "Además, las mediciones de sistemas de almacenamiento en caché web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexión de red entre los grupos de pares sea muy rápida.",
        "Estamos principalmente interesados en entornos donde compañeros que colaboran estrechamente tienen una conectividad rápida a corta distancia, pero la conexión entre grupos de compañeros puede ser lenta.",
        "Como resultado, decidimos que el soporte para la recuperación entre grupos en BuddyCache no es una alta prioridad en este momento.",
        "Para apoyar a compañeros con recursos heterogéneos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compañeros o, cuando esté disponible, en un nodo separado dentro de la infraestructura del sitio.",
        "Además, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una caché de pares en espera para recibir páginas recuperadas por otros pares, emulando una caché central algo similar a una caché de proxy web regional.",
        "Desde el punto de vista del protocolo de coherencia de caché BuddyCache, sin embargo, un caché de compañero en espera es equivalente a un caché de compañero regular y, por lo tanto, no consideramos este caso por separado en la discusión de este documento. 4.",
        "En esta sección proporcionamos los detalles de la implementación de BuddyCache.",
        "Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23].",
        "Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en caché de estos objetos.",
        "Las aplicaciones se ejecutan en los clientes e interactúan con el sistema realizando llamadas a métodos de objetos en caché.",
        "Todas las llamadas a métodos ocurren dentro de transacciones atómicas.",
        "Los clientes se comunican con los servidores para obtener páginas o realizar una transacción.",
        "Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volátil.",
        "El disco está organizado como una colección de páginas que son las unidades de acceso al disco.",
        "El registro estable guarda la información de confirmación y las modificaciones de objetos para transacciones confirmadas.",
        "La memoria del servidor contiene un directorio de caché y una caché de objetos modificados recuperable llamada MOB.",
        "El directorio lleva un registro de qué páginas están almacenadas en caché por qué clientes.",
        "El MOB contiene objetos recientemente modificados que aún no han sido escritos de vuelta en sus páginas en disco.",
        "A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de caché base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la Sección 3.1.",
        "Proporcionamos algunos de los detalles relevantes de la implementación del protocolo OCC.",
        "El cliente lleva un registro de los objetos que son leídos y modificados por su transacción; envía esta información, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacción.",
        "Los servidores determinan si la confirmación es posible, utilizando un protocolo de confirmación de dos fases si la transacción utilizó objetos en múltiples servidores.",
        "Si la transacción se lleva a cabo, las nuevas copias de los objetos modificados se añaden al registro y también se insertan en el MOB.",
        "El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperación escaneando el registro.",
        "Dado que los objetos no están bloqueados antes de ser utilizados, una confirmación de transacción puede hacer que las cachés contengan objetos obsoletos.",
        "Los servidores abortarán una transacción que haya utilizado objetos obsoletos.",
        "Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviándoles mensajes de invalidación; un servidor utiliza su directorio y la información sobre la transacción de confirmación para determinar qué mensajes de invalidación enviar.",
        "Los mensajes de invalidación son pequeños porque simplemente identifican objetos obsoletos.",
        "Además, se envían en segundo plano, agrupados y transportados junto con otros mensajes.",
        "Cuando un cliente recibe un mensaje de invalidación, elimina los objetos obsoletos de su caché y aborta la transacción actual si los utilizó.",
        "El cliente sigue conservando páginas que contienen objetos invalidados; estas páginas ahora están incompletas con agujeros en lugar de los objetos invalidados.",
        "Realizar la invalidación de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener páginas incompletas en la caché del cliente significa que el falso intercambio no conduce a fallos innecesarios en la caché.",
        "Los clientes reconocen las invalidaciones para indicar la eliminación de datos obsoletos, como se explica en la Sección 3.1.",
        "Los mensajes de invalidación evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo así el desperdicio de trabajo y trasladando la detección de abortos de los servidores a los clientes.",
        "Cuando una transacción se aborta, su cliente restaura las copias en caché de los objetos modificados al estado que tenían antes de que la transacción comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacción. 4.3 Redirección El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura.",
        "Mantiene un directorio de páginas disponibles en el grupo de pares y proporciona una redirección rápida y centralizada de recuperación (ver figura 2) entre las cachés de pares.",
        "Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan páginas u objetos al incluir esa información en los mensajes enviados al redireccionador.",
        "Para asegurar que los objetos actualizados se obtengan de la caché de grupo, el redireccionador realiza un seguimiento del estado de las páginas.",
        "Una página en caché está completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una página están marcados como inválidos.",
        "Solo se utilizan páginas completas por el proceso de recuperación de pares.",
        "El protocolo para mantener el estado de la página cuando las páginas son actualizadas e invalidadas se describe en la Sección 4.4.",
        "Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una página solicitada completa no está disponible en el grupo de pares o si un par necesita confirmar una transacción, el redireccionador actúa como un proxy de servidor: reenvía la solicitud al servidor y luego reenvía la respuesta de vuelta al cliente.",
        "Además, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualización o información de invalidación a los clientes que tienen en caché la página modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3).",
        "El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la caché de grupo de pares combinada está desempeñando el papel de una única caché de cliente en el sistema base. 4.4 Actualización de pares La actualización de pares se implementa de la siguiente manera.",
        "Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto.",
        "El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador.",
        "Después de que una transacción se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando.",
        "El redireccionador reenvía la respuesta al cliente que realiza la confirmación.",
        "Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en caché las páginas modificadas (ver figura 3).",
        "Los servidores participantes que albergan objetos modificados por la transacción generan invalidaciones de objetos para cada grupo de caché que almacena páginas que contienen los objetos modificados (incluido el grupo que realiza la confirmación).",
        "Las invalidaciones se envían de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en caché los objetos modificados se deshagan de los datos obsoletos.",
        "En grupos de caché distintos al grupo de confirmación, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en caché las páginas modificadas, recopilan las confirmaciones de los clientes y, después de completar la recopilación, propagan las confirmaciones colectivas de vuelta al servidor.",
        "Dentro del grupo de clientes que realizan la transacción, las invalidaciones que llegan no se propagan.",
        "En cambio, las actualizaciones se envían a los clientes que almacenan en caché esas páginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmación colectiva se propaga al servidor.",
        "Una invalidación hace que una página en caché no esté disponible para la recuperación de pares, cambiando el estado de una página completa p a incompleta.",
        "Por el contrario, una actualización de una página completa conserva el estado completo de la página.",
        "Como se muestra en los estudios de la reconstrucción de fragmentos 31 [2], esta propagación de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento.",
        "Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la recuperación entre pares.",
        "Por lo tanto, el efecto de la actualización de pares es similar a la reconstrucción de fragmentos ansiosa [2].",
        "También hemos considerado la posibilidad de permitir que un compañero recupere una página incompleta (con objetos inválidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos inválidos. 4.5 Vcache El protocolo de validación de confirmación en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo más lentos (o fallidos).",
        "Como se explica en la Sección 3.3, el protocolo de commit único permite que una transacción T pase la validación si la información adicional de coherencia proporcionada por el cliente indica que la transacción T ha leído objetos actualizados.",
        "Los clientes utilizan los números de versión de la página para proporcionar esta información adicional de coherencia.",
        "Es decir, un cliente incluye el número de versión de la página correspondiente a cada objeto en el conjunto de objetos leídos enviado en la solicitud de confirmación al servidor.",
        "Dado que a cada actualización de objeto comprometido le corresponde un número de versión de página único, el número de versión de página asociado con un objeto permite que el procedimiento de validación en el servidor verifique si la transacción del cliente ha leído objetos actualizados.",
        "El uso de versiones de página de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeños, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en caché a la versión de página identificadora (ObjectToVersion).",
        "El principal problema de implementación se refiere a mantener este mapeo de manera eficiente.",
        "En el lado del servidor, cuando se realizan modificaciones, los servidores asocian números de versión de página con las invalidaciones.",
        "En el momento de la validación, si hay una invalidación no reconocida pendiente para un objeto x leído por una transacción T, el procedimiento de validación verifica si el número de versión de x en el conjunto de lectura de Ts coincide con el número de versión de la invalidación pendiente más alta para x, en cuyo caso el valor del objeto está actualizado, de lo contrario, T falla en la validación.",
        "Observamos nuevamente que las verificaciones basadas en el número de versión de la página y las verificaciones basadas en el reconocimiento de invalidación son complementarias en la validación de confirmación individual y ambas son necesarias.",
        "La verificación del número de versión de la página permite que la validación avance antes de que lleguen las confirmaciones de invalidación, pero por sí sola, una verificación del número de versión de la página detecta conflictos a nivel de página y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto.",
        "Ahora describimos cómo el cliente gestiona el mapeo ObjectToVersion.",
        "El cliente mantiene un número de versión de la página para cada página en caché.",
        "El número de versión satisface la siguiente invariante V P sobre el estado de los objetos en una página: si una página en caché P tiene un número de versión v, entonces el valor de un objeto o en la página en caché P es inválido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacción que estableció el número de versión de P en v. Los nuevos valores de objetos y los nuevos números de versión de página llegan cuando un cliente obtiene una página o cuando llega una respuesta de confirmación o invalidaciones para esta página.",
        "Los nuevos valores del objeto modifican la página y, por lo tanto, el número de versión de la página necesita ser actualizado para mantener la invariante V P. Un número de versión de página que llega cuando un cliente obtiene una página, reemplaza la Versión del Objeto x 8 Servidor de Redirección 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el número de versión de la página para esta página.",
        "Tal actualización preserva el invariante V P. De manera similar, un número de versión de página en secuencia que llega al cliente en un mensaje de confirmación o invalidación avanza el número de versión para toda la página en caché, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus números de versión de página correspondientes también pueden llegar al cliente fuera de secuencia, en cuyo caso la actualización del número de versión de la página podría violar V P. Por ejemplo, una respuesta de confirmación para una transacción que actualiza el objeto x en la página P en el servidor S1, y el objeto y en la página Q en el servidor S2, puede entregar un nuevo número de versión para P desde el coordinador de transacciones S1 antes de que llegue una invalidación generada para una transacción anterior que ha modificado el objeto r en la página P desde S1 (como se muestra en la figura 5).",
        "El protocolo de actualización de caché garantiza que el valor de cualquier objeto o en una página en caché P refleje la actualización o invalidación con el número de versión observado más alto.",
        "Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto.",
        "Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de números de versión de página, el cliente gestiona una pequeña caché de números de versión vcache que mantiene el mapeo de un objeto a su número de versión de página correspondiente para todas las actualizaciones de números de versión reordenadas hasta que se ensamble una secuencia completa de números de versión de página.",
        "Cuando llegan los números de versión faltantes para la página y completan una secuencia, el número de versión de toda la página se avanza.",
        "El mapeo de ObjectToVersion, incluyendo los números de versión de vcache y página, se utiliza en el momento de la confirmación de la transacción para proporcionar números de versión para el conjunto de objetos leídos de la siguiente manera.",
        "Si el objeto leído tiene una entrada en la vcache, su número de versión es igual al número de versión más alto en la vcache para este objeto.",
        "Si el objeto no está presente en la vcache, su número de versión es igual al número de versión de la página en caché que lo contiene.",
        "La Figura 6 muestra el mapeo de ObjectToVersion en la caché del cliente, incluyendo los números de versión de las páginas y la vcache.",
        "El cliente puede limitar el tamaño de la caché virtual según sea necesario, ya que volver a cargar una página elimina todos los números de versión de página reordenados de la caché virtual.",
        "Sin embargo, esperamos que la reorganización de números de versión sea poco común y, por lo tanto, esperamos que la vcache sea muy pequeña. 5.",
        "Un grupo de clientes contiene múltiples nodos de cliente y un objeto de página de versión redi32 VCache Cliente Caché Cliente Página Caché Figura 6: Mapa de Objeto a Versión con vcache rector que puede fallar de forma independiente.",
        "El objetivo del protocolo de conmutación por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos.",
        "Además, el fallo del redireccionador debería permitir que los clientes no afectados mantengan sus cachés intactas.",
        "Hemos diseñado un protocolo de conmutación por error para BuddyCache pero aún no lo hemos implementado.",
        "El apéndice describe el protocolo. 6.",
        "La redirección de BuddyCache en la evaluación de rendimiento respalda los beneficios de evitar la comunicación con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes.",
        "¿Es la cura peor que la enfermedad?",
        "Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la recuperación entre pares y la actualización entre pares se deben a la evitación de interacciones con el servidor.",
        "Esta sección presenta un modelo de rendimiento analítico simple para este beneficio.",
        "Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la caché del cliente.",
        "Estos pueden ser fallos fríos, fallos de invalidación y fallos de capacidad.",
        "Nuestro análisis se centra en los fallos por frío y los fallos por invalidación, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frío.",
        "Además, las tendencias tecnológicas indican que la capacidad de memoria y almacenamiento seguirá creciendo y, por lo tanto, es probable que una configuración típica de BuddyCache no esté limitada por la caché.",
        "Los fallos de caché del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuración de caché.",
        "Nuestro análisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validación.",
        "Para estudiar el beneficio de evitar fallos en frío, consideramos el rendimiento de la caché en frío en una carga de trabajo de solo lectura (sin fallos de invalidación).",
        "Esperamos que la recuperación entre pares mejore el costo de latencia para las solicitudes de caché fría del cliente al recuperar objetos de la caché cercana.",
        "Evaluamos cómo el costo de redirección afecta este beneficio al comparar y analizar el rendimiento de una aplicación que se ejecuta en un sistema de almacenamiento con BuddyCache y sin él (llamado Base).",
        "Para estudiar el beneficio de evitar los fallos de invalidación, consideramos el rendimiento de la caché caliente en una carga de trabajo con modificaciones (sin fallos en frío).",
        "En las cachés calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos.",
        "La actualización entre pares permite que un cliente acceda a un objeto modificado por un compañero colaborador cercano sin el retraso impuesto por los protocolos de invalidación únicamente.",
        "En grupos donde los compañeros comparten un interés de solo lectura en los objetos modificados, la recuperación entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compañero colaborador lo tenga, lo que evita el retraso de la recuperación del servidor sin el alto costo impuesto por los protocolos de solo actualización.",
        "Las tendencias tecnológicas indican que ambos beneficios seguirán siendo importantes en el futuro previsible.",
        "La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualización únicamente.",
        "Sin embargo, la tendencia hacia cachés cada vez más grandes, que se actualizan cuando los objetos en caché son modificados, hace que los protocolos basados en invalidación sean más atractivos.",
        "Para evaluar estos dos beneficios consideramos el rendimiento de una aplicación que se ejecuta sin BuddyCache y una aplicación que se ejecuta con BuddyCache en dos configuraciones.",
        "Uno, donde un compañero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compañero fuera del grupo.",
        "La actualización entre pares también puede evitar fallos de invalidación debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma página de forma concurrente.",
        "No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseño del objeto, y también porque este beneficio se puede derivar dado el índice de aciertos en caché y la contención de la carga de trabajo. 6.1.1 El Modelo El modelo considera cómo el tiempo para completar una ejecución con y sin BuddyCache se ve afectado por los fallos de invalidación y los fallos en frío.",
        "Considerando k clientes ejecutándose concurrentemente accediendo de manera uniforme a un conjunto compartido de N páginas en BuddyCache (BC) y Base.",
        "Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacción y realizar cálculos en una transacción, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin él (Base).",
        "Para simplificar, nuestro modelo asume que los tiempos de búsqueda y confirmación son constantes.",
        "En general, pueden variar con la carga del servidor, por ejemplo, dependen del número total de clientes en el sistema.",
        "El número de fallos evitados por la recuperación entre pares depende de k, el número de clientes en la BuddyCache, y del interés conjunto de los clientes en los datos compartidos.",
        "En una ejecución específica de BuddyCache, se modela mediante la variable r, definida como el número de solicitudes que llegan al redireccionador para una versión dada de la página P (es decir, hasta que un objeto en la página se invalida).",
        "Considera una ejecución con fallos en frío.",
        "Un cliente comienza con una caché fría y ejecuta una carga de trabajo de solo lectura hasta que accede a las N páginas mientras realiza l transacciones.",
        "Suponemos que no hay fallos de capacidad, es decir, que la caché del cliente es lo suficientemente grande como para contener N páginas.",
        "En BC, los fríos fallos para la página P llegan al redireccionador.",
        "El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos.",
        "Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consideremos a continuación una ejecución con fallos de invalidación.",
        "Un cliente comienza con una caché caliente que contiene el conjunto de trabajo de N páginas.",
        "Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura.",
        "En un grupo que contiene al escritor (BCW), la actualización entre pares elimina todos los fallos de invalidación.",
        "En un grupo que contiene solo lectores (BCR), durante una ejecución en estado estable con actualizaciones uniformes, una transacción del cliente tiene fallos de invalidación faltantes.",
        "Considera la secuencia de r fallos de cliente en la página P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la página P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos.",
        "A diferencia de los fallos en frío, r ≤ k porque la segunda invalidación deshabilita la redirección para P hasta que el próximo fallo en P provoque una recuperación del servidor.",
        "Suponiendo un acceso uniforme, un fallo de invalidación del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperación del servidor), y una probabilidad de (1 − 1/r) de ser redirigido.",
        "Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacción única en los sistemas Base, BCR y BCW.",
        "En los experimentos descritos a continuación, medimos los parámetros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S).",
        "Calculamos los tiempos de finalización derivados utilizando el modelo anterior y derivamos los beneficios.",
        "Luego validamos el modelo comparando los valores derivados con los tiempos de finalización y beneficios medidos directamente en los experimentos. 6.2 Configuración Experimental Antes de presentar nuestros resultados, describimos nuestra configuración experimental.",
        "Utilizamos dos sistemas en nuestros experimentos.",
        "El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectándose directamente a los servidores.",
        "El sistema Buddy ejecuta nuestra implementación del prototipo de BuddyCache en Thor, admitiendo la recuperación de pares, la actualización de pares y la confirmación en solitario, pero no el failover.",
        "Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark está diseñado para capturar las características de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicación específica.",
        "Utilizamos OO7 porque es un punto de referencia estándar para medir el rendimiento del sistema de almacenamiento de objetos.",
        "La base de datos OO7 contiene un árbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares.",
        "Cada parte compuesta contiene un gráfico de partes atómicas vinculadas por objetos de conexión; cada parte atómica tiene 3 conexiones salientes.",
        "Utilizamos una base de datos mediana que tiene 200 partes atómicas por parte compuesta.",
        "La base de datos multiusuario asigna a cada cliente un módulo privado que consiste en un árbol de objetos de ensamblaje, y agrega un módulo compartido adicional que escala proporcionalmente al número de clientes.",
        "Esperamos que una configuración típica de BuddyCache no esté limitada por la caché y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la caché.",
        "Dado que el objetivo de nuestro estudio es evaluar qué tan efectivamente nuestras técnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos.",
        "Esto nos permite estudiar el efecto que nuestras técnicas tienen en los fallos de caché frío y de consistencia de caché, y aislar tanto como sea posible el efecto de los fallos de capacidad de caché.",
        "Para mantener la duración de nuestros experimentos razonable, utilizamos cachés pequeños.",
        "El benchmark OO7 genera módulos de base de datos de tamaño predefinido.",
        "En nuestra implementación de OO7, el tamaño del módulo privado es de aproximadamente 38MB.",
        "Para asegurarnos de que todo el conjunto de trabajo quepa en la caché, utilizamos un único módulo privado y elegimos un tamaño de caché de 40MB para cada cliente.",
        "La base de datos OO7 se genera con módulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente.",
        "Los objetos en la base de datos están agrupados en páginas de 8K, que también son la unidad de transferencia en las solicitudes de recuperación.",
        "Consideramos dos tipos de cargas de trabajo de transacciones en nuestro análisis, solo lectura y lectura-escritura.",
        "En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas.",
        "Las transacciones de escritura utilizan el recorrido T2b que es idéntico a T1 excepto que modifica todas las partes atómicas en un solo compuesto.",
        "Una transacción única incluye un recorrido y no hay tiempo de espera entre transacciones.",
        "Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo módulo.",
        "Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacción, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura.",
        "La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de búsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg.",
        "En el sistema Base, los clientes se conectan directamente a la base de datos.",
        "En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos.",
        "Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy.",
        "El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2.",
        "Estaban conectados por un Ethernet de 100Mb/s.",
        "El servidor fue configurado con una caché de 50MB (de los cuales 6MB se utilizaron para el búfer de objetos modificados), el cliente tenía una caché de 40MB.",
        "Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos básicos Esta sección analiza el costo básico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 Redirección Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base.",
        "Para una solicitud redirigida al servidor (obtención del servidor), el costo adicional de la redirección incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor.",
        "Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperación o confirmación del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base.",
        "La Tabla 1 muestra la latencia para las solicitudes de confirmación y recuperación del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de área rápida.",
        "Todos los números fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones.",
        "Las mediciones muestran que el costo de redirección al cruzar el redireccionador no es muy alto, incluso en una red de área local.",
        "El costo de la confirmación aumenta con el número de clientes ya que las confirmaciones se procesan de forma secuencial.",
        "El costo de recuperación no aumenta tanto porque la caché del servidor reduce este costo.",
        "En un sistema grande con muchos grupos, sin embargo, la caché del servidor se vuelve menos eficiente.",
        "Para evaluar los costos adicionales de la recuperación entre pares, medimos la latencia de la recuperación entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes.",
        "En la recuperación entre pares, el costo de la redirección incluye, además del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este último incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la página solicitada.",
        "Medimos directamente el tiempo para copiar y desenrollar la página solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula.",
        "La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperación de pares.",
        "CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador más un viaje de ida y vuelta a través de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador.",
        "AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud más un viaje de ida y vuelta a través de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante.",
        "La latencia de la red local es fija y menor a 0.1 ms.",
        "La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch.",
        "Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando está bloqueado esperando una respuesta de búsqueda o confirmación.",
        "Este sobrecosto no es inherente a la arquitectura de BuddyCache y podría ser mitigado por una implementación multi-hilo en un sistema con programación preemptiva. 6.3.2 Versión de Caché El commit en solitario permite que un cliente rápido que modifica un objeto haga un commit de forma independiente a un compañero lento.",
        "El mecanismo de confirmación única introduce un procesamiento adicional en el servidor durante la validación de la transacción, y un procesamiento adicional en el cliente durante la confirmación de la transacción y en el momento del procesamiento de actualización o invalidación.",
        "Los gastos generales del lado del servidor son mínimos y consisten en una actualización del número de versión de la página en el momento de la confirmación, y una comparación del número de versión en el momento de la validación de la transacción.",
        "La caché de versión tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden.",
        "Esto puede ocurrir cuando una transacción accede a objetos en múltiples servidores.",
        "Nuestros experimentos se ejecutan en un sistema de servidor único y, por lo tanto, el tiempo de confirmación adicional de la gestión de la caché de versiones en el cliente no contribuye a los resultados presentados en la sección a continuación.",
        "Para medir estos costos adicionales del lado del cliente en un sistema de múltiples servidores, instrumentamos la implementación de la caché de versiones para ejecutarse con una traza de carga de trabajo que incluía invalidaciones reordenadas y cronometramos las operaciones básicas.",
        "El procesamiento adicional del tiempo de compromiso del cliente incluye una operación de búsqueda de caché de versión para cada objeto leído por la transacción en el momento de preparación de la solicitud de compromiso, y una operación de inserción de caché de versión para cada objeto actualizado por una transacción en el momento de procesamiento de la respuesta de compromiso, pero solo si la página actualizada carece de algunas invalidaciones o actualizaciones anteriores.",
        "Es importante que los costos adicionales de tiempo de confirmación se mantengan al mínimo, ya que el cliente está esperando de forma síncrona la finalización de la confirmación.",
        "Las mediciones muestran que en el peor de los casos, cuando llega un gran número de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en páginas reordenadas, el costo de actualizar la caché de versión es de 0.6 ms.",
        "El costo de tiempo de invalidación es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general.",
        "Actualmente estamos trabajando en optimizar la implementación de la caché de versiones para reducir aún más estos costos. 6.4 Rendimiento general Esta sección examina las mejoras de rendimiento observadas por una aplicación que ejecuta el benchmark OO7 con un BuddyCache en una red de área amplia. 6.4.1 Fallos en frío Para evaluar las mejoras de rendimiento al evitar fallos en frío, comparamos el rendimiento de la caché en frío del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base.",
        "Derivamos los tiempos cronometrando la ejecución de los sistemas en el entorno de la red de área local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de área amplia.",
        "Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en caché fría.",
        "Los números fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frío solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frío solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo.",
        "Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparación con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes.",
        "El tiempo total incluye el tiempo dedicado a realizar cálculos para el cliente, solicitudes de recuperación directa, recuperaciones de pares y solicitudes de confirmación.",
        "En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperación entre pares evitando recuperaciones directas.",
        "En el grupo de clientes de cinco y diez, el costo de recuperación del servidor para cada cliente individual disminuye porque, con más clientes accediendo a un módulo compartido de tamaño fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor.",
        "La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms.",
        "El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms.",
        "El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperación de pares en comparación con la recuperación directa, pero este beneficio se ve contrarrestado por los tiempos de confirmación aumentados.",
        "La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relación con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de caché 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT función de latencia de red, con una carga fija de servidor.",
        "El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja.",
        "En latencias típicas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes).",
        "La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Sorprendentemente, los resultados analíticos predicen la mejora medida muy de cerca, aunque son ligeramente más altos que los valores empíricos.",
        "La razón principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidación evitados, comparamos el rendimiento de caché caliente del sistema Base con dos configuraciones diferentes del sistema Buddy.",
        "Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interés de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache.",
        "En cada uno de los tres sistemas, un único cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores).",
        "El sistema de compañeros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores.",
        "El sistema de compañeros con un grupo que contiene un único escritor y otro grupo con tres lectores modela al grupo de Lectores.",
        "En Base, un escritor y tres lectores acceden directamente al servidor.",
        "Esta configuración simple es suficiente para mostrar el impacto de las técnicas de BuddyCache.",
        "Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de caché caliente de OO7.",
        "Obtenemos los números ejecutando 2000 transacciones para filtrar los fallos en frío y luego medimos el tiempo de las siguientes 1000 transacciones.",
        "Aquí nuevamente, los números reportados se derivan de los resultados del experimento de la red de área local.",
        "Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalización en comparación con el sistema Base.",
        "En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparación con la Base.",
        "Este beneficio se debe a la actualización entre pares que evita todas las omisiones debido a actualizaciones.",
        "El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperación entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperación local evitando el retraso de la recuperación desde el servidor.",
        "El último es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperación de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones.",
        "Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperación de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualización de pares en el grupo de Escritores.",
        "Esta diferencia es similar en una red de 80ms.",
        "La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relación con Base, y Buddy Writer y Base en relación con Base) en un experimento de caché activa en función del aumento de la latencia de red, para una carga de servidor fija.",
        "El beneficio de actualización entre pares domina el gasto general en la configuración de Writer incluso en redes de baja latencia (la actualización entre pares incurre en un gasto mínimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia.",
        "La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico.",
        "Como en experimentos de caché fría, aquí los resultados analíticos predicen de cerca la mejora medida.",
        "La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pérdida de invalidación es mínimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de caché fría).",
        "Como en el caso de caché fría, la razón por la que el modelo analítico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7.",
        "CONCLUSIÓN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común.",
        "Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino.",
        "Estas propiedades son difíciles de proporcionar en una red de área extensa debido a la alta latencia de red.",
        "Este artículo describe BuddyCache, una nueva técnica de almacenamiento en caché cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia.",
        "La técnica mejora el rendimiento y proporciona propiedades sólidas de corrección y disponibilidad en presencia de fallos de nodos y clientes lentos.",
        "BuddyCache utiliza la redirección para obtener objetos faltantes directamente de las cachés de los miembros del grupo, y para admitir la actualización entre pares, una nueva técnica de multidifusión a nivel de aplicación ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo.",
        "Sin embargo, la redirección puede interferir con la disponibilidad del objeto.",
        "Solo commit es una nueva técnica de validación que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos.",
        "Proporciona una validación detallada utilizando información de versión de grano grueso económica.",
        "Hemos diseñado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red.",
        "Los resultados analíticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio.",
        "Las principales contribuciones del artículo son: 1. extender las técnicas de almacenamiento en caché cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementación del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluación del rendimiento basada en análisis y mediciones de los costos y beneficios de las nuevas técnicas que capturan el costo de rendimiento dominante, la alta latencia de red.",
        "AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas.",
        "También agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios útiles que mejoraron este artículo. 9.",
        "REFERENCIAS [1] emulab.net, la Instalación de Emulación de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira.",
        "Reconstrucción de fragmentos: Proporcionando coherencia de caché global en un sistema de almacenamiento transaccional.",
        "Actas de la Conferencia Internacional sobre Sistemas de Computación Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari.",
        "Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados.",
        "En Actas de la Conferencia Internacional de ACM SIGMOD sobre Gestión de Datos, mayo de 1995. [4] C. Amza, A.L.",
        "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel.",
        "Huellas de pisadas: Computación en memoria compartida en redes de estaciones de trabajo.",
        "IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin.",
        "Dos protocolos de coherencia de caché híbridos adaptativos.",
        "En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker.",
        "Recuperación rápida de fallos en sistemas de archivos distribuidos.",
        "Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu.",
        "Manteniendo una fuerte consistencia de caché en la World Wide Web.",
        "En la 17ª Conferencia Internacional sobre Sistemas de Computación Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton.",
        "Un informe de estado sobre el esfuerzo de evaluación del rendimiento del sistema de gestión de bases de datos orientado a objetos OO7.",
        "En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels.",
        "Una caché de objetos jerárquica en Internet.",
        "En la Conferencia Técnica Anual de USENIX, en enero de 1995. [10] J.",
        "Chase, S. Gadde y M. Rabinovich.",
        "Estructuras de directorios para cachés de Internet escalables.",
        "Informe Técnico CS-1997-18, Departamento de Ciencias de la Computación, Universidad de Duke, noviembre de 1997. [11] J.",
        "Chase, S. Gadde y M. Rabinovich.",
        "No todos los aciertos son iguales: Caché de proxy cooperativa en una red de área amplia.",
        "En el Tercer Taller Internacional de Caché de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li.",
        "Caché web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2º Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson.",
        "Caché cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos.",
        "Actas de la Conferencia USENIX sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L.",
        "Cox, R. Rajamony y W. Zwaenepoel.",
        "Combinando el soporte en tiempo de compilación y en tiempo de ejecución para una memoria compartida distribuida eficiente.",
        "En Actas de IEEE, Edición Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder.",
        "Resumen de la caché: un protocolo de intercambio de caché web escalable de área amplia.",
        "En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy.",
        "Implementación de Gestión Global de Memoria en un Clúster de Estaciones de Trabajo.",
        "Actas del 15º Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy.",
        "Integrando coherencia y recuperabilidad en sistemas distribuidos.",
        "En Actas del Primer Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al.",
        "PerDiS: Diseño, Implementación y Uso de una Tienda Distribuida Persistente.",
        "En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny.",
        "Coherencia de caché transaccional cliente-servidor: alternativas y rendimiento.",
        "En ACM Transactions on Database Systems, volumen 22, páginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny.",
        "Gestión global de memoria para arquitecturas de sistemas de gestión de bases de datos cliente-servidor.",
        "En Actas del 19º Congreso Internacional.",
        "Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat.",
        "El Búfer de Objeto Modificado: Una Técnica de Gestión de Almacenamiento para Bases de Datos Orientadas a Objetos.",
        "Tesis doctoral, Instituto Tecnológico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif.",
        "Gestión de documentos replicados en un sistema de comunicación grupal.",
        "En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya.",
        "Proporcionando objetos persistentes en sistemas distribuidos.",
        "En Actas de la 13ª Conferencia Europea sobre Programación Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres.",
        "Un sistema de archivos de red de baja capacidad de banda.",
        "En el 18º Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov.",
        "Replicación con marca de vista: un nuevo método de copia primaria para soportar sistemas distribuidos altamente disponibles.",
        "En Proc. del Simposio de la ACM sobre Principios de Computación Distribuida, agosto de 1988. [26] J. OToole y L. Shrira.",
        "Registro oportunista: Lecturas de instalación eficientes en un servidor de objetos confiable.",
        "En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma.",
        "ALMI: Una Infraestructura de Multidifusión a Nivel de Aplicación.",
        "En el 3er Simposio USENIX sobre Tecnologías y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman.",
        "Uso eficiente de caché cooperativa utilizando pistas.",
        "En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson.",
        "WebFS: Un Sistema de Archivos Coherente en Caché Global.",
        "Informe técnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy.",
        "Sobre la Escala y el Rendimiento del Caché de Proxies Web Cooperativos.",
        "En el 17º Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin.",
        "Consistencia jerárquica de caché en una WAN.",
        "En el Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin.",
        "Arrendamientos de volumen para consistencia en sistemas a gran escala.",
        "IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin.",
        "Compartición adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks.",
        "ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10.",
        "APÉNDICE Este apéndice describe el protocolo de conmutación por error de BuddyCache.",
        "Para dar cabida a clientes heterogéneos, incluidos los dispositivos portátiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache.",
        "El diseño de BuddyCache asume que las cachés del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos.",
        "Un protocolo de membresía detecta el fallo de un cliente o un redireccionador intercambiando mensajes periódicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutación por error.",
        "El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuración y reinicia el protocolo.",
        "El protocolo de reconfiguración del grupo es similar al presentado en [25].",
        "Aquí describimos cómo el failover gestiona el estado de BuddyCache.",
        "Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de páginas redireccionadas y el reenvío de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachés.",
        "En caso de un fallo del cliente, el failover elimina las páginas del cliente que se han bloqueado del directorio.",
        "Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmación, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en caché las páginas modificadas.",
        "En caso de un fallo del redireccionador, el protocolo de conmutación por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de páginas utilizando un protocolo similar al descrito en [6].",
        "El redireccionador recién reiniciado solicita a los miembros activos del grupo la lista de páginas que están almacenando en caché y el estado de estas páginas, es decir, si las páginas están completas o incompletas.",
        "Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse.",
        "Una solicitud de recuperación perdida expirará en el cliente y será retransmitida.",
        "Una transacción que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma después del cambio se trata como una transacción regular; una transacción que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo.",
        "Un cliente reiniciará la transacción y la solicitud de confirmación será retransmitida después del cambio de servidor.",
        "Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caído podrían evitar la recolección de basura de las invalidaciones pendientes en los servidores o la caché virtual en los clientes.",
        "Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas.",
        "Los números de versión únicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas.",
        "Dado que el procedimiento de validación de transacciones depende del protocolo de coherencia de caché para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutación por error de BuddyCache no compromete la corrección del procedimiento de validación.",
        "Recuerda que la validación de transacciones de BuddyCache utiliza dos mecanismos complementarios, números de versión de página y confirmaciones de invalidación de los clientes, para verificar que una transacción ha leído datos actualizados.",
        "La propagación de la confirmación de invalidación (y actualización) basada en el redireccionador garantiza la siguiente invariante.",
        "Cuando un servidor recibe una confirmación de una modificación (invalidación o actualización) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en caché el objeto o bien ha instalado el valor más reciente del objeto o lo ha invalidado.",
        "Por lo tanto, si un servidor recibe una solicitud de confirmación de un cliente para una transacción T que lee un objeto o después de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidación no confirmada para o pendiente para este grupo, la versión del objeto leída por la transacción T está actualizada independientemente de fallos en el cliente o en el redireccionador.",
        "Ahora considera la validación utilizando números de versión.",
        "El registro de confirmación de transacción contiene un número de versión para cada objeto leído por la transacción.",
        "El protocolo de número de versión mantiene la invariante V P que garantiza que el valor del objeto o leído por la transacción corresponda al número de versión más alto para o recibido por el cliente.",
        "La invariante se mantiene ya que el cliente nunca aplica una modificación anterior después de haber recibido una modificación posterior.",
        "La retransmisión de invalidaciones y actualizaciones mantiene esta invariante.",
        "El procedimiento de validación verifica que el número de versión en el registro de confirmación coincida con el número de versión en la invalidación pendiente no reconocida.",
        "Es fácil ver que, dado que esta comprobación es una comprobación cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador.",
        "El protocolo de conmutación por error aún no ha sido implementado."
    ],
    "error_count": 2,
    "keys": {
        "object storage system": {
            "translated_key": "sistema de almacenamiento de objetos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed <br>object storage system</br> [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring <br>object storage system</br> performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional <br>object storage system</br> [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "The Base system runs Thor distributed <br>object storage system</br> [23] with clients connecting directly to the servers.",
                "We use OO7 because it is a standard benchmark for measuring <br>object storage system</br> performance.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional <br>object storage system</br> [23] and evaluated the benefits and costs of the system over a range of network latencies."
            ],
            "translated_annotated_samples": [
                "El sistema Base ejecuta el <br>sistema de almacenamiento de objetos</br> distribuidos Thor [23] con clientes conectándose directamente a los servidores.",
                "Utilizamos OO7 porque es un punto de referencia estándar para medir el rendimiento del <br>sistema de almacenamiento de objetos</br>.",
                "Hemos diseñado e implementado el prototipo de BuddyCache en el <br>sistema de almacenamiento de objetos</br> transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la transacción se cancela. Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de búsqueda de pares envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados. Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente. El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente. El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños. Un objetivo importante del diseño de BuddyCache es mantener este beneficio. Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo. Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché. Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. Almacén x 6. Actualización x 3. Comprométete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes. Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente. Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una red de área amplia serían derrochadores. Sin embargo, los protocolos de coherencia basados en invalidación pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interés para otro miembro del grupo. Con un protocolo basado en invalidación, la actualización de un miembro invalidará la copia en caché de otro miembro, lo que provocará que este último realice una recuperación de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualización e invalidación en entornos de redes de área amplia. Evita la penalización de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalización de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusión localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en caché anteriores. La actualización entre pares funciona de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que la transacción se confirma, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación, y también propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmación. 3.3 Confirmación individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminación de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en caché transaccional, ya que un cliente que es lento para reconocer una invalidación o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacción. Por ejemplo, un ingeniero que realiza una revisión repetida al mismo objeto de diseño compartido (y por lo tanto tiene la última versión del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situación representada en la figura 4 donde el Cliente1 realiza una transacción T que lee la última versión de un objeto x en la página P recientemente modificada por el Cliente1. Si la solicitud de confirmación para T llega al servidor antes de que la confirmación colectiva de Cliente2 por la última modificación de x llegue al servidor, el procedimiento de validación de OCC considera que x está obsoleto y aborta T (porque, como se explicó anteriormente, una invalidación no reconocida por un cliente actúa como indicación para el servidor de que el valor del objeto en caché está obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la corrección del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asíncronas son una parte importante de la razón por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasión de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envían y procesan de forma asíncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devolución de llamada jerárquica [32], pero la naturaleza asincrónica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrónicas. El protocolo de validación de confirmación en solitario permite a un cliente con objetos actualizados confirmar una transacción incluso si la confirmación del grupo se retrasa debido a pares lentos o caídos. El protocolo requiere que los clientes incluyan información adicional con los conjuntos de lectura de transacciones en el mensaje de confirmación, para indicar al servidor que los objetos leídos por la transacción están actualizados. Los números de versión de los objetos podrían proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionó anteriormente, mantener números de versión por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaño de directorio) en todo el sistema de objetos cuando los objetos son pequeños [23]. En cambio, solo utiliza números de versión de página de grano grueso para identificar versiones de objetos de grano fino. El número de versión de una página se incrementa en un servidor cuando una transacción que modifica objetos en la página se confirma. Las actualizaciones realizadas por una única transacción y las invalidaciones correspondientes son identificadas de manera única por el número de versión de la página modificada. Los números de versión de la página se propagan a los clientes en respuestas de recuperación, respuestas de confirmación y con invalidaciones, y los clientes incluyen los números de versión de la página en las solicitudes de confirmación enviadas a los servidores. Si una transacción falla en la validación debido a la falta de reconocimiento de grupo, el servidor verifica los números de versión de página de los objetos en el conjunto de lectura de la transacción y permite que la transacción se confirme si el cliente ha leído desde la última versión de la página. Los números de versión de la página permiten confirmaciones independientes, pero las verificaciones de versión de página solo detectan conflictos a nivel de página. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes. Potencialmente, puede ser más rápido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podría ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en caché de pares de múltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en caché web, simplemente aumentar la población de clientes en una caché proxy a menudo aumenta la tasa general de aciertos en la caché [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacción explícita entre clientes y la colaboración, lo que sugiere que es poco probable que ocurra la recuperación entre grupos. Además, las mediciones de sistemas de almacenamiento en caché web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexión de red entre los grupos de pares sea muy rápida. Estamos principalmente interesados en entornos donde compañeros que colaboran estrechamente tienen una conectividad rápida a corta distancia, pero la conexión entre grupos de compañeros puede ser lenta. Como resultado, decidimos que el soporte para la recuperación entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compañeros con recursos heterogéneos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compañeros o, cuando esté disponible, en un nodo separado dentro de la infraestructura del sitio. Además, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una caché de pares en espera para recibir páginas recuperadas por otros pares, emulando una caché central algo similar a una caché de proxy web regional. Desde el punto de vista del protocolo de coherencia de caché BuddyCache, sin embargo, un caché de compañero en espera es equivalente a un caché de compañero regular y, por lo tanto, no consideramos este caso por separado en la discusión de este documento. 4. En esta sección proporcionamos los detalles de la implementación de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en caché de estos objetos. Las aplicaciones se ejecutan en los clientes e interactúan con el sistema realizando llamadas a métodos de objetos en caché. Todas las llamadas a métodos ocurren dentro de transacciones atómicas. Los clientes se comunican con los servidores para obtener páginas o realizar una transacción. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volátil. El disco está organizado como una colección de páginas que son las unidades de acceso al disco. El registro estable guarda la información de confirmación y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de caché y una caché de objetos modificados recuperable llamada MOB. El directorio lleva un registro de qué páginas están almacenadas en caché por qué clientes. El MOB contiene objetos recientemente modificados que aún no han sido escritos de vuelta en sus páginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de caché base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la Sección 3.1. Proporcionamos algunos de los detalles relevantes de la implementación del protocolo OCC. El cliente lleva un registro de los objetos que son leídos y modificados por su transacción; envía esta información, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacción. Los servidores determinan si la confirmación es posible, utilizando un protocolo de confirmación de dos fases si la transacción utilizó objetos en múltiples servidores. Si la transacción se lleva a cabo, las nuevas copias de los objetos modificados se añaden al registro y también se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperación escaneando el registro. Dado que los objetos no están bloqueados antes de ser utilizados, una confirmación de transacción puede hacer que las cachés contengan objetos obsoletos. Los servidores abortarán una transacción que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviándoles mensajes de invalidación; un servidor utiliza su directorio y la información sobre la transacción de confirmación para determinar qué mensajes de invalidación enviar. Los mensajes de invalidación son pequeños porque simplemente identifican objetos obsoletos. Además, se envían en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidación, elimina los objetos obsoletos de su caché y aborta la transacción actual si los utilizó. El cliente sigue conservando páginas que contienen objetos invalidados; estas páginas ahora están incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidación de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener páginas incompletas en la caché del cliente significa que el falso intercambio no conduce a fallos innecesarios en la caché. Los clientes reconocen las invalidaciones para indicar la eliminación de datos obsoletos, como se explica en la Sección 3.1. Los mensajes de invalidación evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo así el desperdicio de trabajo y trasladando la detección de abortos de los servidores a los clientes. Cuando una transacción se aborta, su cliente restaura las copias en caché de los objetos modificados al estado que tenían antes de que la transacción comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacción. 4.3 Redirección El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de páginas disponibles en el grupo de pares y proporciona una redirección rápida y centralizada de recuperación (ver figura 2) entre las cachés de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan páginas u objetos al incluir esa información en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la caché de grupo, el redireccionador realiza un seguimiento del estado de las páginas. Una página en caché está completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una página están marcados como inválidos. Solo se utilizan páginas completas por el proceso de recuperación de pares. El protocolo para mantener el estado de la página cuando las páginas son actualizadas e invalidadas se describe en la Sección 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una página solicitada completa no está disponible en el grupo de pares o si un par necesita confirmar una transacción, el redireccionador actúa como un proxy de servidor: reenvía la solicitud al servidor y luego reenvía la respuesta de vuelta al cliente. Además, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualización o información de invalidación a los clientes que tienen en caché la página modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la caché de grupo de pares combinada está desempeñando el papel de una única caché de cliente en el sistema base. 4.4 Actualización de pares La actualización de pares se implementa de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que una transacción se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacción generan invalidaciones de objetos para cada grupo de caché que almacena páginas que contienen los objetos modificados (incluido el grupo que realiza la confirmación). Las invalidaciones se envían de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en caché los objetos modificados se deshagan de los datos obsoletos. En grupos de caché distintos al grupo de confirmación, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en caché las páginas modificadas, recopilan las confirmaciones de los clientes y, después de completar la recopilación, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacción, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envían a los clientes que almacenan en caché esas páginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmación colectiva se propaga al servidor. Una invalidación hace que una página en caché no esté disponible para la recuperación de pares, cambiando el estado de una página completa p a incompleta. Por el contrario, una actualización de una página completa conserva el estado completo de la página. Como se muestra en los estudios de la reconstrucción de fragmentos 31 [2], esta propagación de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la recuperación entre pares. Por lo tanto, el efecto de la actualización de pares es similar a la reconstrucción de fragmentos ansiosa [2]. También hemos considerado la posibilidad de permitir que un compañero recupere una página incompleta (con objetos inválidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos inválidos. 4.5 Vcache El protocolo de validación de confirmación en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo más lentos (o fallidos). Como se explica en la Sección 3.3, el protocolo de commit único permite que una transacción T pase la validación si la información adicional de coherencia proporcionada por el cliente indica que la transacción T ha leído objetos actualizados. Los clientes utilizan los números de versión de la página para proporcionar esta información adicional de coherencia. Es decir, un cliente incluye el número de versión de la página correspondiente a cada objeto en el conjunto de objetos leídos enviado en la solicitud de confirmación al servidor. Dado que a cada actualización de objeto comprometido le corresponde un número de versión de página único, el número de versión de página asociado con un objeto permite que el procedimiento de validación en el servidor verifique si la transacción del cliente ha leído objetos actualizados. El uso de versiones de página de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeños, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en caché a la versión de página identificadora (ObjectToVersion). El principal problema de implementación se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian números de versión de página con las invalidaciones. En el momento de la validación, si hay una invalidación no reconocida pendiente para un objeto x leído por una transacción T, el procedimiento de validación verifica si el número de versión de x en el conjunto de lectura de Ts coincide con el número de versión de la invalidación pendiente más alta para x, en cuyo caso el valor del objeto está actualizado, de lo contrario, T falla en la validación. Observamos nuevamente que las verificaciones basadas en el número de versión de la página y las verificaciones basadas en el reconocimiento de invalidación son complementarias en la validación de confirmación individual y ambas son necesarias. La verificación del número de versión de la página permite que la validación avance antes de que lleguen las confirmaciones de invalidación, pero por sí sola, una verificación del número de versión de la página detecta conflictos a nivel de página y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cómo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un número de versión de la página para cada página en caché. El número de versión satisface la siguiente invariante V P sobre el estado de los objetos en una página: si una página en caché P tiene un número de versión v, entonces el valor de un objeto o en la página en caché P es inválido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacción que estableció el número de versión de P en v. Los nuevos valores de objetos y los nuevos números de versión de página llegan cuando un cliente obtiene una página o cuando llega una respuesta de confirmación o invalidaciones para esta página. Los nuevos valores del objeto modifican la página y, por lo tanto, el número de versión de la página necesita ser actualizado para mantener la invariante V P. Un número de versión de página que llega cuando un cliente obtiene una página, reemplaza la Versión del Objeto x 8 Servidor de Redirección 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el número de versión de la página para esta página. Tal actualización preserva el invariante V P. De manera similar, un número de versión de página en secuencia que llega al cliente en un mensaje de confirmación o invalidación avanza el número de versión para toda la página en caché, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus números de versión de página correspondientes también pueden llegar al cliente fuera de secuencia, en cuyo caso la actualización del número de versión de la página podría violar V P. Por ejemplo, una respuesta de confirmación para una transacción que actualiza el objeto x en la página P en el servidor S1, y el objeto y en la página Q en el servidor S2, puede entregar un nuevo número de versión para P desde el coordinador de transacciones S1 antes de que llegue una invalidación generada para una transacción anterior que ha modificado el objeto r en la página P desde S1 (como se muestra en la figura 5). El protocolo de actualización de caché garantiza que el valor de cualquier objeto o en una página en caché P refleje la actualización o invalidación con el número de versión observado más alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de números de versión de página, el cliente gestiona una pequeña caché de números de versión vcache que mantiene el mapeo de un objeto a su número de versión de página correspondiente para todas las actualizaciones de números de versión reordenadas hasta que se ensamble una secuencia completa de números de versión de página. Cuando llegan los números de versión faltantes para la página y completan una secuencia, el número de versión de toda la página se avanza. El mapeo de ObjectToVersion, incluyendo los números de versión de vcache y página, se utiliza en el momento de la confirmación de la transacción para proporcionar números de versión para el conjunto de objetos leídos de la siguiente manera. Si el objeto leído tiene una entrada en la vcache, su número de versión es igual al número de versión más alto en la vcache para este objeto. Si el objeto no está presente en la vcache, su número de versión es igual al número de versión de la página en caché que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la caché del cliente, incluyendo los números de versión de las páginas y la vcache. El cliente puede limitar el tamaño de la caché virtual según sea necesario, ya que volver a cargar una página elimina todos los números de versión de página reordenados de la caché virtual. Sin embargo, esperamos que la reorganización de números de versión sea poco común y, por lo tanto, esperamos que la vcache sea muy pequeña. 5. Un grupo de clientes contiene múltiples nodos de cliente y un objeto de página de versión redi32 VCache Cliente Caché Cliente Página Caché Figura 6: Mapa de Objeto a Versión con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutación por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. Además, el fallo del redireccionador debería permitir que los clientes no afectados mantengan sus cachés intactas. Hemos diseñado un protocolo de conmutación por error para BuddyCache pero aún no lo hemos implementado. El apéndice describe el protocolo. 6. La redirección de BuddyCache en la evaluación de rendimiento respalda los beneficios de evitar la comunicación con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes. ¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la recuperación entre pares y la actualización entre pares se deben a la evitación de interacciones con el servidor. Esta sección presenta un modelo de rendimiento analítico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la caché del cliente. Estos pueden ser fallos fríos, fallos de invalidación y fallos de capacidad. Nuestro análisis se centra en los fallos por frío y los fallos por invalidación, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frío. Además, las tendencias tecnológicas indican que la capacidad de memoria y almacenamiento seguirá creciendo y, por lo tanto, es probable que una configuración típica de BuddyCache no esté limitada por la caché. Los fallos de caché del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuración de caché. Nuestro análisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validación. Para estudiar el beneficio de evitar fallos en frío, consideramos el rendimiento de la caché en frío en una carga de trabajo de solo lectura (sin fallos de invalidación). Esperamos que la recuperación entre pares mejore el costo de latencia para las solicitudes de caché fría del cliente al recuperar objetos de la caché cercana. Evaluamos cómo el costo de redirección afecta este beneficio al comparar y analizar el rendimiento de una aplicación que se ejecuta en un sistema de almacenamiento con BuddyCache y sin él (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidación, consideramos el rendimiento de la caché caliente en una carga de trabajo con modificaciones (sin fallos en frío). En las cachés calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualización entre pares permite que un cliente acceda a un objeto modificado por un compañero colaborador cercano sin el retraso impuesto por los protocolos de invalidación únicamente. En grupos donde los compañeros comparten un interés de solo lectura en los objetos modificados, la recuperación entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compañero colaborador lo tenga, lo que evita el retraso de la recuperación del servidor sin el alto costo impuesto por los protocolos de solo actualización. Las tendencias tecnológicas indican que ambos beneficios seguirán siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualización únicamente. Sin embargo, la tendencia hacia cachés cada vez más grandes, que se actualizan cuando los objetos en caché son modificados, hace que los protocolos basados en invalidación sean más atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicación que se ejecuta sin BuddyCache y una aplicación que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compañero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compañero fuera del grupo. La actualización entre pares también puede evitar fallos de invalidación debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma página de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseño del objeto, y también porque este beneficio se puede derivar dado el índice de aciertos en caché y la contención de la carga de trabajo. 6.1.1 El Modelo El modelo considera cómo el tiempo para completar una ejecución con y sin BuddyCache se ve afectado por los fallos de invalidación y los fallos en frío. Considerando k clientes ejecutándose concurrentemente accediendo de manera uniforme a un conjunto compartido de N páginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacción y realizar cálculos en una transacción, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin él (Base). Para simplificar, nuestro modelo asume que los tiempos de búsqueda y confirmación son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del número total de clientes en el sistema. El número de fallos evitados por la recuperación entre pares depende de k, el número de clientes en la BuddyCache, y del interés conjunto de los clientes en los datos compartidos. En una ejecución específica de BuddyCache, se modela mediante la variable r, definida como el número de solicitudes que llegan al redireccionador para una versión dada de la página P (es decir, hasta que un objeto en la página se invalida). Considera una ejecución con fallos en frío. Un cliente comienza con una caché fría y ejecuta una carga de trabajo de solo lectura hasta que accede a las N páginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la caché del cliente es lo suficientemente grande como para contener N páginas. En BC, los fríos fallos para la página P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consideremos a continuación una ejecución con fallos de invalidación. Un cliente comienza con una caché caliente que contiene el conjunto de trabajo de N páginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualización entre pares elimina todos los fallos de invalidación. En un grupo que contiene solo lectores (BCR), durante una ejecución en estado estable con actualizaciones uniformes, una transacción del cliente tiene fallos de invalidación faltantes. Considera la secuencia de r fallos de cliente en la página P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la página P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frío, r ≤ k porque la segunda invalidación deshabilita la redirección para P hasta que el próximo fallo en P provoque una recuperación del servidor. Suponiendo un acceso uniforme, un fallo de invalidación del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperación del servidor), y una probabilidad de (1 − 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacción única en los sistemas Base, BCR y BCW. En los experimentos descritos a continuación, medimos los parámetros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalización derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalización y beneficios medidos directamente en los experimentos. 6.2 Configuración Experimental Antes de presentar nuestros resultados, describimos nuestra configuración experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el <br>sistema de almacenamiento de objetos</br> distribuidos Thor [23] con clientes conectándose directamente a los servidores. El sistema Buddy ejecuta nuestra implementación del prototipo de BuddyCache en Thor, admitiendo la recuperación de pares, la actualización de pares y la confirmación en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark está diseñado para capturar las características de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicación específica. Utilizamos OO7 porque es un punto de referencia estándar para medir el rendimiento del <br>sistema de almacenamiento de objetos</br>. La base de datos OO7 contiene un árbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un gráfico de partes atómicas vinculadas por objetos de conexión; cada parte atómica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atómicas por parte compuesta. La base de datos multiusuario asigna a cada cliente un módulo privado que consiste en un árbol de objetos de ensamblaje, y agrega un módulo compartido adicional que escala proporcionalmente al número de clientes. Esperamos que una configuración típica de BuddyCache no esté limitada por la caché y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la caché. Dado que el objetivo de nuestro estudio es evaluar qué tan efectivamente nuestras técnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras técnicas tienen en los fallos de caché frío y de consistencia de caché, y aislar tanto como sea posible el efecto de los fallos de capacidad de caché. Para mantener la duración de nuestros experimentos razonable, utilizamos cachés pequeños. El benchmark OO7 genera módulos de base de datos de tamaño predefinido. En nuestra implementación de OO7, el tamaño del módulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la caché, utilizamos un único módulo privado y elegimos un tamaño de caché de 40MB para cada cliente. La base de datos OO7 se genera con módulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos están agrupados en páginas de 8K, que también son la unidad de transferencia en las solicitudes de recuperación. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro análisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idéntico a T1 excepto que modifica todas las partes atómicas en un solo compuesto. Una transacción única incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo módulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacción, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de búsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una caché de 50MB (de los cuales 6MB se utilizaron para el búfer de objetos modificados), el cliente tenía una caché de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos básicos Esta sección analiza el costo básico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 Redirección Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtención del servidor), el costo adicional de la redirección incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperación o confirmación del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmación y recuperación del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de área rápida. Todos los números fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirección al cruzar el redireccionador no es muy alto, incluso en una red de área local. El costo de la confirmación aumenta con el número de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperación no aumenta tanto porque la caché del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la caché del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperación entre pares, medimos la latencia de la recuperación entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperación entre pares, el costo de la redirección incluye, además del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este último incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la página solicitada. Medimos directamente el tiempo para copiar y desenrollar la página solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperación de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador más un viaje de ida y vuelta a través de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud más un viaje de ida y vuelta a través de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando está bloqueado esperando una respuesta de búsqueda o confirmación. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podría ser mitigado por una implementación multi-hilo en un sistema con programación preemptiva. 6.3.2 Versión de Caché El commit en solitario permite que un cliente rápido que modifica un objeto haga un commit de forma independiente a un compañero lento. El mecanismo de confirmación única introduce un procesamiento adicional en el servidor durante la validación de la transacción, y un procesamiento adicional en el cliente durante la confirmación de la transacción y en el momento del procesamiento de actualización o invalidación. Los gastos generales del lado del servidor son mínimos y consisten en una actualización del número de versión de la página en el momento de la confirmación, y una comparación del número de versión en el momento de la validación de la transacción. La caché de versión tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacción accede a objetos en múltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor único y, por lo tanto, el tiempo de confirmación adicional de la gestión de la caché de versiones en el cliente no contribuye a los resultados presentados en la sección a continuación. Para medir estos costos adicionales del lado del cliente en un sistema de múltiples servidores, instrumentamos la implementación de la caché de versiones para ejecutarse con una traza de carga de trabajo que incluía invalidaciones reordenadas y cronometramos las operaciones básicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operación de búsqueda de caché de versión para cada objeto leído por la transacción en el momento de preparación de la solicitud de compromiso, y una operación de inserción de caché de versión para cada objeto actualizado por una transacción en el momento de procesamiento de la respuesta de compromiso, pero solo si la página actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmación se mantengan al mínimo, ya que el cliente está esperando de forma síncrona la finalización de la confirmación. Las mediciones muestran que en el peor de los casos, cuando llega un gran número de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en páginas reordenadas, el costo de actualizar la caché de versión es de 0.6 ms. El costo de tiempo de invalidación es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementación de la caché de versiones para reducir aún más estos costos. 6.4 Rendimiento general Esta sección examina las mejoras de rendimiento observadas por una aplicación que ejecuta el benchmark OO7 con un BuddyCache en una red de área amplia. 6.4.1 Fallos en frío Para evaluar las mejoras de rendimiento al evitar fallos en frío, comparamos el rendimiento de la caché en frío del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecución de los sistemas en el entorno de la red de área local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de área amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en caché fría. Los números fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frío solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frío solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparación con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cálculos para el cliente, solicitudes de recuperación directa, recuperaciones de pares y solicitudes de confirmación. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperación entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperación del servidor para cada cliente individual disminuye porque, con más clientes accediendo a un módulo compartido de tamaño fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperación de pares en comparación con la recuperación directa, pero este beneficio se ve contrarrestado por los tiempos de confirmación aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relación con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de caché 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT función de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias típicas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Sorprendentemente, los resultados analíticos predicen la mejora medida muy de cerca, aunque son ligeramente más altos que los valores empíricos. La razón principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidación evitados, comparamos el rendimiento de caché caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interés de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un único cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compañeros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compañeros con un grupo que contiene un único escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuración simple es suficiente para mostrar el impacto de las técnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de caché caliente de OO7. Obtenemos los números ejecutando 2000 transacciones para filtrar los fallos en frío y luego medimos el tiempo de las siguientes 1000 transacciones. Aquí nuevamente, los números reportados se derivan de los resultados del experimento de la red de área local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalización en comparación con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparación con la Base. Este beneficio se debe a la actualización entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperación entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperación local evitando el retraso de la recuperación desde el servidor. El último es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperación de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperación de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualización de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relación con Base, y Buddy Writer y Base en relación con Base) en un experimento de caché activa en función del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualización entre pares domina el gasto general en la configuración de Writer incluso en redes de baja latencia (la actualización entre pares incurre en un gasto mínimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Como en experimentos de caché fría, aquí los resultados analíticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pérdida de invalidación es mínimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de caché fría). Como en el caso de caché fría, la razón por la que el modelo analítico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÓN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en una red de área extensa debido a la alta latencia de red. Este artículo describe BuddyCache, una nueva técnica de almacenamiento en caché cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La técnica mejora el rendimiento y proporciona propiedades sólidas de corrección y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirección para obtener objetos faltantes directamente de las cachés de los miembros del grupo, y para admitir la actualización entre pares, una nueva técnica de multidifusión a nivel de aplicación ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirección puede interferir con la disponibilidad del objeto. Solo commit es una nueva técnica de validación que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validación detallada utilizando información de versión de grano grueso económica. Hemos diseñado e implementado el prototipo de BuddyCache en el <br>sistema de almacenamiento de objetos</br> transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analíticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Las principales contribuciones del artículo son: 1. extender las técnicas de almacenamiento en caché cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementación del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluación del rendimiento basada en análisis y mediciones de los costos y beneficios de las nuevas técnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. También agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios útiles que mejoraron este artículo. 9. REFERENCIAS [1] emulab.net, la Instalación de Emulación de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. Reconstrucción de fragmentos: Proporcionando coherencia de caché global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de Computación Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre Gestión de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: Computación en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de caché híbridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. Recuperación rápida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de caché en la World Wide Web. En la 17ª Conferencia Internacional sobre Sistemas de Computación Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluación del rendimiento del sistema de gestión de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una caché de objetos jerárquica en Internet. En la Conferencia Técnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachés de Internet escalables. Informe Técnico CS-1997-18, Departamento de Ciencias de la Computación, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: Caché de proxy cooperativa en una red de área amplia. En el Tercer Taller Internacional de Caché de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. Caché web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2º Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. Caché cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilación y en tiempo de ejecución para una memoria compartida distribuida eficiente. En Actas de IEEE, Edición Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la caché: un protocolo de intercambio de caché web escalable de área amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. Implementación de Gestión Global de Memoria en un Clúster de Estaciones de Trabajo. Actas del 15º Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: Diseño, Implementación y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de caché transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, páginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. Gestión global de memoria para arquitecturas de sistemas de gestión de bases de datos cliente-servidor. En Actas del 19º Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El Búfer de Objeto Modificado: Una Técnica de Gestión de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto Tecnológico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. Gestión de documentos replicados en un sistema de comunicación grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13ª Conferencia Europea sobre Programación Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18º Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. Replicación con marca de vista: un nuevo método de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de Computación Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalación eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de Multidifusión a Nivel de Aplicación. En el 3er Simposio USENIX sobre Tecnologías y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de caché cooperativa utilizando pistas. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en Caché Global. Informe técnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del Caché de Proxies Web Cooperativos. En el 17º Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerárquica de caché en una WAN. En el Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. Compartición adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÉNDICE Este apéndice describe el protocolo de conmutación por error de BuddyCache. Para dar cabida a clientes heterogéneos, incluidos los dispositivos portátiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseño de BuddyCache asume que las cachés del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresía detecta el fallo de un cliente o un redireccionador intercambiando mensajes periódicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutación por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuración y reinicia el protocolo. El protocolo de reconfiguración del grupo es similar al presentado en [25]. Aquí describimos cómo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de páginas redireccionadas y el reenvío de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachés. En caso de un fallo del cliente, el failover elimina las páginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmación, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en caché las páginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutación por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de páginas utilizando un protocolo similar al descrito en [6]. El redireccionador recién reiniciado solicita a los miembros activos del grupo la lista de páginas que están almacenando en caché y el estado de estas páginas, es decir, si las páginas están completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperación perdida expirará en el cliente y será retransmitida. Una transacción que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma después del cambio se trata como una transacción regular; una transacción que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciará la transacción y la solicitud de confirmación será retransmitida después del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caído podrían evitar la recolección de basura de las invalidaciones pendientes en los servidores o la caché virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los números de versión únicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validación de transacciones depende del protocolo de coherencia de caché para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutación por error de BuddyCache no compromete la corrección del procedimiento de validación. Recuerda que la validación de transacciones de BuddyCache utiliza dos mecanismos complementarios, números de versión de página y confirmaciones de invalidación de los clientes, para verificar que una transacción ha leído datos actualizados. La propagación de la confirmación de invalidación (y actualización) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmación de una modificación (invalidación o actualización) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en caché el objeto o bien ha instalado el valor más reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmación de un cliente para una transacción T que lee un objeto o después de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidación no confirmada para o pendiente para este grupo, la versión del objeto leída por la transacción T está actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validación utilizando números de versión. El registro de confirmación de transacción contiene un número de versión para cada objeto leído por la transacción. El protocolo de número de versión mantiene la invariante V P que garantiza que el valor del objeto o leído por la transacción corresponda al número de versión más alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificación anterior después de haber recibido una modificación posterior. La retransmisión de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validación verifica que el número de versión en el registro de confirmación coincida con el número de versión en la invalidación pendiente no reconocida. Es fácil ver que, dado que esta comprobación es una comprobación cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutación por error aún no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "collaborative strong-consistency application": {
            "translated_key": "alta consistencia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for <br>collaborative strong-consistency application</br>s in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for <br>collaborative strong-consistency application</br>s in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for <br>collaborative strong-consistency application</br>s in high-latency network environments.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for <br>collaborative strong-consistency application</br>s in high-latency network environments."
            ],
            "translated_annotated_samples": [
                "BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de <br>alta consistencia</br> en entornos de red de alta latencia.",
                "Este artículo describe BuddyCache, una nueva técnica de almacenamiento en caché cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para <br>aplicaciones colaborativas de alta consistencia</br> en entornos de red de alta latencia."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de <br>alta consistencia</br> en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la transacción se cancela. Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de búsqueda de pares envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados. Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente. El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente. El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños. Un objetivo importante del diseño de BuddyCache es mantener este beneficio. Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo. Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché. Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. Almacén x 6. Actualización x 3. Comprométete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes. Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente. Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una red de área amplia serían derrochadores. Sin embargo, los protocolos de coherencia basados en invalidación pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interés para otro miembro del grupo. Con un protocolo basado en invalidación, la actualización de un miembro invalidará la copia en caché de otro miembro, lo que provocará que este último realice una recuperación de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualización e invalidación en entornos de redes de área amplia. Evita la penalización de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalización de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusión localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en caché anteriores. La actualización entre pares funciona de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que la transacción se confirma, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación, y también propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmación. 3.3 Confirmación individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminación de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en caché transaccional, ya que un cliente que es lento para reconocer una invalidación o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacción. Por ejemplo, un ingeniero que realiza una revisión repetida al mismo objeto de diseño compartido (y por lo tanto tiene la última versión del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situación representada en la figura 4 donde el Cliente1 realiza una transacción T que lee la última versión de un objeto x en la página P recientemente modificada por el Cliente1. Si la solicitud de confirmación para T llega al servidor antes de que la confirmación colectiva de Cliente2 por la última modificación de x llegue al servidor, el procedimiento de validación de OCC considera que x está obsoleto y aborta T (porque, como se explicó anteriormente, una invalidación no reconocida por un cliente actúa como indicación para el servidor de que el valor del objeto en caché está obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la corrección del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asíncronas son una parte importante de la razón por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasión de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envían y procesan de forma asíncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devolución de llamada jerárquica [32], pero la naturaleza asincrónica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrónicas. El protocolo de validación de confirmación en solitario permite a un cliente con objetos actualizados confirmar una transacción incluso si la confirmación del grupo se retrasa debido a pares lentos o caídos. El protocolo requiere que los clientes incluyan información adicional con los conjuntos de lectura de transacciones en el mensaje de confirmación, para indicar al servidor que los objetos leídos por la transacción están actualizados. Los números de versión de los objetos podrían proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionó anteriormente, mantener números de versión por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaño de directorio) en todo el sistema de objetos cuando los objetos son pequeños [23]. En cambio, solo utiliza números de versión de página de grano grueso para identificar versiones de objetos de grano fino. El número de versión de una página se incrementa en un servidor cuando una transacción que modifica objetos en la página se confirma. Las actualizaciones realizadas por una única transacción y las invalidaciones correspondientes son identificadas de manera única por el número de versión de la página modificada. Los números de versión de la página se propagan a los clientes en respuestas de recuperación, respuestas de confirmación y con invalidaciones, y los clientes incluyen los números de versión de la página en las solicitudes de confirmación enviadas a los servidores. Si una transacción falla en la validación debido a la falta de reconocimiento de grupo, el servidor verifica los números de versión de página de los objetos en el conjunto de lectura de la transacción y permite que la transacción se confirme si el cliente ha leído desde la última versión de la página. Los números de versión de la página permiten confirmaciones independientes, pero las verificaciones de versión de página solo detectan conflictos a nivel de página. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes. Potencialmente, puede ser más rápido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podría ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en caché de pares de múltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en caché web, simplemente aumentar la población de clientes en una caché proxy a menudo aumenta la tasa general de aciertos en la caché [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacción explícita entre clientes y la colaboración, lo que sugiere que es poco probable que ocurra la recuperación entre grupos. Además, las mediciones de sistemas de almacenamiento en caché web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexión de red entre los grupos de pares sea muy rápida. Estamos principalmente interesados en entornos donde compañeros que colaboran estrechamente tienen una conectividad rápida a corta distancia, pero la conexión entre grupos de compañeros puede ser lenta. Como resultado, decidimos que el soporte para la recuperación entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compañeros con recursos heterogéneos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compañeros o, cuando esté disponible, en un nodo separado dentro de la infraestructura del sitio. Además, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una caché de pares en espera para recibir páginas recuperadas por otros pares, emulando una caché central algo similar a una caché de proxy web regional. Desde el punto de vista del protocolo de coherencia de caché BuddyCache, sin embargo, un caché de compañero en espera es equivalente a un caché de compañero regular y, por lo tanto, no consideramos este caso por separado en la discusión de este documento. 4. En esta sección proporcionamos los detalles de la implementación de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en caché de estos objetos. Las aplicaciones se ejecutan en los clientes e interactúan con el sistema realizando llamadas a métodos de objetos en caché. Todas las llamadas a métodos ocurren dentro de transacciones atómicas. Los clientes se comunican con los servidores para obtener páginas o realizar una transacción. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volátil. El disco está organizado como una colección de páginas que son las unidades de acceso al disco. El registro estable guarda la información de confirmación y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de caché y una caché de objetos modificados recuperable llamada MOB. El directorio lleva un registro de qué páginas están almacenadas en caché por qué clientes. El MOB contiene objetos recientemente modificados que aún no han sido escritos de vuelta en sus páginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de caché base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la Sección 3.1. Proporcionamos algunos de los detalles relevantes de la implementación del protocolo OCC. El cliente lleva un registro de los objetos que son leídos y modificados por su transacción; envía esta información, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacción. Los servidores determinan si la confirmación es posible, utilizando un protocolo de confirmación de dos fases si la transacción utilizó objetos en múltiples servidores. Si la transacción se lleva a cabo, las nuevas copias de los objetos modificados se añaden al registro y también se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperación escaneando el registro. Dado que los objetos no están bloqueados antes de ser utilizados, una confirmación de transacción puede hacer que las cachés contengan objetos obsoletos. Los servidores abortarán una transacción que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviándoles mensajes de invalidación; un servidor utiliza su directorio y la información sobre la transacción de confirmación para determinar qué mensajes de invalidación enviar. Los mensajes de invalidación son pequeños porque simplemente identifican objetos obsoletos. Además, se envían en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidación, elimina los objetos obsoletos de su caché y aborta la transacción actual si los utilizó. El cliente sigue conservando páginas que contienen objetos invalidados; estas páginas ahora están incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidación de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener páginas incompletas en la caché del cliente significa que el falso intercambio no conduce a fallos innecesarios en la caché. Los clientes reconocen las invalidaciones para indicar la eliminación de datos obsoletos, como se explica en la Sección 3.1. Los mensajes de invalidación evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo así el desperdicio de trabajo y trasladando la detección de abortos de los servidores a los clientes. Cuando una transacción se aborta, su cliente restaura las copias en caché de los objetos modificados al estado que tenían antes de que la transacción comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacción. 4.3 Redirección El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de páginas disponibles en el grupo de pares y proporciona una redirección rápida y centralizada de recuperación (ver figura 2) entre las cachés de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan páginas u objetos al incluir esa información en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la caché de grupo, el redireccionador realiza un seguimiento del estado de las páginas. Una página en caché está completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una página están marcados como inválidos. Solo se utilizan páginas completas por el proceso de recuperación de pares. El protocolo para mantener el estado de la página cuando las páginas son actualizadas e invalidadas se describe en la Sección 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una página solicitada completa no está disponible en el grupo de pares o si un par necesita confirmar una transacción, el redireccionador actúa como un proxy de servidor: reenvía la solicitud al servidor y luego reenvía la respuesta de vuelta al cliente. Además, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualización o información de invalidación a los clientes que tienen en caché la página modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la caché de grupo de pares combinada está desempeñando el papel de una única caché de cliente en el sistema base. 4.4 Actualización de pares La actualización de pares se implementa de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que una transacción se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacción generan invalidaciones de objetos para cada grupo de caché que almacena páginas que contienen los objetos modificados (incluido el grupo que realiza la confirmación). Las invalidaciones se envían de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en caché los objetos modificados se deshagan de los datos obsoletos. En grupos de caché distintos al grupo de confirmación, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en caché las páginas modificadas, recopilan las confirmaciones de los clientes y, después de completar la recopilación, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacción, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envían a los clientes que almacenan en caché esas páginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmación colectiva se propaga al servidor. Una invalidación hace que una página en caché no esté disponible para la recuperación de pares, cambiando el estado de una página completa p a incompleta. Por el contrario, una actualización de una página completa conserva el estado completo de la página. Como se muestra en los estudios de la reconstrucción de fragmentos 31 [2], esta propagación de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la recuperación entre pares. Por lo tanto, el efecto de la actualización de pares es similar a la reconstrucción de fragmentos ansiosa [2]. También hemos considerado la posibilidad de permitir que un compañero recupere una página incompleta (con objetos inválidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos inválidos. 4.5 Vcache El protocolo de validación de confirmación en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo más lentos (o fallidos). Como se explica en la Sección 3.3, el protocolo de commit único permite que una transacción T pase la validación si la información adicional de coherencia proporcionada por el cliente indica que la transacción T ha leído objetos actualizados. Los clientes utilizan los números de versión de la página para proporcionar esta información adicional de coherencia. Es decir, un cliente incluye el número de versión de la página correspondiente a cada objeto en el conjunto de objetos leídos enviado en la solicitud de confirmación al servidor. Dado que a cada actualización de objeto comprometido le corresponde un número de versión de página único, el número de versión de página asociado con un objeto permite que el procedimiento de validación en el servidor verifique si la transacción del cliente ha leído objetos actualizados. El uso de versiones de página de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeños, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en caché a la versión de página identificadora (ObjectToVersion). El principal problema de implementación se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian números de versión de página con las invalidaciones. En el momento de la validación, si hay una invalidación no reconocida pendiente para un objeto x leído por una transacción T, el procedimiento de validación verifica si el número de versión de x en el conjunto de lectura de Ts coincide con el número de versión de la invalidación pendiente más alta para x, en cuyo caso el valor del objeto está actualizado, de lo contrario, T falla en la validación. Observamos nuevamente que las verificaciones basadas en el número de versión de la página y las verificaciones basadas en el reconocimiento de invalidación son complementarias en la validación de confirmación individual y ambas son necesarias. La verificación del número de versión de la página permite que la validación avance antes de que lleguen las confirmaciones de invalidación, pero por sí sola, una verificación del número de versión de la página detecta conflictos a nivel de página y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cómo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un número de versión de la página para cada página en caché. El número de versión satisface la siguiente invariante V P sobre el estado de los objetos en una página: si una página en caché P tiene un número de versión v, entonces el valor de un objeto o en la página en caché P es inválido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacción que estableció el número de versión de P en v. Los nuevos valores de objetos y los nuevos números de versión de página llegan cuando un cliente obtiene una página o cuando llega una respuesta de confirmación o invalidaciones para esta página. Los nuevos valores del objeto modifican la página y, por lo tanto, el número de versión de la página necesita ser actualizado para mantener la invariante V P. Un número de versión de página que llega cuando un cliente obtiene una página, reemplaza la Versión del Objeto x 8 Servidor de Redirección 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el número de versión de la página para esta página. Tal actualización preserva el invariante V P. De manera similar, un número de versión de página en secuencia que llega al cliente en un mensaje de confirmación o invalidación avanza el número de versión para toda la página en caché, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus números de versión de página correspondientes también pueden llegar al cliente fuera de secuencia, en cuyo caso la actualización del número de versión de la página podría violar V P. Por ejemplo, una respuesta de confirmación para una transacción que actualiza el objeto x en la página P en el servidor S1, y el objeto y en la página Q en el servidor S2, puede entregar un nuevo número de versión para P desde el coordinador de transacciones S1 antes de que llegue una invalidación generada para una transacción anterior que ha modificado el objeto r en la página P desde S1 (como se muestra en la figura 5). El protocolo de actualización de caché garantiza que el valor de cualquier objeto o en una página en caché P refleje la actualización o invalidación con el número de versión observado más alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de números de versión de página, el cliente gestiona una pequeña caché de números de versión vcache que mantiene el mapeo de un objeto a su número de versión de página correspondiente para todas las actualizaciones de números de versión reordenadas hasta que se ensamble una secuencia completa de números de versión de página. Cuando llegan los números de versión faltantes para la página y completan una secuencia, el número de versión de toda la página se avanza. El mapeo de ObjectToVersion, incluyendo los números de versión de vcache y página, se utiliza en el momento de la confirmación de la transacción para proporcionar números de versión para el conjunto de objetos leídos de la siguiente manera. Si el objeto leído tiene una entrada en la vcache, su número de versión es igual al número de versión más alto en la vcache para este objeto. Si el objeto no está presente en la vcache, su número de versión es igual al número de versión de la página en caché que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la caché del cliente, incluyendo los números de versión de las páginas y la vcache. El cliente puede limitar el tamaño de la caché virtual según sea necesario, ya que volver a cargar una página elimina todos los números de versión de página reordenados de la caché virtual. Sin embargo, esperamos que la reorganización de números de versión sea poco común y, por lo tanto, esperamos que la vcache sea muy pequeña. 5. Un grupo de clientes contiene múltiples nodos de cliente y un objeto de página de versión redi32 VCache Cliente Caché Cliente Página Caché Figura 6: Mapa de Objeto a Versión con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutación por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. Además, el fallo del redireccionador debería permitir que los clientes no afectados mantengan sus cachés intactas. Hemos diseñado un protocolo de conmutación por error para BuddyCache pero aún no lo hemos implementado. El apéndice describe el protocolo. 6. La redirección de BuddyCache en la evaluación de rendimiento respalda los beneficios de evitar la comunicación con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes. ¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la recuperación entre pares y la actualización entre pares se deben a la evitación de interacciones con el servidor. Esta sección presenta un modelo de rendimiento analítico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la caché del cliente. Estos pueden ser fallos fríos, fallos de invalidación y fallos de capacidad. Nuestro análisis se centra en los fallos por frío y los fallos por invalidación, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frío. Además, las tendencias tecnológicas indican que la capacidad de memoria y almacenamiento seguirá creciendo y, por lo tanto, es probable que una configuración típica de BuddyCache no esté limitada por la caché. Los fallos de caché del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuración de caché. Nuestro análisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validación. Para estudiar el beneficio de evitar fallos en frío, consideramos el rendimiento de la caché en frío en una carga de trabajo de solo lectura (sin fallos de invalidación). Esperamos que la recuperación entre pares mejore el costo de latencia para las solicitudes de caché fría del cliente al recuperar objetos de la caché cercana. Evaluamos cómo el costo de redirección afecta este beneficio al comparar y analizar el rendimiento de una aplicación que se ejecuta en un sistema de almacenamiento con BuddyCache y sin él (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidación, consideramos el rendimiento de la caché caliente en una carga de trabajo con modificaciones (sin fallos en frío). En las cachés calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualización entre pares permite que un cliente acceda a un objeto modificado por un compañero colaborador cercano sin el retraso impuesto por los protocolos de invalidación únicamente. En grupos donde los compañeros comparten un interés de solo lectura en los objetos modificados, la recuperación entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compañero colaborador lo tenga, lo que evita el retraso de la recuperación del servidor sin el alto costo impuesto por los protocolos de solo actualización. Las tendencias tecnológicas indican que ambos beneficios seguirán siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualización únicamente. Sin embargo, la tendencia hacia cachés cada vez más grandes, que se actualizan cuando los objetos en caché son modificados, hace que los protocolos basados en invalidación sean más atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicación que se ejecuta sin BuddyCache y una aplicación que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compañero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compañero fuera del grupo. La actualización entre pares también puede evitar fallos de invalidación debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma página de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseño del objeto, y también porque este beneficio se puede derivar dado el índice de aciertos en caché y la contención de la carga de trabajo. 6.1.1 El Modelo El modelo considera cómo el tiempo para completar una ejecución con y sin BuddyCache se ve afectado por los fallos de invalidación y los fallos en frío. Considerando k clientes ejecutándose concurrentemente accediendo de manera uniforme a un conjunto compartido de N páginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacción y realizar cálculos en una transacción, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin él (Base). Para simplificar, nuestro modelo asume que los tiempos de búsqueda y confirmación son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del número total de clientes en el sistema. El número de fallos evitados por la recuperación entre pares depende de k, el número de clientes en la BuddyCache, y del interés conjunto de los clientes en los datos compartidos. En una ejecución específica de BuddyCache, se modela mediante la variable r, definida como el número de solicitudes que llegan al redireccionador para una versión dada de la página P (es decir, hasta que un objeto en la página se invalida). Considera una ejecución con fallos en frío. Un cliente comienza con una caché fría y ejecuta una carga de trabajo de solo lectura hasta que accede a las N páginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la caché del cliente es lo suficientemente grande como para contener N páginas. En BC, los fríos fallos para la página P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consideremos a continuación una ejecución con fallos de invalidación. Un cliente comienza con una caché caliente que contiene el conjunto de trabajo de N páginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualización entre pares elimina todos los fallos de invalidación. En un grupo que contiene solo lectores (BCR), durante una ejecución en estado estable con actualizaciones uniformes, una transacción del cliente tiene fallos de invalidación faltantes. Considera la secuencia de r fallos de cliente en la página P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la página P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frío, r ≤ k porque la segunda invalidación deshabilita la redirección para P hasta que el próximo fallo en P provoque una recuperación del servidor. Suponiendo un acceso uniforme, un fallo de invalidación del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperación del servidor), y una probabilidad de (1 − 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacción única en los sistemas Base, BCR y BCW. En los experimentos descritos a continuación, medimos los parámetros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalización derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalización y beneficios medidos directamente en los experimentos. 6.2 Configuración Experimental Antes de presentar nuestros resultados, describimos nuestra configuración experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectándose directamente a los servidores. El sistema Buddy ejecuta nuestra implementación del prototipo de BuddyCache en Thor, admitiendo la recuperación de pares, la actualización de pares y la confirmación en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark está diseñado para capturar las características de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicación específica. Utilizamos OO7 porque es un punto de referencia estándar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un árbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un gráfico de partes atómicas vinculadas por objetos de conexión; cada parte atómica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atómicas por parte compuesta. La base de datos multiusuario asigna a cada cliente un módulo privado que consiste en un árbol de objetos de ensamblaje, y agrega un módulo compartido adicional que escala proporcionalmente al número de clientes. Esperamos que una configuración típica de BuddyCache no esté limitada por la caché y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la caché. Dado que el objetivo de nuestro estudio es evaluar qué tan efectivamente nuestras técnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras técnicas tienen en los fallos de caché frío y de consistencia de caché, y aislar tanto como sea posible el efecto de los fallos de capacidad de caché. Para mantener la duración de nuestros experimentos razonable, utilizamos cachés pequeños. El benchmark OO7 genera módulos de base de datos de tamaño predefinido. En nuestra implementación de OO7, el tamaño del módulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la caché, utilizamos un único módulo privado y elegimos un tamaño de caché de 40MB para cada cliente. La base de datos OO7 se genera con módulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos están agrupados en páginas de 8K, que también son la unidad de transferencia en las solicitudes de recuperación. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro análisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idéntico a T1 excepto que modifica todas las partes atómicas en un solo compuesto. Una transacción única incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo módulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacción, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de búsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una caché de 50MB (de los cuales 6MB se utilizaron para el búfer de objetos modificados), el cliente tenía una caché de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos básicos Esta sección analiza el costo básico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 Redirección Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtención del servidor), el costo adicional de la redirección incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperación o confirmación del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmación y recuperación del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de área rápida. Todos los números fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirección al cruzar el redireccionador no es muy alto, incluso en una red de área local. El costo de la confirmación aumenta con el número de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperación no aumenta tanto porque la caché del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la caché del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperación entre pares, medimos la latencia de la recuperación entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperación entre pares, el costo de la redirección incluye, además del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este último incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la página solicitada. Medimos directamente el tiempo para copiar y desenrollar la página solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperación de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador más un viaje de ida y vuelta a través de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud más un viaje de ida y vuelta a través de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando está bloqueado esperando una respuesta de búsqueda o confirmación. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podría ser mitigado por una implementación multi-hilo en un sistema con programación preemptiva. 6.3.2 Versión de Caché El commit en solitario permite que un cliente rápido que modifica un objeto haga un commit de forma independiente a un compañero lento. El mecanismo de confirmación única introduce un procesamiento adicional en el servidor durante la validación de la transacción, y un procesamiento adicional en el cliente durante la confirmación de la transacción y en el momento del procesamiento de actualización o invalidación. Los gastos generales del lado del servidor son mínimos y consisten en una actualización del número de versión de la página en el momento de la confirmación, y una comparación del número de versión en el momento de la validación de la transacción. La caché de versión tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacción accede a objetos en múltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor único y, por lo tanto, el tiempo de confirmación adicional de la gestión de la caché de versiones en el cliente no contribuye a los resultados presentados en la sección a continuación. Para medir estos costos adicionales del lado del cliente en un sistema de múltiples servidores, instrumentamos la implementación de la caché de versiones para ejecutarse con una traza de carga de trabajo que incluía invalidaciones reordenadas y cronometramos las operaciones básicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operación de búsqueda de caché de versión para cada objeto leído por la transacción en el momento de preparación de la solicitud de compromiso, y una operación de inserción de caché de versión para cada objeto actualizado por una transacción en el momento de procesamiento de la respuesta de compromiso, pero solo si la página actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmación se mantengan al mínimo, ya que el cliente está esperando de forma síncrona la finalización de la confirmación. Las mediciones muestran que en el peor de los casos, cuando llega un gran número de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en páginas reordenadas, el costo de actualizar la caché de versión es de 0.6 ms. El costo de tiempo de invalidación es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementación de la caché de versiones para reducir aún más estos costos. 6.4 Rendimiento general Esta sección examina las mejoras de rendimiento observadas por una aplicación que ejecuta el benchmark OO7 con un BuddyCache en una red de área amplia. 6.4.1 Fallos en frío Para evaluar las mejoras de rendimiento al evitar fallos en frío, comparamos el rendimiento de la caché en frío del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecución de los sistemas en el entorno de la red de área local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de área amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en caché fría. Los números fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frío solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frío solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparación con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cálculos para el cliente, solicitudes de recuperación directa, recuperaciones de pares y solicitudes de confirmación. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperación entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperación del servidor para cada cliente individual disminuye porque, con más clientes accediendo a un módulo compartido de tamaño fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperación de pares en comparación con la recuperación directa, pero este beneficio se ve contrarrestado por los tiempos de confirmación aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relación con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de caché 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT función de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias típicas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Sorprendentemente, los resultados analíticos predicen la mejora medida muy de cerca, aunque son ligeramente más altos que los valores empíricos. La razón principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidación evitados, comparamos el rendimiento de caché caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interés de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un único cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compañeros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compañeros con un grupo que contiene un único escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuración simple es suficiente para mostrar el impacto de las técnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de caché caliente de OO7. Obtenemos los números ejecutando 2000 transacciones para filtrar los fallos en frío y luego medimos el tiempo de las siguientes 1000 transacciones. Aquí nuevamente, los números reportados se derivan de los resultados del experimento de la red de área local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalización en comparación con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparación con la Base. Este beneficio se debe a la actualización entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperación entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperación local evitando el retraso de la recuperación desde el servidor. El último es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperación de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperación de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualización de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relación con Base, y Buddy Writer y Base en relación con Base) en un experimento de caché activa en función del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualización entre pares domina el gasto general en la configuración de Writer incluso en redes de baja latencia (la actualización entre pares incurre en un gasto mínimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Como en experimentos de caché fría, aquí los resultados analíticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pérdida de invalidación es mínimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de caché fría). Como en el caso de caché fría, la razón por la que el modelo analítico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÓN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en una red de área extensa debido a la alta latencia de red. Este artículo describe BuddyCache, una nueva técnica de almacenamiento en caché cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para <br>aplicaciones colaborativas de alta consistencia</br> en entornos de red de alta latencia. La técnica mejora el rendimiento y proporciona propiedades sólidas de corrección y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirección para obtener objetos faltantes directamente de las cachés de los miembros del grupo, y para admitir la actualización entre pares, una nueva técnica de multidifusión a nivel de aplicación ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirección puede interferir con la disponibilidad del objeto. Solo commit es una nueva técnica de validación que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validación detallada utilizando información de versión de grano grueso económica. Hemos diseñado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analíticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Las principales contribuciones del artículo son: 1. extender las técnicas de almacenamiento en caché cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementación del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluación del rendimiento basada en análisis y mediciones de los costos y beneficios de las nuevas técnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. También agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios útiles que mejoraron este artículo. 9. REFERENCIAS [1] emulab.net, la Instalación de Emulación de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. Reconstrucción de fragmentos: Proporcionando coherencia de caché global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de Computación Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre Gestión de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: Computación en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de caché híbridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. Recuperación rápida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de caché en la World Wide Web. En la 17ª Conferencia Internacional sobre Sistemas de Computación Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluación del rendimiento del sistema de gestión de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una caché de objetos jerárquica en Internet. En la Conferencia Técnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachés de Internet escalables. Informe Técnico CS-1997-18, Departamento de Ciencias de la Computación, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: Caché de proxy cooperativa en una red de área amplia. En el Tercer Taller Internacional de Caché de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. Caché web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2º Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. Caché cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilación y en tiempo de ejecución para una memoria compartida distribuida eficiente. En Actas de IEEE, Edición Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la caché: un protocolo de intercambio de caché web escalable de área amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. Implementación de Gestión Global de Memoria en un Clúster de Estaciones de Trabajo. Actas del 15º Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: Diseño, Implementación y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de caché transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, páginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. Gestión global de memoria para arquitecturas de sistemas de gestión de bases de datos cliente-servidor. En Actas del 19º Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El Búfer de Objeto Modificado: Una Técnica de Gestión de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto Tecnológico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. Gestión de documentos replicados en un sistema de comunicación grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13ª Conferencia Europea sobre Programación Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18º Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. Replicación con marca de vista: un nuevo método de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de Computación Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalación eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de Multidifusión a Nivel de Aplicación. En el 3er Simposio USENIX sobre Tecnologías y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de caché cooperativa utilizando pistas. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en Caché Global. Informe técnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del Caché de Proxies Web Cooperativos. En el 17º Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerárquica de caché en una WAN. En el Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. Compartición adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÉNDICE Este apéndice describe el protocolo de conmutación por error de BuddyCache. Para dar cabida a clientes heterogéneos, incluidos los dispositivos portátiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseño de BuddyCache asume que las cachés del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresía detecta el fallo de un cliente o un redireccionador intercambiando mensajes periódicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutación por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuración y reinicia el protocolo. El protocolo de reconfiguración del grupo es similar al presentado en [25]. Aquí describimos cómo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de páginas redireccionadas y el reenvío de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachés. En caso de un fallo del cliente, el failover elimina las páginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmación, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en caché las páginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutación por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de páginas utilizando un protocolo similar al descrito en [6]. El redireccionador recién reiniciado solicita a los miembros activos del grupo la lista de páginas que están almacenando en caché y el estado de estas páginas, es decir, si las páginas están completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperación perdida expirará en el cliente y será retransmitida. Una transacción que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma después del cambio se trata como una transacción regular; una transacción que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciará la transacción y la solicitud de confirmación será retransmitida después del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caído podrían evitar la recolección de basura de las invalidaciones pendientes en los servidores o la caché virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los números de versión únicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validación de transacciones depende del protocolo de coherencia de caché para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutación por error de BuddyCache no compromete la corrección del procedimiento de validación. Recuerda que la validación de transacciones de BuddyCache utiliza dos mecanismos complementarios, números de versión de página y confirmaciones de invalidación de los clientes, para verificar que una transacción ha leído datos actualizados. La propagación de la confirmación de invalidación (y actualización) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmación de una modificación (invalidación o actualización) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en caché el objeto o bien ha instalado el valor más reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmación de un cliente para una transacción T que lee un objeto o después de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidación no confirmada para o pendiente para este grupo, la versión del objeto leída por la transacción T está actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validación utilizando números de versión. El registro de confirmación de transacción contiene un número de versión para cada objeto leído por la transacción. El protocolo de número de versión mantiene la invariante V P que garantiza que el valor del objeto o leído por la transacción corresponda al número de versión más alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificación anterior después de haber recibido una modificación posterior. La retransmisión de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validación verifica que el número de versión en el registro de confirmación coincida con el número de versión en la invalidación pendiente no reconocida. Es fácil ver que, dado que esta comprobación es una comprobación cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutación por error aún no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    "alta consistencia",
                    "aplicaciones colaborativas de alta consistencia"
                ]
            ]
        },
        "wide-area network": {
            "translated_key": "redes de área amplia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in <br>wide-area network</br> environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in <br>wide-area network</br> environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of <br>wide-area network</br> interactions to maintain data consistency is the main cost limiting the performance and therefore, in <br>wide-area network</br> environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in <br>wide-area network</br> environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a <br>wide-area network</br> would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in <br>wide-area network</br> environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in <br>wide-area network</br> because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a <br>wide-area network</br>.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "Nevertheless, distributed applications may perform poorly in <br>wide-area network</br> environments.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in <br>wide-area network</br> environment.",
                "For transactional storage systems, the high cost of <br>wide-area network</br> interactions to maintain data consistency is the main cost limiting the performance and therefore, in <br>wide-area network</br> environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in <br>wide-area network</br> environment.",
                "Update-based protocols that propagate updates to low-interest objects in a <br>wide-area network</br> would be wasteful."
            ],
            "translated_annotated_samples": [
                "Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de <br>redes de área amplia</br>.",
                "BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de <br>red de área amplia</br>.",
                "Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en <br>redes de área amplia</br> para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de <br>redes de área amplia</br>, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil.",
                "La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de <br>red de área amplia</br>.",
                "Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una <br>red de área amplia</br> serían derrochadores."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de <br>redes de área amplia</br>. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de <br>red de área amplia</br>. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en <br>redes de área amplia</br> para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de <br>redes de área amplia</br>, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de <br>red de área amplia</br>. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la transacción se cancela. Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de búsqueda de pares envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados. Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente. El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente. El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños. Un objetivo importante del diseño de BuddyCache es mantener este beneficio. Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo. Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché. Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. Almacén x 6. Actualización x 3. Comprométete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes. Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente. Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una <br>red de área amplia</br> serían derrochadores. ",
            "candidates": [],
            "error": [
                [
                    "redes de área amplia",
                    "red de área amplia",
                    "redes de área amplia",
                    "redes de área amplia",
                    "red de área amplia",
                    "red de área amplia"
                ]
            ]
        },
        "cooperative web caching": {
            "translated_key": "almacenamiento en caché web cooperativo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "<br>cooperative web caching</br> [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, <br>cooperative web caching</br> techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in <br>cooperative web caching</br> systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "<br>cooperative web caching</br> techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "<br>cooperative web caching</br> [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "However, <br>cooperative web caching</br> techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "BuddyCache uses a redirection approach similar to one used in <br>cooperative web caching</br> systems [11].",
                "<br>cooperative web caching</br> techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes."
            ],
            "translated_annotated_samples": [
                "El <br>almacenamiento en caché web cooperativo</br> [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor.",
                "Sin embargo, las técnicas de <br>almacenamiento en caché web cooperativo</br> no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina.",
                "BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de <br>almacenamiento en caché web cooperativos</br> [11].",
                "Las técnicas de <br>almacenamiento en caché web cooperativo</br>, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El <br>almacenamiento en caché web cooperativo</br> [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de <br>almacenamiento en caché web cooperativo</br> no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de <br>almacenamiento en caché web cooperativos</br> [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de <br>almacenamiento en caché web cooperativo</br>, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la transacción se cancela. Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de búsqueda de pares envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados. Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente. El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente. El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños. Un objetivo importante del diseño de BuddyCache es mantener este beneficio. Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo. Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché. Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. Almacén x 6. Actualización x 3. Comprométete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes. Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente. Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una red de área amplia serían derrochadores. Sin embargo, los protocolos de coherencia basados en invalidación pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interés para otro miembro del grupo. Con un protocolo basado en invalidación, la actualización de un miembro invalidará la copia en caché de otro miembro, lo que provocará que este último realice una recuperación de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualización e invalidación en entornos de redes de área amplia. Evita la penalización de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalización de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusión localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en caché anteriores. La actualización entre pares funciona de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que la transacción se confirma, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación, y también propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmación. 3.3 Confirmación individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminación de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en caché transaccional, ya que un cliente que es lento para reconocer una invalidación o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacción. Por ejemplo, un ingeniero que realiza una revisión repetida al mismo objeto de diseño compartido (y por lo tanto tiene la última versión del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situación representada en la figura 4 donde el Cliente1 realiza una transacción T que lee la última versión de un objeto x en la página P recientemente modificada por el Cliente1. Si la solicitud de confirmación para T llega al servidor antes de que la confirmación colectiva de Cliente2 por la última modificación de x llegue al servidor, el procedimiento de validación de OCC considera que x está obsoleto y aborta T (porque, como se explicó anteriormente, una invalidación no reconocida por un cliente actúa como indicación para el servidor de que el valor del objeto en caché está obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la corrección del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asíncronas son una parte importante de la razón por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasión de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envían y procesan de forma asíncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devolución de llamada jerárquica [32], pero la naturaleza asincrónica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrónicas. El protocolo de validación de confirmación en solitario permite a un cliente con objetos actualizados confirmar una transacción incluso si la confirmación del grupo se retrasa debido a pares lentos o caídos. El protocolo requiere que los clientes incluyan información adicional con los conjuntos de lectura de transacciones en el mensaje de confirmación, para indicar al servidor que los objetos leídos por la transacción están actualizados. Los números de versión de los objetos podrían proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionó anteriormente, mantener números de versión por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaño de directorio) en todo el sistema de objetos cuando los objetos son pequeños [23]. En cambio, solo utiliza números de versión de página de grano grueso para identificar versiones de objetos de grano fino. El número de versión de una página se incrementa en un servidor cuando una transacción que modifica objetos en la página se confirma. Las actualizaciones realizadas por una única transacción y las invalidaciones correspondientes son identificadas de manera única por el número de versión de la página modificada. Los números de versión de la página se propagan a los clientes en respuestas de recuperación, respuestas de confirmación y con invalidaciones, y los clientes incluyen los números de versión de la página en las solicitudes de confirmación enviadas a los servidores. Si una transacción falla en la validación debido a la falta de reconocimiento de grupo, el servidor verifica los números de versión de página de los objetos en el conjunto de lectura de la transacción y permite que la transacción se confirme si el cliente ha leído desde la última versión de la página. Los números de versión de la página permiten confirmaciones independientes, pero las verificaciones de versión de página solo detectan conflictos a nivel de página. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes. Potencialmente, puede ser más rápido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podría ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en caché de pares de múltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en caché web, simplemente aumentar la población de clientes en una caché proxy a menudo aumenta la tasa general de aciertos en la caché [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacción explícita entre clientes y la colaboración, lo que sugiere que es poco probable que ocurra la recuperación entre grupos. Además, las mediciones de sistemas de almacenamiento en caché web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexión de red entre los grupos de pares sea muy rápida. Estamos principalmente interesados en entornos donde compañeros que colaboran estrechamente tienen una conectividad rápida a corta distancia, pero la conexión entre grupos de compañeros puede ser lenta. Como resultado, decidimos que el soporte para la recuperación entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compañeros con recursos heterogéneos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compañeros o, cuando esté disponible, en un nodo separado dentro de la infraestructura del sitio. Además, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una caché de pares en espera para recibir páginas recuperadas por otros pares, emulando una caché central algo similar a una caché de proxy web regional. Desde el punto de vista del protocolo de coherencia de caché BuddyCache, sin embargo, un caché de compañero en espera es equivalente a un caché de compañero regular y, por lo tanto, no consideramos este caso por separado en la discusión de este documento. 4. En esta sección proporcionamos los detalles de la implementación de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en caché de estos objetos. Las aplicaciones se ejecutan en los clientes e interactúan con el sistema realizando llamadas a métodos de objetos en caché. Todas las llamadas a métodos ocurren dentro de transacciones atómicas. Los clientes se comunican con los servidores para obtener páginas o realizar una transacción. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volátil. El disco está organizado como una colección de páginas que son las unidades de acceso al disco. El registro estable guarda la información de confirmación y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de caché y una caché de objetos modificados recuperable llamada MOB. El directorio lleva un registro de qué páginas están almacenadas en caché por qué clientes. El MOB contiene objetos recientemente modificados que aún no han sido escritos de vuelta en sus páginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de caché base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la Sección 3.1. Proporcionamos algunos de los detalles relevantes de la implementación del protocolo OCC. El cliente lleva un registro de los objetos que son leídos y modificados por su transacción; envía esta información, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacción. Los servidores determinan si la confirmación es posible, utilizando un protocolo de confirmación de dos fases si la transacción utilizó objetos en múltiples servidores. Si la transacción se lleva a cabo, las nuevas copias de los objetos modificados se añaden al registro y también se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperación escaneando el registro. Dado que los objetos no están bloqueados antes de ser utilizados, una confirmación de transacción puede hacer que las cachés contengan objetos obsoletos. Los servidores abortarán una transacción que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviándoles mensajes de invalidación; un servidor utiliza su directorio y la información sobre la transacción de confirmación para determinar qué mensajes de invalidación enviar. Los mensajes de invalidación son pequeños porque simplemente identifican objetos obsoletos. Además, se envían en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidación, elimina los objetos obsoletos de su caché y aborta la transacción actual si los utilizó. El cliente sigue conservando páginas que contienen objetos invalidados; estas páginas ahora están incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidación de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener páginas incompletas en la caché del cliente significa que el falso intercambio no conduce a fallos innecesarios en la caché. Los clientes reconocen las invalidaciones para indicar la eliminación de datos obsoletos, como se explica en la Sección 3.1. Los mensajes de invalidación evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo así el desperdicio de trabajo y trasladando la detección de abortos de los servidores a los clientes. Cuando una transacción se aborta, su cliente restaura las copias en caché de los objetos modificados al estado que tenían antes de que la transacción comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacción. 4.3 Redirección El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de páginas disponibles en el grupo de pares y proporciona una redirección rápida y centralizada de recuperación (ver figura 2) entre las cachés de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan páginas u objetos al incluir esa información en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la caché de grupo, el redireccionador realiza un seguimiento del estado de las páginas. Una página en caché está completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una página están marcados como inválidos. Solo se utilizan páginas completas por el proceso de recuperación de pares. El protocolo para mantener el estado de la página cuando las páginas son actualizadas e invalidadas se describe en la Sección 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una página solicitada completa no está disponible en el grupo de pares o si un par necesita confirmar una transacción, el redireccionador actúa como un proxy de servidor: reenvía la solicitud al servidor y luego reenvía la respuesta de vuelta al cliente. Además, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualización o información de invalidación a los clientes que tienen en caché la página modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la caché de grupo de pares combinada está desempeñando el papel de una única caché de cliente en el sistema base. 4.4 Actualización de pares La actualización de pares se implementa de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que una transacción se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacción generan invalidaciones de objetos para cada grupo de caché que almacena páginas que contienen los objetos modificados (incluido el grupo que realiza la confirmación). Las invalidaciones se envían de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en caché los objetos modificados se deshagan de los datos obsoletos. En grupos de caché distintos al grupo de confirmación, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en caché las páginas modificadas, recopilan las confirmaciones de los clientes y, después de completar la recopilación, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacción, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envían a los clientes que almacenan en caché esas páginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmación colectiva se propaga al servidor. Una invalidación hace que una página en caché no esté disponible para la recuperación de pares, cambiando el estado de una página completa p a incompleta. Por el contrario, una actualización de una página completa conserva el estado completo de la página. Como se muestra en los estudios de la reconstrucción de fragmentos 31 [2], esta propagación de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la recuperación entre pares. Por lo tanto, el efecto de la actualización de pares es similar a la reconstrucción de fragmentos ansiosa [2]. También hemos considerado la posibilidad de permitir que un compañero recupere una página incompleta (con objetos inválidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos inválidos. 4.5 Vcache El protocolo de validación de confirmación en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo más lentos (o fallidos). Como se explica en la Sección 3.3, el protocolo de commit único permite que una transacción T pase la validación si la información adicional de coherencia proporcionada por el cliente indica que la transacción T ha leído objetos actualizados. Los clientes utilizan los números de versión de la página para proporcionar esta información adicional de coherencia. Es decir, un cliente incluye el número de versión de la página correspondiente a cada objeto en el conjunto de objetos leídos enviado en la solicitud de confirmación al servidor. Dado que a cada actualización de objeto comprometido le corresponde un número de versión de página único, el número de versión de página asociado con un objeto permite que el procedimiento de validación en el servidor verifique si la transacción del cliente ha leído objetos actualizados. El uso de versiones de página de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeños, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en caché a la versión de página identificadora (ObjectToVersion). El principal problema de implementación se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian números de versión de página con las invalidaciones. En el momento de la validación, si hay una invalidación no reconocida pendiente para un objeto x leído por una transacción T, el procedimiento de validación verifica si el número de versión de x en el conjunto de lectura de Ts coincide con el número de versión de la invalidación pendiente más alta para x, en cuyo caso el valor del objeto está actualizado, de lo contrario, T falla en la validación. Observamos nuevamente que las verificaciones basadas en el número de versión de la página y las verificaciones basadas en el reconocimiento de invalidación son complementarias en la validación de confirmación individual y ambas son necesarias. La verificación del número de versión de la página permite que la validación avance antes de que lleguen las confirmaciones de invalidación, pero por sí sola, una verificación del número de versión de la página detecta conflictos a nivel de página y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cómo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un número de versión de la página para cada página en caché. El número de versión satisface la siguiente invariante V P sobre el estado de los objetos en una página: si una página en caché P tiene un número de versión v, entonces el valor de un objeto o en la página en caché P es inválido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacción que estableció el número de versión de P en v. Los nuevos valores de objetos y los nuevos números de versión de página llegan cuando un cliente obtiene una página o cuando llega una respuesta de confirmación o invalidaciones para esta página. Los nuevos valores del objeto modifican la página y, por lo tanto, el número de versión de la página necesita ser actualizado para mantener la invariante V P. Un número de versión de página que llega cuando un cliente obtiene una página, reemplaza la Versión del Objeto x 8 Servidor de Redirección 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el número de versión de la página para esta página. Tal actualización preserva el invariante V P. De manera similar, un número de versión de página en secuencia que llega al cliente en un mensaje de confirmación o invalidación avanza el número de versión para toda la página en caché, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus números de versión de página correspondientes también pueden llegar al cliente fuera de secuencia, en cuyo caso la actualización del número de versión de la página podría violar V P. Por ejemplo, una respuesta de confirmación para una transacción que actualiza el objeto x en la página P en el servidor S1, y el objeto y en la página Q en el servidor S2, puede entregar un nuevo número de versión para P desde el coordinador de transacciones S1 antes de que llegue una invalidación generada para una transacción anterior que ha modificado el objeto r en la página P desde S1 (como se muestra en la figura 5). El protocolo de actualización de caché garantiza que el valor de cualquier objeto o en una página en caché P refleje la actualización o invalidación con el número de versión observado más alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de números de versión de página, el cliente gestiona una pequeña caché de números de versión vcache que mantiene el mapeo de un objeto a su número de versión de página correspondiente para todas las actualizaciones de números de versión reordenadas hasta que se ensamble una secuencia completa de números de versión de página. Cuando llegan los números de versión faltantes para la página y completan una secuencia, el número de versión de toda la página se avanza. El mapeo de ObjectToVersion, incluyendo los números de versión de vcache y página, se utiliza en el momento de la confirmación de la transacción para proporcionar números de versión para el conjunto de objetos leídos de la siguiente manera. Si el objeto leído tiene una entrada en la vcache, su número de versión es igual al número de versión más alto en la vcache para este objeto. Si el objeto no está presente en la vcache, su número de versión es igual al número de versión de la página en caché que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la caché del cliente, incluyendo los números de versión de las páginas y la vcache. El cliente puede limitar el tamaño de la caché virtual según sea necesario, ya que volver a cargar una página elimina todos los números de versión de página reordenados de la caché virtual. Sin embargo, esperamos que la reorganización de números de versión sea poco común y, por lo tanto, esperamos que la vcache sea muy pequeña. 5. Un grupo de clientes contiene múltiples nodos de cliente y un objeto de página de versión redi32 VCache Cliente Caché Cliente Página Caché Figura 6: Mapa de Objeto a Versión con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutación por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. Además, el fallo del redireccionador debería permitir que los clientes no afectados mantengan sus cachés intactas. Hemos diseñado un protocolo de conmutación por error para BuddyCache pero aún no lo hemos implementado. El apéndice describe el protocolo. 6. La redirección de BuddyCache en la evaluación de rendimiento respalda los beneficios de evitar la comunicación con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes. ¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la recuperación entre pares y la actualización entre pares se deben a la evitación de interacciones con el servidor. Esta sección presenta un modelo de rendimiento analítico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la caché del cliente. Estos pueden ser fallos fríos, fallos de invalidación y fallos de capacidad. Nuestro análisis se centra en los fallos por frío y los fallos por invalidación, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frío. Además, las tendencias tecnológicas indican que la capacidad de memoria y almacenamiento seguirá creciendo y, por lo tanto, es probable que una configuración típica de BuddyCache no esté limitada por la caché. Los fallos de caché del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuración de caché. Nuestro análisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validación. Para estudiar el beneficio de evitar fallos en frío, consideramos el rendimiento de la caché en frío en una carga de trabajo de solo lectura (sin fallos de invalidación). Esperamos que la recuperación entre pares mejore el costo de latencia para las solicitudes de caché fría del cliente al recuperar objetos de la caché cercana. Evaluamos cómo el costo de redirección afecta este beneficio al comparar y analizar el rendimiento de una aplicación que se ejecuta en un sistema de almacenamiento con BuddyCache y sin él (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidación, consideramos el rendimiento de la caché caliente en una carga de trabajo con modificaciones (sin fallos en frío). En las cachés calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualización entre pares permite que un cliente acceda a un objeto modificado por un compañero colaborador cercano sin el retraso impuesto por los protocolos de invalidación únicamente. En grupos donde los compañeros comparten un interés de solo lectura en los objetos modificados, la recuperación entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compañero colaborador lo tenga, lo que evita el retraso de la recuperación del servidor sin el alto costo impuesto por los protocolos de solo actualización. Las tendencias tecnológicas indican que ambos beneficios seguirán siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualización únicamente. Sin embargo, la tendencia hacia cachés cada vez más grandes, que se actualizan cuando los objetos en caché son modificados, hace que los protocolos basados en invalidación sean más atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicación que se ejecuta sin BuddyCache y una aplicación que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compañero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compañero fuera del grupo. La actualización entre pares también puede evitar fallos de invalidación debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma página de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseño del objeto, y también porque este beneficio se puede derivar dado el índice de aciertos en caché y la contención de la carga de trabajo. 6.1.1 El Modelo El modelo considera cómo el tiempo para completar una ejecución con y sin BuddyCache se ve afectado por los fallos de invalidación y los fallos en frío. Considerando k clientes ejecutándose concurrentemente accediendo de manera uniforme a un conjunto compartido de N páginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacción y realizar cálculos en una transacción, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin él (Base). Para simplificar, nuestro modelo asume que los tiempos de búsqueda y confirmación son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del número total de clientes en el sistema. El número de fallos evitados por la recuperación entre pares depende de k, el número de clientes en la BuddyCache, y del interés conjunto de los clientes en los datos compartidos. En una ejecución específica de BuddyCache, se modela mediante la variable r, definida como el número de solicitudes que llegan al redireccionador para una versión dada de la página P (es decir, hasta que un objeto en la página se invalida). Considera una ejecución con fallos en frío. Un cliente comienza con una caché fría y ejecuta una carga de trabajo de solo lectura hasta que accede a las N páginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la caché del cliente es lo suficientemente grande como para contener N páginas. En BC, los fríos fallos para la página P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consideremos a continuación una ejecución con fallos de invalidación. Un cliente comienza con una caché caliente que contiene el conjunto de trabajo de N páginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualización entre pares elimina todos los fallos de invalidación. En un grupo que contiene solo lectores (BCR), durante una ejecución en estado estable con actualizaciones uniformes, una transacción del cliente tiene fallos de invalidación faltantes. Considera la secuencia de r fallos de cliente en la página P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la página P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frío, r ≤ k porque la segunda invalidación deshabilita la redirección para P hasta que el próximo fallo en P provoque una recuperación del servidor. Suponiendo un acceso uniforme, un fallo de invalidación del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperación del servidor), y una probabilidad de (1 − 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacción única en los sistemas Base, BCR y BCW. En los experimentos descritos a continuación, medimos los parámetros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalización derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalización y beneficios medidos directamente en los experimentos. 6.2 Configuración Experimental Antes de presentar nuestros resultados, describimos nuestra configuración experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectándose directamente a los servidores. El sistema Buddy ejecuta nuestra implementación del prototipo de BuddyCache en Thor, admitiendo la recuperación de pares, la actualización de pares y la confirmación en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark está diseñado para capturar las características de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicación específica. Utilizamos OO7 porque es un punto de referencia estándar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un árbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un gráfico de partes atómicas vinculadas por objetos de conexión; cada parte atómica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atómicas por parte compuesta. La base de datos multiusuario asigna a cada cliente un módulo privado que consiste en un árbol de objetos de ensamblaje, y agrega un módulo compartido adicional que escala proporcionalmente al número de clientes. Esperamos que una configuración típica de BuddyCache no esté limitada por la caché y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la caché. Dado que el objetivo de nuestro estudio es evaluar qué tan efectivamente nuestras técnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras técnicas tienen en los fallos de caché frío y de consistencia de caché, y aislar tanto como sea posible el efecto de los fallos de capacidad de caché. Para mantener la duración de nuestros experimentos razonable, utilizamos cachés pequeños. El benchmark OO7 genera módulos de base de datos de tamaño predefinido. En nuestra implementación de OO7, el tamaño del módulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la caché, utilizamos un único módulo privado y elegimos un tamaño de caché de 40MB para cada cliente. La base de datos OO7 se genera con módulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos están agrupados en páginas de 8K, que también son la unidad de transferencia en las solicitudes de recuperación. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro análisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idéntico a T1 excepto que modifica todas las partes atómicas en un solo compuesto. Una transacción única incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo módulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacción, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de búsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una caché de 50MB (de los cuales 6MB se utilizaron para el búfer de objetos modificados), el cliente tenía una caché de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos básicos Esta sección analiza el costo básico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 Redirección Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtención del servidor), el costo adicional de la redirección incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperación o confirmación del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmación y recuperación del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de área rápida. Todos los números fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirección al cruzar el redireccionador no es muy alto, incluso en una red de área local. El costo de la confirmación aumenta con el número de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperación no aumenta tanto porque la caché del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la caché del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperación entre pares, medimos la latencia de la recuperación entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperación entre pares, el costo de la redirección incluye, además del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este último incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la página solicitada. Medimos directamente el tiempo para copiar y desenrollar la página solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperación de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador más un viaje de ida y vuelta a través de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud más un viaje de ida y vuelta a través de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando está bloqueado esperando una respuesta de búsqueda o confirmación. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podría ser mitigado por una implementación multi-hilo en un sistema con programación preemptiva. 6.3.2 Versión de Caché El commit en solitario permite que un cliente rápido que modifica un objeto haga un commit de forma independiente a un compañero lento. El mecanismo de confirmación única introduce un procesamiento adicional en el servidor durante la validación de la transacción, y un procesamiento adicional en el cliente durante la confirmación de la transacción y en el momento del procesamiento de actualización o invalidación. Los gastos generales del lado del servidor son mínimos y consisten en una actualización del número de versión de la página en el momento de la confirmación, y una comparación del número de versión en el momento de la validación de la transacción. La caché de versión tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacción accede a objetos en múltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor único y, por lo tanto, el tiempo de confirmación adicional de la gestión de la caché de versiones en el cliente no contribuye a los resultados presentados en la sección a continuación. Para medir estos costos adicionales del lado del cliente en un sistema de múltiples servidores, instrumentamos la implementación de la caché de versiones para ejecutarse con una traza de carga de trabajo que incluía invalidaciones reordenadas y cronometramos las operaciones básicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operación de búsqueda de caché de versión para cada objeto leído por la transacción en el momento de preparación de la solicitud de compromiso, y una operación de inserción de caché de versión para cada objeto actualizado por una transacción en el momento de procesamiento de la respuesta de compromiso, pero solo si la página actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmación se mantengan al mínimo, ya que el cliente está esperando de forma síncrona la finalización de la confirmación. Las mediciones muestran que en el peor de los casos, cuando llega un gran número de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en páginas reordenadas, el costo de actualizar la caché de versión es de 0.6 ms. El costo de tiempo de invalidación es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementación de la caché de versiones para reducir aún más estos costos. 6.4 Rendimiento general Esta sección examina las mejoras de rendimiento observadas por una aplicación que ejecuta el benchmark OO7 con un BuddyCache en una red de área amplia. 6.4.1 Fallos en frío Para evaluar las mejoras de rendimiento al evitar fallos en frío, comparamos el rendimiento de la caché en frío del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecución de los sistemas en el entorno de la red de área local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de área amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en caché fría. Los números fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frío solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frío solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparación con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cálculos para el cliente, solicitudes de recuperación directa, recuperaciones de pares y solicitudes de confirmación. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperación entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperación del servidor para cada cliente individual disminuye porque, con más clientes accediendo a un módulo compartido de tamaño fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperación de pares en comparación con la recuperación directa, pero este beneficio se ve contrarrestado por los tiempos de confirmación aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relación con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de caché 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT función de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias típicas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Sorprendentemente, los resultados analíticos predicen la mejora medida muy de cerca, aunque son ligeramente más altos que los valores empíricos. La razón principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidación evitados, comparamos el rendimiento de caché caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interés de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un único cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compañeros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compañeros con un grupo que contiene un único escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuración simple es suficiente para mostrar el impacto de las técnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de caché caliente de OO7. Obtenemos los números ejecutando 2000 transacciones para filtrar los fallos en frío y luego medimos el tiempo de las siguientes 1000 transacciones. Aquí nuevamente, los números reportados se derivan de los resultados del experimento de la red de área local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalización en comparación con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparación con la Base. Este beneficio se debe a la actualización entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperación entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperación local evitando el retraso de la recuperación desde el servidor. El último es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperación de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperación de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualización de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relación con Base, y Buddy Writer y Base en relación con Base) en un experimento de caché activa en función del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualización entre pares domina el gasto general en la configuración de Writer incluso en redes de baja latencia (la actualización entre pares incurre en un gasto mínimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Como en experimentos de caché fría, aquí los resultados analíticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pérdida de invalidación es mínimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de caché fría). Como en el caso de caché fría, la razón por la que el modelo analítico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÓN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en una red de área extensa debido a la alta latencia de red. Este artículo describe BuddyCache, una nueva técnica de almacenamiento en caché cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La técnica mejora el rendimiento y proporciona propiedades sólidas de corrección y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirección para obtener objetos faltantes directamente de las cachés de los miembros del grupo, y para admitir la actualización entre pares, una nueva técnica de multidifusión a nivel de aplicación ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirección puede interferir con la disponibilidad del objeto. Solo commit es una nueva técnica de validación que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validación detallada utilizando información de versión de grano grueso económica. Hemos diseñado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analíticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Las principales contribuciones del artículo son: 1. extender las técnicas de almacenamiento en caché cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementación del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluación del rendimiento basada en análisis y mediciones de los costos y beneficios de las nuevas técnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. También agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios útiles que mejoraron este artículo. 9. REFERENCIAS [1] emulab.net, la Instalación de Emulación de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. Reconstrucción de fragmentos: Proporcionando coherencia de caché global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de Computación Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre Gestión de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: Computación en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de caché híbridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. Recuperación rápida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de caché en la World Wide Web. En la 17ª Conferencia Internacional sobre Sistemas de Computación Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluación del rendimiento del sistema de gestión de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una caché de objetos jerárquica en Internet. En la Conferencia Técnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachés de Internet escalables. Informe Técnico CS-1997-18, Departamento de Ciencias de la Computación, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: Caché de proxy cooperativa en una red de área amplia. En el Tercer Taller Internacional de Caché de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. Caché web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2º Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. Caché cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilación y en tiempo de ejecución para una memoria compartida distribuida eficiente. En Actas de IEEE, Edición Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la caché: un protocolo de intercambio de caché web escalable de área amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. Implementación de Gestión Global de Memoria en un Clúster de Estaciones de Trabajo. Actas del 15º Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: Diseño, Implementación y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de caché transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, páginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. Gestión global de memoria para arquitecturas de sistemas de gestión de bases de datos cliente-servidor. En Actas del 19º Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El Búfer de Objeto Modificado: Una Técnica de Gestión de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto Tecnológico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. Gestión de documentos replicados en un sistema de comunicación grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13ª Conferencia Europea sobre Programación Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18º Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. Replicación con marca de vista: un nuevo método de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de Computación Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalación eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de Multidifusión a Nivel de Aplicación. En el 3er Simposio USENIX sobre Tecnologías y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de caché cooperativa utilizando pistas. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en Caché Global. Informe técnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del Caché de Proxies Web Cooperativos. En el 17º Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerárquica de caché en una WAN. En el Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. Compartición adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÉNDICE Este apéndice describe el protocolo de conmutación por error de BuddyCache. Para dar cabida a clientes heterogéneos, incluidos los dispositivos portátiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseño de BuddyCache asume que las cachés del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresía detecta el fallo de un cliente o un redireccionador intercambiando mensajes periódicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutación por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuración y reinicia el protocolo. El protocolo de reconfiguración del grupo es similar al presentado en [25]. Aquí describimos cómo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de páginas redireccionadas y el reenvío de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachés. En caso de un fallo del cliente, el failover elimina las páginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmación, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en caché las páginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutación por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de páginas utilizando un protocolo similar al descrito en [6]. El redireccionador recién reiniciado solicita a los miembros activos del grupo la lista de páginas que están almacenando en caché y el estado de estas páginas, es decir, si las páginas están completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperación perdida expirará en el cliente y será retransmitida. Una transacción que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma después del cambio se trata como una transacción regular; una transacción que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciará la transacción y la solicitud de confirmación será retransmitida después del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caído podrían evitar la recolección de basura de las invalidaciones pendientes en los servidores o la caché virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los números de versión únicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validación de transacciones depende del protocolo de coherencia de caché para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutación por error de BuddyCache no compromete la corrección del procedimiento de validación. Recuerda que la validación de transacciones de BuddyCache utiliza dos mecanismos complementarios, números de versión de página y confirmaciones de invalidación de los clientes, para verificar que una transacción ha leído datos actualizados. La propagación de la confirmación de invalidación (y actualización) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmación de una modificación (invalidación o actualización) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en caché el objeto o bien ha instalado el valor más reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmación de un cliente para una transacción T que lee un objeto o después de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidación no confirmada para o pendiente para este grupo, la versión del objeto leída por la transacción T está actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validación utilizando números de versión. El registro de confirmación de transacción contiene un número de versión para cada objeto leído por la transacción. El protocolo de número de versión mantiene la invariante V P que garantiza que el valor del objeto o leído por la transacción corresponda al número de versión más alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificación anterior después de haber recibido una modificación posterior. La retransmisión de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validación verifica que el número de versión en el registro de confirmación coincida con el número de versión en la invalidación pendiente no reconocida. Es fácil ver que, dado que esta comprobación es una comprobación cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutación por error aún no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    "almacenamiento en caché web cooperativo",
                    "almacenamiento en caché web cooperativo",
                    "almacenamiento en caché web cooperativos",
                    "almacenamiento en caché web cooperativo"
                ]
            ]
        },
        "fine-grain sharing": {
            "translated_key": "intercambio de granularidad fina",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for <br>fine-grain sharing</br>. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "Section 4 describes the details of the implementation of solo commit support for <br>fine-grain sharing</br>. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups."
            ],
            "translated_annotated_samples": [
                "La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el <br>intercambio de granularidad fina</br>. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la transacción se cancela. Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de búsqueda de pares envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados. Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente. El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente. El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños. Un objetivo importante del diseño de BuddyCache es mantener este beneficio. Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo. Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché. Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. Almacén x 6. Actualización x 3. Comprométete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes. Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente. Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una red de área amplia serían derrochadores. Sin embargo, los protocolos de coherencia basados en invalidación pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interés para otro miembro del grupo. Con un protocolo basado en invalidación, la actualización de un miembro invalidará la copia en caché de otro miembro, lo que provocará que este último realice una recuperación de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualización e invalidación en entornos de redes de área amplia. Evita la penalización de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalización de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusión localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en caché anteriores. La actualización entre pares funciona de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que la transacción se confirma, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación, y también propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmación. 3.3 Confirmación individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminación de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en caché transaccional, ya que un cliente que es lento para reconocer una invalidación o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacción. Por ejemplo, un ingeniero que realiza una revisión repetida al mismo objeto de diseño compartido (y por lo tanto tiene la última versión del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situación representada en la figura 4 donde el Cliente1 realiza una transacción T que lee la última versión de un objeto x en la página P recientemente modificada por el Cliente1. Si la solicitud de confirmación para T llega al servidor antes de que la confirmación colectiva de Cliente2 por la última modificación de x llegue al servidor, el procedimiento de validación de OCC considera que x está obsoleto y aborta T (porque, como se explicó anteriormente, una invalidación no reconocida por un cliente actúa como indicación para el servidor de que el valor del objeto en caché está obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la corrección del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asíncronas son una parte importante de la razón por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasión de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envían y procesan de forma asíncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devolución de llamada jerárquica [32], pero la naturaleza asincrónica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrónicas. El protocolo de validación de confirmación en solitario permite a un cliente con objetos actualizados confirmar una transacción incluso si la confirmación del grupo se retrasa debido a pares lentos o caídos. El protocolo requiere que los clientes incluyan información adicional con los conjuntos de lectura de transacciones en el mensaje de confirmación, para indicar al servidor que los objetos leídos por la transacción están actualizados. Los números de versión de los objetos podrían proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionó anteriormente, mantener números de versión por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaño de directorio) en todo el sistema de objetos cuando los objetos son pequeños [23]. En cambio, solo utiliza números de versión de página de grano grueso para identificar versiones de objetos de grano fino. El número de versión de una página se incrementa en un servidor cuando una transacción que modifica objetos en la página se confirma. Las actualizaciones realizadas por una única transacción y las invalidaciones correspondientes son identificadas de manera única por el número de versión de la página modificada. Los números de versión de la página se propagan a los clientes en respuestas de recuperación, respuestas de confirmación y con invalidaciones, y los clientes incluyen los números de versión de la página en las solicitudes de confirmación enviadas a los servidores. Si una transacción falla en la validación debido a la falta de reconocimiento de grupo, el servidor verifica los números de versión de página de los objetos en el conjunto de lectura de la transacción y permite que la transacción se confirme si el cliente ha leído desde la última versión de la página. Los números de versión de la página permiten confirmaciones independientes, pero las verificaciones de versión de página solo detectan conflictos a nivel de página. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el <br>intercambio de granularidad fina</br>. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes. Potencialmente, puede ser más rápido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podría ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en caché de pares de múltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en caché web, simplemente aumentar la población de clientes en una caché proxy a menudo aumenta la tasa general de aciertos en la caché [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacción explícita entre clientes y la colaboración, lo que sugiere que es poco probable que ocurra la recuperación entre grupos. Además, las mediciones de sistemas de almacenamiento en caché web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexión de red entre los grupos de pares sea muy rápida. Estamos principalmente interesados en entornos donde compañeros que colaboran estrechamente tienen una conectividad rápida a corta distancia, pero la conexión entre grupos de compañeros puede ser lenta. Como resultado, decidimos que el soporte para la recuperación entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compañeros con recursos heterogéneos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compañeros o, cuando esté disponible, en un nodo separado dentro de la infraestructura del sitio. Además, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una caché de pares en espera para recibir páginas recuperadas por otros pares, emulando una caché central algo similar a una caché de proxy web regional. Desde el punto de vista del protocolo de coherencia de caché BuddyCache, sin embargo, un caché de compañero en espera es equivalente a un caché de compañero regular y, por lo tanto, no consideramos este caso por separado en la discusión de este documento. 4. En esta sección proporcionamos los detalles de la implementación de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en caché de estos objetos. Las aplicaciones se ejecutan en los clientes e interactúan con el sistema realizando llamadas a métodos de objetos en caché. Todas las llamadas a métodos ocurren dentro de transacciones atómicas. Los clientes se comunican con los servidores para obtener páginas o realizar una transacción. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volátil. El disco está organizado como una colección de páginas que son las unidades de acceso al disco. El registro estable guarda la información de confirmación y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de caché y una caché de objetos modificados recuperable llamada MOB. El directorio lleva un registro de qué páginas están almacenadas en caché por qué clientes. El MOB contiene objetos recientemente modificados que aún no han sido escritos de vuelta en sus páginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de caché base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la Sección 3.1. Proporcionamos algunos de los detalles relevantes de la implementación del protocolo OCC. El cliente lleva un registro de los objetos que son leídos y modificados por su transacción; envía esta información, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacción. Los servidores determinan si la confirmación es posible, utilizando un protocolo de confirmación de dos fases si la transacción utilizó objetos en múltiples servidores. Si la transacción se lleva a cabo, las nuevas copias de los objetos modificados se añaden al registro y también se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperación escaneando el registro. Dado que los objetos no están bloqueados antes de ser utilizados, una confirmación de transacción puede hacer que las cachés contengan objetos obsoletos. Los servidores abortarán una transacción que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviándoles mensajes de invalidación; un servidor utiliza su directorio y la información sobre la transacción de confirmación para determinar qué mensajes de invalidación enviar. Los mensajes de invalidación son pequeños porque simplemente identifican objetos obsoletos. Además, se envían en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidación, elimina los objetos obsoletos de su caché y aborta la transacción actual si los utilizó. El cliente sigue conservando páginas que contienen objetos invalidados; estas páginas ahora están incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidación de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener páginas incompletas en la caché del cliente significa que el falso intercambio no conduce a fallos innecesarios en la caché. Los clientes reconocen las invalidaciones para indicar la eliminación de datos obsoletos, como se explica en la Sección 3.1. Los mensajes de invalidación evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo así el desperdicio de trabajo y trasladando la detección de abortos de los servidores a los clientes. Cuando una transacción se aborta, su cliente restaura las copias en caché de los objetos modificados al estado que tenían antes de que la transacción comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacción. 4.3 Redirección El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de páginas disponibles en el grupo de pares y proporciona una redirección rápida y centralizada de recuperación (ver figura 2) entre las cachés de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan páginas u objetos al incluir esa información en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la caché de grupo, el redireccionador realiza un seguimiento del estado de las páginas. Una página en caché está completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una página están marcados como inválidos. Solo se utilizan páginas completas por el proceso de recuperación de pares. El protocolo para mantener el estado de la página cuando las páginas son actualizadas e invalidadas se describe en la Sección 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una página solicitada completa no está disponible en el grupo de pares o si un par necesita confirmar una transacción, el redireccionador actúa como un proxy de servidor: reenvía la solicitud al servidor y luego reenvía la respuesta de vuelta al cliente. Además, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualización o información de invalidación a los clientes que tienen en caché la página modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la caché de grupo de pares combinada está desempeñando el papel de una única caché de cliente en el sistema base. 4.4 Actualización de pares La actualización de pares se implementa de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que una transacción se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacción generan invalidaciones de objetos para cada grupo de caché que almacena páginas que contienen los objetos modificados (incluido el grupo que realiza la confirmación). Las invalidaciones se envían de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en caché los objetos modificados se deshagan de los datos obsoletos. En grupos de caché distintos al grupo de confirmación, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en caché las páginas modificadas, recopilan las confirmaciones de los clientes y, después de completar la recopilación, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacción, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envían a los clientes que almacenan en caché esas páginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmación colectiva se propaga al servidor. Una invalidación hace que una página en caché no esté disponible para la recuperación de pares, cambiando el estado de una página completa p a incompleta. Por el contrario, una actualización de una página completa conserva el estado completo de la página. Como se muestra en los estudios de la reconstrucción de fragmentos 31 [2], esta propagación de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la recuperación entre pares. Por lo tanto, el efecto de la actualización de pares es similar a la reconstrucción de fragmentos ansiosa [2]. También hemos considerado la posibilidad de permitir que un compañero recupere una página incompleta (con objetos inválidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos inválidos. 4.5 Vcache El protocolo de validación de confirmación en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo más lentos (o fallidos). Como se explica en la Sección 3.3, el protocolo de commit único permite que una transacción T pase la validación si la información adicional de coherencia proporcionada por el cliente indica que la transacción T ha leído objetos actualizados. Los clientes utilizan los números de versión de la página para proporcionar esta información adicional de coherencia. Es decir, un cliente incluye el número de versión de la página correspondiente a cada objeto en el conjunto de objetos leídos enviado en la solicitud de confirmación al servidor. Dado que a cada actualización de objeto comprometido le corresponde un número de versión de página único, el número de versión de página asociado con un objeto permite que el procedimiento de validación en el servidor verifique si la transacción del cliente ha leído objetos actualizados. El uso de versiones de página de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeños, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en caché a la versión de página identificadora (ObjectToVersion). El principal problema de implementación se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian números de versión de página con las invalidaciones. En el momento de la validación, si hay una invalidación no reconocida pendiente para un objeto x leído por una transacción T, el procedimiento de validación verifica si el número de versión de x en el conjunto de lectura de Ts coincide con el número de versión de la invalidación pendiente más alta para x, en cuyo caso el valor del objeto está actualizado, de lo contrario, T falla en la validación. Observamos nuevamente que las verificaciones basadas en el número de versión de la página y las verificaciones basadas en el reconocimiento de invalidación son complementarias en la validación de confirmación individual y ambas son necesarias. La verificación del número de versión de la página permite que la validación avance antes de que lleguen las confirmaciones de invalidación, pero por sí sola, una verificación del número de versión de la página detecta conflictos a nivel de página y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cómo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un número de versión de la página para cada página en caché. El número de versión satisface la siguiente invariante V P sobre el estado de los objetos en una página: si una página en caché P tiene un número de versión v, entonces el valor de un objeto o en la página en caché P es inválido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacción que estableció el número de versión de P en v. Los nuevos valores de objetos y los nuevos números de versión de página llegan cuando un cliente obtiene una página o cuando llega una respuesta de confirmación o invalidaciones para esta página. Los nuevos valores del objeto modifican la página y, por lo tanto, el número de versión de la página necesita ser actualizado para mantener la invariante V P. Un número de versión de página que llega cuando un cliente obtiene una página, reemplaza la Versión del Objeto x 8 Servidor de Redirección 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el número de versión de la página para esta página. Tal actualización preserva el invariante V P. De manera similar, un número de versión de página en secuencia que llega al cliente en un mensaje de confirmación o invalidación avanza el número de versión para toda la página en caché, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus números de versión de página correspondientes también pueden llegar al cliente fuera de secuencia, en cuyo caso la actualización del número de versión de la página podría violar V P. Por ejemplo, una respuesta de confirmación para una transacción que actualiza el objeto x en la página P en el servidor S1, y el objeto y en la página Q en el servidor S2, puede entregar un nuevo número de versión para P desde el coordinador de transacciones S1 antes de que llegue una invalidación generada para una transacción anterior que ha modificado el objeto r en la página P desde S1 (como se muestra en la figura 5). El protocolo de actualización de caché garantiza que el valor de cualquier objeto o en una página en caché P refleje la actualización o invalidación con el número de versión observado más alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de números de versión de página, el cliente gestiona una pequeña caché de números de versión vcache que mantiene el mapeo de un objeto a su número de versión de página correspondiente para todas las actualizaciones de números de versión reordenadas hasta que se ensamble una secuencia completa de números de versión de página. Cuando llegan los números de versión faltantes para la página y completan una secuencia, el número de versión de toda la página se avanza. El mapeo de ObjectToVersion, incluyendo los números de versión de vcache y página, se utiliza en el momento de la confirmación de la transacción para proporcionar números de versión para el conjunto de objetos leídos de la siguiente manera. Si el objeto leído tiene una entrada en la vcache, su número de versión es igual al número de versión más alto en la vcache para este objeto. Si el objeto no está presente en la vcache, su número de versión es igual al número de versión de la página en caché que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la caché del cliente, incluyendo los números de versión de las páginas y la vcache. El cliente puede limitar el tamaño de la caché virtual según sea necesario, ya que volver a cargar una página elimina todos los números de versión de página reordenados de la caché virtual. Sin embargo, esperamos que la reorganización de números de versión sea poco común y, por lo tanto, esperamos que la vcache sea muy pequeña. 5. Un grupo de clientes contiene múltiples nodos de cliente y un objeto de página de versión redi32 VCache Cliente Caché Cliente Página Caché Figura 6: Mapa de Objeto a Versión con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutación por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. Además, el fallo del redireccionador debería permitir que los clientes no afectados mantengan sus cachés intactas. Hemos diseñado un protocolo de conmutación por error para BuddyCache pero aún no lo hemos implementado. El apéndice describe el protocolo. 6. La redirección de BuddyCache en la evaluación de rendimiento respalda los beneficios de evitar la comunicación con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes. ¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la recuperación entre pares y la actualización entre pares se deben a la evitación de interacciones con el servidor. Esta sección presenta un modelo de rendimiento analítico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la caché del cliente. Estos pueden ser fallos fríos, fallos de invalidación y fallos de capacidad. Nuestro análisis se centra en los fallos por frío y los fallos por invalidación, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frío. Además, las tendencias tecnológicas indican que la capacidad de memoria y almacenamiento seguirá creciendo y, por lo tanto, es probable que una configuración típica de BuddyCache no esté limitada por la caché. Los fallos de caché del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuración de caché. Nuestro análisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validación. Para estudiar el beneficio de evitar fallos en frío, consideramos el rendimiento de la caché en frío en una carga de trabajo de solo lectura (sin fallos de invalidación). Esperamos que la recuperación entre pares mejore el costo de latencia para las solicitudes de caché fría del cliente al recuperar objetos de la caché cercana. Evaluamos cómo el costo de redirección afecta este beneficio al comparar y analizar el rendimiento de una aplicación que se ejecuta en un sistema de almacenamiento con BuddyCache y sin él (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidación, consideramos el rendimiento de la caché caliente en una carga de trabajo con modificaciones (sin fallos en frío). En las cachés calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualización entre pares permite que un cliente acceda a un objeto modificado por un compañero colaborador cercano sin el retraso impuesto por los protocolos de invalidación únicamente. En grupos donde los compañeros comparten un interés de solo lectura en los objetos modificados, la recuperación entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compañero colaborador lo tenga, lo que evita el retraso de la recuperación del servidor sin el alto costo impuesto por los protocolos de solo actualización. Las tendencias tecnológicas indican que ambos beneficios seguirán siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualización únicamente. Sin embargo, la tendencia hacia cachés cada vez más grandes, que se actualizan cuando los objetos en caché son modificados, hace que los protocolos basados en invalidación sean más atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicación que se ejecuta sin BuddyCache y una aplicación que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compañero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compañero fuera del grupo. La actualización entre pares también puede evitar fallos de invalidación debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma página de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseño del objeto, y también porque este beneficio se puede derivar dado el índice de aciertos en caché y la contención de la carga de trabajo. 6.1.1 El Modelo El modelo considera cómo el tiempo para completar una ejecución con y sin BuddyCache se ve afectado por los fallos de invalidación y los fallos en frío. Considerando k clientes ejecutándose concurrentemente accediendo de manera uniforme a un conjunto compartido de N páginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacción y realizar cálculos en una transacción, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin él (Base). Para simplificar, nuestro modelo asume que los tiempos de búsqueda y confirmación son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del número total de clientes en el sistema. El número de fallos evitados por la recuperación entre pares depende de k, el número de clientes en la BuddyCache, y del interés conjunto de los clientes en los datos compartidos. En una ejecución específica de BuddyCache, se modela mediante la variable r, definida como el número de solicitudes que llegan al redireccionador para una versión dada de la página P (es decir, hasta que un objeto en la página se invalida). Considera una ejecución con fallos en frío. Un cliente comienza con una caché fría y ejecuta una carga de trabajo de solo lectura hasta que accede a las N páginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la caché del cliente es lo suficientemente grande como para contener N páginas. En BC, los fríos fallos para la página P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consideremos a continuación una ejecución con fallos de invalidación. Un cliente comienza con una caché caliente que contiene el conjunto de trabajo de N páginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualización entre pares elimina todos los fallos de invalidación. En un grupo que contiene solo lectores (BCR), durante una ejecución en estado estable con actualizaciones uniformes, una transacción del cliente tiene fallos de invalidación faltantes. Considera la secuencia de r fallos de cliente en la página P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la página P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frío, r ≤ k porque la segunda invalidación deshabilita la redirección para P hasta que el próximo fallo en P provoque una recuperación del servidor. Suponiendo un acceso uniforme, un fallo de invalidación del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperación del servidor), y una probabilidad de (1 − 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacción única en los sistemas Base, BCR y BCW. En los experimentos descritos a continuación, medimos los parámetros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalización derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalización y beneficios medidos directamente en los experimentos. 6.2 Configuración Experimental Antes de presentar nuestros resultados, describimos nuestra configuración experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectándose directamente a los servidores. El sistema Buddy ejecuta nuestra implementación del prototipo de BuddyCache en Thor, admitiendo la recuperación de pares, la actualización de pares y la confirmación en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark está diseñado para capturar las características de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicación específica. Utilizamos OO7 porque es un punto de referencia estándar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un árbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un gráfico de partes atómicas vinculadas por objetos de conexión; cada parte atómica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atómicas por parte compuesta. La base de datos multiusuario asigna a cada cliente un módulo privado que consiste en un árbol de objetos de ensamblaje, y agrega un módulo compartido adicional que escala proporcionalmente al número de clientes. Esperamos que una configuración típica de BuddyCache no esté limitada por la caché y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la caché. Dado que el objetivo de nuestro estudio es evaluar qué tan efectivamente nuestras técnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras técnicas tienen en los fallos de caché frío y de consistencia de caché, y aislar tanto como sea posible el efecto de los fallos de capacidad de caché. Para mantener la duración de nuestros experimentos razonable, utilizamos cachés pequeños. El benchmark OO7 genera módulos de base de datos de tamaño predefinido. En nuestra implementación de OO7, el tamaño del módulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la caché, utilizamos un único módulo privado y elegimos un tamaño de caché de 40MB para cada cliente. La base de datos OO7 se genera con módulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos están agrupados en páginas de 8K, que también son la unidad de transferencia en las solicitudes de recuperación. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro análisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idéntico a T1 excepto que modifica todas las partes atómicas en un solo compuesto. Una transacción única incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo módulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacción, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de búsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una caché de 50MB (de los cuales 6MB se utilizaron para el búfer de objetos modificados), el cliente tenía una caché de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos básicos Esta sección analiza el costo básico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 Redirección Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtención del servidor), el costo adicional de la redirección incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperación o confirmación del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmación y recuperación del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de área rápida. Todos los números fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirección al cruzar el redireccionador no es muy alto, incluso en una red de área local. El costo de la confirmación aumenta con el número de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperación no aumenta tanto porque la caché del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la caché del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperación entre pares, medimos la latencia de la recuperación entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperación entre pares, el costo de la redirección incluye, además del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este último incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la página solicitada. Medimos directamente el tiempo para copiar y desenrollar la página solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperación de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador más un viaje de ida y vuelta a través de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud más un viaje de ida y vuelta a través de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando está bloqueado esperando una respuesta de búsqueda o confirmación. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podría ser mitigado por una implementación multi-hilo en un sistema con programación preemptiva. 6.3.2 Versión de Caché El commit en solitario permite que un cliente rápido que modifica un objeto haga un commit de forma independiente a un compañero lento. El mecanismo de confirmación única introduce un procesamiento adicional en el servidor durante la validación de la transacción, y un procesamiento adicional en el cliente durante la confirmación de la transacción y en el momento del procesamiento de actualización o invalidación. Los gastos generales del lado del servidor son mínimos y consisten en una actualización del número de versión de la página en el momento de la confirmación, y una comparación del número de versión en el momento de la validación de la transacción. La caché de versión tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacción accede a objetos en múltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor único y, por lo tanto, el tiempo de confirmación adicional de la gestión de la caché de versiones en el cliente no contribuye a los resultados presentados en la sección a continuación. Para medir estos costos adicionales del lado del cliente en un sistema de múltiples servidores, instrumentamos la implementación de la caché de versiones para ejecutarse con una traza de carga de trabajo que incluía invalidaciones reordenadas y cronometramos las operaciones básicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operación de búsqueda de caché de versión para cada objeto leído por la transacción en el momento de preparación de la solicitud de compromiso, y una operación de inserción de caché de versión para cada objeto actualizado por una transacción en el momento de procesamiento de la respuesta de compromiso, pero solo si la página actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmación se mantengan al mínimo, ya que el cliente está esperando de forma síncrona la finalización de la confirmación. Las mediciones muestran que en el peor de los casos, cuando llega un gran número de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en páginas reordenadas, el costo de actualizar la caché de versión es de 0.6 ms. El costo de tiempo de invalidación es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementación de la caché de versiones para reducir aún más estos costos. 6.4 Rendimiento general Esta sección examina las mejoras de rendimiento observadas por una aplicación que ejecuta el benchmark OO7 con un BuddyCache en una red de área amplia. 6.4.1 Fallos en frío Para evaluar las mejoras de rendimiento al evitar fallos en frío, comparamos el rendimiento de la caché en frío del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecución de los sistemas en el entorno de la red de área local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de área amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en caché fría. Los números fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frío solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frío solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparación con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cálculos para el cliente, solicitudes de recuperación directa, recuperaciones de pares y solicitudes de confirmación. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperación entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperación del servidor para cada cliente individual disminuye porque, con más clientes accediendo a un módulo compartido de tamaño fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperación de pares en comparación con la recuperación directa, pero este beneficio se ve contrarrestado por los tiempos de confirmación aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relación con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de caché 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT función de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias típicas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Sorprendentemente, los resultados analíticos predicen la mejora medida muy de cerca, aunque son ligeramente más altos que los valores empíricos. La razón principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidación evitados, comparamos el rendimiento de caché caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interés de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un único cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compañeros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compañeros con un grupo que contiene un único escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuración simple es suficiente para mostrar el impacto de las técnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de caché caliente de OO7. Obtenemos los números ejecutando 2000 transacciones para filtrar los fallos en frío y luego medimos el tiempo de las siguientes 1000 transacciones. Aquí nuevamente, los números reportados se derivan de los resultados del experimento de la red de área local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalización en comparación con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparación con la Base. Este beneficio se debe a la actualización entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperación entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperación local evitando el retraso de la recuperación desde el servidor. El último es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperación de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperación de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualización de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relación con Base, y Buddy Writer y Base en relación con Base) en un experimento de caché activa en función del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualización entre pares domina el gasto general en la configuración de Writer incluso en redes de baja latencia (la actualización entre pares incurre en un gasto mínimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Como en experimentos de caché fría, aquí los resultados analíticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pérdida de invalidación es mínimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de caché fría). Como en el caso de caché fría, la razón por la que el modelo analítico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÓN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en una red de área extensa debido a la alta latencia de red. Este artículo describe BuddyCache, una nueva técnica de almacenamiento en caché cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La técnica mejora el rendimiento y proporciona propiedades sólidas de corrección y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirección para obtener objetos faltantes directamente de las cachés de los miembros del grupo, y para admitir la actualización entre pares, una nueva técnica de multidifusión a nivel de aplicación ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirección puede interferir con la disponibilidad del objeto. Solo commit es una nueva técnica de validación que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validación detallada utilizando información de versión de grano grueso económica. Hemos diseñado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analíticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Las principales contribuciones del artículo son: 1. extender las técnicas de almacenamiento en caché cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementación del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluación del rendimiento basada en análisis y mediciones de los costos y beneficios de las nuevas técnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. También agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios útiles que mejoraron este artículo. 9. REFERENCIAS [1] emulab.net, la Instalación de Emulación de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. Reconstrucción de fragmentos: Proporcionando coherencia de caché global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de Computación Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre Gestión de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: Computación en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de caché híbridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. Recuperación rápida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de caché en la World Wide Web. En la 17ª Conferencia Internacional sobre Sistemas de Computación Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluación del rendimiento del sistema de gestión de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una caché de objetos jerárquica en Internet. En la Conferencia Técnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachés de Internet escalables. Informe Técnico CS-1997-18, Departamento de Ciencias de la Computación, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: Caché de proxy cooperativa en una red de área amplia. En el Tercer Taller Internacional de Caché de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. Caché web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2º Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. Caché cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilación y en tiempo de ejecución para una memoria compartida distribuida eficiente. En Actas de IEEE, Edición Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la caché: un protocolo de intercambio de caché web escalable de área amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. Implementación de Gestión Global de Memoria en un Clúster de Estaciones de Trabajo. Actas del 15º Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: Diseño, Implementación y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de caché transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, páginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. Gestión global de memoria para arquitecturas de sistemas de gestión de bases de datos cliente-servidor. En Actas del 19º Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El Búfer de Objeto Modificado: Una Técnica de Gestión de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto Tecnológico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. Gestión de documentos replicados en un sistema de comunicación grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13ª Conferencia Europea sobre Programación Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18º Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. Replicación con marca de vista: un nuevo método de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de Computación Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalación eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de Multidifusión a Nivel de Aplicación. En el 3er Simposio USENIX sobre Tecnologías y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de caché cooperativa utilizando pistas. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en Caché Global. Informe técnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del Caché de Proxies Web Cooperativos. En el 17º Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerárquica de caché en una WAN. En el Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. Compartición adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÉNDICE Este apéndice describe el protocolo de conmutación por error de BuddyCache. Para dar cabida a clientes heterogéneos, incluidos los dispositivos portátiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseño de BuddyCache asume que las cachés del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresía detecta el fallo de un cliente o un redireccionador intercambiando mensajes periódicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutación por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuración y reinicia el protocolo. El protocolo de reconfiguración del grupo es similar al presentado en [25]. Aquí describimos cómo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de páginas redireccionadas y el reenvío de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachés. En caso de un fallo del cliente, el failover elimina las páginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmación, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en caché las páginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutación por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de páginas utilizando un protocolo similar al descrito en [6]. El redireccionador recién reiniciado solicita a los miembros activos del grupo la lista de páginas que están almacenando en caché y el estado de estas páginas, es decir, si las páginas están completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperación perdida expirará en el cliente y será retransmitida. Una transacción que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma después del cambio se trata como una transacción regular; una transacción que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciará la transacción y la solicitud de confirmación será retransmitida después del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caído podrían evitar la recolección de basura de las invalidaciones pendientes en los servidores o la caché virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los números de versión únicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validación de transacciones depende del protocolo de coherencia de caché para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutación por error de BuddyCache no compromete la corrección del procedimiento de validación. Recuerda que la validación de transacciones de BuddyCache utiliza dos mecanismos complementarios, números de versión de página y confirmaciones de invalidación de los clientes, para verificar que una transacción ha leído datos actualizados. La propagación de la confirmación de invalidación (y actualización) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmación de una modificación (invalidación o actualización) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en caché el objeto o bien ha instalado el valor más reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmación de un cliente para una transacción T que lee un objeto o después de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidación no confirmada para o pendiente para este grupo, la versión del objeto leída por la transacción T está actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validación utilizando números de versión. El registro de confirmación de transacción contiene un número de versión para cada objeto leído por la transacción. El protocolo de número de versión mantiene la invariante V P que garantiza que el valor del objeto o leído por la transacción corresponda al número de versión más alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificación anterior después de haber recibido una modificación posterior. La retransmisión de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validación verifica que el número de versión en el registro de confirmación coincida con el número de versión en la invalidación pendiente no reconocida. Es fácil ver que, dado que esta comprobación es una comprobación cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutación por error aún no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "transaction": {
            "translated_key": "transacción",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a <br>transaction</br>, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide <br>transaction</br> durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "<br>transaction</br> can read and update locally cached objects without server intervention.",
                "However, before a <br>transaction</br> commits it must be validated; the server must make sure the validating <br>transaction</br> has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the <br>transaction</br> is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client <br>transaction</br> if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the <br>transaction</br> commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a <br>transaction</br>.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a <br>transaction</br> T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a <br>transaction</br> even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the <br>transaction</br> read sets in the commit message, to indicate to the server the objects read by the <br>transaction</br> are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at <br>transaction</br> that modifies objects on the page commits.",
                "Updates committed by a single <br>transaction</br> and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a <br>transaction</br> fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the <br>transaction</br> read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a <br>transaction</br>.",
                "The servers have a disk for storing persistent objects, a stable <br>transaction</br> log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its <br>transaction</br>; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the <br>transaction</br>.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the <br>transaction</br> used objects at multiple servers.",
                "If the <br>transaction</br> commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a <br>transaction</br> commit can cause caches to contain obsolete objects.",
                "Servers will abort a <br>transaction</br> that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing <br>transaction</br> to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current <br>transaction</br> if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a <br>transaction</br> aborts, its client restores the cached copies of modified objects to the state they had before the <br>transaction</br> started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a <br>transaction</br>, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a <br>transaction</br> commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the <br>transaction</br> generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a <br>transaction</br> T to pass validation if extra coherence information supplied by the client indicates that <br>transaction</br> T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client <br>transaction</br> has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a <br>transaction</br> T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the <br>transaction</br> that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a <br>transaction</br> that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the <br>transaction</br> coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at <br>transaction</br> commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a <br>transaction</br> and compute in a <br>transaction</br>, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client <br>transaction</br> has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single <br>transaction</br> in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of <br>transaction</br> workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single <br>transaction</br> includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every <br>transaction</br>, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at <br>transaction</br> validation time, and extra processing at the client at <br>transaction</br> commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at <br>transaction</br> validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a <br>transaction</br> accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the <br>transaction</br> at commit request preparation time, and a version cache insert operation for each object updated by a <br>transaction</br> at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A <br>transaction</br> running at the client during a failover and committing after the failover is treated as a regular <br>transaction</br>, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the <br>transaction</br> and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the <br>transaction</br> validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache <br>transaction</br> validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a <br>transaction</br> has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a <br>transaction</br> T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the <br>transaction</br> T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The <br>transaction</br> commit record contains a version number for each object read by the <br>transaction</br>.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the <br>transaction</br> corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "The three types of client server interactions in a transactional caching protocol are the commit of a <br>transaction</br>, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "The redirector always interacts with the servers at commit time because only storage servers provide <br>transaction</br> durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "<br>transaction</br> can read and update locally cached objects without server intervention.",
                "However, before a <br>transaction</br> commits it must be validated; the server must make sure the validating <br>transaction</br> has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the <br>transaction</br> is aborted."
            ],
            "translated_annotated_samples": [
                "Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una <br>transacción</br>, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché.",
                "El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de <br>transacciones</br> de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador.",
                "La <br>transacción</br> puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor.",
                "Sin embargo, antes de que una <br>transacción</br> se confirme, debe ser validada; el servidor debe asegurarse de que la <br>transacción</br> validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada.",
                "Si la validación falla, la <br>transacción</br> se cancela."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una <br>transacción</br>, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de <br>transacciones</br> de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La <br>transacción</br> puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una <br>transacción</br> se confirme, debe ser validada; el servidor debe asegurarse de que la <br>transacción</br> validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la <br>transacción</br> se cancela. ",
            "candidates": [],
            "error": [
                [
                    "transacción",
                    "transacciones",
                    "transacción",
                    "transacción",
                    "transacción",
                    "transacción"
                ]
            ]
        },
        "fault-tolerance properties": {
            "translated_key": "tolerancia a fallos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and <br>fault-tolerance properties</br> of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and <br>fault-tolerance properties</br> ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "BuddyCache redirector supports the correctness, availability and <br>fault-tolerance properties</br> of transactional caching protocol [19].",
                "The availability and <br>fault-tolerance properties</br> ensure that a crashed or slow client does not disrupt any other clients access to persistent objects."
            ],
            "translated_annotated_samples": [
                "El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y <br>tolerancia a fallos</br> del protocolo de almacenamiento en caché transaccional [19].",
                "Las propiedades de disponibilidad y <br>tolerancia a fallos</br> garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y <br>tolerancia a fallos</br> del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y <br>tolerancia a fallos</br> garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la transacción se cancela. Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de búsqueda de pares envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados. Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente. El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente. El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños. Un objetivo importante del diseño de BuddyCache es mantener este beneficio. Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo. Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché. Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. Almacén x 6. Actualización x 3. Comprométete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes. Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente. Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una red de área amplia serían derrochadores. Sin embargo, los protocolos de coherencia basados en invalidación pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interés para otro miembro del grupo. Con un protocolo basado en invalidación, la actualización de un miembro invalidará la copia en caché de otro miembro, lo que provocará que este último realice una recuperación de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualización e invalidación en entornos de redes de área amplia. Evita la penalización de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalización de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusión localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en caché anteriores. La actualización entre pares funciona de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que la transacción se confirma, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación, y también propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmación. 3.3 Confirmación individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminación de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en caché transaccional, ya que un cliente que es lento para reconocer una invalidación o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacción. Por ejemplo, un ingeniero que realiza una revisión repetida al mismo objeto de diseño compartido (y por lo tanto tiene la última versión del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situación representada en la figura 4 donde el Cliente1 realiza una transacción T que lee la última versión de un objeto x en la página P recientemente modificada por el Cliente1. Si la solicitud de confirmación para T llega al servidor antes de que la confirmación colectiva de Cliente2 por la última modificación de x llegue al servidor, el procedimiento de validación de OCC considera que x está obsoleto y aborta T (porque, como se explicó anteriormente, una invalidación no reconocida por un cliente actúa como indicación para el servidor de que el valor del objeto en caché está obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la corrección del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asíncronas son una parte importante de la razón por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasión de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envían y procesan de forma asíncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devolución de llamada jerárquica [32], pero la naturaleza asincrónica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrónicas. El protocolo de validación de confirmación en solitario permite a un cliente con objetos actualizados confirmar una transacción incluso si la confirmación del grupo se retrasa debido a pares lentos o caídos. El protocolo requiere que los clientes incluyan información adicional con los conjuntos de lectura de transacciones en el mensaje de confirmación, para indicar al servidor que los objetos leídos por la transacción están actualizados. Los números de versión de los objetos podrían proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionó anteriormente, mantener números de versión por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaño de directorio) en todo el sistema de objetos cuando los objetos son pequeños [23]. En cambio, solo utiliza números de versión de página de grano grueso para identificar versiones de objetos de grano fino. El número de versión de una página se incrementa en un servidor cuando una transacción que modifica objetos en la página se confirma. Las actualizaciones realizadas por una única transacción y las invalidaciones correspondientes son identificadas de manera única por el número de versión de la página modificada. Los números de versión de la página se propagan a los clientes en respuestas de recuperación, respuestas de confirmación y con invalidaciones, y los clientes incluyen los números de versión de la página en las solicitudes de confirmación enviadas a los servidores. Si una transacción falla en la validación debido a la falta de reconocimiento de grupo, el servidor verifica los números de versión de página de los objetos en el conjunto de lectura de la transacción y permite que la transacción se confirme si el cliente ha leído desde la última versión de la página. Los números de versión de la página permiten confirmaciones independientes, pero las verificaciones de versión de página solo detectan conflictos a nivel de página. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes. Potencialmente, puede ser más rápido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podría ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en caché de pares de múltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en caché web, simplemente aumentar la población de clientes en una caché proxy a menudo aumenta la tasa general de aciertos en la caché [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacción explícita entre clientes y la colaboración, lo que sugiere que es poco probable que ocurra la recuperación entre grupos. Además, las mediciones de sistemas de almacenamiento en caché web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexión de red entre los grupos de pares sea muy rápida. Estamos principalmente interesados en entornos donde compañeros que colaboran estrechamente tienen una conectividad rápida a corta distancia, pero la conexión entre grupos de compañeros puede ser lenta. Como resultado, decidimos que el soporte para la recuperación entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compañeros con recursos heterogéneos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compañeros o, cuando esté disponible, en un nodo separado dentro de la infraestructura del sitio. Además, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una caché de pares en espera para recibir páginas recuperadas por otros pares, emulando una caché central algo similar a una caché de proxy web regional. Desde el punto de vista del protocolo de coherencia de caché BuddyCache, sin embargo, un caché de compañero en espera es equivalente a un caché de compañero regular y, por lo tanto, no consideramos este caso por separado en la discusión de este documento. 4. En esta sección proporcionamos los detalles de la implementación de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en caché de estos objetos. Las aplicaciones se ejecutan en los clientes e interactúan con el sistema realizando llamadas a métodos de objetos en caché. Todas las llamadas a métodos ocurren dentro de transacciones atómicas. Los clientes se comunican con los servidores para obtener páginas o realizar una transacción. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volátil. El disco está organizado como una colección de páginas que son las unidades de acceso al disco. El registro estable guarda la información de confirmación y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de caché y una caché de objetos modificados recuperable llamada MOB. El directorio lleva un registro de qué páginas están almacenadas en caché por qué clientes. El MOB contiene objetos recientemente modificados que aún no han sido escritos de vuelta en sus páginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de caché base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la Sección 3.1. Proporcionamos algunos de los detalles relevantes de la implementación del protocolo OCC. El cliente lleva un registro de los objetos que son leídos y modificados por su transacción; envía esta información, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacción. Los servidores determinan si la confirmación es posible, utilizando un protocolo de confirmación de dos fases si la transacción utilizó objetos en múltiples servidores. Si la transacción se lleva a cabo, las nuevas copias de los objetos modificados se añaden al registro y también se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperación escaneando el registro. Dado que los objetos no están bloqueados antes de ser utilizados, una confirmación de transacción puede hacer que las cachés contengan objetos obsoletos. Los servidores abortarán una transacción que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviándoles mensajes de invalidación; un servidor utiliza su directorio y la información sobre la transacción de confirmación para determinar qué mensajes de invalidación enviar. Los mensajes de invalidación son pequeños porque simplemente identifican objetos obsoletos. Además, se envían en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidación, elimina los objetos obsoletos de su caché y aborta la transacción actual si los utilizó. El cliente sigue conservando páginas que contienen objetos invalidados; estas páginas ahora están incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidación de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener páginas incompletas en la caché del cliente significa que el falso intercambio no conduce a fallos innecesarios en la caché. Los clientes reconocen las invalidaciones para indicar la eliminación de datos obsoletos, como se explica en la Sección 3.1. Los mensajes de invalidación evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo así el desperdicio de trabajo y trasladando la detección de abortos de los servidores a los clientes. Cuando una transacción se aborta, su cliente restaura las copias en caché de los objetos modificados al estado que tenían antes de que la transacción comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacción. 4.3 Redirección El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de páginas disponibles en el grupo de pares y proporciona una redirección rápida y centralizada de recuperación (ver figura 2) entre las cachés de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan páginas u objetos al incluir esa información en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la caché de grupo, el redireccionador realiza un seguimiento del estado de las páginas. Una página en caché está completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una página están marcados como inválidos. Solo se utilizan páginas completas por el proceso de recuperación de pares. El protocolo para mantener el estado de la página cuando las páginas son actualizadas e invalidadas se describe en la Sección 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una página solicitada completa no está disponible en el grupo de pares o si un par necesita confirmar una transacción, el redireccionador actúa como un proxy de servidor: reenvía la solicitud al servidor y luego reenvía la respuesta de vuelta al cliente. Además, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualización o información de invalidación a los clientes que tienen en caché la página modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la caché de grupo de pares combinada está desempeñando el papel de una única caché de cliente en el sistema base. 4.4 Actualización de pares La actualización de pares se implementa de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que una transacción se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacción generan invalidaciones de objetos para cada grupo de caché que almacena páginas que contienen los objetos modificados (incluido el grupo que realiza la confirmación). Las invalidaciones se envían de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en caché los objetos modificados se deshagan de los datos obsoletos. En grupos de caché distintos al grupo de confirmación, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en caché las páginas modificadas, recopilan las confirmaciones de los clientes y, después de completar la recopilación, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacción, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envían a los clientes que almacenan en caché esas páginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmación colectiva se propaga al servidor. Una invalidación hace que una página en caché no esté disponible para la recuperación de pares, cambiando el estado de una página completa p a incompleta. Por el contrario, una actualización de una página completa conserva el estado completo de la página. Como se muestra en los estudios de la reconstrucción de fragmentos 31 [2], esta propagación de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la recuperación entre pares. Por lo tanto, el efecto de la actualización de pares es similar a la reconstrucción de fragmentos ansiosa [2]. También hemos considerado la posibilidad de permitir que un compañero recupere una página incompleta (con objetos inválidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos inválidos. 4.5 Vcache El protocolo de validación de confirmación en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo más lentos (o fallidos). Como se explica en la Sección 3.3, el protocolo de commit único permite que una transacción T pase la validación si la información adicional de coherencia proporcionada por el cliente indica que la transacción T ha leído objetos actualizados. Los clientes utilizan los números de versión de la página para proporcionar esta información adicional de coherencia. Es decir, un cliente incluye el número de versión de la página correspondiente a cada objeto en el conjunto de objetos leídos enviado en la solicitud de confirmación al servidor. Dado que a cada actualización de objeto comprometido le corresponde un número de versión de página único, el número de versión de página asociado con un objeto permite que el procedimiento de validación en el servidor verifique si la transacción del cliente ha leído objetos actualizados. El uso de versiones de página de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeños, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en caché a la versión de página identificadora (ObjectToVersion). El principal problema de implementación se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian números de versión de página con las invalidaciones. En el momento de la validación, si hay una invalidación no reconocida pendiente para un objeto x leído por una transacción T, el procedimiento de validación verifica si el número de versión de x en el conjunto de lectura de Ts coincide con el número de versión de la invalidación pendiente más alta para x, en cuyo caso el valor del objeto está actualizado, de lo contrario, T falla en la validación. Observamos nuevamente que las verificaciones basadas en el número de versión de la página y las verificaciones basadas en el reconocimiento de invalidación son complementarias en la validación de confirmación individual y ambas son necesarias. La verificación del número de versión de la página permite que la validación avance antes de que lleguen las confirmaciones de invalidación, pero por sí sola, una verificación del número de versión de la página detecta conflictos a nivel de página y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cómo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un número de versión de la página para cada página en caché. El número de versión satisface la siguiente invariante V P sobre el estado de los objetos en una página: si una página en caché P tiene un número de versión v, entonces el valor de un objeto o en la página en caché P es inválido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacción que estableció el número de versión de P en v. Los nuevos valores de objetos y los nuevos números de versión de página llegan cuando un cliente obtiene una página o cuando llega una respuesta de confirmación o invalidaciones para esta página. Los nuevos valores del objeto modifican la página y, por lo tanto, el número de versión de la página necesita ser actualizado para mantener la invariante V P. Un número de versión de página que llega cuando un cliente obtiene una página, reemplaza la Versión del Objeto x 8 Servidor de Redirección 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el número de versión de la página para esta página. Tal actualización preserva el invariante V P. De manera similar, un número de versión de página en secuencia que llega al cliente en un mensaje de confirmación o invalidación avanza el número de versión para toda la página en caché, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus números de versión de página correspondientes también pueden llegar al cliente fuera de secuencia, en cuyo caso la actualización del número de versión de la página podría violar V P. Por ejemplo, una respuesta de confirmación para una transacción que actualiza el objeto x en la página P en el servidor S1, y el objeto y en la página Q en el servidor S2, puede entregar un nuevo número de versión para P desde el coordinador de transacciones S1 antes de que llegue una invalidación generada para una transacción anterior que ha modificado el objeto r en la página P desde S1 (como se muestra en la figura 5). El protocolo de actualización de caché garantiza que el valor de cualquier objeto o en una página en caché P refleje la actualización o invalidación con el número de versión observado más alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de números de versión de página, el cliente gestiona una pequeña caché de números de versión vcache que mantiene el mapeo de un objeto a su número de versión de página correspondiente para todas las actualizaciones de números de versión reordenadas hasta que se ensamble una secuencia completa de números de versión de página. Cuando llegan los números de versión faltantes para la página y completan una secuencia, el número de versión de toda la página se avanza. El mapeo de ObjectToVersion, incluyendo los números de versión de vcache y página, se utiliza en el momento de la confirmación de la transacción para proporcionar números de versión para el conjunto de objetos leídos de la siguiente manera. Si el objeto leído tiene una entrada en la vcache, su número de versión es igual al número de versión más alto en la vcache para este objeto. Si el objeto no está presente en la vcache, su número de versión es igual al número de versión de la página en caché que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la caché del cliente, incluyendo los números de versión de las páginas y la vcache. El cliente puede limitar el tamaño de la caché virtual según sea necesario, ya que volver a cargar una página elimina todos los números de versión de página reordenados de la caché virtual. Sin embargo, esperamos que la reorganización de números de versión sea poco común y, por lo tanto, esperamos que la vcache sea muy pequeña. 5. Un grupo de clientes contiene múltiples nodos de cliente y un objeto de página de versión redi32 VCache Cliente Caché Cliente Página Caché Figura 6: Mapa de Objeto a Versión con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutación por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. Además, el fallo del redireccionador debería permitir que los clientes no afectados mantengan sus cachés intactas. Hemos diseñado un protocolo de conmutación por error para BuddyCache pero aún no lo hemos implementado. El apéndice describe el protocolo. 6. La redirección de BuddyCache en la evaluación de rendimiento respalda los beneficios de evitar la comunicación con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes. ¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la recuperación entre pares y la actualización entre pares se deben a la evitación de interacciones con el servidor. Esta sección presenta un modelo de rendimiento analítico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la caché del cliente. Estos pueden ser fallos fríos, fallos de invalidación y fallos de capacidad. Nuestro análisis se centra en los fallos por frío y los fallos por invalidación, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frío. Además, las tendencias tecnológicas indican que la capacidad de memoria y almacenamiento seguirá creciendo y, por lo tanto, es probable que una configuración típica de BuddyCache no esté limitada por la caché. Los fallos de caché del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuración de caché. Nuestro análisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validación. Para estudiar el beneficio de evitar fallos en frío, consideramos el rendimiento de la caché en frío en una carga de trabajo de solo lectura (sin fallos de invalidación). Esperamos que la recuperación entre pares mejore el costo de latencia para las solicitudes de caché fría del cliente al recuperar objetos de la caché cercana. Evaluamos cómo el costo de redirección afecta este beneficio al comparar y analizar el rendimiento de una aplicación que se ejecuta en un sistema de almacenamiento con BuddyCache y sin él (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidación, consideramos el rendimiento de la caché caliente en una carga de trabajo con modificaciones (sin fallos en frío). En las cachés calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualización entre pares permite que un cliente acceda a un objeto modificado por un compañero colaborador cercano sin el retraso impuesto por los protocolos de invalidación únicamente. En grupos donde los compañeros comparten un interés de solo lectura en los objetos modificados, la recuperación entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compañero colaborador lo tenga, lo que evita el retraso de la recuperación del servidor sin el alto costo impuesto por los protocolos de solo actualización. Las tendencias tecnológicas indican que ambos beneficios seguirán siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualización únicamente. Sin embargo, la tendencia hacia cachés cada vez más grandes, que se actualizan cuando los objetos en caché son modificados, hace que los protocolos basados en invalidación sean más atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicación que se ejecuta sin BuddyCache y una aplicación que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compañero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compañero fuera del grupo. La actualización entre pares también puede evitar fallos de invalidación debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma página de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseño del objeto, y también porque este beneficio se puede derivar dado el índice de aciertos en caché y la contención de la carga de trabajo. 6.1.1 El Modelo El modelo considera cómo el tiempo para completar una ejecución con y sin BuddyCache se ve afectado por los fallos de invalidación y los fallos en frío. Considerando k clientes ejecutándose concurrentemente accediendo de manera uniforme a un conjunto compartido de N páginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacción y realizar cálculos en una transacción, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin él (Base). Para simplificar, nuestro modelo asume que los tiempos de búsqueda y confirmación son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del número total de clientes en el sistema. El número de fallos evitados por la recuperación entre pares depende de k, el número de clientes en la BuddyCache, y del interés conjunto de los clientes en los datos compartidos. En una ejecución específica de BuddyCache, se modela mediante la variable r, definida como el número de solicitudes que llegan al redireccionador para una versión dada de la página P (es decir, hasta que un objeto en la página se invalida). Considera una ejecución con fallos en frío. Un cliente comienza con una caché fría y ejecuta una carga de trabajo de solo lectura hasta que accede a las N páginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la caché del cliente es lo suficientemente grande como para contener N páginas. En BC, los fríos fallos para la página P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consideremos a continuación una ejecución con fallos de invalidación. Un cliente comienza con una caché caliente que contiene el conjunto de trabajo de N páginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualización entre pares elimina todos los fallos de invalidación. En un grupo que contiene solo lectores (BCR), durante una ejecución en estado estable con actualizaciones uniformes, una transacción del cliente tiene fallos de invalidación faltantes. Considera la secuencia de r fallos de cliente en la página P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la página P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frío, r ≤ k porque la segunda invalidación deshabilita la redirección para P hasta que el próximo fallo en P provoque una recuperación del servidor. Suponiendo un acceso uniforme, un fallo de invalidación del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperación del servidor), y una probabilidad de (1 − 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacción única en los sistemas Base, BCR y BCW. En los experimentos descritos a continuación, medimos los parámetros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalización derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalización y beneficios medidos directamente en los experimentos. 6.2 Configuración Experimental Antes de presentar nuestros resultados, describimos nuestra configuración experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectándose directamente a los servidores. El sistema Buddy ejecuta nuestra implementación del prototipo de BuddyCache en Thor, admitiendo la recuperación de pares, la actualización de pares y la confirmación en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark está diseñado para capturar las características de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicación específica. Utilizamos OO7 porque es un punto de referencia estándar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un árbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un gráfico de partes atómicas vinculadas por objetos de conexión; cada parte atómica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atómicas por parte compuesta. La base de datos multiusuario asigna a cada cliente un módulo privado que consiste en un árbol de objetos de ensamblaje, y agrega un módulo compartido adicional que escala proporcionalmente al número de clientes. Esperamos que una configuración típica de BuddyCache no esté limitada por la caché y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la caché. Dado que el objetivo de nuestro estudio es evaluar qué tan efectivamente nuestras técnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras técnicas tienen en los fallos de caché frío y de consistencia de caché, y aislar tanto como sea posible el efecto de los fallos de capacidad de caché. Para mantener la duración de nuestros experimentos razonable, utilizamos cachés pequeños. El benchmark OO7 genera módulos de base de datos de tamaño predefinido. En nuestra implementación de OO7, el tamaño del módulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la caché, utilizamos un único módulo privado y elegimos un tamaño de caché de 40MB para cada cliente. La base de datos OO7 se genera con módulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos están agrupados en páginas de 8K, que también son la unidad de transferencia en las solicitudes de recuperación. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro análisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idéntico a T1 excepto que modifica todas las partes atómicas en un solo compuesto. Una transacción única incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo módulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacción, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de búsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una caché de 50MB (de los cuales 6MB se utilizaron para el búfer de objetos modificados), el cliente tenía una caché de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos básicos Esta sección analiza el costo básico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 Redirección Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtención del servidor), el costo adicional de la redirección incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperación o confirmación del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmación y recuperación del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de área rápida. Todos los números fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirección al cruzar el redireccionador no es muy alto, incluso en una red de área local. El costo de la confirmación aumenta con el número de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperación no aumenta tanto porque la caché del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la caché del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperación entre pares, medimos la latencia de la recuperación entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperación entre pares, el costo de la redirección incluye, además del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este último incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la página solicitada. Medimos directamente el tiempo para copiar y desenrollar la página solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperación de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador más un viaje de ida y vuelta a través de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud más un viaje de ida y vuelta a través de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando está bloqueado esperando una respuesta de búsqueda o confirmación. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podría ser mitigado por una implementación multi-hilo en un sistema con programación preemptiva. 6.3.2 Versión de Caché El commit en solitario permite que un cliente rápido que modifica un objeto haga un commit de forma independiente a un compañero lento. El mecanismo de confirmación única introduce un procesamiento adicional en el servidor durante la validación de la transacción, y un procesamiento adicional en el cliente durante la confirmación de la transacción y en el momento del procesamiento de actualización o invalidación. Los gastos generales del lado del servidor son mínimos y consisten en una actualización del número de versión de la página en el momento de la confirmación, y una comparación del número de versión en el momento de la validación de la transacción. La caché de versión tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacción accede a objetos en múltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor único y, por lo tanto, el tiempo de confirmación adicional de la gestión de la caché de versiones en el cliente no contribuye a los resultados presentados en la sección a continuación. Para medir estos costos adicionales del lado del cliente en un sistema de múltiples servidores, instrumentamos la implementación de la caché de versiones para ejecutarse con una traza de carga de trabajo que incluía invalidaciones reordenadas y cronometramos las operaciones básicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operación de búsqueda de caché de versión para cada objeto leído por la transacción en el momento de preparación de la solicitud de compromiso, y una operación de inserción de caché de versión para cada objeto actualizado por una transacción en el momento de procesamiento de la respuesta de compromiso, pero solo si la página actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmación se mantengan al mínimo, ya que el cliente está esperando de forma síncrona la finalización de la confirmación. Las mediciones muestran que en el peor de los casos, cuando llega un gran número de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en páginas reordenadas, el costo de actualizar la caché de versión es de 0.6 ms. El costo de tiempo de invalidación es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementación de la caché de versiones para reducir aún más estos costos. 6.4 Rendimiento general Esta sección examina las mejoras de rendimiento observadas por una aplicación que ejecuta el benchmark OO7 con un BuddyCache en una red de área amplia. 6.4.1 Fallos en frío Para evaluar las mejoras de rendimiento al evitar fallos en frío, comparamos el rendimiento de la caché en frío del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecución de los sistemas en el entorno de la red de área local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de área amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en caché fría. Los números fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frío solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frío solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparación con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cálculos para el cliente, solicitudes de recuperación directa, recuperaciones de pares y solicitudes de confirmación. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperación entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperación del servidor para cada cliente individual disminuye porque, con más clientes accediendo a un módulo compartido de tamaño fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperación de pares en comparación con la recuperación directa, pero este beneficio se ve contrarrestado por los tiempos de confirmación aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relación con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de caché 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT función de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias típicas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Sorprendentemente, los resultados analíticos predicen la mejora medida muy de cerca, aunque son ligeramente más altos que los valores empíricos. La razón principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidación evitados, comparamos el rendimiento de caché caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interés de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un único cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compañeros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compañeros con un grupo que contiene un único escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuración simple es suficiente para mostrar el impacto de las técnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de caché caliente de OO7. Obtenemos los números ejecutando 2000 transacciones para filtrar los fallos en frío y luego medimos el tiempo de las siguientes 1000 transacciones. Aquí nuevamente, los números reportados se derivan de los resultados del experimento de la red de área local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalización en comparación con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparación con la Base. Este beneficio se debe a la actualización entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperación entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperación local evitando el retraso de la recuperación desde el servidor. El último es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperación de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperación de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualización de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relación con Base, y Buddy Writer y Base en relación con Base) en un experimento de caché activa en función del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualización entre pares domina el gasto general en la configuración de Writer incluso en redes de baja latencia (la actualización entre pares incurre en un gasto mínimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Como en experimentos de caché fría, aquí los resultados analíticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pérdida de invalidación es mínimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de caché fría). Como en el caso de caché fría, la razón por la que el modelo analítico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÓN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en una red de área extensa debido a la alta latencia de red. Este artículo describe BuddyCache, una nueva técnica de almacenamiento en caché cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La técnica mejora el rendimiento y proporciona propiedades sólidas de corrección y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirección para obtener objetos faltantes directamente de las cachés de los miembros del grupo, y para admitir la actualización entre pares, una nueva técnica de multidifusión a nivel de aplicación ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirección puede interferir con la disponibilidad del objeto. Solo commit es una nueva técnica de validación que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validación detallada utilizando información de versión de grano grueso económica. Hemos diseñado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analíticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Las principales contribuciones del artículo son: 1. extender las técnicas de almacenamiento en caché cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementación del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluación del rendimiento basada en análisis y mediciones de los costos y beneficios de las nuevas técnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. También agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios útiles que mejoraron este artículo. 9. REFERENCIAS [1] emulab.net, la Instalación de Emulación de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. Reconstrucción de fragmentos: Proporcionando coherencia de caché global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de Computación Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre Gestión de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: Computación en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de caché híbridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. Recuperación rápida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de caché en la World Wide Web. En la 17ª Conferencia Internacional sobre Sistemas de Computación Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluación del rendimiento del sistema de gestión de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una caché de objetos jerárquica en Internet. En la Conferencia Técnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachés de Internet escalables. Informe Técnico CS-1997-18, Departamento de Ciencias de la Computación, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: Caché de proxy cooperativa en una red de área amplia. En el Tercer Taller Internacional de Caché de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. Caché web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2º Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. Caché cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilación y en tiempo de ejecución para una memoria compartida distribuida eficiente. En Actas de IEEE, Edición Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la caché: un protocolo de intercambio de caché web escalable de área amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. Implementación de Gestión Global de Memoria en un Clúster de Estaciones de Trabajo. Actas del 15º Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: Diseño, Implementación y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de caché transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, páginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. Gestión global de memoria para arquitecturas de sistemas de gestión de bases de datos cliente-servidor. En Actas del 19º Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El Búfer de Objeto Modificado: Una Técnica de Gestión de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto Tecnológico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. Gestión de documentos replicados en un sistema de comunicación grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13ª Conferencia Europea sobre Programación Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18º Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. Replicación con marca de vista: un nuevo método de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de Computación Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalación eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de Multidifusión a Nivel de Aplicación. En el 3er Simposio USENIX sobre Tecnologías y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de caché cooperativa utilizando pistas. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en Caché Global. Informe técnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del Caché de Proxies Web Cooperativos. En el 17º Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerárquica de caché en una WAN. En el Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. Compartición adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÉNDICE Este apéndice describe el protocolo de conmutación por error de BuddyCache. Para dar cabida a clientes heterogéneos, incluidos los dispositivos portátiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseño de BuddyCache asume que las cachés del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresía detecta el fallo de un cliente o un redireccionador intercambiando mensajes periódicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutación por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuración y reinicia el protocolo. El protocolo de reconfiguración del grupo es similar al presentado en [25]. Aquí describimos cómo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de páginas redireccionadas y el reenvío de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachés. En caso de un fallo del cliente, el failover elimina las páginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmación, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en caché las páginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutación por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de páginas utilizando un protocolo similar al descrito en [6]. El redireccionador recién reiniciado solicita a los miembros activos del grupo la lista de páginas que están almacenando en caché y el estado de estas páginas, es decir, si las páginas están completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperación perdida expirará en el cliente y será retransmitida. Una transacción que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma después del cambio se trata como una transacción regular; una transacción que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciará la transacción y la solicitud de confirmación será retransmitida después del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caído podrían evitar la recolección de basura de las invalidaciones pendientes en los servidores o la caché virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los números de versión únicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validación de transacciones depende del protocolo de coherencia de caché para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutación por error de BuddyCache no compromete la corrección del procedimiento de validación. Recuerda que la validación de transacciones de BuddyCache utiliza dos mecanismos complementarios, números de versión de página y confirmaciones de invalidación de los clientes, para verificar que una transacción ha leído datos actualizados. La propagación de la confirmación de invalidación (y actualización) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmación de una modificación (invalidación o actualización) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en caché el objeto o bien ha instalado el valor más reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmación de un cliente para una transacción T que lee un objeto o después de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidación no confirmada para o pendiente para este grupo, la versión del objeto leída por la transacción T está actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validación utilizando números de versión. El registro de confirmación de transacción contiene un número de versión para cada objeto leído por la transacción. El protocolo de número de versión mantiene la invariante V P que garantiza que el valor del objeto o leído por la transacción corresponda al número de versión más alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificación anterior después de haber recibido una modificación posterior. La retransmisión de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validación verifica que el número de versión en el registro de confirmación coincida con el número de versión en la invalidación pendiente no reconocida. Es fácil ver que, dado que esta comprobación es una comprobación cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutación por error aún no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "buddycache": {
            "translated_key": "BuddyCache",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>buddycache</br>: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "<br>buddycache</br> is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a <br>buddycache</br> prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the <br>buddycache</br> prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using <br>buddycache</br> can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "<br>buddycache</br> is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With <br>buddycache</br>, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "<br>buddycache</br> presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "<br>buddycache</br> uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "<br>buddycache</br> redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "<br>buddycache</br> uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by <br>buddycache</br> to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a <br>buddycache</br> prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without <br>buddycache</br> and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies <br>buddycache</br> provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the <br>buddycache</br> can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to <br>buddycache</br>.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, <br>buddycache</br> uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "<br>buddycache</br> provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "<br>buddycache</br> High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the <br>buddycache</br> approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "<br>buddycache</br> architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "<br>buddycache</br> redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "<br>buddycache</br> avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: <br>buddycache</br>. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall <br>buddycache</br> architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The <br>buddycache</br> approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate <br>buddycache</br> in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating <br>buddycache</br> with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important <br>buddycache</br> design goal is to maintain this benefit.",
                "Since in <br>buddycache</br> a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in <br>buddycache</br> is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "<br>buddycache</br> circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in <br>buddycache</br> redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the <br>buddycache</br> propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The <br>buddycache</br> architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending <br>buddycache</br> protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In <br>buddycache</br> applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in <br>buddycache</br> is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the <br>buddycache</br> redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the <br>buddycache</br> cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the <br>buddycache</br> implementation.",
                "We have implemented <br>buddycache</br> in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate <br>buddycache</br> performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "<br>buddycache</br> FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the <br>buddycache</br> in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for <br>buddycache</br> but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION <br>buddycache</br> redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a <br>buddycache</br> prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical <br>buddycache</br> configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with <br>buddycache</br> and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect <br>buddycache</br> to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without <br>buddycache</br> with an application running <br>buddycache</br> in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without <br>buddycache</br> is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in <br>buddycache</br> (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with <br>buddycache</br> (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the <br>buddycache</br>, and on the client co-interest in the shared data.",
                "In a specific <br>buddycache</br> execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of <br>buddycache</br> prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical <br>buddycache</br> configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the <br>buddycache</br> cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the <br>buddycache</br> architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a <br>buddycache</br> in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into <br>buddycache</br>, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The <br>buddycache</br> provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by <br>buddycache</br> (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates <br>buddycache</br> benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by <br>buddycache</br> due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the <br>buddycache</br> group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of <br>buddycache</br> techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the <br>buddycache</br> reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by <br>buddycache</br> in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described <br>buddycache</br>, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "<br>buddycache</br> uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented <br>buddycache</br> prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies <br>buddycache</br> provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the <br>buddycache</br> can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the <br>buddycache</br> failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the <br>buddycache</br> peer group.",
                "The <br>buddycache</br> design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the <br>buddycache</br> data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the <br>buddycache</br> state.",
                "To restart the <br>buddycache</br> protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that <br>buddycache</br> failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that <br>buddycache</br> transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "<br>buddycache</br>: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "<br>buddycache</br> is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "We have implemented a <br>buddycache</br> prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the <br>buddycache</br> prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using <br>buddycache</br> can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "<br>buddycache</br> is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment."
            ],
            "translated_annotated_samples": [
                "BuddyCache: <br>Almacenamiento de objetos de alto rendimiento</br> para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común.",
                "<br>BuddyCache</br> es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia.",
                "Hemos implementado un prototipo de <br>BuddyCache</br> y evaluado su rendimiento.",
                "Los resultados analíticos, confirmados por las mediciones del prototipo de <br>BuddyCache</br> utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan <br>BuddyCache</br> pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos.",
                "BuddyCache es una nueva técnica de <br>almacenamiento en caché de objetos</br> que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia."
            ],
            "translated_text": "BuddyCache: <br>Almacenamiento de objetos de alto rendimiento</br> para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. <br>BuddyCache</br> es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de <br>BuddyCache</br> y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de <br>BuddyCache</br> utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan <br>BuddyCache</br> pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de <br>almacenamiento en caché de objetos</br> que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. ",
            "candidates": [],
            "error": [
                [
                    "Almacenamiento de objetos de alto rendimiento",
                    "BuddyCache",
                    "BuddyCache",
                    "BuddyCache",
                    "BuddyCache",
                    "almacenamiento en caché de objetos"
                ]
            ]
        },
        "dominant performance cost": {
            "translated_key": "costo de rendimiento dominante",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the <br>dominant performance cost</br>. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the <br>dominant performance cost</br>, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the <br>dominant performance cost</br>. 7.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the <br>dominant performance cost</br>, high network latency. 8."
            ],
            "translated_annotated_samples": [
                "Como en el caso de caché fría, la razón por la que el modelo analítico simplificado funciona bien es porque captura los costos de la latencia de red, el <br>costo de rendimiento dominante</br>. 7.",
                "Las principales contribuciones del artículo son: 1. extender las técnicas de almacenamiento en caché cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementación del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluación del rendimiento basada en análisis y mediciones de los costos y beneficios de las nuevas técnicas que capturan el <br>costo de rendimiento dominante</br>, la alta latencia de red."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la transacción se cancela. Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de búsqueda de pares envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados. Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente. El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente. El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños. Un objetivo importante del diseño de BuddyCache es mantener este beneficio. Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo. Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché. Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. Almacén x 6. Actualización x 3. Comprométete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes. Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente. Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una red de área amplia serían derrochadores. Sin embargo, los protocolos de coherencia basados en invalidación pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interés para otro miembro del grupo. Con un protocolo basado en invalidación, la actualización de un miembro invalidará la copia en caché de otro miembro, lo que provocará que este último realice una recuperación de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualización e invalidación en entornos de redes de área amplia. Evita la penalización de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalización de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusión localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en caché anteriores. La actualización entre pares funciona de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que la transacción se confirma, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación, y también propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmación. 3.3 Confirmación individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminación de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en caché transaccional, ya que un cliente que es lento para reconocer una invalidación o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacción. Por ejemplo, un ingeniero que realiza una revisión repetida al mismo objeto de diseño compartido (y por lo tanto tiene la última versión del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situación representada en la figura 4 donde el Cliente1 realiza una transacción T que lee la última versión de un objeto x en la página P recientemente modificada por el Cliente1. Si la solicitud de confirmación para T llega al servidor antes de que la confirmación colectiva de Cliente2 por la última modificación de x llegue al servidor, el procedimiento de validación de OCC considera que x está obsoleto y aborta T (porque, como se explicó anteriormente, una invalidación no reconocida por un cliente actúa como indicación para el servidor de que el valor del objeto en caché está obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la corrección del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asíncronas son una parte importante de la razón por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasión de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envían y procesan de forma asíncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devolución de llamada jerárquica [32], pero la naturaleza asincrónica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrónicas. El protocolo de validación de confirmación en solitario permite a un cliente con objetos actualizados confirmar una transacción incluso si la confirmación del grupo se retrasa debido a pares lentos o caídos. El protocolo requiere que los clientes incluyan información adicional con los conjuntos de lectura de transacciones en el mensaje de confirmación, para indicar al servidor que los objetos leídos por la transacción están actualizados. Los números de versión de los objetos podrían proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionó anteriormente, mantener números de versión por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaño de directorio) en todo el sistema de objetos cuando los objetos son pequeños [23]. En cambio, solo utiliza números de versión de página de grano grueso para identificar versiones de objetos de grano fino. El número de versión de una página se incrementa en un servidor cuando una transacción que modifica objetos en la página se confirma. Las actualizaciones realizadas por una única transacción y las invalidaciones correspondientes son identificadas de manera única por el número de versión de la página modificada. Los números de versión de la página se propagan a los clientes en respuestas de recuperación, respuestas de confirmación y con invalidaciones, y los clientes incluyen los números de versión de la página en las solicitudes de confirmación enviadas a los servidores. Si una transacción falla en la validación debido a la falta de reconocimiento de grupo, el servidor verifica los números de versión de página de los objetos en el conjunto de lectura de la transacción y permite que la transacción se confirme si el cliente ha leído desde la última versión de la página. Los números de versión de la página permiten confirmaciones independientes, pero las verificaciones de versión de página solo detectan conflictos a nivel de página. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes. Potencialmente, puede ser más rápido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podría ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en caché de pares de múltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en caché web, simplemente aumentar la población de clientes en una caché proxy a menudo aumenta la tasa general de aciertos en la caché [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacción explícita entre clientes y la colaboración, lo que sugiere que es poco probable que ocurra la recuperación entre grupos. Además, las mediciones de sistemas de almacenamiento en caché web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexión de red entre los grupos de pares sea muy rápida. Estamos principalmente interesados en entornos donde compañeros que colaboran estrechamente tienen una conectividad rápida a corta distancia, pero la conexión entre grupos de compañeros puede ser lenta. Como resultado, decidimos que el soporte para la recuperación entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compañeros con recursos heterogéneos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compañeros o, cuando esté disponible, en un nodo separado dentro de la infraestructura del sitio. Además, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una caché de pares en espera para recibir páginas recuperadas por otros pares, emulando una caché central algo similar a una caché de proxy web regional. Desde el punto de vista del protocolo de coherencia de caché BuddyCache, sin embargo, un caché de compañero en espera es equivalente a un caché de compañero regular y, por lo tanto, no consideramos este caso por separado en la discusión de este documento. 4. En esta sección proporcionamos los detalles de la implementación de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en caché de estos objetos. Las aplicaciones se ejecutan en los clientes e interactúan con el sistema realizando llamadas a métodos de objetos en caché. Todas las llamadas a métodos ocurren dentro de transacciones atómicas. Los clientes se comunican con los servidores para obtener páginas o realizar una transacción. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volátil. El disco está organizado como una colección de páginas que son las unidades de acceso al disco. El registro estable guarda la información de confirmación y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de caché y una caché de objetos modificados recuperable llamada MOB. El directorio lleva un registro de qué páginas están almacenadas en caché por qué clientes. El MOB contiene objetos recientemente modificados que aún no han sido escritos de vuelta en sus páginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de caché base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la Sección 3.1. Proporcionamos algunos de los detalles relevantes de la implementación del protocolo OCC. El cliente lleva un registro de los objetos que son leídos y modificados por su transacción; envía esta información, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacción. Los servidores determinan si la confirmación es posible, utilizando un protocolo de confirmación de dos fases si la transacción utilizó objetos en múltiples servidores. Si la transacción se lleva a cabo, las nuevas copias de los objetos modificados se añaden al registro y también se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperación escaneando el registro. Dado que los objetos no están bloqueados antes de ser utilizados, una confirmación de transacción puede hacer que las cachés contengan objetos obsoletos. Los servidores abortarán una transacción que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviándoles mensajes de invalidación; un servidor utiliza su directorio y la información sobre la transacción de confirmación para determinar qué mensajes de invalidación enviar. Los mensajes de invalidación son pequeños porque simplemente identifican objetos obsoletos. Además, se envían en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidación, elimina los objetos obsoletos de su caché y aborta la transacción actual si los utilizó. El cliente sigue conservando páginas que contienen objetos invalidados; estas páginas ahora están incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidación de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener páginas incompletas en la caché del cliente significa que el falso intercambio no conduce a fallos innecesarios en la caché. Los clientes reconocen las invalidaciones para indicar la eliminación de datos obsoletos, como se explica en la Sección 3.1. Los mensajes de invalidación evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo así el desperdicio de trabajo y trasladando la detección de abortos de los servidores a los clientes. Cuando una transacción se aborta, su cliente restaura las copias en caché de los objetos modificados al estado que tenían antes de que la transacción comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacción. 4.3 Redirección El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de páginas disponibles en el grupo de pares y proporciona una redirección rápida y centralizada de recuperación (ver figura 2) entre las cachés de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan páginas u objetos al incluir esa información en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la caché de grupo, el redireccionador realiza un seguimiento del estado de las páginas. Una página en caché está completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una página están marcados como inválidos. Solo se utilizan páginas completas por el proceso de recuperación de pares. El protocolo para mantener el estado de la página cuando las páginas son actualizadas e invalidadas se describe en la Sección 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una página solicitada completa no está disponible en el grupo de pares o si un par necesita confirmar una transacción, el redireccionador actúa como un proxy de servidor: reenvía la solicitud al servidor y luego reenvía la respuesta de vuelta al cliente. Además, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualización o información de invalidación a los clientes que tienen en caché la página modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la caché de grupo de pares combinada está desempeñando el papel de una única caché de cliente en el sistema base. 4.4 Actualización de pares La actualización de pares se implementa de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que una transacción se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacción generan invalidaciones de objetos para cada grupo de caché que almacena páginas que contienen los objetos modificados (incluido el grupo que realiza la confirmación). Las invalidaciones se envían de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en caché los objetos modificados se deshagan de los datos obsoletos. En grupos de caché distintos al grupo de confirmación, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en caché las páginas modificadas, recopilan las confirmaciones de los clientes y, después de completar la recopilación, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacción, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envían a los clientes que almacenan en caché esas páginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmación colectiva se propaga al servidor. Una invalidación hace que una página en caché no esté disponible para la recuperación de pares, cambiando el estado de una página completa p a incompleta. Por el contrario, una actualización de una página completa conserva el estado completo de la página. Como se muestra en los estudios de la reconstrucción de fragmentos 31 [2], esta propagación de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la recuperación entre pares. Por lo tanto, el efecto de la actualización de pares es similar a la reconstrucción de fragmentos ansiosa [2]. También hemos considerado la posibilidad de permitir que un compañero recupere una página incompleta (con objetos inválidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos inválidos. 4.5 Vcache El protocolo de validación de confirmación en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo más lentos (o fallidos). Como se explica en la Sección 3.3, el protocolo de commit único permite que una transacción T pase la validación si la información adicional de coherencia proporcionada por el cliente indica que la transacción T ha leído objetos actualizados. Los clientes utilizan los números de versión de la página para proporcionar esta información adicional de coherencia. Es decir, un cliente incluye el número de versión de la página correspondiente a cada objeto en el conjunto de objetos leídos enviado en la solicitud de confirmación al servidor. Dado que a cada actualización de objeto comprometido le corresponde un número de versión de página único, el número de versión de página asociado con un objeto permite que el procedimiento de validación en el servidor verifique si la transacción del cliente ha leído objetos actualizados. El uso de versiones de página de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeños, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en caché a la versión de página identificadora (ObjectToVersion). El principal problema de implementación se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian números de versión de página con las invalidaciones. En el momento de la validación, si hay una invalidación no reconocida pendiente para un objeto x leído por una transacción T, el procedimiento de validación verifica si el número de versión de x en el conjunto de lectura de Ts coincide con el número de versión de la invalidación pendiente más alta para x, en cuyo caso el valor del objeto está actualizado, de lo contrario, T falla en la validación. Observamos nuevamente que las verificaciones basadas en el número de versión de la página y las verificaciones basadas en el reconocimiento de invalidación son complementarias en la validación de confirmación individual y ambas son necesarias. La verificación del número de versión de la página permite que la validación avance antes de que lleguen las confirmaciones de invalidación, pero por sí sola, una verificación del número de versión de la página detecta conflictos a nivel de página y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cómo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un número de versión de la página para cada página en caché. El número de versión satisface la siguiente invariante V P sobre el estado de los objetos en una página: si una página en caché P tiene un número de versión v, entonces el valor de un objeto o en la página en caché P es inválido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacción que estableció el número de versión de P en v. Los nuevos valores de objetos y los nuevos números de versión de página llegan cuando un cliente obtiene una página o cuando llega una respuesta de confirmación o invalidaciones para esta página. Los nuevos valores del objeto modifican la página y, por lo tanto, el número de versión de la página necesita ser actualizado para mantener la invariante V P. Un número de versión de página que llega cuando un cliente obtiene una página, reemplaza la Versión del Objeto x 8 Servidor de Redirección 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el número de versión de la página para esta página. Tal actualización preserva el invariante V P. De manera similar, un número de versión de página en secuencia que llega al cliente en un mensaje de confirmación o invalidación avanza el número de versión para toda la página en caché, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus números de versión de página correspondientes también pueden llegar al cliente fuera de secuencia, en cuyo caso la actualización del número de versión de la página podría violar V P. Por ejemplo, una respuesta de confirmación para una transacción que actualiza el objeto x en la página P en el servidor S1, y el objeto y en la página Q en el servidor S2, puede entregar un nuevo número de versión para P desde el coordinador de transacciones S1 antes de que llegue una invalidación generada para una transacción anterior que ha modificado el objeto r en la página P desde S1 (como se muestra en la figura 5). El protocolo de actualización de caché garantiza que el valor de cualquier objeto o en una página en caché P refleje la actualización o invalidación con el número de versión observado más alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de números de versión de página, el cliente gestiona una pequeña caché de números de versión vcache que mantiene el mapeo de un objeto a su número de versión de página correspondiente para todas las actualizaciones de números de versión reordenadas hasta que se ensamble una secuencia completa de números de versión de página. Cuando llegan los números de versión faltantes para la página y completan una secuencia, el número de versión de toda la página se avanza. El mapeo de ObjectToVersion, incluyendo los números de versión de vcache y página, se utiliza en el momento de la confirmación de la transacción para proporcionar números de versión para el conjunto de objetos leídos de la siguiente manera. Si el objeto leído tiene una entrada en la vcache, su número de versión es igual al número de versión más alto en la vcache para este objeto. Si el objeto no está presente en la vcache, su número de versión es igual al número de versión de la página en caché que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la caché del cliente, incluyendo los números de versión de las páginas y la vcache. El cliente puede limitar el tamaño de la caché virtual según sea necesario, ya que volver a cargar una página elimina todos los números de versión de página reordenados de la caché virtual. Sin embargo, esperamos que la reorganización de números de versión sea poco común y, por lo tanto, esperamos que la vcache sea muy pequeña. 5. Un grupo de clientes contiene múltiples nodos de cliente y un objeto de página de versión redi32 VCache Cliente Caché Cliente Página Caché Figura 6: Mapa de Objeto a Versión con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutación por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. Además, el fallo del redireccionador debería permitir que los clientes no afectados mantengan sus cachés intactas. Hemos diseñado un protocolo de conmutación por error para BuddyCache pero aún no lo hemos implementado. El apéndice describe el protocolo. 6. La redirección de BuddyCache en la evaluación de rendimiento respalda los beneficios de evitar la comunicación con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes. ¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la recuperación entre pares y la actualización entre pares se deben a la evitación de interacciones con el servidor. Esta sección presenta un modelo de rendimiento analítico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la caché del cliente. Estos pueden ser fallos fríos, fallos de invalidación y fallos de capacidad. Nuestro análisis se centra en los fallos por frío y los fallos por invalidación, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frío. Además, las tendencias tecnológicas indican que la capacidad de memoria y almacenamiento seguirá creciendo y, por lo tanto, es probable que una configuración típica de BuddyCache no esté limitada por la caché. Los fallos de caché del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuración de caché. Nuestro análisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validación. Para estudiar el beneficio de evitar fallos en frío, consideramos el rendimiento de la caché en frío en una carga de trabajo de solo lectura (sin fallos de invalidación). Esperamos que la recuperación entre pares mejore el costo de latencia para las solicitudes de caché fría del cliente al recuperar objetos de la caché cercana. Evaluamos cómo el costo de redirección afecta este beneficio al comparar y analizar el rendimiento de una aplicación que se ejecuta en un sistema de almacenamiento con BuddyCache y sin él (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidación, consideramos el rendimiento de la caché caliente en una carga de trabajo con modificaciones (sin fallos en frío). En las cachés calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualización entre pares permite que un cliente acceda a un objeto modificado por un compañero colaborador cercano sin el retraso impuesto por los protocolos de invalidación únicamente. En grupos donde los compañeros comparten un interés de solo lectura en los objetos modificados, la recuperación entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compañero colaborador lo tenga, lo que evita el retraso de la recuperación del servidor sin el alto costo impuesto por los protocolos de solo actualización. Las tendencias tecnológicas indican que ambos beneficios seguirán siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualización únicamente. Sin embargo, la tendencia hacia cachés cada vez más grandes, que se actualizan cuando los objetos en caché son modificados, hace que los protocolos basados en invalidación sean más atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicación que se ejecuta sin BuddyCache y una aplicación que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compañero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compañero fuera del grupo. La actualización entre pares también puede evitar fallos de invalidación debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma página de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseño del objeto, y también porque este beneficio se puede derivar dado el índice de aciertos en caché y la contención de la carga de trabajo. 6.1.1 El Modelo El modelo considera cómo el tiempo para completar una ejecución con y sin BuddyCache se ve afectado por los fallos de invalidación y los fallos en frío. Considerando k clientes ejecutándose concurrentemente accediendo de manera uniforme a un conjunto compartido de N páginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacción y realizar cálculos en una transacción, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin él (Base). Para simplificar, nuestro modelo asume que los tiempos de búsqueda y confirmación son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del número total de clientes en el sistema. El número de fallos evitados por la recuperación entre pares depende de k, el número de clientes en la BuddyCache, y del interés conjunto de los clientes en los datos compartidos. En una ejecución específica de BuddyCache, se modela mediante la variable r, definida como el número de solicitudes que llegan al redireccionador para una versión dada de la página P (es decir, hasta que un objeto en la página se invalida). Considera una ejecución con fallos en frío. Un cliente comienza con una caché fría y ejecuta una carga de trabajo de solo lectura hasta que accede a las N páginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la caché del cliente es lo suficientemente grande como para contener N páginas. En BC, los fríos fallos para la página P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consideremos a continuación una ejecución con fallos de invalidación. Un cliente comienza con una caché caliente que contiene el conjunto de trabajo de N páginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualización entre pares elimina todos los fallos de invalidación. En un grupo que contiene solo lectores (BCR), durante una ejecución en estado estable con actualizaciones uniformes, una transacción del cliente tiene fallos de invalidación faltantes. Considera la secuencia de r fallos de cliente en la página P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la página P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frío, r ≤ k porque la segunda invalidación deshabilita la redirección para P hasta que el próximo fallo en P provoque una recuperación del servidor. Suponiendo un acceso uniforme, un fallo de invalidación del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperación del servidor), y una probabilidad de (1 − 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacción única en los sistemas Base, BCR y BCW. En los experimentos descritos a continuación, medimos los parámetros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalización derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalización y beneficios medidos directamente en los experimentos. 6.2 Configuración Experimental Antes de presentar nuestros resultados, describimos nuestra configuración experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectándose directamente a los servidores. El sistema Buddy ejecuta nuestra implementación del prototipo de BuddyCache en Thor, admitiendo la recuperación de pares, la actualización de pares y la confirmación en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark está diseñado para capturar las características de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicación específica. Utilizamos OO7 porque es un punto de referencia estándar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un árbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un gráfico de partes atómicas vinculadas por objetos de conexión; cada parte atómica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atómicas por parte compuesta. La base de datos multiusuario asigna a cada cliente un módulo privado que consiste en un árbol de objetos de ensamblaje, y agrega un módulo compartido adicional que escala proporcionalmente al número de clientes. Esperamos que una configuración típica de BuddyCache no esté limitada por la caché y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la caché. Dado que el objetivo de nuestro estudio es evaluar qué tan efectivamente nuestras técnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras técnicas tienen en los fallos de caché frío y de consistencia de caché, y aislar tanto como sea posible el efecto de los fallos de capacidad de caché. Para mantener la duración de nuestros experimentos razonable, utilizamos cachés pequeños. El benchmark OO7 genera módulos de base de datos de tamaño predefinido. En nuestra implementación de OO7, el tamaño del módulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la caché, utilizamos un único módulo privado y elegimos un tamaño de caché de 40MB para cada cliente. La base de datos OO7 se genera con módulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos están agrupados en páginas de 8K, que también son la unidad de transferencia en las solicitudes de recuperación. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro análisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idéntico a T1 excepto que modifica todas las partes atómicas en un solo compuesto. Una transacción única incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo módulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacción, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de búsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una caché de 50MB (de los cuales 6MB se utilizaron para el búfer de objetos modificados), el cliente tenía una caché de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos básicos Esta sección analiza el costo básico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 Redirección Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtención del servidor), el costo adicional de la redirección incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperación o confirmación del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmación y recuperación del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de área rápida. Todos los números fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirección al cruzar el redireccionador no es muy alto, incluso en una red de área local. El costo de la confirmación aumenta con el número de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperación no aumenta tanto porque la caché del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la caché del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperación entre pares, medimos la latencia de la recuperación entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperación entre pares, el costo de la redirección incluye, además del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este último incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la página solicitada. Medimos directamente el tiempo para copiar y desenrollar la página solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperación de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador más un viaje de ida y vuelta a través de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud más un viaje de ida y vuelta a través de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando está bloqueado esperando una respuesta de búsqueda o confirmación. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podría ser mitigado por una implementación multi-hilo en un sistema con programación preemptiva. 6.3.2 Versión de Caché El commit en solitario permite que un cliente rápido que modifica un objeto haga un commit de forma independiente a un compañero lento. El mecanismo de confirmación única introduce un procesamiento adicional en el servidor durante la validación de la transacción, y un procesamiento adicional en el cliente durante la confirmación de la transacción y en el momento del procesamiento de actualización o invalidación. Los gastos generales del lado del servidor son mínimos y consisten en una actualización del número de versión de la página en el momento de la confirmación, y una comparación del número de versión en el momento de la validación de la transacción. La caché de versión tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacción accede a objetos en múltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor único y, por lo tanto, el tiempo de confirmación adicional de la gestión de la caché de versiones en el cliente no contribuye a los resultados presentados en la sección a continuación. Para medir estos costos adicionales del lado del cliente en un sistema de múltiples servidores, instrumentamos la implementación de la caché de versiones para ejecutarse con una traza de carga de trabajo que incluía invalidaciones reordenadas y cronometramos las operaciones básicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operación de búsqueda de caché de versión para cada objeto leído por la transacción en el momento de preparación de la solicitud de compromiso, y una operación de inserción de caché de versión para cada objeto actualizado por una transacción en el momento de procesamiento de la respuesta de compromiso, pero solo si la página actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmación se mantengan al mínimo, ya que el cliente está esperando de forma síncrona la finalización de la confirmación. Las mediciones muestran que en el peor de los casos, cuando llega un gran número de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en páginas reordenadas, el costo de actualizar la caché de versión es de 0.6 ms. El costo de tiempo de invalidación es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementación de la caché de versiones para reducir aún más estos costos. 6.4 Rendimiento general Esta sección examina las mejoras de rendimiento observadas por una aplicación que ejecuta el benchmark OO7 con un BuddyCache en una red de área amplia. 6.4.1 Fallos en frío Para evaluar las mejoras de rendimiento al evitar fallos en frío, comparamos el rendimiento de la caché en frío del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecución de los sistemas en el entorno de la red de área local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de área amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en caché fría. Los números fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frío solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frío solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparación con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cálculos para el cliente, solicitudes de recuperación directa, recuperaciones de pares y solicitudes de confirmación. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperación entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperación del servidor para cada cliente individual disminuye porque, con más clientes accediendo a un módulo compartido de tamaño fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperación de pares en comparación con la recuperación directa, pero este beneficio se ve contrarrestado por los tiempos de confirmación aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relación con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de caché 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT función de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias típicas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Sorprendentemente, los resultados analíticos predicen la mejora medida muy de cerca, aunque son ligeramente más altos que los valores empíricos. La razón principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidación evitados, comparamos el rendimiento de caché caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interés de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un único cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compañeros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compañeros con un grupo que contiene un único escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuración simple es suficiente para mostrar el impacto de las técnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de caché caliente de OO7. Obtenemos los números ejecutando 2000 transacciones para filtrar los fallos en frío y luego medimos el tiempo de las siguientes 1000 transacciones. Aquí nuevamente, los números reportados se derivan de los resultados del experimento de la red de área local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalización en comparación con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparación con la Base. Este beneficio se debe a la actualización entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperación entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperación local evitando el retraso de la recuperación desde el servidor. El último es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperación de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperación de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualización de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relación con Base, y Buddy Writer y Base en relación con Base) en un experimento de caché activa en función del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualización entre pares domina el gasto general en la configuración de Writer incluso en redes de baja latencia (la actualización entre pares incurre en un gasto mínimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Como en experimentos de caché fría, aquí los resultados analíticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pérdida de invalidación es mínimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de caché fría). Como en el caso de caché fría, la razón por la que el modelo analítico simplificado funciona bien es porque captura los costos de la latencia de red, el <br>costo de rendimiento dominante</br>. 7. CONCLUSIÓN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en una red de área extensa debido a la alta latencia de red. Este artículo describe BuddyCache, una nueva técnica de almacenamiento en caché cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La técnica mejora el rendimiento y proporciona propiedades sólidas de corrección y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirección para obtener objetos faltantes directamente de las cachés de los miembros del grupo, y para admitir la actualización entre pares, una nueva técnica de multidifusión a nivel de aplicación ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirección puede interferir con la disponibilidad del objeto. Solo commit es una nueva técnica de validación que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validación detallada utilizando información de versión de grano grueso económica. Hemos diseñado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analíticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Las principales contribuciones del artículo son: 1. extender las técnicas de almacenamiento en caché cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementación del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluación del rendimiento basada en análisis y mediciones de los costos y beneficios de las nuevas técnicas que capturan el <br>costo de rendimiento dominante</br>, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. También agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios útiles que mejoraron este artículo. 9. REFERENCIAS [1] emulab.net, la Instalación de Emulación de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. Reconstrucción de fragmentos: Proporcionando coherencia de caché global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de Computación Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre Gestión de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: Computación en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de caché híbridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. Recuperación rápida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de caché en la World Wide Web. En la 17ª Conferencia Internacional sobre Sistemas de Computación Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluación del rendimiento del sistema de gestión de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una caché de objetos jerárquica en Internet. En la Conferencia Técnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachés de Internet escalables. Informe Técnico CS-1997-18, Departamento de Ciencias de la Computación, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: Caché de proxy cooperativa en una red de área amplia. En el Tercer Taller Internacional de Caché de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. Caché web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2º Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. Caché cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilación y en tiempo de ejecución para una memoria compartida distribuida eficiente. En Actas de IEEE, Edición Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la caché: un protocolo de intercambio de caché web escalable de área amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. Implementación de Gestión Global de Memoria en un Clúster de Estaciones de Trabajo. Actas del 15º Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: Diseño, Implementación y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de caché transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, páginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. Gestión global de memoria para arquitecturas de sistemas de gestión de bases de datos cliente-servidor. En Actas del 19º Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El Búfer de Objeto Modificado: Una Técnica de Gestión de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto Tecnológico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. Gestión de documentos replicados en un sistema de comunicación grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13ª Conferencia Europea sobre Programación Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18º Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. Replicación con marca de vista: un nuevo método de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de Computación Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalación eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de Multidifusión a Nivel de Aplicación. En el 3er Simposio USENIX sobre Tecnologías y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de caché cooperativa utilizando pistas. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en Caché Global. Informe técnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del Caché de Proxies Web Cooperativos. En el 17º Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerárquica de caché en una WAN. En el Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. Compartición adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÉNDICE Este apéndice describe el protocolo de conmutación por error de BuddyCache. Para dar cabida a clientes heterogéneos, incluidos los dispositivos portátiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseño de BuddyCache asume que las cachés del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresía detecta el fallo de un cliente o un redireccionador intercambiando mensajes periódicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutación por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuración y reinicia el protocolo. El protocolo de reconfiguración del grupo es similar al presentado en [25]. Aquí describimos cómo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de páginas redireccionadas y el reenvío de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachés. En caso de un fallo del cliente, el failover elimina las páginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmación, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en caché las páginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutación por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de páginas utilizando un protocolo similar al descrito en [6]. El redireccionador recién reiniciado solicita a los miembros activos del grupo la lista de páginas que están almacenando en caché y el estado de estas páginas, es decir, si las páginas están completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperación perdida expirará en el cliente y será retransmitida. Una transacción que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma después del cambio se trata como una transacción regular; una transacción que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciará la transacción y la solicitud de confirmación será retransmitida después del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caído podrían evitar la recolección de basura de las invalidaciones pendientes en los servidores o la caché virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los números de versión únicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validación de transacciones depende del protocolo de coherencia de caché para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutación por error de BuddyCache no compromete la corrección del procedimiento de validación. Recuerda que la validación de transacciones de BuddyCache utiliza dos mecanismos complementarios, números de versión de página y confirmaciones de invalidación de los clientes, para verificar que una transacción ha leído datos actualizados. La propagación de la confirmación de invalidación (y actualización) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmación de una modificación (invalidación o actualización) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en caché el objeto o bien ha instalado el valor más reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmación de un cliente para una transacción T que lee un objeto o después de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidación no confirmada para o pendiente para este grupo, la versión del objeto leída por la transacción T está actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validación utilizando números de versión. El registro de confirmación de transacción contiene un número de versión para cada objeto leído por la transacción. El protocolo de número de versión mantiene la invariante V P que garantiza que el valor del objeto o leído por la transacción corresponda al número de versión más alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificación anterior después de haber recibido una modificación posterior. La retransmisión de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validación verifica que el número de versión en el registro de confirmación coincida con el número de versión en la invalidación pendiente no reconocida. Es fácil ver que, dado que esta comprobación es una comprobación cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutación por error aún no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "optimistic system": {
            "translated_key": "sistema optimista",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an <br>optimistic system</br>.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an <br>optimistic system</br>."
            ],
            "translated_annotated_samples": [
                "Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un <br>sistema optimista</br>."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un <br>sistema optimista</br>. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la transacción se cancela. Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de búsqueda de pares envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados. Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente. El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente. El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños. Un objetivo importante del diseño de BuddyCache es mantener este beneficio. Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo. Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché. Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. Almacén x 6. Actualización x 3. Comprométete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes. Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente. Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una red de área amplia serían derrochadores. Sin embargo, los protocolos de coherencia basados en invalidación pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interés para otro miembro del grupo. Con un protocolo basado en invalidación, la actualización de un miembro invalidará la copia en caché de otro miembro, lo que provocará que este último realice una recuperación de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualización e invalidación en entornos de redes de área amplia. Evita la penalización de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalización de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusión localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en caché anteriores. La actualización entre pares funciona de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que la transacción se confirma, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación, y también propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmación. 3.3 Confirmación individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminación de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en caché transaccional, ya que un cliente que es lento para reconocer una invalidación o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacción. Por ejemplo, un ingeniero que realiza una revisión repetida al mismo objeto de diseño compartido (y por lo tanto tiene la última versión del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situación representada en la figura 4 donde el Cliente1 realiza una transacción T que lee la última versión de un objeto x en la página P recientemente modificada por el Cliente1. Si la solicitud de confirmación para T llega al servidor antes de que la confirmación colectiva de Cliente2 por la última modificación de x llegue al servidor, el procedimiento de validación de OCC considera que x está obsoleto y aborta T (porque, como se explicó anteriormente, una invalidación no reconocida por un cliente actúa como indicación para el servidor de que el valor del objeto en caché está obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la corrección del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asíncronas son una parte importante de la razón por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasión de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envían y procesan de forma asíncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devolución de llamada jerárquica [32], pero la naturaleza asincrónica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrónicas. El protocolo de validación de confirmación en solitario permite a un cliente con objetos actualizados confirmar una transacción incluso si la confirmación del grupo se retrasa debido a pares lentos o caídos. El protocolo requiere que los clientes incluyan información adicional con los conjuntos de lectura de transacciones en el mensaje de confirmación, para indicar al servidor que los objetos leídos por la transacción están actualizados. Los números de versión de los objetos podrían proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionó anteriormente, mantener números de versión por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaño de directorio) en todo el sistema de objetos cuando los objetos son pequeños [23]. En cambio, solo utiliza números de versión de página de grano grueso para identificar versiones de objetos de grano fino. El número de versión de una página se incrementa en un servidor cuando una transacción que modifica objetos en la página se confirma. Las actualizaciones realizadas por una única transacción y las invalidaciones correspondientes son identificadas de manera única por el número de versión de la página modificada. Los números de versión de la página se propagan a los clientes en respuestas de recuperación, respuestas de confirmación y con invalidaciones, y los clientes incluyen los números de versión de la página en las solicitudes de confirmación enviadas a los servidores. Si una transacción falla en la validación debido a la falta de reconocimiento de grupo, el servidor verifica los números de versión de página de los objetos en el conjunto de lectura de la transacción y permite que la transacción se confirme si el cliente ha leído desde la última versión de la página. Los números de versión de la página permiten confirmaciones independientes, pero las verificaciones de versión de página solo detectan conflictos a nivel de página. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes. Potencialmente, puede ser más rápido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podría ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en caché de pares de múltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en caché web, simplemente aumentar la población de clientes en una caché proxy a menudo aumenta la tasa general de aciertos en la caché [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacción explícita entre clientes y la colaboración, lo que sugiere que es poco probable que ocurra la recuperación entre grupos. Además, las mediciones de sistemas de almacenamiento en caché web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexión de red entre los grupos de pares sea muy rápida. Estamos principalmente interesados en entornos donde compañeros que colaboran estrechamente tienen una conectividad rápida a corta distancia, pero la conexión entre grupos de compañeros puede ser lenta. Como resultado, decidimos que el soporte para la recuperación entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compañeros con recursos heterogéneos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compañeros o, cuando esté disponible, en un nodo separado dentro de la infraestructura del sitio. Además, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una caché de pares en espera para recibir páginas recuperadas por otros pares, emulando una caché central algo similar a una caché de proxy web regional. Desde el punto de vista del protocolo de coherencia de caché BuddyCache, sin embargo, un caché de compañero en espera es equivalente a un caché de compañero regular y, por lo tanto, no consideramos este caso por separado en la discusión de este documento. 4. En esta sección proporcionamos los detalles de la implementación de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en caché de estos objetos. Las aplicaciones se ejecutan en los clientes e interactúan con el sistema realizando llamadas a métodos de objetos en caché. Todas las llamadas a métodos ocurren dentro de transacciones atómicas. Los clientes se comunican con los servidores para obtener páginas o realizar una transacción. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volátil. El disco está organizado como una colección de páginas que son las unidades de acceso al disco. El registro estable guarda la información de confirmación y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de caché y una caché de objetos modificados recuperable llamada MOB. El directorio lleva un registro de qué páginas están almacenadas en caché por qué clientes. El MOB contiene objetos recientemente modificados que aún no han sido escritos de vuelta en sus páginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de caché base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la Sección 3.1. Proporcionamos algunos de los detalles relevantes de la implementación del protocolo OCC. El cliente lleva un registro de los objetos que son leídos y modificados por su transacción; envía esta información, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacción. Los servidores determinan si la confirmación es posible, utilizando un protocolo de confirmación de dos fases si la transacción utilizó objetos en múltiples servidores. Si la transacción se lleva a cabo, las nuevas copias de los objetos modificados se añaden al registro y también se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperación escaneando el registro. Dado que los objetos no están bloqueados antes de ser utilizados, una confirmación de transacción puede hacer que las cachés contengan objetos obsoletos. Los servidores abortarán una transacción que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviándoles mensajes de invalidación; un servidor utiliza su directorio y la información sobre la transacción de confirmación para determinar qué mensajes de invalidación enviar. Los mensajes de invalidación son pequeños porque simplemente identifican objetos obsoletos. Además, se envían en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidación, elimina los objetos obsoletos de su caché y aborta la transacción actual si los utilizó. El cliente sigue conservando páginas que contienen objetos invalidados; estas páginas ahora están incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidación de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener páginas incompletas en la caché del cliente significa que el falso intercambio no conduce a fallos innecesarios en la caché. Los clientes reconocen las invalidaciones para indicar la eliminación de datos obsoletos, como se explica en la Sección 3.1. Los mensajes de invalidación evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo así el desperdicio de trabajo y trasladando la detección de abortos de los servidores a los clientes. Cuando una transacción se aborta, su cliente restaura las copias en caché de los objetos modificados al estado que tenían antes de que la transacción comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacción. 4.3 Redirección El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de páginas disponibles en el grupo de pares y proporciona una redirección rápida y centralizada de recuperación (ver figura 2) entre las cachés de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan páginas u objetos al incluir esa información en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la caché de grupo, el redireccionador realiza un seguimiento del estado de las páginas. Una página en caché está completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una página están marcados como inválidos. Solo se utilizan páginas completas por el proceso de recuperación de pares. El protocolo para mantener el estado de la página cuando las páginas son actualizadas e invalidadas se describe en la Sección 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una página solicitada completa no está disponible en el grupo de pares o si un par necesita confirmar una transacción, el redireccionador actúa como un proxy de servidor: reenvía la solicitud al servidor y luego reenvía la respuesta de vuelta al cliente. Además, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualización o información de invalidación a los clientes que tienen en caché la página modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la caché de grupo de pares combinada está desempeñando el papel de una única caché de cliente en el sistema base. 4.4 Actualización de pares La actualización de pares se implementa de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que una transacción se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacción generan invalidaciones de objetos para cada grupo de caché que almacena páginas que contienen los objetos modificados (incluido el grupo que realiza la confirmación). Las invalidaciones se envían de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en caché los objetos modificados se deshagan de los datos obsoletos. En grupos de caché distintos al grupo de confirmación, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en caché las páginas modificadas, recopilan las confirmaciones de los clientes y, después de completar la recopilación, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacción, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envían a los clientes que almacenan en caché esas páginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmación colectiva se propaga al servidor. Una invalidación hace que una página en caché no esté disponible para la recuperación de pares, cambiando el estado de una página completa p a incompleta. Por el contrario, una actualización de una página completa conserva el estado completo de la página. Como se muestra en los estudios de la reconstrucción de fragmentos 31 [2], esta propagación de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la recuperación entre pares. Por lo tanto, el efecto de la actualización de pares es similar a la reconstrucción de fragmentos ansiosa [2]. También hemos considerado la posibilidad de permitir que un compañero recupere una página incompleta (con objetos inválidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos inválidos. 4.5 Vcache El protocolo de validación de confirmación en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo más lentos (o fallidos). Como se explica en la Sección 3.3, el protocolo de commit único permite que una transacción T pase la validación si la información adicional de coherencia proporcionada por el cliente indica que la transacción T ha leído objetos actualizados. Los clientes utilizan los números de versión de la página para proporcionar esta información adicional de coherencia. Es decir, un cliente incluye el número de versión de la página correspondiente a cada objeto en el conjunto de objetos leídos enviado en la solicitud de confirmación al servidor. Dado que a cada actualización de objeto comprometido le corresponde un número de versión de página único, el número de versión de página asociado con un objeto permite que el procedimiento de validación en el servidor verifique si la transacción del cliente ha leído objetos actualizados. El uso de versiones de página de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeños, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en caché a la versión de página identificadora (ObjectToVersion). El principal problema de implementación se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian números de versión de página con las invalidaciones. En el momento de la validación, si hay una invalidación no reconocida pendiente para un objeto x leído por una transacción T, el procedimiento de validación verifica si el número de versión de x en el conjunto de lectura de Ts coincide con el número de versión de la invalidación pendiente más alta para x, en cuyo caso el valor del objeto está actualizado, de lo contrario, T falla en la validación. Observamos nuevamente que las verificaciones basadas en el número de versión de la página y las verificaciones basadas en el reconocimiento de invalidación son complementarias en la validación de confirmación individual y ambas son necesarias. La verificación del número de versión de la página permite que la validación avance antes de que lleguen las confirmaciones de invalidación, pero por sí sola, una verificación del número de versión de la página detecta conflictos a nivel de página y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cómo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un número de versión de la página para cada página en caché. El número de versión satisface la siguiente invariante V P sobre el estado de los objetos en una página: si una página en caché P tiene un número de versión v, entonces el valor de un objeto o en la página en caché P es inválido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacción que estableció el número de versión de P en v. Los nuevos valores de objetos y los nuevos números de versión de página llegan cuando un cliente obtiene una página o cuando llega una respuesta de confirmación o invalidaciones para esta página. Los nuevos valores del objeto modifican la página y, por lo tanto, el número de versión de la página necesita ser actualizado para mantener la invariante V P. Un número de versión de página que llega cuando un cliente obtiene una página, reemplaza la Versión del Objeto x 8 Servidor de Redirección 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el número de versión de la página para esta página. Tal actualización preserva el invariante V P. De manera similar, un número de versión de página en secuencia que llega al cliente en un mensaje de confirmación o invalidación avanza el número de versión para toda la página en caché, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus números de versión de página correspondientes también pueden llegar al cliente fuera de secuencia, en cuyo caso la actualización del número de versión de la página podría violar V P. Por ejemplo, una respuesta de confirmación para una transacción que actualiza el objeto x en la página P en el servidor S1, y el objeto y en la página Q en el servidor S2, puede entregar un nuevo número de versión para P desde el coordinador de transacciones S1 antes de que llegue una invalidación generada para una transacción anterior que ha modificado el objeto r en la página P desde S1 (como se muestra en la figura 5). El protocolo de actualización de caché garantiza que el valor de cualquier objeto o en una página en caché P refleje la actualización o invalidación con el número de versión observado más alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de números de versión de página, el cliente gestiona una pequeña caché de números de versión vcache que mantiene el mapeo de un objeto a su número de versión de página correspondiente para todas las actualizaciones de números de versión reordenadas hasta que se ensamble una secuencia completa de números de versión de página. Cuando llegan los números de versión faltantes para la página y completan una secuencia, el número de versión de toda la página se avanza. El mapeo de ObjectToVersion, incluyendo los números de versión de vcache y página, se utiliza en el momento de la confirmación de la transacción para proporcionar números de versión para el conjunto de objetos leídos de la siguiente manera. Si el objeto leído tiene una entrada en la vcache, su número de versión es igual al número de versión más alto en la vcache para este objeto. Si el objeto no está presente en la vcache, su número de versión es igual al número de versión de la página en caché que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la caché del cliente, incluyendo los números de versión de las páginas y la vcache. El cliente puede limitar el tamaño de la caché virtual según sea necesario, ya que volver a cargar una página elimina todos los números de versión de página reordenados de la caché virtual. Sin embargo, esperamos que la reorganización de números de versión sea poco común y, por lo tanto, esperamos que la vcache sea muy pequeña. 5. Un grupo de clientes contiene múltiples nodos de cliente y un objeto de página de versión redi32 VCache Cliente Caché Cliente Página Caché Figura 6: Mapa de Objeto a Versión con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutación por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. Además, el fallo del redireccionador debería permitir que los clientes no afectados mantengan sus cachés intactas. Hemos diseñado un protocolo de conmutación por error para BuddyCache pero aún no lo hemos implementado. El apéndice describe el protocolo. 6. La redirección de BuddyCache en la evaluación de rendimiento respalda los beneficios de evitar la comunicación con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes. ¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la recuperación entre pares y la actualización entre pares se deben a la evitación de interacciones con el servidor. Esta sección presenta un modelo de rendimiento analítico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la caché del cliente. Estos pueden ser fallos fríos, fallos de invalidación y fallos de capacidad. Nuestro análisis se centra en los fallos por frío y los fallos por invalidación, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frío. Además, las tendencias tecnológicas indican que la capacidad de memoria y almacenamiento seguirá creciendo y, por lo tanto, es probable que una configuración típica de BuddyCache no esté limitada por la caché. Los fallos de caché del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuración de caché. Nuestro análisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validación. Para estudiar el beneficio de evitar fallos en frío, consideramos el rendimiento de la caché en frío en una carga de trabajo de solo lectura (sin fallos de invalidación). Esperamos que la recuperación entre pares mejore el costo de latencia para las solicitudes de caché fría del cliente al recuperar objetos de la caché cercana. Evaluamos cómo el costo de redirección afecta este beneficio al comparar y analizar el rendimiento de una aplicación que se ejecuta en un sistema de almacenamiento con BuddyCache y sin él (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidación, consideramos el rendimiento de la caché caliente en una carga de trabajo con modificaciones (sin fallos en frío). En las cachés calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualización entre pares permite que un cliente acceda a un objeto modificado por un compañero colaborador cercano sin el retraso impuesto por los protocolos de invalidación únicamente. En grupos donde los compañeros comparten un interés de solo lectura en los objetos modificados, la recuperación entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compañero colaborador lo tenga, lo que evita el retraso de la recuperación del servidor sin el alto costo impuesto por los protocolos de solo actualización. Las tendencias tecnológicas indican que ambos beneficios seguirán siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualización únicamente. Sin embargo, la tendencia hacia cachés cada vez más grandes, que se actualizan cuando los objetos en caché son modificados, hace que los protocolos basados en invalidación sean más atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicación que se ejecuta sin BuddyCache y una aplicación que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compañero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compañero fuera del grupo. La actualización entre pares también puede evitar fallos de invalidación debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma página de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseño del objeto, y también porque este beneficio se puede derivar dado el índice de aciertos en caché y la contención de la carga de trabajo. 6.1.1 El Modelo El modelo considera cómo el tiempo para completar una ejecución con y sin BuddyCache se ve afectado por los fallos de invalidación y los fallos en frío. Considerando k clientes ejecutándose concurrentemente accediendo de manera uniforme a un conjunto compartido de N páginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacción y realizar cálculos en una transacción, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin él (Base). Para simplificar, nuestro modelo asume que los tiempos de búsqueda y confirmación son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del número total de clientes en el sistema. El número de fallos evitados por la recuperación entre pares depende de k, el número de clientes en la BuddyCache, y del interés conjunto de los clientes en los datos compartidos. En una ejecución específica de BuddyCache, se modela mediante la variable r, definida como el número de solicitudes que llegan al redireccionador para una versión dada de la página P (es decir, hasta que un objeto en la página se invalida). Considera una ejecución con fallos en frío. Un cliente comienza con una caché fría y ejecuta una carga de trabajo de solo lectura hasta que accede a las N páginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la caché del cliente es lo suficientemente grande como para contener N páginas. En BC, los fríos fallos para la página P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consideremos a continuación una ejecución con fallos de invalidación. Un cliente comienza con una caché caliente que contiene el conjunto de trabajo de N páginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualización entre pares elimina todos los fallos de invalidación. En un grupo que contiene solo lectores (BCR), durante una ejecución en estado estable con actualizaciones uniformes, una transacción del cliente tiene fallos de invalidación faltantes. Considera la secuencia de r fallos de cliente en la página P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la página P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frío, r ≤ k porque la segunda invalidación deshabilita la redirección para P hasta que el próximo fallo en P provoque una recuperación del servidor. Suponiendo un acceso uniforme, un fallo de invalidación del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperación del servidor), y una probabilidad de (1 − 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacción única en los sistemas Base, BCR y BCW. En los experimentos descritos a continuación, medimos los parámetros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalización derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalización y beneficios medidos directamente en los experimentos. 6.2 Configuración Experimental Antes de presentar nuestros resultados, describimos nuestra configuración experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectándose directamente a los servidores. El sistema Buddy ejecuta nuestra implementación del prototipo de BuddyCache en Thor, admitiendo la recuperación de pares, la actualización de pares y la confirmación en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark está diseñado para capturar las características de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicación específica. Utilizamos OO7 porque es un punto de referencia estándar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un árbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un gráfico de partes atómicas vinculadas por objetos de conexión; cada parte atómica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atómicas por parte compuesta. La base de datos multiusuario asigna a cada cliente un módulo privado que consiste en un árbol de objetos de ensamblaje, y agrega un módulo compartido adicional que escala proporcionalmente al número de clientes. Esperamos que una configuración típica de BuddyCache no esté limitada por la caché y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la caché. Dado que el objetivo de nuestro estudio es evaluar qué tan efectivamente nuestras técnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras técnicas tienen en los fallos de caché frío y de consistencia de caché, y aislar tanto como sea posible el efecto de los fallos de capacidad de caché. Para mantener la duración de nuestros experimentos razonable, utilizamos cachés pequeños. El benchmark OO7 genera módulos de base de datos de tamaño predefinido. En nuestra implementación de OO7, el tamaño del módulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la caché, utilizamos un único módulo privado y elegimos un tamaño de caché de 40MB para cada cliente. La base de datos OO7 se genera con módulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos están agrupados en páginas de 8K, que también son la unidad de transferencia en las solicitudes de recuperación. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro análisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idéntico a T1 excepto que modifica todas las partes atómicas en un solo compuesto. Una transacción única incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo módulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacción, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de búsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una caché de 50MB (de los cuales 6MB se utilizaron para el búfer de objetos modificados), el cliente tenía una caché de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos básicos Esta sección analiza el costo básico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 Redirección Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtención del servidor), el costo adicional de la redirección incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperación o confirmación del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmación y recuperación del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de área rápida. Todos los números fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirección al cruzar el redireccionador no es muy alto, incluso en una red de área local. El costo de la confirmación aumenta con el número de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperación no aumenta tanto porque la caché del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la caché del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperación entre pares, medimos la latencia de la recuperación entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperación entre pares, el costo de la redirección incluye, además del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este último incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la página solicitada. Medimos directamente el tiempo para copiar y desenrollar la página solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperación de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador más un viaje de ida y vuelta a través de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud más un viaje de ida y vuelta a través de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando está bloqueado esperando una respuesta de búsqueda o confirmación. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podría ser mitigado por una implementación multi-hilo en un sistema con programación preemptiva. 6.3.2 Versión de Caché El commit en solitario permite que un cliente rápido que modifica un objeto haga un commit de forma independiente a un compañero lento. El mecanismo de confirmación única introduce un procesamiento adicional en el servidor durante la validación de la transacción, y un procesamiento adicional en el cliente durante la confirmación de la transacción y en el momento del procesamiento de actualización o invalidación. Los gastos generales del lado del servidor son mínimos y consisten en una actualización del número de versión de la página en el momento de la confirmación, y una comparación del número de versión en el momento de la validación de la transacción. La caché de versión tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacción accede a objetos en múltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor único y, por lo tanto, el tiempo de confirmación adicional de la gestión de la caché de versiones en el cliente no contribuye a los resultados presentados en la sección a continuación. Para medir estos costos adicionales del lado del cliente en un sistema de múltiples servidores, instrumentamos la implementación de la caché de versiones para ejecutarse con una traza de carga de trabajo que incluía invalidaciones reordenadas y cronometramos las operaciones básicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operación de búsqueda de caché de versión para cada objeto leído por la transacción en el momento de preparación de la solicitud de compromiso, y una operación de inserción de caché de versión para cada objeto actualizado por una transacción en el momento de procesamiento de la respuesta de compromiso, pero solo si la página actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmación se mantengan al mínimo, ya que el cliente está esperando de forma síncrona la finalización de la confirmación. Las mediciones muestran que en el peor de los casos, cuando llega un gran número de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en páginas reordenadas, el costo de actualizar la caché de versión es de 0.6 ms. El costo de tiempo de invalidación es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementación de la caché de versiones para reducir aún más estos costos. 6.4 Rendimiento general Esta sección examina las mejoras de rendimiento observadas por una aplicación que ejecuta el benchmark OO7 con un BuddyCache en una red de área amplia. 6.4.1 Fallos en frío Para evaluar las mejoras de rendimiento al evitar fallos en frío, comparamos el rendimiento de la caché en frío del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecución de los sistemas en el entorno de la red de área local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de área amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en caché fría. Los números fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frío solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frío solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparación con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cálculos para el cliente, solicitudes de recuperación directa, recuperaciones de pares y solicitudes de confirmación. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperación entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperación del servidor para cada cliente individual disminuye porque, con más clientes accediendo a un módulo compartido de tamaño fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperación de pares en comparación con la recuperación directa, pero este beneficio se ve contrarrestado por los tiempos de confirmación aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relación con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de caché 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT función de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias típicas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Sorprendentemente, los resultados analíticos predicen la mejora medida muy de cerca, aunque son ligeramente más altos que los valores empíricos. La razón principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidación evitados, comparamos el rendimiento de caché caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interés de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un único cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compañeros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compañeros con un grupo que contiene un único escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuración simple es suficiente para mostrar el impacto de las técnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de caché caliente de OO7. Obtenemos los números ejecutando 2000 transacciones para filtrar los fallos en frío y luego medimos el tiempo de las siguientes 1000 transacciones. Aquí nuevamente, los números reportados se derivan de los resultados del experimento de la red de área local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalización en comparación con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparación con la Base. Este beneficio se debe a la actualización entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperación entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperación local evitando el retraso de la recuperación desde el servidor. El último es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperación de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperación de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualización de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relación con Base, y Buddy Writer y Base en relación con Base) en un experimento de caché activa en función del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualización entre pares domina el gasto general en la configuración de Writer incluso en redes de baja latencia (la actualización entre pares incurre en un gasto mínimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Como en experimentos de caché fría, aquí los resultados analíticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pérdida de invalidación es mínimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de caché fría). Como en el caso de caché fría, la razón por la que el modelo analítico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÓN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en una red de área extensa debido a la alta latencia de red. Este artículo describe BuddyCache, una nueva técnica de almacenamiento en caché cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La técnica mejora el rendimiento y proporciona propiedades sólidas de corrección y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirección para obtener objetos faltantes directamente de las cachés de los miembros del grupo, y para admitir la actualización entre pares, una nueva técnica de multidifusión a nivel de aplicación ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirección puede interferir con la disponibilidad del objeto. Solo commit es una nueva técnica de validación que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validación detallada utilizando información de versión de grano grueso económica. Hemos diseñado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analíticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Las principales contribuciones del artículo son: 1. extender las técnicas de almacenamiento en caché cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementación del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluación del rendimiento basada en análisis y mediciones de los costos y beneficios de las nuevas técnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. También agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios útiles que mejoraron este artículo. 9. REFERENCIAS [1] emulab.net, la Instalación de Emulación de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. Reconstrucción de fragmentos: Proporcionando coherencia de caché global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de Computación Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre Gestión de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: Computación en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de caché híbridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. Recuperación rápida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de caché en la World Wide Web. En la 17ª Conferencia Internacional sobre Sistemas de Computación Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluación del rendimiento del sistema de gestión de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una caché de objetos jerárquica en Internet. En la Conferencia Técnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachés de Internet escalables. Informe Técnico CS-1997-18, Departamento de Ciencias de la Computación, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: Caché de proxy cooperativa en una red de área amplia. En el Tercer Taller Internacional de Caché de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. Caché web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2º Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. Caché cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilación y en tiempo de ejecución para una memoria compartida distribuida eficiente. En Actas de IEEE, Edición Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la caché: un protocolo de intercambio de caché web escalable de área amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. Implementación de Gestión Global de Memoria en un Clúster de Estaciones de Trabajo. Actas del 15º Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: Diseño, Implementación y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de caché transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, páginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. Gestión global de memoria para arquitecturas de sistemas de gestión de bases de datos cliente-servidor. En Actas del 19º Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El Búfer de Objeto Modificado: Una Técnica de Gestión de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto Tecnológico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. Gestión de documentos replicados en un sistema de comunicación grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13ª Conferencia Europea sobre Programación Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18º Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. Replicación con marca de vista: un nuevo método de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de Computación Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalación eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de Multidifusión a Nivel de Aplicación. En el 3er Simposio USENIX sobre Tecnologías y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de caché cooperativa utilizando pistas. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en Caché Global. Informe técnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del Caché de Proxies Web Cooperativos. En el 17º Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerárquica de caché en una WAN. En el Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. Compartición adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÉNDICE Este apéndice describe el protocolo de conmutación por error de BuddyCache. Para dar cabida a clientes heterogéneos, incluidos los dispositivos portátiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseño de BuddyCache asume que las cachés del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresía detecta el fallo de un cliente o un redireccionador intercambiando mensajes periódicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutación por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuración y reinicia el protocolo. El protocolo de reconfiguración del grupo es similar al presentado en [25]. Aquí describimos cómo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de páginas redireccionadas y el reenvío de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachés. En caso de un fallo del cliente, el failover elimina las páginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmación, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en caché las páginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutación por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de páginas utilizando un protocolo similar al descrito en [6]. El redireccionador recién reiniciado solicita a los miembros activos del grupo la lista de páginas que están almacenando en caché y el estado de estas páginas, es decir, si las páginas están completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperación perdida expirará en el cliente y será retransmitida. Una transacción que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma después del cambio se trata como una transacción regular; una transacción que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciará la transacción y la solicitud de confirmación será retransmitida después del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caído podrían evitar la recolección de basura de las invalidaciones pendientes en los servidores o la caché virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los números de versión únicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validación de transacciones depende del protocolo de coherencia de caché para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutación por error de BuddyCache no compromete la corrección del procedimiento de validación. Recuerda que la validación de transacciones de BuddyCache utiliza dos mecanismos complementarios, números de versión de página y confirmaciones de invalidación de los clientes, para verificar que una transacción ha leído datos actualizados. La propagación de la confirmación de invalidación (y actualización) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmación de una modificación (invalidación o actualización) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en caché el objeto o bien ha instalado el valor más reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmación de un cliente para una transacción T que lee un objeto o después de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidación no confirmada para o pendiente para este grupo, la versión del objeto leída por la transacción T está actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validación utilizando números de versión. El registro de confirmación de transacción contiene un número de versión para cada objeto leído por la transacción. El protocolo de número de versión mantiene la invariante V P que garantiza que el valor del objeto o leído por la transacción corresponda al número de versión más alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificación anterior después de haber recibido una modificación posterior. La retransmisión de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validación verifica que el número de versión en el registro de confirmación coincida con el número de versión en la invalidación pendiente no reconocida. Es fácil ver que, dado que esta comprobación es una comprobación cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutación por error aún no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "peer fetch": {
            "translated_key": "recuperación de pares",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: <br>peer fetch</br> a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the <br>peer fetch</br>.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for <br>peer fetch</br> changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for <br>peer fetch</br>.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of <br>peer fetch</br> and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect <br>peer fetch</br> to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, <br>peer fetch</br> allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, <br>peer fetch</br>, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by <br>peer fetch</br> depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting <br>peer fetch</br>, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: <br>peer fetch</br> 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the <br>peer fetch</br>, we measure the <br>peer fetch</br> latency (PeerFetch) at the requesting client and break down its component costs.",
                "In <br>peer fetch</br>, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the <br>peer fetch</br> costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch <br>peer fetch</br> Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch <br>peer fetch</br> Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to <br>peer fetch</br> avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by <br>peer fetch</br> relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch <br>peer fetch</br> Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch <br>peer fetch</br> Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to <br>peer fetch</br> that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, <br>peer fetch</br> allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the <br>peer fetch</br> in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: <br>peer fetch</br> a server sends background object invalidation messages to clients caching the containing pages.",
                "Only complete pages are used by the <br>peer fetch</br>.",
                "An invalidation renders a cached page unavailable for <br>peer fetch</br> changing the status of a complete page p into an incomplete.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for <br>peer fetch</br>.",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of <br>peer fetch</br> and peer update are due to avoided server interactions."
            ],
            "translated_annotated_samples": [
                "Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de <br>búsqueda de pares</br> envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen.",
                "Solo se utilizan páginas completas por el proceso de <br>recuperación de pares</br>.",
                "Una invalidación hace que una página en caché no esté disponible para la <br>recuperación de pares</br>, cambiando el estado de una página completa p a incompleta.",
                "Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la <br>recuperación entre pares</br>.",
                "Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la <br>recuperación entre pares</br> y la actualización entre pares se deben a la evitación de interacciones con el servidor."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la transacción se cancela. Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de <br>búsqueda de pares</br> envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados. Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente. El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente. El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños. Un objetivo importante del diseño de BuddyCache es mantener este beneficio. Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo. Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché. Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. Almacén x 6. Actualización x 3. Comprométete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes. Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente. Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una red de área amplia serían derrochadores. Sin embargo, los protocolos de coherencia basados en invalidación pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interés para otro miembro del grupo. Con un protocolo basado en invalidación, la actualización de un miembro invalidará la copia en caché de otro miembro, lo que provocará que este último realice una recuperación de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualización e invalidación en entornos de redes de área amplia. Evita la penalización de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalización de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusión localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en caché anteriores. La actualización entre pares funciona de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que la transacción se confirma, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación, y también propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmación. 3.3 Confirmación individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminación de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en caché transaccional, ya que un cliente que es lento para reconocer una invalidación o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacción. Por ejemplo, un ingeniero que realiza una revisión repetida al mismo objeto de diseño compartido (y por lo tanto tiene la última versión del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situación representada en la figura 4 donde el Cliente1 realiza una transacción T que lee la última versión de un objeto x en la página P recientemente modificada por el Cliente1. Si la solicitud de confirmación para T llega al servidor antes de que la confirmación colectiva de Cliente2 por la última modificación de x llegue al servidor, el procedimiento de validación de OCC considera que x está obsoleto y aborta T (porque, como se explicó anteriormente, una invalidación no reconocida por un cliente actúa como indicación para el servidor de que el valor del objeto en caché está obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la corrección del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asíncronas son una parte importante de la razón por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasión de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envían y procesan de forma asíncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devolución de llamada jerárquica [32], pero la naturaleza asincrónica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrónicas. El protocolo de validación de confirmación en solitario permite a un cliente con objetos actualizados confirmar una transacción incluso si la confirmación del grupo se retrasa debido a pares lentos o caídos. El protocolo requiere que los clientes incluyan información adicional con los conjuntos de lectura de transacciones en el mensaje de confirmación, para indicar al servidor que los objetos leídos por la transacción están actualizados. Los números de versión de los objetos podrían proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionó anteriormente, mantener números de versión por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaño de directorio) en todo el sistema de objetos cuando los objetos son pequeños [23]. En cambio, solo utiliza números de versión de página de grano grueso para identificar versiones de objetos de grano fino. El número de versión de una página se incrementa en un servidor cuando una transacción que modifica objetos en la página se confirma. Las actualizaciones realizadas por una única transacción y las invalidaciones correspondientes son identificadas de manera única por el número de versión de la página modificada. Los números de versión de la página se propagan a los clientes en respuestas de recuperación, respuestas de confirmación y con invalidaciones, y los clientes incluyen los números de versión de la página en las solicitudes de confirmación enviadas a los servidores. Si una transacción falla en la validación debido a la falta de reconocimiento de grupo, el servidor verifica los números de versión de página de los objetos en el conjunto de lectura de la transacción y permite que la transacción se confirme si el cliente ha leído desde la última versión de la página. Los números de versión de la página permiten confirmaciones independientes, pero las verificaciones de versión de página solo detectan conflictos a nivel de página. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes. Potencialmente, puede ser más rápido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podría ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en caché de pares de múltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en caché web, simplemente aumentar la población de clientes en una caché proxy a menudo aumenta la tasa general de aciertos en la caché [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacción explícita entre clientes y la colaboración, lo que sugiere que es poco probable que ocurra la recuperación entre grupos. Además, las mediciones de sistemas de almacenamiento en caché web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexión de red entre los grupos de pares sea muy rápida. Estamos principalmente interesados en entornos donde compañeros que colaboran estrechamente tienen una conectividad rápida a corta distancia, pero la conexión entre grupos de compañeros puede ser lenta. Como resultado, decidimos que el soporte para la recuperación entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compañeros con recursos heterogéneos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compañeros o, cuando esté disponible, en un nodo separado dentro de la infraestructura del sitio. Además, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una caché de pares en espera para recibir páginas recuperadas por otros pares, emulando una caché central algo similar a una caché de proxy web regional. Desde el punto de vista del protocolo de coherencia de caché BuddyCache, sin embargo, un caché de compañero en espera es equivalente a un caché de compañero regular y, por lo tanto, no consideramos este caso por separado en la discusión de este documento. 4. En esta sección proporcionamos los detalles de la implementación de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en caché de estos objetos. Las aplicaciones se ejecutan en los clientes e interactúan con el sistema realizando llamadas a métodos de objetos en caché. Todas las llamadas a métodos ocurren dentro de transacciones atómicas. Los clientes se comunican con los servidores para obtener páginas o realizar una transacción. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volátil. El disco está organizado como una colección de páginas que son las unidades de acceso al disco. El registro estable guarda la información de confirmación y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de caché y una caché de objetos modificados recuperable llamada MOB. El directorio lleva un registro de qué páginas están almacenadas en caché por qué clientes. El MOB contiene objetos recientemente modificados que aún no han sido escritos de vuelta en sus páginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de caché base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la Sección 3.1. Proporcionamos algunos de los detalles relevantes de la implementación del protocolo OCC. El cliente lleva un registro de los objetos que son leídos y modificados por su transacción; envía esta información, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacción. Los servidores determinan si la confirmación es posible, utilizando un protocolo de confirmación de dos fases si la transacción utilizó objetos en múltiples servidores. Si la transacción se lleva a cabo, las nuevas copias de los objetos modificados se añaden al registro y también se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperación escaneando el registro. Dado que los objetos no están bloqueados antes de ser utilizados, una confirmación de transacción puede hacer que las cachés contengan objetos obsoletos. Los servidores abortarán una transacción que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviándoles mensajes de invalidación; un servidor utiliza su directorio y la información sobre la transacción de confirmación para determinar qué mensajes de invalidación enviar. Los mensajes de invalidación son pequeños porque simplemente identifican objetos obsoletos. Además, se envían en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidación, elimina los objetos obsoletos de su caché y aborta la transacción actual si los utilizó. El cliente sigue conservando páginas que contienen objetos invalidados; estas páginas ahora están incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidación de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener páginas incompletas en la caché del cliente significa que el falso intercambio no conduce a fallos innecesarios en la caché. Los clientes reconocen las invalidaciones para indicar la eliminación de datos obsoletos, como se explica en la Sección 3.1. Los mensajes de invalidación evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo así el desperdicio de trabajo y trasladando la detección de abortos de los servidores a los clientes. Cuando una transacción se aborta, su cliente restaura las copias en caché de los objetos modificados al estado que tenían antes de que la transacción comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacción. 4.3 Redirección El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de páginas disponibles en el grupo de pares y proporciona una redirección rápida y centralizada de recuperación (ver figura 2) entre las cachés de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan páginas u objetos al incluir esa información en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la caché de grupo, el redireccionador realiza un seguimiento del estado de las páginas. Una página en caché está completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una página están marcados como inválidos. Solo se utilizan páginas completas por el proceso de <br>recuperación de pares</br>. El protocolo para mantener el estado de la página cuando las páginas son actualizadas e invalidadas se describe en la Sección 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una página solicitada completa no está disponible en el grupo de pares o si un par necesita confirmar una transacción, el redireccionador actúa como un proxy de servidor: reenvía la solicitud al servidor y luego reenvía la respuesta de vuelta al cliente. Además, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualización o información de invalidación a los clientes que tienen en caché la página modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la caché de grupo de pares combinada está desempeñando el papel de una única caché de cliente en el sistema base. 4.4 Actualización de pares La actualización de pares se implementa de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que una transacción se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacción generan invalidaciones de objetos para cada grupo de caché que almacena páginas que contienen los objetos modificados (incluido el grupo que realiza la confirmación). Las invalidaciones se envían de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en caché los objetos modificados se deshagan de los datos obsoletos. En grupos de caché distintos al grupo de confirmación, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en caché las páginas modificadas, recopilan las confirmaciones de los clientes y, después de completar la recopilación, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacción, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envían a los clientes que almacenan en caché esas páginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmación colectiva se propaga al servidor. Una invalidación hace que una página en caché no esté disponible para la <br>recuperación de pares</br>, cambiando el estado de una página completa p a incompleta. Por el contrario, una actualización de una página completa conserva el estado completo de la página. Como se muestra en los estudios de la reconstrucción de fragmentos 31 [2], esta propagación de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la <br>recuperación entre pares</br>. Por lo tanto, el efecto de la actualización de pares es similar a la reconstrucción de fragmentos ansiosa [2]. También hemos considerado la posibilidad de permitir que un compañero recupere una página incompleta (con objetos inválidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos inválidos. 4.5 Vcache El protocolo de validación de confirmación en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo más lentos (o fallidos). Como se explica en la Sección 3.3, el protocolo de commit único permite que una transacción T pase la validación si la información adicional de coherencia proporcionada por el cliente indica que la transacción T ha leído objetos actualizados. Los clientes utilizan los números de versión de la página para proporcionar esta información adicional de coherencia. Es decir, un cliente incluye el número de versión de la página correspondiente a cada objeto en el conjunto de objetos leídos enviado en la solicitud de confirmación al servidor. Dado que a cada actualización de objeto comprometido le corresponde un número de versión de página único, el número de versión de página asociado con un objeto permite que el procedimiento de validación en el servidor verifique si la transacción del cliente ha leído objetos actualizados. El uso de versiones de página de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeños, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en caché a la versión de página identificadora (ObjectToVersion). El principal problema de implementación se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian números de versión de página con las invalidaciones. En el momento de la validación, si hay una invalidación no reconocida pendiente para un objeto x leído por una transacción T, el procedimiento de validación verifica si el número de versión de x en el conjunto de lectura de Ts coincide con el número de versión de la invalidación pendiente más alta para x, en cuyo caso el valor del objeto está actualizado, de lo contrario, T falla en la validación. Observamos nuevamente que las verificaciones basadas en el número de versión de la página y las verificaciones basadas en el reconocimiento de invalidación son complementarias en la validación de confirmación individual y ambas son necesarias. La verificación del número de versión de la página permite que la validación avance antes de que lleguen las confirmaciones de invalidación, pero por sí sola, una verificación del número de versión de la página detecta conflictos a nivel de página y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cómo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un número de versión de la página para cada página en caché. El número de versión satisface la siguiente invariante V P sobre el estado de los objetos en una página: si una página en caché P tiene un número de versión v, entonces el valor de un objeto o en la página en caché P es inválido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacción que estableció el número de versión de P en v. Los nuevos valores de objetos y los nuevos números de versión de página llegan cuando un cliente obtiene una página o cuando llega una respuesta de confirmación o invalidaciones para esta página. Los nuevos valores del objeto modifican la página y, por lo tanto, el número de versión de la página necesita ser actualizado para mantener la invariante V P. Un número de versión de página que llega cuando un cliente obtiene una página, reemplaza la Versión del Objeto x 8 Servidor de Redirección 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el número de versión de la página para esta página. Tal actualización preserva el invariante V P. De manera similar, un número de versión de página en secuencia que llega al cliente en un mensaje de confirmación o invalidación avanza el número de versión para toda la página en caché, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus números de versión de página correspondientes también pueden llegar al cliente fuera de secuencia, en cuyo caso la actualización del número de versión de la página podría violar V P. Por ejemplo, una respuesta de confirmación para una transacción que actualiza el objeto x en la página P en el servidor S1, y el objeto y en la página Q en el servidor S2, puede entregar un nuevo número de versión para P desde el coordinador de transacciones S1 antes de que llegue una invalidación generada para una transacción anterior que ha modificado el objeto r en la página P desde S1 (como se muestra en la figura 5). El protocolo de actualización de caché garantiza que el valor de cualquier objeto o en una página en caché P refleje la actualización o invalidación con el número de versión observado más alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de números de versión de página, el cliente gestiona una pequeña caché de números de versión vcache que mantiene el mapeo de un objeto a su número de versión de página correspondiente para todas las actualizaciones de números de versión reordenadas hasta que se ensamble una secuencia completa de números de versión de página. Cuando llegan los números de versión faltantes para la página y completan una secuencia, el número de versión de toda la página se avanza. El mapeo de ObjectToVersion, incluyendo los números de versión de vcache y página, se utiliza en el momento de la confirmación de la transacción para proporcionar números de versión para el conjunto de objetos leídos de la siguiente manera. Si el objeto leído tiene una entrada en la vcache, su número de versión es igual al número de versión más alto en la vcache para este objeto. Si el objeto no está presente en la vcache, su número de versión es igual al número de versión de la página en caché que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la caché del cliente, incluyendo los números de versión de las páginas y la vcache. El cliente puede limitar el tamaño de la caché virtual según sea necesario, ya que volver a cargar una página elimina todos los números de versión de página reordenados de la caché virtual. Sin embargo, esperamos que la reorganización de números de versión sea poco común y, por lo tanto, esperamos que la vcache sea muy pequeña. 5. Un grupo de clientes contiene múltiples nodos de cliente y un objeto de página de versión redi32 VCache Cliente Caché Cliente Página Caché Figura 6: Mapa de Objeto a Versión con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutación por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. Además, el fallo del redireccionador debería permitir que los clientes no afectados mantengan sus cachés intactas. Hemos diseñado un protocolo de conmutación por error para BuddyCache pero aún no lo hemos implementado. El apéndice describe el protocolo. 6. La redirección de BuddyCache en la evaluación de rendimiento respalda los beneficios de evitar la comunicación con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes. ¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la <br>recuperación entre pares</br> y la actualización entre pares se deben a la evitación de interacciones con el servidor. ",
            "candidates": [],
            "error": [
                [
                    "búsqueda de pares",
                    "recuperación de pares",
                    "recuperación de pares",
                    "recuperación entre pares",
                    "recuperación entre pares"
                ]
            ]
        },
        "multi-user oo7 benchmark": {
            "translated_key": "multiusuario OO7",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the <br>multi-user oo7 benchmark</br> [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "Our workloads are based on the <br>multi-user oo7 benchmark</br> [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application."
            ],
            "translated_annotated_samples": [
                "Nuestras cargas de trabajo se basan en el benchmark <br>multiusuario OO7</br> [8]; este benchmark está diseñado para capturar las características de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicación específica."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la transacción se cancela. Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de búsqueda de pares envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados. Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente. El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente. El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños. Un objetivo importante del diseño de BuddyCache es mantener este beneficio. Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo. Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché. Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. Almacén x 6. Actualización x 3. Comprométete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes. Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente. Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una red de área amplia serían derrochadores. Sin embargo, los protocolos de coherencia basados en invalidación pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interés para otro miembro del grupo. Con un protocolo basado en invalidación, la actualización de un miembro invalidará la copia en caché de otro miembro, lo que provocará que este último realice una recuperación de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualización e invalidación en entornos de redes de área amplia. Evita la penalización de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalización de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusión localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en caché anteriores. La actualización entre pares funciona de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que la transacción se confirma, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación, y también propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmación. 3.3 Confirmación individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminación de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en caché transaccional, ya que un cliente que es lento para reconocer una invalidación o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacción. Por ejemplo, un ingeniero que realiza una revisión repetida al mismo objeto de diseño compartido (y por lo tanto tiene la última versión del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situación representada en la figura 4 donde el Cliente1 realiza una transacción T que lee la última versión de un objeto x en la página P recientemente modificada por el Cliente1. Si la solicitud de confirmación para T llega al servidor antes de que la confirmación colectiva de Cliente2 por la última modificación de x llegue al servidor, el procedimiento de validación de OCC considera que x está obsoleto y aborta T (porque, como se explicó anteriormente, una invalidación no reconocida por un cliente actúa como indicación para el servidor de que el valor del objeto en caché está obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la corrección del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asíncronas son una parte importante de la razón por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasión de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envían y procesan de forma asíncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devolución de llamada jerárquica [32], pero la naturaleza asincrónica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrónicas. El protocolo de validación de confirmación en solitario permite a un cliente con objetos actualizados confirmar una transacción incluso si la confirmación del grupo se retrasa debido a pares lentos o caídos. El protocolo requiere que los clientes incluyan información adicional con los conjuntos de lectura de transacciones en el mensaje de confirmación, para indicar al servidor que los objetos leídos por la transacción están actualizados. Los números de versión de los objetos podrían proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionó anteriormente, mantener números de versión por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaño de directorio) en todo el sistema de objetos cuando los objetos son pequeños [23]. En cambio, solo utiliza números de versión de página de grano grueso para identificar versiones de objetos de grano fino. El número de versión de una página se incrementa en un servidor cuando una transacción que modifica objetos en la página se confirma. Las actualizaciones realizadas por una única transacción y las invalidaciones correspondientes son identificadas de manera única por el número de versión de la página modificada. Los números de versión de la página se propagan a los clientes en respuestas de recuperación, respuestas de confirmación y con invalidaciones, y los clientes incluyen los números de versión de la página en las solicitudes de confirmación enviadas a los servidores. Si una transacción falla en la validación debido a la falta de reconocimiento de grupo, el servidor verifica los números de versión de página de los objetos en el conjunto de lectura de la transacción y permite que la transacción se confirme si el cliente ha leído desde la última versión de la página. Los números de versión de la página permiten confirmaciones independientes, pero las verificaciones de versión de página solo detectan conflictos a nivel de página. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes. Potencialmente, puede ser más rápido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podría ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en caché de pares de múltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en caché web, simplemente aumentar la población de clientes en una caché proxy a menudo aumenta la tasa general de aciertos en la caché [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacción explícita entre clientes y la colaboración, lo que sugiere que es poco probable que ocurra la recuperación entre grupos. Además, las mediciones de sistemas de almacenamiento en caché web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexión de red entre los grupos de pares sea muy rápida. Estamos principalmente interesados en entornos donde compañeros que colaboran estrechamente tienen una conectividad rápida a corta distancia, pero la conexión entre grupos de compañeros puede ser lenta. Como resultado, decidimos que el soporte para la recuperación entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compañeros con recursos heterogéneos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compañeros o, cuando esté disponible, en un nodo separado dentro de la infraestructura del sitio. Además, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una caché de pares en espera para recibir páginas recuperadas por otros pares, emulando una caché central algo similar a una caché de proxy web regional. Desde el punto de vista del protocolo de coherencia de caché BuddyCache, sin embargo, un caché de compañero en espera es equivalente a un caché de compañero regular y, por lo tanto, no consideramos este caso por separado en la discusión de este documento. 4. En esta sección proporcionamos los detalles de la implementación de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en caché de estos objetos. Las aplicaciones se ejecutan en los clientes e interactúan con el sistema realizando llamadas a métodos de objetos en caché. Todas las llamadas a métodos ocurren dentro de transacciones atómicas. Los clientes se comunican con los servidores para obtener páginas o realizar una transacción. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volátil. El disco está organizado como una colección de páginas que son las unidades de acceso al disco. El registro estable guarda la información de confirmación y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de caché y una caché de objetos modificados recuperable llamada MOB. El directorio lleva un registro de qué páginas están almacenadas en caché por qué clientes. El MOB contiene objetos recientemente modificados que aún no han sido escritos de vuelta en sus páginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de caché base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la Sección 3.1. Proporcionamos algunos de los detalles relevantes de la implementación del protocolo OCC. El cliente lleva un registro de los objetos que son leídos y modificados por su transacción; envía esta información, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacción. Los servidores determinan si la confirmación es posible, utilizando un protocolo de confirmación de dos fases si la transacción utilizó objetos en múltiples servidores. Si la transacción se lleva a cabo, las nuevas copias de los objetos modificados se añaden al registro y también se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperación escaneando el registro. Dado que los objetos no están bloqueados antes de ser utilizados, una confirmación de transacción puede hacer que las cachés contengan objetos obsoletos. Los servidores abortarán una transacción que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviándoles mensajes de invalidación; un servidor utiliza su directorio y la información sobre la transacción de confirmación para determinar qué mensajes de invalidación enviar. Los mensajes de invalidación son pequeños porque simplemente identifican objetos obsoletos. Además, se envían en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidación, elimina los objetos obsoletos de su caché y aborta la transacción actual si los utilizó. El cliente sigue conservando páginas que contienen objetos invalidados; estas páginas ahora están incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidación de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener páginas incompletas en la caché del cliente significa que el falso intercambio no conduce a fallos innecesarios en la caché. Los clientes reconocen las invalidaciones para indicar la eliminación de datos obsoletos, como se explica en la Sección 3.1. Los mensajes de invalidación evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo así el desperdicio de trabajo y trasladando la detección de abortos de los servidores a los clientes. Cuando una transacción se aborta, su cliente restaura las copias en caché de los objetos modificados al estado que tenían antes de que la transacción comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacción. 4.3 Redirección El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de páginas disponibles en el grupo de pares y proporciona una redirección rápida y centralizada de recuperación (ver figura 2) entre las cachés de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan páginas u objetos al incluir esa información en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la caché de grupo, el redireccionador realiza un seguimiento del estado de las páginas. Una página en caché está completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una página están marcados como inválidos. Solo se utilizan páginas completas por el proceso de recuperación de pares. El protocolo para mantener el estado de la página cuando las páginas son actualizadas e invalidadas se describe en la Sección 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una página solicitada completa no está disponible en el grupo de pares o si un par necesita confirmar una transacción, el redireccionador actúa como un proxy de servidor: reenvía la solicitud al servidor y luego reenvía la respuesta de vuelta al cliente. Además, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualización o información de invalidación a los clientes que tienen en caché la página modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la caché de grupo de pares combinada está desempeñando el papel de una única caché de cliente en el sistema base. 4.4 Actualización de pares La actualización de pares se implementa de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que una transacción se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacción generan invalidaciones de objetos para cada grupo de caché que almacena páginas que contienen los objetos modificados (incluido el grupo que realiza la confirmación). Las invalidaciones se envían de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en caché los objetos modificados se deshagan de los datos obsoletos. En grupos de caché distintos al grupo de confirmación, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en caché las páginas modificadas, recopilan las confirmaciones de los clientes y, después de completar la recopilación, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacción, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envían a los clientes que almacenan en caché esas páginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmación colectiva se propaga al servidor. Una invalidación hace que una página en caché no esté disponible para la recuperación de pares, cambiando el estado de una página completa p a incompleta. Por el contrario, una actualización de una página completa conserva el estado completo de la página. Como se muestra en los estudios de la reconstrucción de fragmentos 31 [2], esta propagación de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la recuperación entre pares. Por lo tanto, el efecto de la actualización de pares es similar a la reconstrucción de fragmentos ansiosa [2]. También hemos considerado la posibilidad de permitir que un compañero recupere una página incompleta (con objetos inválidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos inválidos. 4.5 Vcache El protocolo de validación de confirmación en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo más lentos (o fallidos). Como se explica en la Sección 3.3, el protocolo de commit único permite que una transacción T pase la validación si la información adicional de coherencia proporcionada por el cliente indica que la transacción T ha leído objetos actualizados. Los clientes utilizan los números de versión de la página para proporcionar esta información adicional de coherencia. Es decir, un cliente incluye el número de versión de la página correspondiente a cada objeto en el conjunto de objetos leídos enviado en la solicitud de confirmación al servidor. Dado que a cada actualización de objeto comprometido le corresponde un número de versión de página único, el número de versión de página asociado con un objeto permite que el procedimiento de validación en el servidor verifique si la transacción del cliente ha leído objetos actualizados. El uso de versiones de página de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeños, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en caché a la versión de página identificadora (ObjectToVersion). El principal problema de implementación se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian números de versión de página con las invalidaciones. En el momento de la validación, si hay una invalidación no reconocida pendiente para un objeto x leído por una transacción T, el procedimiento de validación verifica si el número de versión de x en el conjunto de lectura de Ts coincide con el número de versión de la invalidación pendiente más alta para x, en cuyo caso el valor del objeto está actualizado, de lo contrario, T falla en la validación. Observamos nuevamente que las verificaciones basadas en el número de versión de la página y las verificaciones basadas en el reconocimiento de invalidación son complementarias en la validación de confirmación individual y ambas son necesarias. La verificación del número de versión de la página permite que la validación avance antes de que lleguen las confirmaciones de invalidación, pero por sí sola, una verificación del número de versión de la página detecta conflictos a nivel de página y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cómo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un número de versión de la página para cada página en caché. El número de versión satisface la siguiente invariante V P sobre el estado de los objetos en una página: si una página en caché P tiene un número de versión v, entonces el valor de un objeto o en la página en caché P es inválido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacción que estableció el número de versión de P en v. Los nuevos valores de objetos y los nuevos números de versión de página llegan cuando un cliente obtiene una página o cuando llega una respuesta de confirmación o invalidaciones para esta página. Los nuevos valores del objeto modifican la página y, por lo tanto, el número de versión de la página necesita ser actualizado para mantener la invariante V P. Un número de versión de página que llega cuando un cliente obtiene una página, reemplaza la Versión del Objeto x 8 Servidor de Redirección 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el número de versión de la página para esta página. Tal actualización preserva el invariante V P. De manera similar, un número de versión de página en secuencia que llega al cliente en un mensaje de confirmación o invalidación avanza el número de versión para toda la página en caché, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus números de versión de página correspondientes también pueden llegar al cliente fuera de secuencia, en cuyo caso la actualización del número de versión de la página podría violar V P. Por ejemplo, una respuesta de confirmación para una transacción que actualiza el objeto x en la página P en el servidor S1, y el objeto y en la página Q en el servidor S2, puede entregar un nuevo número de versión para P desde el coordinador de transacciones S1 antes de que llegue una invalidación generada para una transacción anterior que ha modificado el objeto r en la página P desde S1 (como se muestra en la figura 5). El protocolo de actualización de caché garantiza que el valor de cualquier objeto o en una página en caché P refleje la actualización o invalidación con el número de versión observado más alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de números de versión de página, el cliente gestiona una pequeña caché de números de versión vcache que mantiene el mapeo de un objeto a su número de versión de página correspondiente para todas las actualizaciones de números de versión reordenadas hasta que se ensamble una secuencia completa de números de versión de página. Cuando llegan los números de versión faltantes para la página y completan una secuencia, el número de versión de toda la página se avanza. El mapeo de ObjectToVersion, incluyendo los números de versión de vcache y página, se utiliza en el momento de la confirmación de la transacción para proporcionar números de versión para el conjunto de objetos leídos de la siguiente manera. Si el objeto leído tiene una entrada en la vcache, su número de versión es igual al número de versión más alto en la vcache para este objeto. Si el objeto no está presente en la vcache, su número de versión es igual al número de versión de la página en caché que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la caché del cliente, incluyendo los números de versión de las páginas y la vcache. El cliente puede limitar el tamaño de la caché virtual según sea necesario, ya que volver a cargar una página elimina todos los números de versión de página reordenados de la caché virtual. Sin embargo, esperamos que la reorganización de números de versión sea poco común y, por lo tanto, esperamos que la vcache sea muy pequeña. 5. Un grupo de clientes contiene múltiples nodos de cliente y un objeto de página de versión redi32 VCache Cliente Caché Cliente Página Caché Figura 6: Mapa de Objeto a Versión con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutación por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. Además, el fallo del redireccionador debería permitir que los clientes no afectados mantengan sus cachés intactas. Hemos diseñado un protocolo de conmutación por error para BuddyCache pero aún no lo hemos implementado. El apéndice describe el protocolo. 6. La redirección de BuddyCache en la evaluación de rendimiento respalda los beneficios de evitar la comunicación con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes. ¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la recuperación entre pares y la actualización entre pares se deben a la evitación de interacciones con el servidor. Esta sección presenta un modelo de rendimiento analítico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la caché del cliente. Estos pueden ser fallos fríos, fallos de invalidación y fallos de capacidad. Nuestro análisis se centra en los fallos por frío y los fallos por invalidación, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frío. Además, las tendencias tecnológicas indican que la capacidad de memoria y almacenamiento seguirá creciendo y, por lo tanto, es probable que una configuración típica de BuddyCache no esté limitada por la caché. Los fallos de caché del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuración de caché. Nuestro análisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validación. Para estudiar el beneficio de evitar fallos en frío, consideramos el rendimiento de la caché en frío en una carga de trabajo de solo lectura (sin fallos de invalidación). Esperamos que la recuperación entre pares mejore el costo de latencia para las solicitudes de caché fría del cliente al recuperar objetos de la caché cercana. Evaluamos cómo el costo de redirección afecta este beneficio al comparar y analizar el rendimiento de una aplicación que se ejecuta en un sistema de almacenamiento con BuddyCache y sin él (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidación, consideramos el rendimiento de la caché caliente en una carga de trabajo con modificaciones (sin fallos en frío). En las cachés calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualización entre pares permite que un cliente acceda a un objeto modificado por un compañero colaborador cercano sin el retraso impuesto por los protocolos de invalidación únicamente. En grupos donde los compañeros comparten un interés de solo lectura en los objetos modificados, la recuperación entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compañero colaborador lo tenga, lo que evita el retraso de la recuperación del servidor sin el alto costo impuesto por los protocolos de solo actualización. Las tendencias tecnológicas indican que ambos beneficios seguirán siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualización únicamente. Sin embargo, la tendencia hacia cachés cada vez más grandes, que se actualizan cuando los objetos en caché son modificados, hace que los protocolos basados en invalidación sean más atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicación que se ejecuta sin BuddyCache y una aplicación que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compañero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compañero fuera del grupo. La actualización entre pares también puede evitar fallos de invalidación debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma página de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseño del objeto, y también porque este beneficio se puede derivar dado el índice de aciertos en caché y la contención de la carga de trabajo. 6.1.1 El Modelo El modelo considera cómo el tiempo para completar una ejecución con y sin BuddyCache se ve afectado por los fallos de invalidación y los fallos en frío. Considerando k clientes ejecutándose concurrentemente accediendo de manera uniforme a un conjunto compartido de N páginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacción y realizar cálculos en una transacción, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin él (Base). Para simplificar, nuestro modelo asume que los tiempos de búsqueda y confirmación son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del número total de clientes en el sistema. El número de fallos evitados por la recuperación entre pares depende de k, el número de clientes en la BuddyCache, y del interés conjunto de los clientes en los datos compartidos. En una ejecución específica de BuddyCache, se modela mediante la variable r, definida como el número de solicitudes que llegan al redireccionador para una versión dada de la página P (es decir, hasta que un objeto en la página se invalida). Considera una ejecución con fallos en frío. Un cliente comienza con una caché fría y ejecuta una carga de trabajo de solo lectura hasta que accede a las N páginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la caché del cliente es lo suficientemente grande como para contener N páginas. En BC, los fríos fallos para la página P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consideremos a continuación una ejecución con fallos de invalidación. Un cliente comienza con una caché caliente que contiene el conjunto de trabajo de N páginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualización entre pares elimina todos los fallos de invalidación. En un grupo que contiene solo lectores (BCR), durante una ejecución en estado estable con actualizaciones uniformes, una transacción del cliente tiene fallos de invalidación faltantes. Considera la secuencia de r fallos de cliente en la página P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la página P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frío, r ≤ k porque la segunda invalidación deshabilita la redirección para P hasta que el próximo fallo en P provoque una recuperación del servidor. Suponiendo un acceso uniforme, un fallo de invalidación del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperación del servidor), y una probabilidad de (1 − 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacción única en los sistemas Base, BCR y BCW. En los experimentos descritos a continuación, medimos los parámetros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalización derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalización y beneficios medidos directamente en los experimentos. 6.2 Configuración Experimental Antes de presentar nuestros resultados, describimos nuestra configuración experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectándose directamente a los servidores. El sistema Buddy ejecuta nuestra implementación del prototipo de BuddyCache en Thor, admitiendo la recuperación de pares, la actualización de pares y la confirmación en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark <br>multiusuario OO7</br> [8]; este benchmark está diseñado para capturar las características de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicación específica. Utilizamos OO7 porque es un punto de referencia estándar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un árbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un gráfico de partes atómicas vinculadas por objetos de conexión; cada parte atómica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atómicas por parte compuesta. La base de datos multiusuario asigna a cada cliente un módulo privado que consiste en un árbol de objetos de ensamblaje, y agrega un módulo compartido adicional que escala proporcionalmente al número de clientes. Esperamos que una configuración típica de BuddyCache no esté limitada por la caché y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la caché. Dado que el objetivo de nuestro estudio es evaluar qué tan efectivamente nuestras técnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras técnicas tienen en los fallos de caché frío y de consistencia de caché, y aislar tanto como sea posible el efecto de los fallos de capacidad de caché. Para mantener la duración de nuestros experimentos razonable, utilizamos cachés pequeños. El benchmark OO7 genera módulos de base de datos de tamaño predefinido. En nuestra implementación de OO7, el tamaño del módulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la caché, utilizamos un único módulo privado y elegimos un tamaño de caché de 40MB para cada cliente. La base de datos OO7 se genera con módulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos están agrupados en páginas de 8K, que también son la unidad de transferencia en las solicitudes de recuperación. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro análisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idéntico a T1 excepto que modifica todas las partes atómicas en un solo compuesto. Una transacción única incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo módulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacción, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de búsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una caché de 50MB (de los cuales 6MB se utilizaron para el búfer de objetos modificados), el cliente tenía una caché de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos básicos Esta sección analiza el costo básico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 Redirección Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtención del servidor), el costo adicional de la redirección incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperación o confirmación del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmación y recuperación del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de área rápida. Todos los números fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirección al cruzar el redireccionador no es muy alto, incluso en una red de área local. El costo de la confirmación aumenta con el número de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperación no aumenta tanto porque la caché del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la caché del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperación entre pares, medimos la latencia de la recuperación entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperación entre pares, el costo de la redirección incluye, además del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este último incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la página solicitada. Medimos directamente el tiempo para copiar y desenrollar la página solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperación de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador más un viaje de ida y vuelta a través de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud más un viaje de ida y vuelta a través de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando está bloqueado esperando una respuesta de búsqueda o confirmación. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podría ser mitigado por una implementación multi-hilo en un sistema con programación preemptiva. 6.3.2 Versión de Caché El commit en solitario permite que un cliente rápido que modifica un objeto haga un commit de forma independiente a un compañero lento. El mecanismo de confirmación única introduce un procesamiento adicional en el servidor durante la validación de la transacción, y un procesamiento adicional en el cliente durante la confirmación de la transacción y en el momento del procesamiento de actualización o invalidación. Los gastos generales del lado del servidor son mínimos y consisten en una actualización del número de versión de la página en el momento de la confirmación, y una comparación del número de versión en el momento de la validación de la transacción. La caché de versión tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacción accede a objetos en múltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor único y, por lo tanto, el tiempo de confirmación adicional de la gestión de la caché de versiones en el cliente no contribuye a los resultados presentados en la sección a continuación. Para medir estos costos adicionales del lado del cliente en un sistema de múltiples servidores, instrumentamos la implementación de la caché de versiones para ejecutarse con una traza de carga de trabajo que incluía invalidaciones reordenadas y cronometramos las operaciones básicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operación de búsqueda de caché de versión para cada objeto leído por la transacción en el momento de preparación de la solicitud de compromiso, y una operación de inserción de caché de versión para cada objeto actualizado por una transacción en el momento de procesamiento de la respuesta de compromiso, pero solo si la página actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmación se mantengan al mínimo, ya que el cliente está esperando de forma síncrona la finalización de la confirmación. Las mediciones muestran que en el peor de los casos, cuando llega un gran número de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en páginas reordenadas, el costo de actualizar la caché de versión es de 0.6 ms. El costo de tiempo de invalidación es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementación de la caché de versiones para reducir aún más estos costos. 6.4 Rendimiento general Esta sección examina las mejoras de rendimiento observadas por una aplicación que ejecuta el benchmark OO7 con un BuddyCache en una red de área amplia. 6.4.1 Fallos en frío Para evaluar las mejoras de rendimiento al evitar fallos en frío, comparamos el rendimiento de la caché en frío del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecución de los sistemas en el entorno de la red de área local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de área amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en caché fría. Los números fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frío solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frío solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparación con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cálculos para el cliente, solicitudes de recuperación directa, recuperaciones de pares y solicitudes de confirmación. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperación entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperación del servidor para cada cliente individual disminuye porque, con más clientes accediendo a un módulo compartido de tamaño fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperación de pares en comparación con la recuperación directa, pero este beneficio se ve contrarrestado por los tiempos de confirmación aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relación con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de caché 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT función de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias típicas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Sorprendentemente, los resultados analíticos predicen la mejora medida muy de cerca, aunque son ligeramente más altos que los valores empíricos. La razón principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidación evitados, comparamos el rendimiento de caché caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interés de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un único cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compañeros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compañeros con un grupo que contiene un único escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuración simple es suficiente para mostrar el impacto de las técnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de caché caliente de OO7. Obtenemos los números ejecutando 2000 transacciones para filtrar los fallos en frío y luego medimos el tiempo de las siguientes 1000 transacciones. Aquí nuevamente, los números reportados se derivan de los resultados del experimento de la red de área local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalización en comparación con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparación con la Base. Este beneficio se debe a la actualización entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperación entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperación local evitando el retraso de la recuperación desde el servidor. El último es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperación de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperación de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualización de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relación con Base, y Buddy Writer y Base en relación con Base) en un experimento de caché activa en función del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualización entre pares domina el gasto general en la configuración de Writer incluso en redes de baja latencia (la actualización entre pares incurre en un gasto mínimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Como en experimentos de caché fría, aquí los resultados analíticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pérdida de invalidación es mínimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de caché fría). Como en el caso de caché fría, la razón por la que el modelo analítico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÓN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en una red de área extensa debido a la alta latencia de red. Este artículo describe BuddyCache, una nueva técnica de almacenamiento en caché cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La técnica mejora el rendimiento y proporciona propiedades sólidas de corrección y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirección para obtener objetos faltantes directamente de las cachés de los miembros del grupo, y para admitir la actualización entre pares, una nueva técnica de multidifusión a nivel de aplicación ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirección puede interferir con la disponibilidad del objeto. Solo commit es una nueva técnica de validación que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validación detallada utilizando información de versión de grano grueso económica. Hemos diseñado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analíticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Las principales contribuciones del artículo son: 1. extender las técnicas de almacenamiento en caché cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementación del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluación del rendimiento basada en análisis y mediciones de los costos y beneficios de las nuevas técnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. También agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios útiles que mejoraron este artículo. 9. REFERENCIAS [1] emulab.net, la Instalación de Emulación de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. Reconstrucción de fragmentos: Proporcionando coherencia de caché global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de Computación Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre Gestión de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: Computación en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de caché híbridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. Recuperación rápida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de caché en la World Wide Web. En la 17ª Conferencia Internacional sobre Sistemas de Computación Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluación del rendimiento del sistema de gestión de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una caché de objetos jerárquica en Internet. En la Conferencia Técnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachés de Internet escalables. Informe Técnico CS-1997-18, Departamento de Ciencias de la Computación, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: Caché de proxy cooperativa en una red de área amplia. En el Tercer Taller Internacional de Caché de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. Caché web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2º Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. Caché cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilación y en tiempo de ejecución para una memoria compartida distribuida eficiente. En Actas de IEEE, Edición Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la caché: un protocolo de intercambio de caché web escalable de área amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. Implementación de Gestión Global de Memoria en un Clúster de Estaciones de Trabajo. Actas del 15º Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: Diseño, Implementación y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de caché transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, páginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. Gestión global de memoria para arquitecturas de sistemas de gestión de bases de datos cliente-servidor. En Actas del 19º Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El Búfer de Objeto Modificado: Una Técnica de Gestión de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto Tecnológico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. Gestión de documentos replicados en un sistema de comunicación grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13ª Conferencia Europea sobre Programación Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18º Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. Replicación con marca de vista: un nuevo método de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de Computación Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalación eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de Multidifusión a Nivel de Aplicación. En el 3er Simposio USENIX sobre Tecnologías y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de caché cooperativa utilizando pistas. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en Caché Global. Informe técnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del Caché de Proxies Web Cooperativos. En el 17º Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerárquica de caché en una WAN. En el Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. Compartición adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÉNDICE Este apéndice describe el protocolo de conmutación por error de BuddyCache. Para dar cabida a clientes heterogéneos, incluidos los dispositivos portátiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseño de BuddyCache asume que las cachés del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresía detecta el fallo de un cliente o un redireccionador intercambiando mensajes periódicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutación por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuración y reinicia el protocolo. El protocolo de reconfiguración del grupo es similar al presentado en [25]. Aquí describimos cómo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de páginas redireccionadas y el reenvío de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachés. En caso de un fallo del cliente, el failover elimina las páginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmación, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en caché las páginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutación por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de páginas utilizando un protocolo similar al descrito en [6]. El redireccionador recién reiniciado solicita a los miembros activos del grupo la lista de páginas que están almacenando en caché y el estado de estas páginas, es decir, si las páginas están completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperación perdida expirará en el cliente y será retransmitida. Una transacción que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma después del cambio se trata como una transacción regular; una transacción que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciará la transacción y la solicitud de confirmación será retransmitida después del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caído podrían evitar la recolección de basura de las invalidaciones pendientes en los servidores o la caché virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los números de versión únicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validación de transacciones depende del protocolo de coherencia de caché para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutación por error de BuddyCache no compromete la corrección del procedimiento de validación. Recuerda que la validación de transacciones de BuddyCache utiliza dos mecanismos complementarios, números de versión de página y confirmaciones de invalidación de los clientes, para verificar que una transacción ha leído datos actualizados. La propagación de la confirmación de invalidación (y actualización) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmación de una modificación (invalidación o actualización) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en caché el objeto o bien ha instalado el valor más reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmación de un cliente para una transacción T que lee un objeto o después de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidación no confirmada para o pendiente para este grupo, la versión del objeto leída por la transacción T está actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validación utilizando números de versión. El registro de confirmación de transacción contiene un número de versión para cada objeto leído por la transacción. El protocolo de número de versión mantiene la invariante V P que garantiza que el valor del objeto o leído por la transacción corresponda al número de versión más alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificación anterior después de haber recibido una modificación posterior. La retransmisión de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validación verifica que el número de versión en el registro de confirmación coincida con el número de versión en la invalidación pendiente no reconocida. Es fácil ver que, dado que esta comprobación es una comprobación cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutación por error aún no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "cooperative cache": {
            "translated_key": "caché cooperativo",
            "is_in_text": false,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "fine-grain share": {
            "translated_key": "participación detallada",
            "is_in_text": false,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "fault-tolerance": {
            "translated_key": "tolerancia a fallos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN ∗ Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and <br>fault-tolerance</br> properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and <br>fault-tolerance</br> properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oﬄoading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r − 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r − 1 subsequent misses are redirected.",
                "Unlike with cold misses, r ≤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 − 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv ∗ tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv ∗ ( 1 r ∗ tfetch(BCR) +(1 − 1 r ) ∗ tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "BuddyCache redirector supports the correctness, availability and <br>fault-tolerance</br> properties of transactional caching protocol [19].",
                "The availability and <br>fault-tolerance</br> properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects."
            ],
            "translated_annotated_samples": [
                "El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y <br>tolerancia a fallos</br> del protocolo de almacenamiento en caché transaccional [19].",
                "Las propiedades de disponibilidad y <br>tolerancia a fallos</br> garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN ∗ Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la Computación Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en redes de área extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en caché transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafío es mejorar el rendimiento al tiempo que se proporcionan las propiedades de corrección y disponibilidad de un protocolo de almacenamiento en caché transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analíticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias típicas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con acceder directamente a los servidores remotos. Categorías y Descriptores de Asignaturas C.2.4 [Organización de Sistemas Informáticos]: Sistemas Distribuidos Términos Generales Diseño, Rendimiento 1. INTRODUCCIÓN Las mejoras en la conectividad de redes erosionan la distinción entre la computación local y de área amplia y, cada vez más, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de área amplia. Los problemas de ancho de banda de la red mejorarán en un futuro previsible, pero la mejora en la latencia de la red está fundamentalmente limitada. BuddyCache es una nueva técnica de almacenamiento en caché de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de área amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea común, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcción. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a través de redes de área amplia, ya que el rendimiento sería inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de área amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de área amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia más débil. Adaptar una aplicación para utilizar un sistema de almacenamiento de consistencia débil requiere un esfuerzo significativo, ya que la aplicación necesita ser reescrita para manejar la semántica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podría abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en caché web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacción del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinación especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difíciles, a saber, determinar qué objetos están almacenados en qué lugar, se vuelve fácil en grupos pequeños típicos de entornos colaborativos. Sin embargo, las técnicas de almacenamiento en caché web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en caché de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacción con el servidor para proporcionar coherencia de caché de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma página física. La interacción con el servidor aumenta la latencia. La contribución de este trabajo es extender las técnicas de almacenamiento en caché cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de área amplia. Considera un equipo de ingenieros empleados por una empresa de construcción supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcción. Los ingenieros utilizan una aplicación CAD colaborativa para revisar y actualizar documentos de diseño de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo están interconectadas por un Ethernet local rápido, pero la conexión de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachés de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicación colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sí, conectados a un repositorio de almacenamiento a través de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o información de coherencia están disponibles en algún cliente del grupo. BuddyCache presenta dos desafíos técnicos principales. Uno de los desafíos es cómo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en caché. El otro desafío es mantener la coherencia de caché de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirección similar al utilizado en sistemas de almacenamiento en caché web cooperativos [11]. Un servidor de redirección, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes también lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en caché. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interés potencial para todos los miembros del grupo. BuddyCache utiliza la redirección para admitir la actualización entre pares, una técnica de multidifusión a nivel de aplicación ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirección interfiere con la disponibilidad de objetos compartidos. Solo commit, es una técnica de validación utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una característica destacada de la confirmación individual es el soporte de validación detallada utilizando información de coherencia de grano grueso económica. Dado que la redirección respalda los beneficios de rendimiento al reducir la interacción con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes, surge la pregunta: ¿es peor el remedio que la enfermedad? Diseñamos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analítico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cómo la relación costo-beneficio se ve afectada por la latencia de red. Los resultados analíticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Estos sólidos avances en el rendimiento podrían hacer que los sistemas de almacenamiento de objetos transaccionales sean más atractivos para aplicaciones colaborativas en entornos de área amplia. El trabajo relacionado Las técnicas de almacenamiento en caché cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachés de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de área local rápida. Estas técnicas utilizan el servidor para proporcionar redirección y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan técnicas de coherencia de grano fino para evitar la penalización de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las técnicas de almacenamiento en caché web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachés proxy cercanas en un entorno de área amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la caché. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo híbrido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepción confiable, explotando la localidad de una manera similar a BuddyCache. Esta solución de nivel de transporte multicast está diseñada para la semántica de escritura única de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicación y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La solución de multidifusión a nivel de aplicación en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeños de múltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni compartición detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerárquico de coherencia de caché en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachés cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulación para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerárquica basado en la evitación. Por el contrario, nuestro trabajo utiliza la implementación y el análisis para evaluar los costos y beneficios de la redirección y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusión en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota métodos específicos de aplicación, por ejemplo, la política de último escritor en aplicaciones de difusión, para manejar actualizaciones concurrentes pero está limitado a sistemas de archivos. Mazieres estudia una técnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a través de una WAN cuando los fragmentos están disponibles en una caché local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos están disponibles en la caché de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalización de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de área amplia. Esta sección describe el enfoque de BuddyCache para reducir la penalización de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseño. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizás subcontratados en centros de datos conectados a través de redes confiables de alta velocidad. Clientes colaboradores interconectados a través de una red local rápida se conectan a los servidores en los centros de datos a través de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un único servidor. Los objetos pueden ser pequeños (del orden de 100 bytes para objetos de lenguajes de programación [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en páginas físicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en caché para acceder a ellos localmente. Un protocolo de coherencia de caché transaccional se ejecuta en clientes y servidores para garantizar que las cachés de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirección de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la función de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacción con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envía a un servidor remoto. El enfoque de redirección se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en caché web. El redireccionador de BuddyCache admite las propiedades de corrección, disponibilidad y <br>tolerancia a fallos</br> del protocolo de almacenamiento en caché transaccional [19]. La propiedad de corrección garantiza la serialización de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y <br>tolerancia a fallos</br> garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en caché transaccional son la confirmación de una transacción, la recuperación de un objeto faltante en la caché del cliente y el intercambio de información de coherencia de caché. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la información de coherencia de caché necesaria por un cliente está disponible dentro del grupo colaborador. El redireccionador siempre interactúa con los servidores en el momento de la confirmación porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la caché El redireccionador mantiene un directorio de páginas almacenadas en caché en cada cliente para proporcionar una caché cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperación de un cliente a otro cliente que almacena en caché el objeto solicitado. Además, el redireccionador gestiona la coherencia de la caché. Varios protocolos eficientes de coherencia de caché transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la caché. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de página cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de página). La taxonomía de almacenamiento en caché transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorías principales según si un protocolo evita o detecta el acceso a objetos obsoletos en la caché del cliente. El enfoque BuddyCache podría aplicarse a ambas categorías con diferentes costos de rendimiento y beneficios en cada categoría. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detección de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y teníamos acceso a la implementación. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitación de mejor rendimiento. A continuación, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la página que lo contiene. La transacción puede leer y actualizar objetos almacenados en caché localmente sin intervención del servidor. Sin embargo, antes de que una transacción se confirme, debe ser validada; el servidor debe asegurarse de que la transacción validadora no haya leído una versión obsoleta de algún objeto que fue actualizado por una transacción exitosamente confirmada o validada. Si la validación falla, la transacción se cancela. Para reducir el número y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de búsqueda de pares envía mensajes de invalidación de objetos en segundo plano a los clientes que almacenan en caché las páginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la caché y envían confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la caché del cliente, la confirmación de invalidación indica al servidor que un cliente sin invalidaciones pendientes ha leído objetos actualizados. Una invalidación no reconocida indica que un objeto obsoleto puede haber sido accedido en la caché del cliente. El procedimiento de validación en el servidor aborta una transacción del cliente si este lee un objeto mientras hay una invalidación pendiente. El mecanismo de invalidación reconocido admite coherencia de caché a nivel de objeto sin directorios basados en objetos o números de versión por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeños, ya que los objetos típicos son pequeños. Un objetivo importante del diseño de BuddyCache es mantener este beneficio. Dado que en BuddyCache una página puede ser recuperada en una caché de cliente sin intervención del servidor (como se ilustra en la figura 2), los directorios de caché en los servidores llevan un registro de las páginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las páginas almacenadas en caché en cada cliente de un grupo. Los servidores envían al redireccionador invalidaciones para las páginas almacenadas en caché en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. Actualización de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en caché por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interés potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de caché y las actualizaciones de caché. Los estudios de coherencia de caché en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualización y la invalidación. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. Almacén x 6. Actualización x 3. Comprométete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares están fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeñas, agrupadas y se envían junto con otros mensajes. Además, los protocolos de invalidación se ajustan a la tendencia actual de hardware de aumentar los tamaños de caché del cliente. Es probable que las cachés más grandes contengan mucha más información de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interés en una red de área amplia serían derrochadores. Sin embargo, los protocolos de coherencia basados en invalidación pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interés para otro miembro del grupo. Con un protocolo basado en invalidación, la actualización de un miembro invalidará la copia en caché de otro miembro, lo que provocará que este último realice una recuperación de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualización e invalidación en entornos de redes de área amplia. Evita la penalización de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalización de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusión localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en caché anteriores. La actualización entre pares funciona de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que la transacción se confirma, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación, y también propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmación. 3.3 Confirmación individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminación de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en caché transaccional, ya que un cliente que es lento para reconocer una invalidación o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacción. Por ejemplo, un ingeniero que realiza una revisión repetida al mismo objeto de diseño compartido (y por lo tanto tiene la última versión del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situación representada en la figura 4 donde el Cliente1 realiza una transacción T que lee la última versión de un objeto x en la página P recientemente modificada por el Cliente1. Si la solicitud de confirmación para T llega al servidor antes de que la confirmación colectiva de Cliente2 por la última modificación de x llegue al servidor, el procedimiento de validación de OCC considera que x está obsoleto y aborta T (porque, como se explicó anteriormente, una invalidación no reconocida por un cliente actúa como indicación para el servidor de que el valor del objeto en caché está obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la corrección del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asíncronas son una parte importante de la razón por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasión de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envían y procesan de forma asíncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devolución de llamada jerárquica [32], pero la naturaleza asincrónica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrónicas. El protocolo de validación de confirmación en solitario permite a un cliente con objetos actualizados confirmar una transacción incluso si la confirmación del grupo se retrasa debido a pares lentos o caídos. El protocolo requiere que los clientes incluyan información adicional con los conjuntos de lectura de transacciones en el mensaje de confirmación, para indicar al servidor que los objetos leídos por la transacción están actualizados. Los números de versión de los objetos podrían proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionó anteriormente, mantener números de versión por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaño de directorio) en todo el sistema de objetos cuando los objetos son pequeños [23]. En cambio, solo utiliza números de versión de página de grano grueso para identificar versiones de objetos de grano fino. El número de versión de una página se incrementa en un servidor cuando una transacción que modifica objetos en la página se confirma. Las actualizaciones realizadas por una única transacción y las invalidaciones correspondientes son identificadas de manera única por el número de versión de la página modificada. Los números de versión de la página se propagan a los clientes en respuestas de recuperación, respuestas de confirmación y con invalidaciones, y los clientes incluyen los números de versión de la página en las solicitudes de confirmación enviadas a los servidores. Si una transacción falla en la validación debido a la falta de reconocimiento de grupo, el servidor verifica los números de versión de página de los objetos en el conjunto de lectura de la transacción y permite que la transacción se confirme si el cliente ha leído desde la última versión de la página. Los números de versión de la página permiten confirmaciones independientes, pero las verificaciones de versión de página solo detectan conflictos a nivel de página. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La sección 4 describe los detalles de la implementación del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 Configuración de Grupo La arquitectura BuddyCache admite múltiples grupos de pares concurrentes. Potencialmente, puede ser más rápido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podría ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en caché de pares de múltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en caché web, simplemente aumentar la población de clientes en una caché proxy a menudo aumenta la tasa general de aciertos en la caché [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacción explícita entre clientes y la colaboración, lo que sugiere que es poco probable que ocurra la recuperación entre grupos. Además, las mediciones de sistemas de almacenamiento en caché web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexión de red entre los grupos de pares sea muy rápida. Estamos principalmente interesados en entornos donde compañeros que colaboran estrechamente tienen una conectividad rápida a corta distancia, pero la conexión entre grupos de compañeros puede ser lenta. Como resultado, decidimos que el soporte para la recuperación entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compañeros con recursos heterogéneos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compañeros o, cuando esté disponible, en un nodo separado dentro de la infraestructura del sitio. Además, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una caché de pares en espera para recibir páginas recuperadas por otros pares, emulando una caché central algo similar a una caché de proxy web regional. Desde el punto de vista del protocolo de coherencia de caché BuddyCache, sin embargo, un caché de compañero en espera es equivalente a un caché de compañero regular y, por lo tanto, no consideramos este caso por separado en la discusión de este documento. 4. En esta sección proporcionamos los detalles de la implementación de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en caché de estos objetos. Las aplicaciones se ejecutan en los clientes e interactúan con el sistema realizando llamadas a métodos de objetos en caché. Todas las llamadas a métodos ocurren dentro de transacciones atómicas. Los clientes se comunican con los servidores para obtener páginas o realizar una transacción. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volátil. El disco está organizado como una colección de páginas que son las unidades de acceso al disco. El registro estable guarda la información de confirmación y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de caché y una caché de objetos modificados recuperable llamada MOB. El directorio lleva un registro de qué páginas están almacenadas en caché por qué clientes. El MOB contiene objetos recientemente modificados que aún no han sido escritos de vuelta en sus páginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de caché base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la Sección 3.1. Proporcionamos algunos de los detalles relevantes de la implementación del protocolo OCC. El cliente lleva un registro de los objetos que son leídos y modificados por su transacción; envía esta información, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacción. Los servidores determinan si la confirmación es posible, utilizando un protocolo de confirmación de dos fases si la transacción utilizó objetos en múltiples servidores. Si la transacción se lleva a cabo, las nuevas copias de los objetos modificados se añaden al registro y también se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperación escaneando el registro. Dado que los objetos no están bloqueados antes de ser utilizados, una confirmación de transacción puede hacer que las cachés contengan objetos obsoletos. Los servidores abortarán una transacción que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviándoles mensajes de invalidación; un servidor utiliza su directorio y la información sobre la transacción de confirmación para determinar qué mensajes de invalidación enviar. Los mensajes de invalidación son pequeños porque simplemente identifican objetos obsoletos. Además, se envían en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidación, elimina los objetos obsoletos de su caché y aborta la transacción actual si los utilizó. El cliente sigue conservando páginas que contienen objetos invalidados; estas páginas ahora están incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidación de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener páginas incompletas en la caché del cliente significa que el falso intercambio no conduce a fallos innecesarios en la caché. Los clientes reconocen las invalidaciones para indicar la eliminación de datos obsoletos, como se explica en la Sección 3.1. Los mensajes de invalidación evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo así el desperdicio de trabajo y trasladando la detección de abortos de los servidores a los clientes. Cuando una transacción se aborta, su cliente restaura las copias en caché de los objetos modificados al estado que tenían antes de que la transacción comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacción. 4.3 Redirección El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de páginas disponibles en el grupo de pares y proporciona una redirección rápida y centralizada de recuperación (ver figura 2) entre las cachés de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan páginas u objetos al incluir esa información en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la caché de grupo, el redireccionador realiza un seguimiento del estado de las páginas. Una página en caché está completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una página están marcados como inválidos. Solo se utilizan páginas completas por el proceso de recuperación de pares. El protocolo para mantener el estado de la página cuando las páginas son actualizadas e invalidadas se describe en la Sección 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una página solicitada completa no está disponible en el grupo de pares o si un par necesita confirmar una transacción, el redireccionador actúa como un proxy de servidor: reenvía la solicitud al servidor y luego reenvía la respuesta de vuelta al cliente. Además, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualización o información de invalidación a los clientes que tienen en caché la página modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la caché de grupo de pares combinada está desempeñando el papel de una única caché de cliente en el sistema base. 4.4 Actualización de pares La actualización de pares se implementa de la siguiente manera. Una solicitud de actualización de confirmación de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. Después de que una transacción se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envía una respuesta de confirmación al redirigente del grupo de clientes que están confirmando. El redireccionador reenvía la respuesta al cliente que realiza la confirmación. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en caché las páginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacción generan invalidaciones de objetos para cada grupo de caché que almacena páginas que contienen los objetos modificados (incluido el grupo que realiza la confirmación). Las invalidaciones se envían de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en caché los objetos modificados se deshagan de los datos obsoletos. En grupos de caché distintos al grupo de confirmación, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en caché las páginas modificadas, recopilan las confirmaciones de los clientes y, después de completar la recopilación, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacción, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envían a los clientes que almacenan en caché esas páginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmación colectiva se propaga al servidor. Una invalidación hace que una página en caché no esté disponible para la recuperación de pares, cambiando el estado de una página completa p a incompleta. Por el contrario, una actualización de una página completa conserva el estado completo de la página. Como se muestra en los estudios de la reconstrucción de fragmentos 31 [2], esta propagación de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma página, la página conserva su estado completo y permanece disponible para la recuperación entre pares. Por lo tanto, el efecto de la actualización de pares es similar a la reconstrucción de fragmentos ansiosa [2]. También hemos considerado la posibilidad de permitir que un compañero recupere una página incompleta (con objetos inválidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos inválidos. 4.5 Vcache El protocolo de validación de confirmación en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo más lentos (o fallidos). Como se explica en la Sección 3.3, el protocolo de commit único permite que una transacción T pase la validación si la información adicional de coherencia proporcionada por el cliente indica que la transacción T ha leído objetos actualizados. Los clientes utilizan los números de versión de la página para proporcionar esta información adicional de coherencia. Es decir, un cliente incluye el número de versión de la página correspondiente a cada objeto en el conjunto de objetos leídos enviado en la solicitud de confirmación al servidor. Dado que a cada actualización de objeto comprometido le corresponde un número de versión de página único, el número de versión de página asociado con un objeto permite que el procedimiento de validación en el servidor verifique si la transacción del cliente ha leído objetos actualizados. El uso de versiones de página de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeños, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en caché a la versión de página identificadora (ObjectToVersion). El principal problema de implementación se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian números de versión de página con las invalidaciones. En el momento de la validación, si hay una invalidación no reconocida pendiente para un objeto x leído por una transacción T, el procedimiento de validación verifica si el número de versión de x en el conjunto de lectura de Ts coincide con el número de versión de la invalidación pendiente más alta para x, en cuyo caso el valor del objeto está actualizado, de lo contrario, T falla en la validación. Observamos nuevamente que las verificaciones basadas en el número de versión de la página y las verificaciones basadas en el reconocimiento de invalidación son complementarias en la validación de confirmación individual y ambas son necesarias. La verificación del número de versión de la página permite que la validación avance antes de que lleguen las confirmaciones de invalidación, pero por sí sola, una verificación del número de versión de la página detecta conflictos a nivel de página y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cómo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un número de versión de la página para cada página en caché. El número de versión satisface la siguiente invariante V P sobre el estado de los objetos en una página: si una página en caché P tiene un número de versión v, entonces el valor de un objeto o en la página en caché P es inválido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacción que estableció el número de versión de P en v. Los nuevos valores de objetos y los nuevos números de versión de página llegan cuando un cliente obtiene una página o cuando llega una respuesta de confirmación o invalidaciones para esta página. Los nuevos valores del objeto modifican la página y, por lo tanto, el número de versión de la página necesita ser actualizado para mantener la invariante V P. Un número de versión de página que llega cuando un cliente obtiene una página, reemplaza la Versión del Objeto x 8 Servidor de Redirección 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el número de versión de la página para esta página. Tal actualización preserva el invariante V P. De manera similar, un número de versión de página en secuencia que llega al cliente en un mensaje de confirmación o invalidación avanza el número de versión para toda la página en caché, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus números de versión de página correspondientes también pueden llegar al cliente fuera de secuencia, en cuyo caso la actualización del número de versión de la página podría violar V P. Por ejemplo, una respuesta de confirmación para una transacción que actualiza el objeto x en la página P en el servidor S1, y el objeto y en la página Q en el servidor S2, puede entregar un nuevo número de versión para P desde el coordinador de transacciones S1 antes de que llegue una invalidación generada para una transacción anterior que ha modificado el objeto r en la página P desde S1 (como se muestra en la figura 5). El protocolo de actualización de caché garantiza que el valor de cualquier objeto o en una página en caché P refleje la actualización o invalidación con el número de versión observado más alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de números de versión de página, el cliente gestiona una pequeña caché de números de versión vcache que mantiene el mapeo de un objeto a su número de versión de página correspondiente para todas las actualizaciones de números de versión reordenadas hasta que se ensamble una secuencia completa de números de versión de página. Cuando llegan los números de versión faltantes para la página y completan una secuencia, el número de versión de toda la página se avanza. El mapeo de ObjectToVersion, incluyendo los números de versión de vcache y página, se utiliza en el momento de la confirmación de la transacción para proporcionar números de versión para el conjunto de objetos leídos de la siguiente manera. Si el objeto leído tiene una entrada en la vcache, su número de versión es igual al número de versión más alto en la vcache para este objeto. Si el objeto no está presente en la vcache, su número de versión es igual al número de versión de la página en caché que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la caché del cliente, incluyendo los números de versión de las páginas y la vcache. El cliente puede limitar el tamaño de la caché virtual según sea necesario, ya que volver a cargar una página elimina todos los números de versión de página reordenados de la caché virtual. Sin embargo, esperamos que la reorganización de números de versión sea poco común y, por lo tanto, esperamos que la vcache sea muy pequeña. 5. Un grupo de clientes contiene múltiples nodos de cliente y un objeto de página de versión redi32 VCache Cliente Caché Cliente Página Caché Figura 6: Mapa de Objeto a Versión con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutación por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. Además, el fallo del redireccionador debería permitir que los clientes no afectados mantengan sus cachés intactas. Hemos diseñado un protocolo de conmutación por error para BuddyCache pero aún no lo hemos implementado. El apéndice describe el protocolo. 6. La redirección de BuddyCache en la evaluación de rendimiento respalda los beneficios de evitar la comunicación con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvío de solicitudes. ¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 Análisis Los beneficios de rendimiento de la recuperación entre pares y la actualización entre pares se deben a la evitación de interacciones con el servidor. Esta sección presenta un modelo de rendimiento analítico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la caché del cliente. Estos pueden ser fallos fríos, fallos de invalidación y fallos de capacidad. Nuestro análisis se centra en los fallos por frío y los fallos por invalidación, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frío. Además, las tendencias tecnológicas indican que la capacidad de memoria y almacenamiento seguirá creciendo y, por lo tanto, es probable que una configuración típica de BuddyCache no esté limitada por la caché. Los fallos de caché del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuración de caché. Nuestro análisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validación. Para estudiar el beneficio de evitar fallos en frío, consideramos el rendimiento de la caché en frío en una carga de trabajo de solo lectura (sin fallos de invalidación). Esperamos que la recuperación entre pares mejore el costo de latencia para las solicitudes de caché fría del cliente al recuperar objetos de la caché cercana. Evaluamos cómo el costo de redirección afecta este beneficio al comparar y analizar el rendimiento de una aplicación que se ejecuta en un sistema de almacenamiento con BuddyCache y sin él (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidación, consideramos el rendimiento de la caché caliente en una carga de trabajo con modificaciones (sin fallos en frío). En las cachés calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualización entre pares permite que un cliente acceda a un objeto modificado por un compañero colaborador cercano sin el retraso impuesto por los protocolos de invalidación únicamente. En grupos donde los compañeros comparten un interés de solo lectura en los objetos modificados, la recuperación entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compañero colaborador lo tenga, lo que evita el retraso de la recuperación del servidor sin el alto costo impuesto por los protocolos de solo actualización. Las tendencias tecnológicas indican que ambos beneficios seguirán siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualización únicamente. Sin embargo, la tendencia hacia cachés cada vez más grandes, que se actualizan cuando los objetos en caché son modificados, hace que los protocolos basados en invalidación sean más atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicación que se ejecuta sin BuddyCache y una aplicación que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compañero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compañero fuera del grupo. La actualización entre pares también puede evitar fallos de invalidación debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma página de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseño del objeto, y también porque este beneficio se puede derivar dado el índice de aciertos en caché y la contención de la carga de trabajo. 6.1.1 El Modelo El modelo considera cómo el tiempo para completar una ejecución con y sin BuddyCache se ve afectado por los fallos de invalidación y los fallos en frío. Considerando k clientes ejecutándose concurrentemente accediendo de manera uniforme a un conjunto compartido de N páginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacción y realizar cálculos en una transacción, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin él (Base). Para simplificar, nuestro modelo asume que los tiempos de búsqueda y confirmación son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del número total de clientes en el sistema. El número de fallos evitados por la recuperación entre pares depende de k, el número de clientes en la BuddyCache, y del interés conjunto de los clientes en los datos compartidos. En una ejecución específica de BuddyCache, se modela mediante la variable r, definida como el número de solicitudes que llegan al redireccionador para una versión dada de la página P (es decir, hasta que un objeto en la página se invalida). Considera una ejecución con fallos en frío. Un cliente comienza con una caché fría y ejecuta una carga de trabajo de solo lectura hasta que accede a las N páginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la caché del cliente es lo suficientemente grande como para contener N páginas. En BC, los fríos fallos para la página P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N ∗ tfetch(Base) +(tcompute + tcommit(Base)) ∗ l (1) Tcold(BC) = N ∗ 1 k ∗ tfetch(BC) + (1 − 1 k ) ∗ tredirect +(tcompute + tcommit(BC)) ∗ l (2) Consideremos a continuación una ejecución con fallos de invalidación. Un cliente comienza con una caché caliente que contiene el conjunto de trabajo de N páginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualización entre pares elimina todos los fallos de invalidación. En un grupo que contiene solo lectores (BCR), durante una ejecución en estado estable con actualizaciones uniformes, una transacción del cliente tiene fallos de invalidación faltantes. Considera la secuencia de r fallos de cliente en la página P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la página P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frío, r ≤ k porque la segunda invalidación deshabilita la redirección para P hasta que el próximo fallo en P provoque una recuperación del servidor. Suponiendo un acceso uniforme, un fallo de invalidación del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperación del servidor), y una probabilidad de (1 − 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacción única en los sistemas Base, BCR y BCW. En los experimentos descritos a continuación, medimos los parámetros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalización derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalización y beneficios medidos directamente en los experimentos. 6.2 Configuración Experimental Antes de presentar nuestros resultados, describimos nuestra configuración experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectándose directamente a los servidores. El sistema Buddy ejecuta nuestra implementación del prototipo de BuddyCache en Thor, admitiendo la recuperación de pares, la actualización de pares y la confirmación en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark está diseñado para capturar las características de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicación específica. Utilizamos OO7 porque es un punto de referencia estándar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un árbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un gráfico de partes atómicas vinculadas por objetos de conexión; cada parte atómica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atómicas por parte compuesta. La base de datos multiusuario asigna a cada cliente un módulo privado que consiste en un árbol de objetos de ensamblaje, y agrega un módulo compartido adicional que escala proporcionalmente al número de clientes. Esperamos que una configuración típica de BuddyCache no esté limitada por la caché y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la caché. Dado que el objetivo de nuestro estudio es evaluar qué tan efectivamente nuestras técnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras técnicas tienen en los fallos de caché frío y de consistencia de caché, y aislar tanto como sea posible el efecto de los fallos de capacidad de caché. Para mantener la duración de nuestros experimentos razonable, utilizamos cachés pequeños. El benchmark OO7 genera módulos de base de datos de tamaño predefinido. En nuestra implementación de OO7, el tamaño del módulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la caché, utilizamos un único módulo privado y elegimos un tamaño de caché de 40MB para cada cliente. La base de datos OO7 se genera con módulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos están agrupados en páginas de 8K, que también son la unidad de transferencia en las solicitudes de recuperación. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro análisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idéntico a T1 excepto que modifica todas las partes atómicas en un solo compuesto. Una transacción única incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo módulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacción, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de búsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una caché de 50MB (de los cuales 6MB se utilizaron para el búfer de objetos modificados), el cliente tenía una caché de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 −AlertHelper 0.3 - 4.6 −CopyUnswizzle 0.24 −CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos básicos Esta sección analiza el costo básico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 Redirección Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtención del servidor), el costo adicional de la redirección incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperación o confirmación del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmación y recuperación del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de área rápida. Todos los números fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirección al cruzar el redireccionador no es muy alto, incluso en una red de área local. El costo de la confirmación aumenta con el número de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperación no aumenta tanto porque la caché del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la caché del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperación entre pares, medimos la latencia de la recuperación entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperación entre pares, el costo de la redirección incluye, además del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este último incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la página solicitada. Medimos directamente el tiempo para copiar y desenrollar la página solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperación de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador más un viaje de ida y vuelta a través de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud más un viaje de ida y vuelta a través de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando está bloqueado esperando una respuesta de búsqueda o confirmación. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podría ser mitigado por una implementación multi-hilo en un sistema con programación preemptiva. 6.3.2 Versión de Caché El commit en solitario permite que un cliente rápido que modifica un objeto haga un commit de forma independiente a un compañero lento. El mecanismo de confirmación única introduce un procesamiento adicional en el servidor durante la validación de la transacción, y un procesamiento adicional en el cliente durante la confirmación de la transacción y en el momento del procesamiento de actualización o invalidación. Los gastos generales del lado del servidor son mínimos y consisten en una actualización del número de versión de la página en el momento de la confirmación, y una comparación del número de versión en el momento de la validación de la transacción. La caché de versión tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacción accede a objetos en múltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor único y, por lo tanto, el tiempo de confirmación adicional de la gestión de la caché de versiones en el cliente no contribuye a los resultados presentados en la sección a continuación. Para medir estos costos adicionales del lado del cliente en un sistema de múltiples servidores, instrumentamos la implementación de la caché de versiones para ejecutarse con una traza de carga de trabajo que incluía invalidaciones reordenadas y cronometramos las operaciones básicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operación de búsqueda de caché de versión para cada objeto leído por la transacción en el momento de preparación de la solicitud de compromiso, y una operación de inserción de caché de versión para cada objeto actualizado por una transacción en el momento de procesamiento de la respuesta de compromiso, pero solo si la página actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmación se mantengan al mínimo, ya que el cliente está esperando de forma síncrona la finalización de la confirmación. Las mediciones muestran que en el peor de los casos, cuando llega un gran número de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en páginas reordenadas, el costo de actualizar la caché de versión es de 0.6 ms. El costo de tiempo de invalidación es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementación de la caché de versiones para reducir aún más estos costos. 6.4 Rendimiento general Esta sección examina las mejoras de rendimiento observadas por una aplicación que ejecuta el benchmark OO7 con un BuddyCache en una red de área amplia. 6.4.1 Fallos en frío Para evaluar las mejoras de rendimiento al evitar fallos en frío, comparamos el rendimiento de la caché en frío del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecución de los sistemas en el entorno de la red de área local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de área amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en caché fría. Los números fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frío solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frío solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparación con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cálculos para el cliente, solicitudes de recuperación directa, recuperaciones de pares y solicitudes de confirmación. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperación entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperación del servidor para cada cliente individual disminuye porque, con más clientes accediendo a un módulo compartido de tamaño fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperación de pares en comparación con la recuperación directa, pero este beneficio se ve contrarrestado por los tiempos de confirmación aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relación con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de caché 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT función de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias típicas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Sorprendentemente, los resultados analíticos predicen la mejora medida muy de cerca, aunque son ligeramente más altos que los valores empíricos. La razón principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidación evitados, comparamos el rendimiento de caché caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interés de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un único cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compañeros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compañeros con un grupo que contiene un único escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuración simple es suficiente para mostrar el impacto de las técnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de caché caliente de OO7. Obtenemos los números ejecutando 2000 transacciones para filtrar los fallos en frío y luego medimos el tiempo de las siguientes 1000 transacciones. Aquí nuevamente, los números reportados se derivan de los resultados del experimento de la red de área local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalización en comparación con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparación con la Base. Este beneficio se debe a la actualización entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperación entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperación local evitando el retraso de la recuperación desde el servidor. El último es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperación de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperación de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualización de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relación con Base, y Buddy Writer y Base en relación con Base) en un experimento de caché activa en función del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualización entre pares domina el gasto general en la configuración de Writer incluso en redes de baja latencia (la actualización entre pares incurre en un gasto mínimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analítico. Como en experimentos de caché fría, aquí los resultados analíticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pérdida de invalidación es mínimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de caché fría). Como en el caso de caché fría, la razón por la que el modelo analítico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÓN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea común. Requieren una consistencia sólida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difíciles de proporcionar en una red de área extensa debido a la alta latencia de red. Este artículo describe BuddyCache, una nueva técnica de almacenamiento en caché cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La técnica mejora el rendimiento y proporciona propiedades sólidas de corrección y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirección para obtener objetos faltantes directamente de las cachés de los miembros del grupo, y para admitir la actualización entre pares, una nueva técnica de multidifusión a nivel de aplicación ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirección puede interferir con la disponibilidad del objeto. Solo commit es una nueva técnica de validación que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validación detallada utilizando información de versión de grano grueso económica. Hemos diseñado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analíticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias típicas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparación con los clientes que acceden directamente al repositorio. Las principales contribuciones del artículo son: 1. extender las técnicas de almacenamiento en caché cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementación del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluación del rendimiento basada en análisis y mediciones de los costos y beneficios de las nuevas técnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. También agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios útiles que mejoraron este artículo. 9. REFERENCIAS [1] emulab.net, la Instalación de Emulación de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. Reconstrucción de fragmentos: Proporcionando coherencia de caché global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de Computación Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre Gestión de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: Computación en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de caché híbridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. Recuperación rápida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de caché en la World Wide Web. En la 17ª Conferencia Internacional sobre Sistemas de Computación Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluación del rendimiento del sistema de gestión de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una caché de objetos jerárquica en Internet. En la Conferencia Técnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachés de Internet escalables. Informe Técnico CS-1997-18, Departamento de Ciencias de la Computación, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: Caché de proxy cooperativa en una red de área amplia. En el Tercer Taller Internacional de Caché de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. Caché web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2º Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. Caché cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilación y en tiempo de ejecución para una memoria compartida distribuida eficiente. En Actas de IEEE, Edición Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la caché: un protocolo de intercambio de caché web escalable de área amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. Implementación de Gestión Global de Memoria en un Clúster de Estaciones de Trabajo. Actas del 15º Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: Diseño, Implementación y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de caché transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, páginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. Gestión global de memoria para arquitecturas de sistemas de gestión de bases de datos cliente-servidor. En Actas del 19º Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El Búfer de Objeto Modificado: Una Técnica de Gestión de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto Tecnológico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. Gestión de documentos replicados en un sistema de comunicación grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13ª Conferencia Europea sobre Programación Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18º Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. Replicación con marca de vista: un nuevo método de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de Computación Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalación eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de Multidifusión a Nivel de Aplicación. En el 3er Simposio USENIX sobre Tecnologías y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de caché cooperativa utilizando pistas. En el Simposio Usenix sobre Diseño e Implementación de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en Caché Global. Informe técnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del Caché de Proxies Web Cooperativos. En el 17º Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerárquica de caché en una WAN. En el Simposio USENIX sobre Tecnologías y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. Compartición adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÉNDICE Este apéndice describe el protocolo de conmutación por error de BuddyCache. Para dar cabida a clientes heterogéneos, incluidos los dispositivos portátiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseño de BuddyCache asume que las cachés del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresía detecta el fallo de un cliente o un redireccionador intercambiando mensajes periódicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutación por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuración y reinicia el protocolo. El protocolo de reconfiguración del grupo es similar al presentado en [25]. Aquí describimos cómo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de páginas redireccionadas y el reenvío de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachés. En caso de un fallo del cliente, el failover elimina las páginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmación, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en caché las páginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutación por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de páginas utilizando un protocolo similar al descrito en [6]. El redireccionador recién reiniciado solicita a los miembros activos del grupo la lista de páginas que están almacenando en caché y el estado de estas páginas, es decir, si las páginas están completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperación perdida expirará en el cliente y será retransmitida. Una transacción que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma después del cambio se trata como una transacción regular; una transacción que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciará la transacción y la solicitud de confirmación será retransmitida después del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caído podrían evitar la recolección de basura de las invalidaciones pendientes en los servidores o la caché virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los números de versión únicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validación de transacciones depende del protocolo de coherencia de caché para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutación por error de BuddyCache no compromete la corrección del procedimiento de validación. Recuerda que la validación de transacciones de BuddyCache utiliza dos mecanismos complementarios, números de versión de página y confirmaciones de invalidación de los clientes, para verificar que una transacción ha leído datos actualizados. La propagación de la confirmación de invalidación (y actualización) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmación de una modificación (invalidación o actualización) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en caché el objeto o bien ha instalado el valor más reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmación de un cliente para una transacción T que lee un objeto o después de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidación no confirmada para o pendiente para este grupo, la versión del objeto leída por la transacción T está actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validación utilizando números de versión. El registro de confirmación de transacción contiene un número de versión para cada objeto leído por la transacción. El protocolo de número de versión mantiene la invariante V P que garantiza que el valor del objeto o leído por la transacción corresponda al número de versión más alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificación anterior después de haber recibido una modificación posterior. La retransmisión de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validación verifica que el número de versión en el registro de confirmación coincida con el número de versión en la invalidación pendiente no reconocida. Es fácil ver que, dado que esta comprobación es una comprobación cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutación por error aún no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}