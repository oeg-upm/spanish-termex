{
    "id": "C-32",
    "original_text": "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task. They require strong consistency for shared persistent data and efficient access to fine-grained objects. These properties are difficult to provide in wide-area networks because of high network latency. BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments. The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers. We have implemented a BuddyCache prototype and evaluated its performance. Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly. Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1. INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go. Nevertheless, distributed applications may perform poorly in wide-area network environments. Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited. BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment. Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project. Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data. Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24]. For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22]. Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics. If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened. Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server. Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings. However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects. Cooperative object caching systems [2] provide these properties. However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page. Interaction with the server increases latency. The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments. Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site. The engineers use a collaborative CAD application to revise and update complex project design documents. The shared documents are stored in transactional repository servers at the company home site. The engineers use workstations running repository clients. The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow. To improve access latency, clients fetch objects from repository servers and cache and access them locally. A coherence protocol ensures that client caches remain consistent when objects are modified. The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects. With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group. BuddyCache presents two main technical challenges. One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system. The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes. BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11]. A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers. If the client request can not be served locally, the redirector forwards it to a remote server. When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients. BuddyCache redirects subsequent requests for this object to the caching client. Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members. BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group. Nevertheless, in a transactional system, redirection interferes with shared object availability. Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently. A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information. Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease? We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements. We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency. Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly. These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2. RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network. These techniques use the server to provide redirection and do not consider issues of high network latency. Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail. Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes. This work does not consider issues of consistent concurrent updates to shared fine-grained objects. Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache. This multicast transport level solution is geared to the single writer semantics of web objects. In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects. Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27]. The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing. Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme. The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions. The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme. In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system. Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations. Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels. The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems. Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache. BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3. BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment. This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions. We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks. Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects. The servers provide disk storage for the persistent objects. A persistent object is owned by a single server. Objects may be small (order of 100 bytes for programming language objects [23]). To amortize the cost of disk and network transfer objects are grouped into physical pages. To improve object access latency, clients fetch the objects from the servers and cache and access them locally. A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified. The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects. BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers. The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers. If the client request can be served locally, the interaction with the server is avoided. If the client request can not be served locally, redirector forwards it to a remote server. Redirection approach has been used to improve the performance of web caching protocols. BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19]. The correctness property ensures onecopy serializability of the objects committed by the client transactions. The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects. The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information. BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group. The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures. Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object. In addition, redirector manages cache coherence. Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems. Protocols make different choices in granularity of data transfers and granularity of cache consistency. The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts. The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache. The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category. We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol. We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation. We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol. Below we outline the OCC protocol [3]. The OCC protocol uses object-level coherence. When a client requests a missing object, the server transfers the containing page. Transaction can read and update locally cached objects without server intervention. However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction. If validation fails, the transaction is aborted. To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages. When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this. Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects. An unacknowledged invalidation indicates a stale object may have been accessed in the client cache. The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding. The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers. Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small. An important BuddyCache design goal is to maintain this benefit. Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client. Redirector keeps track of pages cached in each client in a group. Servers send to the redirector invalidations for pages cached in the entire group. The redirector propagates invalidations from servers to affected clients. When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members. The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system. The two possible approaches to deal with stale data are cache invalidations and cache updates. Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation. The studies show the Committing Client Server Redirector x2. Store x 6. Update x 3. Commit x 4. Commit OK 5. Commit OK1. Commit x Figure 3: Peer update. benefits are strongly workload-dependent. In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages. Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes. Larger caches are likely to contain much more data than is actively used. Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful. Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member. With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server. BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments. It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group. This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors. As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems. The peer update works as follows. An update commit request from a client arriving at the redirector contains the object updates. Redirector retains the updates and propagates the request to the coordinating server. After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group. The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3). Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data. The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction. E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server. Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1. If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client). Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing. The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3]. Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client. Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations. The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers. The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date. Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23]. Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions. A page version number is incremented at a server when at transaction that modifies objects on the page commits. Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number. Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers. If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version. The page version numbers enable independent commits but page version checks only detect page-level conflicts. To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations. Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups. Potentially, it may be faster to access data cached in another peer group than to access a remote server. In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile. We have not pursued this possibility for several reasons. In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30]. In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur. Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast. We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow. As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now. To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure. Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache. From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4. IMPLEMENTATION In this section we provide the details of the BuddyCache implementation. We have implemented BuddyCache in the Thor client/server object-oriented database [23]. Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects. Applications run at the clients and interact with the system by making calls on methods of cached objects. All method calls occur within atomic transactions. Clients communicate with servers to fetch pages or to commit a transaction. The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory. The disk is organized as a collection of pages which are the units of disk access. The stable log holds commit information and object modifications for committed transactions. The server memory contains cache directory and a recoverable modified object cache called the MOB. The directory keeps track of which pages are cached by which clients. The MOB holds recently modified objects that have not yet been written back to their pages on disk. As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1. We provide some of the relevant OCC protocol implementation details. The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction. The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers. If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB. The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log. Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects. Servers will abort a transaction that used obsolete objects. However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send. Invalidation messages are small because they simply identify obsolete objects. Furthermore, they are sent in the background, batched and piggybacked on other messages. When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them. The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects. Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses. Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1. Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients. When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure. It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches. To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector. To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages. A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid. Only complete pages are used by the peer fetch. The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4. When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client. In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3). The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows. An update commit request from a client arriving at the redirector contains the object updates. Redirector retains the updates and propagates the request to the coordinator server. After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group. The redirector forwards the reply to the committing client. It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.) Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group). The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data. In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server. Within the committing client group, the arriving invalidations are not propagated. Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server. An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete. In contrast, an update of a complete page preserves the complete page status. As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing. That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch. Therefore, the effect of peer update is similar to eager fragment reconstruction [2]. We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members. As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects. Clients use page version numbers to provide this extra coherence information. That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server. Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects. The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion). The main implementation issue is concerned with maintaining this mapping efficiently. At the server side, when modifications commit, servers associate page version numbers with the invalidations. At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation. We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed. The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations. We now describe how the client manages the mapping ObjectToVersion. The client maintains a page version number for each cached page. The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page. The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page. Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5). The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number. That is, obsolete updates or invalidations received out of sequence do not affect the value of an object. To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled. When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced. The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows. If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object. If the object is not present in the vcache, its version number is equal the version number of its containing cached page. Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache. Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache. However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5. BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently. The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects. Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact. We have designed a failover protocols for BuddyCache but have not implemented it yet. The appendix outlines the protocol. 6. PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding. Is the cure worse then the disease? To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions. This section presents a simple analytical performance model for this benefit. The avoided server interactions correspond to different types of client cache misses. These can be cold misses, invalidation misses and capacity misses. Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses. Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited. The client cache misses are determined by several variables, including the workload and the cache configuration. Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments. To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses). We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache. We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base). To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses). In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects. Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols. In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols. Technology trends indicate that both benefits will remain important in the foreseeable future. The trend toward increase in available network bandwidth decreases the cost of the update-only protocols. However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive. To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations. One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group. Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently. We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses. Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base. Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base). For simplicity, our model assumes the fetch and commit times are constant. In general they may vary with the server load, e.g. they depend on the total number of clients in the system. The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data. In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated). Consider an execution with cold misses. A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions. We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages. In BC, r cold misses for page P reach the redirector. The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected. Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses. A client starts with a hot cache containing the working set of N pages. We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload. In a group containing the writer (BCW ), peer update eliminates all invalidation misses. In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses. Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected. Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch. Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected. Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems. Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S). We compute the completion times derived using the above model and derive the benefits. We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup. We use two systems in our experiments. The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers. The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover. Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application. We use OO7 because it is a standard benchmark for measuring object storage system performance. The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects. Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections. We use a medium database that has 200 atomic parts per composite part. The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients. We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache. Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only. This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses. To keep the length of our experiments reasonable, we use small caches. The OO7 benchmark generates database modules of predefined size. In our implementation of OO7, the private module size is about 38MB. To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client. The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above. The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests. We consider two types of transaction workloads in our analysis, read-only and read-write. In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph. Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite. A single transaction includes one traversal and there is no sleep time between transactions. Both read-only and read-write transactions always work with data from the same module. Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions. The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates. In Base system clients connect directly to the database. In Buddy system clients connect to the redirector that connects to the database. We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy. The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2. They were connected by a 100Mb/s Ethernet. The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache. The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system. For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server. We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system. Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network. All the numbers were computed by averaging measured request latency over 1000 requests. The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network. The commit cost increases with the number of clients since commits are processed sequentially. The fetch cost does not increase as much because the server cache reduces this cost. In a large system with many groups, however, the server cache becomes less efficient. To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs. In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page. We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request. Table 2 summarizes the latencies that allows us to break down the peer fetch costs. CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector. AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client. The local network latency is fixed and less than 0.1 ms. The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time. This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply. This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer. The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time. The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time. The version cache has an entry only when invalidations or updates arrive out of order. This may happen when a transaction accesses objects in multiple servers. Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below. To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations. The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates. It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion. The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms. The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance. We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems. We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network. Figures 7 and 8 show the overall time to complete 1000 cold cache transactions. The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group. The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case. The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests. In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches. In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches. Figure 8 shows the overall time and cost break down in the 80 ms network. The BuddyCache provides similar performance improvements as with the 40ms network. Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times. Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load. The cost of the extra mechanism dominates BuddyCache benefit when network latency is low. At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement. Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values. The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations. One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group. In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers). Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group. Buddy system with one group containing a single writer and another group running three readers models the Reader group. In Base, one writer and three readers access the server directly. This simple configuration is sufficient to show the impact of BuddyCache techniques. Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions. We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions. Here again, the reported numbers are derived from the local area network experiment results. The results show that the BuddyCache reduces significantly the completion time compared to the Base system. In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base. This benefit is due to peer update that avoids all misses due to updates. The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server. The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol. Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group. This difference is similar in 80ms network. Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load. The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range. The figure includes both the measured improvement and the improvement derived using the analytical model. As in cold cache experiments, here the analytical results predict the measured improvement closely. The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments). As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7. CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task. They require strong consistency for shared persistent data and efficient access to fine-grained objects. These properties are difficult to provide in wide-area network because of high network latency. This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments. The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients. BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group. Redirection, however, can interfere with object availability. Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers. It provides fine-grained validation using inexpensive coarse-grain version information. We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies. Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly. The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8. ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed. We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9. REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira. Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System. Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari. Efficient optimistic concurrencty control using loosely synchronized clocks. In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel. Treadmarks: Shared memory computing on networks of workstations. IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin. Two Adaptive Hybrid Cache Coherency Protocols. In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker. Fast Crash Recovery in Distributed File Systems. PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu. Maintaining Strong Cache Consistency in the World Wide Web. In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton. A Status Report on the OO7 OODBMS Benchmarking Effort. In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels. A Hierarchical Internet Object Cache. In USENIX Annual Technical Conference, January 1995. [10] J. Chase, S. Gadde, and M. Rabinovich. Directory Structures for Scalable Internet Caches. Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J. Chase, S. Gadde, and M. Rabinovich. Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network. In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li. Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson. Cooperative caching: Using remote client memory to improve file system performance. Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony, and W. Zwaenepoel. Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory. In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder. Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol. In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy. Implementing Global Memory Management in a Workstation Cluster. Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy. Integrating Coherency and Recoverablity in Distributed Systems. In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al. PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store. In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny. Transactional Client-Server Cache Consistency: Alternatives and Performance. In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny. Global Memory Management for Client-Server DBMS Architectures. In Proceedings of the 19th Intl. Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat. The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases. PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif. Replicated document management in a group communication system. In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya. Providing Persistent Objects in Distributed Systems. In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres. A Low-bandwidth Network File System. In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov. Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems. In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira. Opportunistic Log: Efficient Installation Reads in a Reliable Object Server. In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma. ALMI: An Application Level Multicast Infrastructure. In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman. Efficient Cooperative Caching Using Hints. In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson. WebFS: A Global Cache Coherent File System. Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy. On the Scale and Performance of Cooperative Web Proxy Caching. In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin. Hierarchical Cache Consistency in a WAN. In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin. Volume Leases for Consistency in Large-Scale Systems. IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin. Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach. ACM Transactions on Database Systems, 22:570-627, December 1997. 10. APPENDIX This appendix outlines the BuddyCache failover protocol. To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group. The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures. A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol. The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol. The group reconfiguration protocol is similar to the one presented in [25]. Here we describe how the failover manages the BuddyCache state. To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches. In the case of a client failure, the failover removes the crashed client pages from the directory. Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages. In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6]. The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete. Requests outstanding at the redirector at the time of the crash may be lost. A lost fetch request will time out at the client and will be retransmitted. A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol. A client will restart the transaction and the commit request will be retransmitted after the failover. Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients. Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies. Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded. Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure. Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data. The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant. When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o. Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures. Now consider the validation using version numbers. The transaction commit record contains a version number for each object read by the transaction. The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client. The invariant holds since the client never applies an earlier modification after a later modification has been received. Retransmition of invalidations and updates maintains this invariant. The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation. It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure. The failover protocol has not been implemented yet. 39",
    "original_translation": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de Ã¡rea amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de Ã¡rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil. Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en cachÃ© web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos. Sin embargo, las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica. La interacciÃ³n con el servidor aumenta la latencia. La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia. Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n. Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo. BuddyCache presenta dos desafÃ­os tÃ©cnicos principales. Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©. El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de almacenamiento en cachÃ© web cooperativos [11]. Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo. BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos. Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica. Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad? DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red. Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia. El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida. Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache. Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n. Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos. Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de Ã¡rea amplia. Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad. Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un Ãºnico servidor. Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web. El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en cachÃ© transaccional [19]. La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una transacciÃ³n, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador. El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado. AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©. Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina). La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente. El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento. A continuaciÃ³n, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene. La transacciÃ³n puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor. Sin embargo, antes de que una transacciÃ³n se confirme, debe ser validada; el servidor debe asegurarse de que la transacciÃ³n validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada. Si la validaciÃ³n falla, la transacciÃ³n se cancela. Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de bÃºsqueda de pares envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la cachÃ© y envÃ­an confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la cachÃ© del cliente, la confirmaciÃ³n de invalidaciÃ³n indica al servidor que un cliente sin invalidaciones pendientes ha leÃ­do objetos actualizados. Una invalidaciÃ³n no reconocida indica que un objeto obsoleto puede haber sido accedido en la cachÃ© del cliente. El procedimiento de validaciÃ³n en el servidor aborta una transacciÃ³n del cliente si este lee un objeto mientras hay una invalidaciÃ³n pendiente. El mecanismo de invalidaciÃ³n reconocido admite coherencia de cachÃ© a nivel de objeto sin directorios basados en objetos o nÃºmeros de versiÃ³n por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeÃ±os, ya que los objetos tÃ­picos son pequeÃ±os. Un objetivo importante del diseÃ±o de BuddyCache es mantener este beneficio. Dado que en BuddyCache una pÃ¡gina puede ser recuperada en una cachÃ© de cliente sin intervenciÃ³n del servidor (como se ilustra en la figura 2), los directorios de cachÃ© en los servidores llevan un registro de las pÃ¡ginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las pÃ¡ginas almacenadas en cachÃ© en cada cliente de un grupo. Los servidores envÃ­an al redireccionador invalidaciones para las pÃ¡ginas almacenadas en cachÃ© en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. ActualizaciÃ³n de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en cachÃ© por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interÃ©s potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de cachÃ© y las actualizaciones de cachÃ©. Los estudios de coherencia de cachÃ© en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualizaciÃ³n y la invalidaciÃ³n. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. AlmacÃ©n x 6. ActualizaciÃ³n x 3. CompromÃ©tete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares estÃ¡n fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeÃ±as, agrupadas y se envÃ­an junto con otros mensajes. AdemÃ¡s, los protocolos de invalidaciÃ³n se ajustan a la tendencia actual de hardware de aumentar los tamaÃ±os de cachÃ© del cliente. Es probable que las cachÃ©s mÃ¡s grandes contengan mucha mÃ¡s informaciÃ³n de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una red de Ã¡rea amplia serÃ­an derrochadores. Sin embargo, los protocolos de coherencia basados en invalidaciÃ³n pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interÃ©s para otro miembro del grupo. Con un protocolo basado en invalidaciÃ³n, la actualizaciÃ³n de un miembro invalidarÃ¡ la copia en cachÃ© de otro miembro, lo que provocarÃ¡ que este Ãºltimo realice una recuperaciÃ³n de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualizaciÃ³n e invalidaciÃ³n en entornos de redes de Ã¡rea amplia. Evita la penalizaciÃ³n de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalizaciÃ³n de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusiÃ³n localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en cachÃ© anteriores. La actualizaciÃ³n entre pares funciona de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que la transacciÃ³n se confirma, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n, y tambiÃ©n propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmaciÃ³n. 3.3 ConfirmaciÃ³n individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminaciÃ³n de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en cachÃ© transaccional, ya que un cliente que es lento para reconocer una invalidaciÃ³n o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacciÃ³n. Por ejemplo, un ingeniero que realiza una revisiÃ³n repetida al mismo objeto de diseÃ±o compartido (y por lo tanto tiene la Ãºltima versiÃ³n del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situaciÃ³n representada en la figura 4 donde el Cliente1 realiza una transacciÃ³n T que lee la Ãºltima versiÃ³n de un objeto x en la pÃ¡gina P recientemente modificada por el Cliente1. Si la solicitud de confirmaciÃ³n para T llega al servidor antes de que la confirmaciÃ³n colectiva de Cliente2 por la Ãºltima modificaciÃ³n de x llegue al servidor, el procedimiento de validaciÃ³n de OCC considera que x estÃ¡ obsoleto y aborta T (porque, como se explicÃ³ anteriormente, una invalidaciÃ³n no reconocida por un cliente actÃºa como indicaciÃ³n para el servidor de que el valor del objeto en cachÃ© estÃ¡ obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la correcciÃ³n del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asÃ­ncronas son una parte importante de la razÃ³n por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasiÃ³n de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envÃ­an y procesan de forma asÃ­ncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devoluciÃ³n de llamada jerÃ¡rquica [32], pero la naturaleza asincrÃ³nica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrÃ³nicas. El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a un cliente con objetos actualizados confirmar una transacciÃ³n incluso si la confirmaciÃ³n del grupo se retrasa debido a pares lentos o caÃ­dos. El protocolo requiere que los clientes incluyan informaciÃ³n adicional con los conjuntos de lectura de transacciones en el mensaje de confirmaciÃ³n, para indicar al servidor que los objetos leÃ­dos por la transacciÃ³n estÃ¡n actualizados. Los nÃºmeros de versiÃ³n de los objetos podrÃ­an proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionÃ³ anteriormente, mantener nÃºmeros de versiÃ³n por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaÃ±o de directorio) en todo el sistema de objetos cuando los objetos son pequeÃ±os [23]. En cambio, solo utiliza nÃºmeros de versiÃ³n de pÃ¡gina de grano grueso para identificar versiones de objetos de grano fino. El nÃºmero de versiÃ³n de una pÃ¡gina se incrementa en un servidor cuando una transacciÃ³n que modifica objetos en la pÃ¡gina se confirma. Las actualizaciones realizadas por una Ãºnica transacciÃ³n y las invalidaciones correspondientes son identificadas de manera Ãºnica por el nÃºmero de versiÃ³n de la pÃ¡gina modificada. Los nÃºmeros de versiÃ³n de la pÃ¡gina se propagan a los clientes en respuestas de recuperaciÃ³n, respuestas de confirmaciÃ³n y con invalidaciones, y los clientes incluyen los nÃºmeros de versiÃ³n de la pÃ¡gina en las solicitudes de confirmaciÃ³n enviadas a los servidores. Si una transacciÃ³n falla en la validaciÃ³n debido a la falta de reconocimiento de grupo, el servidor verifica los nÃºmeros de versiÃ³n de pÃ¡gina de los objetos en el conjunto de lectura de la transacciÃ³n y permite que la transacciÃ³n se confirme si el cliente ha leÃ­do desde la Ãºltima versiÃ³n de la pÃ¡gina. Los nÃºmeros de versiÃ³n de la pÃ¡gina permiten confirmaciones independientes, pero las verificaciones de versiÃ³n de pÃ¡gina solo detectan conflictos a nivel de pÃ¡gina. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La secciÃ³n 4 describe los detalles de la implementaciÃ³n del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 ConfiguraciÃ³n de Grupo La arquitectura BuddyCache admite mÃºltiples grupos de pares concurrentes. Potencialmente, puede ser mÃ¡s rÃ¡pido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podrÃ­a ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en cachÃ© de pares de mÃºltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en cachÃ© web, simplemente aumentar la poblaciÃ³n de clientes en una cachÃ© proxy a menudo aumenta la tasa general de aciertos en la cachÃ© [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacciÃ³n explÃ­cita entre clientes y la colaboraciÃ³n, lo que sugiere que es poco probable que ocurra la recuperaciÃ³n entre grupos. AdemÃ¡s, las mediciones de sistemas de almacenamiento en cachÃ© web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexiÃ³n de red entre los grupos de pares sea muy rÃ¡pida. Estamos principalmente interesados en entornos donde compaÃ±eros que colaboran estrechamente tienen una conectividad rÃ¡pida a corta distancia, pero la conexiÃ³n entre grupos de compaÃ±eros puede ser lenta. Como resultado, decidimos que el soporte para la recuperaciÃ³n entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compaÃ±eros con recursos heterogÃ©neos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compaÃ±eros o, cuando estÃ© disponible, en un nodo separado dentro de la infraestructura del sitio. AdemÃ¡s, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una cachÃ© de pares en espera para recibir pÃ¡ginas recuperadas por otros pares, emulando una cachÃ© central algo similar a una cachÃ© de proxy web regional. Desde el punto de vista del protocolo de coherencia de cachÃ© BuddyCache, sin embargo, un cachÃ© de compaÃ±ero en espera es equivalente a un cachÃ© de compaÃ±ero regular y, por lo tanto, no consideramos este caso por separado en la discusiÃ³n de este documento. 4. En esta secciÃ³n proporcionamos los detalles de la implementaciÃ³n de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en cachÃ© de estos objetos. Las aplicaciones se ejecutan en los clientes e interactÃºan con el sistema realizando llamadas a mÃ©todos de objetos en cachÃ©. Todas las llamadas a mÃ©todos ocurren dentro de transacciones atÃ³micas. Los clientes se comunican con los servidores para obtener pÃ¡ginas o realizar una transacciÃ³n. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volÃ¡til. El disco estÃ¡ organizado como una colecciÃ³n de pÃ¡ginas que son las unidades de acceso al disco. El registro estable guarda la informaciÃ³n de confirmaciÃ³n y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de cachÃ© y una cachÃ© de objetos modificados recuperable llamada MOB. El directorio lleva un registro de quÃ© pÃ¡ginas estÃ¡n almacenadas en cachÃ© por quÃ© clientes. El MOB contiene objetos recientemente modificados que aÃºn no han sido escritos de vuelta en sus pÃ¡ginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de cachÃ© base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la SecciÃ³n 3.1. Proporcionamos algunos de los detalles relevantes de la implementaciÃ³n del protocolo OCC. El cliente lleva un registro de los objetos que son leÃ­dos y modificados por su transacciÃ³n; envÃ­a esta informaciÃ³n, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacciÃ³n. Los servidores determinan si la confirmaciÃ³n es posible, utilizando un protocolo de confirmaciÃ³n de dos fases si la transacciÃ³n utilizÃ³ objetos en mÃºltiples servidores. Si la transacciÃ³n se lleva a cabo, las nuevas copias de los objetos modificados se aÃ±aden al registro y tambiÃ©n se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperaciÃ³n escaneando el registro. Dado que los objetos no estÃ¡n bloqueados antes de ser utilizados, una confirmaciÃ³n de transacciÃ³n puede hacer que las cachÃ©s contengan objetos obsoletos. Los servidores abortarÃ¡n una transacciÃ³n que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviÃ¡ndoles mensajes de invalidaciÃ³n; un servidor utiliza su directorio y la informaciÃ³n sobre la transacciÃ³n de confirmaciÃ³n para determinar quÃ© mensajes de invalidaciÃ³n enviar. Los mensajes de invalidaciÃ³n son pequeÃ±os porque simplemente identifican objetos obsoletos. AdemÃ¡s, se envÃ­an en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidaciÃ³n, elimina los objetos obsoletos de su cachÃ© y aborta la transacciÃ³n actual si los utilizÃ³. El cliente sigue conservando pÃ¡ginas que contienen objetos invalidados; estas pÃ¡ginas ahora estÃ¡n incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidaciÃ³n de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener pÃ¡ginas incompletas en la cachÃ© del cliente significa que el falso intercambio no conduce a fallos innecesarios en la cachÃ©. Los clientes reconocen las invalidaciones para indicar la eliminaciÃ³n de datos obsoletos, como se explica en la SecciÃ³n 3.1. Los mensajes de invalidaciÃ³n evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo asÃ­ el desperdicio de trabajo y trasladando la detecciÃ³n de abortos de los servidores a los clientes. Cuando una transacciÃ³n se aborta, su cliente restaura las copias en cachÃ© de los objetos modificados al estado que tenÃ­an antes de que la transacciÃ³n comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacciÃ³n. 4.3 RedirecciÃ³n El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de pÃ¡ginas disponibles en el grupo de pares y proporciona una redirecciÃ³n rÃ¡pida y centralizada de recuperaciÃ³n (ver figura 2) entre las cachÃ©s de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan pÃ¡ginas u objetos al incluir esa informaciÃ³n en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la cachÃ© de grupo, el redireccionador realiza un seguimiento del estado de las pÃ¡ginas. Una pÃ¡gina en cachÃ© estÃ¡ completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una pÃ¡gina estÃ¡n marcados como invÃ¡lidos. Solo se utilizan pÃ¡ginas completas por el proceso de recuperaciÃ³n de pares. El protocolo para mantener el estado de la pÃ¡gina cuando las pÃ¡ginas son actualizadas e invalidadas se describe en la SecciÃ³n 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una pÃ¡gina solicitada completa no estÃ¡ disponible en el grupo de pares o si un par necesita confirmar una transacciÃ³n, el redireccionador actÃºa como un proxy de servidor: reenvÃ­a la solicitud al servidor y luego reenvÃ­a la respuesta de vuelta al cliente. AdemÃ¡s, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualizaciÃ³n o informaciÃ³n de invalidaciÃ³n a los clientes que tienen en cachÃ© la pÃ¡gina modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la cachÃ© de grupo de pares combinada estÃ¡ desempeÃ±ando el papel de una Ãºnica cachÃ© de cliente en el sistema base. 4.4 ActualizaciÃ³n de pares La actualizaciÃ³n de pares se implementa de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que una transacciÃ³n se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacciÃ³n generan invalidaciones de objetos para cada grupo de cachÃ© que almacena pÃ¡ginas que contienen los objetos modificados (incluido el grupo que realiza la confirmaciÃ³n). Las invalidaciones se envÃ­an de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en cachÃ© los objetos modificados se deshagan de los datos obsoletos. En grupos de cachÃ© distintos al grupo de confirmaciÃ³n, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas, recopilan las confirmaciones de los clientes y, despuÃ©s de completar la recopilaciÃ³n, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacciÃ³n, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envÃ­an a los clientes que almacenan en cachÃ© esas pÃ¡ginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmaciÃ³n colectiva se propaga al servidor. Una invalidaciÃ³n hace que una pÃ¡gina en cachÃ© no estÃ© disponible para la recuperaciÃ³n de pares, cambiando el estado de una pÃ¡gina completa p a incompleta. Por el contrario, una actualizaciÃ³n de una pÃ¡gina completa conserva el estado completo de la pÃ¡gina. Como se muestra en los estudios de la reconstrucciÃ³n de fragmentos 31 [2], esta propagaciÃ³n de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma pÃ¡gina, la pÃ¡gina conserva su estado completo y permanece disponible para la recuperaciÃ³n entre pares. Por lo tanto, el efecto de la actualizaciÃ³n de pares es similar a la reconstrucciÃ³n de fragmentos ansiosa [2]. TambiÃ©n hemos considerado la posibilidad de permitir que un compaÃ±ero recupere una pÃ¡gina incompleta (con objetos invÃ¡lidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos invÃ¡lidos. 4.5 Vcache El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo mÃ¡s lentos (o fallidos). Como se explica en la SecciÃ³n 3.3, el protocolo de commit Ãºnico permite que una transacciÃ³n T pase la validaciÃ³n si la informaciÃ³n adicional de coherencia proporcionada por el cliente indica que la transacciÃ³n T ha leÃ­do objetos actualizados. Los clientes utilizan los nÃºmeros de versiÃ³n de la pÃ¡gina para proporcionar esta informaciÃ³n adicional de coherencia. Es decir, un cliente incluye el nÃºmero de versiÃ³n de la pÃ¡gina correspondiente a cada objeto en el conjunto de objetos leÃ­dos enviado en la solicitud de confirmaciÃ³n al servidor. Dado que a cada actualizaciÃ³n de objeto comprometido le corresponde un nÃºmero de versiÃ³n de pÃ¡gina Ãºnico, el nÃºmero de versiÃ³n de pÃ¡gina asociado con un objeto permite que el procedimiento de validaciÃ³n en el servidor verifique si la transacciÃ³n del cliente ha leÃ­do objetos actualizados. El uso de versiones de pÃ¡gina de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeÃ±os, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en cachÃ© a la versiÃ³n de pÃ¡gina identificadora (ObjectToVersion). El principal problema de implementaciÃ³n se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian nÃºmeros de versiÃ³n de pÃ¡gina con las invalidaciones. En el momento de la validaciÃ³n, si hay una invalidaciÃ³n no reconocida pendiente para un objeto x leÃ­do por una transacciÃ³n T, el procedimiento de validaciÃ³n verifica si el nÃºmero de versiÃ³n de x en el conjunto de lectura de Ts coincide con el nÃºmero de versiÃ³n de la invalidaciÃ³n pendiente mÃ¡s alta para x, en cuyo caso el valor del objeto estÃ¡ actualizado, de lo contrario, T falla en la validaciÃ³n. Observamos nuevamente que las verificaciones basadas en el nÃºmero de versiÃ³n de la pÃ¡gina y las verificaciones basadas en el reconocimiento de invalidaciÃ³n son complementarias en la validaciÃ³n de confirmaciÃ³n individual y ambas son necesarias. La verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina permite que la validaciÃ³n avance antes de que lleguen las confirmaciones de invalidaciÃ³n, pero por sÃ­ sola, una verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina detecta conflictos a nivel de pÃ¡gina y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cÃ³mo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un nÃºmero de versiÃ³n de la pÃ¡gina para cada pÃ¡gina en cachÃ©. El nÃºmero de versiÃ³n satisface la siguiente invariante V P sobre el estado de los objetos en una pÃ¡gina: si una pÃ¡gina en cachÃ© P tiene un nÃºmero de versiÃ³n v, entonces el valor de un objeto o en la pÃ¡gina en cachÃ© P es invÃ¡lido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacciÃ³n que estableciÃ³ el nÃºmero de versiÃ³n de P en v. Los nuevos valores de objetos y los nuevos nÃºmeros de versiÃ³n de pÃ¡gina llegan cuando un cliente obtiene una pÃ¡gina o cuando llega una respuesta de confirmaciÃ³n o invalidaciones para esta pÃ¡gina. Los nuevos valores del objeto modifican la pÃ¡gina y, por lo tanto, el nÃºmero de versiÃ³n de la pÃ¡gina necesita ser actualizado para mantener la invariante V P. Un nÃºmero de versiÃ³n de pÃ¡gina que llega cuando un cliente obtiene una pÃ¡gina, reemplaza la VersiÃ³n del Objeto x 8 Servidor de RedirecciÃ³n 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el nÃºmero de versiÃ³n de la pÃ¡gina para esta pÃ¡gina. Tal actualizaciÃ³n preserva el invariante V P. De manera similar, un nÃºmero de versiÃ³n de pÃ¡gina en secuencia que llega al cliente en un mensaje de confirmaciÃ³n o invalidaciÃ³n avanza el nÃºmero de versiÃ³n para toda la pÃ¡gina en cachÃ©, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus nÃºmeros de versiÃ³n de pÃ¡gina correspondientes tambiÃ©n pueden llegar al cliente fuera de secuencia, en cuyo caso la actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina podrÃ­a violar V P. Por ejemplo, una respuesta de confirmaciÃ³n para una transacciÃ³n que actualiza el objeto x en la pÃ¡gina P en el servidor S1, y el objeto y en la pÃ¡gina Q en el servidor S2, puede entregar un nuevo nÃºmero de versiÃ³n para P desde el coordinador de transacciones S1 antes de que llegue una invalidaciÃ³n generada para una transacciÃ³n anterior que ha modificado el objeto r en la pÃ¡gina P desde S1 (como se muestra en la figura 5). El protocolo de actualizaciÃ³n de cachÃ© garantiza que el valor de cualquier objeto o en una pÃ¡gina en cachÃ© P refleje la actualizaciÃ³n o invalidaciÃ³n con el nÃºmero de versiÃ³n observado mÃ¡s alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de nÃºmeros de versiÃ³n de pÃ¡gina, el cliente gestiona una pequeÃ±a cachÃ© de nÃºmeros de versiÃ³n vcache que mantiene el mapeo de un objeto a su nÃºmero de versiÃ³n de pÃ¡gina correspondiente para todas las actualizaciones de nÃºmeros de versiÃ³n reordenadas hasta que se ensamble una secuencia completa de nÃºmeros de versiÃ³n de pÃ¡gina. Cuando llegan los nÃºmeros de versiÃ³n faltantes para la pÃ¡gina y completan una secuencia, el nÃºmero de versiÃ³n de toda la pÃ¡gina se avanza. El mapeo de ObjectToVersion, incluyendo los nÃºmeros de versiÃ³n de vcache y pÃ¡gina, se utiliza en el momento de la confirmaciÃ³n de la transacciÃ³n para proporcionar nÃºmeros de versiÃ³n para el conjunto de objetos leÃ­dos de la siguiente manera. Si el objeto leÃ­do tiene una entrada en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n mÃ¡s alto en la vcache para este objeto. Si el objeto no estÃ¡ presente en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n de la pÃ¡gina en cachÃ© que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la cachÃ© del cliente, incluyendo los nÃºmeros de versiÃ³n de las pÃ¡ginas y la vcache. El cliente puede limitar el tamaÃ±o de la cachÃ© virtual segÃºn sea necesario, ya que volver a cargar una pÃ¡gina elimina todos los nÃºmeros de versiÃ³n de pÃ¡gina reordenados de la cachÃ© virtual. Sin embargo, esperamos que la reorganizaciÃ³n de nÃºmeros de versiÃ³n sea poco comÃºn y, por lo tanto, esperamos que la vcache sea muy pequeÃ±a. 5. Un grupo de clientes contiene mÃºltiples nodos de cliente y un objeto de pÃ¡gina de versiÃ³n redi32 VCache Cliente CachÃ© Cliente PÃ¡gina CachÃ© Figura 6: Mapa de Objeto a VersiÃ³n con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutaciÃ³n por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. AdemÃ¡s, el fallo del redireccionador deberÃ­a permitir que los clientes no afectados mantengan sus cachÃ©s intactas. Hemos diseÃ±ado un protocolo de conmutaciÃ³n por error para BuddyCache pero aÃºn no lo hemos implementado. El apÃ©ndice describe el protocolo. 6. La redirecciÃ³n de BuddyCache en la evaluaciÃ³n de rendimiento respalda los beneficios de evitar la comunicaciÃ³n con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes. Â¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 AnÃ¡lisis Los beneficios de rendimiento de la recuperaciÃ³n entre pares y la actualizaciÃ³n entre pares se deben a la evitaciÃ³n de interacciones con el servidor. Esta secciÃ³n presenta un modelo de rendimiento analÃ­tico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la cachÃ© del cliente. Estos pueden ser fallos frÃ­os, fallos de invalidaciÃ³n y fallos de capacidad. Nuestro anÃ¡lisis se centra en los fallos por frÃ­o y los fallos por invalidaciÃ³n, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frÃ­o. AdemÃ¡s, las tendencias tecnolÃ³gicas indican que la capacidad de memoria y almacenamiento seguirÃ¡ creciendo y, por lo tanto, es probable que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ©. Los fallos de cachÃ© del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuraciÃ³n de cachÃ©. Nuestro anÃ¡lisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validaciÃ³n. Para estudiar el beneficio de evitar fallos en frÃ­o, consideramos el rendimiento de la cachÃ© en frÃ­o en una carga de trabajo de solo lectura (sin fallos de invalidaciÃ³n). Esperamos que la recuperaciÃ³n entre pares mejore el costo de latencia para las solicitudes de cachÃ© frÃ­a del cliente al recuperar objetos de la cachÃ© cercana. Evaluamos cÃ³mo el costo de redirecciÃ³n afecta este beneficio al comparar y analizar el rendimiento de una aplicaciÃ³n que se ejecuta en un sistema de almacenamiento con BuddyCache y sin Ã©l (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidaciÃ³n, consideramos el rendimiento de la cachÃ© caliente en una carga de trabajo con modificaciones (sin fallos en frÃ­o). En las cachÃ©s calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualizaciÃ³n entre pares permite que un cliente acceda a un objeto modificado por un compaÃ±ero colaborador cercano sin el retraso impuesto por los protocolos de invalidaciÃ³n Ãºnicamente. En grupos donde los compaÃ±eros comparten un interÃ©s de solo lectura en los objetos modificados, la recuperaciÃ³n entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compaÃ±ero colaborador lo tenga, lo que evita el retraso de la recuperaciÃ³n del servidor sin el alto costo impuesto por los protocolos de solo actualizaciÃ³n. Las tendencias tecnolÃ³gicas indican que ambos beneficios seguirÃ¡n siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualizaciÃ³n Ãºnicamente. Sin embargo, la tendencia hacia cachÃ©s cada vez mÃ¡s grandes, que se actualizan cuando los objetos en cachÃ© son modificados, hace que los protocolos basados en invalidaciÃ³n sean mÃ¡s atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicaciÃ³n que se ejecuta sin BuddyCache y una aplicaciÃ³n que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compaÃ±ero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compaÃ±ero fuera del grupo. La actualizaciÃ³n entre pares tambiÃ©n puede evitar fallos de invalidaciÃ³n debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma pÃ¡gina de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseÃ±o del objeto, y tambiÃ©n porque este beneficio se puede derivar dado el Ã­ndice de aciertos en cachÃ© y la contenciÃ³n de la carga de trabajo. 6.1.1 El Modelo El modelo considera cÃ³mo el tiempo para completar una ejecuciÃ³n con y sin BuddyCache se ve afectado por los fallos de invalidaciÃ³n y los fallos en frÃ­o. Considerando k clientes ejecutÃ¡ndose concurrentemente accediendo de manera uniforme a un conjunto compartido de N pÃ¡ginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacciÃ³n y realizar cÃ¡lculos en una transacciÃ³n, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin Ã©l (Base). Para simplificar, nuestro modelo asume que los tiempos de bÃºsqueda y confirmaciÃ³n son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del nÃºmero total de clientes en el sistema. El nÃºmero de fallos evitados por la recuperaciÃ³n entre pares depende de k, el nÃºmero de clientes en la BuddyCache, y del interÃ©s conjunto de los clientes en los datos compartidos. En una ejecuciÃ³n especÃ­fica de BuddyCache, se modela mediante la variable r, definida como el nÃºmero de solicitudes que llegan al redireccionador para una versiÃ³n dada de la pÃ¡gina P (es decir, hasta que un objeto en la pÃ¡gina se invalida). Considera una ejecuciÃ³n con fallos en frÃ­o. Un cliente comienza con una cachÃ© frÃ­a y ejecuta una carga de trabajo de solo lectura hasta que accede a las N pÃ¡ginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la cachÃ© del cliente es lo suficientemente grande como para contener N pÃ¡ginas. En BC, los frÃ­os fallos para la pÃ¡gina P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consideremos a continuaciÃ³n una ejecuciÃ³n con fallos de invalidaciÃ³n. Un cliente comienza con una cachÃ© caliente que contiene el conjunto de trabajo de N pÃ¡ginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualizaciÃ³n entre pares elimina todos los fallos de invalidaciÃ³n. En un grupo que contiene solo lectores (BCR), durante una ejecuciÃ³n en estado estable con actualizaciones uniformes, una transacciÃ³n del cliente tiene fallos de invalidaciÃ³n faltantes. Considera la secuencia de r fallos de cliente en la pÃ¡gina P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la pÃ¡gina P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frÃ­o, r â‰¤ k porque la segunda invalidaciÃ³n deshabilita la redirecciÃ³n para P hasta que el prÃ³ximo fallo en P provoque una recuperaciÃ³n del servidor. Suponiendo un acceso uniforme, un fallo de invalidaciÃ³n del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperaciÃ³n del servidor), y una probabilidad de (1 âˆ’ 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacciÃ³n Ãºnica en los sistemas Base, BCR y BCW. En los experimentos descritos a continuaciÃ³n, medimos los parÃ¡metros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalizaciÃ³n derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalizaciÃ³n y beneficios medidos directamente en los experimentos. 6.2 ConfiguraciÃ³n Experimental Antes de presentar nuestros resultados, describimos nuestra configuraciÃ³n experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectÃ¡ndose directamente a los servidores. El sistema Buddy ejecuta nuestra implementaciÃ³n del prototipo de BuddyCache en Thor, admitiendo la recuperaciÃ³n de pares, la actualizaciÃ³n de pares y la confirmaciÃ³n en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark estÃ¡ diseÃ±ado para capturar las caracterÃ­sticas de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicaciÃ³n especÃ­fica. Utilizamos OO7 porque es un punto de referencia estÃ¡ndar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un Ã¡rbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un grÃ¡fico de partes atÃ³micas vinculadas por objetos de conexiÃ³n; cada parte atÃ³mica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atÃ³micas por parte compuesta. La base de datos multiusuario asigna a cada cliente un mÃ³dulo privado que consiste en un Ã¡rbol de objetos de ensamblaje, y agrega un mÃ³dulo compartido adicional que escala proporcionalmente al nÃºmero de clientes. Esperamos que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ© y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la cachÃ©. Dado que el objetivo de nuestro estudio es evaluar quÃ© tan efectivamente nuestras tÃ©cnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras tÃ©cnicas tienen en los fallos de cachÃ© frÃ­o y de consistencia de cachÃ©, y aislar tanto como sea posible el efecto de los fallos de capacidad de cachÃ©. Para mantener la duraciÃ³n de nuestros experimentos razonable, utilizamos cachÃ©s pequeÃ±os. El benchmark OO7 genera mÃ³dulos de base de datos de tamaÃ±o predefinido. En nuestra implementaciÃ³n de OO7, el tamaÃ±o del mÃ³dulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la cachÃ©, utilizamos un Ãºnico mÃ³dulo privado y elegimos un tamaÃ±o de cachÃ© de 40MB para cada cliente. La base de datos OO7 se genera con mÃ³dulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos estÃ¡n agrupados en pÃ¡ginas de 8K, que tambiÃ©n son la unidad de transferencia en las solicitudes de recuperaciÃ³n. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro anÃ¡lisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idÃ©ntico a T1 excepto que modifica todas las partes atÃ³micas en un solo compuesto. Una transacciÃ³n Ãºnica incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo mÃ³dulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacciÃ³n, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de bÃºsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una cachÃ© de 50MB (de los cuales 6MB se utilizaron para el bÃºfer de objetos modificados), el cliente tenÃ­a una cachÃ© de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos bÃ¡sicos Esta secciÃ³n analiza el costo bÃ¡sico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 RedirecciÃ³n Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtenciÃ³n del servidor), el costo adicional de la redirecciÃ³n incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperaciÃ³n o confirmaciÃ³n del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmaciÃ³n y recuperaciÃ³n del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de Ã¡rea rÃ¡pida. Todos los nÃºmeros fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirecciÃ³n al cruzar el redireccionador no es muy alto, incluso en una red de Ã¡rea local. El costo de la confirmaciÃ³n aumenta con el nÃºmero de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperaciÃ³n no aumenta tanto porque la cachÃ© del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la cachÃ© del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperaciÃ³n entre pares, medimos la latencia de la recuperaciÃ³n entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperaciÃ³n entre pares, el costo de la redirecciÃ³n incluye, ademÃ¡s del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este Ãºltimo incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la pÃ¡gina solicitada. Medimos directamente el tiempo para copiar y desenrollar la pÃ¡gina solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperaciÃ³n de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador mÃ¡s un viaje de ida y vuelta a travÃ©s de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud mÃ¡s un viaje de ida y vuelta a travÃ©s de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando estÃ¡ bloqueado esperando una respuesta de bÃºsqueda o confirmaciÃ³n. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podrÃ­a ser mitigado por una implementaciÃ³n multi-hilo en un sistema con programaciÃ³n preemptiva. 6.3.2 VersiÃ³n de CachÃ© El commit en solitario permite que un cliente rÃ¡pido que modifica un objeto haga un commit de forma independiente a un compaÃ±ero lento. El mecanismo de confirmaciÃ³n Ãºnica introduce un procesamiento adicional en el servidor durante la validaciÃ³n de la transacciÃ³n, y un procesamiento adicional en el cliente durante la confirmaciÃ³n de la transacciÃ³n y en el momento del procesamiento de actualizaciÃ³n o invalidaciÃ³n. Los gastos generales del lado del servidor son mÃ­nimos y consisten en una actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina en el momento de la confirmaciÃ³n, y una comparaciÃ³n del nÃºmero de versiÃ³n en el momento de la validaciÃ³n de la transacciÃ³n. La cachÃ© de versiÃ³n tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacciÃ³n accede a objetos en mÃºltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor Ãºnico y, por lo tanto, el tiempo de confirmaciÃ³n adicional de la gestiÃ³n de la cachÃ© de versiones en el cliente no contribuye a los resultados presentados en la secciÃ³n a continuaciÃ³n. Para medir estos costos adicionales del lado del cliente en un sistema de mÃºltiples servidores, instrumentamos la implementaciÃ³n de la cachÃ© de versiones para ejecutarse con una traza de carga de trabajo que incluÃ­a invalidaciones reordenadas y cronometramos las operaciones bÃ¡sicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operaciÃ³n de bÃºsqueda de cachÃ© de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n en el momento de preparaciÃ³n de la solicitud de compromiso, y una operaciÃ³n de inserciÃ³n de cachÃ© de versiÃ³n para cada objeto actualizado por una transacciÃ³n en el momento de procesamiento de la respuesta de compromiso, pero solo si la pÃ¡gina actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmaciÃ³n se mantengan al mÃ­nimo, ya que el cliente estÃ¡ esperando de forma sÃ­ncrona la finalizaciÃ³n de la confirmaciÃ³n. Las mediciones muestran que en el peor de los casos, cuando llega un gran nÃºmero de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en pÃ¡ginas reordenadas, el costo de actualizar la cachÃ© de versiÃ³n es de 0.6 ms. El costo de tiempo de invalidaciÃ³n es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementaciÃ³n de la cachÃ© de versiones para reducir aÃºn mÃ¡s estos costos. 6.4 Rendimiento general Esta secciÃ³n examina las mejoras de rendimiento observadas por una aplicaciÃ³n que ejecuta el benchmark OO7 con un BuddyCache en una red de Ã¡rea amplia. 6.4.1 Fallos en frÃ­o Para evaluar las mejoras de rendimiento al evitar fallos en frÃ­o, comparamos el rendimiento de la cachÃ© en frÃ­o del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecuciÃ³n de los sistemas en el entorno de la red de Ã¡rea local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de Ã¡rea amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en cachÃ© frÃ­a. Los nÃºmeros fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frÃ­o solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frÃ­o solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparaciÃ³n con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cÃ¡lculos para el cliente, solicitudes de recuperaciÃ³n directa, recuperaciones de pares y solicitudes de confirmaciÃ³n. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperaciÃ³n entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperaciÃ³n del servidor para cada cliente individual disminuye porque, con mÃ¡s clientes accediendo a un mÃ³dulo compartido de tamaÃ±o fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperaciÃ³n de pares en comparaciÃ³n con la recuperaciÃ³n directa, pero este beneficio se ve contrarrestado por los tiempos de confirmaciÃ³n aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relaciÃ³n con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de cachÃ© 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT funciÃ³n de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias tÃ­picas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Sorprendentemente, los resultados analÃ­ticos predicen la mejora medida muy de cerca, aunque son ligeramente mÃ¡s altos que los valores empÃ­ricos. La razÃ³n principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidaciÃ³n evitados, comparamos el rendimiento de cachÃ© caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interÃ©s de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un Ãºnico cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compaÃ±eros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compaÃ±eros con un grupo que contiene un Ãºnico escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuraciÃ³n simple es suficiente para mostrar el impacto de las tÃ©cnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de cachÃ© caliente de OO7. Obtenemos los nÃºmeros ejecutando 2000 transacciones para filtrar los fallos en frÃ­o y luego medimos el tiempo de las siguientes 1000 transacciones. AquÃ­ nuevamente, los nÃºmeros reportados se derivan de los resultados del experimento de la red de Ã¡rea local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalizaciÃ³n en comparaciÃ³n con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparaciÃ³n con la Base. Este beneficio se debe a la actualizaciÃ³n entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperaciÃ³n entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperaciÃ³n local evitando el retraso de la recuperaciÃ³n desde el servidor. El Ãºltimo es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperaciÃ³n de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperaciÃ³n de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualizaciÃ³n de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relaciÃ³n con Base, y Buddy Writer y Base en relaciÃ³n con Base) en un experimento de cachÃ© activa en funciÃ³n del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualizaciÃ³n entre pares domina el gasto general en la configuraciÃ³n de Writer incluso en redes de baja latencia (la actualizaciÃ³n entre pares incurre en un gasto mÃ­nimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Como en experimentos de cachÃ© frÃ­a, aquÃ­ los resultados analÃ­ticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pÃ©rdida de invalidaciÃ³n es mÃ­nimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de cachÃ© frÃ­a). Como en el caso de cachÃ© frÃ­a, la razÃ³n por la que el modelo analÃ­tico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÃ“N Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en una red de Ã¡rea extensa debido a la alta latencia de red. Este artÃ­culo describe BuddyCache, una nueva tÃ©cnica de almacenamiento en cachÃ© cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La tÃ©cnica mejora el rendimiento y proporciona propiedades sÃ³lidas de correcciÃ³n y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirecciÃ³n para obtener objetos faltantes directamente de las cachÃ©s de los miembros del grupo, y para admitir la actualizaciÃ³n entre pares, una nueva tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirecciÃ³n puede interferir con la disponibilidad del objeto. Solo commit es una nueva tÃ©cnica de validaciÃ³n que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validaciÃ³n detallada utilizando informaciÃ³n de versiÃ³n de grano grueso econÃ³mica. Hemos diseÃ±ado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analÃ­ticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Las principales contribuciones del artÃ­culo son: 1. extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementaciÃ³n del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluaciÃ³n del rendimiento basada en anÃ¡lisis y mediciones de los costos y beneficios de las nuevas tÃ©cnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. TambiÃ©n agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios Ãºtiles que mejoraron este artÃ­culo. 9. REFERENCIAS [1] emulab.net, la InstalaciÃ³n de EmulaciÃ³n de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. ReconstrucciÃ³n de fragmentos: Proporcionando coherencia de cachÃ© global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre GestiÃ³n de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: ComputaciÃ³n en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de cachÃ© hÃ­bridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. RecuperaciÃ³n rÃ¡pida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de cachÃ© en la World Wide Web. En la 17Âª Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluaciÃ³n del rendimiento del sistema de gestiÃ³n de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una cachÃ© de objetos jerÃ¡rquica en Internet. En la Conferencia TÃ©cnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachÃ©s de Internet escalables. Informe TÃ©cnico CS-1997-18, Departamento de Ciencias de la ComputaciÃ³n, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: CachÃ© de proxy cooperativa en una red de Ã¡rea amplia. En el Tercer Taller Internacional de CachÃ© de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. CachÃ© web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2Âº Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. CachÃ© cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilaciÃ³n y en tiempo de ejecuciÃ³n para una memoria compartida distribuida eficiente. En Actas de IEEE, EdiciÃ³n Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la cachÃ©: un protocolo de intercambio de cachÃ© web escalable de Ã¡rea amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. ImplementaciÃ³n de GestiÃ³n Global de Memoria en un ClÃºster de Estaciones de Trabajo. Actas del 15Âº Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: DiseÃ±o, ImplementaciÃ³n y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de cachÃ© transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, pÃ¡ginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. GestiÃ³n global de memoria para arquitecturas de sistemas de gestiÃ³n de bases de datos cliente-servidor. En Actas del 19Âº Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El BÃºfer de Objeto Modificado: Una TÃ©cnica de GestiÃ³n de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto TecnolÃ³gico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. GestiÃ³n de documentos replicados en un sistema de comunicaciÃ³n grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13Âª Conferencia Europea sobre ProgramaciÃ³n Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18Âº Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. ReplicaciÃ³n con marca de vista: un nuevo mÃ©todo de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de ComputaciÃ³n Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalaciÃ³n eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de MultidifusiÃ³n a Nivel de AplicaciÃ³n. En el 3er Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de cachÃ© cooperativa utilizando pistas. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en CachÃ© Global. Informe tÃ©cnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del CachÃ© de Proxies Web Cooperativos. En el 17Âº Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerÃ¡rquica de cachÃ© en una WAN. En el Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. ComparticiÃ³n adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÃ‰NDICE Este apÃ©ndice describe el protocolo de conmutaciÃ³n por error de BuddyCache. Para dar cabida a clientes heterogÃ©neos, incluidos los dispositivos portÃ¡tiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseÃ±o de BuddyCache asume que las cachÃ©s del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresÃ­a detecta el fallo de un cliente o un redireccionador intercambiando mensajes periÃ³dicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutaciÃ³n por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuraciÃ³n y reinicia el protocolo. El protocolo de reconfiguraciÃ³n del grupo es similar al presentado en [25]. AquÃ­ describimos cÃ³mo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de pÃ¡ginas redireccionadas y el reenvÃ­o de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachÃ©s. En caso de un fallo del cliente, el failover elimina las pÃ¡ginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmaciÃ³n, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en cachÃ© las pÃ¡ginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutaciÃ³n por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de pÃ¡ginas utilizando un protocolo similar al descrito en [6]. El redireccionador reciÃ©n reiniciado solicita a los miembros activos del grupo la lista de pÃ¡ginas que estÃ¡n almacenando en cachÃ© y el estado de estas pÃ¡ginas, es decir, si las pÃ¡ginas estÃ¡n completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperaciÃ³n perdida expirarÃ¡ en el cliente y serÃ¡ retransmitida. Una transacciÃ³n que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma despuÃ©s del cambio se trata como una transacciÃ³n regular; una transacciÃ³n que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciarÃ¡ la transacciÃ³n y la solicitud de confirmaciÃ³n serÃ¡ retransmitida despuÃ©s del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caÃ­do podrÃ­an evitar la recolecciÃ³n de basura de las invalidaciones pendientes en los servidores o la cachÃ© virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los nÃºmeros de versiÃ³n Ãºnicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validaciÃ³n de transacciones depende del protocolo de coherencia de cachÃ© para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutaciÃ³n por error de BuddyCache no compromete la correcciÃ³n del procedimiento de validaciÃ³n. Recuerda que la validaciÃ³n de transacciones de BuddyCache utiliza dos mecanismos complementarios, nÃºmeros de versiÃ³n de pÃ¡gina y confirmaciones de invalidaciÃ³n de los clientes, para verificar que una transacciÃ³n ha leÃ­do datos actualizados. La propagaciÃ³n de la confirmaciÃ³n de invalidaciÃ³n (y actualizaciÃ³n) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmaciÃ³n de una modificaciÃ³n (invalidaciÃ³n o actualizaciÃ³n) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en cachÃ© el objeto o bien ha instalado el valor mÃ¡s reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmaciÃ³n de un cliente para una transacciÃ³n T que lee un objeto o despuÃ©s de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidaciÃ³n no confirmada para o pendiente para este grupo, la versiÃ³n del objeto leÃ­da por la transacciÃ³n T estÃ¡ actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validaciÃ³n utilizando nÃºmeros de versiÃ³n. El registro de confirmaciÃ³n de transacciÃ³n contiene un nÃºmero de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n. El protocolo de nÃºmero de versiÃ³n mantiene la invariante V P que garantiza que el valor del objeto o leÃ­do por la transacciÃ³n corresponda al nÃºmero de versiÃ³n mÃ¡s alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificaciÃ³n anterior despuÃ©s de haber recibido una modificaciÃ³n posterior. La retransmisiÃ³n de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validaciÃ³n verifica que el nÃºmero de versiÃ³n en el registro de confirmaciÃ³n coincida con el nÃºmero de versiÃ³n en la invalidaciÃ³n pendiente no reconocida. Es fÃ¡cil ver que, dado que esta comprobaciÃ³n es una comprobaciÃ³n cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutaciÃ³n por error aÃºn no ha sido implementado.",
    "original_sentences": [
        "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
        "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
        "These properties are difficult to provide in wide-area networks because of high network latency.",
        "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
        "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
        "We have implemented a BuddyCache prototype and evaluated its performance.",
        "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
        "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
        "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
        "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
        "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
        "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
        "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
        "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
        "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
        "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
        "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
        "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
        "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
        "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
        "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
        "Cooperative object caching systems [2] provide these properties.",
        "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
        "Interaction with the server increases latency.",
        "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
        "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
        "The engineers use a collaborative CAD application to revise and update complex project design documents.",
        "The shared documents are stored in transactional repository servers at the company home site.",
        "The engineers use workstations running repository clients.",
        "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
        "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
        "A coherence protocol ensures that client caches remain consistent when objects are modified.",
        "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
        "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
        "BuddyCache presents two main technical challenges.",
        "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
        "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
        "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
        "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
        "If the client request can not be served locally, the redirector forwards it to a remote server.",
        "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
        "BuddyCache redirects subsequent requests for this object to the caching client.",
        "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
        "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
        "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
        "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
        "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
        "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
        "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
        "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
        "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
        "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
        "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
        "These techniques use the server to provide redirection and do not consider issues of high network latency.",
        "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
        "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
        "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
        "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
        "This multicast transport level solution is geared to the single writer semantics of web objects.",
        "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
        "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
        "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
        "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
        "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
        "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
        "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
        "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
        "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
        "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
        "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
        "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
        "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
        "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
        "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
        "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
        "The servers provide disk storage for the persistent objects.",
        "A persistent object is owned by a single server.",
        "Objects may be small (order of 100 bytes for programming language objects [23]).",
        "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
        "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
        "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
        "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
        "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
        "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
        "If the client request can be served locally, the interaction with the server is avoided.",
        "If the client request can not be served locally, redirector forwards it to a remote server.",
        "Redirection approach has been used to improve the performance of web caching protocols.",
        "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
        "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
        "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
        "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
        "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
        "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
        "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
        "In addition, redirector manages cache coherence.",
        "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
        "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
        "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
        "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
        "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
        "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
        "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
        "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
        "Below we outline the OCC protocol [3].",
        "The OCC protocol uses object-level coherence.",
        "When a client requests a missing object, the server transfers the containing page.",
        "Transaction can read and update locally cached objects without server intervention.",
        "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
        "If validation fails, the transaction is aborted.",
        "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
        "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
        "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
        "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
        "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
        "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
        "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
        "An important BuddyCache design goal is to maintain this benefit.",
        "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
        "Redirector keeps track of pages cached in each client in a group.",
        "Servers send to the redirector invalidations for pages cached in the entire group.",
        "The redirector propagates invalidations from servers to affected clients.",
        "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
        "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
        "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
        "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
        "The studies show the Committing Client Server Redirector x2.",
        "Store x 6.",
        "Update x 3.",
        "Commit x 4.",
        "Commit OK 5.",
        "Commit OK1.",
        "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
        "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
        "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
        "Larger caches are likely to contain much more data than is actively used.",
        "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
        "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
        "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
        "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
        "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
        "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
        "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
        "The peer update works as follows.",
        "An update commit request from a client arriving at the redirector contains the object updates.",
        "Redirector retains the updates and propagates the request to the coordinating server.",
        "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
        "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
        "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
        "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
        "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
        "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
        "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
        "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
        "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
        "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
        "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
        "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
        "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
        "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
        "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
        "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
        "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
        "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
        "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
        "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
        "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
        "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
        "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
        "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
        "We have not pursued this possibility for several reasons.",
        "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
        "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
        "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
        "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
        "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
        "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
        "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
        "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
        "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
        "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
        "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
        "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
        "All method calls occur within atomic transactions.",
        "Clients communicate with servers to fetch pages or to commit a transaction.",
        "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
        "The disk is organized as a collection of pages which are the units of disk access.",
        "The stable log holds commit information and object modifications for committed transactions.",
        "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
        "The directory keeps track of which pages are cached by which clients.",
        "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
        "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
        "We provide some of the relevant OCC protocol implementation details.",
        "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
        "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
        "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
        "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
        "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
        "Servers will abort a transaction that used obsolete objects.",
        "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
        "Invalidation messages are small because they simply identify obsolete objects.",
        "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
        "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
        "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
        "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
        "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
        "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
        "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
        "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
        "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
        "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
        "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
        "Only complete pages are used by the peer fetch.",
        "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
        "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
        "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
        "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
        "An update commit request from a client arriving at the redirector contains the object updates.",
        "Redirector retains the updates and propagates the request to the coordinator server.",
        "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
        "The redirector forwards the reply to the committing client.",
        "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
        "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
        "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
        "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
        "Within the committing client group, the arriving invalidations are not propagated.",
        "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
        "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
        "In contrast, an update of a complete page preserves the complete page status.",
        "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
        "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
        "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
        "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
        "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
        "Clients use page version numbers to provide this extra coherence information.",
        "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
        "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
        "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
        "The main implementation issue is concerned with maintaining this mapping efficiently.",
        "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
        "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
        "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
        "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
        "We now describe how the client manages the mapping ObjectToVersion.",
        "The client maintains a page version number for each cached page.",
        "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
        "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
        "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
        "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
        "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
        "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
        "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
        "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
        "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
        "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
        "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
        "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
        "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
        "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
        "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
        "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
        "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
        "The appendix outlines the protocol. 6.",
        "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
        "Is the cure worse then the disease?",
        "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
        "This section presents a simple analytical performance model for this benefit.",
        "The avoided server interactions correspond to different types of client cache misses.",
        "These can be cold misses, invalidation misses and capacity misses.",
        "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
        "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
        "The client cache misses are determined by several variables, including the workload and the cache configuration.",
        "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
        "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
        "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
        "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
        "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
        "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
        "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
        "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
        "Technology trends indicate that both benefits will remain important in the foreseeable future.",
        "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
        "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
        "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
        "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
        "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
        "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
        "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
        "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
        "For simplicity, our model assumes the fetch and commit times are constant.",
        "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
        "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
        "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
        "Consider an execution with cold misses.",
        "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
        "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
        "In BC, r cold misses for page P reach the redirector.",
        "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
        "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
        "A client starts with a hot cache containing the working set of N pages.",
        "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
        "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
        "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
        "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
        "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
        "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
        "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
        "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
        "We compute the completion times derived using the above model and derive the benefits.",
        "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
        "We use two systems in our experiments.",
        "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
        "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
        "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
        "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
        "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
        "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
        "We use a medium database that has 200 atomic parts per composite part.",
        "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
        "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
        "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
        "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
        "To keep the length of our experiments reasonable, we use small caches.",
        "The OO7 benchmark generates database modules of predefined size.",
        "In our implementation of OO7, the private module size is about 38MB.",
        "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
        "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
        "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
        "We consider two types of transaction workloads in our analysis, read-only and read-write.",
        "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
        "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
        "A single transaction includes one traversal and there is no sleep time between transactions.",
        "Both read-only and read-write transactions always work with data from the same module.",
        "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
        "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
        "In Base system clients connect directly to the database.",
        "In Buddy system clients connect to the redirector that connects to the database.",
        "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
        "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
        "They were connected by a 100Mb/s Ethernet.",
        "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
        "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
        "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
        "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
        "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
        "All the numbers were computed by averaging measured request latency over 1000 requests.",
        "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
        "The commit cost increases with the number of clients since commits are processed sequentially.",
        "The fetch cost does not increase as much because the server cache reduces this cost.",
        "In a large system with many groups, however, the server cache becomes less efficient.",
        "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
        "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
        "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
        "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
        "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
        "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
        "The local network latency is fixed and less than 0.1 ms.",
        "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
        "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
        "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
        "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
        "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
        "The version cache has an entry only when invalidations or updates arrive out of order.",
        "This may happen when a transaction accesses objects in multiple servers.",
        "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
        "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
        "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
        "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
        "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
        "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
        "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
        "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
        "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
        "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
        "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
        "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
        "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
        "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
        "Figure 8 shows the overall time and cost break down in the 80 ms network.",
        "The BuddyCache provides similar performance improvements as with the 40ms network.",
        "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
        "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
        "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
        "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
        "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
        "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
        "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
        "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
        "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
        "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
        "In Base, one writer and three readers access the server directly.",
        "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
        "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
        "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
        "Here again, the reported numbers are derived from the local area network experiment results.",
        "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
        "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
        "This benefit is due to peer update that avoids all misses due to updates.",
        "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
        "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
        "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
        "This difference is similar in 80ms network.",
        "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
        "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
        "The figure includes both the measured improvement and the improvement derived using the analytical model.",
        "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
        "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
        "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
        "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
        "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
        "These properties are difficult to provide in wide-area network because of high network latency.",
        "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
        "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
        "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
        "Redirection, however, can interfere with object availability.",
        "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
        "It provides fine-grained validation using inexpensive coarse-grain version information.",
        "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
        "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
        "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
        "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
        "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
        "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
        "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
        "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
        "Efficient optimistic concurrencty control using loosely synchronized clocks.",
        "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
        "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
        "Treadmarks: Shared memory computing on networks of workstations.",
        "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
        "Two Adaptive Hybrid Cache Coherency Protocols.",
        "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
        "Fast Crash Recovery in Distributed File Systems.",
        "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
        "Maintaining Strong Cache Consistency in the World Wide Web.",
        "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
        "A Status Report on the OO7 OODBMS Benchmarking Effort.",
        "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
        "A Hierarchical Internet Object Cache.",
        "In USENIX Annual Technical Conference, January 1995. [10] J.",
        "Chase, S. Gadde, and M. Rabinovich.",
        "Directory Structures for Scalable Internet Caches.",
        "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
        "Chase, S. Gadde, and M. Rabinovich.",
        "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
        "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
        "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
        "Cooperative caching: Using remote client memory to improve file system performance.",
        "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
        "Cox, R. Rajamony, and W. Zwaenepoel.",
        "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
        "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
        "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
        "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
        "Implementing Global Memory Management in a Workstation Cluster.",
        "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
        "Integrating Coherency and Recoverablity in Distributed Systems.",
        "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
        "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
        "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
        "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
        "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
        "Global Memory Management for Client-Server DBMS Architectures.",
        "In Proceedings of the 19th Intl.",
        "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
        "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
        "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
        "Replicated document management in a group communication system.",
        "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
        "Providing Persistent Objects in Distributed Systems.",
        "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
        "A Low-bandwidth Network File System.",
        "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
        "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
        "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
        "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
        "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
        "ALMI: An Application Level Multicast Infrastructure.",
        "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
        "Efficient Cooperative Caching Using Hints.",
        "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
        "WebFS: A Global Cache Coherent File System.",
        "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
        "On the Scale and Performance of Cooperative Web Proxy Caching.",
        "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
        "Hierarchical Cache Consistency in a WAN.",
        "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
        "Volume Leases for Consistency in Large-Scale Systems.",
        "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
        "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
        "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
        "APPENDIX This appendix outlines the BuddyCache failover protocol.",
        "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
        "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
        "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
        "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
        "The group reconfiguration protocol is similar to the one presented in [25].",
        "Here we describe how the failover manages the BuddyCache state.",
        "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
        "In the case of a client failure, the failover removes the crashed client pages from the directory.",
        "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
        "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
        "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
        "Requests outstanding at the redirector at the time of the crash may be lost.",
        "A lost fetch request will time out at the client and will be retransmitted.",
        "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
        "A client will restart the transaction and the commit request will be retransmitted after the failover.",
        "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
        "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
        "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
        "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
        "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
        "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
        "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
        "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
        "Now consider the validation using version numbers.",
        "The transaction commit record contains a version number for each object read by the transaction.",
        "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
        "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
        "Retransmition of invalidations and updates maintains this invariant.",
        "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
        "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
        "The failover protocol has not been implemented yet. 39"
    ],
    "translated_text_sentences": [
        "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn.",
        "Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino.",
        "Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red.",
        "BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia.",
        "El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos.",
        "Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento.",
        "Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos.",
        "CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1.",
        "INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan.",
        "Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia.",
        "Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada.",
        "BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia.",
        "Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n.",
        "Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos.",
        "Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24].",
        "Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de Ã¡rea amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de Ã¡rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil.",
        "Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente.",
        "Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte.",
        "El almacenamiento en cachÃ© web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor.",
        "Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos.",
        "Sin embargo, las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina.",
        "Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades.",
        "Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica.",
        "La interacciÃ³n con el servidor aumenta la latencia.",
        "La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia.",
        "Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n.",
        "Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos.",
        "Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa.",
        "Los ingenieros utilizan estaciones de trabajo con clientes de repositorio.",
        "Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta.",
        "Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente.",
        "Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados.",
        "El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos.",
        "Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo.",
        "BuddyCache presenta dos desafÃ­os tÃ©cnicos principales.",
        "Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©.",
        "El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos.",
        "BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de almacenamiento en cachÃ© web cooperativos [11].",
        "Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos.",
        "Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto.",
        "Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten.",
        "BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©.",
        "De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo.",
        "BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo.",
        "Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos.",
        "Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente.",
        "Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica.",
        "Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad?",
        "DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema.",
        "Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red.",
        "Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio.",
        "Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia.",
        "El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida.",
        "Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red.",
        "Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan.",
        "Las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©.",
        "Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina.",
        "Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache.",
        "Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web.",
        "Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales.",
        "La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27].",
        "El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada.",
        "Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN.",
        "El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento.",
        "El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n.",
        "Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un sistema optimista.",
        "Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo.",
        "Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales.",
        "El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos.",
        "Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local.",
        "BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3.",
        "La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de Ã¡rea amplia.",
        "Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o.",
        "Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad.",
        "Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos.",
        "Los servidores proporcionan almacenamiento en disco para los objetos persistentes.",
        "Un objeto persistente es propiedad de un Ãºnico servidor.",
        "Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]).",
        "Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas.",
        "Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente.",
        "Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos.",
        "El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos.",
        "La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos.",
        "El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos.",
        "Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor.",
        "Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto.",
        "El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web.",
        "El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en cachÃ© transaccional [19].",
        "La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente.",
        "Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes.",
        "Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una transacciÃ³n, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©.",
        "BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador.",
        "El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador.",
        "La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado.",
        "AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©.",
        "Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes.",
        "Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©.",
        "Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina).",
        "La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente.",
        "El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a.",
        "Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual.",
        "Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n.",
        "Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento.",
        "A continuaciÃ³n, detallamos el protocolo OCC [3].",
        "El protocolo OCC utiliza coherencia a nivel de objeto.",
        "Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene.",
        "La transacciÃ³n puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor.",
        "Sin embargo, antes de que una transacciÃ³n se confirme, debe ser validada; el servidor debe asegurarse de que la transacciÃ³n validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada.",
        "Si la validaciÃ³n falla, la transacciÃ³n se cancela.",
        "Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de bÃºsqueda de pares envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen.",
        "Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la cachÃ© y envÃ­an confirmaciones en segundo plano para informar al servidor al respecto.",
        "Dado que las invalidaciones eliminan objetos obsoletos de la cachÃ© del cliente, la confirmaciÃ³n de invalidaciÃ³n indica al servidor que un cliente sin invalidaciones pendientes ha leÃ­do objetos actualizados.",
        "Una invalidaciÃ³n no reconocida indica que un objeto obsoleto puede haber sido accedido en la cachÃ© del cliente.",
        "El procedimiento de validaciÃ³n en el servidor aborta una transacciÃ³n del cliente si este lee un objeto mientras hay una invalidaciÃ³n pendiente.",
        "El mecanismo de invalidaciÃ³n reconocido admite coherencia de cachÃ© a nivel de objeto sin directorios basados en objetos o nÃºmeros de versiÃ³n por objeto.",
        "Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeÃ±os, ya que los objetos tÃ­picos son pequeÃ±os.",
        "Un objetivo importante del diseÃ±o de BuddyCache es mantener este beneficio.",
        "Dado que en BuddyCache una pÃ¡gina puede ser recuperada en una cachÃ© de cliente sin intervenciÃ³n del servidor (como se ilustra en la figura 2), los directorios de cachÃ© en los servidores llevan un registro de las pÃ¡ginas almacenadas en cada grupo colaborador en lugar de en cada cliente.",
        "El redireccionador lleva un registro de las pÃ¡ginas almacenadas en cachÃ© en cada cliente de un grupo.",
        "Los servidores envÃ­an al redireccionador invalidaciones para las pÃ¡ginas almacenadas en cachÃ© en todo el grupo.",
        "El redireccionador propaga invalidaciones desde los servidores a los clientes afectados.",
        "Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. ActualizaciÃ³n de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en cachÃ© por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interÃ©s potencial para los miembros del grupo.",
        "El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento.",
        "Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de cachÃ© y las actualizaciones de cachÃ©.",
        "Los estudios de coherencia de cachÃ© en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualizaciÃ³n y la invalidaciÃ³n.",
        "Los estudios muestran el redireccionador del servidor del cliente comprometido x2.",
        "AlmacÃ©n x 6.",
        "ActualizaciÃ³n x 3.",
        "CompromÃ©tete x 4.",
        "Compromiso OK 5.",
        "Comprometer OK1.",
        "La figura 3 muestra que los beneficios del compromiso de pares estÃ¡n fuertemente influenciados por la carga de trabajo.",
        "En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeÃ±as, agrupadas y se envÃ­an junto con otros mensajes.",
        "AdemÃ¡s, los protocolos de invalidaciÃ³n se ajustan a la tendencia actual de hardware de aumentar los tamaÃ±os de cachÃ© del cliente.",
        "Es probable que las cachÃ©s mÃ¡s grandes contengan mucha mÃ¡s informaciÃ³n de la que se utiliza activamente.",
        "Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una red de Ã¡rea amplia serÃ­an derrochadores.",
        "Sin embargo, los protocolos de coherencia basados en invalidaciÃ³n pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interÃ©s para otro miembro del grupo.",
        "Con un protocolo basado en invalidaciÃ³n, la actualizaciÃ³n de un miembro invalidarÃ¡ la copia en cachÃ© de otro miembro, lo que provocarÃ¡ que este Ãºltimo realice una recuperaciÃ³n de alto retardo del nuevo valor desde el servidor.",
        "BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualizaciÃ³n e invalidaciÃ³n en entornos de redes de Ã¡rea amplia.",
        "Evita la penalizaciÃ³n de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo.",
        "Esto evita la penalizaciÃ³n de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores.",
        "Hasta donde sabemos, este uso de multidifusiÃ³n localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en cachÃ© anteriores.",
        "La actualizaciÃ³n entre pares funciona de la siguiente manera.",
        "Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto.",
        "El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador.",
        "DespuÃ©s de que la transacciÃ³n se confirma, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando.",
        "El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n, y tambiÃ©n propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3).",
        "Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmaciÃ³n. 3.3 ConfirmaciÃ³n individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminaciÃ³n de datos obsoletos.",
        "El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en cachÃ© transaccional, ya que un cliente que es lento para reconocer una invalidaciÃ³n o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacciÃ³n.",
        "Por ejemplo, un ingeniero que realiza una revisiÃ³n repetida al mismo objeto de diseÃ±o compartido (y por lo tanto tiene la Ãºltima versiÃ³n del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor.",
        "Considera una situaciÃ³n representada en la figura 4 donde el Cliente1 realiza una transacciÃ³n T que lee la Ãºltima versiÃ³n de un objeto x en la pÃ¡gina P recientemente modificada por el Cliente1.",
        "Si la solicitud de confirmaciÃ³n para T llega al servidor antes de que la confirmaciÃ³n colectiva de Cliente2 por la Ãºltima modificaciÃ³n de x llegue al servidor, el procedimiento de validaciÃ³n de OCC considera que x estÃ¡ obsoleto y aborta T (porque, como se explicÃ³ anteriormente, una invalidaciÃ³n no reconocida por un cliente actÃºa como indicaciÃ³n para el servidor de que el valor del objeto en cachÃ© estÃ¡ obsoleto en el cliente).",
        "Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la correcciÃ³n del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos.",
        "Las invalidaciones asÃ­ncronas son una parte importante de la razÃ³n por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasiÃ³n de mejor rendimiento [3].",
        "Sin embargo, dado que las invalidaciones se envÃ­an y procesan de forma asÃ­ncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente.",
        "Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devoluciÃ³n de llamada jerÃ¡rquica [32], pero la naturaleza asincrÃ³nica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrÃ³nicas.",
        "El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a un cliente con objetos actualizados confirmar una transacciÃ³n incluso si la confirmaciÃ³n del grupo se retrasa debido a pares lentos o caÃ­dos.",
        "El protocolo requiere que los clientes incluyan informaciÃ³n adicional con los conjuntos de lectura de transacciones en el mensaje de confirmaciÃ³n, para indicar al servidor que los objetos leÃ­dos por la transacciÃ³n estÃ¡n actualizados.",
        "Los nÃºmeros de versiÃ³n de los objetos podrÃ­an proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionÃ³ anteriormente, mantener nÃºmeros de versiÃ³n por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaÃ±o de directorio) en todo el sistema de objetos cuando los objetos son pequeÃ±os [23].",
        "En cambio, solo utiliza nÃºmeros de versiÃ³n de pÃ¡gina de grano grueso para identificar versiones de objetos de grano fino.",
        "El nÃºmero de versiÃ³n de una pÃ¡gina se incrementa en un servidor cuando una transacciÃ³n que modifica objetos en la pÃ¡gina se confirma.",
        "Las actualizaciones realizadas por una Ãºnica transacciÃ³n y las invalidaciones correspondientes son identificadas de manera Ãºnica por el nÃºmero de versiÃ³n de la pÃ¡gina modificada.",
        "Los nÃºmeros de versiÃ³n de la pÃ¡gina se propagan a los clientes en respuestas de recuperaciÃ³n, respuestas de confirmaciÃ³n y con invalidaciones, y los clientes incluyen los nÃºmeros de versiÃ³n de la pÃ¡gina en las solicitudes de confirmaciÃ³n enviadas a los servidores.",
        "Si una transacciÃ³n falla en la validaciÃ³n debido a la falta de reconocimiento de grupo, el servidor verifica los nÃºmeros de versiÃ³n de pÃ¡gina de los objetos en el conjunto de lectura de la transacciÃ³n y permite que la transacciÃ³n se confirme si el cliente ha leÃ­do desde la Ãºltima versiÃ³n de la pÃ¡gina.",
        "Los nÃºmeros de versiÃ³n de la pÃ¡gina permiten confirmaciones independientes, pero las verificaciones de versiÃ³n de pÃ¡gina solo detectan conflictos a nivel de pÃ¡gina.",
        "Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas.",
        "La secciÃ³n 4 describe los detalles de la implementaciÃ³n del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 ConfiguraciÃ³n de Grupo La arquitectura BuddyCache admite mÃºltiples grupos de pares concurrentes.",
        "Potencialmente, puede ser mÃ¡s rÃ¡pido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto.",
        "En tal caso, podrÃ­a ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en cachÃ© de pares de mÃºltiples niveles.",
        "No hemos seguido esta posibilidad por varias razones.",
        "En las cargas de trabajo de almacenamiento en cachÃ© web, simplemente aumentar la poblaciÃ³n de clientes en una cachÃ© proxy a menudo aumenta la tasa general de aciertos en la cachÃ© [30].",
        "En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacciÃ³n explÃ­cita entre clientes y la colaboraciÃ³n, lo que sugiere que es poco probable que ocurra la recuperaciÃ³n entre grupos.",
        "AdemÃ¡s, las mediciones de sistemas de almacenamiento en cachÃ© web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexiÃ³n de red entre los grupos de pares sea muy rÃ¡pida.",
        "Estamos principalmente interesados en entornos donde compaÃ±eros que colaboran estrechamente tienen una conectividad rÃ¡pida a corta distancia, pero la conexiÃ³n entre grupos de compaÃ±eros puede ser lenta.",
        "Como resultado, decidimos que el soporte para la recuperaciÃ³n entre grupos en BuddyCache no es una alta prioridad en este momento.",
        "Para apoyar a compaÃ±eros con recursos heterogÃ©neos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compaÃ±eros o, cuando estÃ© disponible, en un nodo separado dentro de la infraestructura del sitio.",
        "AdemÃ¡s, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una cachÃ© de pares en espera para recibir pÃ¡ginas recuperadas por otros pares, emulando una cachÃ© central algo similar a una cachÃ© de proxy web regional.",
        "Desde el punto de vista del protocolo de coherencia de cachÃ© BuddyCache, sin embargo, un cachÃ© de compaÃ±ero en espera es equivalente a un cachÃ© de compaÃ±ero regular y, por lo tanto, no consideramos este caso por separado en la discusiÃ³n de este documento. 4.",
        "En esta secciÃ³n proporcionamos los detalles de la implementaciÃ³n de BuddyCache.",
        "Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23].",
        "Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en cachÃ© de estos objetos.",
        "Las aplicaciones se ejecutan en los clientes e interactÃºan con el sistema realizando llamadas a mÃ©todos de objetos en cachÃ©.",
        "Todas las llamadas a mÃ©todos ocurren dentro de transacciones atÃ³micas.",
        "Los clientes se comunican con los servidores para obtener pÃ¡ginas o realizar una transacciÃ³n.",
        "Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volÃ¡til.",
        "El disco estÃ¡ organizado como una colecciÃ³n de pÃ¡ginas que son las unidades de acceso al disco.",
        "El registro estable guarda la informaciÃ³n de confirmaciÃ³n y las modificaciones de objetos para transacciones confirmadas.",
        "La memoria del servidor contiene un directorio de cachÃ© y una cachÃ© de objetos modificados recuperable llamada MOB.",
        "El directorio lleva un registro de quÃ© pÃ¡ginas estÃ¡n almacenadas en cachÃ© por quÃ© clientes.",
        "El MOB contiene objetos recientemente modificados que aÃºn no han sido escritos de vuelta en sus pÃ¡ginas en disco.",
        "A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de cachÃ© base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la SecciÃ³n 3.1.",
        "Proporcionamos algunos de los detalles relevantes de la implementaciÃ³n del protocolo OCC.",
        "El cliente lleva un registro de los objetos que son leÃ­dos y modificados por su transacciÃ³n; envÃ­a esta informaciÃ³n, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacciÃ³n.",
        "Los servidores determinan si la confirmaciÃ³n es posible, utilizando un protocolo de confirmaciÃ³n de dos fases si la transacciÃ³n utilizÃ³ objetos en mÃºltiples servidores.",
        "Si la transacciÃ³n se lleva a cabo, las nuevas copias de los objetos modificados se aÃ±aden al registro y tambiÃ©n se insertan en el MOB.",
        "El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperaciÃ³n escaneando el registro.",
        "Dado que los objetos no estÃ¡n bloqueados antes de ser utilizados, una confirmaciÃ³n de transacciÃ³n puede hacer que las cachÃ©s contengan objetos obsoletos.",
        "Los servidores abortarÃ¡n una transacciÃ³n que haya utilizado objetos obsoletos.",
        "Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviÃ¡ndoles mensajes de invalidaciÃ³n; un servidor utiliza su directorio y la informaciÃ³n sobre la transacciÃ³n de confirmaciÃ³n para determinar quÃ© mensajes de invalidaciÃ³n enviar.",
        "Los mensajes de invalidaciÃ³n son pequeÃ±os porque simplemente identifican objetos obsoletos.",
        "AdemÃ¡s, se envÃ­an en segundo plano, agrupados y transportados junto con otros mensajes.",
        "Cuando un cliente recibe un mensaje de invalidaciÃ³n, elimina los objetos obsoletos de su cachÃ© y aborta la transacciÃ³n actual si los utilizÃ³.",
        "El cliente sigue conservando pÃ¡ginas que contienen objetos invalidados; estas pÃ¡ginas ahora estÃ¡n incompletas con agujeros en lugar de los objetos invalidados.",
        "Realizar la invalidaciÃ³n de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener pÃ¡ginas incompletas en la cachÃ© del cliente significa que el falso intercambio no conduce a fallos innecesarios en la cachÃ©.",
        "Los clientes reconocen las invalidaciones para indicar la eliminaciÃ³n de datos obsoletos, como se explica en la SecciÃ³n 3.1.",
        "Los mensajes de invalidaciÃ³n evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo asÃ­ el desperdicio de trabajo y trasladando la detecciÃ³n de abortos de los servidores a los clientes.",
        "Cuando una transacciÃ³n se aborta, su cliente restaura las copias en cachÃ© de los objetos modificados al estado que tenÃ­an antes de que la transacciÃ³n comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacciÃ³n. 4.3 RedirecciÃ³n El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura.",
        "Mantiene un directorio de pÃ¡ginas disponibles en el grupo de pares y proporciona una redirecciÃ³n rÃ¡pida y centralizada de recuperaciÃ³n (ver figura 2) entre las cachÃ©s de pares.",
        "Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan pÃ¡ginas u objetos al incluir esa informaciÃ³n en los mensajes enviados al redireccionador.",
        "Para asegurar que los objetos actualizados se obtengan de la cachÃ© de grupo, el redireccionador realiza un seguimiento del estado de las pÃ¡ginas.",
        "Una pÃ¡gina en cachÃ© estÃ¡ completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una pÃ¡gina estÃ¡n marcados como invÃ¡lidos.",
        "Solo se utilizan pÃ¡ginas completas por el proceso de recuperaciÃ³n de pares.",
        "El protocolo para mantener el estado de la pÃ¡gina cuando las pÃ¡ginas son actualizadas e invalidadas se describe en la SecciÃ³n 4.4.",
        "Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una pÃ¡gina solicitada completa no estÃ¡ disponible en el grupo de pares o si un par necesita confirmar una transacciÃ³n, el redireccionador actÃºa como un proxy de servidor: reenvÃ­a la solicitud al servidor y luego reenvÃ­a la respuesta de vuelta al cliente.",
        "AdemÃ¡s, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualizaciÃ³n o informaciÃ³n de invalidaciÃ³n a los clientes que tienen en cachÃ© la pÃ¡gina modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3).",
        "El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la cachÃ© de grupo de pares combinada estÃ¡ desempeÃ±ando el papel de una Ãºnica cachÃ© de cliente en el sistema base. 4.4 ActualizaciÃ³n de pares La actualizaciÃ³n de pares se implementa de la siguiente manera.",
        "Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto.",
        "El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador.",
        "DespuÃ©s de que una transacciÃ³n se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando.",
        "El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n.",
        "Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3).",
        "Los servidores participantes que albergan objetos modificados por la transacciÃ³n generan invalidaciones de objetos para cada grupo de cachÃ© que almacena pÃ¡ginas que contienen los objetos modificados (incluido el grupo que realiza la confirmaciÃ³n).",
        "Las invalidaciones se envÃ­an de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en cachÃ© los objetos modificados se deshagan de los datos obsoletos.",
        "En grupos de cachÃ© distintos al grupo de confirmaciÃ³n, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas, recopilan las confirmaciones de los clientes y, despuÃ©s de completar la recopilaciÃ³n, propagan las confirmaciones colectivas de vuelta al servidor.",
        "Dentro del grupo de clientes que realizan la transacciÃ³n, las invalidaciones que llegan no se propagan.",
        "En cambio, las actualizaciones se envÃ­an a los clientes que almacenan en cachÃ© esas pÃ¡ginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmaciÃ³n colectiva se propaga al servidor.",
        "Una invalidaciÃ³n hace que una pÃ¡gina en cachÃ© no estÃ© disponible para la recuperaciÃ³n de pares, cambiando el estado de una pÃ¡gina completa p a incompleta.",
        "Por el contrario, una actualizaciÃ³n de una pÃ¡gina completa conserva el estado completo de la pÃ¡gina.",
        "Como se muestra en los estudios de la reconstrucciÃ³n de fragmentos 31 [2], esta propagaciÃ³n de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento.",
        "Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma pÃ¡gina, la pÃ¡gina conserva su estado completo y permanece disponible para la recuperaciÃ³n entre pares.",
        "Por lo tanto, el efecto de la actualizaciÃ³n de pares es similar a la reconstrucciÃ³n de fragmentos ansiosa [2].",
        "TambiÃ©n hemos considerado la posibilidad de permitir que un compaÃ±ero recupere una pÃ¡gina incompleta (con objetos invÃ¡lidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos invÃ¡lidos. 4.5 Vcache El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo mÃ¡s lentos (o fallidos).",
        "Como se explica en la SecciÃ³n 3.3, el protocolo de commit Ãºnico permite que una transacciÃ³n T pase la validaciÃ³n si la informaciÃ³n adicional de coherencia proporcionada por el cliente indica que la transacciÃ³n T ha leÃ­do objetos actualizados.",
        "Los clientes utilizan los nÃºmeros de versiÃ³n de la pÃ¡gina para proporcionar esta informaciÃ³n adicional de coherencia.",
        "Es decir, un cliente incluye el nÃºmero de versiÃ³n de la pÃ¡gina correspondiente a cada objeto en el conjunto de objetos leÃ­dos enviado en la solicitud de confirmaciÃ³n al servidor.",
        "Dado que a cada actualizaciÃ³n de objeto comprometido le corresponde un nÃºmero de versiÃ³n de pÃ¡gina Ãºnico, el nÃºmero de versiÃ³n de pÃ¡gina asociado con un objeto permite que el procedimiento de validaciÃ³n en el servidor verifique si la transacciÃ³n del cliente ha leÃ­do objetos actualizados.",
        "El uso de versiones de pÃ¡gina de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeÃ±os, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en cachÃ© a la versiÃ³n de pÃ¡gina identificadora (ObjectToVersion).",
        "El principal problema de implementaciÃ³n se refiere a mantener este mapeo de manera eficiente.",
        "En el lado del servidor, cuando se realizan modificaciones, los servidores asocian nÃºmeros de versiÃ³n de pÃ¡gina con las invalidaciones.",
        "En el momento de la validaciÃ³n, si hay una invalidaciÃ³n no reconocida pendiente para un objeto x leÃ­do por una transacciÃ³n T, el procedimiento de validaciÃ³n verifica si el nÃºmero de versiÃ³n de x en el conjunto de lectura de Ts coincide con el nÃºmero de versiÃ³n de la invalidaciÃ³n pendiente mÃ¡s alta para x, en cuyo caso el valor del objeto estÃ¡ actualizado, de lo contrario, T falla en la validaciÃ³n.",
        "Observamos nuevamente que las verificaciones basadas en el nÃºmero de versiÃ³n de la pÃ¡gina y las verificaciones basadas en el reconocimiento de invalidaciÃ³n son complementarias en la validaciÃ³n de confirmaciÃ³n individual y ambas son necesarias.",
        "La verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina permite que la validaciÃ³n avance antes de que lleguen las confirmaciones de invalidaciÃ³n, pero por sÃ­ sola, una verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina detecta conflictos a nivel de pÃ¡gina y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto.",
        "Ahora describimos cÃ³mo el cliente gestiona el mapeo ObjectToVersion.",
        "El cliente mantiene un nÃºmero de versiÃ³n de la pÃ¡gina para cada pÃ¡gina en cachÃ©.",
        "El nÃºmero de versiÃ³n satisface la siguiente invariante V P sobre el estado de los objetos en una pÃ¡gina: si una pÃ¡gina en cachÃ© P tiene un nÃºmero de versiÃ³n v, entonces el valor de un objeto o en la pÃ¡gina en cachÃ© P es invÃ¡lido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacciÃ³n que estableciÃ³ el nÃºmero de versiÃ³n de P en v. Los nuevos valores de objetos y los nuevos nÃºmeros de versiÃ³n de pÃ¡gina llegan cuando un cliente obtiene una pÃ¡gina o cuando llega una respuesta de confirmaciÃ³n o invalidaciones para esta pÃ¡gina.",
        "Los nuevos valores del objeto modifican la pÃ¡gina y, por lo tanto, el nÃºmero de versiÃ³n de la pÃ¡gina necesita ser actualizado para mantener la invariante V P. Un nÃºmero de versiÃ³n de pÃ¡gina que llega cuando un cliente obtiene una pÃ¡gina, reemplaza la VersiÃ³n del Objeto x 8 Servidor de RedirecciÃ³n 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el nÃºmero de versiÃ³n de la pÃ¡gina para esta pÃ¡gina.",
        "Tal actualizaciÃ³n preserva el invariante V P. De manera similar, un nÃºmero de versiÃ³n de pÃ¡gina en secuencia que llega al cliente en un mensaje de confirmaciÃ³n o invalidaciÃ³n avanza el nÃºmero de versiÃ³n para toda la pÃ¡gina en cachÃ©, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus nÃºmeros de versiÃ³n de pÃ¡gina correspondientes tambiÃ©n pueden llegar al cliente fuera de secuencia, en cuyo caso la actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina podrÃ­a violar V P. Por ejemplo, una respuesta de confirmaciÃ³n para una transacciÃ³n que actualiza el objeto x en la pÃ¡gina P en el servidor S1, y el objeto y en la pÃ¡gina Q en el servidor S2, puede entregar un nuevo nÃºmero de versiÃ³n para P desde el coordinador de transacciones S1 antes de que llegue una invalidaciÃ³n generada para una transacciÃ³n anterior que ha modificado el objeto r en la pÃ¡gina P desde S1 (como se muestra en la figura 5).",
        "El protocolo de actualizaciÃ³n de cachÃ© garantiza que el valor de cualquier objeto o en una pÃ¡gina en cachÃ© P refleje la actualizaciÃ³n o invalidaciÃ³n con el nÃºmero de versiÃ³n observado mÃ¡s alto.",
        "Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto.",
        "Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de nÃºmeros de versiÃ³n de pÃ¡gina, el cliente gestiona una pequeÃ±a cachÃ© de nÃºmeros de versiÃ³n vcache que mantiene el mapeo de un objeto a su nÃºmero de versiÃ³n de pÃ¡gina correspondiente para todas las actualizaciones de nÃºmeros de versiÃ³n reordenadas hasta que se ensamble una secuencia completa de nÃºmeros de versiÃ³n de pÃ¡gina.",
        "Cuando llegan los nÃºmeros de versiÃ³n faltantes para la pÃ¡gina y completan una secuencia, el nÃºmero de versiÃ³n de toda la pÃ¡gina se avanza.",
        "El mapeo de ObjectToVersion, incluyendo los nÃºmeros de versiÃ³n de vcache y pÃ¡gina, se utiliza en el momento de la confirmaciÃ³n de la transacciÃ³n para proporcionar nÃºmeros de versiÃ³n para el conjunto de objetos leÃ­dos de la siguiente manera.",
        "Si el objeto leÃ­do tiene una entrada en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n mÃ¡s alto en la vcache para este objeto.",
        "Si el objeto no estÃ¡ presente en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n de la pÃ¡gina en cachÃ© que lo contiene.",
        "La Figura 6 muestra el mapeo de ObjectToVersion en la cachÃ© del cliente, incluyendo los nÃºmeros de versiÃ³n de las pÃ¡ginas y la vcache.",
        "El cliente puede limitar el tamaÃ±o de la cachÃ© virtual segÃºn sea necesario, ya que volver a cargar una pÃ¡gina elimina todos los nÃºmeros de versiÃ³n de pÃ¡gina reordenados de la cachÃ© virtual.",
        "Sin embargo, esperamos que la reorganizaciÃ³n de nÃºmeros de versiÃ³n sea poco comÃºn y, por lo tanto, esperamos que la vcache sea muy pequeÃ±a. 5.",
        "Un grupo de clientes contiene mÃºltiples nodos de cliente y un objeto de pÃ¡gina de versiÃ³n redi32 VCache Cliente CachÃ© Cliente PÃ¡gina CachÃ© Figura 6: Mapa de Objeto a VersiÃ³n con vcache rector que puede fallar de forma independiente.",
        "El objetivo del protocolo de conmutaciÃ³n por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos.",
        "AdemÃ¡s, el fallo del redireccionador deberÃ­a permitir que los clientes no afectados mantengan sus cachÃ©s intactas.",
        "Hemos diseÃ±ado un protocolo de conmutaciÃ³n por error para BuddyCache pero aÃºn no lo hemos implementado.",
        "El apÃ©ndice describe el protocolo. 6.",
        "La redirecciÃ³n de BuddyCache en la evaluaciÃ³n de rendimiento respalda los beneficios de evitar la comunicaciÃ³n con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes.",
        "Â¿Es la cura peor que la enfermedad?",
        "Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 AnÃ¡lisis Los beneficios de rendimiento de la recuperaciÃ³n entre pares y la actualizaciÃ³n entre pares se deben a la evitaciÃ³n de interacciones con el servidor.",
        "Esta secciÃ³n presenta un modelo de rendimiento analÃ­tico simple para este beneficio.",
        "Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la cachÃ© del cliente.",
        "Estos pueden ser fallos frÃ­os, fallos de invalidaciÃ³n y fallos de capacidad.",
        "Nuestro anÃ¡lisis se centra en los fallos por frÃ­o y los fallos por invalidaciÃ³n, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frÃ­o.",
        "AdemÃ¡s, las tendencias tecnolÃ³gicas indican que la capacidad de memoria y almacenamiento seguirÃ¡ creciendo y, por lo tanto, es probable que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ©.",
        "Los fallos de cachÃ© del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuraciÃ³n de cachÃ©.",
        "Nuestro anÃ¡lisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validaciÃ³n.",
        "Para estudiar el beneficio de evitar fallos en frÃ­o, consideramos el rendimiento de la cachÃ© en frÃ­o en una carga de trabajo de solo lectura (sin fallos de invalidaciÃ³n).",
        "Esperamos que la recuperaciÃ³n entre pares mejore el costo de latencia para las solicitudes de cachÃ© frÃ­a del cliente al recuperar objetos de la cachÃ© cercana.",
        "Evaluamos cÃ³mo el costo de redirecciÃ³n afecta este beneficio al comparar y analizar el rendimiento de una aplicaciÃ³n que se ejecuta en un sistema de almacenamiento con BuddyCache y sin Ã©l (llamado Base).",
        "Para estudiar el beneficio de evitar los fallos de invalidaciÃ³n, consideramos el rendimiento de la cachÃ© caliente en una carga de trabajo con modificaciones (sin fallos en frÃ­o).",
        "En las cachÃ©s calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos.",
        "La actualizaciÃ³n entre pares permite que un cliente acceda a un objeto modificado por un compaÃ±ero colaborador cercano sin el retraso impuesto por los protocolos de invalidaciÃ³n Ãºnicamente.",
        "En grupos donde los compaÃ±eros comparten un interÃ©s de solo lectura en los objetos modificados, la recuperaciÃ³n entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compaÃ±ero colaborador lo tenga, lo que evita el retraso de la recuperaciÃ³n del servidor sin el alto costo impuesto por los protocolos de solo actualizaciÃ³n.",
        "Las tendencias tecnolÃ³gicas indican que ambos beneficios seguirÃ¡n siendo importantes en el futuro previsible.",
        "La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualizaciÃ³n Ãºnicamente.",
        "Sin embargo, la tendencia hacia cachÃ©s cada vez mÃ¡s grandes, que se actualizan cuando los objetos en cachÃ© son modificados, hace que los protocolos basados en invalidaciÃ³n sean mÃ¡s atractivos.",
        "Para evaluar estos dos beneficios consideramos el rendimiento de una aplicaciÃ³n que se ejecuta sin BuddyCache y una aplicaciÃ³n que se ejecuta con BuddyCache en dos configuraciones.",
        "Uno, donde un compaÃ±ero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compaÃ±ero fuera del grupo.",
        "La actualizaciÃ³n entre pares tambiÃ©n puede evitar fallos de invalidaciÃ³n debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma pÃ¡gina de forma concurrente.",
        "No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseÃ±o del objeto, y tambiÃ©n porque este beneficio se puede derivar dado el Ã­ndice de aciertos en cachÃ© y la contenciÃ³n de la carga de trabajo. 6.1.1 El Modelo El modelo considera cÃ³mo el tiempo para completar una ejecuciÃ³n con y sin BuddyCache se ve afectado por los fallos de invalidaciÃ³n y los fallos en frÃ­o.",
        "Considerando k clientes ejecutÃ¡ndose concurrentemente accediendo de manera uniforme a un conjunto compartido de N pÃ¡ginas en BuddyCache (BC) y Base.",
        "Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacciÃ³n y realizar cÃ¡lculos en una transacciÃ³n, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin Ã©l (Base).",
        "Para simplificar, nuestro modelo asume que los tiempos de bÃºsqueda y confirmaciÃ³n son constantes.",
        "En general, pueden variar con la carga del servidor, por ejemplo, dependen del nÃºmero total de clientes en el sistema.",
        "El nÃºmero de fallos evitados por la recuperaciÃ³n entre pares depende de k, el nÃºmero de clientes en la BuddyCache, y del interÃ©s conjunto de los clientes en los datos compartidos.",
        "En una ejecuciÃ³n especÃ­fica de BuddyCache, se modela mediante la variable r, definida como el nÃºmero de solicitudes que llegan al redireccionador para una versiÃ³n dada de la pÃ¡gina P (es decir, hasta que un objeto en la pÃ¡gina se invalida).",
        "Considera una ejecuciÃ³n con fallos en frÃ­o.",
        "Un cliente comienza con una cachÃ© frÃ­a y ejecuta una carga de trabajo de solo lectura hasta que accede a las N pÃ¡ginas mientras realiza l transacciones.",
        "Suponemos que no hay fallos de capacidad, es decir, que la cachÃ© del cliente es lo suficientemente grande como para contener N pÃ¡ginas.",
        "En BC, los frÃ­os fallos para la pÃ¡gina P llegan al redireccionador.",
        "El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos.",
        "Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consideremos a continuaciÃ³n una ejecuciÃ³n con fallos de invalidaciÃ³n.",
        "Un cliente comienza con una cachÃ© caliente que contiene el conjunto de trabajo de N pÃ¡ginas.",
        "Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura.",
        "En un grupo que contiene al escritor (BCW), la actualizaciÃ³n entre pares elimina todos los fallos de invalidaciÃ³n.",
        "En un grupo que contiene solo lectores (BCR), durante una ejecuciÃ³n en estado estable con actualizaciones uniformes, una transacciÃ³n del cliente tiene fallos de invalidaciÃ³n faltantes.",
        "Considera la secuencia de r fallos de cliente en la pÃ¡gina P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la pÃ¡gina P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos.",
        "A diferencia de los fallos en frÃ­o, r â‰¤ k porque la segunda invalidaciÃ³n deshabilita la redirecciÃ³n para P hasta que el prÃ³ximo fallo en P provoque una recuperaciÃ³n del servidor.",
        "Suponiendo un acceso uniforme, un fallo de invalidaciÃ³n del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperaciÃ³n del servidor), y una probabilidad de (1 âˆ’ 1/r) de ser redirigido.",
        "Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacciÃ³n Ãºnica en los sistemas Base, BCR y BCW.",
        "En los experimentos descritos a continuaciÃ³n, medimos los parÃ¡metros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S).",
        "Calculamos los tiempos de finalizaciÃ³n derivados utilizando el modelo anterior y derivamos los beneficios.",
        "Luego validamos el modelo comparando los valores derivados con los tiempos de finalizaciÃ³n y beneficios medidos directamente en los experimentos. 6.2 ConfiguraciÃ³n Experimental Antes de presentar nuestros resultados, describimos nuestra configuraciÃ³n experimental.",
        "Utilizamos dos sistemas en nuestros experimentos.",
        "El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectÃ¡ndose directamente a los servidores.",
        "El sistema Buddy ejecuta nuestra implementaciÃ³n del prototipo de BuddyCache en Thor, admitiendo la recuperaciÃ³n de pares, la actualizaciÃ³n de pares y la confirmaciÃ³n en solitario, pero no el failover.",
        "Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark estÃ¡ diseÃ±ado para capturar las caracterÃ­sticas de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicaciÃ³n especÃ­fica.",
        "Utilizamos OO7 porque es un punto de referencia estÃ¡ndar para medir el rendimiento del sistema de almacenamiento de objetos.",
        "La base de datos OO7 contiene un Ã¡rbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares.",
        "Cada parte compuesta contiene un grÃ¡fico de partes atÃ³micas vinculadas por objetos de conexiÃ³n; cada parte atÃ³mica tiene 3 conexiones salientes.",
        "Utilizamos una base de datos mediana que tiene 200 partes atÃ³micas por parte compuesta.",
        "La base de datos multiusuario asigna a cada cliente un mÃ³dulo privado que consiste en un Ã¡rbol de objetos de ensamblaje, y agrega un mÃ³dulo compartido adicional que escala proporcionalmente al nÃºmero de clientes.",
        "Esperamos que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ© y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la cachÃ©.",
        "Dado que el objetivo de nuestro estudio es evaluar quÃ© tan efectivamente nuestras tÃ©cnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos.",
        "Esto nos permite estudiar el efecto que nuestras tÃ©cnicas tienen en los fallos de cachÃ© frÃ­o y de consistencia de cachÃ©, y aislar tanto como sea posible el efecto de los fallos de capacidad de cachÃ©.",
        "Para mantener la duraciÃ³n de nuestros experimentos razonable, utilizamos cachÃ©s pequeÃ±os.",
        "El benchmark OO7 genera mÃ³dulos de base de datos de tamaÃ±o predefinido.",
        "En nuestra implementaciÃ³n de OO7, el tamaÃ±o del mÃ³dulo privado es de aproximadamente 38MB.",
        "Para asegurarnos de que todo el conjunto de trabajo quepa en la cachÃ©, utilizamos un Ãºnico mÃ³dulo privado y elegimos un tamaÃ±o de cachÃ© de 40MB para cada cliente.",
        "La base de datos OO7 se genera con mÃ³dulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente.",
        "Los objetos en la base de datos estÃ¡n agrupados en pÃ¡ginas de 8K, que tambiÃ©n son la unidad de transferencia en las solicitudes de recuperaciÃ³n.",
        "Consideramos dos tipos de cargas de trabajo de transacciones en nuestro anÃ¡lisis, solo lectura y lectura-escritura.",
        "En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas.",
        "Las transacciones de escritura utilizan el recorrido T2b que es idÃ©ntico a T1 excepto que modifica todas las partes atÃ³micas en un solo compuesto.",
        "Una transacciÃ³n Ãºnica incluye un recorrido y no hay tiempo de espera entre transacciones.",
        "Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo mÃ³dulo.",
        "Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacciÃ³n, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura.",
        "La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de bÃºsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg.",
        "En el sistema Base, los clientes se conectan directamente a la base de datos.",
        "En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos.",
        "Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy.",
        "El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2.",
        "Estaban conectados por un Ethernet de 100Mb/s.",
        "El servidor fue configurado con una cachÃ© de 50MB (de los cuales 6MB se utilizaron para el bÃºfer de objetos modificados), el cliente tenÃ­a una cachÃ© de 40MB.",
        "Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos bÃ¡sicos Esta secciÃ³n analiza el costo bÃ¡sico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 RedirecciÃ³n Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base.",
        "Para una solicitud redirigida al servidor (obtenciÃ³n del servidor), el costo adicional de la redirecciÃ³n incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor.",
        "Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperaciÃ³n o confirmaciÃ³n del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base.",
        "La Tabla 1 muestra la latencia para las solicitudes de confirmaciÃ³n y recuperaciÃ³n del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de Ã¡rea rÃ¡pida.",
        "Todos los nÃºmeros fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones.",
        "Las mediciones muestran que el costo de redirecciÃ³n al cruzar el redireccionador no es muy alto, incluso en una red de Ã¡rea local.",
        "El costo de la confirmaciÃ³n aumenta con el nÃºmero de clientes ya que las confirmaciones se procesan de forma secuencial.",
        "El costo de recuperaciÃ³n no aumenta tanto porque la cachÃ© del servidor reduce este costo.",
        "En un sistema grande con muchos grupos, sin embargo, la cachÃ© del servidor se vuelve menos eficiente.",
        "Para evaluar los costos adicionales de la recuperaciÃ³n entre pares, medimos la latencia de la recuperaciÃ³n entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes.",
        "En la recuperaciÃ³n entre pares, el costo de la redirecciÃ³n incluye, ademÃ¡s del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este Ãºltimo incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la pÃ¡gina solicitada.",
        "Medimos directamente el tiempo para copiar y desenrollar la pÃ¡gina solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula.",
        "La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperaciÃ³n de pares.",
        "CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador mÃ¡s un viaje de ida y vuelta a travÃ©s de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador.",
        "AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud mÃ¡s un viaje de ida y vuelta a travÃ©s de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante.",
        "La latencia de la red local es fija y menor a 0.1 ms.",
        "La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch.",
        "Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando estÃ¡ bloqueado esperando una respuesta de bÃºsqueda o confirmaciÃ³n.",
        "Este sobrecosto no es inherente a la arquitectura de BuddyCache y podrÃ­a ser mitigado por una implementaciÃ³n multi-hilo en un sistema con programaciÃ³n preemptiva. 6.3.2 VersiÃ³n de CachÃ© El commit en solitario permite que un cliente rÃ¡pido que modifica un objeto haga un commit de forma independiente a un compaÃ±ero lento.",
        "El mecanismo de confirmaciÃ³n Ãºnica introduce un procesamiento adicional en el servidor durante la validaciÃ³n de la transacciÃ³n, y un procesamiento adicional en el cliente durante la confirmaciÃ³n de la transacciÃ³n y en el momento del procesamiento de actualizaciÃ³n o invalidaciÃ³n.",
        "Los gastos generales del lado del servidor son mÃ­nimos y consisten en una actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina en el momento de la confirmaciÃ³n, y una comparaciÃ³n del nÃºmero de versiÃ³n en el momento de la validaciÃ³n de la transacciÃ³n.",
        "La cachÃ© de versiÃ³n tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden.",
        "Esto puede ocurrir cuando una transacciÃ³n accede a objetos en mÃºltiples servidores.",
        "Nuestros experimentos se ejecutan en un sistema de servidor Ãºnico y, por lo tanto, el tiempo de confirmaciÃ³n adicional de la gestiÃ³n de la cachÃ© de versiones en el cliente no contribuye a los resultados presentados en la secciÃ³n a continuaciÃ³n.",
        "Para medir estos costos adicionales del lado del cliente en un sistema de mÃºltiples servidores, instrumentamos la implementaciÃ³n de la cachÃ© de versiones para ejecutarse con una traza de carga de trabajo que incluÃ­a invalidaciones reordenadas y cronometramos las operaciones bÃ¡sicas.",
        "El procesamiento adicional del tiempo de compromiso del cliente incluye una operaciÃ³n de bÃºsqueda de cachÃ© de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n en el momento de preparaciÃ³n de la solicitud de compromiso, y una operaciÃ³n de inserciÃ³n de cachÃ© de versiÃ³n para cada objeto actualizado por una transacciÃ³n en el momento de procesamiento de la respuesta de compromiso, pero solo si la pÃ¡gina actualizada carece de algunas invalidaciones o actualizaciones anteriores.",
        "Es importante que los costos adicionales de tiempo de confirmaciÃ³n se mantengan al mÃ­nimo, ya que el cliente estÃ¡ esperando de forma sÃ­ncrona la finalizaciÃ³n de la confirmaciÃ³n.",
        "Las mediciones muestran que en el peor de los casos, cuando llega un gran nÃºmero de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en pÃ¡ginas reordenadas, el costo de actualizar la cachÃ© de versiÃ³n es de 0.6 ms.",
        "El costo de tiempo de invalidaciÃ³n es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general.",
        "Actualmente estamos trabajando en optimizar la implementaciÃ³n de la cachÃ© de versiones para reducir aÃºn mÃ¡s estos costos. 6.4 Rendimiento general Esta secciÃ³n examina las mejoras de rendimiento observadas por una aplicaciÃ³n que ejecuta el benchmark OO7 con un BuddyCache en una red de Ã¡rea amplia. 6.4.1 Fallos en frÃ­o Para evaluar las mejoras de rendimiento al evitar fallos en frÃ­o, comparamos el rendimiento de la cachÃ© en frÃ­o del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base.",
        "Derivamos los tiempos cronometrando la ejecuciÃ³n de los sistemas en el entorno de la red de Ã¡rea local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de Ã¡rea amplia.",
        "Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en cachÃ© frÃ­a.",
        "Los nÃºmeros fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frÃ­o solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frÃ­o solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo.",
        "Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparaciÃ³n con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes.",
        "El tiempo total incluye el tiempo dedicado a realizar cÃ¡lculos para el cliente, solicitudes de recuperaciÃ³n directa, recuperaciones de pares y solicitudes de confirmaciÃ³n.",
        "En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperaciÃ³n entre pares evitando recuperaciones directas.",
        "En el grupo de clientes de cinco y diez, el costo de recuperaciÃ³n del servidor para cada cliente individual disminuye porque, con mÃ¡s clientes accediendo a un mÃ³dulo compartido de tamaÃ±o fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor.",
        "La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms.",
        "El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms.",
        "El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperaciÃ³n de pares en comparaciÃ³n con la recuperaciÃ³n directa, pero este beneficio se ve contrarrestado por los tiempos de confirmaciÃ³n aumentados.",
        "La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relaciÃ³n con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de cachÃ© 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT funciÃ³n de latencia de red, con una carga fija de servidor.",
        "El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja.",
        "En latencias tÃ­picas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes).",
        "La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Sorprendentemente, los resultados analÃ­ticos predicen la mejora medida muy de cerca, aunque son ligeramente mÃ¡s altos que los valores empÃ­ricos.",
        "La razÃ³n principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidaciÃ³n evitados, comparamos el rendimiento de cachÃ© caliente del sistema Base con dos configuraciones diferentes del sistema Buddy.",
        "Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interÃ©s de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache.",
        "En cada uno de los tres sistemas, un Ãºnico cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores).",
        "El sistema de compaÃ±eros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores.",
        "El sistema de compaÃ±eros con un grupo que contiene un Ãºnico escritor y otro grupo con tres lectores modela al grupo de Lectores.",
        "En Base, un escritor y tres lectores acceden directamente al servidor.",
        "Esta configuraciÃ³n simple es suficiente para mostrar el impacto de las tÃ©cnicas de BuddyCache.",
        "Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de cachÃ© caliente de OO7.",
        "Obtenemos los nÃºmeros ejecutando 2000 transacciones para filtrar los fallos en frÃ­o y luego medimos el tiempo de las siguientes 1000 transacciones.",
        "AquÃ­ nuevamente, los nÃºmeros reportados se derivan de los resultados del experimento de la red de Ã¡rea local.",
        "Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalizaciÃ³n en comparaciÃ³n con el sistema Base.",
        "En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparaciÃ³n con la Base.",
        "Este beneficio se debe a la actualizaciÃ³n entre pares que evita todas las omisiones debido a actualizaciones.",
        "El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperaciÃ³n entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperaciÃ³n local evitando el retraso de la recuperaciÃ³n desde el servidor.",
        "El Ãºltimo es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperaciÃ³n de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones.",
        "Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperaciÃ³n de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualizaciÃ³n de pares en el grupo de Escritores.",
        "Esta diferencia es similar en una red de 80ms.",
        "La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relaciÃ³n con Base, y Buddy Writer y Base en relaciÃ³n con Base) en un experimento de cachÃ© activa en funciÃ³n del aumento de la latencia de red, para una carga de servidor fija.",
        "El beneficio de actualizaciÃ³n entre pares domina el gasto general en la configuraciÃ³n de Writer incluso en redes de baja latencia (la actualizaciÃ³n entre pares incurre en un gasto mÃ­nimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia.",
        "La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico.",
        "Como en experimentos de cachÃ© frÃ­a, aquÃ­ los resultados analÃ­ticos predicen de cerca la mejora medida.",
        "La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pÃ©rdida de invalidaciÃ³n es mÃ­nimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de cachÃ© frÃ­a).",
        "Como en el caso de cachÃ© frÃ­a, la razÃ³n por la que el modelo analÃ­tico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7.",
        "CONCLUSIÃ“N Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn.",
        "Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino.",
        "Estas propiedades son difÃ­ciles de proporcionar en una red de Ã¡rea extensa debido a la alta latencia de red.",
        "Este artÃ­culo describe BuddyCache, una nueva tÃ©cnica de almacenamiento en cachÃ© cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia.",
        "La tÃ©cnica mejora el rendimiento y proporciona propiedades sÃ³lidas de correcciÃ³n y disponibilidad en presencia de fallos de nodos y clientes lentos.",
        "BuddyCache utiliza la redirecciÃ³n para obtener objetos faltantes directamente de las cachÃ©s de los miembros del grupo, y para admitir la actualizaciÃ³n entre pares, una nueva tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo.",
        "Sin embargo, la redirecciÃ³n puede interferir con la disponibilidad del objeto.",
        "Solo commit es una nueva tÃ©cnica de validaciÃ³n que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos.",
        "Proporciona una validaciÃ³n detallada utilizando informaciÃ³n de versiÃ³n de grano grueso econÃ³mica.",
        "Hemos diseÃ±ado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red.",
        "Los resultados analÃ­ticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio.",
        "Las principales contribuciones del artÃ­culo son: 1. extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementaciÃ³n del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluaciÃ³n del rendimiento basada en anÃ¡lisis y mediciones de los costos y beneficios de las nuevas tÃ©cnicas que capturan el costo de rendimiento dominante, la alta latencia de red.",
        "AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas.",
        "TambiÃ©n agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios Ãºtiles que mejoraron este artÃ­culo. 9.",
        "REFERENCIAS [1] emulab.net, la InstalaciÃ³n de EmulaciÃ³n de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira.",
        "ReconstrucciÃ³n de fragmentos: Proporcionando coherencia de cachÃ© global en un sistema de almacenamiento transaccional.",
        "Actas de la Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari.",
        "Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados.",
        "En Actas de la Conferencia Internacional de ACM SIGMOD sobre GestiÃ³n de Datos, mayo de 1995. [4] C. Amza, A.L.",
        "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel.",
        "Huellas de pisadas: ComputaciÃ³n en memoria compartida en redes de estaciones de trabajo.",
        "IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin.",
        "Dos protocolos de coherencia de cachÃ© hÃ­bridos adaptativos.",
        "En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker.",
        "RecuperaciÃ³n rÃ¡pida de fallos en sistemas de archivos distribuidos.",
        "Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu.",
        "Manteniendo una fuerte consistencia de cachÃ© en la World Wide Web.",
        "En la 17Âª Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton.",
        "Un informe de estado sobre el esfuerzo de evaluaciÃ³n del rendimiento del sistema de gestiÃ³n de bases de datos orientado a objetos OO7.",
        "En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels.",
        "Una cachÃ© de objetos jerÃ¡rquica en Internet.",
        "En la Conferencia TÃ©cnica Anual de USENIX, en enero de 1995. [10] J.",
        "Chase, S. Gadde y M. Rabinovich.",
        "Estructuras de directorios para cachÃ©s de Internet escalables.",
        "Informe TÃ©cnico CS-1997-18, Departamento de Ciencias de la ComputaciÃ³n, Universidad de Duke, noviembre de 1997. [11] J.",
        "Chase, S. Gadde y M. Rabinovich.",
        "No todos los aciertos son iguales: CachÃ© de proxy cooperativa en una red de Ã¡rea amplia.",
        "En el Tercer Taller Internacional de CachÃ© de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li.",
        "CachÃ© web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2Âº Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson.",
        "CachÃ© cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos.",
        "Actas de la Conferencia USENIX sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L.",
        "Cox, R. Rajamony y W. Zwaenepoel.",
        "Combinando el soporte en tiempo de compilaciÃ³n y en tiempo de ejecuciÃ³n para una memoria compartida distribuida eficiente.",
        "En Actas de IEEE, EdiciÃ³n Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder.",
        "Resumen de la cachÃ©: un protocolo de intercambio de cachÃ© web escalable de Ã¡rea amplia.",
        "En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy.",
        "ImplementaciÃ³n de GestiÃ³n Global de Memoria en un ClÃºster de Estaciones de Trabajo.",
        "Actas del 15Âº Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy.",
        "Integrando coherencia y recuperabilidad en sistemas distribuidos.",
        "En Actas del Primer Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al.",
        "PerDiS: DiseÃ±o, ImplementaciÃ³n y Uso de una Tienda Distribuida Persistente.",
        "En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny.",
        "Coherencia de cachÃ© transaccional cliente-servidor: alternativas y rendimiento.",
        "En ACM Transactions on Database Systems, volumen 22, pÃ¡ginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny.",
        "GestiÃ³n global de memoria para arquitecturas de sistemas de gestiÃ³n de bases de datos cliente-servidor.",
        "En Actas del 19Âº Congreso Internacional.",
        "Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat.",
        "El BÃºfer de Objeto Modificado: Una TÃ©cnica de GestiÃ³n de Almacenamiento para Bases de Datos Orientadas a Objetos.",
        "Tesis doctoral, Instituto TecnolÃ³gico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif.",
        "GestiÃ³n de documentos replicados en un sistema de comunicaciÃ³n grupal.",
        "En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya.",
        "Proporcionando objetos persistentes en sistemas distribuidos.",
        "En Actas de la 13Âª Conferencia Europea sobre ProgramaciÃ³n Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres.",
        "Un sistema de archivos de red de baja capacidad de banda.",
        "En el 18Âº Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov.",
        "ReplicaciÃ³n con marca de vista: un nuevo mÃ©todo de copia primaria para soportar sistemas distribuidos altamente disponibles.",
        "En Proc. del Simposio de la ACM sobre Principios de ComputaciÃ³n Distribuida, agosto de 1988. [26] J. OToole y L. Shrira.",
        "Registro oportunista: Lecturas de instalaciÃ³n eficientes en un servidor de objetos confiable.",
        "En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma.",
        "ALMI: Una Infraestructura de MultidifusiÃ³n a Nivel de AplicaciÃ³n.",
        "En el 3er Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman.",
        "Uso eficiente de cachÃ© cooperativa utilizando pistas.",
        "En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson.",
        "WebFS: Un Sistema de Archivos Coherente en CachÃ© Global.",
        "Informe tÃ©cnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy.",
        "Sobre la Escala y el Rendimiento del CachÃ© de Proxies Web Cooperativos.",
        "En el 17Âº Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin.",
        "Consistencia jerÃ¡rquica de cachÃ© en una WAN.",
        "En el Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin.",
        "Arrendamientos de volumen para consistencia en sistemas a gran escala.",
        "IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin.",
        "ComparticiÃ³n adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks.",
        "ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10.",
        "APÃ‰NDICE Este apÃ©ndice describe el protocolo de conmutaciÃ³n por error de BuddyCache.",
        "Para dar cabida a clientes heterogÃ©neos, incluidos los dispositivos portÃ¡tiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache.",
        "El diseÃ±o de BuddyCache asume que las cachÃ©s del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos.",
        "Un protocolo de membresÃ­a detecta el fallo de un cliente o un redireccionador intercambiando mensajes periÃ³dicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutaciÃ³n por error.",
        "El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuraciÃ³n y reinicia el protocolo.",
        "El protocolo de reconfiguraciÃ³n del grupo es similar al presentado en [25].",
        "AquÃ­ describimos cÃ³mo el failover gestiona el estado de BuddyCache.",
        "Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de pÃ¡ginas redireccionadas y el reenvÃ­o de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachÃ©s.",
        "En caso de un fallo del cliente, el failover elimina las pÃ¡ginas del cliente que se han bloqueado del directorio.",
        "Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmaciÃ³n, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en cachÃ© las pÃ¡ginas modificadas.",
        "En caso de un fallo del redireccionador, el protocolo de conmutaciÃ³n por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de pÃ¡ginas utilizando un protocolo similar al descrito en [6].",
        "El redireccionador reciÃ©n reiniciado solicita a los miembros activos del grupo la lista de pÃ¡ginas que estÃ¡n almacenando en cachÃ© y el estado de estas pÃ¡ginas, es decir, si las pÃ¡ginas estÃ¡n completas o incompletas.",
        "Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse.",
        "Una solicitud de recuperaciÃ³n perdida expirarÃ¡ en el cliente y serÃ¡ retransmitida.",
        "Una transacciÃ³n que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma despuÃ©s del cambio se trata como una transacciÃ³n regular; una transacciÃ³n que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo.",
        "Un cliente reiniciarÃ¡ la transacciÃ³n y la solicitud de confirmaciÃ³n serÃ¡ retransmitida despuÃ©s del cambio de servidor.",
        "Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caÃ­do podrÃ­an evitar la recolecciÃ³n de basura de las invalidaciones pendientes en los servidores o la cachÃ© virtual en los clientes.",
        "Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas.",
        "Los nÃºmeros de versiÃ³n Ãºnicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas.",
        "Dado que el procedimiento de validaciÃ³n de transacciones depende del protocolo de coherencia de cachÃ© para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutaciÃ³n por error de BuddyCache no compromete la correcciÃ³n del procedimiento de validaciÃ³n.",
        "Recuerda que la validaciÃ³n de transacciones de BuddyCache utiliza dos mecanismos complementarios, nÃºmeros de versiÃ³n de pÃ¡gina y confirmaciones de invalidaciÃ³n de los clientes, para verificar que una transacciÃ³n ha leÃ­do datos actualizados.",
        "La propagaciÃ³n de la confirmaciÃ³n de invalidaciÃ³n (y actualizaciÃ³n) basada en el redireccionador garantiza la siguiente invariante.",
        "Cuando un servidor recibe una confirmaciÃ³n de una modificaciÃ³n (invalidaciÃ³n o actualizaciÃ³n) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en cachÃ© el objeto o bien ha instalado el valor mÃ¡s reciente del objeto o lo ha invalidado.",
        "Por lo tanto, si un servidor recibe una solicitud de confirmaciÃ³n de un cliente para una transacciÃ³n T que lee un objeto o despuÃ©s de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidaciÃ³n no confirmada para o pendiente para este grupo, la versiÃ³n del objeto leÃ­da por la transacciÃ³n T estÃ¡ actualizada independientemente de fallos en el cliente o en el redireccionador.",
        "Ahora considera la validaciÃ³n utilizando nÃºmeros de versiÃ³n.",
        "El registro de confirmaciÃ³n de transacciÃ³n contiene un nÃºmero de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n.",
        "El protocolo de nÃºmero de versiÃ³n mantiene la invariante V P que garantiza que el valor del objeto o leÃ­do por la transacciÃ³n corresponda al nÃºmero de versiÃ³n mÃ¡s alto para o recibido por el cliente.",
        "La invariante se mantiene ya que el cliente nunca aplica una modificaciÃ³n anterior despuÃ©s de haber recibido una modificaciÃ³n posterior.",
        "La retransmisiÃ³n de invalidaciones y actualizaciones mantiene esta invariante.",
        "El procedimiento de validaciÃ³n verifica que el nÃºmero de versiÃ³n en el registro de confirmaciÃ³n coincida con el nÃºmero de versiÃ³n en la invalidaciÃ³n pendiente no reconocida.",
        "Es fÃ¡cil ver que, dado que esta comprobaciÃ³n es una comprobaciÃ³n cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador.",
        "El protocolo de conmutaciÃ³n por error aÃºn no ha sido implementado."
    ],
    "error_count": 2,
    "keys": {
        "object storage system": {
            "translated_key": "sistema de almacenamiento de objetos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed <br>object storage system</br> [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring <br>object storage system</br> performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional <br>object storage system</br> [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "The Base system runs Thor distributed <br>object storage system</br> [23] with clients connecting directly to the servers.",
                "We use OO7 because it is a standard benchmark for measuring <br>object storage system</br> performance.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional <br>object storage system</br> [23] and evaluated the benefits and costs of the system over a range of network latencies."
            ],
            "translated_annotated_samples": [
                "El sistema Base ejecuta el <br>sistema de almacenamiento de objetos</br> distribuidos Thor [23] con clientes conectÃ¡ndose directamente a los servidores.",
                "Utilizamos OO7 porque es un punto de referencia estÃ¡ndar para medir el rendimiento del <br>sistema de almacenamiento de objetos</br>.",
                "Hemos diseÃ±ado e implementado el prototipo de BuddyCache en el <br>sistema de almacenamiento de objetos</br> transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de Ã¡rea amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de Ã¡rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil. Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en cachÃ© web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos. Sin embargo, las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica. La interacciÃ³n con el servidor aumenta la latencia. La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia. Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n. Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo. BuddyCache presenta dos desafÃ­os tÃ©cnicos principales. Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©. El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de almacenamiento en cachÃ© web cooperativos [11]. Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo. BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos. Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica. Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad? DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red. Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia. El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida. Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache. Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n. Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos. Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de Ã¡rea amplia. Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad. Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un Ãºnico servidor. Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web. El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en cachÃ© transaccional [19]. La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una transacciÃ³n, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador. El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado. AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©. Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina). La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente. El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento. A continuaciÃ³n, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene. La transacciÃ³n puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor. Sin embargo, antes de que una transacciÃ³n se confirme, debe ser validada; el servidor debe asegurarse de que la transacciÃ³n validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada. Si la validaciÃ³n falla, la transacciÃ³n se cancela. Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de bÃºsqueda de pares envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la cachÃ© y envÃ­an confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la cachÃ© del cliente, la confirmaciÃ³n de invalidaciÃ³n indica al servidor que un cliente sin invalidaciones pendientes ha leÃ­do objetos actualizados. Una invalidaciÃ³n no reconocida indica que un objeto obsoleto puede haber sido accedido en la cachÃ© del cliente. El procedimiento de validaciÃ³n en el servidor aborta una transacciÃ³n del cliente si este lee un objeto mientras hay una invalidaciÃ³n pendiente. El mecanismo de invalidaciÃ³n reconocido admite coherencia de cachÃ© a nivel de objeto sin directorios basados en objetos o nÃºmeros de versiÃ³n por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeÃ±os, ya que los objetos tÃ­picos son pequeÃ±os. Un objetivo importante del diseÃ±o de BuddyCache es mantener este beneficio. Dado que en BuddyCache una pÃ¡gina puede ser recuperada en una cachÃ© de cliente sin intervenciÃ³n del servidor (como se ilustra en la figura 2), los directorios de cachÃ© en los servidores llevan un registro de las pÃ¡ginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las pÃ¡ginas almacenadas en cachÃ© en cada cliente de un grupo. Los servidores envÃ­an al redireccionador invalidaciones para las pÃ¡ginas almacenadas en cachÃ© en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. ActualizaciÃ³n de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en cachÃ© por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interÃ©s potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de cachÃ© y las actualizaciones de cachÃ©. Los estudios de coherencia de cachÃ© en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualizaciÃ³n y la invalidaciÃ³n. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. AlmacÃ©n x 6. ActualizaciÃ³n x 3. CompromÃ©tete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares estÃ¡n fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeÃ±as, agrupadas y se envÃ­an junto con otros mensajes. AdemÃ¡s, los protocolos de invalidaciÃ³n se ajustan a la tendencia actual de hardware de aumentar los tamaÃ±os de cachÃ© del cliente. Es probable que las cachÃ©s mÃ¡s grandes contengan mucha mÃ¡s informaciÃ³n de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una red de Ã¡rea amplia serÃ­an derrochadores. Sin embargo, los protocolos de coherencia basados en invalidaciÃ³n pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interÃ©s para otro miembro del grupo. Con un protocolo basado en invalidaciÃ³n, la actualizaciÃ³n de un miembro invalidarÃ¡ la copia en cachÃ© de otro miembro, lo que provocarÃ¡ que este Ãºltimo realice una recuperaciÃ³n de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualizaciÃ³n e invalidaciÃ³n en entornos de redes de Ã¡rea amplia. Evita la penalizaciÃ³n de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalizaciÃ³n de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusiÃ³n localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en cachÃ© anteriores. La actualizaciÃ³n entre pares funciona de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que la transacciÃ³n se confirma, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n, y tambiÃ©n propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmaciÃ³n. 3.3 ConfirmaciÃ³n individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminaciÃ³n de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en cachÃ© transaccional, ya que un cliente que es lento para reconocer una invalidaciÃ³n o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacciÃ³n. Por ejemplo, un ingeniero que realiza una revisiÃ³n repetida al mismo objeto de diseÃ±o compartido (y por lo tanto tiene la Ãºltima versiÃ³n del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situaciÃ³n representada en la figura 4 donde el Cliente1 realiza una transacciÃ³n T que lee la Ãºltima versiÃ³n de un objeto x en la pÃ¡gina P recientemente modificada por el Cliente1. Si la solicitud de confirmaciÃ³n para T llega al servidor antes de que la confirmaciÃ³n colectiva de Cliente2 por la Ãºltima modificaciÃ³n de x llegue al servidor, el procedimiento de validaciÃ³n de OCC considera que x estÃ¡ obsoleto y aborta T (porque, como se explicÃ³ anteriormente, una invalidaciÃ³n no reconocida por un cliente actÃºa como indicaciÃ³n para el servidor de que el valor del objeto en cachÃ© estÃ¡ obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la correcciÃ³n del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asÃ­ncronas son una parte importante de la razÃ³n por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasiÃ³n de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envÃ­an y procesan de forma asÃ­ncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devoluciÃ³n de llamada jerÃ¡rquica [32], pero la naturaleza asincrÃ³nica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrÃ³nicas. El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a un cliente con objetos actualizados confirmar una transacciÃ³n incluso si la confirmaciÃ³n del grupo se retrasa debido a pares lentos o caÃ­dos. El protocolo requiere que los clientes incluyan informaciÃ³n adicional con los conjuntos de lectura de transacciones en el mensaje de confirmaciÃ³n, para indicar al servidor que los objetos leÃ­dos por la transacciÃ³n estÃ¡n actualizados. Los nÃºmeros de versiÃ³n de los objetos podrÃ­an proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionÃ³ anteriormente, mantener nÃºmeros de versiÃ³n por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaÃ±o de directorio) en todo el sistema de objetos cuando los objetos son pequeÃ±os [23]. En cambio, solo utiliza nÃºmeros de versiÃ³n de pÃ¡gina de grano grueso para identificar versiones de objetos de grano fino. El nÃºmero de versiÃ³n de una pÃ¡gina se incrementa en un servidor cuando una transacciÃ³n que modifica objetos en la pÃ¡gina se confirma. Las actualizaciones realizadas por una Ãºnica transacciÃ³n y las invalidaciones correspondientes son identificadas de manera Ãºnica por el nÃºmero de versiÃ³n de la pÃ¡gina modificada. Los nÃºmeros de versiÃ³n de la pÃ¡gina se propagan a los clientes en respuestas de recuperaciÃ³n, respuestas de confirmaciÃ³n y con invalidaciones, y los clientes incluyen los nÃºmeros de versiÃ³n de la pÃ¡gina en las solicitudes de confirmaciÃ³n enviadas a los servidores. Si una transacciÃ³n falla en la validaciÃ³n debido a la falta de reconocimiento de grupo, el servidor verifica los nÃºmeros de versiÃ³n de pÃ¡gina de los objetos en el conjunto de lectura de la transacciÃ³n y permite que la transacciÃ³n se confirme si el cliente ha leÃ­do desde la Ãºltima versiÃ³n de la pÃ¡gina. Los nÃºmeros de versiÃ³n de la pÃ¡gina permiten confirmaciones independientes, pero las verificaciones de versiÃ³n de pÃ¡gina solo detectan conflictos a nivel de pÃ¡gina. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La secciÃ³n 4 describe los detalles de la implementaciÃ³n del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 ConfiguraciÃ³n de Grupo La arquitectura BuddyCache admite mÃºltiples grupos de pares concurrentes. Potencialmente, puede ser mÃ¡s rÃ¡pido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podrÃ­a ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en cachÃ© de pares de mÃºltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en cachÃ© web, simplemente aumentar la poblaciÃ³n de clientes en una cachÃ© proxy a menudo aumenta la tasa general de aciertos en la cachÃ© [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacciÃ³n explÃ­cita entre clientes y la colaboraciÃ³n, lo que sugiere que es poco probable que ocurra la recuperaciÃ³n entre grupos. AdemÃ¡s, las mediciones de sistemas de almacenamiento en cachÃ© web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexiÃ³n de red entre los grupos de pares sea muy rÃ¡pida. Estamos principalmente interesados en entornos donde compaÃ±eros que colaboran estrechamente tienen una conectividad rÃ¡pida a corta distancia, pero la conexiÃ³n entre grupos de compaÃ±eros puede ser lenta. Como resultado, decidimos que el soporte para la recuperaciÃ³n entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compaÃ±eros con recursos heterogÃ©neos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compaÃ±eros o, cuando estÃ© disponible, en un nodo separado dentro de la infraestructura del sitio. AdemÃ¡s, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una cachÃ© de pares en espera para recibir pÃ¡ginas recuperadas por otros pares, emulando una cachÃ© central algo similar a una cachÃ© de proxy web regional. Desde el punto de vista del protocolo de coherencia de cachÃ© BuddyCache, sin embargo, un cachÃ© de compaÃ±ero en espera es equivalente a un cachÃ© de compaÃ±ero regular y, por lo tanto, no consideramos este caso por separado en la discusiÃ³n de este documento. 4. En esta secciÃ³n proporcionamos los detalles de la implementaciÃ³n de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en cachÃ© de estos objetos. Las aplicaciones se ejecutan en los clientes e interactÃºan con el sistema realizando llamadas a mÃ©todos de objetos en cachÃ©. Todas las llamadas a mÃ©todos ocurren dentro de transacciones atÃ³micas. Los clientes se comunican con los servidores para obtener pÃ¡ginas o realizar una transacciÃ³n. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volÃ¡til. El disco estÃ¡ organizado como una colecciÃ³n de pÃ¡ginas que son las unidades de acceso al disco. El registro estable guarda la informaciÃ³n de confirmaciÃ³n y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de cachÃ© y una cachÃ© de objetos modificados recuperable llamada MOB. El directorio lleva un registro de quÃ© pÃ¡ginas estÃ¡n almacenadas en cachÃ© por quÃ© clientes. El MOB contiene objetos recientemente modificados que aÃºn no han sido escritos de vuelta en sus pÃ¡ginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de cachÃ© base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la SecciÃ³n 3.1. Proporcionamos algunos de los detalles relevantes de la implementaciÃ³n del protocolo OCC. El cliente lleva un registro de los objetos que son leÃ­dos y modificados por su transacciÃ³n; envÃ­a esta informaciÃ³n, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacciÃ³n. Los servidores determinan si la confirmaciÃ³n es posible, utilizando un protocolo de confirmaciÃ³n de dos fases si la transacciÃ³n utilizÃ³ objetos en mÃºltiples servidores. Si la transacciÃ³n se lleva a cabo, las nuevas copias de los objetos modificados se aÃ±aden al registro y tambiÃ©n se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperaciÃ³n escaneando el registro. Dado que los objetos no estÃ¡n bloqueados antes de ser utilizados, una confirmaciÃ³n de transacciÃ³n puede hacer que las cachÃ©s contengan objetos obsoletos. Los servidores abortarÃ¡n una transacciÃ³n que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviÃ¡ndoles mensajes de invalidaciÃ³n; un servidor utiliza su directorio y la informaciÃ³n sobre la transacciÃ³n de confirmaciÃ³n para determinar quÃ© mensajes de invalidaciÃ³n enviar. Los mensajes de invalidaciÃ³n son pequeÃ±os porque simplemente identifican objetos obsoletos. AdemÃ¡s, se envÃ­an en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidaciÃ³n, elimina los objetos obsoletos de su cachÃ© y aborta la transacciÃ³n actual si los utilizÃ³. El cliente sigue conservando pÃ¡ginas que contienen objetos invalidados; estas pÃ¡ginas ahora estÃ¡n incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidaciÃ³n de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener pÃ¡ginas incompletas en la cachÃ© del cliente significa que el falso intercambio no conduce a fallos innecesarios en la cachÃ©. Los clientes reconocen las invalidaciones para indicar la eliminaciÃ³n de datos obsoletos, como se explica en la SecciÃ³n 3.1. Los mensajes de invalidaciÃ³n evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo asÃ­ el desperdicio de trabajo y trasladando la detecciÃ³n de abortos de los servidores a los clientes. Cuando una transacciÃ³n se aborta, su cliente restaura las copias en cachÃ© de los objetos modificados al estado que tenÃ­an antes de que la transacciÃ³n comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacciÃ³n. 4.3 RedirecciÃ³n El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de pÃ¡ginas disponibles en el grupo de pares y proporciona una redirecciÃ³n rÃ¡pida y centralizada de recuperaciÃ³n (ver figura 2) entre las cachÃ©s de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan pÃ¡ginas u objetos al incluir esa informaciÃ³n en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la cachÃ© de grupo, el redireccionador realiza un seguimiento del estado de las pÃ¡ginas. Una pÃ¡gina en cachÃ© estÃ¡ completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una pÃ¡gina estÃ¡n marcados como invÃ¡lidos. Solo se utilizan pÃ¡ginas completas por el proceso de recuperaciÃ³n de pares. El protocolo para mantener el estado de la pÃ¡gina cuando las pÃ¡ginas son actualizadas e invalidadas se describe en la SecciÃ³n 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una pÃ¡gina solicitada completa no estÃ¡ disponible en el grupo de pares o si un par necesita confirmar una transacciÃ³n, el redireccionador actÃºa como un proxy de servidor: reenvÃ­a la solicitud al servidor y luego reenvÃ­a la respuesta de vuelta al cliente. AdemÃ¡s, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualizaciÃ³n o informaciÃ³n de invalidaciÃ³n a los clientes que tienen en cachÃ© la pÃ¡gina modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la cachÃ© de grupo de pares combinada estÃ¡ desempeÃ±ando el papel de una Ãºnica cachÃ© de cliente en el sistema base. 4.4 ActualizaciÃ³n de pares La actualizaciÃ³n de pares se implementa de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que una transacciÃ³n se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacciÃ³n generan invalidaciones de objetos para cada grupo de cachÃ© que almacena pÃ¡ginas que contienen los objetos modificados (incluido el grupo que realiza la confirmaciÃ³n). Las invalidaciones se envÃ­an de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en cachÃ© los objetos modificados se deshagan de los datos obsoletos. En grupos de cachÃ© distintos al grupo de confirmaciÃ³n, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas, recopilan las confirmaciones de los clientes y, despuÃ©s de completar la recopilaciÃ³n, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacciÃ³n, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envÃ­an a los clientes que almacenan en cachÃ© esas pÃ¡ginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmaciÃ³n colectiva se propaga al servidor. Una invalidaciÃ³n hace que una pÃ¡gina en cachÃ© no estÃ© disponible para la recuperaciÃ³n de pares, cambiando el estado de una pÃ¡gina completa p a incompleta. Por el contrario, una actualizaciÃ³n de una pÃ¡gina completa conserva el estado completo de la pÃ¡gina. Como se muestra en los estudios de la reconstrucciÃ³n de fragmentos 31 [2], esta propagaciÃ³n de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma pÃ¡gina, la pÃ¡gina conserva su estado completo y permanece disponible para la recuperaciÃ³n entre pares. Por lo tanto, el efecto de la actualizaciÃ³n de pares es similar a la reconstrucciÃ³n de fragmentos ansiosa [2]. TambiÃ©n hemos considerado la posibilidad de permitir que un compaÃ±ero recupere una pÃ¡gina incompleta (con objetos invÃ¡lidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos invÃ¡lidos. 4.5 Vcache El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo mÃ¡s lentos (o fallidos). Como se explica en la SecciÃ³n 3.3, el protocolo de commit Ãºnico permite que una transacciÃ³n T pase la validaciÃ³n si la informaciÃ³n adicional de coherencia proporcionada por el cliente indica que la transacciÃ³n T ha leÃ­do objetos actualizados. Los clientes utilizan los nÃºmeros de versiÃ³n de la pÃ¡gina para proporcionar esta informaciÃ³n adicional de coherencia. Es decir, un cliente incluye el nÃºmero de versiÃ³n de la pÃ¡gina correspondiente a cada objeto en el conjunto de objetos leÃ­dos enviado en la solicitud de confirmaciÃ³n al servidor. Dado que a cada actualizaciÃ³n de objeto comprometido le corresponde un nÃºmero de versiÃ³n de pÃ¡gina Ãºnico, el nÃºmero de versiÃ³n de pÃ¡gina asociado con un objeto permite que el procedimiento de validaciÃ³n en el servidor verifique si la transacciÃ³n del cliente ha leÃ­do objetos actualizados. El uso de versiones de pÃ¡gina de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeÃ±os, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en cachÃ© a la versiÃ³n de pÃ¡gina identificadora (ObjectToVersion). El principal problema de implementaciÃ³n se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian nÃºmeros de versiÃ³n de pÃ¡gina con las invalidaciones. En el momento de la validaciÃ³n, si hay una invalidaciÃ³n no reconocida pendiente para un objeto x leÃ­do por una transacciÃ³n T, el procedimiento de validaciÃ³n verifica si el nÃºmero de versiÃ³n de x en el conjunto de lectura de Ts coincide con el nÃºmero de versiÃ³n de la invalidaciÃ³n pendiente mÃ¡s alta para x, en cuyo caso el valor del objeto estÃ¡ actualizado, de lo contrario, T falla en la validaciÃ³n. Observamos nuevamente que las verificaciones basadas en el nÃºmero de versiÃ³n de la pÃ¡gina y las verificaciones basadas en el reconocimiento de invalidaciÃ³n son complementarias en la validaciÃ³n de confirmaciÃ³n individual y ambas son necesarias. La verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina permite que la validaciÃ³n avance antes de que lleguen las confirmaciones de invalidaciÃ³n, pero por sÃ­ sola, una verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina detecta conflictos a nivel de pÃ¡gina y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cÃ³mo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un nÃºmero de versiÃ³n de la pÃ¡gina para cada pÃ¡gina en cachÃ©. El nÃºmero de versiÃ³n satisface la siguiente invariante V P sobre el estado de los objetos en una pÃ¡gina: si una pÃ¡gina en cachÃ© P tiene un nÃºmero de versiÃ³n v, entonces el valor de un objeto o en la pÃ¡gina en cachÃ© P es invÃ¡lido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacciÃ³n que estableciÃ³ el nÃºmero de versiÃ³n de P en v. Los nuevos valores de objetos y los nuevos nÃºmeros de versiÃ³n de pÃ¡gina llegan cuando un cliente obtiene una pÃ¡gina o cuando llega una respuesta de confirmaciÃ³n o invalidaciones para esta pÃ¡gina. Los nuevos valores del objeto modifican la pÃ¡gina y, por lo tanto, el nÃºmero de versiÃ³n de la pÃ¡gina necesita ser actualizado para mantener la invariante V P. Un nÃºmero de versiÃ³n de pÃ¡gina que llega cuando un cliente obtiene una pÃ¡gina, reemplaza la VersiÃ³n del Objeto x 8 Servidor de RedirecciÃ³n 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el nÃºmero de versiÃ³n de la pÃ¡gina para esta pÃ¡gina. Tal actualizaciÃ³n preserva el invariante V P. De manera similar, un nÃºmero de versiÃ³n de pÃ¡gina en secuencia que llega al cliente en un mensaje de confirmaciÃ³n o invalidaciÃ³n avanza el nÃºmero de versiÃ³n para toda la pÃ¡gina en cachÃ©, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus nÃºmeros de versiÃ³n de pÃ¡gina correspondientes tambiÃ©n pueden llegar al cliente fuera de secuencia, en cuyo caso la actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina podrÃ­a violar V P. Por ejemplo, una respuesta de confirmaciÃ³n para una transacciÃ³n que actualiza el objeto x en la pÃ¡gina P en el servidor S1, y el objeto y en la pÃ¡gina Q en el servidor S2, puede entregar un nuevo nÃºmero de versiÃ³n para P desde el coordinador de transacciones S1 antes de que llegue una invalidaciÃ³n generada para una transacciÃ³n anterior que ha modificado el objeto r en la pÃ¡gina P desde S1 (como se muestra en la figura 5). El protocolo de actualizaciÃ³n de cachÃ© garantiza que el valor de cualquier objeto o en una pÃ¡gina en cachÃ© P refleje la actualizaciÃ³n o invalidaciÃ³n con el nÃºmero de versiÃ³n observado mÃ¡s alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de nÃºmeros de versiÃ³n de pÃ¡gina, el cliente gestiona una pequeÃ±a cachÃ© de nÃºmeros de versiÃ³n vcache que mantiene el mapeo de un objeto a su nÃºmero de versiÃ³n de pÃ¡gina correspondiente para todas las actualizaciones de nÃºmeros de versiÃ³n reordenadas hasta que se ensamble una secuencia completa de nÃºmeros de versiÃ³n de pÃ¡gina. Cuando llegan los nÃºmeros de versiÃ³n faltantes para la pÃ¡gina y completan una secuencia, el nÃºmero de versiÃ³n de toda la pÃ¡gina se avanza. El mapeo de ObjectToVersion, incluyendo los nÃºmeros de versiÃ³n de vcache y pÃ¡gina, se utiliza en el momento de la confirmaciÃ³n de la transacciÃ³n para proporcionar nÃºmeros de versiÃ³n para el conjunto de objetos leÃ­dos de la siguiente manera. Si el objeto leÃ­do tiene una entrada en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n mÃ¡s alto en la vcache para este objeto. Si el objeto no estÃ¡ presente en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n de la pÃ¡gina en cachÃ© que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la cachÃ© del cliente, incluyendo los nÃºmeros de versiÃ³n de las pÃ¡ginas y la vcache. El cliente puede limitar el tamaÃ±o de la cachÃ© virtual segÃºn sea necesario, ya que volver a cargar una pÃ¡gina elimina todos los nÃºmeros de versiÃ³n de pÃ¡gina reordenados de la cachÃ© virtual. Sin embargo, esperamos que la reorganizaciÃ³n de nÃºmeros de versiÃ³n sea poco comÃºn y, por lo tanto, esperamos que la vcache sea muy pequeÃ±a. 5. Un grupo de clientes contiene mÃºltiples nodos de cliente y un objeto de pÃ¡gina de versiÃ³n redi32 VCache Cliente CachÃ© Cliente PÃ¡gina CachÃ© Figura 6: Mapa de Objeto a VersiÃ³n con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutaciÃ³n por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. AdemÃ¡s, el fallo del redireccionador deberÃ­a permitir que los clientes no afectados mantengan sus cachÃ©s intactas. Hemos diseÃ±ado un protocolo de conmutaciÃ³n por error para BuddyCache pero aÃºn no lo hemos implementado. El apÃ©ndice describe el protocolo. 6. La redirecciÃ³n de BuddyCache en la evaluaciÃ³n de rendimiento respalda los beneficios de evitar la comunicaciÃ³n con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes. Â¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 AnÃ¡lisis Los beneficios de rendimiento de la recuperaciÃ³n entre pares y la actualizaciÃ³n entre pares se deben a la evitaciÃ³n de interacciones con el servidor. Esta secciÃ³n presenta un modelo de rendimiento analÃ­tico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la cachÃ© del cliente. Estos pueden ser fallos frÃ­os, fallos de invalidaciÃ³n y fallos de capacidad. Nuestro anÃ¡lisis se centra en los fallos por frÃ­o y los fallos por invalidaciÃ³n, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frÃ­o. AdemÃ¡s, las tendencias tecnolÃ³gicas indican que la capacidad de memoria y almacenamiento seguirÃ¡ creciendo y, por lo tanto, es probable que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ©. Los fallos de cachÃ© del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuraciÃ³n de cachÃ©. Nuestro anÃ¡lisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validaciÃ³n. Para estudiar el beneficio de evitar fallos en frÃ­o, consideramos el rendimiento de la cachÃ© en frÃ­o en una carga de trabajo de solo lectura (sin fallos de invalidaciÃ³n). Esperamos que la recuperaciÃ³n entre pares mejore el costo de latencia para las solicitudes de cachÃ© frÃ­a del cliente al recuperar objetos de la cachÃ© cercana. Evaluamos cÃ³mo el costo de redirecciÃ³n afecta este beneficio al comparar y analizar el rendimiento de una aplicaciÃ³n que se ejecuta en un sistema de almacenamiento con BuddyCache y sin Ã©l (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidaciÃ³n, consideramos el rendimiento de la cachÃ© caliente en una carga de trabajo con modificaciones (sin fallos en frÃ­o). En las cachÃ©s calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualizaciÃ³n entre pares permite que un cliente acceda a un objeto modificado por un compaÃ±ero colaborador cercano sin el retraso impuesto por los protocolos de invalidaciÃ³n Ãºnicamente. En grupos donde los compaÃ±eros comparten un interÃ©s de solo lectura en los objetos modificados, la recuperaciÃ³n entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compaÃ±ero colaborador lo tenga, lo que evita el retraso de la recuperaciÃ³n del servidor sin el alto costo impuesto por los protocolos de solo actualizaciÃ³n. Las tendencias tecnolÃ³gicas indican que ambos beneficios seguirÃ¡n siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualizaciÃ³n Ãºnicamente. Sin embargo, la tendencia hacia cachÃ©s cada vez mÃ¡s grandes, que se actualizan cuando los objetos en cachÃ© son modificados, hace que los protocolos basados en invalidaciÃ³n sean mÃ¡s atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicaciÃ³n que se ejecuta sin BuddyCache y una aplicaciÃ³n que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compaÃ±ero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compaÃ±ero fuera del grupo. La actualizaciÃ³n entre pares tambiÃ©n puede evitar fallos de invalidaciÃ³n debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma pÃ¡gina de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseÃ±o del objeto, y tambiÃ©n porque este beneficio se puede derivar dado el Ã­ndice de aciertos en cachÃ© y la contenciÃ³n de la carga de trabajo. 6.1.1 El Modelo El modelo considera cÃ³mo el tiempo para completar una ejecuciÃ³n con y sin BuddyCache se ve afectado por los fallos de invalidaciÃ³n y los fallos en frÃ­o. Considerando k clientes ejecutÃ¡ndose concurrentemente accediendo de manera uniforme a un conjunto compartido de N pÃ¡ginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacciÃ³n y realizar cÃ¡lculos en una transacciÃ³n, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin Ã©l (Base). Para simplificar, nuestro modelo asume que los tiempos de bÃºsqueda y confirmaciÃ³n son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del nÃºmero total de clientes en el sistema. El nÃºmero de fallos evitados por la recuperaciÃ³n entre pares depende de k, el nÃºmero de clientes en la BuddyCache, y del interÃ©s conjunto de los clientes en los datos compartidos. En una ejecuciÃ³n especÃ­fica de BuddyCache, se modela mediante la variable r, definida como el nÃºmero de solicitudes que llegan al redireccionador para una versiÃ³n dada de la pÃ¡gina P (es decir, hasta que un objeto en la pÃ¡gina se invalida). Considera una ejecuciÃ³n con fallos en frÃ­o. Un cliente comienza con una cachÃ© frÃ­a y ejecuta una carga de trabajo de solo lectura hasta que accede a las N pÃ¡ginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la cachÃ© del cliente es lo suficientemente grande como para contener N pÃ¡ginas. En BC, los frÃ­os fallos para la pÃ¡gina P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consideremos a continuaciÃ³n una ejecuciÃ³n con fallos de invalidaciÃ³n. Un cliente comienza con una cachÃ© caliente que contiene el conjunto de trabajo de N pÃ¡ginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualizaciÃ³n entre pares elimina todos los fallos de invalidaciÃ³n. En un grupo que contiene solo lectores (BCR), durante una ejecuciÃ³n en estado estable con actualizaciones uniformes, una transacciÃ³n del cliente tiene fallos de invalidaciÃ³n faltantes. Considera la secuencia de r fallos de cliente en la pÃ¡gina P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la pÃ¡gina P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frÃ­o, r â‰¤ k porque la segunda invalidaciÃ³n deshabilita la redirecciÃ³n para P hasta que el prÃ³ximo fallo en P provoque una recuperaciÃ³n del servidor. Suponiendo un acceso uniforme, un fallo de invalidaciÃ³n del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperaciÃ³n del servidor), y una probabilidad de (1 âˆ’ 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacciÃ³n Ãºnica en los sistemas Base, BCR y BCW. En los experimentos descritos a continuaciÃ³n, medimos los parÃ¡metros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalizaciÃ³n derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalizaciÃ³n y beneficios medidos directamente en los experimentos. 6.2 ConfiguraciÃ³n Experimental Antes de presentar nuestros resultados, describimos nuestra configuraciÃ³n experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el <br>sistema de almacenamiento de objetos</br> distribuidos Thor [23] con clientes conectÃ¡ndose directamente a los servidores. El sistema Buddy ejecuta nuestra implementaciÃ³n del prototipo de BuddyCache en Thor, admitiendo la recuperaciÃ³n de pares, la actualizaciÃ³n de pares y la confirmaciÃ³n en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark estÃ¡ diseÃ±ado para capturar las caracterÃ­sticas de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicaciÃ³n especÃ­fica. Utilizamos OO7 porque es un punto de referencia estÃ¡ndar para medir el rendimiento del <br>sistema de almacenamiento de objetos</br>. La base de datos OO7 contiene un Ã¡rbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un grÃ¡fico de partes atÃ³micas vinculadas por objetos de conexiÃ³n; cada parte atÃ³mica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atÃ³micas por parte compuesta. La base de datos multiusuario asigna a cada cliente un mÃ³dulo privado que consiste en un Ã¡rbol de objetos de ensamblaje, y agrega un mÃ³dulo compartido adicional que escala proporcionalmente al nÃºmero de clientes. Esperamos que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ© y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la cachÃ©. Dado que el objetivo de nuestro estudio es evaluar quÃ© tan efectivamente nuestras tÃ©cnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras tÃ©cnicas tienen en los fallos de cachÃ© frÃ­o y de consistencia de cachÃ©, y aislar tanto como sea posible el efecto de los fallos de capacidad de cachÃ©. Para mantener la duraciÃ³n de nuestros experimentos razonable, utilizamos cachÃ©s pequeÃ±os. El benchmark OO7 genera mÃ³dulos de base de datos de tamaÃ±o predefinido. En nuestra implementaciÃ³n de OO7, el tamaÃ±o del mÃ³dulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la cachÃ©, utilizamos un Ãºnico mÃ³dulo privado y elegimos un tamaÃ±o de cachÃ© de 40MB para cada cliente. La base de datos OO7 se genera con mÃ³dulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos estÃ¡n agrupados en pÃ¡ginas de 8K, que tambiÃ©n son la unidad de transferencia en las solicitudes de recuperaciÃ³n. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro anÃ¡lisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idÃ©ntico a T1 excepto que modifica todas las partes atÃ³micas en un solo compuesto. Una transacciÃ³n Ãºnica incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo mÃ³dulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacciÃ³n, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de bÃºsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una cachÃ© de 50MB (de los cuales 6MB se utilizaron para el bÃºfer de objetos modificados), el cliente tenÃ­a una cachÃ© de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos bÃ¡sicos Esta secciÃ³n analiza el costo bÃ¡sico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 RedirecciÃ³n Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtenciÃ³n del servidor), el costo adicional de la redirecciÃ³n incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperaciÃ³n o confirmaciÃ³n del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmaciÃ³n y recuperaciÃ³n del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de Ã¡rea rÃ¡pida. Todos los nÃºmeros fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirecciÃ³n al cruzar el redireccionador no es muy alto, incluso en una red de Ã¡rea local. El costo de la confirmaciÃ³n aumenta con el nÃºmero de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperaciÃ³n no aumenta tanto porque la cachÃ© del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la cachÃ© del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperaciÃ³n entre pares, medimos la latencia de la recuperaciÃ³n entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperaciÃ³n entre pares, el costo de la redirecciÃ³n incluye, ademÃ¡s del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este Ãºltimo incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la pÃ¡gina solicitada. Medimos directamente el tiempo para copiar y desenrollar la pÃ¡gina solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperaciÃ³n de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador mÃ¡s un viaje de ida y vuelta a travÃ©s de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud mÃ¡s un viaje de ida y vuelta a travÃ©s de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando estÃ¡ bloqueado esperando una respuesta de bÃºsqueda o confirmaciÃ³n. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podrÃ­a ser mitigado por una implementaciÃ³n multi-hilo en un sistema con programaciÃ³n preemptiva. 6.3.2 VersiÃ³n de CachÃ© El commit en solitario permite que un cliente rÃ¡pido que modifica un objeto haga un commit de forma independiente a un compaÃ±ero lento. El mecanismo de confirmaciÃ³n Ãºnica introduce un procesamiento adicional en el servidor durante la validaciÃ³n de la transacciÃ³n, y un procesamiento adicional en el cliente durante la confirmaciÃ³n de la transacciÃ³n y en el momento del procesamiento de actualizaciÃ³n o invalidaciÃ³n. Los gastos generales del lado del servidor son mÃ­nimos y consisten en una actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina en el momento de la confirmaciÃ³n, y una comparaciÃ³n del nÃºmero de versiÃ³n en el momento de la validaciÃ³n de la transacciÃ³n. La cachÃ© de versiÃ³n tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacciÃ³n accede a objetos en mÃºltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor Ãºnico y, por lo tanto, el tiempo de confirmaciÃ³n adicional de la gestiÃ³n de la cachÃ© de versiones en el cliente no contribuye a los resultados presentados en la secciÃ³n a continuaciÃ³n. Para medir estos costos adicionales del lado del cliente en un sistema de mÃºltiples servidores, instrumentamos la implementaciÃ³n de la cachÃ© de versiones para ejecutarse con una traza de carga de trabajo que incluÃ­a invalidaciones reordenadas y cronometramos las operaciones bÃ¡sicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operaciÃ³n de bÃºsqueda de cachÃ© de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n en el momento de preparaciÃ³n de la solicitud de compromiso, y una operaciÃ³n de inserciÃ³n de cachÃ© de versiÃ³n para cada objeto actualizado por una transacciÃ³n en el momento de procesamiento de la respuesta de compromiso, pero solo si la pÃ¡gina actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmaciÃ³n se mantengan al mÃ­nimo, ya que el cliente estÃ¡ esperando de forma sÃ­ncrona la finalizaciÃ³n de la confirmaciÃ³n. Las mediciones muestran que en el peor de los casos, cuando llega un gran nÃºmero de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en pÃ¡ginas reordenadas, el costo de actualizar la cachÃ© de versiÃ³n es de 0.6 ms. El costo de tiempo de invalidaciÃ³n es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementaciÃ³n de la cachÃ© de versiones para reducir aÃºn mÃ¡s estos costos. 6.4 Rendimiento general Esta secciÃ³n examina las mejoras de rendimiento observadas por una aplicaciÃ³n que ejecuta el benchmark OO7 con un BuddyCache en una red de Ã¡rea amplia. 6.4.1 Fallos en frÃ­o Para evaluar las mejoras de rendimiento al evitar fallos en frÃ­o, comparamos el rendimiento de la cachÃ© en frÃ­o del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecuciÃ³n de los sistemas en el entorno de la red de Ã¡rea local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de Ã¡rea amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en cachÃ© frÃ­a. Los nÃºmeros fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frÃ­o solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frÃ­o solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparaciÃ³n con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cÃ¡lculos para el cliente, solicitudes de recuperaciÃ³n directa, recuperaciones de pares y solicitudes de confirmaciÃ³n. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperaciÃ³n entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperaciÃ³n del servidor para cada cliente individual disminuye porque, con mÃ¡s clientes accediendo a un mÃ³dulo compartido de tamaÃ±o fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperaciÃ³n de pares en comparaciÃ³n con la recuperaciÃ³n directa, pero este beneficio se ve contrarrestado por los tiempos de confirmaciÃ³n aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relaciÃ³n con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de cachÃ© 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT funciÃ³n de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias tÃ­picas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Sorprendentemente, los resultados analÃ­ticos predicen la mejora medida muy de cerca, aunque son ligeramente mÃ¡s altos que los valores empÃ­ricos. La razÃ³n principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidaciÃ³n evitados, comparamos el rendimiento de cachÃ© caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interÃ©s de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un Ãºnico cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compaÃ±eros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compaÃ±eros con un grupo que contiene un Ãºnico escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuraciÃ³n simple es suficiente para mostrar el impacto de las tÃ©cnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de cachÃ© caliente de OO7. Obtenemos los nÃºmeros ejecutando 2000 transacciones para filtrar los fallos en frÃ­o y luego medimos el tiempo de las siguientes 1000 transacciones. AquÃ­ nuevamente, los nÃºmeros reportados se derivan de los resultados del experimento de la red de Ã¡rea local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalizaciÃ³n en comparaciÃ³n con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparaciÃ³n con la Base. Este beneficio se debe a la actualizaciÃ³n entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperaciÃ³n entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperaciÃ³n local evitando el retraso de la recuperaciÃ³n desde el servidor. El Ãºltimo es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperaciÃ³n de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperaciÃ³n de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualizaciÃ³n de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relaciÃ³n con Base, y Buddy Writer y Base en relaciÃ³n con Base) en un experimento de cachÃ© activa en funciÃ³n del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualizaciÃ³n entre pares domina el gasto general en la configuraciÃ³n de Writer incluso en redes de baja latencia (la actualizaciÃ³n entre pares incurre en un gasto mÃ­nimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Como en experimentos de cachÃ© frÃ­a, aquÃ­ los resultados analÃ­ticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pÃ©rdida de invalidaciÃ³n es mÃ­nimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de cachÃ© frÃ­a). Como en el caso de cachÃ© frÃ­a, la razÃ³n por la que el modelo analÃ­tico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÃ“N Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en una red de Ã¡rea extensa debido a la alta latencia de red. Este artÃ­culo describe BuddyCache, una nueva tÃ©cnica de almacenamiento en cachÃ© cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La tÃ©cnica mejora el rendimiento y proporciona propiedades sÃ³lidas de correcciÃ³n y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirecciÃ³n para obtener objetos faltantes directamente de las cachÃ©s de los miembros del grupo, y para admitir la actualizaciÃ³n entre pares, una nueva tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirecciÃ³n puede interferir con la disponibilidad del objeto. Solo commit es una nueva tÃ©cnica de validaciÃ³n que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validaciÃ³n detallada utilizando informaciÃ³n de versiÃ³n de grano grueso econÃ³mica. Hemos diseÃ±ado e implementado el prototipo de BuddyCache en el <br>sistema de almacenamiento de objetos</br> transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analÃ­ticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Las principales contribuciones del artÃ­culo son: 1. extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementaciÃ³n del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluaciÃ³n del rendimiento basada en anÃ¡lisis y mediciones de los costos y beneficios de las nuevas tÃ©cnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. TambiÃ©n agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios Ãºtiles que mejoraron este artÃ­culo. 9. REFERENCIAS [1] emulab.net, la InstalaciÃ³n de EmulaciÃ³n de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. ReconstrucciÃ³n de fragmentos: Proporcionando coherencia de cachÃ© global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre GestiÃ³n de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: ComputaciÃ³n en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de cachÃ© hÃ­bridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. RecuperaciÃ³n rÃ¡pida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de cachÃ© en la World Wide Web. En la 17Âª Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluaciÃ³n del rendimiento del sistema de gestiÃ³n de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una cachÃ© de objetos jerÃ¡rquica en Internet. En la Conferencia TÃ©cnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachÃ©s de Internet escalables. Informe TÃ©cnico CS-1997-18, Departamento de Ciencias de la ComputaciÃ³n, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: CachÃ© de proxy cooperativa en una red de Ã¡rea amplia. En el Tercer Taller Internacional de CachÃ© de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. CachÃ© web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2Âº Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. CachÃ© cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilaciÃ³n y en tiempo de ejecuciÃ³n para una memoria compartida distribuida eficiente. En Actas de IEEE, EdiciÃ³n Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la cachÃ©: un protocolo de intercambio de cachÃ© web escalable de Ã¡rea amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. ImplementaciÃ³n de GestiÃ³n Global de Memoria en un ClÃºster de Estaciones de Trabajo. Actas del 15Âº Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: DiseÃ±o, ImplementaciÃ³n y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de cachÃ© transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, pÃ¡ginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. GestiÃ³n global de memoria para arquitecturas de sistemas de gestiÃ³n de bases de datos cliente-servidor. En Actas del 19Âº Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El BÃºfer de Objeto Modificado: Una TÃ©cnica de GestiÃ³n de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto TecnolÃ³gico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. GestiÃ³n de documentos replicados en un sistema de comunicaciÃ³n grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13Âª Conferencia Europea sobre ProgramaciÃ³n Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18Âº Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. ReplicaciÃ³n con marca de vista: un nuevo mÃ©todo de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de ComputaciÃ³n Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalaciÃ³n eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de MultidifusiÃ³n a Nivel de AplicaciÃ³n. En el 3er Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de cachÃ© cooperativa utilizando pistas. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en CachÃ© Global. Informe tÃ©cnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del CachÃ© de Proxies Web Cooperativos. En el 17Âº Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerÃ¡rquica de cachÃ© en una WAN. En el Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. ComparticiÃ³n adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÃ‰NDICE Este apÃ©ndice describe el protocolo de conmutaciÃ³n por error de BuddyCache. Para dar cabida a clientes heterogÃ©neos, incluidos los dispositivos portÃ¡tiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseÃ±o de BuddyCache asume que las cachÃ©s del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresÃ­a detecta el fallo de un cliente o un redireccionador intercambiando mensajes periÃ³dicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutaciÃ³n por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuraciÃ³n y reinicia el protocolo. El protocolo de reconfiguraciÃ³n del grupo es similar al presentado en [25]. AquÃ­ describimos cÃ³mo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de pÃ¡ginas redireccionadas y el reenvÃ­o de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachÃ©s. En caso de un fallo del cliente, el failover elimina las pÃ¡ginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmaciÃ³n, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en cachÃ© las pÃ¡ginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutaciÃ³n por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de pÃ¡ginas utilizando un protocolo similar al descrito en [6]. El redireccionador reciÃ©n reiniciado solicita a los miembros activos del grupo la lista de pÃ¡ginas que estÃ¡n almacenando en cachÃ© y el estado de estas pÃ¡ginas, es decir, si las pÃ¡ginas estÃ¡n completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperaciÃ³n perdida expirarÃ¡ en el cliente y serÃ¡ retransmitida. Una transacciÃ³n que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma despuÃ©s del cambio se trata como una transacciÃ³n regular; una transacciÃ³n que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciarÃ¡ la transacciÃ³n y la solicitud de confirmaciÃ³n serÃ¡ retransmitida despuÃ©s del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caÃ­do podrÃ­an evitar la recolecciÃ³n de basura de las invalidaciones pendientes en los servidores o la cachÃ© virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los nÃºmeros de versiÃ³n Ãºnicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validaciÃ³n de transacciones depende del protocolo de coherencia de cachÃ© para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutaciÃ³n por error de BuddyCache no compromete la correcciÃ³n del procedimiento de validaciÃ³n. Recuerda que la validaciÃ³n de transacciones de BuddyCache utiliza dos mecanismos complementarios, nÃºmeros de versiÃ³n de pÃ¡gina y confirmaciones de invalidaciÃ³n de los clientes, para verificar que una transacciÃ³n ha leÃ­do datos actualizados. La propagaciÃ³n de la confirmaciÃ³n de invalidaciÃ³n (y actualizaciÃ³n) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmaciÃ³n de una modificaciÃ³n (invalidaciÃ³n o actualizaciÃ³n) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en cachÃ© el objeto o bien ha instalado el valor mÃ¡s reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmaciÃ³n de un cliente para una transacciÃ³n T que lee un objeto o despuÃ©s de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidaciÃ³n no confirmada para o pendiente para este grupo, la versiÃ³n del objeto leÃ­da por la transacciÃ³n T estÃ¡ actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validaciÃ³n utilizando nÃºmeros de versiÃ³n. El registro de confirmaciÃ³n de transacciÃ³n contiene un nÃºmero de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n. El protocolo de nÃºmero de versiÃ³n mantiene la invariante V P que garantiza que el valor del objeto o leÃ­do por la transacciÃ³n corresponda al nÃºmero de versiÃ³n mÃ¡s alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificaciÃ³n anterior despuÃ©s de haber recibido una modificaciÃ³n posterior. La retransmisiÃ³n de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validaciÃ³n verifica que el nÃºmero de versiÃ³n en el registro de confirmaciÃ³n coincida con el nÃºmero de versiÃ³n en la invalidaciÃ³n pendiente no reconocida. Es fÃ¡cil ver que, dado que esta comprobaciÃ³n es una comprobaciÃ³n cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutaciÃ³n por error aÃºn no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "collaborative strong-consistency application": {
            "translated_key": "alta consistencia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for <br>collaborative strong-consistency application</br>s in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for <br>collaborative strong-consistency application</br>s in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for <br>collaborative strong-consistency application</br>s in high-latency network environments.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for <br>collaborative strong-consistency application</br>s in high-latency network environments."
            ],
            "translated_annotated_samples": [
                "BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de <br>alta consistencia</br> en entornos de red de alta latencia.",
                "Este artÃ­culo describe BuddyCache, una nueva tÃ©cnica de almacenamiento en cachÃ© cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para <br>aplicaciones colaborativas de alta consistencia</br> en entornos de red de alta latencia."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de <br>alta consistencia</br> en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de Ã¡rea amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de Ã¡rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil. Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en cachÃ© web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos. Sin embargo, las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica. La interacciÃ³n con el servidor aumenta la latencia. La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia. Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n. Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo. BuddyCache presenta dos desafÃ­os tÃ©cnicos principales. Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©. El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de almacenamiento en cachÃ© web cooperativos [11]. Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo. BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos. Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica. Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad? DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red. Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia. El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida. Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache. Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n. Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos. Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de Ã¡rea amplia. Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad. Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un Ãºnico servidor. Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web. El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en cachÃ© transaccional [19]. La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una transacciÃ³n, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador. El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado. AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©. Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina). La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente. El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento. A continuaciÃ³n, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene. La transacciÃ³n puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor. Sin embargo, antes de que una transacciÃ³n se confirme, debe ser validada; el servidor debe asegurarse de que la transacciÃ³n validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada. Si la validaciÃ³n falla, la transacciÃ³n se cancela. Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de bÃºsqueda de pares envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la cachÃ© y envÃ­an confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la cachÃ© del cliente, la confirmaciÃ³n de invalidaciÃ³n indica al servidor que un cliente sin invalidaciones pendientes ha leÃ­do objetos actualizados. Una invalidaciÃ³n no reconocida indica que un objeto obsoleto puede haber sido accedido en la cachÃ© del cliente. El procedimiento de validaciÃ³n en el servidor aborta una transacciÃ³n del cliente si este lee un objeto mientras hay una invalidaciÃ³n pendiente. El mecanismo de invalidaciÃ³n reconocido admite coherencia de cachÃ© a nivel de objeto sin directorios basados en objetos o nÃºmeros de versiÃ³n por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeÃ±os, ya que los objetos tÃ­picos son pequeÃ±os. Un objetivo importante del diseÃ±o de BuddyCache es mantener este beneficio. Dado que en BuddyCache una pÃ¡gina puede ser recuperada en una cachÃ© de cliente sin intervenciÃ³n del servidor (como se ilustra en la figura 2), los directorios de cachÃ© en los servidores llevan un registro de las pÃ¡ginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las pÃ¡ginas almacenadas en cachÃ© en cada cliente de un grupo. Los servidores envÃ­an al redireccionador invalidaciones para las pÃ¡ginas almacenadas en cachÃ© en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. ActualizaciÃ³n de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en cachÃ© por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interÃ©s potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de cachÃ© y las actualizaciones de cachÃ©. Los estudios de coherencia de cachÃ© en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualizaciÃ³n y la invalidaciÃ³n. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. AlmacÃ©n x 6. ActualizaciÃ³n x 3. CompromÃ©tete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares estÃ¡n fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeÃ±as, agrupadas y se envÃ­an junto con otros mensajes. AdemÃ¡s, los protocolos de invalidaciÃ³n se ajustan a la tendencia actual de hardware de aumentar los tamaÃ±os de cachÃ© del cliente. Es probable que las cachÃ©s mÃ¡s grandes contengan mucha mÃ¡s informaciÃ³n de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una red de Ã¡rea amplia serÃ­an derrochadores. Sin embargo, los protocolos de coherencia basados en invalidaciÃ³n pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interÃ©s para otro miembro del grupo. Con un protocolo basado en invalidaciÃ³n, la actualizaciÃ³n de un miembro invalidarÃ¡ la copia en cachÃ© de otro miembro, lo que provocarÃ¡ que este Ãºltimo realice una recuperaciÃ³n de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualizaciÃ³n e invalidaciÃ³n en entornos de redes de Ã¡rea amplia. Evita la penalizaciÃ³n de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalizaciÃ³n de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusiÃ³n localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en cachÃ© anteriores. La actualizaciÃ³n entre pares funciona de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que la transacciÃ³n se confirma, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n, y tambiÃ©n propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmaciÃ³n. 3.3 ConfirmaciÃ³n individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminaciÃ³n de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en cachÃ© transaccional, ya que un cliente que es lento para reconocer una invalidaciÃ³n o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacciÃ³n. Por ejemplo, un ingeniero que realiza una revisiÃ³n repetida al mismo objeto de diseÃ±o compartido (y por lo tanto tiene la Ãºltima versiÃ³n del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situaciÃ³n representada en la figura 4 donde el Cliente1 realiza una transacciÃ³n T que lee la Ãºltima versiÃ³n de un objeto x en la pÃ¡gina P recientemente modificada por el Cliente1. Si la solicitud de confirmaciÃ³n para T llega al servidor antes de que la confirmaciÃ³n colectiva de Cliente2 por la Ãºltima modificaciÃ³n de x llegue al servidor, el procedimiento de validaciÃ³n de OCC considera que x estÃ¡ obsoleto y aborta T (porque, como se explicÃ³ anteriormente, una invalidaciÃ³n no reconocida por un cliente actÃºa como indicaciÃ³n para el servidor de que el valor del objeto en cachÃ© estÃ¡ obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la correcciÃ³n del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asÃ­ncronas son una parte importante de la razÃ³n por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasiÃ³n de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envÃ­an y procesan de forma asÃ­ncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devoluciÃ³n de llamada jerÃ¡rquica [32], pero la naturaleza asincrÃ³nica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrÃ³nicas. El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a un cliente con objetos actualizados confirmar una transacciÃ³n incluso si la confirmaciÃ³n del grupo se retrasa debido a pares lentos o caÃ­dos. El protocolo requiere que los clientes incluyan informaciÃ³n adicional con los conjuntos de lectura de transacciones en el mensaje de confirmaciÃ³n, para indicar al servidor que los objetos leÃ­dos por la transacciÃ³n estÃ¡n actualizados. Los nÃºmeros de versiÃ³n de los objetos podrÃ­an proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionÃ³ anteriormente, mantener nÃºmeros de versiÃ³n por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaÃ±o de directorio) en todo el sistema de objetos cuando los objetos son pequeÃ±os [23]. En cambio, solo utiliza nÃºmeros de versiÃ³n de pÃ¡gina de grano grueso para identificar versiones de objetos de grano fino. El nÃºmero de versiÃ³n de una pÃ¡gina se incrementa en un servidor cuando una transacciÃ³n que modifica objetos en la pÃ¡gina se confirma. Las actualizaciones realizadas por una Ãºnica transacciÃ³n y las invalidaciones correspondientes son identificadas de manera Ãºnica por el nÃºmero de versiÃ³n de la pÃ¡gina modificada. Los nÃºmeros de versiÃ³n de la pÃ¡gina se propagan a los clientes en respuestas de recuperaciÃ³n, respuestas de confirmaciÃ³n y con invalidaciones, y los clientes incluyen los nÃºmeros de versiÃ³n de la pÃ¡gina en las solicitudes de confirmaciÃ³n enviadas a los servidores. Si una transacciÃ³n falla en la validaciÃ³n debido a la falta de reconocimiento de grupo, el servidor verifica los nÃºmeros de versiÃ³n de pÃ¡gina de los objetos en el conjunto de lectura de la transacciÃ³n y permite que la transacciÃ³n se confirme si el cliente ha leÃ­do desde la Ãºltima versiÃ³n de la pÃ¡gina. Los nÃºmeros de versiÃ³n de la pÃ¡gina permiten confirmaciones independientes, pero las verificaciones de versiÃ³n de pÃ¡gina solo detectan conflictos a nivel de pÃ¡gina. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La secciÃ³n 4 describe los detalles de la implementaciÃ³n del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 ConfiguraciÃ³n de Grupo La arquitectura BuddyCache admite mÃºltiples grupos de pares concurrentes. Potencialmente, puede ser mÃ¡s rÃ¡pido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podrÃ­a ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en cachÃ© de pares de mÃºltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en cachÃ© web, simplemente aumentar la poblaciÃ³n de clientes en una cachÃ© proxy a menudo aumenta la tasa general de aciertos en la cachÃ© [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacciÃ³n explÃ­cita entre clientes y la colaboraciÃ³n, lo que sugiere que es poco probable que ocurra la recuperaciÃ³n entre grupos. AdemÃ¡s, las mediciones de sistemas de almacenamiento en cachÃ© web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexiÃ³n de red entre los grupos de pares sea muy rÃ¡pida. Estamos principalmente interesados en entornos donde compaÃ±eros que colaboran estrechamente tienen una conectividad rÃ¡pida a corta distancia, pero la conexiÃ³n entre grupos de compaÃ±eros puede ser lenta. Como resultado, decidimos que el soporte para la recuperaciÃ³n entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compaÃ±eros con recursos heterogÃ©neos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compaÃ±eros o, cuando estÃ© disponible, en un nodo separado dentro de la infraestructura del sitio. AdemÃ¡s, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una cachÃ© de pares en espera para recibir pÃ¡ginas recuperadas por otros pares, emulando una cachÃ© central algo similar a una cachÃ© de proxy web regional. Desde el punto de vista del protocolo de coherencia de cachÃ© BuddyCache, sin embargo, un cachÃ© de compaÃ±ero en espera es equivalente a un cachÃ© de compaÃ±ero regular y, por lo tanto, no consideramos este caso por separado en la discusiÃ³n de este documento. 4. En esta secciÃ³n proporcionamos los detalles de la implementaciÃ³n de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en cachÃ© de estos objetos. Las aplicaciones se ejecutan en los clientes e interactÃºan con el sistema realizando llamadas a mÃ©todos de objetos en cachÃ©. Todas las llamadas a mÃ©todos ocurren dentro de transacciones atÃ³micas. Los clientes se comunican con los servidores para obtener pÃ¡ginas o realizar una transacciÃ³n. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volÃ¡til. El disco estÃ¡ organizado como una colecciÃ³n de pÃ¡ginas que son las unidades de acceso al disco. El registro estable guarda la informaciÃ³n de confirmaciÃ³n y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de cachÃ© y una cachÃ© de objetos modificados recuperable llamada MOB. El directorio lleva un registro de quÃ© pÃ¡ginas estÃ¡n almacenadas en cachÃ© por quÃ© clientes. El MOB contiene objetos recientemente modificados que aÃºn no han sido escritos de vuelta en sus pÃ¡ginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de cachÃ© base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la SecciÃ³n 3.1. Proporcionamos algunos de los detalles relevantes de la implementaciÃ³n del protocolo OCC. El cliente lleva un registro de los objetos que son leÃ­dos y modificados por su transacciÃ³n; envÃ­a esta informaciÃ³n, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacciÃ³n. Los servidores determinan si la confirmaciÃ³n es posible, utilizando un protocolo de confirmaciÃ³n de dos fases si la transacciÃ³n utilizÃ³ objetos en mÃºltiples servidores. Si la transacciÃ³n se lleva a cabo, las nuevas copias de los objetos modificados se aÃ±aden al registro y tambiÃ©n se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperaciÃ³n escaneando el registro. Dado que los objetos no estÃ¡n bloqueados antes de ser utilizados, una confirmaciÃ³n de transacciÃ³n puede hacer que las cachÃ©s contengan objetos obsoletos. Los servidores abortarÃ¡n una transacciÃ³n que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviÃ¡ndoles mensajes de invalidaciÃ³n; un servidor utiliza su directorio y la informaciÃ³n sobre la transacciÃ³n de confirmaciÃ³n para determinar quÃ© mensajes de invalidaciÃ³n enviar. Los mensajes de invalidaciÃ³n son pequeÃ±os porque simplemente identifican objetos obsoletos. AdemÃ¡s, se envÃ­an en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidaciÃ³n, elimina los objetos obsoletos de su cachÃ© y aborta la transacciÃ³n actual si los utilizÃ³. El cliente sigue conservando pÃ¡ginas que contienen objetos invalidados; estas pÃ¡ginas ahora estÃ¡n incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidaciÃ³n de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener pÃ¡ginas incompletas en la cachÃ© del cliente significa que el falso intercambio no conduce a fallos innecesarios en la cachÃ©. Los clientes reconocen las invalidaciones para indicar la eliminaciÃ³n de datos obsoletos, como se explica en la SecciÃ³n 3.1. Los mensajes de invalidaciÃ³n evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo asÃ­ el desperdicio de trabajo y trasladando la detecciÃ³n de abortos de los servidores a los clientes. Cuando una transacciÃ³n se aborta, su cliente restaura las copias en cachÃ© de los objetos modificados al estado que tenÃ­an antes de que la transacciÃ³n comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacciÃ³n. 4.3 RedirecciÃ³n El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de pÃ¡ginas disponibles en el grupo de pares y proporciona una redirecciÃ³n rÃ¡pida y centralizada de recuperaciÃ³n (ver figura 2) entre las cachÃ©s de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan pÃ¡ginas u objetos al incluir esa informaciÃ³n en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la cachÃ© de grupo, el redireccionador realiza un seguimiento del estado de las pÃ¡ginas. Una pÃ¡gina en cachÃ© estÃ¡ completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una pÃ¡gina estÃ¡n marcados como invÃ¡lidos. Solo se utilizan pÃ¡ginas completas por el proceso de recuperaciÃ³n de pares. El protocolo para mantener el estado de la pÃ¡gina cuando las pÃ¡ginas son actualizadas e invalidadas se describe en la SecciÃ³n 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una pÃ¡gina solicitada completa no estÃ¡ disponible en el grupo de pares o si un par necesita confirmar una transacciÃ³n, el redireccionador actÃºa como un proxy de servidor: reenvÃ­a la solicitud al servidor y luego reenvÃ­a la respuesta de vuelta al cliente. AdemÃ¡s, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualizaciÃ³n o informaciÃ³n de invalidaciÃ³n a los clientes que tienen en cachÃ© la pÃ¡gina modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la cachÃ© de grupo de pares combinada estÃ¡ desempeÃ±ando el papel de una Ãºnica cachÃ© de cliente en el sistema base. 4.4 ActualizaciÃ³n de pares La actualizaciÃ³n de pares se implementa de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que una transacciÃ³n se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacciÃ³n generan invalidaciones de objetos para cada grupo de cachÃ© que almacena pÃ¡ginas que contienen los objetos modificados (incluido el grupo que realiza la confirmaciÃ³n). Las invalidaciones se envÃ­an de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en cachÃ© los objetos modificados se deshagan de los datos obsoletos. En grupos de cachÃ© distintos al grupo de confirmaciÃ³n, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas, recopilan las confirmaciones de los clientes y, despuÃ©s de completar la recopilaciÃ³n, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacciÃ³n, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envÃ­an a los clientes que almacenan en cachÃ© esas pÃ¡ginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmaciÃ³n colectiva se propaga al servidor. Una invalidaciÃ³n hace que una pÃ¡gina en cachÃ© no estÃ© disponible para la recuperaciÃ³n de pares, cambiando el estado de una pÃ¡gina completa p a incompleta. Por el contrario, una actualizaciÃ³n de una pÃ¡gina completa conserva el estado completo de la pÃ¡gina. Como se muestra en los estudios de la reconstrucciÃ³n de fragmentos 31 [2], esta propagaciÃ³n de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma pÃ¡gina, la pÃ¡gina conserva su estado completo y permanece disponible para la recuperaciÃ³n entre pares. Por lo tanto, el efecto de la actualizaciÃ³n de pares es similar a la reconstrucciÃ³n de fragmentos ansiosa [2]. TambiÃ©n hemos considerado la posibilidad de permitir que un compaÃ±ero recupere una pÃ¡gina incompleta (con objetos invÃ¡lidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos invÃ¡lidos. 4.5 Vcache El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo mÃ¡s lentos (o fallidos). Como se explica en la SecciÃ³n 3.3, el protocolo de commit Ãºnico permite que una transacciÃ³n T pase la validaciÃ³n si la informaciÃ³n adicional de coherencia proporcionada por el cliente indica que la transacciÃ³n T ha leÃ­do objetos actualizados. Los clientes utilizan los nÃºmeros de versiÃ³n de la pÃ¡gina para proporcionar esta informaciÃ³n adicional de coherencia. Es decir, un cliente incluye el nÃºmero de versiÃ³n de la pÃ¡gina correspondiente a cada objeto en el conjunto de objetos leÃ­dos enviado en la solicitud de confirmaciÃ³n al servidor. Dado que a cada actualizaciÃ³n de objeto comprometido le corresponde un nÃºmero de versiÃ³n de pÃ¡gina Ãºnico, el nÃºmero de versiÃ³n de pÃ¡gina asociado con un objeto permite que el procedimiento de validaciÃ³n en el servidor verifique si la transacciÃ³n del cliente ha leÃ­do objetos actualizados. El uso de versiones de pÃ¡gina de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeÃ±os, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en cachÃ© a la versiÃ³n de pÃ¡gina identificadora (ObjectToVersion). El principal problema de implementaciÃ³n se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian nÃºmeros de versiÃ³n de pÃ¡gina con las invalidaciones. En el momento de la validaciÃ³n, si hay una invalidaciÃ³n no reconocida pendiente para un objeto x leÃ­do por una transacciÃ³n T, el procedimiento de validaciÃ³n verifica si el nÃºmero de versiÃ³n de x en el conjunto de lectura de Ts coincide con el nÃºmero de versiÃ³n de la invalidaciÃ³n pendiente mÃ¡s alta para x, en cuyo caso el valor del objeto estÃ¡ actualizado, de lo contrario, T falla en la validaciÃ³n. Observamos nuevamente que las verificaciones basadas en el nÃºmero de versiÃ³n de la pÃ¡gina y las verificaciones basadas en el reconocimiento de invalidaciÃ³n son complementarias en la validaciÃ³n de confirmaciÃ³n individual y ambas son necesarias. La verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina permite que la validaciÃ³n avance antes de que lleguen las confirmaciones de invalidaciÃ³n, pero por sÃ­ sola, una verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina detecta conflictos a nivel de pÃ¡gina y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cÃ³mo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un nÃºmero de versiÃ³n de la pÃ¡gina para cada pÃ¡gina en cachÃ©. El nÃºmero de versiÃ³n satisface la siguiente invariante V P sobre el estado de los objetos en una pÃ¡gina: si una pÃ¡gina en cachÃ© P tiene un nÃºmero de versiÃ³n v, entonces el valor de un objeto o en la pÃ¡gina en cachÃ© P es invÃ¡lido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacciÃ³n que estableciÃ³ el nÃºmero de versiÃ³n de P en v. Los nuevos valores de objetos y los nuevos nÃºmeros de versiÃ³n de pÃ¡gina llegan cuando un cliente obtiene una pÃ¡gina o cuando llega una respuesta de confirmaciÃ³n o invalidaciones para esta pÃ¡gina. Los nuevos valores del objeto modifican la pÃ¡gina y, por lo tanto, el nÃºmero de versiÃ³n de la pÃ¡gina necesita ser actualizado para mantener la invariante V P. Un nÃºmero de versiÃ³n de pÃ¡gina que llega cuando un cliente obtiene una pÃ¡gina, reemplaza la VersiÃ³n del Objeto x 8 Servidor de RedirecciÃ³n 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el nÃºmero de versiÃ³n de la pÃ¡gina para esta pÃ¡gina. Tal actualizaciÃ³n preserva el invariante V P. De manera similar, un nÃºmero de versiÃ³n de pÃ¡gina en secuencia que llega al cliente en un mensaje de confirmaciÃ³n o invalidaciÃ³n avanza el nÃºmero de versiÃ³n para toda la pÃ¡gina en cachÃ©, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus nÃºmeros de versiÃ³n de pÃ¡gina correspondientes tambiÃ©n pueden llegar al cliente fuera de secuencia, en cuyo caso la actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina podrÃ­a violar V P. Por ejemplo, una respuesta de confirmaciÃ³n para una transacciÃ³n que actualiza el objeto x en la pÃ¡gina P en el servidor S1, y el objeto y en la pÃ¡gina Q en el servidor S2, puede entregar un nuevo nÃºmero de versiÃ³n para P desde el coordinador de transacciones S1 antes de que llegue una invalidaciÃ³n generada para una transacciÃ³n anterior que ha modificado el objeto r en la pÃ¡gina P desde S1 (como se muestra en la figura 5). El protocolo de actualizaciÃ³n de cachÃ© garantiza que el valor de cualquier objeto o en una pÃ¡gina en cachÃ© P refleje la actualizaciÃ³n o invalidaciÃ³n con el nÃºmero de versiÃ³n observado mÃ¡s alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de nÃºmeros de versiÃ³n de pÃ¡gina, el cliente gestiona una pequeÃ±a cachÃ© de nÃºmeros de versiÃ³n vcache que mantiene el mapeo de un objeto a su nÃºmero de versiÃ³n de pÃ¡gina correspondiente para todas las actualizaciones de nÃºmeros de versiÃ³n reordenadas hasta que se ensamble una secuencia completa de nÃºmeros de versiÃ³n de pÃ¡gina. Cuando llegan los nÃºmeros de versiÃ³n faltantes para la pÃ¡gina y completan una secuencia, el nÃºmero de versiÃ³n de toda la pÃ¡gina se avanza. El mapeo de ObjectToVersion, incluyendo los nÃºmeros de versiÃ³n de vcache y pÃ¡gina, se utiliza en el momento de la confirmaciÃ³n de la transacciÃ³n para proporcionar nÃºmeros de versiÃ³n para el conjunto de objetos leÃ­dos de la siguiente manera. Si el objeto leÃ­do tiene una entrada en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n mÃ¡s alto en la vcache para este objeto. Si el objeto no estÃ¡ presente en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n de la pÃ¡gina en cachÃ© que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la cachÃ© del cliente, incluyendo los nÃºmeros de versiÃ³n de las pÃ¡ginas y la vcache. El cliente puede limitar el tamaÃ±o de la cachÃ© virtual segÃºn sea necesario, ya que volver a cargar una pÃ¡gina elimina todos los nÃºmeros de versiÃ³n de pÃ¡gina reordenados de la cachÃ© virtual. Sin embargo, esperamos que la reorganizaciÃ³n de nÃºmeros de versiÃ³n sea poco comÃºn y, por lo tanto, esperamos que la vcache sea muy pequeÃ±a. 5. Un grupo de clientes contiene mÃºltiples nodos de cliente y un objeto de pÃ¡gina de versiÃ³n redi32 VCache Cliente CachÃ© Cliente PÃ¡gina CachÃ© Figura 6: Mapa de Objeto a VersiÃ³n con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutaciÃ³n por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. AdemÃ¡s, el fallo del redireccionador deberÃ­a permitir que los clientes no afectados mantengan sus cachÃ©s intactas. Hemos diseÃ±ado un protocolo de conmutaciÃ³n por error para BuddyCache pero aÃºn no lo hemos implementado. El apÃ©ndice describe el protocolo. 6. La redirecciÃ³n de BuddyCache en la evaluaciÃ³n de rendimiento respalda los beneficios de evitar la comunicaciÃ³n con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes. Â¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 AnÃ¡lisis Los beneficios de rendimiento de la recuperaciÃ³n entre pares y la actualizaciÃ³n entre pares se deben a la evitaciÃ³n de interacciones con el servidor. Esta secciÃ³n presenta un modelo de rendimiento analÃ­tico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la cachÃ© del cliente. Estos pueden ser fallos frÃ­os, fallos de invalidaciÃ³n y fallos de capacidad. Nuestro anÃ¡lisis se centra en los fallos por frÃ­o y los fallos por invalidaciÃ³n, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frÃ­o. AdemÃ¡s, las tendencias tecnolÃ³gicas indican que la capacidad de memoria y almacenamiento seguirÃ¡ creciendo y, por lo tanto, es probable que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ©. Los fallos de cachÃ© del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuraciÃ³n de cachÃ©. Nuestro anÃ¡lisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validaciÃ³n. Para estudiar el beneficio de evitar fallos en frÃ­o, consideramos el rendimiento de la cachÃ© en frÃ­o en una carga de trabajo de solo lectura (sin fallos de invalidaciÃ³n). Esperamos que la recuperaciÃ³n entre pares mejore el costo de latencia para las solicitudes de cachÃ© frÃ­a del cliente al recuperar objetos de la cachÃ© cercana. Evaluamos cÃ³mo el costo de redirecciÃ³n afecta este beneficio al comparar y analizar el rendimiento de una aplicaciÃ³n que se ejecuta en un sistema de almacenamiento con BuddyCache y sin Ã©l (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidaciÃ³n, consideramos el rendimiento de la cachÃ© caliente en una carga de trabajo con modificaciones (sin fallos en frÃ­o). En las cachÃ©s calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualizaciÃ³n entre pares permite que un cliente acceda a un objeto modificado por un compaÃ±ero colaborador cercano sin el retraso impuesto por los protocolos de invalidaciÃ³n Ãºnicamente. En grupos donde los compaÃ±eros comparten un interÃ©s de solo lectura en los objetos modificados, la recuperaciÃ³n entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compaÃ±ero colaborador lo tenga, lo que evita el retraso de la recuperaciÃ³n del servidor sin el alto costo impuesto por los protocolos de solo actualizaciÃ³n. Las tendencias tecnolÃ³gicas indican que ambos beneficios seguirÃ¡n siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualizaciÃ³n Ãºnicamente. Sin embargo, la tendencia hacia cachÃ©s cada vez mÃ¡s grandes, que se actualizan cuando los objetos en cachÃ© son modificados, hace que los protocolos basados en invalidaciÃ³n sean mÃ¡s atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicaciÃ³n que se ejecuta sin BuddyCache y una aplicaciÃ³n que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compaÃ±ero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compaÃ±ero fuera del grupo. La actualizaciÃ³n entre pares tambiÃ©n puede evitar fallos de invalidaciÃ³n debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma pÃ¡gina de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseÃ±o del objeto, y tambiÃ©n porque este beneficio se puede derivar dado el Ã­ndice de aciertos en cachÃ© y la contenciÃ³n de la carga de trabajo. 6.1.1 El Modelo El modelo considera cÃ³mo el tiempo para completar una ejecuciÃ³n con y sin BuddyCache se ve afectado por los fallos de invalidaciÃ³n y los fallos en frÃ­o. Considerando k clientes ejecutÃ¡ndose concurrentemente accediendo de manera uniforme a un conjunto compartido de N pÃ¡ginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacciÃ³n y realizar cÃ¡lculos en una transacciÃ³n, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin Ã©l (Base). Para simplificar, nuestro modelo asume que los tiempos de bÃºsqueda y confirmaciÃ³n son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del nÃºmero total de clientes en el sistema. El nÃºmero de fallos evitados por la recuperaciÃ³n entre pares depende de k, el nÃºmero de clientes en la BuddyCache, y del interÃ©s conjunto de los clientes en los datos compartidos. En una ejecuciÃ³n especÃ­fica de BuddyCache, se modela mediante la variable r, definida como el nÃºmero de solicitudes que llegan al redireccionador para una versiÃ³n dada de la pÃ¡gina P (es decir, hasta que un objeto en la pÃ¡gina se invalida). Considera una ejecuciÃ³n con fallos en frÃ­o. Un cliente comienza con una cachÃ© frÃ­a y ejecuta una carga de trabajo de solo lectura hasta que accede a las N pÃ¡ginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la cachÃ© del cliente es lo suficientemente grande como para contener N pÃ¡ginas. En BC, los frÃ­os fallos para la pÃ¡gina P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consideremos a continuaciÃ³n una ejecuciÃ³n con fallos de invalidaciÃ³n. Un cliente comienza con una cachÃ© caliente que contiene el conjunto de trabajo de N pÃ¡ginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualizaciÃ³n entre pares elimina todos los fallos de invalidaciÃ³n. En un grupo que contiene solo lectores (BCR), durante una ejecuciÃ³n en estado estable con actualizaciones uniformes, una transacciÃ³n del cliente tiene fallos de invalidaciÃ³n faltantes. Considera la secuencia de r fallos de cliente en la pÃ¡gina P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la pÃ¡gina P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frÃ­o, r â‰¤ k porque la segunda invalidaciÃ³n deshabilita la redirecciÃ³n para P hasta que el prÃ³ximo fallo en P provoque una recuperaciÃ³n del servidor. Suponiendo un acceso uniforme, un fallo de invalidaciÃ³n del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperaciÃ³n del servidor), y una probabilidad de (1 âˆ’ 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacciÃ³n Ãºnica en los sistemas Base, BCR y BCW. En los experimentos descritos a continuaciÃ³n, medimos los parÃ¡metros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalizaciÃ³n derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalizaciÃ³n y beneficios medidos directamente en los experimentos. 6.2 ConfiguraciÃ³n Experimental Antes de presentar nuestros resultados, describimos nuestra configuraciÃ³n experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectÃ¡ndose directamente a los servidores. El sistema Buddy ejecuta nuestra implementaciÃ³n del prototipo de BuddyCache en Thor, admitiendo la recuperaciÃ³n de pares, la actualizaciÃ³n de pares y la confirmaciÃ³n en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark estÃ¡ diseÃ±ado para capturar las caracterÃ­sticas de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicaciÃ³n especÃ­fica. Utilizamos OO7 porque es un punto de referencia estÃ¡ndar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un Ã¡rbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un grÃ¡fico de partes atÃ³micas vinculadas por objetos de conexiÃ³n; cada parte atÃ³mica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atÃ³micas por parte compuesta. La base de datos multiusuario asigna a cada cliente un mÃ³dulo privado que consiste en un Ã¡rbol de objetos de ensamblaje, y agrega un mÃ³dulo compartido adicional que escala proporcionalmente al nÃºmero de clientes. Esperamos que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ© y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la cachÃ©. Dado que el objetivo de nuestro estudio es evaluar quÃ© tan efectivamente nuestras tÃ©cnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras tÃ©cnicas tienen en los fallos de cachÃ© frÃ­o y de consistencia de cachÃ©, y aislar tanto como sea posible el efecto de los fallos de capacidad de cachÃ©. Para mantener la duraciÃ³n de nuestros experimentos razonable, utilizamos cachÃ©s pequeÃ±os. El benchmark OO7 genera mÃ³dulos de base de datos de tamaÃ±o predefinido. En nuestra implementaciÃ³n de OO7, el tamaÃ±o del mÃ³dulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la cachÃ©, utilizamos un Ãºnico mÃ³dulo privado y elegimos un tamaÃ±o de cachÃ© de 40MB para cada cliente. La base de datos OO7 se genera con mÃ³dulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos estÃ¡n agrupados en pÃ¡ginas de 8K, que tambiÃ©n son la unidad de transferencia en las solicitudes de recuperaciÃ³n. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro anÃ¡lisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idÃ©ntico a T1 excepto que modifica todas las partes atÃ³micas en un solo compuesto. Una transacciÃ³n Ãºnica incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo mÃ³dulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacciÃ³n, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de bÃºsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una cachÃ© de 50MB (de los cuales 6MB se utilizaron para el bÃºfer de objetos modificados), el cliente tenÃ­a una cachÃ© de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos bÃ¡sicos Esta secciÃ³n analiza el costo bÃ¡sico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 RedirecciÃ³n Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtenciÃ³n del servidor), el costo adicional de la redirecciÃ³n incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperaciÃ³n o confirmaciÃ³n del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmaciÃ³n y recuperaciÃ³n del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de Ã¡rea rÃ¡pida. Todos los nÃºmeros fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirecciÃ³n al cruzar el redireccionador no es muy alto, incluso en una red de Ã¡rea local. El costo de la confirmaciÃ³n aumenta con el nÃºmero de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperaciÃ³n no aumenta tanto porque la cachÃ© del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la cachÃ© del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperaciÃ³n entre pares, medimos la latencia de la recuperaciÃ³n entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperaciÃ³n entre pares, el costo de la redirecciÃ³n incluye, ademÃ¡s del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este Ãºltimo incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la pÃ¡gina solicitada. Medimos directamente el tiempo para copiar y desenrollar la pÃ¡gina solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperaciÃ³n de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador mÃ¡s un viaje de ida y vuelta a travÃ©s de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud mÃ¡s un viaje de ida y vuelta a travÃ©s de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando estÃ¡ bloqueado esperando una respuesta de bÃºsqueda o confirmaciÃ³n. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podrÃ­a ser mitigado por una implementaciÃ³n multi-hilo en un sistema con programaciÃ³n preemptiva. 6.3.2 VersiÃ³n de CachÃ© El commit en solitario permite que un cliente rÃ¡pido que modifica un objeto haga un commit de forma independiente a un compaÃ±ero lento. El mecanismo de confirmaciÃ³n Ãºnica introduce un procesamiento adicional en el servidor durante la validaciÃ³n de la transacciÃ³n, y un procesamiento adicional en el cliente durante la confirmaciÃ³n de la transacciÃ³n y en el momento del procesamiento de actualizaciÃ³n o invalidaciÃ³n. Los gastos generales del lado del servidor son mÃ­nimos y consisten en una actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina en el momento de la confirmaciÃ³n, y una comparaciÃ³n del nÃºmero de versiÃ³n en el momento de la validaciÃ³n de la transacciÃ³n. La cachÃ© de versiÃ³n tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacciÃ³n accede a objetos en mÃºltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor Ãºnico y, por lo tanto, el tiempo de confirmaciÃ³n adicional de la gestiÃ³n de la cachÃ© de versiones en el cliente no contribuye a los resultados presentados en la secciÃ³n a continuaciÃ³n. Para medir estos costos adicionales del lado del cliente en un sistema de mÃºltiples servidores, instrumentamos la implementaciÃ³n de la cachÃ© de versiones para ejecutarse con una traza de carga de trabajo que incluÃ­a invalidaciones reordenadas y cronometramos las operaciones bÃ¡sicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operaciÃ³n de bÃºsqueda de cachÃ© de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n en el momento de preparaciÃ³n de la solicitud de compromiso, y una operaciÃ³n de inserciÃ³n de cachÃ© de versiÃ³n para cada objeto actualizado por una transacciÃ³n en el momento de procesamiento de la respuesta de compromiso, pero solo si la pÃ¡gina actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmaciÃ³n se mantengan al mÃ­nimo, ya que el cliente estÃ¡ esperando de forma sÃ­ncrona la finalizaciÃ³n de la confirmaciÃ³n. Las mediciones muestran que en el peor de los casos, cuando llega un gran nÃºmero de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en pÃ¡ginas reordenadas, el costo de actualizar la cachÃ© de versiÃ³n es de 0.6 ms. El costo de tiempo de invalidaciÃ³n es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementaciÃ³n de la cachÃ© de versiones para reducir aÃºn mÃ¡s estos costos. 6.4 Rendimiento general Esta secciÃ³n examina las mejoras de rendimiento observadas por una aplicaciÃ³n que ejecuta el benchmark OO7 con un BuddyCache en una red de Ã¡rea amplia. 6.4.1 Fallos en frÃ­o Para evaluar las mejoras de rendimiento al evitar fallos en frÃ­o, comparamos el rendimiento de la cachÃ© en frÃ­o del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecuciÃ³n de los sistemas en el entorno de la red de Ã¡rea local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de Ã¡rea amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en cachÃ© frÃ­a. Los nÃºmeros fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frÃ­o solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frÃ­o solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparaciÃ³n con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cÃ¡lculos para el cliente, solicitudes de recuperaciÃ³n directa, recuperaciones de pares y solicitudes de confirmaciÃ³n. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperaciÃ³n entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperaciÃ³n del servidor para cada cliente individual disminuye porque, con mÃ¡s clientes accediendo a un mÃ³dulo compartido de tamaÃ±o fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperaciÃ³n de pares en comparaciÃ³n con la recuperaciÃ³n directa, pero este beneficio se ve contrarrestado por los tiempos de confirmaciÃ³n aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relaciÃ³n con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de cachÃ© 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT funciÃ³n de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias tÃ­picas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Sorprendentemente, los resultados analÃ­ticos predicen la mejora medida muy de cerca, aunque son ligeramente mÃ¡s altos que los valores empÃ­ricos. La razÃ³n principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidaciÃ³n evitados, comparamos el rendimiento de cachÃ© caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interÃ©s de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un Ãºnico cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compaÃ±eros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compaÃ±eros con un grupo que contiene un Ãºnico escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuraciÃ³n simple es suficiente para mostrar el impacto de las tÃ©cnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de cachÃ© caliente de OO7. Obtenemos los nÃºmeros ejecutando 2000 transacciones para filtrar los fallos en frÃ­o y luego medimos el tiempo de las siguientes 1000 transacciones. AquÃ­ nuevamente, los nÃºmeros reportados se derivan de los resultados del experimento de la red de Ã¡rea local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalizaciÃ³n en comparaciÃ³n con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparaciÃ³n con la Base. Este beneficio se debe a la actualizaciÃ³n entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperaciÃ³n entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperaciÃ³n local evitando el retraso de la recuperaciÃ³n desde el servidor. El Ãºltimo es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperaciÃ³n de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperaciÃ³n de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualizaciÃ³n de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relaciÃ³n con Base, y Buddy Writer y Base en relaciÃ³n con Base) en un experimento de cachÃ© activa en funciÃ³n del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualizaciÃ³n entre pares domina el gasto general en la configuraciÃ³n de Writer incluso en redes de baja latencia (la actualizaciÃ³n entre pares incurre en un gasto mÃ­nimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Como en experimentos de cachÃ© frÃ­a, aquÃ­ los resultados analÃ­ticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pÃ©rdida de invalidaciÃ³n es mÃ­nimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de cachÃ© frÃ­a). Como en el caso de cachÃ© frÃ­a, la razÃ³n por la que el modelo analÃ­tico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÃ“N Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en una red de Ã¡rea extensa debido a la alta latencia de red. Este artÃ­culo describe BuddyCache, una nueva tÃ©cnica de almacenamiento en cachÃ© cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para <br>aplicaciones colaborativas de alta consistencia</br> en entornos de red de alta latencia. La tÃ©cnica mejora el rendimiento y proporciona propiedades sÃ³lidas de correcciÃ³n y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirecciÃ³n para obtener objetos faltantes directamente de las cachÃ©s de los miembros del grupo, y para admitir la actualizaciÃ³n entre pares, una nueva tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirecciÃ³n puede interferir con la disponibilidad del objeto. Solo commit es una nueva tÃ©cnica de validaciÃ³n que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validaciÃ³n detallada utilizando informaciÃ³n de versiÃ³n de grano grueso econÃ³mica. Hemos diseÃ±ado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analÃ­ticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Las principales contribuciones del artÃ­culo son: 1. extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementaciÃ³n del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluaciÃ³n del rendimiento basada en anÃ¡lisis y mediciones de los costos y beneficios de las nuevas tÃ©cnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. TambiÃ©n agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios Ãºtiles que mejoraron este artÃ­culo. 9. REFERENCIAS [1] emulab.net, la InstalaciÃ³n de EmulaciÃ³n de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. ReconstrucciÃ³n de fragmentos: Proporcionando coherencia de cachÃ© global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre GestiÃ³n de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: ComputaciÃ³n en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de cachÃ© hÃ­bridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. RecuperaciÃ³n rÃ¡pida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de cachÃ© en la World Wide Web. En la 17Âª Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluaciÃ³n del rendimiento del sistema de gestiÃ³n de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una cachÃ© de objetos jerÃ¡rquica en Internet. En la Conferencia TÃ©cnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachÃ©s de Internet escalables. Informe TÃ©cnico CS-1997-18, Departamento de Ciencias de la ComputaciÃ³n, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: CachÃ© de proxy cooperativa en una red de Ã¡rea amplia. En el Tercer Taller Internacional de CachÃ© de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. CachÃ© web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2Âº Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. CachÃ© cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilaciÃ³n y en tiempo de ejecuciÃ³n para una memoria compartida distribuida eficiente. En Actas de IEEE, EdiciÃ³n Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la cachÃ©: un protocolo de intercambio de cachÃ© web escalable de Ã¡rea amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. ImplementaciÃ³n de GestiÃ³n Global de Memoria en un ClÃºster de Estaciones de Trabajo. Actas del 15Âº Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: DiseÃ±o, ImplementaciÃ³n y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de cachÃ© transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, pÃ¡ginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. GestiÃ³n global de memoria para arquitecturas de sistemas de gestiÃ³n de bases de datos cliente-servidor. En Actas del 19Âº Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El BÃºfer de Objeto Modificado: Una TÃ©cnica de GestiÃ³n de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto TecnolÃ³gico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. GestiÃ³n de documentos replicados en un sistema de comunicaciÃ³n grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13Âª Conferencia Europea sobre ProgramaciÃ³n Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18Âº Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. ReplicaciÃ³n con marca de vista: un nuevo mÃ©todo de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de ComputaciÃ³n Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalaciÃ³n eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de MultidifusiÃ³n a Nivel de AplicaciÃ³n. En el 3er Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de cachÃ© cooperativa utilizando pistas. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en CachÃ© Global. Informe tÃ©cnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del CachÃ© de Proxies Web Cooperativos. En el 17Âº Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerÃ¡rquica de cachÃ© en una WAN. En el Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. ComparticiÃ³n adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÃ‰NDICE Este apÃ©ndice describe el protocolo de conmutaciÃ³n por error de BuddyCache. Para dar cabida a clientes heterogÃ©neos, incluidos los dispositivos portÃ¡tiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseÃ±o de BuddyCache asume que las cachÃ©s del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresÃ­a detecta el fallo de un cliente o un redireccionador intercambiando mensajes periÃ³dicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutaciÃ³n por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuraciÃ³n y reinicia el protocolo. El protocolo de reconfiguraciÃ³n del grupo es similar al presentado en [25]. AquÃ­ describimos cÃ³mo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de pÃ¡ginas redireccionadas y el reenvÃ­o de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachÃ©s. En caso de un fallo del cliente, el failover elimina las pÃ¡ginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmaciÃ³n, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en cachÃ© las pÃ¡ginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutaciÃ³n por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de pÃ¡ginas utilizando un protocolo similar al descrito en [6]. El redireccionador reciÃ©n reiniciado solicita a los miembros activos del grupo la lista de pÃ¡ginas que estÃ¡n almacenando en cachÃ© y el estado de estas pÃ¡ginas, es decir, si las pÃ¡ginas estÃ¡n completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperaciÃ³n perdida expirarÃ¡ en el cliente y serÃ¡ retransmitida. Una transacciÃ³n que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma despuÃ©s del cambio se trata como una transacciÃ³n regular; una transacciÃ³n que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciarÃ¡ la transacciÃ³n y la solicitud de confirmaciÃ³n serÃ¡ retransmitida despuÃ©s del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caÃ­do podrÃ­an evitar la recolecciÃ³n de basura de las invalidaciones pendientes en los servidores o la cachÃ© virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los nÃºmeros de versiÃ³n Ãºnicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validaciÃ³n de transacciones depende del protocolo de coherencia de cachÃ© para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutaciÃ³n por error de BuddyCache no compromete la correcciÃ³n del procedimiento de validaciÃ³n. Recuerda que la validaciÃ³n de transacciones de BuddyCache utiliza dos mecanismos complementarios, nÃºmeros de versiÃ³n de pÃ¡gina y confirmaciones de invalidaciÃ³n de los clientes, para verificar que una transacciÃ³n ha leÃ­do datos actualizados. La propagaciÃ³n de la confirmaciÃ³n de invalidaciÃ³n (y actualizaciÃ³n) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmaciÃ³n de una modificaciÃ³n (invalidaciÃ³n o actualizaciÃ³n) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en cachÃ© el objeto o bien ha instalado el valor mÃ¡s reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmaciÃ³n de un cliente para una transacciÃ³n T que lee un objeto o despuÃ©s de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidaciÃ³n no confirmada para o pendiente para este grupo, la versiÃ³n del objeto leÃ­da por la transacciÃ³n T estÃ¡ actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validaciÃ³n utilizando nÃºmeros de versiÃ³n. El registro de confirmaciÃ³n de transacciÃ³n contiene un nÃºmero de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n. El protocolo de nÃºmero de versiÃ³n mantiene la invariante V P que garantiza que el valor del objeto o leÃ­do por la transacciÃ³n corresponda al nÃºmero de versiÃ³n mÃ¡s alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificaciÃ³n anterior despuÃ©s de haber recibido una modificaciÃ³n posterior. La retransmisiÃ³n de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validaciÃ³n verifica que el nÃºmero de versiÃ³n en el registro de confirmaciÃ³n coincida con el nÃºmero de versiÃ³n en la invalidaciÃ³n pendiente no reconocida. Es fÃ¡cil ver que, dado que esta comprobaciÃ³n es una comprobaciÃ³n cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutaciÃ³n por error aÃºn no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    "alta consistencia",
                    "aplicaciones colaborativas de alta consistencia"
                ]
            ]
        },
        "wide-area network": {
            "translated_key": "redes de Ã¡rea amplia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in <br>wide-area network</br> environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in <br>wide-area network</br> environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of <br>wide-area network</br> interactions to maintain data consistency is the main cost limiting the performance and therefore, in <br>wide-area network</br> environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in <br>wide-area network</br> environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a <br>wide-area network</br> would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in <br>wide-area network</br> environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in <br>wide-area network</br> because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a <br>wide-area network</br>.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "Nevertheless, distributed applications may perform poorly in <br>wide-area network</br> environments.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in <br>wide-area network</br> environment.",
                "For transactional storage systems, the high cost of <br>wide-area network</br> interactions to maintain data consistency is the main cost limiting the performance and therefore, in <br>wide-area network</br> environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in <br>wide-area network</br> environment.",
                "Update-based protocols that propagate updates to low-interest objects in a <br>wide-area network</br> would be wasteful."
            ],
            "translated_annotated_samples": [
                "Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de <br>redes de Ã¡rea amplia</br>.",
                "BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de <br>red de Ã¡rea amplia</br>.",
                "Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en <br>redes de Ã¡rea amplia</br> para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de <br>redes de Ã¡rea amplia</br>, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil.",
                "La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de <br>red de Ã¡rea amplia</br>.",
                "Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una <br>red de Ã¡rea amplia</br> serÃ­an derrochadores."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de <br>redes de Ã¡rea amplia</br>. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de <br>red de Ã¡rea amplia</br>. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en <br>redes de Ã¡rea amplia</br> para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de <br>redes de Ã¡rea amplia</br>, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil. Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en cachÃ© web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos. Sin embargo, las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica. La interacciÃ³n con el servidor aumenta la latencia. La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia. Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n. Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo. BuddyCache presenta dos desafÃ­os tÃ©cnicos principales. Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©. El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de almacenamiento en cachÃ© web cooperativos [11]. Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo. BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos. Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica. Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad? DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red. Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia. El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida. Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache. Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n. Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos. Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de <br>red de Ã¡rea amplia</br>. Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad. Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un Ãºnico servidor. Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web. El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en cachÃ© transaccional [19]. La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una transacciÃ³n, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador. El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado. AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©. Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina). La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente. El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento. A continuaciÃ³n, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene. La transacciÃ³n puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor. Sin embargo, antes de que una transacciÃ³n se confirme, debe ser validada; el servidor debe asegurarse de que la transacciÃ³n validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada. Si la validaciÃ³n falla, la transacciÃ³n se cancela. Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de bÃºsqueda de pares envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la cachÃ© y envÃ­an confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la cachÃ© del cliente, la confirmaciÃ³n de invalidaciÃ³n indica al servidor que un cliente sin invalidaciones pendientes ha leÃ­do objetos actualizados. Una invalidaciÃ³n no reconocida indica que un objeto obsoleto puede haber sido accedido en la cachÃ© del cliente. El procedimiento de validaciÃ³n en el servidor aborta una transacciÃ³n del cliente si este lee un objeto mientras hay una invalidaciÃ³n pendiente. El mecanismo de invalidaciÃ³n reconocido admite coherencia de cachÃ© a nivel de objeto sin directorios basados en objetos o nÃºmeros de versiÃ³n por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeÃ±os, ya que los objetos tÃ­picos son pequeÃ±os. Un objetivo importante del diseÃ±o de BuddyCache es mantener este beneficio. Dado que en BuddyCache una pÃ¡gina puede ser recuperada en una cachÃ© de cliente sin intervenciÃ³n del servidor (como se ilustra en la figura 2), los directorios de cachÃ© en los servidores llevan un registro de las pÃ¡ginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las pÃ¡ginas almacenadas en cachÃ© en cada cliente de un grupo. Los servidores envÃ­an al redireccionador invalidaciones para las pÃ¡ginas almacenadas en cachÃ© en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. ActualizaciÃ³n de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en cachÃ© por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interÃ©s potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de cachÃ© y las actualizaciones de cachÃ©. Los estudios de coherencia de cachÃ© en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualizaciÃ³n y la invalidaciÃ³n. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. AlmacÃ©n x 6. ActualizaciÃ³n x 3. CompromÃ©tete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares estÃ¡n fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeÃ±as, agrupadas y se envÃ­an junto con otros mensajes. AdemÃ¡s, los protocolos de invalidaciÃ³n se ajustan a la tendencia actual de hardware de aumentar los tamaÃ±os de cachÃ© del cliente. Es probable que las cachÃ©s mÃ¡s grandes contengan mucha mÃ¡s informaciÃ³n de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una <br>red de Ã¡rea amplia</br> serÃ­an derrochadores. ",
            "candidates": [],
            "error": [
                [
                    "redes de Ã¡rea amplia",
                    "red de Ã¡rea amplia",
                    "redes de Ã¡rea amplia",
                    "redes de Ã¡rea amplia",
                    "red de Ã¡rea amplia",
                    "red de Ã¡rea amplia"
                ]
            ]
        },
        "cooperative web caching": {
            "translated_key": "almacenamiento en cachÃ© web cooperativo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "<br>cooperative web caching</br> [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, <br>cooperative web caching</br> techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in <br>cooperative web caching</br> systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "<br>cooperative web caching</br> techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "<br>cooperative web caching</br> [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "However, <br>cooperative web caching</br> techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "BuddyCache uses a redirection approach similar to one used in <br>cooperative web caching</br> systems [11].",
                "<br>cooperative web caching</br> techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes."
            ],
            "translated_annotated_samples": [
                "El <br>almacenamiento en cachÃ© web cooperativo</br> [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor.",
                "Sin embargo, las tÃ©cnicas de <br>almacenamiento en cachÃ© web cooperativo</br> no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina.",
                "BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de <br>almacenamiento en cachÃ© web cooperativos</br> [11].",
                "Las tÃ©cnicas de <br>almacenamiento en cachÃ© web cooperativo</br>, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de Ã¡rea amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de Ã¡rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil. Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El <br>almacenamiento en cachÃ© web cooperativo</br> [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos. Sin embargo, las tÃ©cnicas de <br>almacenamiento en cachÃ© web cooperativo</br> no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica. La interacciÃ³n con el servidor aumenta la latencia. La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia. Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n. Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo. BuddyCache presenta dos desafÃ­os tÃ©cnicos principales. Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©. El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de <br>almacenamiento en cachÃ© web cooperativos</br> [11]. Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo. BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos. Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica. Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad? DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red. Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia. El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida. Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las tÃ©cnicas de <br>almacenamiento en cachÃ© web cooperativo</br>, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache. Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n. Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos. Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de Ã¡rea amplia. Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad. Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un Ãºnico servidor. Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web. El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en cachÃ© transaccional [19]. La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una transacciÃ³n, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador. El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado. AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©. Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina). La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente. El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento. A continuaciÃ³n, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene. La transacciÃ³n puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor. Sin embargo, antes de que una transacciÃ³n se confirme, debe ser validada; el servidor debe asegurarse de que la transacciÃ³n validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada. Si la validaciÃ³n falla, la transacciÃ³n se cancela. Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de bÃºsqueda de pares envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la cachÃ© y envÃ­an confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la cachÃ© del cliente, la confirmaciÃ³n de invalidaciÃ³n indica al servidor que un cliente sin invalidaciones pendientes ha leÃ­do objetos actualizados. Una invalidaciÃ³n no reconocida indica que un objeto obsoleto puede haber sido accedido en la cachÃ© del cliente. El procedimiento de validaciÃ³n en el servidor aborta una transacciÃ³n del cliente si este lee un objeto mientras hay una invalidaciÃ³n pendiente. El mecanismo de invalidaciÃ³n reconocido admite coherencia de cachÃ© a nivel de objeto sin directorios basados en objetos o nÃºmeros de versiÃ³n por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeÃ±os, ya que los objetos tÃ­picos son pequeÃ±os. Un objetivo importante del diseÃ±o de BuddyCache es mantener este beneficio. Dado que en BuddyCache una pÃ¡gina puede ser recuperada en una cachÃ© de cliente sin intervenciÃ³n del servidor (como se ilustra en la figura 2), los directorios de cachÃ© en los servidores llevan un registro de las pÃ¡ginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las pÃ¡ginas almacenadas en cachÃ© en cada cliente de un grupo. Los servidores envÃ­an al redireccionador invalidaciones para las pÃ¡ginas almacenadas en cachÃ© en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. ActualizaciÃ³n de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en cachÃ© por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interÃ©s potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de cachÃ© y las actualizaciones de cachÃ©. Los estudios de coherencia de cachÃ© en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualizaciÃ³n y la invalidaciÃ³n. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. AlmacÃ©n x 6. ActualizaciÃ³n x 3. CompromÃ©tete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares estÃ¡n fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeÃ±as, agrupadas y se envÃ­an junto con otros mensajes. AdemÃ¡s, los protocolos de invalidaciÃ³n se ajustan a la tendencia actual de hardware de aumentar los tamaÃ±os de cachÃ© del cliente. Es probable que las cachÃ©s mÃ¡s grandes contengan mucha mÃ¡s informaciÃ³n de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una red de Ã¡rea amplia serÃ­an derrochadores. Sin embargo, los protocolos de coherencia basados en invalidaciÃ³n pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interÃ©s para otro miembro del grupo. Con un protocolo basado en invalidaciÃ³n, la actualizaciÃ³n de un miembro invalidarÃ¡ la copia en cachÃ© de otro miembro, lo que provocarÃ¡ que este Ãºltimo realice una recuperaciÃ³n de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualizaciÃ³n e invalidaciÃ³n en entornos de redes de Ã¡rea amplia. Evita la penalizaciÃ³n de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalizaciÃ³n de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusiÃ³n localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en cachÃ© anteriores. La actualizaciÃ³n entre pares funciona de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que la transacciÃ³n se confirma, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n, y tambiÃ©n propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmaciÃ³n. 3.3 ConfirmaciÃ³n individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminaciÃ³n de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en cachÃ© transaccional, ya que un cliente que es lento para reconocer una invalidaciÃ³n o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacciÃ³n. Por ejemplo, un ingeniero que realiza una revisiÃ³n repetida al mismo objeto de diseÃ±o compartido (y por lo tanto tiene la Ãºltima versiÃ³n del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situaciÃ³n representada en la figura 4 donde el Cliente1 realiza una transacciÃ³n T que lee la Ãºltima versiÃ³n de un objeto x en la pÃ¡gina P recientemente modificada por el Cliente1. Si la solicitud de confirmaciÃ³n para T llega al servidor antes de que la confirmaciÃ³n colectiva de Cliente2 por la Ãºltima modificaciÃ³n de x llegue al servidor, el procedimiento de validaciÃ³n de OCC considera que x estÃ¡ obsoleto y aborta T (porque, como se explicÃ³ anteriormente, una invalidaciÃ³n no reconocida por un cliente actÃºa como indicaciÃ³n para el servidor de que el valor del objeto en cachÃ© estÃ¡ obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la correcciÃ³n del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asÃ­ncronas son una parte importante de la razÃ³n por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasiÃ³n de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envÃ­an y procesan de forma asÃ­ncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devoluciÃ³n de llamada jerÃ¡rquica [32], pero la naturaleza asincrÃ³nica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrÃ³nicas. El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a un cliente con objetos actualizados confirmar una transacciÃ³n incluso si la confirmaciÃ³n del grupo se retrasa debido a pares lentos o caÃ­dos. El protocolo requiere que los clientes incluyan informaciÃ³n adicional con los conjuntos de lectura de transacciones en el mensaje de confirmaciÃ³n, para indicar al servidor que los objetos leÃ­dos por la transacciÃ³n estÃ¡n actualizados. Los nÃºmeros de versiÃ³n de los objetos podrÃ­an proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionÃ³ anteriormente, mantener nÃºmeros de versiÃ³n por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaÃ±o de directorio) en todo el sistema de objetos cuando los objetos son pequeÃ±os [23]. En cambio, solo utiliza nÃºmeros de versiÃ³n de pÃ¡gina de grano grueso para identificar versiones de objetos de grano fino. El nÃºmero de versiÃ³n de una pÃ¡gina se incrementa en un servidor cuando una transacciÃ³n que modifica objetos en la pÃ¡gina se confirma. Las actualizaciones realizadas por una Ãºnica transacciÃ³n y las invalidaciones correspondientes son identificadas de manera Ãºnica por el nÃºmero de versiÃ³n de la pÃ¡gina modificada. Los nÃºmeros de versiÃ³n de la pÃ¡gina se propagan a los clientes en respuestas de recuperaciÃ³n, respuestas de confirmaciÃ³n y con invalidaciones, y los clientes incluyen los nÃºmeros de versiÃ³n de la pÃ¡gina en las solicitudes de confirmaciÃ³n enviadas a los servidores. Si una transacciÃ³n falla en la validaciÃ³n debido a la falta de reconocimiento de grupo, el servidor verifica los nÃºmeros de versiÃ³n de pÃ¡gina de los objetos en el conjunto de lectura de la transacciÃ³n y permite que la transacciÃ³n se confirme si el cliente ha leÃ­do desde la Ãºltima versiÃ³n de la pÃ¡gina. Los nÃºmeros de versiÃ³n de la pÃ¡gina permiten confirmaciones independientes, pero las verificaciones de versiÃ³n de pÃ¡gina solo detectan conflictos a nivel de pÃ¡gina. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La secciÃ³n 4 describe los detalles de la implementaciÃ³n del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 ConfiguraciÃ³n de Grupo La arquitectura BuddyCache admite mÃºltiples grupos de pares concurrentes. Potencialmente, puede ser mÃ¡s rÃ¡pido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podrÃ­a ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en cachÃ© de pares de mÃºltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en cachÃ© web, simplemente aumentar la poblaciÃ³n de clientes en una cachÃ© proxy a menudo aumenta la tasa general de aciertos en la cachÃ© [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacciÃ³n explÃ­cita entre clientes y la colaboraciÃ³n, lo que sugiere que es poco probable que ocurra la recuperaciÃ³n entre grupos. AdemÃ¡s, las mediciones de sistemas de almacenamiento en cachÃ© web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexiÃ³n de red entre los grupos de pares sea muy rÃ¡pida. Estamos principalmente interesados en entornos donde compaÃ±eros que colaboran estrechamente tienen una conectividad rÃ¡pida a corta distancia, pero la conexiÃ³n entre grupos de compaÃ±eros puede ser lenta. Como resultado, decidimos que el soporte para la recuperaciÃ³n entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compaÃ±eros con recursos heterogÃ©neos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compaÃ±eros o, cuando estÃ© disponible, en un nodo separado dentro de la infraestructura del sitio. AdemÃ¡s, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una cachÃ© de pares en espera para recibir pÃ¡ginas recuperadas por otros pares, emulando una cachÃ© central algo similar a una cachÃ© de proxy web regional. Desde el punto de vista del protocolo de coherencia de cachÃ© BuddyCache, sin embargo, un cachÃ© de compaÃ±ero en espera es equivalente a un cachÃ© de compaÃ±ero regular y, por lo tanto, no consideramos este caso por separado en la discusiÃ³n de este documento. 4. En esta secciÃ³n proporcionamos los detalles de la implementaciÃ³n de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en cachÃ© de estos objetos. Las aplicaciones se ejecutan en los clientes e interactÃºan con el sistema realizando llamadas a mÃ©todos de objetos en cachÃ©. Todas las llamadas a mÃ©todos ocurren dentro de transacciones atÃ³micas. Los clientes se comunican con los servidores para obtener pÃ¡ginas o realizar una transacciÃ³n. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volÃ¡til. El disco estÃ¡ organizado como una colecciÃ³n de pÃ¡ginas que son las unidades de acceso al disco. El registro estable guarda la informaciÃ³n de confirmaciÃ³n y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de cachÃ© y una cachÃ© de objetos modificados recuperable llamada MOB. El directorio lleva un registro de quÃ© pÃ¡ginas estÃ¡n almacenadas en cachÃ© por quÃ© clientes. El MOB contiene objetos recientemente modificados que aÃºn no han sido escritos de vuelta en sus pÃ¡ginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de cachÃ© base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la SecciÃ³n 3.1. Proporcionamos algunos de los detalles relevantes de la implementaciÃ³n del protocolo OCC. El cliente lleva un registro de los objetos que son leÃ­dos y modificados por su transacciÃ³n; envÃ­a esta informaciÃ³n, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacciÃ³n. Los servidores determinan si la confirmaciÃ³n es posible, utilizando un protocolo de confirmaciÃ³n de dos fases si la transacciÃ³n utilizÃ³ objetos en mÃºltiples servidores. Si la transacciÃ³n se lleva a cabo, las nuevas copias de los objetos modificados se aÃ±aden al registro y tambiÃ©n se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperaciÃ³n escaneando el registro. Dado que los objetos no estÃ¡n bloqueados antes de ser utilizados, una confirmaciÃ³n de transacciÃ³n puede hacer que las cachÃ©s contengan objetos obsoletos. Los servidores abortarÃ¡n una transacciÃ³n que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviÃ¡ndoles mensajes de invalidaciÃ³n; un servidor utiliza su directorio y la informaciÃ³n sobre la transacciÃ³n de confirmaciÃ³n para determinar quÃ© mensajes de invalidaciÃ³n enviar. Los mensajes de invalidaciÃ³n son pequeÃ±os porque simplemente identifican objetos obsoletos. AdemÃ¡s, se envÃ­an en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidaciÃ³n, elimina los objetos obsoletos de su cachÃ© y aborta la transacciÃ³n actual si los utilizÃ³. El cliente sigue conservando pÃ¡ginas que contienen objetos invalidados; estas pÃ¡ginas ahora estÃ¡n incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidaciÃ³n de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener pÃ¡ginas incompletas en la cachÃ© del cliente significa que el falso intercambio no conduce a fallos innecesarios en la cachÃ©. Los clientes reconocen las invalidaciones para indicar la eliminaciÃ³n de datos obsoletos, como se explica en la SecciÃ³n 3.1. Los mensajes de invalidaciÃ³n evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo asÃ­ el desperdicio de trabajo y trasladando la detecciÃ³n de abortos de los servidores a los clientes. Cuando una transacciÃ³n se aborta, su cliente restaura las copias en cachÃ© de los objetos modificados al estado que tenÃ­an antes de que la transacciÃ³n comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacciÃ³n. 4.3 RedirecciÃ³n El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de pÃ¡ginas disponibles en el grupo de pares y proporciona una redirecciÃ³n rÃ¡pida y centralizada de recuperaciÃ³n (ver figura 2) entre las cachÃ©s de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan pÃ¡ginas u objetos al incluir esa informaciÃ³n en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la cachÃ© de grupo, el redireccionador realiza un seguimiento del estado de las pÃ¡ginas. Una pÃ¡gina en cachÃ© estÃ¡ completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una pÃ¡gina estÃ¡n marcados como invÃ¡lidos. Solo se utilizan pÃ¡ginas completas por el proceso de recuperaciÃ³n de pares. El protocolo para mantener el estado de la pÃ¡gina cuando las pÃ¡ginas son actualizadas e invalidadas se describe en la SecciÃ³n 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una pÃ¡gina solicitada completa no estÃ¡ disponible en el grupo de pares o si un par necesita confirmar una transacciÃ³n, el redireccionador actÃºa como un proxy de servidor: reenvÃ­a la solicitud al servidor y luego reenvÃ­a la respuesta de vuelta al cliente. AdemÃ¡s, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualizaciÃ³n o informaciÃ³n de invalidaciÃ³n a los clientes que tienen en cachÃ© la pÃ¡gina modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la cachÃ© de grupo de pares combinada estÃ¡ desempeÃ±ando el papel de una Ãºnica cachÃ© de cliente en el sistema base. 4.4 ActualizaciÃ³n de pares La actualizaciÃ³n de pares se implementa de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que una transacciÃ³n se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacciÃ³n generan invalidaciones de objetos para cada grupo de cachÃ© que almacena pÃ¡ginas que contienen los objetos modificados (incluido el grupo que realiza la confirmaciÃ³n). Las invalidaciones se envÃ­an de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en cachÃ© los objetos modificados se deshagan de los datos obsoletos. En grupos de cachÃ© distintos al grupo de confirmaciÃ³n, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas, recopilan las confirmaciones de los clientes y, despuÃ©s de completar la recopilaciÃ³n, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacciÃ³n, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envÃ­an a los clientes que almacenan en cachÃ© esas pÃ¡ginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmaciÃ³n colectiva se propaga al servidor. Una invalidaciÃ³n hace que una pÃ¡gina en cachÃ© no estÃ© disponible para la recuperaciÃ³n de pares, cambiando el estado de una pÃ¡gina completa p a incompleta. Por el contrario, una actualizaciÃ³n de una pÃ¡gina completa conserva el estado completo de la pÃ¡gina. Como se muestra en los estudios de la reconstrucciÃ³n de fragmentos 31 [2], esta propagaciÃ³n de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma pÃ¡gina, la pÃ¡gina conserva su estado completo y permanece disponible para la recuperaciÃ³n entre pares. Por lo tanto, el efecto de la actualizaciÃ³n de pares es similar a la reconstrucciÃ³n de fragmentos ansiosa [2]. TambiÃ©n hemos considerado la posibilidad de permitir que un compaÃ±ero recupere una pÃ¡gina incompleta (con objetos invÃ¡lidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos invÃ¡lidos. 4.5 Vcache El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo mÃ¡s lentos (o fallidos). Como se explica en la SecciÃ³n 3.3, el protocolo de commit Ãºnico permite que una transacciÃ³n T pase la validaciÃ³n si la informaciÃ³n adicional de coherencia proporcionada por el cliente indica que la transacciÃ³n T ha leÃ­do objetos actualizados. Los clientes utilizan los nÃºmeros de versiÃ³n de la pÃ¡gina para proporcionar esta informaciÃ³n adicional de coherencia. Es decir, un cliente incluye el nÃºmero de versiÃ³n de la pÃ¡gina correspondiente a cada objeto en el conjunto de objetos leÃ­dos enviado en la solicitud de confirmaciÃ³n al servidor. Dado que a cada actualizaciÃ³n de objeto comprometido le corresponde un nÃºmero de versiÃ³n de pÃ¡gina Ãºnico, el nÃºmero de versiÃ³n de pÃ¡gina asociado con un objeto permite que el procedimiento de validaciÃ³n en el servidor verifique si la transacciÃ³n del cliente ha leÃ­do objetos actualizados. El uso de versiones de pÃ¡gina de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeÃ±os, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en cachÃ© a la versiÃ³n de pÃ¡gina identificadora (ObjectToVersion). El principal problema de implementaciÃ³n se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian nÃºmeros de versiÃ³n de pÃ¡gina con las invalidaciones. En el momento de la validaciÃ³n, si hay una invalidaciÃ³n no reconocida pendiente para un objeto x leÃ­do por una transacciÃ³n T, el procedimiento de validaciÃ³n verifica si el nÃºmero de versiÃ³n de x en el conjunto de lectura de Ts coincide con el nÃºmero de versiÃ³n de la invalidaciÃ³n pendiente mÃ¡s alta para x, en cuyo caso el valor del objeto estÃ¡ actualizado, de lo contrario, T falla en la validaciÃ³n. Observamos nuevamente que las verificaciones basadas en el nÃºmero de versiÃ³n de la pÃ¡gina y las verificaciones basadas en el reconocimiento de invalidaciÃ³n son complementarias en la validaciÃ³n de confirmaciÃ³n individual y ambas son necesarias. La verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina permite que la validaciÃ³n avance antes de que lleguen las confirmaciones de invalidaciÃ³n, pero por sÃ­ sola, una verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina detecta conflictos a nivel de pÃ¡gina y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cÃ³mo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un nÃºmero de versiÃ³n de la pÃ¡gina para cada pÃ¡gina en cachÃ©. El nÃºmero de versiÃ³n satisface la siguiente invariante V P sobre el estado de los objetos en una pÃ¡gina: si una pÃ¡gina en cachÃ© P tiene un nÃºmero de versiÃ³n v, entonces el valor de un objeto o en la pÃ¡gina en cachÃ© P es invÃ¡lido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacciÃ³n que estableciÃ³ el nÃºmero de versiÃ³n de P en v. Los nuevos valores de objetos y los nuevos nÃºmeros de versiÃ³n de pÃ¡gina llegan cuando un cliente obtiene una pÃ¡gina o cuando llega una respuesta de confirmaciÃ³n o invalidaciones para esta pÃ¡gina. Los nuevos valores del objeto modifican la pÃ¡gina y, por lo tanto, el nÃºmero de versiÃ³n de la pÃ¡gina necesita ser actualizado para mantener la invariante V P. Un nÃºmero de versiÃ³n de pÃ¡gina que llega cuando un cliente obtiene una pÃ¡gina, reemplaza la VersiÃ³n del Objeto x 8 Servidor de RedirecciÃ³n 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el nÃºmero de versiÃ³n de la pÃ¡gina para esta pÃ¡gina. Tal actualizaciÃ³n preserva el invariante V P. De manera similar, un nÃºmero de versiÃ³n de pÃ¡gina en secuencia que llega al cliente en un mensaje de confirmaciÃ³n o invalidaciÃ³n avanza el nÃºmero de versiÃ³n para toda la pÃ¡gina en cachÃ©, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus nÃºmeros de versiÃ³n de pÃ¡gina correspondientes tambiÃ©n pueden llegar al cliente fuera de secuencia, en cuyo caso la actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina podrÃ­a violar V P. Por ejemplo, una respuesta de confirmaciÃ³n para una transacciÃ³n que actualiza el objeto x en la pÃ¡gina P en el servidor S1, y el objeto y en la pÃ¡gina Q en el servidor S2, puede entregar un nuevo nÃºmero de versiÃ³n para P desde el coordinador de transacciones S1 antes de que llegue una invalidaciÃ³n generada para una transacciÃ³n anterior que ha modificado el objeto r en la pÃ¡gina P desde S1 (como se muestra en la figura 5). El protocolo de actualizaciÃ³n de cachÃ© garantiza que el valor de cualquier objeto o en una pÃ¡gina en cachÃ© P refleje la actualizaciÃ³n o invalidaciÃ³n con el nÃºmero de versiÃ³n observado mÃ¡s alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de nÃºmeros de versiÃ³n de pÃ¡gina, el cliente gestiona una pequeÃ±a cachÃ© de nÃºmeros de versiÃ³n vcache que mantiene el mapeo de un objeto a su nÃºmero de versiÃ³n de pÃ¡gina correspondiente para todas las actualizaciones de nÃºmeros de versiÃ³n reordenadas hasta que se ensamble una secuencia completa de nÃºmeros de versiÃ³n de pÃ¡gina. Cuando llegan los nÃºmeros de versiÃ³n faltantes para la pÃ¡gina y completan una secuencia, el nÃºmero de versiÃ³n de toda la pÃ¡gina se avanza. El mapeo de ObjectToVersion, incluyendo los nÃºmeros de versiÃ³n de vcache y pÃ¡gina, se utiliza en el momento de la confirmaciÃ³n de la transacciÃ³n para proporcionar nÃºmeros de versiÃ³n para el conjunto de objetos leÃ­dos de la siguiente manera. Si el objeto leÃ­do tiene una entrada en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n mÃ¡s alto en la vcache para este objeto. Si el objeto no estÃ¡ presente en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n de la pÃ¡gina en cachÃ© que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la cachÃ© del cliente, incluyendo los nÃºmeros de versiÃ³n de las pÃ¡ginas y la vcache. El cliente puede limitar el tamaÃ±o de la cachÃ© virtual segÃºn sea necesario, ya que volver a cargar una pÃ¡gina elimina todos los nÃºmeros de versiÃ³n de pÃ¡gina reordenados de la cachÃ© virtual. Sin embargo, esperamos que la reorganizaciÃ³n de nÃºmeros de versiÃ³n sea poco comÃºn y, por lo tanto, esperamos que la vcache sea muy pequeÃ±a. 5. Un grupo de clientes contiene mÃºltiples nodos de cliente y un objeto de pÃ¡gina de versiÃ³n redi32 VCache Cliente CachÃ© Cliente PÃ¡gina CachÃ© Figura 6: Mapa de Objeto a VersiÃ³n con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutaciÃ³n por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. AdemÃ¡s, el fallo del redireccionador deberÃ­a permitir que los clientes no afectados mantengan sus cachÃ©s intactas. Hemos diseÃ±ado un protocolo de conmutaciÃ³n por error para BuddyCache pero aÃºn no lo hemos implementado. El apÃ©ndice describe el protocolo. 6. La redirecciÃ³n de BuddyCache en la evaluaciÃ³n de rendimiento respalda los beneficios de evitar la comunicaciÃ³n con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes. Â¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 AnÃ¡lisis Los beneficios de rendimiento de la recuperaciÃ³n entre pares y la actualizaciÃ³n entre pares se deben a la evitaciÃ³n de interacciones con el servidor. Esta secciÃ³n presenta un modelo de rendimiento analÃ­tico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la cachÃ© del cliente. Estos pueden ser fallos frÃ­os, fallos de invalidaciÃ³n y fallos de capacidad. Nuestro anÃ¡lisis se centra en los fallos por frÃ­o y los fallos por invalidaciÃ³n, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frÃ­o. AdemÃ¡s, las tendencias tecnolÃ³gicas indican que la capacidad de memoria y almacenamiento seguirÃ¡ creciendo y, por lo tanto, es probable que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ©. Los fallos de cachÃ© del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuraciÃ³n de cachÃ©. Nuestro anÃ¡lisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validaciÃ³n. Para estudiar el beneficio de evitar fallos en frÃ­o, consideramos el rendimiento de la cachÃ© en frÃ­o en una carga de trabajo de solo lectura (sin fallos de invalidaciÃ³n). Esperamos que la recuperaciÃ³n entre pares mejore el costo de latencia para las solicitudes de cachÃ© frÃ­a del cliente al recuperar objetos de la cachÃ© cercana. Evaluamos cÃ³mo el costo de redirecciÃ³n afecta este beneficio al comparar y analizar el rendimiento de una aplicaciÃ³n que se ejecuta en un sistema de almacenamiento con BuddyCache y sin Ã©l (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidaciÃ³n, consideramos el rendimiento de la cachÃ© caliente en una carga de trabajo con modificaciones (sin fallos en frÃ­o). En las cachÃ©s calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualizaciÃ³n entre pares permite que un cliente acceda a un objeto modificado por un compaÃ±ero colaborador cercano sin el retraso impuesto por los protocolos de invalidaciÃ³n Ãºnicamente. En grupos donde los compaÃ±eros comparten un interÃ©s de solo lectura en los objetos modificados, la recuperaciÃ³n entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compaÃ±ero colaborador lo tenga, lo que evita el retraso de la recuperaciÃ³n del servidor sin el alto costo impuesto por los protocolos de solo actualizaciÃ³n. Las tendencias tecnolÃ³gicas indican que ambos beneficios seguirÃ¡n siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualizaciÃ³n Ãºnicamente. Sin embargo, la tendencia hacia cachÃ©s cada vez mÃ¡s grandes, que se actualizan cuando los objetos en cachÃ© son modificados, hace que los protocolos basados en invalidaciÃ³n sean mÃ¡s atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicaciÃ³n que se ejecuta sin BuddyCache y una aplicaciÃ³n que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compaÃ±ero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compaÃ±ero fuera del grupo. La actualizaciÃ³n entre pares tambiÃ©n puede evitar fallos de invalidaciÃ³n debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma pÃ¡gina de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseÃ±o del objeto, y tambiÃ©n porque este beneficio se puede derivar dado el Ã­ndice de aciertos en cachÃ© y la contenciÃ³n de la carga de trabajo. 6.1.1 El Modelo El modelo considera cÃ³mo el tiempo para completar una ejecuciÃ³n con y sin BuddyCache se ve afectado por los fallos de invalidaciÃ³n y los fallos en frÃ­o. Considerando k clientes ejecutÃ¡ndose concurrentemente accediendo de manera uniforme a un conjunto compartido de N pÃ¡ginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacciÃ³n y realizar cÃ¡lculos en una transacciÃ³n, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin Ã©l (Base). Para simplificar, nuestro modelo asume que los tiempos de bÃºsqueda y confirmaciÃ³n son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del nÃºmero total de clientes en el sistema. El nÃºmero de fallos evitados por la recuperaciÃ³n entre pares depende de k, el nÃºmero de clientes en la BuddyCache, y del interÃ©s conjunto de los clientes en los datos compartidos. En una ejecuciÃ³n especÃ­fica de BuddyCache, se modela mediante la variable r, definida como el nÃºmero de solicitudes que llegan al redireccionador para una versiÃ³n dada de la pÃ¡gina P (es decir, hasta que un objeto en la pÃ¡gina se invalida). Considera una ejecuciÃ³n con fallos en frÃ­o. Un cliente comienza con una cachÃ© frÃ­a y ejecuta una carga de trabajo de solo lectura hasta que accede a las N pÃ¡ginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la cachÃ© del cliente es lo suficientemente grande como para contener N pÃ¡ginas. En BC, los frÃ­os fallos para la pÃ¡gina P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consideremos a continuaciÃ³n una ejecuciÃ³n con fallos de invalidaciÃ³n. Un cliente comienza con una cachÃ© caliente que contiene el conjunto de trabajo de N pÃ¡ginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualizaciÃ³n entre pares elimina todos los fallos de invalidaciÃ³n. En un grupo que contiene solo lectores (BCR), durante una ejecuciÃ³n en estado estable con actualizaciones uniformes, una transacciÃ³n del cliente tiene fallos de invalidaciÃ³n faltantes. Considera la secuencia de r fallos de cliente en la pÃ¡gina P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la pÃ¡gina P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frÃ­o, r â‰¤ k porque la segunda invalidaciÃ³n deshabilita la redirecciÃ³n para P hasta que el prÃ³ximo fallo en P provoque una recuperaciÃ³n del servidor. Suponiendo un acceso uniforme, un fallo de invalidaciÃ³n del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperaciÃ³n del servidor), y una probabilidad de (1 âˆ’ 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacciÃ³n Ãºnica en los sistemas Base, BCR y BCW. En los experimentos descritos a continuaciÃ³n, medimos los parÃ¡metros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalizaciÃ³n derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalizaciÃ³n y beneficios medidos directamente en los experimentos. 6.2 ConfiguraciÃ³n Experimental Antes de presentar nuestros resultados, describimos nuestra configuraciÃ³n experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectÃ¡ndose directamente a los servidores. El sistema Buddy ejecuta nuestra implementaciÃ³n del prototipo de BuddyCache en Thor, admitiendo la recuperaciÃ³n de pares, la actualizaciÃ³n de pares y la confirmaciÃ³n en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark estÃ¡ diseÃ±ado para capturar las caracterÃ­sticas de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicaciÃ³n especÃ­fica. Utilizamos OO7 porque es un punto de referencia estÃ¡ndar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un Ã¡rbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un grÃ¡fico de partes atÃ³micas vinculadas por objetos de conexiÃ³n; cada parte atÃ³mica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atÃ³micas por parte compuesta. La base de datos multiusuario asigna a cada cliente un mÃ³dulo privado que consiste en un Ã¡rbol de objetos de ensamblaje, y agrega un mÃ³dulo compartido adicional que escala proporcionalmente al nÃºmero de clientes. Esperamos que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ© y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la cachÃ©. Dado que el objetivo de nuestro estudio es evaluar quÃ© tan efectivamente nuestras tÃ©cnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras tÃ©cnicas tienen en los fallos de cachÃ© frÃ­o y de consistencia de cachÃ©, y aislar tanto como sea posible el efecto de los fallos de capacidad de cachÃ©. Para mantener la duraciÃ³n de nuestros experimentos razonable, utilizamos cachÃ©s pequeÃ±os. El benchmark OO7 genera mÃ³dulos de base de datos de tamaÃ±o predefinido. En nuestra implementaciÃ³n de OO7, el tamaÃ±o del mÃ³dulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la cachÃ©, utilizamos un Ãºnico mÃ³dulo privado y elegimos un tamaÃ±o de cachÃ© de 40MB para cada cliente. La base de datos OO7 se genera con mÃ³dulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos estÃ¡n agrupados en pÃ¡ginas de 8K, que tambiÃ©n son la unidad de transferencia en las solicitudes de recuperaciÃ³n. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro anÃ¡lisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idÃ©ntico a T1 excepto que modifica todas las partes atÃ³micas en un solo compuesto. Una transacciÃ³n Ãºnica incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo mÃ³dulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacciÃ³n, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de bÃºsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una cachÃ© de 50MB (de los cuales 6MB se utilizaron para el bÃºfer de objetos modificados), el cliente tenÃ­a una cachÃ© de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos bÃ¡sicos Esta secciÃ³n analiza el costo bÃ¡sico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 RedirecciÃ³n Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtenciÃ³n del servidor), el costo adicional de la redirecciÃ³n incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperaciÃ³n o confirmaciÃ³n del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmaciÃ³n y recuperaciÃ³n del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de Ã¡rea rÃ¡pida. Todos los nÃºmeros fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirecciÃ³n al cruzar el redireccionador no es muy alto, incluso en una red de Ã¡rea local. El costo de la confirmaciÃ³n aumenta con el nÃºmero de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperaciÃ³n no aumenta tanto porque la cachÃ© del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la cachÃ© del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperaciÃ³n entre pares, medimos la latencia de la recuperaciÃ³n entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperaciÃ³n entre pares, el costo de la redirecciÃ³n incluye, ademÃ¡s del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este Ãºltimo incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la pÃ¡gina solicitada. Medimos directamente el tiempo para copiar y desenrollar la pÃ¡gina solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperaciÃ³n de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador mÃ¡s un viaje de ida y vuelta a travÃ©s de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud mÃ¡s un viaje de ida y vuelta a travÃ©s de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando estÃ¡ bloqueado esperando una respuesta de bÃºsqueda o confirmaciÃ³n. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podrÃ­a ser mitigado por una implementaciÃ³n multi-hilo en un sistema con programaciÃ³n preemptiva. 6.3.2 VersiÃ³n de CachÃ© El commit en solitario permite que un cliente rÃ¡pido que modifica un objeto haga un commit de forma independiente a un compaÃ±ero lento. El mecanismo de confirmaciÃ³n Ãºnica introduce un procesamiento adicional en el servidor durante la validaciÃ³n de la transacciÃ³n, y un procesamiento adicional en el cliente durante la confirmaciÃ³n de la transacciÃ³n y en el momento del procesamiento de actualizaciÃ³n o invalidaciÃ³n. Los gastos generales del lado del servidor son mÃ­nimos y consisten en una actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina en el momento de la confirmaciÃ³n, y una comparaciÃ³n del nÃºmero de versiÃ³n en el momento de la validaciÃ³n de la transacciÃ³n. La cachÃ© de versiÃ³n tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacciÃ³n accede a objetos en mÃºltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor Ãºnico y, por lo tanto, el tiempo de confirmaciÃ³n adicional de la gestiÃ³n de la cachÃ© de versiones en el cliente no contribuye a los resultados presentados en la secciÃ³n a continuaciÃ³n. Para medir estos costos adicionales del lado del cliente en un sistema de mÃºltiples servidores, instrumentamos la implementaciÃ³n de la cachÃ© de versiones para ejecutarse con una traza de carga de trabajo que incluÃ­a invalidaciones reordenadas y cronometramos las operaciones bÃ¡sicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operaciÃ³n de bÃºsqueda de cachÃ© de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n en el momento de preparaciÃ³n de la solicitud de compromiso, y una operaciÃ³n de inserciÃ³n de cachÃ© de versiÃ³n para cada objeto actualizado por una transacciÃ³n en el momento de procesamiento de la respuesta de compromiso, pero solo si la pÃ¡gina actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmaciÃ³n se mantengan al mÃ­nimo, ya que el cliente estÃ¡ esperando de forma sÃ­ncrona la finalizaciÃ³n de la confirmaciÃ³n. Las mediciones muestran que en el peor de los casos, cuando llega un gran nÃºmero de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en pÃ¡ginas reordenadas, el costo de actualizar la cachÃ© de versiÃ³n es de 0.6 ms. El costo de tiempo de invalidaciÃ³n es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementaciÃ³n de la cachÃ© de versiones para reducir aÃºn mÃ¡s estos costos. 6.4 Rendimiento general Esta secciÃ³n examina las mejoras de rendimiento observadas por una aplicaciÃ³n que ejecuta el benchmark OO7 con un BuddyCache en una red de Ã¡rea amplia. 6.4.1 Fallos en frÃ­o Para evaluar las mejoras de rendimiento al evitar fallos en frÃ­o, comparamos el rendimiento de la cachÃ© en frÃ­o del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecuciÃ³n de los sistemas en el entorno de la red de Ã¡rea local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de Ã¡rea amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en cachÃ© frÃ­a. Los nÃºmeros fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frÃ­o solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frÃ­o solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparaciÃ³n con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cÃ¡lculos para el cliente, solicitudes de recuperaciÃ³n directa, recuperaciones de pares y solicitudes de confirmaciÃ³n. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperaciÃ³n entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperaciÃ³n del servidor para cada cliente individual disminuye porque, con mÃ¡s clientes accediendo a un mÃ³dulo compartido de tamaÃ±o fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperaciÃ³n de pares en comparaciÃ³n con la recuperaciÃ³n directa, pero este beneficio se ve contrarrestado por los tiempos de confirmaciÃ³n aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relaciÃ³n con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de cachÃ© 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT funciÃ³n de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias tÃ­picas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Sorprendentemente, los resultados analÃ­ticos predicen la mejora medida muy de cerca, aunque son ligeramente mÃ¡s altos que los valores empÃ­ricos. La razÃ³n principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidaciÃ³n evitados, comparamos el rendimiento de cachÃ© caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interÃ©s de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un Ãºnico cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compaÃ±eros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compaÃ±eros con un grupo que contiene un Ãºnico escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuraciÃ³n simple es suficiente para mostrar el impacto de las tÃ©cnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de cachÃ© caliente de OO7. Obtenemos los nÃºmeros ejecutando 2000 transacciones para filtrar los fallos en frÃ­o y luego medimos el tiempo de las siguientes 1000 transacciones. AquÃ­ nuevamente, los nÃºmeros reportados se derivan de los resultados del experimento de la red de Ã¡rea local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalizaciÃ³n en comparaciÃ³n con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparaciÃ³n con la Base. Este beneficio se debe a la actualizaciÃ³n entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperaciÃ³n entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperaciÃ³n local evitando el retraso de la recuperaciÃ³n desde el servidor. El Ãºltimo es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperaciÃ³n de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperaciÃ³n de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualizaciÃ³n de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relaciÃ³n con Base, y Buddy Writer y Base en relaciÃ³n con Base) en un experimento de cachÃ© activa en funciÃ³n del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualizaciÃ³n entre pares domina el gasto general en la configuraciÃ³n de Writer incluso en redes de baja latencia (la actualizaciÃ³n entre pares incurre en un gasto mÃ­nimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Como en experimentos de cachÃ© frÃ­a, aquÃ­ los resultados analÃ­ticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pÃ©rdida de invalidaciÃ³n es mÃ­nimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de cachÃ© frÃ­a). Como en el caso de cachÃ© frÃ­a, la razÃ³n por la que el modelo analÃ­tico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÃ“N Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en una red de Ã¡rea extensa debido a la alta latencia de red. Este artÃ­culo describe BuddyCache, una nueva tÃ©cnica de almacenamiento en cachÃ© cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La tÃ©cnica mejora el rendimiento y proporciona propiedades sÃ³lidas de correcciÃ³n y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirecciÃ³n para obtener objetos faltantes directamente de las cachÃ©s de los miembros del grupo, y para admitir la actualizaciÃ³n entre pares, una nueva tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirecciÃ³n puede interferir con la disponibilidad del objeto. Solo commit es una nueva tÃ©cnica de validaciÃ³n que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validaciÃ³n detallada utilizando informaciÃ³n de versiÃ³n de grano grueso econÃ³mica. Hemos diseÃ±ado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analÃ­ticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Las principales contribuciones del artÃ­culo son: 1. extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementaciÃ³n del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluaciÃ³n del rendimiento basada en anÃ¡lisis y mediciones de los costos y beneficios de las nuevas tÃ©cnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. TambiÃ©n agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios Ãºtiles que mejoraron este artÃ­culo. 9. REFERENCIAS [1] emulab.net, la InstalaciÃ³n de EmulaciÃ³n de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. ReconstrucciÃ³n de fragmentos: Proporcionando coherencia de cachÃ© global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre GestiÃ³n de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: ComputaciÃ³n en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de cachÃ© hÃ­bridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. RecuperaciÃ³n rÃ¡pida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de cachÃ© en la World Wide Web. En la 17Âª Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluaciÃ³n del rendimiento del sistema de gestiÃ³n de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una cachÃ© de objetos jerÃ¡rquica en Internet. En la Conferencia TÃ©cnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachÃ©s de Internet escalables. Informe TÃ©cnico CS-1997-18, Departamento de Ciencias de la ComputaciÃ³n, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: CachÃ© de proxy cooperativa en una red de Ã¡rea amplia. En el Tercer Taller Internacional de CachÃ© de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. CachÃ© web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2Âº Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. CachÃ© cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilaciÃ³n y en tiempo de ejecuciÃ³n para una memoria compartida distribuida eficiente. En Actas de IEEE, EdiciÃ³n Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la cachÃ©: un protocolo de intercambio de cachÃ© web escalable de Ã¡rea amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. ImplementaciÃ³n de GestiÃ³n Global de Memoria en un ClÃºster de Estaciones de Trabajo. Actas del 15Âº Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: DiseÃ±o, ImplementaciÃ³n y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de cachÃ© transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, pÃ¡ginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. GestiÃ³n global de memoria para arquitecturas de sistemas de gestiÃ³n de bases de datos cliente-servidor. En Actas del 19Âº Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El BÃºfer de Objeto Modificado: Una TÃ©cnica de GestiÃ³n de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto TecnolÃ³gico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. GestiÃ³n de documentos replicados en un sistema de comunicaciÃ³n grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13Âª Conferencia Europea sobre ProgramaciÃ³n Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18Âº Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. ReplicaciÃ³n con marca de vista: un nuevo mÃ©todo de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de ComputaciÃ³n Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalaciÃ³n eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de MultidifusiÃ³n a Nivel de AplicaciÃ³n. En el 3er Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de cachÃ© cooperativa utilizando pistas. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en CachÃ© Global. Informe tÃ©cnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del CachÃ© de Proxies Web Cooperativos. En el 17Âº Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerÃ¡rquica de cachÃ© en una WAN. En el Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. ComparticiÃ³n adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÃ‰NDICE Este apÃ©ndice describe el protocolo de conmutaciÃ³n por error de BuddyCache. Para dar cabida a clientes heterogÃ©neos, incluidos los dispositivos portÃ¡tiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseÃ±o de BuddyCache asume que las cachÃ©s del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresÃ­a detecta el fallo de un cliente o un redireccionador intercambiando mensajes periÃ³dicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutaciÃ³n por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuraciÃ³n y reinicia el protocolo. El protocolo de reconfiguraciÃ³n del grupo es similar al presentado en [25]. AquÃ­ describimos cÃ³mo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de pÃ¡ginas redireccionadas y el reenvÃ­o de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachÃ©s. En caso de un fallo del cliente, el failover elimina las pÃ¡ginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmaciÃ³n, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en cachÃ© las pÃ¡ginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutaciÃ³n por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de pÃ¡ginas utilizando un protocolo similar al descrito en [6]. El redireccionador reciÃ©n reiniciado solicita a los miembros activos del grupo la lista de pÃ¡ginas que estÃ¡n almacenando en cachÃ© y el estado de estas pÃ¡ginas, es decir, si las pÃ¡ginas estÃ¡n completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperaciÃ³n perdida expirarÃ¡ en el cliente y serÃ¡ retransmitida. Una transacciÃ³n que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma despuÃ©s del cambio se trata como una transacciÃ³n regular; una transacciÃ³n que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciarÃ¡ la transacciÃ³n y la solicitud de confirmaciÃ³n serÃ¡ retransmitida despuÃ©s del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caÃ­do podrÃ­an evitar la recolecciÃ³n de basura de las invalidaciones pendientes en los servidores o la cachÃ© virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los nÃºmeros de versiÃ³n Ãºnicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validaciÃ³n de transacciones depende del protocolo de coherencia de cachÃ© para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutaciÃ³n por error de BuddyCache no compromete la correcciÃ³n del procedimiento de validaciÃ³n. Recuerda que la validaciÃ³n de transacciones de BuddyCache utiliza dos mecanismos complementarios, nÃºmeros de versiÃ³n de pÃ¡gina y confirmaciones de invalidaciÃ³n de los clientes, para verificar que una transacciÃ³n ha leÃ­do datos actualizados. La propagaciÃ³n de la confirmaciÃ³n de invalidaciÃ³n (y actualizaciÃ³n) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmaciÃ³n de una modificaciÃ³n (invalidaciÃ³n o actualizaciÃ³n) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en cachÃ© el objeto o bien ha instalado el valor mÃ¡s reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmaciÃ³n de un cliente para una transacciÃ³n T que lee un objeto o despuÃ©s de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidaciÃ³n no confirmada para o pendiente para este grupo, la versiÃ³n del objeto leÃ­da por la transacciÃ³n T estÃ¡ actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validaciÃ³n utilizando nÃºmeros de versiÃ³n. El registro de confirmaciÃ³n de transacciÃ³n contiene un nÃºmero de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n. El protocolo de nÃºmero de versiÃ³n mantiene la invariante V P que garantiza que el valor del objeto o leÃ­do por la transacciÃ³n corresponda al nÃºmero de versiÃ³n mÃ¡s alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificaciÃ³n anterior despuÃ©s de haber recibido una modificaciÃ³n posterior. La retransmisiÃ³n de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validaciÃ³n verifica que el nÃºmero de versiÃ³n en el registro de confirmaciÃ³n coincida con el nÃºmero de versiÃ³n en la invalidaciÃ³n pendiente no reconocida. Es fÃ¡cil ver que, dado que esta comprobaciÃ³n es una comprobaciÃ³n cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutaciÃ³n por error aÃºn no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    "almacenamiento en cachÃ© web cooperativo",
                    "almacenamiento en cachÃ© web cooperativo",
                    "almacenamiento en cachÃ© web cooperativos",
                    "almacenamiento en cachÃ© web cooperativo"
                ]
            ]
        },
        "fine-grain sharing": {
            "translated_key": "intercambio de granularidad fina",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for <br>fine-grain sharing</br>. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "Section 4 describes the details of the implementation of solo commit support for <br>fine-grain sharing</br>. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups."
            ],
            "translated_annotated_samples": [
                "La secciÃ³n 4 describe los detalles de la implementaciÃ³n del soporte de compromiso individual para el <br>intercambio de granularidad fina</br>. 3.4 ConfiguraciÃ³n de Grupo La arquitectura BuddyCache admite mÃºltiples grupos de pares concurrentes."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de Ã¡rea amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de Ã¡rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil. Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en cachÃ© web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos. Sin embargo, las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica. La interacciÃ³n con el servidor aumenta la latencia. La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia. Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n. Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo. BuddyCache presenta dos desafÃ­os tÃ©cnicos principales. Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©. El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de almacenamiento en cachÃ© web cooperativos [11]. Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo. BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos. Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica. Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad? DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red. Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia. El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida. Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache. Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n. Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos. Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de Ã¡rea amplia. Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad. Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un Ãºnico servidor. Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web. El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en cachÃ© transaccional [19]. La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una transacciÃ³n, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador. El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado. AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©. Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina). La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente. El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento. A continuaciÃ³n, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene. La transacciÃ³n puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor. Sin embargo, antes de que una transacciÃ³n se confirme, debe ser validada; el servidor debe asegurarse de que la transacciÃ³n validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada. Si la validaciÃ³n falla, la transacciÃ³n se cancela. Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de bÃºsqueda de pares envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la cachÃ© y envÃ­an confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la cachÃ© del cliente, la confirmaciÃ³n de invalidaciÃ³n indica al servidor que un cliente sin invalidaciones pendientes ha leÃ­do objetos actualizados. Una invalidaciÃ³n no reconocida indica que un objeto obsoleto puede haber sido accedido en la cachÃ© del cliente. El procedimiento de validaciÃ³n en el servidor aborta una transacciÃ³n del cliente si este lee un objeto mientras hay una invalidaciÃ³n pendiente. El mecanismo de invalidaciÃ³n reconocido admite coherencia de cachÃ© a nivel de objeto sin directorios basados en objetos o nÃºmeros de versiÃ³n por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeÃ±os, ya que los objetos tÃ­picos son pequeÃ±os. Un objetivo importante del diseÃ±o de BuddyCache es mantener este beneficio. Dado que en BuddyCache una pÃ¡gina puede ser recuperada en una cachÃ© de cliente sin intervenciÃ³n del servidor (como se ilustra en la figura 2), los directorios de cachÃ© en los servidores llevan un registro de las pÃ¡ginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las pÃ¡ginas almacenadas en cachÃ© en cada cliente de un grupo. Los servidores envÃ­an al redireccionador invalidaciones para las pÃ¡ginas almacenadas en cachÃ© en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. ActualizaciÃ³n de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en cachÃ© por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interÃ©s potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de cachÃ© y las actualizaciones de cachÃ©. Los estudios de coherencia de cachÃ© en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualizaciÃ³n y la invalidaciÃ³n. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. AlmacÃ©n x 6. ActualizaciÃ³n x 3. CompromÃ©tete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares estÃ¡n fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeÃ±as, agrupadas y se envÃ­an junto con otros mensajes. AdemÃ¡s, los protocolos de invalidaciÃ³n se ajustan a la tendencia actual de hardware de aumentar los tamaÃ±os de cachÃ© del cliente. Es probable que las cachÃ©s mÃ¡s grandes contengan mucha mÃ¡s informaciÃ³n de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una red de Ã¡rea amplia serÃ­an derrochadores. Sin embargo, los protocolos de coherencia basados en invalidaciÃ³n pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interÃ©s para otro miembro del grupo. Con un protocolo basado en invalidaciÃ³n, la actualizaciÃ³n de un miembro invalidarÃ¡ la copia en cachÃ© de otro miembro, lo que provocarÃ¡ que este Ãºltimo realice una recuperaciÃ³n de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualizaciÃ³n e invalidaciÃ³n en entornos de redes de Ã¡rea amplia. Evita la penalizaciÃ³n de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalizaciÃ³n de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusiÃ³n localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en cachÃ© anteriores. La actualizaciÃ³n entre pares funciona de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que la transacciÃ³n se confirma, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n, y tambiÃ©n propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmaciÃ³n. 3.3 ConfirmaciÃ³n individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminaciÃ³n de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en cachÃ© transaccional, ya que un cliente que es lento para reconocer una invalidaciÃ³n o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacciÃ³n. Por ejemplo, un ingeniero que realiza una revisiÃ³n repetida al mismo objeto de diseÃ±o compartido (y por lo tanto tiene la Ãºltima versiÃ³n del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situaciÃ³n representada en la figura 4 donde el Cliente1 realiza una transacciÃ³n T que lee la Ãºltima versiÃ³n de un objeto x en la pÃ¡gina P recientemente modificada por el Cliente1. Si la solicitud de confirmaciÃ³n para T llega al servidor antes de que la confirmaciÃ³n colectiva de Cliente2 por la Ãºltima modificaciÃ³n de x llegue al servidor, el procedimiento de validaciÃ³n de OCC considera que x estÃ¡ obsoleto y aborta T (porque, como se explicÃ³ anteriormente, una invalidaciÃ³n no reconocida por un cliente actÃºa como indicaciÃ³n para el servidor de que el valor del objeto en cachÃ© estÃ¡ obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la correcciÃ³n del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asÃ­ncronas son una parte importante de la razÃ³n por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasiÃ³n de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envÃ­an y procesan de forma asÃ­ncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devoluciÃ³n de llamada jerÃ¡rquica [32], pero la naturaleza asincrÃ³nica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrÃ³nicas. El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a un cliente con objetos actualizados confirmar una transacciÃ³n incluso si la confirmaciÃ³n del grupo se retrasa debido a pares lentos o caÃ­dos. El protocolo requiere que los clientes incluyan informaciÃ³n adicional con los conjuntos de lectura de transacciones en el mensaje de confirmaciÃ³n, para indicar al servidor que los objetos leÃ­dos por la transacciÃ³n estÃ¡n actualizados. Los nÃºmeros de versiÃ³n de los objetos podrÃ­an proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionÃ³ anteriormente, mantener nÃºmeros de versiÃ³n por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaÃ±o de directorio) en todo el sistema de objetos cuando los objetos son pequeÃ±os [23]. En cambio, solo utiliza nÃºmeros de versiÃ³n de pÃ¡gina de grano grueso para identificar versiones de objetos de grano fino. El nÃºmero de versiÃ³n de una pÃ¡gina se incrementa en un servidor cuando una transacciÃ³n que modifica objetos en la pÃ¡gina se confirma. Las actualizaciones realizadas por una Ãºnica transacciÃ³n y las invalidaciones correspondientes son identificadas de manera Ãºnica por el nÃºmero de versiÃ³n de la pÃ¡gina modificada. Los nÃºmeros de versiÃ³n de la pÃ¡gina se propagan a los clientes en respuestas de recuperaciÃ³n, respuestas de confirmaciÃ³n y con invalidaciones, y los clientes incluyen los nÃºmeros de versiÃ³n de la pÃ¡gina en las solicitudes de confirmaciÃ³n enviadas a los servidores. Si una transacciÃ³n falla en la validaciÃ³n debido a la falta de reconocimiento de grupo, el servidor verifica los nÃºmeros de versiÃ³n de pÃ¡gina de los objetos en el conjunto de lectura de la transacciÃ³n y permite que la transacciÃ³n se confirme si el cliente ha leÃ­do desde la Ãºltima versiÃ³n de la pÃ¡gina. Los nÃºmeros de versiÃ³n de la pÃ¡gina permiten confirmaciones independientes, pero las verificaciones de versiÃ³n de pÃ¡gina solo detectan conflictos a nivel de pÃ¡gina. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La secciÃ³n 4 describe los detalles de la implementaciÃ³n del soporte de compromiso individual para el <br>intercambio de granularidad fina</br>. 3.4 ConfiguraciÃ³n de Grupo La arquitectura BuddyCache admite mÃºltiples grupos de pares concurrentes. Potencialmente, puede ser mÃ¡s rÃ¡pido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podrÃ­a ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en cachÃ© de pares de mÃºltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en cachÃ© web, simplemente aumentar la poblaciÃ³n de clientes en una cachÃ© proxy a menudo aumenta la tasa general de aciertos en la cachÃ© [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacciÃ³n explÃ­cita entre clientes y la colaboraciÃ³n, lo que sugiere que es poco probable que ocurra la recuperaciÃ³n entre grupos. AdemÃ¡s, las mediciones de sistemas de almacenamiento en cachÃ© web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexiÃ³n de red entre los grupos de pares sea muy rÃ¡pida. Estamos principalmente interesados en entornos donde compaÃ±eros que colaboran estrechamente tienen una conectividad rÃ¡pida a corta distancia, pero la conexiÃ³n entre grupos de compaÃ±eros puede ser lenta. Como resultado, decidimos que el soporte para la recuperaciÃ³n entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compaÃ±eros con recursos heterogÃ©neos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compaÃ±eros o, cuando estÃ© disponible, en un nodo separado dentro de la infraestructura del sitio. AdemÃ¡s, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una cachÃ© de pares en espera para recibir pÃ¡ginas recuperadas por otros pares, emulando una cachÃ© central algo similar a una cachÃ© de proxy web regional. Desde el punto de vista del protocolo de coherencia de cachÃ© BuddyCache, sin embargo, un cachÃ© de compaÃ±ero en espera es equivalente a un cachÃ© de compaÃ±ero regular y, por lo tanto, no consideramos este caso por separado en la discusiÃ³n de este documento. 4. En esta secciÃ³n proporcionamos los detalles de la implementaciÃ³n de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en cachÃ© de estos objetos. Las aplicaciones se ejecutan en los clientes e interactÃºan con el sistema realizando llamadas a mÃ©todos de objetos en cachÃ©. Todas las llamadas a mÃ©todos ocurren dentro de transacciones atÃ³micas. Los clientes se comunican con los servidores para obtener pÃ¡ginas o realizar una transacciÃ³n. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volÃ¡til. El disco estÃ¡ organizado como una colecciÃ³n de pÃ¡ginas que son las unidades de acceso al disco. El registro estable guarda la informaciÃ³n de confirmaciÃ³n y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de cachÃ© y una cachÃ© de objetos modificados recuperable llamada MOB. El directorio lleva un registro de quÃ© pÃ¡ginas estÃ¡n almacenadas en cachÃ© por quÃ© clientes. El MOB contiene objetos recientemente modificados que aÃºn no han sido escritos de vuelta en sus pÃ¡ginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de cachÃ© base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la SecciÃ³n 3.1. Proporcionamos algunos de los detalles relevantes de la implementaciÃ³n del protocolo OCC. El cliente lleva un registro de los objetos que son leÃ­dos y modificados por su transacciÃ³n; envÃ­a esta informaciÃ³n, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacciÃ³n. Los servidores determinan si la confirmaciÃ³n es posible, utilizando un protocolo de confirmaciÃ³n de dos fases si la transacciÃ³n utilizÃ³ objetos en mÃºltiples servidores. Si la transacciÃ³n se lleva a cabo, las nuevas copias de los objetos modificados se aÃ±aden al registro y tambiÃ©n se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperaciÃ³n escaneando el registro. Dado que los objetos no estÃ¡n bloqueados antes de ser utilizados, una confirmaciÃ³n de transacciÃ³n puede hacer que las cachÃ©s contengan objetos obsoletos. Los servidores abortarÃ¡n una transacciÃ³n que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviÃ¡ndoles mensajes de invalidaciÃ³n; un servidor utiliza su directorio y la informaciÃ³n sobre la transacciÃ³n de confirmaciÃ³n para determinar quÃ© mensajes de invalidaciÃ³n enviar. Los mensajes de invalidaciÃ³n son pequeÃ±os porque simplemente identifican objetos obsoletos. AdemÃ¡s, se envÃ­an en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidaciÃ³n, elimina los objetos obsoletos de su cachÃ© y aborta la transacciÃ³n actual si los utilizÃ³. El cliente sigue conservando pÃ¡ginas que contienen objetos invalidados; estas pÃ¡ginas ahora estÃ¡n incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidaciÃ³n de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener pÃ¡ginas incompletas en la cachÃ© del cliente significa que el falso intercambio no conduce a fallos innecesarios en la cachÃ©. Los clientes reconocen las invalidaciones para indicar la eliminaciÃ³n de datos obsoletos, como se explica en la SecciÃ³n 3.1. Los mensajes de invalidaciÃ³n evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo asÃ­ el desperdicio de trabajo y trasladando la detecciÃ³n de abortos de los servidores a los clientes. Cuando una transacciÃ³n se aborta, su cliente restaura las copias en cachÃ© de los objetos modificados al estado que tenÃ­an antes de que la transacciÃ³n comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacciÃ³n. 4.3 RedirecciÃ³n El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de pÃ¡ginas disponibles en el grupo de pares y proporciona una redirecciÃ³n rÃ¡pida y centralizada de recuperaciÃ³n (ver figura 2) entre las cachÃ©s de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan pÃ¡ginas u objetos al incluir esa informaciÃ³n en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la cachÃ© de grupo, el redireccionador realiza un seguimiento del estado de las pÃ¡ginas. Una pÃ¡gina en cachÃ© estÃ¡ completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una pÃ¡gina estÃ¡n marcados como invÃ¡lidos. Solo se utilizan pÃ¡ginas completas por el proceso de recuperaciÃ³n de pares. El protocolo para mantener el estado de la pÃ¡gina cuando las pÃ¡ginas son actualizadas e invalidadas se describe en la SecciÃ³n 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una pÃ¡gina solicitada completa no estÃ¡ disponible en el grupo de pares o si un par necesita confirmar una transacciÃ³n, el redireccionador actÃºa como un proxy de servidor: reenvÃ­a la solicitud al servidor y luego reenvÃ­a la respuesta de vuelta al cliente. AdemÃ¡s, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualizaciÃ³n o informaciÃ³n de invalidaciÃ³n a los clientes que tienen en cachÃ© la pÃ¡gina modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la cachÃ© de grupo de pares combinada estÃ¡ desempeÃ±ando el papel de una Ãºnica cachÃ© de cliente en el sistema base. 4.4 ActualizaciÃ³n de pares La actualizaciÃ³n de pares se implementa de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que una transacciÃ³n se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacciÃ³n generan invalidaciones de objetos para cada grupo de cachÃ© que almacena pÃ¡ginas que contienen los objetos modificados (incluido el grupo que realiza la confirmaciÃ³n). Las invalidaciones se envÃ­an de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en cachÃ© los objetos modificados se deshagan de los datos obsoletos. En grupos de cachÃ© distintos al grupo de confirmaciÃ³n, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas, recopilan las confirmaciones de los clientes y, despuÃ©s de completar la recopilaciÃ³n, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacciÃ³n, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envÃ­an a los clientes que almacenan en cachÃ© esas pÃ¡ginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmaciÃ³n colectiva se propaga al servidor. Una invalidaciÃ³n hace que una pÃ¡gina en cachÃ© no estÃ© disponible para la recuperaciÃ³n de pares, cambiando el estado de una pÃ¡gina completa p a incompleta. Por el contrario, una actualizaciÃ³n de una pÃ¡gina completa conserva el estado completo de la pÃ¡gina. Como se muestra en los estudios de la reconstrucciÃ³n de fragmentos 31 [2], esta propagaciÃ³n de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma pÃ¡gina, la pÃ¡gina conserva su estado completo y permanece disponible para la recuperaciÃ³n entre pares. Por lo tanto, el efecto de la actualizaciÃ³n de pares es similar a la reconstrucciÃ³n de fragmentos ansiosa [2]. TambiÃ©n hemos considerado la posibilidad de permitir que un compaÃ±ero recupere una pÃ¡gina incompleta (con objetos invÃ¡lidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos invÃ¡lidos. 4.5 Vcache El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo mÃ¡s lentos (o fallidos). Como se explica en la SecciÃ³n 3.3, el protocolo de commit Ãºnico permite que una transacciÃ³n T pase la validaciÃ³n si la informaciÃ³n adicional de coherencia proporcionada por el cliente indica que la transacciÃ³n T ha leÃ­do objetos actualizados. Los clientes utilizan los nÃºmeros de versiÃ³n de la pÃ¡gina para proporcionar esta informaciÃ³n adicional de coherencia. Es decir, un cliente incluye el nÃºmero de versiÃ³n de la pÃ¡gina correspondiente a cada objeto en el conjunto de objetos leÃ­dos enviado en la solicitud de confirmaciÃ³n al servidor. Dado que a cada actualizaciÃ³n de objeto comprometido le corresponde un nÃºmero de versiÃ³n de pÃ¡gina Ãºnico, el nÃºmero de versiÃ³n de pÃ¡gina asociado con un objeto permite que el procedimiento de validaciÃ³n en el servidor verifique si la transacciÃ³n del cliente ha leÃ­do objetos actualizados. El uso de versiones de pÃ¡gina de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeÃ±os, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en cachÃ© a la versiÃ³n de pÃ¡gina identificadora (ObjectToVersion). El principal problema de implementaciÃ³n se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian nÃºmeros de versiÃ³n de pÃ¡gina con las invalidaciones. En el momento de la validaciÃ³n, si hay una invalidaciÃ³n no reconocida pendiente para un objeto x leÃ­do por una transacciÃ³n T, el procedimiento de validaciÃ³n verifica si el nÃºmero de versiÃ³n de x en el conjunto de lectura de Ts coincide con el nÃºmero de versiÃ³n de la invalidaciÃ³n pendiente mÃ¡s alta para x, en cuyo caso el valor del objeto estÃ¡ actualizado, de lo contrario, T falla en la validaciÃ³n. Observamos nuevamente que las verificaciones basadas en el nÃºmero de versiÃ³n de la pÃ¡gina y las verificaciones basadas en el reconocimiento de invalidaciÃ³n son complementarias en la validaciÃ³n de confirmaciÃ³n individual y ambas son necesarias. La verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina permite que la validaciÃ³n avance antes de que lleguen las confirmaciones de invalidaciÃ³n, pero por sÃ­ sola, una verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina detecta conflictos a nivel de pÃ¡gina y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cÃ³mo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un nÃºmero de versiÃ³n de la pÃ¡gina para cada pÃ¡gina en cachÃ©. El nÃºmero de versiÃ³n satisface la siguiente invariante V P sobre el estado de los objetos en una pÃ¡gina: si una pÃ¡gina en cachÃ© P tiene un nÃºmero de versiÃ³n v, entonces el valor de un objeto o en la pÃ¡gina en cachÃ© P es invÃ¡lido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacciÃ³n que estableciÃ³ el nÃºmero de versiÃ³n de P en v. Los nuevos valores de objetos y los nuevos nÃºmeros de versiÃ³n de pÃ¡gina llegan cuando un cliente obtiene una pÃ¡gina o cuando llega una respuesta de confirmaciÃ³n o invalidaciones para esta pÃ¡gina. Los nuevos valores del objeto modifican la pÃ¡gina y, por lo tanto, el nÃºmero de versiÃ³n de la pÃ¡gina necesita ser actualizado para mantener la invariante V P. Un nÃºmero de versiÃ³n de pÃ¡gina que llega cuando un cliente obtiene una pÃ¡gina, reemplaza la VersiÃ³n del Objeto x 8 Servidor de RedirecciÃ³n 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el nÃºmero de versiÃ³n de la pÃ¡gina para esta pÃ¡gina. Tal actualizaciÃ³n preserva el invariante V P. De manera similar, un nÃºmero de versiÃ³n de pÃ¡gina en secuencia que llega al cliente en un mensaje de confirmaciÃ³n o invalidaciÃ³n avanza el nÃºmero de versiÃ³n para toda la pÃ¡gina en cachÃ©, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus nÃºmeros de versiÃ³n de pÃ¡gina correspondientes tambiÃ©n pueden llegar al cliente fuera de secuencia, en cuyo caso la actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina podrÃ­a violar V P. Por ejemplo, una respuesta de confirmaciÃ³n para una transacciÃ³n que actualiza el objeto x en la pÃ¡gina P en el servidor S1, y el objeto y en la pÃ¡gina Q en el servidor S2, puede entregar un nuevo nÃºmero de versiÃ³n para P desde el coordinador de transacciones S1 antes de que llegue una invalidaciÃ³n generada para una transacciÃ³n anterior que ha modificado el objeto r en la pÃ¡gina P desde S1 (como se muestra en la figura 5). El protocolo de actualizaciÃ³n de cachÃ© garantiza que el valor de cualquier objeto o en una pÃ¡gina en cachÃ© P refleje la actualizaciÃ³n o invalidaciÃ³n con el nÃºmero de versiÃ³n observado mÃ¡s alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de nÃºmeros de versiÃ³n de pÃ¡gina, el cliente gestiona una pequeÃ±a cachÃ© de nÃºmeros de versiÃ³n vcache que mantiene el mapeo de un objeto a su nÃºmero de versiÃ³n de pÃ¡gina correspondiente para todas las actualizaciones de nÃºmeros de versiÃ³n reordenadas hasta que se ensamble una secuencia completa de nÃºmeros de versiÃ³n de pÃ¡gina. Cuando llegan los nÃºmeros de versiÃ³n faltantes para la pÃ¡gina y completan una secuencia, el nÃºmero de versiÃ³n de toda la pÃ¡gina se avanza. El mapeo de ObjectToVersion, incluyendo los nÃºmeros de versiÃ³n de vcache y pÃ¡gina, se utiliza en el momento de la confirmaciÃ³n de la transacciÃ³n para proporcionar nÃºmeros de versiÃ³n para el conjunto de objetos leÃ­dos de la siguiente manera. Si el objeto leÃ­do tiene una entrada en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n mÃ¡s alto en la vcache para este objeto. Si el objeto no estÃ¡ presente en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n de la pÃ¡gina en cachÃ© que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la cachÃ© del cliente, incluyendo los nÃºmeros de versiÃ³n de las pÃ¡ginas y la vcache. El cliente puede limitar el tamaÃ±o de la cachÃ© virtual segÃºn sea necesario, ya que volver a cargar una pÃ¡gina elimina todos los nÃºmeros de versiÃ³n de pÃ¡gina reordenados de la cachÃ© virtual. Sin embargo, esperamos que la reorganizaciÃ³n de nÃºmeros de versiÃ³n sea poco comÃºn y, por lo tanto, esperamos que la vcache sea muy pequeÃ±a. 5. Un grupo de clientes contiene mÃºltiples nodos de cliente y un objeto de pÃ¡gina de versiÃ³n redi32 VCache Cliente CachÃ© Cliente PÃ¡gina CachÃ© Figura 6: Mapa de Objeto a VersiÃ³n con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutaciÃ³n por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. AdemÃ¡s, el fallo del redireccionador deberÃ­a permitir que los clientes no afectados mantengan sus cachÃ©s intactas. Hemos diseÃ±ado un protocolo de conmutaciÃ³n por error para BuddyCache pero aÃºn no lo hemos implementado. El apÃ©ndice describe el protocolo. 6. La redirecciÃ³n de BuddyCache en la evaluaciÃ³n de rendimiento respalda los beneficios de evitar la comunicaciÃ³n con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes. Â¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 AnÃ¡lisis Los beneficios de rendimiento de la recuperaciÃ³n entre pares y la actualizaciÃ³n entre pares se deben a la evitaciÃ³n de interacciones con el servidor. Esta secciÃ³n presenta un modelo de rendimiento analÃ­tico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la cachÃ© del cliente. Estos pueden ser fallos frÃ­os, fallos de invalidaciÃ³n y fallos de capacidad. Nuestro anÃ¡lisis se centra en los fallos por frÃ­o y los fallos por invalidaciÃ³n, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frÃ­o. AdemÃ¡s, las tendencias tecnolÃ³gicas indican que la capacidad de memoria y almacenamiento seguirÃ¡ creciendo y, por lo tanto, es probable que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ©. Los fallos de cachÃ© del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuraciÃ³n de cachÃ©. Nuestro anÃ¡lisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validaciÃ³n. Para estudiar el beneficio de evitar fallos en frÃ­o, consideramos el rendimiento de la cachÃ© en frÃ­o en una carga de trabajo de solo lectura (sin fallos de invalidaciÃ³n). Esperamos que la recuperaciÃ³n entre pares mejore el costo de latencia para las solicitudes de cachÃ© frÃ­a del cliente al recuperar objetos de la cachÃ© cercana. Evaluamos cÃ³mo el costo de redirecciÃ³n afecta este beneficio al comparar y analizar el rendimiento de una aplicaciÃ³n que se ejecuta en un sistema de almacenamiento con BuddyCache y sin Ã©l (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidaciÃ³n, consideramos el rendimiento de la cachÃ© caliente en una carga de trabajo con modificaciones (sin fallos en frÃ­o). En las cachÃ©s calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualizaciÃ³n entre pares permite que un cliente acceda a un objeto modificado por un compaÃ±ero colaborador cercano sin el retraso impuesto por los protocolos de invalidaciÃ³n Ãºnicamente. En grupos donde los compaÃ±eros comparten un interÃ©s de solo lectura en los objetos modificados, la recuperaciÃ³n entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compaÃ±ero colaborador lo tenga, lo que evita el retraso de la recuperaciÃ³n del servidor sin el alto costo impuesto por los protocolos de solo actualizaciÃ³n. Las tendencias tecnolÃ³gicas indican que ambos beneficios seguirÃ¡n siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualizaciÃ³n Ãºnicamente. Sin embargo, la tendencia hacia cachÃ©s cada vez mÃ¡s grandes, que se actualizan cuando los objetos en cachÃ© son modificados, hace que los protocolos basados en invalidaciÃ³n sean mÃ¡s atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicaciÃ³n que se ejecuta sin BuddyCache y una aplicaciÃ³n que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compaÃ±ero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compaÃ±ero fuera del grupo. La actualizaciÃ³n entre pares tambiÃ©n puede evitar fallos de invalidaciÃ³n debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma pÃ¡gina de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseÃ±o del objeto, y tambiÃ©n porque este beneficio se puede derivar dado el Ã­ndice de aciertos en cachÃ© y la contenciÃ³n de la carga de trabajo. 6.1.1 El Modelo El modelo considera cÃ³mo el tiempo para completar una ejecuciÃ³n con y sin BuddyCache se ve afectado por los fallos de invalidaciÃ³n y los fallos en frÃ­o. Considerando k clientes ejecutÃ¡ndose concurrentemente accediendo de manera uniforme a un conjunto compartido de N pÃ¡ginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacciÃ³n y realizar cÃ¡lculos en una transacciÃ³n, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin Ã©l (Base). Para simplificar, nuestro modelo asume que los tiempos de bÃºsqueda y confirmaciÃ³n son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del nÃºmero total de clientes en el sistema. El nÃºmero de fallos evitados por la recuperaciÃ³n entre pares depende de k, el nÃºmero de clientes en la BuddyCache, y del interÃ©s conjunto de los clientes en los datos compartidos. En una ejecuciÃ³n especÃ­fica de BuddyCache, se modela mediante la variable r, definida como el nÃºmero de solicitudes que llegan al redireccionador para una versiÃ³n dada de la pÃ¡gina P (es decir, hasta que un objeto en la pÃ¡gina se invalida). Considera una ejecuciÃ³n con fallos en frÃ­o. Un cliente comienza con una cachÃ© frÃ­a y ejecuta una carga de trabajo de solo lectura hasta que accede a las N pÃ¡ginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la cachÃ© del cliente es lo suficientemente grande como para contener N pÃ¡ginas. En BC, los frÃ­os fallos para la pÃ¡gina P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consideremos a continuaciÃ³n una ejecuciÃ³n con fallos de invalidaciÃ³n. Un cliente comienza con una cachÃ© caliente que contiene el conjunto de trabajo de N pÃ¡ginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualizaciÃ³n entre pares elimina todos los fallos de invalidaciÃ³n. En un grupo que contiene solo lectores (BCR), durante una ejecuciÃ³n en estado estable con actualizaciones uniformes, una transacciÃ³n del cliente tiene fallos de invalidaciÃ³n faltantes. Considera la secuencia de r fallos de cliente en la pÃ¡gina P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la pÃ¡gina P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frÃ­o, r â‰¤ k porque la segunda invalidaciÃ³n deshabilita la redirecciÃ³n para P hasta que el prÃ³ximo fallo en P provoque una recuperaciÃ³n del servidor. Suponiendo un acceso uniforme, un fallo de invalidaciÃ³n del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperaciÃ³n del servidor), y una probabilidad de (1 âˆ’ 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacciÃ³n Ãºnica en los sistemas Base, BCR y BCW. En los experimentos descritos a continuaciÃ³n, medimos los parÃ¡metros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalizaciÃ³n derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalizaciÃ³n y beneficios medidos directamente en los experimentos. 6.2 ConfiguraciÃ³n Experimental Antes de presentar nuestros resultados, describimos nuestra configuraciÃ³n experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectÃ¡ndose directamente a los servidores. El sistema Buddy ejecuta nuestra implementaciÃ³n del prototipo de BuddyCache en Thor, admitiendo la recuperaciÃ³n de pares, la actualizaciÃ³n de pares y la confirmaciÃ³n en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark estÃ¡ diseÃ±ado para capturar las caracterÃ­sticas de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicaciÃ³n especÃ­fica. Utilizamos OO7 porque es un punto de referencia estÃ¡ndar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un Ã¡rbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un grÃ¡fico de partes atÃ³micas vinculadas por objetos de conexiÃ³n; cada parte atÃ³mica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atÃ³micas por parte compuesta. La base de datos multiusuario asigna a cada cliente un mÃ³dulo privado que consiste en un Ã¡rbol de objetos de ensamblaje, y agrega un mÃ³dulo compartido adicional que escala proporcionalmente al nÃºmero de clientes. Esperamos que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ© y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la cachÃ©. Dado que el objetivo de nuestro estudio es evaluar quÃ© tan efectivamente nuestras tÃ©cnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras tÃ©cnicas tienen en los fallos de cachÃ© frÃ­o y de consistencia de cachÃ©, y aislar tanto como sea posible el efecto de los fallos de capacidad de cachÃ©. Para mantener la duraciÃ³n de nuestros experimentos razonable, utilizamos cachÃ©s pequeÃ±os. El benchmark OO7 genera mÃ³dulos de base de datos de tamaÃ±o predefinido. En nuestra implementaciÃ³n de OO7, el tamaÃ±o del mÃ³dulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la cachÃ©, utilizamos un Ãºnico mÃ³dulo privado y elegimos un tamaÃ±o de cachÃ© de 40MB para cada cliente. La base de datos OO7 se genera con mÃ³dulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos estÃ¡n agrupados en pÃ¡ginas de 8K, que tambiÃ©n son la unidad de transferencia en las solicitudes de recuperaciÃ³n. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro anÃ¡lisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idÃ©ntico a T1 excepto que modifica todas las partes atÃ³micas en un solo compuesto. Una transacciÃ³n Ãºnica incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo mÃ³dulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacciÃ³n, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de bÃºsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una cachÃ© de 50MB (de los cuales 6MB se utilizaron para el bÃºfer de objetos modificados), el cliente tenÃ­a una cachÃ© de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos bÃ¡sicos Esta secciÃ³n analiza el costo bÃ¡sico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 RedirecciÃ³n Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtenciÃ³n del servidor), el costo adicional de la redirecciÃ³n incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperaciÃ³n o confirmaciÃ³n del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmaciÃ³n y recuperaciÃ³n del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de Ã¡rea rÃ¡pida. Todos los nÃºmeros fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirecciÃ³n al cruzar el redireccionador no es muy alto, incluso en una red de Ã¡rea local. El costo de la confirmaciÃ³n aumenta con el nÃºmero de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperaciÃ³n no aumenta tanto porque la cachÃ© del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la cachÃ© del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperaciÃ³n entre pares, medimos la latencia de la recuperaciÃ³n entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperaciÃ³n entre pares, el costo de la redirecciÃ³n incluye, ademÃ¡s del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este Ãºltimo incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la pÃ¡gina solicitada. Medimos directamente el tiempo para copiar y desenrollar la pÃ¡gina solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperaciÃ³n de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador mÃ¡s un viaje de ida y vuelta a travÃ©s de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud mÃ¡s un viaje de ida y vuelta a travÃ©s de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando estÃ¡ bloqueado esperando una respuesta de bÃºsqueda o confirmaciÃ³n. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podrÃ­a ser mitigado por una implementaciÃ³n multi-hilo en un sistema con programaciÃ³n preemptiva. 6.3.2 VersiÃ³n de CachÃ© El commit en solitario permite que un cliente rÃ¡pido que modifica un objeto haga un commit de forma independiente a un compaÃ±ero lento. El mecanismo de confirmaciÃ³n Ãºnica introduce un procesamiento adicional en el servidor durante la validaciÃ³n de la transacciÃ³n, y un procesamiento adicional en el cliente durante la confirmaciÃ³n de la transacciÃ³n y en el momento del procesamiento de actualizaciÃ³n o invalidaciÃ³n. Los gastos generales del lado del servidor son mÃ­nimos y consisten en una actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina en el momento de la confirmaciÃ³n, y una comparaciÃ³n del nÃºmero de versiÃ³n en el momento de la validaciÃ³n de la transacciÃ³n. La cachÃ© de versiÃ³n tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacciÃ³n accede a objetos en mÃºltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor Ãºnico y, por lo tanto, el tiempo de confirmaciÃ³n adicional de la gestiÃ³n de la cachÃ© de versiones en el cliente no contribuye a los resultados presentados en la secciÃ³n a continuaciÃ³n. Para medir estos costos adicionales del lado del cliente en un sistema de mÃºltiples servidores, instrumentamos la implementaciÃ³n de la cachÃ© de versiones para ejecutarse con una traza de carga de trabajo que incluÃ­a invalidaciones reordenadas y cronometramos las operaciones bÃ¡sicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operaciÃ³n de bÃºsqueda de cachÃ© de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n en el momento de preparaciÃ³n de la solicitud de compromiso, y una operaciÃ³n de inserciÃ³n de cachÃ© de versiÃ³n para cada objeto actualizado por una transacciÃ³n en el momento de procesamiento de la respuesta de compromiso, pero solo si la pÃ¡gina actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmaciÃ³n se mantengan al mÃ­nimo, ya que el cliente estÃ¡ esperando de forma sÃ­ncrona la finalizaciÃ³n de la confirmaciÃ³n. Las mediciones muestran que en el peor de los casos, cuando llega un gran nÃºmero de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en pÃ¡ginas reordenadas, el costo de actualizar la cachÃ© de versiÃ³n es de 0.6 ms. El costo de tiempo de invalidaciÃ³n es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementaciÃ³n de la cachÃ© de versiones para reducir aÃºn mÃ¡s estos costos. 6.4 Rendimiento general Esta secciÃ³n examina las mejoras de rendimiento observadas por una aplicaciÃ³n que ejecuta el benchmark OO7 con un BuddyCache en una red de Ã¡rea amplia. 6.4.1 Fallos en frÃ­o Para evaluar las mejoras de rendimiento al evitar fallos en frÃ­o, comparamos el rendimiento de la cachÃ© en frÃ­o del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecuciÃ³n de los sistemas en el entorno de la red de Ã¡rea local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de Ã¡rea amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en cachÃ© frÃ­a. Los nÃºmeros fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frÃ­o solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frÃ­o solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparaciÃ³n con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cÃ¡lculos para el cliente, solicitudes de recuperaciÃ³n directa, recuperaciones de pares y solicitudes de confirmaciÃ³n. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperaciÃ³n entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperaciÃ³n del servidor para cada cliente individual disminuye porque, con mÃ¡s clientes accediendo a un mÃ³dulo compartido de tamaÃ±o fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperaciÃ³n de pares en comparaciÃ³n con la recuperaciÃ³n directa, pero este beneficio se ve contrarrestado por los tiempos de confirmaciÃ³n aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relaciÃ³n con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de cachÃ© 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT funciÃ³n de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias tÃ­picas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Sorprendentemente, los resultados analÃ­ticos predicen la mejora medida muy de cerca, aunque son ligeramente mÃ¡s altos que los valores empÃ­ricos. La razÃ³n principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidaciÃ³n evitados, comparamos el rendimiento de cachÃ© caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interÃ©s de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un Ãºnico cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compaÃ±eros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compaÃ±eros con un grupo que contiene un Ãºnico escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuraciÃ³n simple es suficiente para mostrar el impacto de las tÃ©cnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de cachÃ© caliente de OO7. Obtenemos los nÃºmeros ejecutando 2000 transacciones para filtrar los fallos en frÃ­o y luego medimos el tiempo de las siguientes 1000 transacciones. AquÃ­ nuevamente, los nÃºmeros reportados se derivan de los resultados del experimento de la red de Ã¡rea local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalizaciÃ³n en comparaciÃ³n con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparaciÃ³n con la Base. Este beneficio se debe a la actualizaciÃ³n entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperaciÃ³n entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperaciÃ³n local evitando el retraso de la recuperaciÃ³n desde el servidor. El Ãºltimo es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperaciÃ³n de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperaciÃ³n de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualizaciÃ³n de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relaciÃ³n con Base, y Buddy Writer y Base en relaciÃ³n con Base) en un experimento de cachÃ© activa en funciÃ³n del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualizaciÃ³n entre pares domina el gasto general en la configuraciÃ³n de Writer incluso en redes de baja latencia (la actualizaciÃ³n entre pares incurre en un gasto mÃ­nimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Como en experimentos de cachÃ© frÃ­a, aquÃ­ los resultados analÃ­ticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pÃ©rdida de invalidaciÃ³n es mÃ­nimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de cachÃ© frÃ­a). Como en el caso de cachÃ© frÃ­a, la razÃ³n por la que el modelo analÃ­tico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÃ“N Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en una red de Ã¡rea extensa debido a la alta latencia de red. Este artÃ­culo describe BuddyCache, una nueva tÃ©cnica de almacenamiento en cachÃ© cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La tÃ©cnica mejora el rendimiento y proporciona propiedades sÃ³lidas de correcciÃ³n y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirecciÃ³n para obtener objetos faltantes directamente de las cachÃ©s de los miembros del grupo, y para admitir la actualizaciÃ³n entre pares, una nueva tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirecciÃ³n puede interferir con la disponibilidad del objeto. Solo commit es una nueva tÃ©cnica de validaciÃ³n que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validaciÃ³n detallada utilizando informaciÃ³n de versiÃ³n de grano grueso econÃ³mica. Hemos diseÃ±ado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analÃ­ticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Las principales contribuciones del artÃ­culo son: 1. extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementaciÃ³n del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluaciÃ³n del rendimiento basada en anÃ¡lisis y mediciones de los costos y beneficios de las nuevas tÃ©cnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. TambiÃ©n agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios Ãºtiles que mejoraron este artÃ­culo. 9. REFERENCIAS [1] emulab.net, la InstalaciÃ³n de EmulaciÃ³n de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. ReconstrucciÃ³n de fragmentos: Proporcionando coherencia de cachÃ© global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre GestiÃ³n de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: ComputaciÃ³n en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de cachÃ© hÃ­bridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. RecuperaciÃ³n rÃ¡pida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de cachÃ© en la World Wide Web. En la 17Âª Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluaciÃ³n del rendimiento del sistema de gestiÃ³n de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una cachÃ© de objetos jerÃ¡rquica en Internet. En la Conferencia TÃ©cnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachÃ©s de Internet escalables. Informe TÃ©cnico CS-1997-18, Departamento de Ciencias de la ComputaciÃ³n, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: CachÃ© de proxy cooperativa en una red de Ã¡rea amplia. En el Tercer Taller Internacional de CachÃ© de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. CachÃ© web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2Âº Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. CachÃ© cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilaciÃ³n y en tiempo de ejecuciÃ³n para una memoria compartida distribuida eficiente. En Actas de IEEE, EdiciÃ³n Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la cachÃ©: un protocolo de intercambio de cachÃ© web escalable de Ã¡rea amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. ImplementaciÃ³n de GestiÃ³n Global de Memoria en un ClÃºster de Estaciones de Trabajo. Actas del 15Âº Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: DiseÃ±o, ImplementaciÃ³n y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de cachÃ© transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, pÃ¡ginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. GestiÃ³n global de memoria para arquitecturas de sistemas de gestiÃ³n de bases de datos cliente-servidor. En Actas del 19Âº Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El BÃºfer de Objeto Modificado: Una TÃ©cnica de GestiÃ³n de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto TecnolÃ³gico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. GestiÃ³n de documentos replicados en un sistema de comunicaciÃ³n grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13Âª Conferencia Europea sobre ProgramaciÃ³n Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18Âº Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. ReplicaciÃ³n con marca de vista: un nuevo mÃ©todo de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de ComputaciÃ³n Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalaciÃ³n eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de MultidifusiÃ³n a Nivel de AplicaciÃ³n. En el 3er Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de cachÃ© cooperativa utilizando pistas. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en CachÃ© Global. Informe tÃ©cnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del CachÃ© de Proxies Web Cooperativos. En el 17Âº Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerÃ¡rquica de cachÃ© en una WAN. En el Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. ComparticiÃ³n adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÃ‰NDICE Este apÃ©ndice describe el protocolo de conmutaciÃ³n por error de BuddyCache. Para dar cabida a clientes heterogÃ©neos, incluidos los dispositivos portÃ¡tiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseÃ±o de BuddyCache asume que las cachÃ©s del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresÃ­a detecta el fallo de un cliente o un redireccionador intercambiando mensajes periÃ³dicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutaciÃ³n por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuraciÃ³n y reinicia el protocolo. El protocolo de reconfiguraciÃ³n del grupo es similar al presentado en [25]. AquÃ­ describimos cÃ³mo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de pÃ¡ginas redireccionadas y el reenvÃ­o de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachÃ©s. En caso de un fallo del cliente, el failover elimina las pÃ¡ginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmaciÃ³n, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en cachÃ© las pÃ¡ginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutaciÃ³n por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de pÃ¡ginas utilizando un protocolo similar al descrito en [6]. El redireccionador reciÃ©n reiniciado solicita a los miembros activos del grupo la lista de pÃ¡ginas que estÃ¡n almacenando en cachÃ© y el estado de estas pÃ¡ginas, es decir, si las pÃ¡ginas estÃ¡n completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperaciÃ³n perdida expirarÃ¡ en el cliente y serÃ¡ retransmitida. Una transacciÃ³n que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma despuÃ©s del cambio se trata como una transacciÃ³n regular; una transacciÃ³n que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciarÃ¡ la transacciÃ³n y la solicitud de confirmaciÃ³n serÃ¡ retransmitida despuÃ©s del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caÃ­do podrÃ­an evitar la recolecciÃ³n de basura de las invalidaciones pendientes en los servidores o la cachÃ© virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los nÃºmeros de versiÃ³n Ãºnicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validaciÃ³n de transacciones depende del protocolo de coherencia de cachÃ© para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutaciÃ³n por error de BuddyCache no compromete la correcciÃ³n del procedimiento de validaciÃ³n. Recuerda que la validaciÃ³n de transacciones de BuddyCache utiliza dos mecanismos complementarios, nÃºmeros de versiÃ³n de pÃ¡gina y confirmaciones de invalidaciÃ³n de los clientes, para verificar que una transacciÃ³n ha leÃ­do datos actualizados. La propagaciÃ³n de la confirmaciÃ³n de invalidaciÃ³n (y actualizaciÃ³n) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmaciÃ³n de una modificaciÃ³n (invalidaciÃ³n o actualizaciÃ³n) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en cachÃ© el objeto o bien ha instalado el valor mÃ¡s reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmaciÃ³n de un cliente para una transacciÃ³n T que lee un objeto o despuÃ©s de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidaciÃ³n no confirmada para o pendiente para este grupo, la versiÃ³n del objeto leÃ­da por la transacciÃ³n T estÃ¡ actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validaciÃ³n utilizando nÃºmeros de versiÃ³n. El registro de confirmaciÃ³n de transacciÃ³n contiene un nÃºmero de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n. El protocolo de nÃºmero de versiÃ³n mantiene la invariante V P que garantiza que el valor del objeto o leÃ­do por la transacciÃ³n corresponda al nÃºmero de versiÃ³n mÃ¡s alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificaciÃ³n anterior despuÃ©s de haber recibido una modificaciÃ³n posterior. La retransmisiÃ³n de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validaciÃ³n verifica que el nÃºmero de versiÃ³n en el registro de confirmaciÃ³n coincida con el nÃºmero de versiÃ³n en la invalidaciÃ³n pendiente no reconocida. Es fÃ¡cil ver que, dado que esta comprobaciÃ³n es una comprobaciÃ³n cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutaciÃ³n por error aÃºn no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "transaction": {
            "translated_key": "transacciÃ³n",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a <br>transaction</br>, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide <br>transaction</br> durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "<br>transaction</br> can read and update locally cached objects without server intervention.",
                "However, before a <br>transaction</br> commits it must be validated; the server must make sure the validating <br>transaction</br> has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the <br>transaction</br> is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client <br>transaction</br> if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the <br>transaction</br> commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a <br>transaction</br>.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a <br>transaction</br> T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a <br>transaction</br> even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the <br>transaction</br> read sets in the commit message, to indicate to the server the objects read by the <br>transaction</br> are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at <br>transaction</br> that modifies objects on the page commits.",
                "Updates committed by a single <br>transaction</br> and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a <br>transaction</br> fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the <br>transaction</br> read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a <br>transaction</br>.",
                "The servers have a disk for storing persistent objects, a stable <br>transaction</br> log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its <br>transaction</br>; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the <br>transaction</br>.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the <br>transaction</br> used objects at multiple servers.",
                "If the <br>transaction</br> commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a <br>transaction</br> commit can cause caches to contain obsolete objects.",
                "Servers will abort a <br>transaction</br> that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing <br>transaction</br> to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current <br>transaction</br> if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a <br>transaction</br> aborts, its client restores the cached copies of modified objects to the state they had before the <br>transaction</br> started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a <br>transaction</br>, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a <br>transaction</br> commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the <br>transaction</br> generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a <br>transaction</br> T to pass validation if extra coherence information supplied by the client indicates that <br>transaction</br> T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client <br>transaction</br> has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a <br>transaction</br> T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the <br>transaction</br> that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a <br>transaction</br> that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the <br>transaction</br> coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at <br>transaction</br> commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a <br>transaction</br> and compute in a <br>transaction</br>, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client <br>transaction</br> has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single <br>transaction</br> in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of <br>transaction</br> workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single <br>transaction</br> includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every <br>transaction</br>, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at <br>transaction</br> validation time, and extra processing at the client at <br>transaction</br> commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at <br>transaction</br> validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a <br>transaction</br> accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the <br>transaction</br> at commit request preparation time, and a version cache insert operation for each object updated by a <br>transaction</br> at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A <br>transaction</br> running at the client during a failover and committing after the failover is treated as a regular <br>transaction</br>, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the <br>transaction</br> and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the <br>transaction</br> validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache <br>transaction</br> validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a <br>transaction</br> has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a <br>transaction</br> T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the <br>transaction</br> T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The <br>transaction</br> commit record contains a version number for each object read by the <br>transaction</br>.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the <br>transaction</br> corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "The three types of client server interactions in a transactional caching protocol are the commit of a <br>transaction</br>, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "The redirector always interacts with the servers at commit time because only storage servers provide <br>transaction</br> durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "<br>transaction</br> can read and update locally cached objects without server intervention.",
                "However, before a <br>transaction</br> commits it must be validated; the server must make sure the validating <br>transaction</br> has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the <br>transaction</br> is aborted."
            ],
            "translated_annotated_samples": [
                "Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una <br>transacciÃ³n</br>, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©.",
                "El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de <br>transacciones</br> de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador.",
                "La <br>transacciÃ³n</br> puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor.",
                "Sin embargo, antes de que una <br>transacciÃ³n</br> se confirme, debe ser validada; el servidor debe asegurarse de que la <br>transacciÃ³n</br> validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada.",
                "Si la validaciÃ³n falla, la <br>transacciÃ³n</br> se cancela."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de Ã¡rea amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de Ã¡rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil. Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en cachÃ© web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos. Sin embargo, las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica. La interacciÃ³n con el servidor aumenta la latencia. La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia. Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n. Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo. BuddyCache presenta dos desafÃ­os tÃ©cnicos principales. Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©. El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de almacenamiento en cachÃ© web cooperativos [11]. Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo. BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos. Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica. Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad? DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red. Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia. El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida. Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache. Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n. Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos. Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de Ã¡rea amplia. Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad. Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un Ãºnico servidor. Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web. El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en cachÃ© transaccional [19]. La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una <br>transacciÃ³n</br>, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador. El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de <br>transacciones</br> de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado. AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©. Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina). La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente. El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento. A continuaciÃ³n, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene. La <br>transacciÃ³n</br> puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor. Sin embargo, antes de que una <br>transacciÃ³n</br> se confirme, debe ser validada; el servidor debe asegurarse de que la <br>transacciÃ³n</br> validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada. Si la validaciÃ³n falla, la <br>transacciÃ³n</br> se cancela. ",
            "candidates": [],
            "error": [
                [
                    "transacciÃ³n",
                    "transacciones",
                    "transacciÃ³n",
                    "transacciÃ³n",
                    "transacciÃ³n",
                    "transacciÃ³n"
                ]
            ]
        },
        "fault-tolerance properties": {
            "translated_key": "tolerancia a fallos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and <br>fault-tolerance properties</br> of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and <br>fault-tolerance properties</br> ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "BuddyCache redirector supports the correctness, availability and <br>fault-tolerance properties</br> of transactional caching protocol [19].",
                "The availability and <br>fault-tolerance properties</br> ensure that a crashed or slow client does not disrupt any other clients access to persistent objects."
            ],
            "translated_annotated_samples": [
                "El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y <br>tolerancia a fallos</br> del protocolo de almacenamiento en cachÃ© transaccional [19].",
                "Las propiedades de disponibilidad y <br>tolerancia a fallos</br> garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de Ã¡rea amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de Ã¡rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil. Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en cachÃ© web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos. Sin embargo, las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica. La interacciÃ³n con el servidor aumenta la latencia. La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia. Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n. Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo. BuddyCache presenta dos desafÃ­os tÃ©cnicos principales. Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©. El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de almacenamiento en cachÃ© web cooperativos [11]. Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo. BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos. Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica. Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad? DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red. Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia. El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida. Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache. Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n. Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos. Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de Ã¡rea amplia. Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad. Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un Ãºnico servidor. Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web. El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y <br>tolerancia a fallos</br> del protocolo de almacenamiento en cachÃ© transaccional [19]. La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y <br>tolerancia a fallos</br> garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una transacciÃ³n, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador. El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado. AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©. Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina). La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente. El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento. A continuaciÃ³n, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene. La transacciÃ³n puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor. Sin embargo, antes de que una transacciÃ³n se confirme, debe ser validada; el servidor debe asegurarse de que la transacciÃ³n validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada. Si la validaciÃ³n falla, la transacciÃ³n se cancela. Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de bÃºsqueda de pares envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la cachÃ© y envÃ­an confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la cachÃ© del cliente, la confirmaciÃ³n de invalidaciÃ³n indica al servidor que un cliente sin invalidaciones pendientes ha leÃ­do objetos actualizados. Una invalidaciÃ³n no reconocida indica que un objeto obsoleto puede haber sido accedido en la cachÃ© del cliente. El procedimiento de validaciÃ³n en el servidor aborta una transacciÃ³n del cliente si este lee un objeto mientras hay una invalidaciÃ³n pendiente. El mecanismo de invalidaciÃ³n reconocido admite coherencia de cachÃ© a nivel de objeto sin directorios basados en objetos o nÃºmeros de versiÃ³n por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeÃ±os, ya que los objetos tÃ­picos son pequeÃ±os. Un objetivo importante del diseÃ±o de BuddyCache es mantener este beneficio. Dado que en BuddyCache una pÃ¡gina puede ser recuperada en una cachÃ© de cliente sin intervenciÃ³n del servidor (como se ilustra en la figura 2), los directorios de cachÃ© en los servidores llevan un registro de las pÃ¡ginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las pÃ¡ginas almacenadas en cachÃ© en cada cliente de un grupo. Los servidores envÃ­an al redireccionador invalidaciones para las pÃ¡ginas almacenadas en cachÃ© en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. ActualizaciÃ³n de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en cachÃ© por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interÃ©s potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de cachÃ© y las actualizaciones de cachÃ©. Los estudios de coherencia de cachÃ© en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualizaciÃ³n y la invalidaciÃ³n. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. AlmacÃ©n x 6. ActualizaciÃ³n x 3. CompromÃ©tete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares estÃ¡n fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeÃ±as, agrupadas y se envÃ­an junto con otros mensajes. AdemÃ¡s, los protocolos de invalidaciÃ³n se ajustan a la tendencia actual de hardware de aumentar los tamaÃ±os de cachÃ© del cliente. Es probable que las cachÃ©s mÃ¡s grandes contengan mucha mÃ¡s informaciÃ³n de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una red de Ã¡rea amplia serÃ­an derrochadores. Sin embargo, los protocolos de coherencia basados en invalidaciÃ³n pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interÃ©s para otro miembro del grupo. Con un protocolo basado en invalidaciÃ³n, la actualizaciÃ³n de un miembro invalidarÃ¡ la copia en cachÃ© de otro miembro, lo que provocarÃ¡ que este Ãºltimo realice una recuperaciÃ³n de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualizaciÃ³n e invalidaciÃ³n en entornos de redes de Ã¡rea amplia. Evita la penalizaciÃ³n de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalizaciÃ³n de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusiÃ³n localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en cachÃ© anteriores. La actualizaciÃ³n entre pares funciona de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que la transacciÃ³n se confirma, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n, y tambiÃ©n propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmaciÃ³n. 3.3 ConfirmaciÃ³n individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminaciÃ³n de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en cachÃ© transaccional, ya que un cliente que es lento para reconocer una invalidaciÃ³n o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacciÃ³n. Por ejemplo, un ingeniero que realiza una revisiÃ³n repetida al mismo objeto de diseÃ±o compartido (y por lo tanto tiene la Ãºltima versiÃ³n del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situaciÃ³n representada en la figura 4 donde el Cliente1 realiza una transacciÃ³n T que lee la Ãºltima versiÃ³n de un objeto x en la pÃ¡gina P recientemente modificada por el Cliente1. Si la solicitud de confirmaciÃ³n para T llega al servidor antes de que la confirmaciÃ³n colectiva de Cliente2 por la Ãºltima modificaciÃ³n de x llegue al servidor, el procedimiento de validaciÃ³n de OCC considera que x estÃ¡ obsoleto y aborta T (porque, como se explicÃ³ anteriormente, una invalidaciÃ³n no reconocida por un cliente actÃºa como indicaciÃ³n para el servidor de que el valor del objeto en cachÃ© estÃ¡ obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la correcciÃ³n del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asÃ­ncronas son una parte importante de la razÃ³n por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasiÃ³n de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envÃ­an y procesan de forma asÃ­ncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devoluciÃ³n de llamada jerÃ¡rquica [32], pero la naturaleza asincrÃ³nica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrÃ³nicas. El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a un cliente con objetos actualizados confirmar una transacciÃ³n incluso si la confirmaciÃ³n del grupo se retrasa debido a pares lentos o caÃ­dos. El protocolo requiere que los clientes incluyan informaciÃ³n adicional con los conjuntos de lectura de transacciones en el mensaje de confirmaciÃ³n, para indicar al servidor que los objetos leÃ­dos por la transacciÃ³n estÃ¡n actualizados. Los nÃºmeros de versiÃ³n de los objetos podrÃ­an proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionÃ³ anteriormente, mantener nÃºmeros de versiÃ³n por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaÃ±o de directorio) en todo el sistema de objetos cuando los objetos son pequeÃ±os [23]. En cambio, solo utiliza nÃºmeros de versiÃ³n de pÃ¡gina de grano grueso para identificar versiones de objetos de grano fino. El nÃºmero de versiÃ³n de una pÃ¡gina se incrementa en un servidor cuando una transacciÃ³n que modifica objetos en la pÃ¡gina se confirma. Las actualizaciones realizadas por una Ãºnica transacciÃ³n y las invalidaciones correspondientes son identificadas de manera Ãºnica por el nÃºmero de versiÃ³n de la pÃ¡gina modificada. Los nÃºmeros de versiÃ³n de la pÃ¡gina se propagan a los clientes en respuestas de recuperaciÃ³n, respuestas de confirmaciÃ³n y con invalidaciones, y los clientes incluyen los nÃºmeros de versiÃ³n de la pÃ¡gina en las solicitudes de confirmaciÃ³n enviadas a los servidores. Si una transacciÃ³n falla en la validaciÃ³n debido a la falta de reconocimiento de grupo, el servidor verifica los nÃºmeros de versiÃ³n de pÃ¡gina de los objetos en el conjunto de lectura de la transacciÃ³n y permite que la transacciÃ³n se confirme si el cliente ha leÃ­do desde la Ãºltima versiÃ³n de la pÃ¡gina. Los nÃºmeros de versiÃ³n de la pÃ¡gina permiten confirmaciones independientes, pero las verificaciones de versiÃ³n de pÃ¡gina solo detectan conflictos a nivel de pÃ¡gina. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La secciÃ³n 4 describe los detalles de la implementaciÃ³n del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 ConfiguraciÃ³n de Grupo La arquitectura BuddyCache admite mÃºltiples grupos de pares concurrentes. Potencialmente, puede ser mÃ¡s rÃ¡pido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podrÃ­a ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en cachÃ© de pares de mÃºltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en cachÃ© web, simplemente aumentar la poblaciÃ³n de clientes en una cachÃ© proxy a menudo aumenta la tasa general de aciertos en la cachÃ© [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacciÃ³n explÃ­cita entre clientes y la colaboraciÃ³n, lo que sugiere que es poco probable que ocurra la recuperaciÃ³n entre grupos. AdemÃ¡s, las mediciones de sistemas de almacenamiento en cachÃ© web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexiÃ³n de red entre los grupos de pares sea muy rÃ¡pida. Estamos principalmente interesados en entornos donde compaÃ±eros que colaboran estrechamente tienen una conectividad rÃ¡pida a corta distancia, pero la conexiÃ³n entre grupos de compaÃ±eros puede ser lenta. Como resultado, decidimos que el soporte para la recuperaciÃ³n entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compaÃ±eros con recursos heterogÃ©neos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compaÃ±eros o, cuando estÃ© disponible, en un nodo separado dentro de la infraestructura del sitio. AdemÃ¡s, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una cachÃ© de pares en espera para recibir pÃ¡ginas recuperadas por otros pares, emulando una cachÃ© central algo similar a una cachÃ© de proxy web regional. Desde el punto de vista del protocolo de coherencia de cachÃ© BuddyCache, sin embargo, un cachÃ© de compaÃ±ero en espera es equivalente a un cachÃ© de compaÃ±ero regular y, por lo tanto, no consideramos este caso por separado en la discusiÃ³n de este documento. 4. En esta secciÃ³n proporcionamos los detalles de la implementaciÃ³n de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en cachÃ© de estos objetos. Las aplicaciones se ejecutan en los clientes e interactÃºan con el sistema realizando llamadas a mÃ©todos de objetos en cachÃ©. Todas las llamadas a mÃ©todos ocurren dentro de transacciones atÃ³micas. Los clientes se comunican con los servidores para obtener pÃ¡ginas o realizar una transacciÃ³n. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volÃ¡til. El disco estÃ¡ organizado como una colecciÃ³n de pÃ¡ginas que son las unidades de acceso al disco. El registro estable guarda la informaciÃ³n de confirmaciÃ³n y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de cachÃ© y una cachÃ© de objetos modificados recuperable llamada MOB. El directorio lleva un registro de quÃ© pÃ¡ginas estÃ¡n almacenadas en cachÃ© por quÃ© clientes. El MOB contiene objetos recientemente modificados que aÃºn no han sido escritos de vuelta en sus pÃ¡ginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de cachÃ© base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la SecciÃ³n 3.1. Proporcionamos algunos de los detalles relevantes de la implementaciÃ³n del protocolo OCC. El cliente lleva un registro de los objetos que son leÃ­dos y modificados por su transacciÃ³n; envÃ­a esta informaciÃ³n, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacciÃ³n. Los servidores determinan si la confirmaciÃ³n es posible, utilizando un protocolo de confirmaciÃ³n de dos fases si la transacciÃ³n utilizÃ³ objetos en mÃºltiples servidores. Si la transacciÃ³n se lleva a cabo, las nuevas copias de los objetos modificados se aÃ±aden al registro y tambiÃ©n se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperaciÃ³n escaneando el registro. Dado que los objetos no estÃ¡n bloqueados antes de ser utilizados, una confirmaciÃ³n de transacciÃ³n puede hacer que las cachÃ©s contengan objetos obsoletos. Los servidores abortarÃ¡n una transacciÃ³n que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviÃ¡ndoles mensajes de invalidaciÃ³n; un servidor utiliza su directorio y la informaciÃ³n sobre la transacciÃ³n de confirmaciÃ³n para determinar quÃ© mensajes de invalidaciÃ³n enviar. Los mensajes de invalidaciÃ³n son pequeÃ±os porque simplemente identifican objetos obsoletos. AdemÃ¡s, se envÃ­an en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidaciÃ³n, elimina los objetos obsoletos de su cachÃ© y aborta la transacciÃ³n actual si los utilizÃ³. El cliente sigue conservando pÃ¡ginas que contienen objetos invalidados; estas pÃ¡ginas ahora estÃ¡n incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidaciÃ³n de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener pÃ¡ginas incompletas en la cachÃ© del cliente significa que el falso intercambio no conduce a fallos innecesarios en la cachÃ©. Los clientes reconocen las invalidaciones para indicar la eliminaciÃ³n de datos obsoletos, como se explica en la SecciÃ³n 3.1. Los mensajes de invalidaciÃ³n evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo asÃ­ el desperdicio de trabajo y trasladando la detecciÃ³n de abortos de los servidores a los clientes. Cuando una transacciÃ³n se aborta, su cliente restaura las copias en cachÃ© de los objetos modificados al estado que tenÃ­an antes de que la transacciÃ³n comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacciÃ³n. 4.3 RedirecciÃ³n El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de pÃ¡ginas disponibles en el grupo de pares y proporciona una redirecciÃ³n rÃ¡pida y centralizada de recuperaciÃ³n (ver figura 2) entre las cachÃ©s de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan pÃ¡ginas u objetos al incluir esa informaciÃ³n en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la cachÃ© de grupo, el redireccionador realiza un seguimiento del estado de las pÃ¡ginas. Una pÃ¡gina en cachÃ© estÃ¡ completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una pÃ¡gina estÃ¡n marcados como invÃ¡lidos. Solo se utilizan pÃ¡ginas completas por el proceso de recuperaciÃ³n de pares. El protocolo para mantener el estado de la pÃ¡gina cuando las pÃ¡ginas son actualizadas e invalidadas se describe en la SecciÃ³n 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una pÃ¡gina solicitada completa no estÃ¡ disponible en el grupo de pares o si un par necesita confirmar una transacciÃ³n, el redireccionador actÃºa como un proxy de servidor: reenvÃ­a la solicitud al servidor y luego reenvÃ­a la respuesta de vuelta al cliente. AdemÃ¡s, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualizaciÃ³n o informaciÃ³n de invalidaciÃ³n a los clientes que tienen en cachÃ© la pÃ¡gina modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la cachÃ© de grupo de pares combinada estÃ¡ desempeÃ±ando el papel de una Ãºnica cachÃ© de cliente en el sistema base. 4.4 ActualizaciÃ³n de pares La actualizaciÃ³n de pares se implementa de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que una transacciÃ³n se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacciÃ³n generan invalidaciones de objetos para cada grupo de cachÃ© que almacena pÃ¡ginas que contienen los objetos modificados (incluido el grupo que realiza la confirmaciÃ³n). Las invalidaciones se envÃ­an de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en cachÃ© los objetos modificados se deshagan de los datos obsoletos. En grupos de cachÃ© distintos al grupo de confirmaciÃ³n, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas, recopilan las confirmaciones de los clientes y, despuÃ©s de completar la recopilaciÃ³n, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacciÃ³n, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envÃ­an a los clientes que almacenan en cachÃ© esas pÃ¡ginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmaciÃ³n colectiva se propaga al servidor. Una invalidaciÃ³n hace que una pÃ¡gina en cachÃ© no estÃ© disponible para la recuperaciÃ³n de pares, cambiando el estado de una pÃ¡gina completa p a incompleta. Por el contrario, una actualizaciÃ³n de una pÃ¡gina completa conserva el estado completo de la pÃ¡gina. Como se muestra en los estudios de la reconstrucciÃ³n de fragmentos 31 [2], esta propagaciÃ³n de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma pÃ¡gina, la pÃ¡gina conserva su estado completo y permanece disponible para la recuperaciÃ³n entre pares. Por lo tanto, el efecto de la actualizaciÃ³n de pares es similar a la reconstrucciÃ³n de fragmentos ansiosa [2]. TambiÃ©n hemos considerado la posibilidad de permitir que un compaÃ±ero recupere una pÃ¡gina incompleta (con objetos invÃ¡lidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos invÃ¡lidos. 4.5 Vcache El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo mÃ¡s lentos (o fallidos). Como se explica en la SecciÃ³n 3.3, el protocolo de commit Ãºnico permite que una transacciÃ³n T pase la validaciÃ³n si la informaciÃ³n adicional de coherencia proporcionada por el cliente indica que la transacciÃ³n T ha leÃ­do objetos actualizados. Los clientes utilizan los nÃºmeros de versiÃ³n de la pÃ¡gina para proporcionar esta informaciÃ³n adicional de coherencia. Es decir, un cliente incluye el nÃºmero de versiÃ³n de la pÃ¡gina correspondiente a cada objeto en el conjunto de objetos leÃ­dos enviado en la solicitud de confirmaciÃ³n al servidor. Dado que a cada actualizaciÃ³n de objeto comprometido le corresponde un nÃºmero de versiÃ³n de pÃ¡gina Ãºnico, el nÃºmero de versiÃ³n de pÃ¡gina asociado con un objeto permite que el procedimiento de validaciÃ³n en el servidor verifique si la transacciÃ³n del cliente ha leÃ­do objetos actualizados. El uso de versiones de pÃ¡gina de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeÃ±os, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en cachÃ© a la versiÃ³n de pÃ¡gina identificadora (ObjectToVersion). El principal problema de implementaciÃ³n se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian nÃºmeros de versiÃ³n de pÃ¡gina con las invalidaciones. En el momento de la validaciÃ³n, si hay una invalidaciÃ³n no reconocida pendiente para un objeto x leÃ­do por una transacciÃ³n T, el procedimiento de validaciÃ³n verifica si el nÃºmero de versiÃ³n de x en el conjunto de lectura de Ts coincide con el nÃºmero de versiÃ³n de la invalidaciÃ³n pendiente mÃ¡s alta para x, en cuyo caso el valor del objeto estÃ¡ actualizado, de lo contrario, T falla en la validaciÃ³n. Observamos nuevamente que las verificaciones basadas en el nÃºmero de versiÃ³n de la pÃ¡gina y las verificaciones basadas en el reconocimiento de invalidaciÃ³n son complementarias en la validaciÃ³n de confirmaciÃ³n individual y ambas son necesarias. La verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina permite que la validaciÃ³n avance antes de que lleguen las confirmaciones de invalidaciÃ³n, pero por sÃ­ sola, una verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina detecta conflictos a nivel de pÃ¡gina y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cÃ³mo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un nÃºmero de versiÃ³n de la pÃ¡gina para cada pÃ¡gina en cachÃ©. El nÃºmero de versiÃ³n satisface la siguiente invariante V P sobre el estado de los objetos en una pÃ¡gina: si una pÃ¡gina en cachÃ© P tiene un nÃºmero de versiÃ³n v, entonces el valor de un objeto o en la pÃ¡gina en cachÃ© P es invÃ¡lido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacciÃ³n que estableciÃ³ el nÃºmero de versiÃ³n de P en v. Los nuevos valores de objetos y los nuevos nÃºmeros de versiÃ³n de pÃ¡gina llegan cuando un cliente obtiene una pÃ¡gina o cuando llega una respuesta de confirmaciÃ³n o invalidaciones para esta pÃ¡gina. Los nuevos valores del objeto modifican la pÃ¡gina y, por lo tanto, el nÃºmero de versiÃ³n de la pÃ¡gina necesita ser actualizado para mantener la invariante V P. Un nÃºmero de versiÃ³n de pÃ¡gina que llega cuando un cliente obtiene una pÃ¡gina, reemplaza la VersiÃ³n del Objeto x 8 Servidor de RedirecciÃ³n 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el nÃºmero de versiÃ³n de la pÃ¡gina para esta pÃ¡gina. Tal actualizaciÃ³n preserva el invariante V P. De manera similar, un nÃºmero de versiÃ³n de pÃ¡gina en secuencia que llega al cliente en un mensaje de confirmaciÃ³n o invalidaciÃ³n avanza el nÃºmero de versiÃ³n para toda la pÃ¡gina en cachÃ©, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus nÃºmeros de versiÃ³n de pÃ¡gina correspondientes tambiÃ©n pueden llegar al cliente fuera de secuencia, en cuyo caso la actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina podrÃ­a violar V P. Por ejemplo, una respuesta de confirmaciÃ³n para una transacciÃ³n que actualiza el objeto x en la pÃ¡gina P en el servidor S1, y el objeto y en la pÃ¡gina Q en el servidor S2, puede entregar un nuevo nÃºmero de versiÃ³n para P desde el coordinador de transacciones S1 antes de que llegue una invalidaciÃ³n generada para una transacciÃ³n anterior que ha modificado el objeto r en la pÃ¡gina P desde S1 (como se muestra en la figura 5). El protocolo de actualizaciÃ³n de cachÃ© garantiza que el valor de cualquier objeto o en una pÃ¡gina en cachÃ© P refleje la actualizaciÃ³n o invalidaciÃ³n con el nÃºmero de versiÃ³n observado mÃ¡s alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de nÃºmeros de versiÃ³n de pÃ¡gina, el cliente gestiona una pequeÃ±a cachÃ© de nÃºmeros de versiÃ³n vcache que mantiene el mapeo de un objeto a su nÃºmero de versiÃ³n de pÃ¡gina correspondiente para todas las actualizaciones de nÃºmeros de versiÃ³n reordenadas hasta que se ensamble una secuencia completa de nÃºmeros de versiÃ³n de pÃ¡gina. Cuando llegan los nÃºmeros de versiÃ³n faltantes para la pÃ¡gina y completan una secuencia, el nÃºmero de versiÃ³n de toda la pÃ¡gina se avanza. El mapeo de ObjectToVersion, incluyendo los nÃºmeros de versiÃ³n de vcache y pÃ¡gina, se utiliza en el momento de la confirmaciÃ³n de la transacciÃ³n para proporcionar nÃºmeros de versiÃ³n para el conjunto de objetos leÃ­dos de la siguiente manera. Si el objeto leÃ­do tiene una entrada en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n mÃ¡s alto en la vcache para este objeto. Si el objeto no estÃ¡ presente en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n de la pÃ¡gina en cachÃ© que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la cachÃ© del cliente, incluyendo los nÃºmeros de versiÃ³n de las pÃ¡ginas y la vcache. El cliente puede limitar el tamaÃ±o de la cachÃ© virtual segÃºn sea necesario, ya que volver a cargar una pÃ¡gina elimina todos los nÃºmeros de versiÃ³n de pÃ¡gina reordenados de la cachÃ© virtual. Sin embargo, esperamos que la reorganizaciÃ³n de nÃºmeros de versiÃ³n sea poco comÃºn y, por lo tanto, esperamos que la vcache sea muy pequeÃ±a. 5. Un grupo de clientes contiene mÃºltiples nodos de cliente y un objeto de pÃ¡gina de versiÃ³n redi32 VCache Cliente CachÃ© Cliente PÃ¡gina CachÃ© Figura 6: Mapa de Objeto a VersiÃ³n con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutaciÃ³n por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. AdemÃ¡s, el fallo del redireccionador deberÃ­a permitir que los clientes no afectados mantengan sus cachÃ©s intactas. Hemos diseÃ±ado un protocolo de conmutaciÃ³n por error para BuddyCache pero aÃºn no lo hemos implementado. El apÃ©ndice describe el protocolo. 6. La redirecciÃ³n de BuddyCache en la evaluaciÃ³n de rendimiento respalda los beneficios de evitar la comunicaciÃ³n con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes. Â¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 AnÃ¡lisis Los beneficios de rendimiento de la recuperaciÃ³n entre pares y la actualizaciÃ³n entre pares se deben a la evitaciÃ³n de interacciones con el servidor. Esta secciÃ³n presenta un modelo de rendimiento analÃ­tico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la cachÃ© del cliente. Estos pueden ser fallos frÃ­os, fallos de invalidaciÃ³n y fallos de capacidad. Nuestro anÃ¡lisis se centra en los fallos por frÃ­o y los fallos por invalidaciÃ³n, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frÃ­o. AdemÃ¡s, las tendencias tecnolÃ³gicas indican que la capacidad de memoria y almacenamiento seguirÃ¡ creciendo y, por lo tanto, es probable que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ©. Los fallos de cachÃ© del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuraciÃ³n de cachÃ©. Nuestro anÃ¡lisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validaciÃ³n. Para estudiar el beneficio de evitar fallos en frÃ­o, consideramos el rendimiento de la cachÃ© en frÃ­o en una carga de trabajo de solo lectura (sin fallos de invalidaciÃ³n). Esperamos que la recuperaciÃ³n entre pares mejore el costo de latencia para las solicitudes de cachÃ© frÃ­a del cliente al recuperar objetos de la cachÃ© cercana. Evaluamos cÃ³mo el costo de redirecciÃ³n afecta este beneficio al comparar y analizar el rendimiento de una aplicaciÃ³n que se ejecuta en un sistema de almacenamiento con BuddyCache y sin Ã©l (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidaciÃ³n, consideramos el rendimiento de la cachÃ© caliente en una carga de trabajo con modificaciones (sin fallos en frÃ­o). En las cachÃ©s calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualizaciÃ³n entre pares permite que un cliente acceda a un objeto modificado por un compaÃ±ero colaborador cercano sin el retraso impuesto por los protocolos de invalidaciÃ³n Ãºnicamente. En grupos donde los compaÃ±eros comparten un interÃ©s de solo lectura en los objetos modificados, la recuperaciÃ³n entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compaÃ±ero colaborador lo tenga, lo que evita el retraso de la recuperaciÃ³n del servidor sin el alto costo impuesto por los protocolos de solo actualizaciÃ³n. Las tendencias tecnolÃ³gicas indican que ambos beneficios seguirÃ¡n siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualizaciÃ³n Ãºnicamente. Sin embargo, la tendencia hacia cachÃ©s cada vez mÃ¡s grandes, que se actualizan cuando los objetos en cachÃ© son modificados, hace que los protocolos basados en invalidaciÃ³n sean mÃ¡s atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicaciÃ³n que se ejecuta sin BuddyCache y una aplicaciÃ³n que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compaÃ±ero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compaÃ±ero fuera del grupo. La actualizaciÃ³n entre pares tambiÃ©n puede evitar fallos de invalidaciÃ³n debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma pÃ¡gina de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseÃ±o del objeto, y tambiÃ©n porque este beneficio se puede derivar dado el Ã­ndice de aciertos en cachÃ© y la contenciÃ³n de la carga de trabajo. 6.1.1 El Modelo El modelo considera cÃ³mo el tiempo para completar una ejecuciÃ³n con y sin BuddyCache se ve afectado por los fallos de invalidaciÃ³n y los fallos en frÃ­o. Considerando k clientes ejecutÃ¡ndose concurrentemente accediendo de manera uniforme a un conjunto compartido de N pÃ¡ginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacciÃ³n y realizar cÃ¡lculos en una transacciÃ³n, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin Ã©l (Base). Para simplificar, nuestro modelo asume que los tiempos de bÃºsqueda y confirmaciÃ³n son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del nÃºmero total de clientes en el sistema. El nÃºmero de fallos evitados por la recuperaciÃ³n entre pares depende de k, el nÃºmero de clientes en la BuddyCache, y del interÃ©s conjunto de los clientes en los datos compartidos. En una ejecuciÃ³n especÃ­fica de BuddyCache, se modela mediante la variable r, definida como el nÃºmero de solicitudes que llegan al redireccionador para una versiÃ³n dada de la pÃ¡gina P (es decir, hasta que un objeto en la pÃ¡gina se invalida). Considera una ejecuciÃ³n con fallos en frÃ­o. Un cliente comienza con una cachÃ© frÃ­a y ejecuta una carga de trabajo de solo lectura hasta que accede a las N pÃ¡ginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la cachÃ© del cliente es lo suficientemente grande como para contener N pÃ¡ginas. En BC, los frÃ­os fallos para la pÃ¡gina P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consideremos a continuaciÃ³n una ejecuciÃ³n con fallos de invalidaciÃ³n. Un cliente comienza con una cachÃ© caliente que contiene el conjunto de trabajo de N pÃ¡ginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualizaciÃ³n entre pares elimina todos los fallos de invalidaciÃ³n. En un grupo que contiene solo lectores (BCR), durante una ejecuciÃ³n en estado estable con actualizaciones uniformes, una transacciÃ³n del cliente tiene fallos de invalidaciÃ³n faltantes. Considera la secuencia de r fallos de cliente en la pÃ¡gina P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la pÃ¡gina P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frÃ­o, r â‰¤ k porque la segunda invalidaciÃ³n deshabilita la redirecciÃ³n para P hasta que el prÃ³ximo fallo en P provoque una recuperaciÃ³n del servidor. Suponiendo un acceso uniforme, un fallo de invalidaciÃ³n del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperaciÃ³n del servidor), y una probabilidad de (1 âˆ’ 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacciÃ³n Ãºnica en los sistemas Base, BCR y BCW. En los experimentos descritos a continuaciÃ³n, medimos los parÃ¡metros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalizaciÃ³n derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalizaciÃ³n y beneficios medidos directamente en los experimentos. 6.2 ConfiguraciÃ³n Experimental Antes de presentar nuestros resultados, describimos nuestra configuraciÃ³n experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectÃ¡ndose directamente a los servidores. El sistema Buddy ejecuta nuestra implementaciÃ³n del prototipo de BuddyCache en Thor, admitiendo la recuperaciÃ³n de pares, la actualizaciÃ³n de pares y la confirmaciÃ³n en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark estÃ¡ diseÃ±ado para capturar las caracterÃ­sticas de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicaciÃ³n especÃ­fica. Utilizamos OO7 porque es un punto de referencia estÃ¡ndar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un Ã¡rbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un grÃ¡fico de partes atÃ³micas vinculadas por objetos de conexiÃ³n; cada parte atÃ³mica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atÃ³micas por parte compuesta. La base de datos multiusuario asigna a cada cliente un mÃ³dulo privado que consiste en un Ã¡rbol de objetos de ensamblaje, y agrega un mÃ³dulo compartido adicional que escala proporcionalmente al nÃºmero de clientes. Esperamos que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ© y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la cachÃ©. Dado que el objetivo de nuestro estudio es evaluar quÃ© tan efectivamente nuestras tÃ©cnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras tÃ©cnicas tienen en los fallos de cachÃ© frÃ­o y de consistencia de cachÃ©, y aislar tanto como sea posible el efecto de los fallos de capacidad de cachÃ©. Para mantener la duraciÃ³n de nuestros experimentos razonable, utilizamos cachÃ©s pequeÃ±os. El benchmark OO7 genera mÃ³dulos de base de datos de tamaÃ±o predefinido. En nuestra implementaciÃ³n de OO7, el tamaÃ±o del mÃ³dulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la cachÃ©, utilizamos un Ãºnico mÃ³dulo privado y elegimos un tamaÃ±o de cachÃ© de 40MB para cada cliente. La base de datos OO7 se genera con mÃ³dulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos estÃ¡n agrupados en pÃ¡ginas de 8K, que tambiÃ©n son la unidad de transferencia en las solicitudes de recuperaciÃ³n. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro anÃ¡lisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idÃ©ntico a T1 excepto que modifica todas las partes atÃ³micas en un solo compuesto. Una transacciÃ³n Ãºnica incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo mÃ³dulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacciÃ³n, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de bÃºsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una cachÃ© de 50MB (de los cuales 6MB se utilizaron para el bÃºfer de objetos modificados), el cliente tenÃ­a una cachÃ© de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos bÃ¡sicos Esta secciÃ³n analiza el costo bÃ¡sico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 RedirecciÃ³n Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtenciÃ³n del servidor), el costo adicional de la redirecciÃ³n incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperaciÃ³n o confirmaciÃ³n del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmaciÃ³n y recuperaciÃ³n del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de Ã¡rea rÃ¡pida. Todos los nÃºmeros fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirecciÃ³n al cruzar el redireccionador no es muy alto, incluso en una red de Ã¡rea local. El costo de la confirmaciÃ³n aumenta con el nÃºmero de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperaciÃ³n no aumenta tanto porque la cachÃ© del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la cachÃ© del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperaciÃ³n entre pares, medimos la latencia de la recuperaciÃ³n entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperaciÃ³n entre pares, el costo de la redirecciÃ³n incluye, ademÃ¡s del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este Ãºltimo incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la pÃ¡gina solicitada. Medimos directamente el tiempo para copiar y desenrollar la pÃ¡gina solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperaciÃ³n de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador mÃ¡s un viaje de ida y vuelta a travÃ©s de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud mÃ¡s un viaje de ida y vuelta a travÃ©s de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando estÃ¡ bloqueado esperando una respuesta de bÃºsqueda o confirmaciÃ³n. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podrÃ­a ser mitigado por una implementaciÃ³n multi-hilo en un sistema con programaciÃ³n preemptiva. 6.3.2 VersiÃ³n de CachÃ© El commit en solitario permite que un cliente rÃ¡pido que modifica un objeto haga un commit de forma independiente a un compaÃ±ero lento. El mecanismo de confirmaciÃ³n Ãºnica introduce un procesamiento adicional en el servidor durante la validaciÃ³n de la transacciÃ³n, y un procesamiento adicional en el cliente durante la confirmaciÃ³n de la transacciÃ³n y en el momento del procesamiento de actualizaciÃ³n o invalidaciÃ³n. Los gastos generales del lado del servidor son mÃ­nimos y consisten en una actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina en el momento de la confirmaciÃ³n, y una comparaciÃ³n del nÃºmero de versiÃ³n en el momento de la validaciÃ³n de la transacciÃ³n. La cachÃ© de versiÃ³n tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacciÃ³n accede a objetos en mÃºltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor Ãºnico y, por lo tanto, el tiempo de confirmaciÃ³n adicional de la gestiÃ³n de la cachÃ© de versiones en el cliente no contribuye a los resultados presentados en la secciÃ³n a continuaciÃ³n. Para medir estos costos adicionales del lado del cliente en un sistema de mÃºltiples servidores, instrumentamos la implementaciÃ³n de la cachÃ© de versiones para ejecutarse con una traza de carga de trabajo que incluÃ­a invalidaciones reordenadas y cronometramos las operaciones bÃ¡sicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operaciÃ³n de bÃºsqueda de cachÃ© de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n en el momento de preparaciÃ³n de la solicitud de compromiso, y una operaciÃ³n de inserciÃ³n de cachÃ© de versiÃ³n para cada objeto actualizado por una transacciÃ³n en el momento de procesamiento de la respuesta de compromiso, pero solo si la pÃ¡gina actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmaciÃ³n se mantengan al mÃ­nimo, ya que el cliente estÃ¡ esperando de forma sÃ­ncrona la finalizaciÃ³n de la confirmaciÃ³n. Las mediciones muestran que en el peor de los casos, cuando llega un gran nÃºmero de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en pÃ¡ginas reordenadas, el costo de actualizar la cachÃ© de versiÃ³n es de 0.6 ms. El costo de tiempo de invalidaciÃ³n es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementaciÃ³n de la cachÃ© de versiones para reducir aÃºn mÃ¡s estos costos. 6.4 Rendimiento general Esta secciÃ³n examina las mejoras de rendimiento observadas por una aplicaciÃ³n que ejecuta el benchmark OO7 con un BuddyCache en una red de Ã¡rea amplia. 6.4.1 Fallos en frÃ­o Para evaluar las mejoras de rendimiento al evitar fallos en frÃ­o, comparamos el rendimiento de la cachÃ© en frÃ­o del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecuciÃ³n de los sistemas en el entorno de la red de Ã¡rea local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de Ã¡rea amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en cachÃ© frÃ­a. Los nÃºmeros fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frÃ­o solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frÃ­o solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparaciÃ³n con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cÃ¡lculos para el cliente, solicitudes de recuperaciÃ³n directa, recuperaciones de pares y solicitudes de confirmaciÃ³n. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperaciÃ³n entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperaciÃ³n del servidor para cada cliente individual disminuye porque, con mÃ¡s clientes accediendo a un mÃ³dulo compartido de tamaÃ±o fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperaciÃ³n de pares en comparaciÃ³n con la recuperaciÃ³n directa, pero este beneficio se ve contrarrestado por los tiempos de confirmaciÃ³n aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relaciÃ³n con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de cachÃ© 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT funciÃ³n de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias tÃ­picas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Sorprendentemente, los resultados analÃ­ticos predicen la mejora medida muy de cerca, aunque son ligeramente mÃ¡s altos que los valores empÃ­ricos. La razÃ³n principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidaciÃ³n evitados, comparamos el rendimiento de cachÃ© caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interÃ©s de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un Ãºnico cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compaÃ±eros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compaÃ±eros con un grupo que contiene un Ãºnico escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuraciÃ³n simple es suficiente para mostrar el impacto de las tÃ©cnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de cachÃ© caliente de OO7. Obtenemos los nÃºmeros ejecutando 2000 transacciones para filtrar los fallos en frÃ­o y luego medimos el tiempo de las siguientes 1000 transacciones. AquÃ­ nuevamente, los nÃºmeros reportados se derivan de los resultados del experimento de la red de Ã¡rea local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalizaciÃ³n en comparaciÃ³n con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparaciÃ³n con la Base. Este beneficio se debe a la actualizaciÃ³n entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperaciÃ³n entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperaciÃ³n local evitando el retraso de la recuperaciÃ³n desde el servidor. El Ãºltimo es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperaciÃ³n de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperaciÃ³n de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualizaciÃ³n de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relaciÃ³n con Base, y Buddy Writer y Base en relaciÃ³n con Base) en un experimento de cachÃ© activa en funciÃ³n del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualizaciÃ³n entre pares domina el gasto general en la configuraciÃ³n de Writer incluso en redes de baja latencia (la actualizaciÃ³n entre pares incurre en un gasto mÃ­nimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Como en experimentos de cachÃ© frÃ­a, aquÃ­ los resultados analÃ­ticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pÃ©rdida de invalidaciÃ³n es mÃ­nimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de cachÃ© frÃ­a). Como en el caso de cachÃ© frÃ­a, la razÃ³n por la que el modelo analÃ­tico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÃ“N Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en una red de Ã¡rea extensa debido a la alta latencia de red. Este artÃ­culo describe BuddyCache, una nueva tÃ©cnica de almacenamiento en cachÃ© cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La tÃ©cnica mejora el rendimiento y proporciona propiedades sÃ³lidas de correcciÃ³n y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirecciÃ³n para obtener objetos faltantes directamente de las cachÃ©s de los miembros del grupo, y para admitir la actualizaciÃ³n entre pares, una nueva tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirecciÃ³n puede interferir con la disponibilidad del objeto. Solo commit es una nueva tÃ©cnica de validaciÃ³n que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validaciÃ³n detallada utilizando informaciÃ³n de versiÃ³n de grano grueso econÃ³mica. Hemos diseÃ±ado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analÃ­ticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Las principales contribuciones del artÃ­culo son: 1. extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementaciÃ³n del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluaciÃ³n del rendimiento basada en anÃ¡lisis y mediciones de los costos y beneficios de las nuevas tÃ©cnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. TambiÃ©n agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios Ãºtiles que mejoraron este artÃ­culo. 9. REFERENCIAS [1] emulab.net, la InstalaciÃ³n de EmulaciÃ³n de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. ReconstrucciÃ³n de fragmentos: Proporcionando coherencia de cachÃ© global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre GestiÃ³n de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: ComputaciÃ³n en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de cachÃ© hÃ­bridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. RecuperaciÃ³n rÃ¡pida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de cachÃ© en la World Wide Web. En la 17Âª Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluaciÃ³n del rendimiento del sistema de gestiÃ³n de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una cachÃ© de objetos jerÃ¡rquica en Internet. En la Conferencia TÃ©cnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachÃ©s de Internet escalables. Informe TÃ©cnico CS-1997-18, Departamento de Ciencias de la ComputaciÃ³n, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: CachÃ© de proxy cooperativa en una red de Ã¡rea amplia. En el Tercer Taller Internacional de CachÃ© de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. CachÃ© web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2Âº Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. CachÃ© cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilaciÃ³n y en tiempo de ejecuciÃ³n para una memoria compartida distribuida eficiente. En Actas de IEEE, EdiciÃ³n Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la cachÃ©: un protocolo de intercambio de cachÃ© web escalable de Ã¡rea amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. ImplementaciÃ³n de GestiÃ³n Global de Memoria en un ClÃºster de Estaciones de Trabajo. Actas del 15Âº Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: DiseÃ±o, ImplementaciÃ³n y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de cachÃ© transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, pÃ¡ginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. GestiÃ³n global de memoria para arquitecturas de sistemas de gestiÃ³n de bases de datos cliente-servidor. En Actas del 19Âº Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El BÃºfer de Objeto Modificado: Una TÃ©cnica de GestiÃ³n de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto TecnolÃ³gico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. GestiÃ³n de documentos replicados en un sistema de comunicaciÃ³n grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13Âª Conferencia Europea sobre ProgramaciÃ³n Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18Âº Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. ReplicaciÃ³n con marca de vista: un nuevo mÃ©todo de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de ComputaciÃ³n Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalaciÃ³n eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de MultidifusiÃ³n a Nivel de AplicaciÃ³n. En el 3er Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de cachÃ© cooperativa utilizando pistas. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en CachÃ© Global. Informe tÃ©cnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del CachÃ© de Proxies Web Cooperativos. En el 17Âº Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerÃ¡rquica de cachÃ© en una WAN. En el Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. ComparticiÃ³n adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÃ‰NDICE Este apÃ©ndice describe el protocolo de conmutaciÃ³n por error de BuddyCache. Para dar cabida a clientes heterogÃ©neos, incluidos los dispositivos portÃ¡tiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseÃ±o de BuddyCache asume que las cachÃ©s del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresÃ­a detecta el fallo de un cliente o un redireccionador intercambiando mensajes periÃ³dicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutaciÃ³n por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuraciÃ³n y reinicia el protocolo. El protocolo de reconfiguraciÃ³n del grupo es similar al presentado en [25]. AquÃ­ describimos cÃ³mo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de pÃ¡ginas redireccionadas y el reenvÃ­o de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachÃ©s. En caso de un fallo del cliente, el failover elimina las pÃ¡ginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmaciÃ³n, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en cachÃ© las pÃ¡ginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutaciÃ³n por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de pÃ¡ginas utilizando un protocolo similar al descrito en [6]. El redireccionador reciÃ©n reiniciado solicita a los miembros activos del grupo la lista de pÃ¡ginas que estÃ¡n almacenando en cachÃ© y el estado de estas pÃ¡ginas, es decir, si las pÃ¡ginas estÃ¡n completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperaciÃ³n perdida expirarÃ¡ en el cliente y serÃ¡ retransmitida. Una transacciÃ³n que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma despuÃ©s del cambio se trata como una transacciÃ³n regular; una transacciÃ³n que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciarÃ¡ la transacciÃ³n y la solicitud de confirmaciÃ³n serÃ¡ retransmitida despuÃ©s del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caÃ­do podrÃ­an evitar la recolecciÃ³n de basura de las invalidaciones pendientes en los servidores o la cachÃ© virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los nÃºmeros de versiÃ³n Ãºnicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validaciÃ³n de transacciones depende del protocolo de coherencia de cachÃ© para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutaciÃ³n por error de BuddyCache no compromete la correcciÃ³n del procedimiento de validaciÃ³n. Recuerda que la validaciÃ³n de transacciones de BuddyCache utiliza dos mecanismos complementarios, nÃºmeros de versiÃ³n de pÃ¡gina y confirmaciones de invalidaciÃ³n de los clientes, para verificar que una transacciÃ³n ha leÃ­do datos actualizados. La propagaciÃ³n de la confirmaciÃ³n de invalidaciÃ³n (y actualizaciÃ³n) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmaciÃ³n de una modificaciÃ³n (invalidaciÃ³n o actualizaciÃ³n) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en cachÃ© el objeto o bien ha instalado el valor mÃ¡s reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmaciÃ³n de un cliente para una transacciÃ³n T que lee un objeto o despuÃ©s de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidaciÃ³n no confirmada para o pendiente para este grupo, la versiÃ³n del objeto leÃ­da por la transacciÃ³n T estÃ¡ actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validaciÃ³n utilizando nÃºmeros de versiÃ³n. El registro de confirmaciÃ³n de transacciÃ³n contiene un nÃºmero de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n. El protocolo de nÃºmero de versiÃ³n mantiene la invariante V P que garantiza que el valor del objeto o leÃ­do por la transacciÃ³n corresponda al nÃºmero de versiÃ³n mÃ¡s alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificaciÃ³n anterior despuÃ©s de haber recibido una modificaciÃ³n posterior. La retransmisiÃ³n de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validaciÃ³n verifica que el nÃºmero de versiÃ³n en el registro de confirmaciÃ³n coincida con el nÃºmero de versiÃ³n en la invalidaciÃ³n pendiente no reconocida. Es fÃ¡cil ver que, dado que esta comprobaciÃ³n es una comprobaciÃ³n cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutaciÃ³n por error aÃºn no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "buddycache": {
            "translated_key": "BuddyCache",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>buddycache</br>: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "<br>buddycache</br> is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a <br>buddycache</br> prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the <br>buddycache</br> prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using <br>buddycache</br> can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "<br>buddycache</br> is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With <br>buddycache</br>, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "<br>buddycache</br> presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "<br>buddycache</br> uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "<br>buddycache</br> redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "<br>buddycache</br> uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by <br>buddycache</br> to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a <br>buddycache</br> prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without <br>buddycache</br> and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies <br>buddycache</br> provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the <br>buddycache</br> can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to <br>buddycache</br>.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, <br>buddycache</br> uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "<br>buddycache</br> provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "<br>buddycache</br> High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the <br>buddycache</br> approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "<br>buddycache</br> architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "<br>buddycache</br> redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "<br>buddycache</br> avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: <br>buddycache</br>. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall <br>buddycache</br> architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The <br>buddycache</br> approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate <br>buddycache</br> in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating <br>buddycache</br> with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important <br>buddycache</br> design goal is to maintain this benefit.",
                "Since in <br>buddycache</br> a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in <br>buddycache</br> is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "<br>buddycache</br> circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in <br>buddycache</br> redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the <br>buddycache</br> propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The <br>buddycache</br> architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending <br>buddycache</br> protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In <br>buddycache</br> applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in <br>buddycache</br> is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the <br>buddycache</br> redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the <br>buddycache</br> cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the <br>buddycache</br> implementation.",
                "We have implemented <br>buddycache</br> in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate <br>buddycache</br> performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "<br>buddycache</br> FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the <br>buddycache</br> in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for <br>buddycache</br> but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION <br>buddycache</br> redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a <br>buddycache</br> prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical <br>buddycache</br> configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with <br>buddycache</br> and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect <br>buddycache</br> to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without <br>buddycache</br> with an application running <br>buddycache</br> in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without <br>buddycache</br> is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in <br>buddycache</br> (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with <br>buddycache</br> (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the <br>buddycache</br>, and on the client co-interest in the shared data.",
                "In a specific <br>buddycache</br> execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of <br>buddycache</br> prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical <br>buddycache</br> configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the <br>buddycache</br> cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the <br>buddycache</br> architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a <br>buddycache</br> in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into <br>buddycache</br>, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The <br>buddycache</br> provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by <br>buddycache</br> (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates <br>buddycache</br> benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by <br>buddycache</br> due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the <br>buddycache</br> group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of <br>buddycache</br> techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the <br>buddycache</br> reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by <br>buddycache</br> in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described <br>buddycache</br>, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "<br>buddycache</br> uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented <br>buddycache</br> prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies <br>buddycache</br> provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the <br>buddycache</br> can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the <br>buddycache</br> failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the <br>buddycache</br> peer group.",
                "The <br>buddycache</br> design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the <br>buddycache</br> data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the <br>buddycache</br> state.",
                "To restart the <br>buddycache</br> protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that <br>buddycache</br> failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that <br>buddycache</br> transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "<br>buddycache</br>: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "<br>buddycache</br> is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "We have implemented a <br>buddycache</br> prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the <br>buddycache</br> prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using <br>buddycache</br> can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "<br>buddycache</br> is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment."
            ],
            "translated_annotated_samples": [
                "BuddyCache: <br>Almacenamiento de objetos de alto rendimiento</br> para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn.",
                "<br>BuddyCache</br> es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia.",
                "Hemos implementado un prototipo de <br>BuddyCache</br> y evaluado su rendimiento.",
                "Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de <br>BuddyCache</br> utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan <br>BuddyCache</br> pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos.",
                "BuddyCache es una nueva tÃ©cnica de <br>almacenamiento en cachÃ© de objetos</br> que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia."
            ],
            "translated_text": "BuddyCache: <br>Almacenamiento de objetos de alto rendimiento</br> para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. <br>BuddyCache</br> es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de <br>BuddyCache</br> y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de <br>BuddyCache</br> utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan <br>BuddyCache</br> pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de <br>almacenamiento en cachÃ© de objetos</br> que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia. ",
            "candidates": [],
            "error": [
                [
                    "Almacenamiento de objetos de alto rendimiento",
                    "BuddyCache",
                    "BuddyCache",
                    "BuddyCache",
                    "BuddyCache",
                    "almacenamiento en cachÃ© de objetos"
                ]
            ]
        },
        "dominant performance cost": {
            "translated_key": "costo de rendimiento dominante",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the <br>dominant performance cost</br>. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the <br>dominant performance cost</br>, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the <br>dominant performance cost</br>. 7.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the <br>dominant performance cost</br>, high network latency. 8."
            ],
            "translated_annotated_samples": [
                "Como en el caso de cachÃ© frÃ­a, la razÃ³n por la que el modelo analÃ­tico simplificado funciona bien es porque captura los costos de la latencia de red, el <br>costo de rendimiento dominante</br>. 7.",
                "Las principales contribuciones del artÃ­culo son: 1. extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementaciÃ³n del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluaciÃ³n del rendimiento basada en anÃ¡lisis y mediciones de los costos y beneficios de las nuevas tÃ©cnicas que capturan el <br>costo de rendimiento dominante</br>, la alta latencia de red."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de Ã¡rea amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de Ã¡rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil. Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en cachÃ© web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos. Sin embargo, las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica. La interacciÃ³n con el servidor aumenta la latencia. La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia. Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n. Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo. BuddyCache presenta dos desafÃ­os tÃ©cnicos principales. Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©. El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de almacenamiento en cachÃ© web cooperativos [11]. Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo. BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos. Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica. Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad? DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red. Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia. El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida. Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache. Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n. Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos. Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de Ã¡rea amplia. Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad. Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un Ãºnico servidor. Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web. El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en cachÃ© transaccional [19]. La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una transacciÃ³n, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador. El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado. AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©. Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina). La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente. El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento. A continuaciÃ³n, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene. La transacciÃ³n puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor. Sin embargo, antes de que una transacciÃ³n se confirme, debe ser validada; el servidor debe asegurarse de que la transacciÃ³n validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada. Si la validaciÃ³n falla, la transacciÃ³n se cancela. Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de bÃºsqueda de pares envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la cachÃ© y envÃ­an confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la cachÃ© del cliente, la confirmaciÃ³n de invalidaciÃ³n indica al servidor que un cliente sin invalidaciones pendientes ha leÃ­do objetos actualizados. Una invalidaciÃ³n no reconocida indica que un objeto obsoleto puede haber sido accedido en la cachÃ© del cliente. El procedimiento de validaciÃ³n en el servidor aborta una transacciÃ³n del cliente si este lee un objeto mientras hay una invalidaciÃ³n pendiente. El mecanismo de invalidaciÃ³n reconocido admite coherencia de cachÃ© a nivel de objeto sin directorios basados en objetos o nÃºmeros de versiÃ³n por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeÃ±os, ya que los objetos tÃ­picos son pequeÃ±os. Un objetivo importante del diseÃ±o de BuddyCache es mantener este beneficio. Dado que en BuddyCache una pÃ¡gina puede ser recuperada en una cachÃ© de cliente sin intervenciÃ³n del servidor (como se ilustra en la figura 2), los directorios de cachÃ© en los servidores llevan un registro de las pÃ¡ginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las pÃ¡ginas almacenadas en cachÃ© en cada cliente de un grupo. Los servidores envÃ­an al redireccionador invalidaciones para las pÃ¡ginas almacenadas en cachÃ© en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. ActualizaciÃ³n de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en cachÃ© por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interÃ©s potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de cachÃ© y las actualizaciones de cachÃ©. Los estudios de coherencia de cachÃ© en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualizaciÃ³n y la invalidaciÃ³n. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. AlmacÃ©n x 6. ActualizaciÃ³n x 3. CompromÃ©tete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares estÃ¡n fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeÃ±as, agrupadas y se envÃ­an junto con otros mensajes. AdemÃ¡s, los protocolos de invalidaciÃ³n se ajustan a la tendencia actual de hardware de aumentar los tamaÃ±os de cachÃ© del cliente. Es probable que las cachÃ©s mÃ¡s grandes contengan mucha mÃ¡s informaciÃ³n de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una red de Ã¡rea amplia serÃ­an derrochadores. Sin embargo, los protocolos de coherencia basados en invalidaciÃ³n pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interÃ©s para otro miembro del grupo. Con un protocolo basado en invalidaciÃ³n, la actualizaciÃ³n de un miembro invalidarÃ¡ la copia en cachÃ© de otro miembro, lo que provocarÃ¡ que este Ãºltimo realice una recuperaciÃ³n de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualizaciÃ³n e invalidaciÃ³n en entornos de redes de Ã¡rea amplia. Evita la penalizaciÃ³n de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalizaciÃ³n de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusiÃ³n localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en cachÃ© anteriores. La actualizaciÃ³n entre pares funciona de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que la transacciÃ³n se confirma, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n, y tambiÃ©n propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmaciÃ³n. 3.3 ConfirmaciÃ³n individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminaciÃ³n de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en cachÃ© transaccional, ya que un cliente que es lento para reconocer una invalidaciÃ³n o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacciÃ³n. Por ejemplo, un ingeniero que realiza una revisiÃ³n repetida al mismo objeto de diseÃ±o compartido (y por lo tanto tiene la Ãºltima versiÃ³n del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situaciÃ³n representada en la figura 4 donde el Cliente1 realiza una transacciÃ³n T que lee la Ãºltima versiÃ³n de un objeto x en la pÃ¡gina P recientemente modificada por el Cliente1. Si la solicitud de confirmaciÃ³n para T llega al servidor antes de que la confirmaciÃ³n colectiva de Cliente2 por la Ãºltima modificaciÃ³n de x llegue al servidor, el procedimiento de validaciÃ³n de OCC considera que x estÃ¡ obsoleto y aborta T (porque, como se explicÃ³ anteriormente, una invalidaciÃ³n no reconocida por un cliente actÃºa como indicaciÃ³n para el servidor de que el valor del objeto en cachÃ© estÃ¡ obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la correcciÃ³n del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asÃ­ncronas son una parte importante de la razÃ³n por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasiÃ³n de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envÃ­an y procesan de forma asÃ­ncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devoluciÃ³n de llamada jerÃ¡rquica [32], pero la naturaleza asincrÃ³nica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrÃ³nicas. El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a un cliente con objetos actualizados confirmar una transacciÃ³n incluso si la confirmaciÃ³n del grupo se retrasa debido a pares lentos o caÃ­dos. El protocolo requiere que los clientes incluyan informaciÃ³n adicional con los conjuntos de lectura de transacciones en el mensaje de confirmaciÃ³n, para indicar al servidor que los objetos leÃ­dos por la transacciÃ³n estÃ¡n actualizados. Los nÃºmeros de versiÃ³n de los objetos podrÃ­an proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionÃ³ anteriormente, mantener nÃºmeros de versiÃ³n por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaÃ±o de directorio) en todo el sistema de objetos cuando los objetos son pequeÃ±os [23]. En cambio, solo utiliza nÃºmeros de versiÃ³n de pÃ¡gina de grano grueso para identificar versiones de objetos de grano fino. El nÃºmero de versiÃ³n de una pÃ¡gina se incrementa en un servidor cuando una transacciÃ³n que modifica objetos en la pÃ¡gina se confirma. Las actualizaciones realizadas por una Ãºnica transacciÃ³n y las invalidaciones correspondientes son identificadas de manera Ãºnica por el nÃºmero de versiÃ³n de la pÃ¡gina modificada. Los nÃºmeros de versiÃ³n de la pÃ¡gina se propagan a los clientes en respuestas de recuperaciÃ³n, respuestas de confirmaciÃ³n y con invalidaciones, y los clientes incluyen los nÃºmeros de versiÃ³n de la pÃ¡gina en las solicitudes de confirmaciÃ³n enviadas a los servidores. Si una transacciÃ³n falla en la validaciÃ³n debido a la falta de reconocimiento de grupo, el servidor verifica los nÃºmeros de versiÃ³n de pÃ¡gina de los objetos en el conjunto de lectura de la transacciÃ³n y permite que la transacciÃ³n se confirme si el cliente ha leÃ­do desde la Ãºltima versiÃ³n de la pÃ¡gina. Los nÃºmeros de versiÃ³n de la pÃ¡gina permiten confirmaciones independientes, pero las verificaciones de versiÃ³n de pÃ¡gina solo detectan conflictos a nivel de pÃ¡gina. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La secciÃ³n 4 describe los detalles de la implementaciÃ³n del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 ConfiguraciÃ³n de Grupo La arquitectura BuddyCache admite mÃºltiples grupos de pares concurrentes. Potencialmente, puede ser mÃ¡s rÃ¡pido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podrÃ­a ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en cachÃ© de pares de mÃºltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en cachÃ© web, simplemente aumentar la poblaciÃ³n de clientes en una cachÃ© proxy a menudo aumenta la tasa general de aciertos en la cachÃ© [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacciÃ³n explÃ­cita entre clientes y la colaboraciÃ³n, lo que sugiere que es poco probable que ocurra la recuperaciÃ³n entre grupos. AdemÃ¡s, las mediciones de sistemas de almacenamiento en cachÃ© web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexiÃ³n de red entre los grupos de pares sea muy rÃ¡pida. Estamos principalmente interesados en entornos donde compaÃ±eros que colaboran estrechamente tienen una conectividad rÃ¡pida a corta distancia, pero la conexiÃ³n entre grupos de compaÃ±eros puede ser lenta. Como resultado, decidimos que el soporte para la recuperaciÃ³n entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compaÃ±eros con recursos heterogÃ©neos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compaÃ±eros o, cuando estÃ© disponible, en un nodo separado dentro de la infraestructura del sitio. AdemÃ¡s, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una cachÃ© de pares en espera para recibir pÃ¡ginas recuperadas por otros pares, emulando una cachÃ© central algo similar a una cachÃ© de proxy web regional. Desde el punto de vista del protocolo de coherencia de cachÃ© BuddyCache, sin embargo, un cachÃ© de compaÃ±ero en espera es equivalente a un cachÃ© de compaÃ±ero regular y, por lo tanto, no consideramos este caso por separado en la discusiÃ³n de este documento. 4. En esta secciÃ³n proporcionamos los detalles de la implementaciÃ³n de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en cachÃ© de estos objetos. Las aplicaciones se ejecutan en los clientes e interactÃºan con el sistema realizando llamadas a mÃ©todos de objetos en cachÃ©. Todas las llamadas a mÃ©todos ocurren dentro de transacciones atÃ³micas. Los clientes se comunican con los servidores para obtener pÃ¡ginas o realizar una transacciÃ³n. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volÃ¡til. El disco estÃ¡ organizado como una colecciÃ³n de pÃ¡ginas que son las unidades de acceso al disco. El registro estable guarda la informaciÃ³n de confirmaciÃ³n y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de cachÃ© y una cachÃ© de objetos modificados recuperable llamada MOB. El directorio lleva un registro de quÃ© pÃ¡ginas estÃ¡n almacenadas en cachÃ© por quÃ© clientes. El MOB contiene objetos recientemente modificados que aÃºn no han sido escritos de vuelta en sus pÃ¡ginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de cachÃ© base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la SecciÃ³n 3.1. Proporcionamos algunos de los detalles relevantes de la implementaciÃ³n del protocolo OCC. El cliente lleva un registro de los objetos que son leÃ­dos y modificados por su transacciÃ³n; envÃ­a esta informaciÃ³n, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacciÃ³n. Los servidores determinan si la confirmaciÃ³n es posible, utilizando un protocolo de confirmaciÃ³n de dos fases si la transacciÃ³n utilizÃ³ objetos en mÃºltiples servidores. Si la transacciÃ³n se lleva a cabo, las nuevas copias de los objetos modificados se aÃ±aden al registro y tambiÃ©n se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperaciÃ³n escaneando el registro. Dado que los objetos no estÃ¡n bloqueados antes de ser utilizados, una confirmaciÃ³n de transacciÃ³n puede hacer que las cachÃ©s contengan objetos obsoletos. Los servidores abortarÃ¡n una transacciÃ³n que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviÃ¡ndoles mensajes de invalidaciÃ³n; un servidor utiliza su directorio y la informaciÃ³n sobre la transacciÃ³n de confirmaciÃ³n para determinar quÃ© mensajes de invalidaciÃ³n enviar. Los mensajes de invalidaciÃ³n son pequeÃ±os porque simplemente identifican objetos obsoletos. AdemÃ¡s, se envÃ­an en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidaciÃ³n, elimina los objetos obsoletos de su cachÃ© y aborta la transacciÃ³n actual si los utilizÃ³. El cliente sigue conservando pÃ¡ginas que contienen objetos invalidados; estas pÃ¡ginas ahora estÃ¡n incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidaciÃ³n de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener pÃ¡ginas incompletas en la cachÃ© del cliente significa que el falso intercambio no conduce a fallos innecesarios en la cachÃ©. Los clientes reconocen las invalidaciones para indicar la eliminaciÃ³n de datos obsoletos, como se explica en la SecciÃ³n 3.1. Los mensajes de invalidaciÃ³n evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo asÃ­ el desperdicio de trabajo y trasladando la detecciÃ³n de abortos de los servidores a los clientes. Cuando una transacciÃ³n se aborta, su cliente restaura las copias en cachÃ© de los objetos modificados al estado que tenÃ­an antes de que la transacciÃ³n comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacciÃ³n. 4.3 RedirecciÃ³n El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de pÃ¡ginas disponibles en el grupo de pares y proporciona una redirecciÃ³n rÃ¡pida y centralizada de recuperaciÃ³n (ver figura 2) entre las cachÃ©s de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan pÃ¡ginas u objetos al incluir esa informaciÃ³n en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la cachÃ© de grupo, el redireccionador realiza un seguimiento del estado de las pÃ¡ginas. Una pÃ¡gina en cachÃ© estÃ¡ completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una pÃ¡gina estÃ¡n marcados como invÃ¡lidos. Solo se utilizan pÃ¡ginas completas por el proceso de recuperaciÃ³n de pares. El protocolo para mantener el estado de la pÃ¡gina cuando las pÃ¡ginas son actualizadas e invalidadas se describe en la SecciÃ³n 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una pÃ¡gina solicitada completa no estÃ¡ disponible en el grupo de pares o si un par necesita confirmar una transacciÃ³n, el redireccionador actÃºa como un proxy de servidor: reenvÃ­a la solicitud al servidor y luego reenvÃ­a la respuesta de vuelta al cliente. AdemÃ¡s, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualizaciÃ³n o informaciÃ³n de invalidaciÃ³n a los clientes que tienen en cachÃ© la pÃ¡gina modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la cachÃ© de grupo de pares combinada estÃ¡ desempeÃ±ando el papel de una Ãºnica cachÃ© de cliente en el sistema base. 4.4 ActualizaciÃ³n de pares La actualizaciÃ³n de pares se implementa de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que una transacciÃ³n se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacciÃ³n generan invalidaciones de objetos para cada grupo de cachÃ© que almacena pÃ¡ginas que contienen los objetos modificados (incluido el grupo que realiza la confirmaciÃ³n). Las invalidaciones se envÃ­an de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en cachÃ© los objetos modificados se deshagan de los datos obsoletos. En grupos de cachÃ© distintos al grupo de confirmaciÃ³n, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas, recopilan las confirmaciones de los clientes y, despuÃ©s de completar la recopilaciÃ³n, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacciÃ³n, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envÃ­an a los clientes que almacenan en cachÃ© esas pÃ¡ginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmaciÃ³n colectiva se propaga al servidor. Una invalidaciÃ³n hace que una pÃ¡gina en cachÃ© no estÃ© disponible para la recuperaciÃ³n de pares, cambiando el estado de una pÃ¡gina completa p a incompleta. Por el contrario, una actualizaciÃ³n de una pÃ¡gina completa conserva el estado completo de la pÃ¡gina. Como se muestra en los estudios de la reconstrucciÃ³n de fragmentos 31 [2], esta propagaciÃ³n de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma pÃ¡gina, la pÃ¡gina conserva su estado completo y permanece disponible para la recuperaciÃ³n entre pares. Por lo tanto, el efecto de la actualizaciÃ³n de pares es similar a la reconstrucciÃ³n de fragmentos ansiosa [2]. TambiÃ©n hemos considerado la posibilidad de permitir que un compaÃ±ero recupere una pÃ¡gina incompleta (con objetos invÃ¡lidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos invÃ¡lidos. 4.5 Vcache El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo mÃ¡s lentos (o fallidos). Como se explica en la SecciÃ³n 3.3, el protocolo de commit Ãºnico permite que una transacciÃ³n T pase la validaciÃ³n si la informaciÃ³n adicional de coherencia proporcionada por el cliente indica que la transacciÃ³n T ha leÃ­do objetos actualizados. Los clientes utilizan los nÃºmeros de versiÃ³n de la pÃ¡gina para proporcionar esta informaciÃ³n adicional de coherencia. Es decir, un cliente incluye el nÃºmero de versiÃ³n de la pÃ¡gina correspondiente a cada objeto en el conjunto de objetos leÃ­dos enviado en la solicitud de confirmaciÃ³n al servidor. Dado que a cada actualizaciÃ³n de objeto comprometido le corresponde un nÃºmero de versiÃ³n de pÃ¡gina Ãºnico, el nÃºmero de versiÃ³n de pÃ¡gina asociado con un objeto permite que el procedimiento de validaciÃ³n en el servidor verifique si la transacciÃ³n del cliente ha leÃ­do objetos actualizados. El uso de versiones de pÃ¡gina de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeÃ±os, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en cachÃ© a la versiÃ³n de pÃ¡gina identificadora (ObjectToVersion). El principal problema de implementaciÃ³n se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian nÃºmeros de versiÃ³n de pÃ¡gina con las invalidaciones. En el momento de la validaciÃ³n, si hay una invalidaciÃ³n no reconocida pendiente para un objeto x leÃ­do por una transacciÃ³n T, el procedimiento de validaciÃ³n verifica si el nÃºmero de versiÃ³n de x en el conjunto de lectura de Ts coincide con el nÃºmero de versiÃ³n de la invalidaciÃ³n pendiente mÃ¡s alta para x, en cuyo caso el valor del objeto estÃ¡ actualizado, de lo contrario, T falla en la validaciÃ³n. Observamos nuevamente que las verificaciones basadas en el nÃºmero de versiÃ³n de la pÃ¡gina y las verificaciones basadas en el reconocimiento de invalidaciÃ³n son complementarias en la validaciÃ³n de confirmaciÃ³n individual y ambas son necesarias. La verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina permite que la validaciÃ³n avance antes de que lleguen las confirmaciones de invalidaciÃ³n, pero por sÃ­ sola, una verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina detecta conflictos a nivel de pÃ¡gina y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cÃ³mo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un nÃºmero de versiÃ³n de la pÃ¡gina para cada pÃ¡gina en cachÃ©. El nÃºmero de versiÃ³n satisface la siguiente invariante V P sobre el estado de los objetos en una pÃ¡gina: si una pÃ¡gina en cachÃ© P tiene un nÃºmero de versiÃ³n v, entonces el valor de un objeto o en la pÃ¡gina en cachÃ© P es invÃ¡lido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacciÃ³n que estableciÃ³ el nÃºmero de versiÃ³n de P en v. Los nuevos valores de objetos y los nuevos nÃºmeros de versiÃ³n de pÃ¡gina llegan cuando un cliente obtiene una pÃ¡gina o cuando llega una respuesta de confirmaciÃ³n o invalidaciones para esta pÃ¡gina. Los nuevos valores del objeto modifican la pÃ¡gina y, por lo tanto, el nÃºmero de versiÃ³n de la pÃ¡gina necesita ser actualizado para mantener la invariante V P. Un nÃºmero de versiÃ³n de pÃ¡gina que llega cuando un cliente obtiene una pÃ¡gina, reemplaza la VersiÃ³n del Objeto x 8 Servidor de RedirecciÃ³n 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el nÃºmero de versiÃ³n de la pÃ¡gina para esta pÃ¡gina. Tal actualizaciÃ³n preserva el invariante V P. De manera similar, un nÃºmero de versiÃ³n de pÃ¡gina en secuencia que llega al cliente en un mensaje de confirmaciÃ³n o invalidaciÃ³n avanza el nÃºmero de versiÃ³n para toda la pÃ¡gina en cachÃ©, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus nÃºmeros de versiÃ³n de pÃ¡gina correspondientes tambiÃ©n pueden llegar al cliente fuera de secuencia, en cuyo caso la actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina podrÃ­a violar V P. Por ejemplo, una respuesta de confirmaciÃ³n para una transacciÃ³n que actualiza el objeto x en la pÃ¡gina P en el servidor S1, y el objeto y en la pÃ¡gina Q en el servidor S2, puede entregar un nuevo nÃºmero de versiÃ³n para P desde el coordinador de transacciones S1 antes de que llegue una invalidaciÃ³n generada para una transacciÃ³n anterior que ha modificado el objeto r en la pÃ¡gina P desde S1 (como se muestra en la figura 5). El protocolo de actualizaciÃ³n de cachÃ© garantiza que el valor de cualquier objeto o en una pÃ¡gina en cachÃ© P refleje la actualizaciÃ³n o invalidaciÃ³n con el nÃºmero de versiÃ³n observado mÃ¡s alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de nÃºmeros de versiÃ³n de pÃ¡gina, el cliente gestiona una pequeÃ±a cachÃ© de nÃºmeros de versiÃ³n vcache que mantiene el mapeo de un objeto a su nÃºmero de versiÃ³n de pÃ¡gina correspondiente para todas las actualizaciones de nÃºmeros de versiÃ³n reordenadas hasta que se ensamble una secuencia completa de nÃºmeros de versiÃ³n de pÃ¡gina. Cuando llegan los nÃºmeros de versiÃ³n faltantes para la pÃ¡gina y completan una secuencia, el nÃºmero de versiÃ³n de toda la pÃ¡gina se avanza. El mapeo de ObjectToVersion, incluyendo los nÃºmeros de versiÃ³n de vcache y pÃ¡gina, se utiliza en el momento de la confirmaciÃ³n de la transacciÃ³n para proporcionar nÃºmeros de versiÃ³n para el conjunto de objetos leÃ­dos de la siguiente manera. Si el objeto leÃ­do tiene una entrada en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n mÃ¡s alto en la vcache para este objeto. Si el objeto no estÃ¡ presente en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n de la pÃ¡gina en cachÃ© que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la cachÃ© del cliente, incluyendo los nÃºmeros de versiÃ³n de las pÃ¡ginas y la vcache. El cliente puede limitar el tamaÃ±o de la cachÃ© virtual segÃºn sea necesario, ya que volver a cargar una pÃ¡gina elimina todos los nÃºmeros de versiÃ³n de pÃ¡gina reordenados de la cachÃ© virtual. Sin embargo, esperamos que la reorganizaciÃ³n de nÃºmeros de versiÃ³n sea poco comÃºn y, por lo tanto, esperamos que la vcache sea muy pequeÃ±a. 5. Un grupo de clientes contiene mÃºltiples nodos de cliente y un objeto de pÃ¡gina de versiÃ³n redi32 VCache Cliente CachÃ© Cliente PÃ¡gina CachÃ© Figura 6: Mapa de Objeto a VersiÃ³n con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutaciÃ³n por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. AdemÃ¡s, el fallo del redireccionador deberÃ­a permitir que los clientes no afectados mantengan sus cachÃ©s intactas. Hemos diseÃ±ado un protocolo de conmutaciÃ³n por error para BuddyCache pero aÃºn no lo hemos implementado. El apÃ©ndice describe el protocolo. 6. La redirecciÃ³n de BuddyCache en la evaluaciÃ³n de rendimiento respalda los beneficios de evitar la comunicaciÃ³n con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes. Â¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 AnÃ¡lisis Los beneficios de rendimiento de la recuperaciÃ³n entre pares y la actualizaciÃ³n entre pares se deben a la evitaciÃ³n de interacciones con el servidor. Esta secciÃ³n presenta un modelo de rendimiento analÃ­tico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la cachÃ© del cliente. Estos pueden ser fallos frÃ­os, fallos de invalidaciÃ³n y fallos de capacidad. Nuestro anÃ¡lisis se centra en los fallos por frÃ­o y los fallos por invalidaciÃ³n, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frÃ­o. AdemÃ¡s, las tendencias tecnolÃ³gicas indican que la capacidad de memoria y almacenamiento seguirÃ¡ creciendo y, por lo tanto, es probable que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ©. Los fallos de cachÃ© del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuraciÃ³n de cachÃ©. Nuestro anÃ¡lisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validaciÃ³n. Para estudiar el beneficio de evitar fallos en frÃ­o, consideramos el rendimiento de la cachÃ© en frÃ­o en una carga de trabajo de solo lectura (sin fallos de invalidaciÃ³n). Esperamos que la recuperaciÃ³n entre pares mejore el costo de latencia para las solicitudes de cachÃ© frÃ­a del cliente al recuperar objetos de la cachÃ© cercana. Evaluamos cÃ³mo el costo de redirecciÃ³n afecta este beneficio al comparar y analizar el rendimiento de una aplicaciÃ³n que se ejecuta en un sistema de almacenamiento con BuddyCache y sin Ã©l (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidaciÃ³n, consideramos el rendimiento de la cachÃ© caliente en una carga de trabajo con modificaciones (sin fallos en frÃ­o). En las cachÃ©s calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualizaciÃ³n entre pares permite que un cliente acceda a un objeto modificado por un compaÃ±ero colaborador cercano sin el retraso impuesto por los protocolos de invalidaciÃ³n Ãºnicamente. En grupos donde los compaÃ±eros comparten un interÃ©s de solo lectura en los objetos modificados, la recuperaciÃ³n entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compaÃ±ero colaborador lo tenga, lo que evita el retraso de la recuperaciÃ³n del servidor sin el alto costo impuesto por los protocolos de solo actualizaciÃ³n. Las tendencias tecnolÃ³gicas indican que ambos beneficios seguirÃ¡n siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualizaciÃ³n Ãºnicamente. Sin embargo, la tendencia hacia cachÃ©s cada vez mÃ¡s grandes, que se actualizan cuando los objetos en cachÃ© son modificados, hace que los protocolos basados en invalidaciÃ³n sean mÃ¡s atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicaciÃ³n que se ejecuta sin BuddyCache y una aplicaciÃ³n que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compaÃ±ero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compaÃ±ero fuera del grupo. La actualizaciÃ³n entre pares tambiÃ©n puede evitar fallos de invalidaciÃ³n debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma pÃ¡gina de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseÃ±o del objeto, y tambiÃ©n porque este beneficio se puede derivar dado el Ã­ndice de aciertos en cachÃ© y la contenciÃ³n de la carga de trabajo. 6.1.1 El Modelo El modelo considera cÃ³mo el tiempo para completar una ejecuciÃ³n con y sin BuddyCache se ve afectado por los fallos de invalidaciÃ³n y los fallos en frÃ­o. Considerando k clientes ejecutÃ¡ndose concurrentemente accediendo de manera uniforme a un conjunto compartido de N pÃ¡ginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacciÃ³n y realizar cÃ¡lculos en una transacciÃ³n, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin Ã©l (Base). Para simplificar, nuestro modelo asume que los tiempos de bÃºsqueda y confirmaciÃ³n son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del nÃºmero total de clientes en el sistema. El nÃºmero de fallos evitados por la recuperaciÃ³n entre pares depende de k, el nÃºmero de clientes en la BuddyCache, y del interÃ©s conjunto de los clientes en los datos compartidos. En una ejecuciÃ³n especÃ­fica de BuddyCache, se modela mediante la variable r, definida como el nÃºmero de solicitudes que llegan al redireccionador para una versiÃ³n dada de la pÃ¡gina P (es decir, hasta que un objeto en la pÃ¡gina se invalida). Considera una ejecuciÃ³n con fallos en frÃ­o. Un cliente comienza con una cachÃ© frÃ­a y ejecuta una carga de trabajo de solo lectura hasta que accede a las N pÃ¡ginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la cachÃ© del cliente es lo suficientemente grande como para contener N pÃ¡ginas. En BC, los frÃ­os fallos para la pÃ¡gina P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consideremos a continuaciÃ³n una ejecuciÃ³n con fallos de invalidaciÃ³n. Un cliente comienza con una cachÃ© caliente que contiene el conjunto de trabajo de N pÃ¡ginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualizaciÃ³n entre pares elimina todos los fallos de invalidaciÃ³n. En un grupo que contiene solo lectores (BCR), durante una ejecuciÃ³n en estado estable con actualizaciones uniformes, una transacciÃ³n del cliente tiene fallos de invalidaciÃ³n faltantes. Considera la secuencia de r fallos de cliente en la pÃ¡gina P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la pÃ¡gina P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frÃ­o, r â‰¤ k porque la segunda invalidaciÃ³n deshabilita la redirecciÃ³n para P hasta que el prÃ³ximo fallo en P provoque una recuperaciÃ³n del servidor. Suponiendo un acceso uniforme, un fallo de invalidaciÃ³n del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperaciÃ³n del servidor), y una probabilidad de (1 âˆ’ 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacciÃ³n Ãºnica en los sistemas Base, BCR y BCW. En los experimentos descritos a continuaciÃ³n, medimos los parÃ¡metros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalizaciÃ³n derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalizaciÃ³n y beneficios medidos directamente en los experimentos. 6.2 ConfiguraciÃ³n Experimental Antes de presentar nuestros resultados, describimos nuestra configuraciÃ³n experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectÃ¡ndose directamente a los servidores. El sistema Buddy ejecuta nuestra implementaciÃ³n del prototipo de BuddyCache en Thor, admitiendo la recuperaciÃ³n de pares, la actualizaciÃ³n de pares y la confirmaciÃ³n en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark estÃ¡ diseÃ±ado para capturar las caracterÃ­sticas de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicaciÃ³n especÃ­fica. Utilizamos OO7 porque es un punto de referencia estÃ¡ndar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un Ã¡rbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un grÃ¡fico de partes atÃ³micas vinculadas por objetos de conexiÃ³n; cada parte atÃ³mica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atÃ³micas por parte compuesta. La base de datos multiusuario asigna a cada cliente un mÃ³dulo privado que consiste en un Ã¡rbol de objetos de ensamblaje, y agrega un mÃ³dulo compartido adicional que escala proporcionalmente al nÃºmero de clientes. Esperamos que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ© y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la cachÃ©. Dado que el objetivo de nuestro estudio es evaluar quÃ© tan efectivamente nuestras tÃ©cnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras tÃ©cnicas tienen en los fallos de cachÃ© frÃ­o y de consistencia de cachÃ©, y aislar tanto como sea posible el efecto de los fallos de capacidad de cachÃ©. Para mantener la duraciÃ³n de nuestros experimentos razonable, utilizamos cachÃ©s pequeÃ±os. El benchmark OO7 genera mÃ³dulos de base de datos de tamaÃ±o predefinido. En nuestra implementaciÃ³n de OO7, el tamaÃ±o del mÃ³dulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la cachÃ©, utilizamos un Ãºnico mÃ³dulo privado y elegimos un tamaÃ±o de cachÃ© de 40MB para cada cliente. La base de datos OO7 se genera con mÃ³dulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos estÃ¡n agrupados en pÃ¡ginas de 8K, que tambiÃ©n son la unidad de transferencia en las solicitudes de recuperaciÃ³n. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro anÃ¡lisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idÃ©ntico a T1 excepto que modifica todas las partes atÃ³micas en un solo compuesto. Una transacciÃ³n Ãºnica incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo mÃ³dulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacciÃ³n, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de bÃºsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una cachÃ© de 50MB (de los cuales 6MB se utilizaron para el bÃºfer de objetos modificados), el cliente tenÃ­a una cachÃ© de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos bÃ¡sicos Esta secciÃ³n analiza el costo bÃ¡sico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 RedirecciÃ³n Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtenciÃ³n del servidor), el costo adicional de la redirecciÃ³n incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperaciÃ³n o confirmaciÃ³n del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmaciÃ³n y recuperaciÃ³n del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de Ã¡rea rÃ¡pida. Todos los nÃºmeros fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirecciÃ³n al cruzar el redireccionador no es muy alto, incluso en una red de Ã¡rea local. El costo de la confirmaciÃ³n aumenta con el nÃºmero de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperaciÃ³n no aumenta tanto porque la cachÃ© del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la cachÃ© del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperaciÃ³n entre pares, medimos la latencia de la recuperaciÃ³n entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperaciÃ³n entre pares, el costo de la redirecciÃ³n incluye, ademÃ¡s del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este Ãºltimo incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la pÃ¡gina solicitada. Medimos directamente el tiempo para copiar y desenrollar la pÃ¡gina solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperaciÃ³n de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador mÃ¡s un viaje de ida y vuelta a travÃ©s de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud mÃ¡s un viaje de ida y vuelta a travÃ©s de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando estÃ¡ bloqueado esperando una respuesta de bÃºsqueda o confirmaciÃ³n. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podrÃ­a ser mitigado por una implementaciÃ³n multi-hilo en un sistema con programaciÃ³n preemptiva. 6.3.2 VersiÃ³n de CachÃ© El commit en solitario permite que un cliente rÃ¡pido que modifica un objeto haga un commit de forma independiente a un compaÃ±ero lento. El mecanismo de confirmaciÃ³n Ãºnica introduce un procesamiento adicional en el servidor durante la validaciÃ³n de la transacciÃ³n, y un procesamiento adicional en el cliente durante la confirmaciÃ³n de la transacciÃ³n y en el momento del procesamiento de actualizaciÃ³n o invalidaciÃ³n. Los gastos generales del lado del servidor son mÃ­nimos y consisten en una actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina en el momento de la confirmaciÃ³n, y una comparaciÃ³n del nÃºmero de versiÃ³n en el momento de la validaciÃ³n de la transacciÃ³n. La cachÃ© de versiÃ³n tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacciÃ³n accede a objetos en mÃºltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor Ãºnico y, por lo tanto, el tiempo de confirmaciÃ³n adicional de la gestiÃ³n de la cachÃ© de versiones en el cliente no contribuye a los resultados presentados en la secciÃ³n a continuaciÃ³n. Para medir estos costos adicionales del lado del cliente en un sistema de mÃºltiples servidores, instrumentamos la implementaciÃ³n de la cachÃ© de versiones para ejecutarse con una traza de carga de trabajo que incluÃ­a invalidaciones reordenadas y cronometramos las operaciones bÃ¡sicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operaciÃ³n de bÃºsqueda de cachÃ© de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n en el momento de preparaciÃ³n de la solicitud de compromiso, y una operaciÃ³n de inserciÃ³n de cachÃ© de versiÃ³n para cada objeto actualizado por una transacciÃ³n en el momento de procesamiento de la respuesta de compromiso, pero solo si la pÃ¡gina actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmaciÃ³n se mantengan al mÃ­nimo, ya que el cliente estÃ¡ esperando de forma sÃ­ncrona la finalizaciÃ³n de la confirmaciÃ³n. Las mediciones muestran que en el peor de los casos, cuando llega un gran nÃºmero de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en pÃ¡ginas reordenadas, el costo de actualizar la cachÃ© de versiÃ³n es de 0.6 ms. El costo de tiempo de invalidaciÃ³n es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementaciÃ³n de la cachÃ© de versiones para reducir aÃºn mÃ¡s estos costos. 6.4 Rendimiento general Esta secciÃ³n examina las mejoras de rendimiento observadas por una aplicaciÃ³n que ejecuta el benchmark OO7 con un BuddyCache en una red de Ã¡rea amplia. 6.4.1 Fallos en frÃ­o Para evaluar las mejoras de rendimiento al evitar fallos en frÃ­o, comparamos el rendimiento de la cachÃ© en frÃ­o del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecuciÃ³n de los sistemas en el entorno de la red de Ã¡rea local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de Ã¡rea amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en cachÃ© frÃ­a. Los nÃºmeros fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frÃ­o solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frÃ­o solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparaciÃ³n con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cÃ¡lculos para el cliente, solicitudes de recuperaciÃ³n directa, recuperaciones de pares y solicitudes de confirmaciÃ³n. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperaciÃ³n entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperaciÃ³n del servidor para cada cliente individual disminuye porque, con mÃ¡s clientes accediendo a un mÃ³dulo compartido de tamaÃ±o fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperaciÃ³n de pares en comparaciÃ³n con la recuperaciÃ³n directa, pero este beneficio se ve contrarrestado por los tiempos de confirmaciÃ³n aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relaciÃ³n con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de cachÃ© 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT funciÃ³n de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias tÃ­picas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Sorprendentemente, los resultados analÃ­ticos predicen la mejora medida muy de cerca, aunque son ligeramente mÃ¡s altos que los valores empÃ­ricos. La razÃ³n principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidaciÃ³n evitados, comparamos el rendimiento de cachÃ© caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interÃ©s de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un Ãºnico cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compaÃ±eros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compaÃ±eros con un grupo que contiene un Ãºnico escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuraciÃ³n simple es suficiente para mostrar el impacto de las tÃ©cnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de cachÃ© caliente de OO7. Obtenemos los nÃºmeros ejecutando 2000 transacciones para filtrar los fallos en frÃ­o y luego medimos el tiempo de las siguientes 1000 transacciones. AquÃ­ nuevamente, los nÃºmeros reportados se derivan de los resultados del experimento de la red de Ã¡rea local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalizaciÃ³n en comparaciÃ³n con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparaciÃ³n con la Base. Este beneficio se debe a la actualizaciÃ³n entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperaciÃ³n entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperaciÃ³n local evitando el retraso de la recuperaciÃ³n desde el servidor. El Ãºltimo es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperaciÃ³n de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperaciÃ³n de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualizaciÃ³n de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relaciÃ³n con Base, y Buddy Writer y Base en relaciÃ³n con Base) en un experimento de cachÃ© activa en funciÃ³n del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualizaciÃ³n entre pares domina el gasto general en la configuraciÃ³n de Writer incluso en redes de baja latencia (la actualizaciÃ³n entre pares incurre en un gasto mÃ­nimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Como en experimentos de cachÃ© frÃ­a, aquÃ­ los resultados analÃ­ticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pÃ©rdida de invalidaciÃ³n es mÃ­nimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de cachÃ© frÃ­a). Como en el caso de cachÃ© frÃ­a, la razÃ³n por la que el modelo analÃ­tico simplificado funciona bien es porque captura los costos de la latencia de red, el <br>costo de rendimiento dominante</br>. 7. CONCLUSIÃ“N Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en una red de Ã¡rea extensa debido a la alta latencia de red. Este artÃ­culo describe BuddyCache, una nueva tÃ©cnica de almacenamiento en cachÃ© cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La tÃ©cnica mejora el rendimiento y proporciona propiedades sÃ³lidas de correcciÃ³n y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirecciÃ³n para obtener objetos faltantes directamente de las cachÃ©s de los miembros del grupo, y para admitir la actualizaciÃ³n entre pares, una nueva tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirecciÃ³n puede interferir con la disponibilidad del objeto. Solo commit es una nueva tÃ©cnica de validaciÃ³n que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validaciÃ³n detallada utilizando informaciÃ³n de versiÃ³n de grano grueso econÃ³mica. Hemos diseÃ±ado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analÃ­ticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Las principales contribuciones del artÃ­culo son: 1. extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementaciÃ³n del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluaciÃ³n del rendimiento basada en anÃ¡lisis y mediciones de los costos y beneficios de las nuevas tÃ©cnicas que capturan el <br>costo de rendimiento dominante</br>, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. TambiÃ©n agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios Ãºtiles que mejoraron este artÃ­culo. 9. REFERENCIAS [1] emulab.net, la InstalaciÃ³n de EmulaciÃ³n de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. ReconstrucciÃ³n de fragmentos: Proporcionando coherencia de cachÃ© global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre GestiÃ³n de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: ComputaciÃ³n en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de cachÃ© hÃ­bridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. RecuperaciÃ³n rÃ¡pida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de cachÃ© en la World Wide Web. En la 17Âª Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluaciÃ³n del rendimiento del sistema de gestiÃ³n de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una cachÃ© de objetos jerÃ¡rquica en Internet. En la Conferencia TÃ©cnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachÃ©s de Internet escalables. Informe TÃ©cnico CS-1997-18, Departamento de Ciencias de la ComputaciÃ³n, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: CachÃ© de proxy cooperativa en una red de Ã¡rea amplia. En el Tercer Taller Internacional de CachÃ© de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. CachÃ© web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2Âº Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. CachÃ© cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilaciÃ³n y en tiempo de ejecuciÃ³n para una memoria compartida distribuida eficiente. En Actas de IEEE, EdiciÃ³n Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la cachÃ©: un protocolo de intercambio de cachÃ© web escalable de Ã¡rea amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. ImplementaciÃ³n de GestiÃ³n Global de Memoria en un ClÃºster de Estaciones de Trabajo. Actas del 15Âº Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: DiseÃ±o, ImplementaciÃ³n y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de cachÃ© transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, pÃ¡ginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. GestiÃ³n global de memoria para arquitecturas de sistemas de gestiÃ³n de bases de datos cliente-servidor. En Actas del 19Âº Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El BÃºfer de Objeto Modificado: Una TÃ©cnica de GestiÃ³n de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto TecnolÃ³gico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. GestiÃ³n de documentos replicados en un sistema de comunicaciÃ³n grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13Âª Conferencia Europea sobre ProgramaciÃ³n Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18Âº Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. ReplicaciÃ³n con marca de vista: un nuevo mÃ©todo de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de ComputaciÃ³n Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalaciÃ³n eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de MultidifusiÃ³n a Nivel de AplicaciÃ³n. En el 3er Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de cachÃ© cooperativa utilizando pistas. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en CachÃ© Global. Informe tÃ©cnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del CachÃ© de Proxies Web Cooperativos. En el 17Âº Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerÃ¡rquica de cachÃ© en una WAN. En el Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. ComparticiÃ³n adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÃ‰NDICE Este apÃ©ndice describe el protocolo de conmutaciÃ³n por error de BuddyCache. Para dar cabida a clientes heterogÃ©neos, incluidos los dispositivos portÃ¡tiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseÃ±o de BuddyCache asume que las cachÃ©s del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresÃ­a detecta el fallo de un cliente o un redireccionador intercambiando mensajes periÃ³dicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutaciÃ³n por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuraciÃ³n y reinicia el protocolo. El protocolo de reconfiguraciÃ³n del grupo es similar al presentado en [25]. AquÃ­ describimos cÃ³mo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de pÃ¡ginas redireccionadas y el reenvÃ­o de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachÃ©s. En caso de un fallo del cliente, el failover elimina las pÃ¡ginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmaciÃ³n, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en cachÃ© las pÃ¡ginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutaciÃ³n por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de pÃ¡ginas utilizando un protocolo similar al descrito en [6]. El redireccionador reciÃ©n reiniciado solicita a los miembros activos del grupo la lista de pÃ¡ginas que estÃ¡n almacenando en cachÃ© y el estado de estas pÃ¡ginas, es decir, si las pÃ¡ginas estÃ¡n completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperaciÃ³n perdida expirarÃ¡ en el cliente y serÃ¡ retransmitida. Una transacciÃ³n que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma despuÃ©s del cambio se trata como una transacciÃ³n regular; una transacciÃ³n que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciarÃ¡ la transacciÃ³n y la solicitud de confirmaciÃ³n serÃ¡ retransmitida despuÃ©s del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caÃ­do podrÃ­an evitar la recolecciÃ³n de basura de las invalidaciones pendientes en los servidores o la cachÃ© virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los nÃºmeros de versiÃ³n Ãºnicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validaciÃ³n de transacciones depende del protocolo de coherencia de cachÃ© para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutaciÃ³n por error de BuddyCache no compromete la correcciÃ³n del procedimiento de validaciÃ³n. Recuerda que la validaciÃ³n de transacciones de BuddyCache utiliza dos mecanismos complementarios, nÃºmeros de versiÃ³n de pÃ¡gina y confirmaciones de invalidaciÃ³n de los clientes, para verificar que una transacciÃ³n ha leÃ­do datos actualizados. La propagaciÃ³n de la confirmaciÃ³n de invalidaciÃ³n (y actualizaciÃ³n) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmaciÃ³n de una modificaciÃ³n (invalidaciÃ³n o actualizaciÃ³n) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en cachÃ© el objeto o bien ha instalado el valor mÃ¡s reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmaciÃ³n de un cliente para una transacciÃ³n T que lee un objeto o despuÃ©s de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidaciÃ³n no confirmada para o pendiente para este grupo, la versiÃ³n del objeto leÃ­da por la transacciÃ³n T estÃ¡ actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validaciÃ³n utilizando nÃºmeros de versiÃ³n. El registro de confirmaciÃ³n de transacciÃ³n contiene un nÃºmero de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n. El protocolo de nÃºmero de versiÃ³n mantiene la invariante V P que garantiza que el valor del objeto o leÃ­do por la transacciÃ³n corresponda al nÃºmero de versiÃ³n mÃ¡s alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificaciÃ³n anterior despuÃ©s de haber recibido una modificaciÃ³n posterior. La retransmisiÃ³n de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validaciÃ³n verifica que el nÃºmero de versiÃ³n en el registro de confirmaciÃ³n coincida con el nÃºmero de versiÃ³n en la invalidaciÃ³n pendiente no reconocida. Es fÃ¡cil ver que, dado que esta comprobaciÃ³n es una comprobaciÃ³n cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutaciÃ³n por error aÃºn no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "optimistic system": {
            "translated_key": "sistema optimista",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an <br>optimistic system</br>.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an <br>optimistic system</br>."
            ],
            "translated_annotated_samples": [
                "Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un <br>sistema optimista</br>."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de Ã¡rea amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de Ã¡rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil. Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en cachÃ© web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos. Sin embargo, las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica. La interacciÃ³n con el servidor aumenta la latencia. La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia. Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n. Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo. BuddyCache presenta dos desafÃ­os tÃ©cnicos principales. Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©. El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de almacenamiento en cachÃ© web cooperativos [11]. Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo. BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos. Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica. Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad? DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red. Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia. El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida. Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache. Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n. Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un <br>sistema optimista</br>. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos. Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de Ã¡rea amplia. Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad. Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un Ãºnico servidor. Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web. El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en cachÃ© transaccional [19]. La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una transacciÃ³n, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador. El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado. AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©. Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina). La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente. El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento. A continuaciÃ³n, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene. La transacciÃ³n puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor. Sin embargo, antes de que una transacciÃ³n se confirme, debe ser validada; el servidor debe asegurarse de que la transacciÃ³n validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada. Si la validaciÃ³n falla, la transacciÃ³n se cancela. Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de bÃºsqueda de pares envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la cachÃ© y envÃ­an confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la cachÃ© del cliente, la confirmaciÃ³n de invalidaciÃ³n indica al servidor que un cliente sin invalidaciones pendientes ha leÃ­do objetos actualizados. Una invalidaciÃ³n no reconocida indica que un objeto obsoleto puede haber sido accedido en la cachÃ© del cliente. El procedimiento de validaciÃ³n en el servidor aborta una transacciÃ³n del cliente si este lee un objeto mientras hay una invalidaciÃ³n pendiente. El mecanismo de invalidaciÃ³n reconocido admite coherencia de cachÃ© a nivel de objeto sin directorios basados en objetos o nÃºmeros de versiÃ³n por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeÃ±os, ya que los objetos tÃ­picos son pequeÃ±os. Un objetivo importante del diseÃ±o de BuddyCache es mantener este beneficio. Dado que en BuddyCache una pÃ¡gina puede ser recuperada en una cachÃ© de cliente sin intervenciÃ³n del servidor (como se ilustra en la figura 2), los directorios de cachÃ© en los servidores llevan un registro de las pÃ¡ginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las pÃ¡ginas almacenadas en cachÃ© en cada cliente de un grupo. Los servidores envÃ­an al redireccionador invalidaciones para las pÃ¡ginas almacenadas en cachÃ© en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. ActualizaciÃ³n de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en cachÃ© por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interÃ©s potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de cachÃ© y las actualizaciones de cachÃ©. Los estudios de coherencia de cachÃ© en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualizaciÃ³n y la invalidaciÃ³n. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. AlmacÃ©n x 6. ActualizaciÃ³n x 3. CompromÃ©tete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares estÃ¡n fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeÃ±as, agrupadas y se envÃ­an junto con otros mensajes. AdemÃ¡s, los protocolos de invalidaciÃ³n se ajustan a la tendencia actual de hardware de aumentar los tamaÃ±os de cachÃ© del cliente. Es probable que las cachÃ©s mÃ¡s grandes contengan mucha mÃ¡s informaciÃ³n de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una red de Ã¡rea amplia serÃ­an derrochadores. Sin embargo, los protocolos de coherencia basados en invalidaciÃ³n pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interÃ©s para otro miembro del grupo. Con un protocolo basado en invalidaciÃ³n, la actualizaciÃ³n de un miembro invalidarÃ¡ la copia en cachÃ© de otro miembro, lo que provocarÃ¡ que este Ãºltimo realice una recuperaciÃ³n de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualizaciÃ³n e invalidaciÃ³n en entornos de redes de Ã¡rea amplia. Evita la penalizaciÃ³n de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalizaciÃ³n de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusiÃ³n localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en cachÃ© anteriores. La actualizaciÃ³n entre pares funciona de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que la transacciÃ³n se confirma, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n, y tambiÃ©n propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmaciÃ³n. 3.3 ConfirmaciÃ³n individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminaciÃ³n de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en cachÃ© transaccional, ya que un cliente que es lento para reconocer una invalidaciÃ³n o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacciÃ³n. Por ejemplo, un ingeniero que realiza una revisiÃ³n repetida al mismo objeto de diseÃ±o compartido (y por lo tanto tiene la Ãºltima versiÃ³n del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situaciÃ³n representada en la figura 4 donde el Cliente1 realiza una transacciÃ³n T que lee la Ãºltima versiÃ³n de un objeto x en la pÃ¡gina P recientemente modificada por el Cliente1. Si la solicitud de confirmaciÃ³n para T llega al servidor antes de que la confirmaciÃ³n colectiva de Cliente2 por la Ãºltima modificaciÃ³n de x llegue al servidor, el procedimiento de validaciÃ³n de OCC considera que x estÃ¡ obsoleto y aborta T (porque, como se explicÃ³ anteriormente, una invalidaciÃ³n no reconocida por un cliente actÃºa como indicaciÃ³n para el servidor de que el valor del objeto en cachÃ© estÃ¡ obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la correcciÃ³n del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asÃ­ncronas son una parte importante de la razÃ³n por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasiÃ³n de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envÃ­an y procesan de forma asÃ­ncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devoluciÃ³n de llamada jerÃ¡rquica [32], pero la naturaleza asincrÃ³nica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrÃ³nicas. El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a un cliente con objetos actualizados confirmar una transacciÃ³n incluso si la confirmaciÃ³n del grupo se retrasa debido a pares lentos o caÃ­dos. El protocolo requiere que los clientes incluyan informaciÃ³n adicional con los conjuntos de lectura de transacciones en el mensaje de confirmaciÃ³n, para indicar al servidor que los objetos leÃ­dos por la transacciÃ³n estÃ¡n actualizados. Los nÃºmeros de versiÃ³n de los objetos podrÃ­an proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionÃ³ anteriormente, mantener nÃºmeros de versiÃ³n por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaÃ±o de directorio) en todo el sistema de objetos cuando los objetos son pequeÃ±os [23]. En cambio, solo utiliza nÃºmeros de versiÃ³n de pÃ¡gina de grano grueso para identificar versiones de objetos de grano fino. El nÃºmero de versiÃ³n de una pÃ¡gina se incrementa en un servidor cuando una transacciÃ³n que modifica objetos en la pÃ¡gina se confirma. Las actualizaciones realizadas por una Ãºnica transacciÃ³n y las invalidaciones correspondientes son identificadas de manera Ãºnica por el nÃºmero de versiÃ³n de la pÃ¡gina modificada. Los nÃºmeros de versiÃ³n de la pÃ¡gina se propagan a los clientes en respuestas de recuperaciÃ³n, respuestas de confirmaciÃ³n y con invalidaciones, y los clientes incluyen los nÃºmeros de versiÃ³n de la pÃ¡gina en las solicitudes de confirmaciÃ³n enviadas a los servidores. Si una transacciÃ³n falla en la validaciÃ³n debido a la falta de reconocimiento de grupo, el servidor verifica los nÃºmeros de versiÃ³n de pÃ¡gina de los objetos en el conjunto de lectura de la transacciÃ³n y permite que la transacciÃ³n se confirme si el cliente ha leÃ­do desde la Ãºltima versiÃ³n de la pÃ¡gina. Los nÃºmeros de versiÃ³n de la pÃ¡gina permiten confirmaciones independientes, pero las verificaciones de versiÃ³n de pÃ¡gina solo detectan conflictos a nivel de pÃ¡gina. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La secciÃ³n 4 describe los detalles de la implementaciÃ³n del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 ConfiguraciÃ³n de Grupo La arquitectura BuddyCache admite mÃºltiples grupos de pares concurrentes. Potencialmente, puede ser mÃ¡s rÃ¡pido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podrÃ­a ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en cachÃ© de pares de mÃºltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en cachÃ© web, simplemente aumentar la poblaciÃ³n de clientes en una cachÃ© proxy a menudo aumenta la tasa general de aciertos en la cachÃ© [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacciÃ³n explÃ­cita entre clientes y la colaboraciÃ³n, lo que sugiere que es poco probable que ocurra la recuperaciÃ³n entre grupos. AdemÃ¡s, las mediciones de sistemas de almacenamiento en cachÃ© web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexiÃ³n de red entre los grupos de pares sea muy rÃ¡pida. Estamos principalmente interesados en entornos donde compaÃ±eros que colaboran estrechamente tienen una conectividad rÃ¡pida a corta distancia, pero la conexiÃ³n entre grupos de compaÃ±eros puede ser lenta. Como resultado, decidimos que el soporte para la recuperaciÃ³n entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compaÃ±eros con recursos heterogÃ©neos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compaÃ±eros o, cuando estÃ© disponible, en un nodo separado dentro de la infraestructura del sitio. AdemÃ¡s, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una cachÃ© de pares en espera para recibir pÃ¡ginas recuperadas por otros pares, emulando una cachÃ© central algo similar a una cachÃ© de proxy web regional. Desde el punto de vista del protocolo de coherencia de cachÃ© BuddyCache, sin embargo, un cachÃ© de compaÃ±ero en espera es equivalente a un cachÃ© de compaÃ±ero regular y, por lo tanto, no consideramos este caso por separado en la discusiÃ³n de este documento. 4. En esta secciÃ³n proporcionamos los detalles de la implementaciÃ³n de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en cachÃ© de estos objetos. Las aplicaciones se ejecutan en los clientes e interactÃºan con el sistema realizando llamadas a mÃ©todos de objetos en cachÃ©. Todas las llamadas a mÃ©todos ocurren dentro de transacciones atÃ³micas. Los clientes se comunican con los servidores para obtener pÃ¡ginas o realizar una transacciÃ³n. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volÃ¡til. El disco estÃ¡ organizado como una colecciÃ³n de pÃ¡ginas que son las unidades de acceso al disco. El registro estable guarda la informaciÃ³n de confirmaciÃ³n y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de cachÃ© y una cachÃ© de objetos modificados recuperable llamada MOB. El directorio lleva un registro de quÃ© pÃ¡ginas estÃ¡n almacenadas en cachÃ© por quÃ© clientes. El MOB contiene objetos recientemente modificados que aÃºn no han sido escritos de vuelta en sus pÃ¡ginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de cachÃ© base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la SecciÃ³n 3.1. Proporcionamos algunos de los detalles relevantes de la implementaciÃ³n del protocolo OCC. El cliente lleva un registro de los objetos que son leÃ­dos y modificados por su transacciÃ³n; envÃ­a esta informaciÃ³n, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacciÃ³n. Los servidores determinan si la confirmaciÃ³n es posible, utilizando un protocolo de confirmaciÃ³n de dos fases si la transacciÃ³n utilizÃ³ objetos en mÃºltiples servidores. Si la transacciÃ³n se lleva a cabo, las nuevas copias de los objetos modificados se aÃ±aden al registro y tambiÃ©n se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperaciÃ³n escaneando el registro. Dado que los objetos no estÃ¡n bloqueados antes de ser utilizados, una confirmaciÃ³n de transacciÃ³n puede hacer que las cachÃ©s contengan objetos obsoletos. Los servidores abortarÃ¡n una transacciÃ³n que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviÃ¡ndoles mensajes de invalidaciÃ³n; un servidor utiliza su directorio y la informaciÃ³n sobre la transacciÃ³n de confirmaciÃ³n para determinar quÃ© mensajes de invalidaciÃ³n enviar. Los mensajes de invalidaciÃ³n son pequeÃ±os porque simplemente identifican objetos obsoletos. AdemÃ¡s, se envÃ­an en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidaciÃ³n, elimina los objetos obsoletos de su cachÃ© y aborta la transacciÃ³n actual si los utilizÃ³. El cliente sigue conservando pÃ¡ginas que contienen objetos invalidados; estas pÃ¡ginas ahora estÃ¡n incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidaciÃ³n de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener pÃ¡ginas incompletas en la cachÃ© del cliente significa que el falso intercambio no conduce a fallos innecesarios en la cachÃ©. Los clientes reconocen las invalidaciones para indicar la eliminaciÃ³n de datos obsoletos, como se explica en la SecciÃ³n 3.1. Los mensajes de invalidaciÃ³n evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo asÃ­ el desperdicio de trabajo y trasladando la detecciÃ³n de abortos de los servidores a los clientes. Cuando una transacciÃ³n se aborta, su cliente restaura las copias en cachÃ© de los objetos modificados al estado que tenÃ­an antes de que la transacciÃ³n comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacciÃ³n. 4.3 RedirecciÃ³n El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de pÃ¡ginas disponibles en el grupo de pares y proporciona una redirecciÃ³n rÃ¡pida y centralizada de recuperaciÃ³n (ver figura 2) entre las cachÃ©s de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan pÃ¡ginas u objetos al incluir esa informaciÃ³n en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la cachÃ© de grupo, el redireccionador realiza un seguimiento del estado de las pÃ¡ginas. Una pÃ¡gina en cachÃ© estÃ¡ completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una pÃ¡gina estÃ¡n marcados como invÃ¡lidos. Solo se utilizan pÃ¡ginas completas por el proceso de recuperaciÃ³n de pares. El protocolo para mantener el estado de la pÃ¡gina cuando las pÃ¡ginas son actualizadas e invalidadas se describe en la SecciÃ³n 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una pÃ¡gina solicitada completa no estÃ¡ disponible en el grupo de pares o si un par necesita confirmar una transacciÃ³n, el redireccionador actÃºa como un proxy de servidor: reenvÃ­a la solicitud al servidor y luego reenvÃ­a la respuesta de vuelta al cliente. AdemÃ¡s, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualizaciÃ³n o informaciÃ³n de invalidaciÃ³n a los clientes que tienen en cachÃ© la pÃ¡gina modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la cachÃ© de grupo de pares combinada estÃ¡ desempeÃ±ando el papel de una Ãºnica cachÃ© de cliente en el sistema base. 4.4 ActualizaciÃ³n de pares La actualizaciÃ³n de pares se implementa de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que una transacciÃ³n se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacciÃ³n generan invalidaciones de objetos para cada grupo de cachÃ© que almacena pÃ¡ginas que contienen los objetos modificados (incluido el grupo que realiza la confirmaciÃ³n). Las invalidaciones se envÃ­an de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en cachÃ© los objetos modificados se deshagan de los datos obsoletos. En grupos de cachÃ© distintos al grupo de confirmaciÃ³n, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas, recopilan las confirmaciones de los clientes y, despuÃ©s de completar la recopilaciÃ³n, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacciÃ³n, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envÃ­an a los clientes que almacenan en cachÃ© esas pÃ¡ginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmaciÃ³n colectiva se propaga al servidor. Una invalidaciÃ³n hace que una pÃ¡gina en cachÃ© no estÃ© disponible para la recuperaciÃ³n de pares, cambiando el estado de una pÃ¡gina completa p a incompleta. Por el contrario, una actualizaciÃ³n de una pÃ¡gina completa conserva el estado completo de la pÃ¡gina. Como se muestra en los estudios de la reconstrucciÃ³n de fragmentos 31 [2], esta propagaciÃ³n de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma pÃ¡gina, la pÃ¡gina conserva su estado completo y permanece disponible para la recuperaciÃ³n entre pares. Por lo tanto, el efecto de la actualizaciÃ³n de pares es similar a la reconstrucciÃ³n de fragmentos ansiosa [2]. TambiÃ©n hemos considerado la posibilidad de permitir que un compaÃ±ero recupere una pÃ¡gina incompleta (con objetos invÃ¡lidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos invÃ¡lidos. 4.5 Vcache El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo mÃ¡s lentos (o fallidos). Como se explica en la SecciÃ³n 3.3, el protocolo de commit Ãºnico permite que una transacciÃ³n T pase la validaciÃ³n si la informaciÃ³n adicional de coherencia proporcionada por el cliente indica que la transacciÃ³n T ha leÃ­do objetos actualizados. Los clientes utilizan los nÃºmeros de versiÃ³n de la pÃ¡gina para proporcionar esta informaciÃ³n adicional de coherencia. Es decir, un cliente incluye el nÃºmero de versiÃ³n de la pÃ¡gina correspondiente a cada objeto en el conjunto de objetos leÃ­dos enviado en la solicitud de confirmaciÃ³n al servidor. Dado que a cada actualizaciÃ³n de objeto comprometido le corresponde un nÃºmero de versiÃ³n de pÃ¡gina Ãºnico, el nÃºmero de versiÃ³n de pÃ¡gina asociado con un objeto permite que el procedimiento de validaciÃ³n en el servidor verifique si la transacciÃ³n del cliente ha leÃ­do objetos actualizados. El uso de versiones de pÃ¡gina de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeÃ±os, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en cachÃ© a la versiÃ³n de pÃ¡gina identificadora (ObjectToVersion). El principal problema de implementaciÃ³n se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian nÃºmeros de versiÃ³n de pÃ¡gina con las invalidaciones. En el momento de la validaciÃ³n, si hay una invalidaciÃ³n no reconocida pendiente para un objeto x leÃ­do por una transacciÃ³n T, el procedimiento de validaciÃ³n verifica si el nÃºmero de versiÃ³n de x en el conjunto de lectura de Ts coincide con el nÃºmero de versiÃ³n de la invalidaciÃ³n pendiente mÃ¡s alta para x, en cuyo caso el valor del objeto estÃ¡ actualizado, de lo contrario, T falla en la validaciÃ³n. Observamos nuevamente que las verificaciones basadas en el nÃºmero de versiÃ³n de la pÃ¡gina y las verificaciones basadas en el reconocimiento de invalidaciÃ³n son complementarias en la validaciÃ³n de confirmaciÃ³n individual y ambas son necesarias. La verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina permite que la validaciÃ³n avance antes de que lleguen las confirmaciones de invalidaciÃ³n, pero por sÃ­ sola, una verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina detecta conflictos a nivel de pÃ¡gina y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cÃ³mo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un nÃºmero de versiÃ³n de la pÃ¡gina para cada pÃ¡gina en cachÃ©. El nÃºmero de versiÃ³n satisface la siguiente invariante V P sobre el estado de los objetos en una pÃ¡gina: si una pÃ¡gina en cachÃ© P tiene un nÃºmero de versiÃ³n v, entonces el valor de un objeto o en la pÃ¡gina en cachÃ© P es invÃ¡lido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacciÃ³n que estableciÃ³ el nÃºmero de versiÃ³n de P en v. Los nuevos valores de objetos y los nuevos nÃºmeros de versiÃ³n de pÃ¡gina llegan cuando un cliente obtiene una pÃ¡gina o cuando llega una respuesta de confirmaciÃ³n o invalidaciones para esta pÃ¡gina. Los nuevos valores del objeto modifican la pÃ¡gina y, por lo tanto, el nÃºmero de versiÃ³n de la pÃ¡gina necesita ser actualizado para mantener la invariante V P. Un nÃºmero de versiÃ³n de pÃ¡gina que llega cuando un cliente obtiene una pÃ¡gina, reemplaza la VersiÃ³n del Objeto x 8 Servidor de RedirecciÃ³n 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el nÃºmero de versiÃ³n de la pÃ¡gina para esta pÃ¡gina. Tal actualizaciÃ³n preserva el invariante V P. De manera similar, un nÃºmero de versiÃ³n de pÃ¡gina en secuencia que llega al cliente en un mensaje de confirmaciÃ³n o invalidaciÃ³n avanza el nÃºmero de versiÃ³n para toda la pÃ¡gina en cachÃ©, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus nÃºmeros de versiÃ³n de pÃ¡gina correspondientes tambiÃ©n pueden llegar al cliente fuera de secuencia, en cuyo caso la actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina podrÃ­a violar V P. Por ejemplo, una respuesta de confirmaciÃ³n para una transacciÃ³n que actualiza el objeto x en la pÃ¡gina P en el servidor S1, y el objeto y en la pÃ¡gina Q en el servidor S2, puede entregar un nuevo nÃºmero de versiÃ³n para P desde el coordinador de transacciones S1 antes de que llegue una invalidaciÃ³n generada para una transacciÃ³n anterior que ha modificado el objeto r en la pÃ¡gina P desde S1 (como se muestra en la figura 5). El protocolo de actualizaciÃ³n de cachÃ© garantiza que el valor de cualquier objeto o en una pÃ¡gina en cachÃ© P refleje la actualizaciÃ³n o invalidaciÃ³n con el nÃºmero de versiÃ³n observado mÃ¡s alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de nÃºmeros de versiÃ³n de pÃ¡gina, el cliente gestiona una pequeÃ±a cachÃ© de nÃºmeros de versiÃ³n vcache que mantiene el mapeo de un objeto a su nÃºmero de versiÃ³n de pÃ¡gina correspondiente para todas las actualizaciones de nÃºmeros de versiÃ³n reordenadas hasta que se ensamble una secuencia completa de nÃºmeros de versiÃ³n de pÃ¡gina. Cuando llegan los nÃºmeros de versiÃ³n faltantes para la pÃ¡gina y completan una secuencia, el nÃºmero de versiÃ³n de toda la pÃ¡gina se avanza. El mapeo de ObjectToVersion, incluyendo los nÃºmeros de versiÃ³n de vcache y pÃ¡gina, se utiliza en el momento de la confirmaciÃ³n de la transacciÃ³n para proporcionar nÃºmeros de versiÃ³n para el conjunto de objetos leÃ­dos de la siguiente manera. Si el objeto leÃ­do tiene una entrada en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n mÃ¡s alto en la vcache para este objeto. Si el objeto no estÃ¡ presente en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n de la pÃ¡gina en cachÃ© que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la cachÃ© del cliente, incluyendo los nÃºmeros de versiÃ³n de las pÃ¡ginas y la vcache. El cliente puede limitar el tamaÃ±o de la cachÃ© virtual segÃºn sea necesario, ya que volver a cargar una pÃ¡gina elimina todos los nÃºmeros de versiÃ³n de pÃ¡gina reordenados de la cachÃ© virtual. Sin embargo, esperamos que la reorganizaciÃ³n de nÃºmeros de versiÃ³n sea poco comÃºn y, por lo tanto, esperamos que la vcache sea muy pequeÃ±a. 5. Un grupo de clientes contiene mÃºltiples nodos de cliente y un objeto de pÃ¡gina de versiÃ³n redi32 VCache Cliente CachÃ© Cliente PÃ¡gina CachÃ© Figura 6: Mapa de Objeto a VersiÃ³n con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutaciÃ³n por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. AdemÃ¡s, el fallo del redireccionador deberÃ­a permitir que los clientes no afectados mantengan sus cachÃ©s intactas. Hemos diseÃ±ado un protocolo de conmutaciÃ³n por error para BuddyCache pero aÃºn no lo hemos implementado. El apÃ©ndice describe el protocolo. 6. La redirecciÃ³n de BuddyCache en la evaluaciÃ³n de rendimiento respalda los beneficios de evitar la comunicaciÃ³n con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes. Â¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 AnÃ¡lisis Los beneficios de rendimiento de la recuperaciÃ³n entre pares y la actualizaciÃ³n entre pares se deben a la evitaciÃ³n de interacciones con el servidor. Esta secciÃ³n presenta un modelo de rendimiento analÃ­tico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la cachÃ© del cliente. Estos pueden ser fallos frÃ­os, fallos de invalidaciÃ³n y fallos de capacidad. Nuestro anÃ¡lisis se centra en los fallos por frÃ­o y los fallos por invalidaciÃ³n, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frÃ­o. AdemÃ¡s, las tendencias tecnolÃ³gicas indican que la capacidad de memoria y almacenamiento seguirÃ¡ creciendo y, por lo tanto, es probable que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ©. Los fallos de cachÃ© del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuraciÃ³n de cachÃ©. Nuestro anÃ¡lisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validaciÃ³n. Para estudiar el beneficio de evitar fallos en frÃ­o, consideramos el rendimiento de la cachÃ© en frÃ­o en una carga de trabajo de solo lectura (sin fallos de invalidaciÃ³n). Esperamos que la recuperaciÃ³n entre pares mejore el costo de latencia para las solicitudes de cachÃ© frÃ­a del cliente al recuperar objetos de la cachÃ© cercana. Evaluamos cÃ³mo el costo de redirecciÃ³n afecta este beneficio al comparar y analizar el rendimiento de una aplicaciÃ³n que se ejecuta en un sistema de almacenamiento con BuddyCache y sin Ã©l (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidaciÃ³n, consideramos el rendimiento de la cachÃ© caliente en una carga de trabajo con modificaciones (sin fallos en frÃ­o). En las cachÃ©s calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualizaciÃ³n entre pares permite que un cliente acceda a un objeto modificado por un compaÃ±ero colaborador cercano sin el retraso impuesto por los protocolos de invalidaciÃ³n Ãºnicamente. En grupos donde los compaÃ±eros comparten un interÃ©s de solo lectura en los objetos modificados, la recuperaciÃ³n entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compaÃ±ero colaborador lo tenga, lo que evita el retraso de la recuperaciÃ³n del servidor sin el alto costo impuesto por los protocolos de solo actualizaciÃ³n. Las tendencias tecnolÃ³gicas indican que ambos beneficios seguirÃ¡n siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualizaciÃ³n Ãºnicamente. Sin embargo, la tendencia hacia cachÃ©s cada vez mÃ¡s grandes, que se actualizan cuando los objetos en cachÃ© son modificados, hace que los protocolos basados en invalidaciÃ³n sean mÃ¡s atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicaciÃ³n que se ejecuta sin BuddyCache y una aplicaciÃ³n que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compaÃ±ero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compaÃ±ero fuera del grupo. La actualizaciÃ³n entre pares tambiÃ©n puede evitar fallos de invalidaciÃ³n debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma pÃ¡gina de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseÃ±o del objeto, y tambiÃ©n porque este beneficio se puede derivar dado el Ã­ndice de aciertos en cachÃ© y la contenciÃ³n de la carga de trabajo. 6.1.1 El Modelo El modelo considera cÃ³mo el tiempo para completar una ejecuciÃ³n con y sin BuddyCache se ve afectado por los fallos de invalidaciÃ³n y los fallos en frÃ­o. Considerando k clientes ejecutÃ¡ndose concurrentemente accediendo de manera uniforme a un conjunto compartido de N pÃ¡ginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacciÃ³n y realizar cÃ¡lculos en una transacciÃ³n, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin Ã©l (Base). Para simplificar, nuestro modelo asume que los tiempos de bÃºsqueda y confirmaciÃ³n son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del nÃºmero total de clientes en el sistema. El nÃºmero de fallos evitados por la recuperaciÃ³n entre pares depende de k, el nÃºmero de clientes en la BuddyCache, y del interÃ©s conjunto de los clientes en los datos compartidos. En una ejecuciÃ³n especÃ­fica de BuddyCache, se modela mediante la variable r, definida como el nÃºmero de solicitudes que llegan al redireccionador para una versiÃ³n dada de la pÃ¡gina P (es decir, hasta que un objeto en la pÃ¡gina se invalida). Considera una ejecuciÃ³n con fallos en frÃ­o. Un cliente comienza con una cachÃ© frÃ­a y ejecuta una carga de trabajo de solo lectura hasta que accede a las N pÃ¡ginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la cachÃ© del cliente es lo suficientemente grande como para contener N pÃ¡ginas. En BC, los frÃ­os fallos para la pÃ¡gina P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consideremos a continuaciÃ³n una ejecuciÃ³n con fallos de invalidaciÃ³n. Un cliente comienza con una cachÃ© caliente que contiene el conjunto de trabajo de N pÃ¡ginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualizaciÃ³n entre pares elimina todos los fallos de invalidaciÃ³n. En un grupo que contiene solo lectores (BCR), durante una ejecuciÃ³n en estado estable con actualizaciones uniformes, una transacciÃ³n del cliente tiene fallos de invalidaciÃ³n faltantes. Considera la secuencia de r fallos de cliente en la pÃ¡gina P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la pÃ¡gina P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frÃ­o, r â‰¤ k porque la segunda invalidaciÃ³n deshabilita la redirecciÃ³n para P hasta que el prÃ³ximo fallo en P provoque una recuperaciÃ³n del servidor. Suponiendo un acceso uniforme, un fallo de invalidaciÃ³n del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperaciÃ³n del servidor), y una probabilidad de (1 âˆ’ 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacciÃ³n Ãºnica en los sistemas Base, BCR y BCW. En los experimentos descritos a continuaciÃ³n, medimos los parÃ¡metros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalizaciÃ³n derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalizaciÃ³n y beneficios medidos directamente en los experimentos. 6.2 ConfiguraciÃ³n Experimental Antes de presentar nuestros resultados, describimos nuestra configuraciÃ³n experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectÃ¡ndose directamente a los servidores. El sistema Buddy ejecuta nuestra implementaciÃ³n del prototipo de BuddyCache en Thor, admitiendo la recuperaciÃ³n de pares, la actualizaciÃ³n de pares y la confirmaciÃ³n en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark estÃ¡ diseÃ±ado para capturar las caracterÃ­sticas de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicaciÃ³n especÃ­fica. Utilizamos OO7 porque es un punto de referencia estÃ¡ndar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un Ã¡rbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un grÃ¡fico de partes atÃ³micas vinculadas por objetos de conexiÃ³n; cada parte atÃ³mica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atÃ³micas por parte compuesta. La base de datos multiusuario asigna a cada cliente un mÃ³dulo privado que consiste en un Ã¡rbol de objetos de ensamblaje, y agrega un mÃ³dulo compartido adicional que escala proporcionalmente al nÃºmero de clientes. Esperamos que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ© y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la cachÃ©. Dado que el objetivo de nuestro estudio es evaluar quÃ© tan efectivamente nuestras tÃ©cnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras tÃ©cnicas tienen en los fallos de cachÃ© frÃ­o y de consistencia de cachÃ©, y aislar tanto como sea posible el efecto de los fallos de capacidad de cachÃ©. Para mantener la duraciÃ³n de nuestros experimentos razonable, utilizamos cachÃ©s pequeÃ±os. El benchmark OO7 genera mÃ³dulos de base de datos de tamaÃ±o predefinido. En nuestra implementaciÃ³n de OO7, el tamaÃ±o del mÃ³dulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la cachÃ©, utilizamos un Ãºnico mÃ³dulo privado y elegimos un tamaÃ±o de cachÃ© de 40MB para cada cliente. La base de datos OO7 se genera con mÃ³dulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos estÃ¡n agrupados en pÃ¡ginas de 8K, que tambiÃ©n son la unidad de transferencia en las solicitudes de recuperaciÃ³n. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro anÃ¡lisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idÃ©ntico a T1 excepto que modifica todas las partes atÃ³micas en un solo compuesto. Una transacciÃ³n Ãºnica incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo mÃ³dulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacciÃ³n, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de bÃºsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una cachÃ© de 50MB (de los cuales 6MB se utilizaron para el bÃºfer de objetos modificados), el cliente tenÃ­a una cachÃ© de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos bÃ¡sicos Esta secciÃ³n analiza el costo bÃ¡sico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 RedirecciÃ³n Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtenciÃ³n del servidor), el costo adicional de la redirecciÃ³n incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperaciÃ³n o confirmaciÃ³n del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmaciÃ³n y recuperaciÃ³n del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de Ã¡rea rÃ¡pida. Todos los nÃºmeros fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirecciÃ³n al cruzar el redireccionador no es muy alto, incluso en una red de Ã¡rea local. El costo de la confirmaciÃ³n aumenta con el nÃºmero de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperaciÃ³n no aumenta tanto porque la cachÃ© del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la cachÃ© del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperaciÃ³n entre pares, medimos la latencia de la recuperaciÃ³n entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperaciÃ³n entre pares, el costo de la redirecciÃ³n incluye, ademÃ¡s del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este Ãºltimo incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la pÃ¡gina solicitada. Medimos directamente el tiempo para copiar y desenrollar la pÃ¡gina solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperaciÃ³n de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador mÃ¡s un viaje de ida y vuelta a travÃ©s de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud mÃ¡s un viaje de ida y vuelta a travÃ©s de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando estÃ¡ bloqueado esperando una respuesta de bÃºsqueda o confirmaciÃ³n. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podrÃ­a ser mitigado por una implementaciÃ³n multi-hilo en un sistema con programaciÃ³n preemptiva. 6.3.2 VersiÃ³n de CachÃ© El commit en solitario permite que un cliente rÃ¡pido que modifica un objeto haga un commit de forma independiente a un compaÃ±ero lento. El mecanismo de confirmaciÃ³n Ãºnica introduce un procesamiento adicional en el servidor durante la validaciÃ³n de la transacciÃ³n, y un procesamiento adicional en el cliente durante la confirmaciÃ³n de la transacciÃ³n y en el momento del procesamiento de actualizaciÃ³n o invalidaciÃ³n. Los gastos generales del lado del servidor son mÃ­nimos y consisten en una actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina en el momento de la confirmaciÃ³n, y una comparaciÃ³n del nÃºmero de versiÃ³n en el momento de la validaciÃ³n de la transacciÃ³n. La cachÃ© de versiÃ³n tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacciÃ³n accede a objetos en mÃºltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor Ãºnico y, por lo tanto, el tiempo de confirmaciÃ³n adicional de la gestiÃ³n de la cachÃ© de versiones en el cliente no contribuye a los resultados presentados en la secciÃ³n a continuaciÃ³n. Para medir estos costos adicionales del lado del cliente en un sistema de mÃºltiples servidores, instrumentamos la implementaciÃ³n de la cachÃ© de versiones para ejecutarse con una traza de carga de trabajo que incluÃ­a invalidaciones reordenadas y cronometramos las operaciones bÃ¡sicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operaciÃ³n de bÃºsqueda de cachÃ© de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n en el momento de preparaciÃ³n de la solicitud de compromiso, y una operaciÃ³n de inserciÃ³n de cachÃ© de versiÃ³n para cada objeto actualizado por una transacciÃ³n en el momento de procesamiento de la respuesta de compromiso, pero solo si la pÃ¡gina actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmaciÃ³n se mantengan al mÃ­nimo, ya que el cliente estÃ¡ esperando de forma sÃ­ncrona la finalizaciÃ³n de la confirmaciÃ³n. Las mediciones muestran que en el peor de los casos, cuando llega un gran nÃºmero de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en pÃ¡ginas reordenadas, el costo de actualizar la cachÃ© de versiÃ³n es de 0.6 ms. El costo de tiempo de invalidaciÃ³n es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementaciÃ³n de la cachÃ© de versiones para reducir aÃºn mÃ¡s estos costos. 6.4 Rendimiento general Esta secciÃ³n examina las mejoras de rendimiento observadas por una aplicaciÃ³n que ejecuta el benchmark OO7 con un BuddyCache en una red de Ã¡rea amplia. 6.4.1 Fallos en frÃ­o Para evaluar las mejoras de rendimiento al evitar fallos en frÃ­o, comparamos el rendimiento de la cachÃ© en frÃ­o del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecuciÃ³n de los sistemas en el entorno de la red de Ã¡rea local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de Ã¡rea amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en cachÃ© frÃ­a. Los nÃºmeros fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frÃ­o solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frÃ­o solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparaciÃ³n con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cÃ¡lculos para el cliente, solicitudes de recuperaciÃ³n directa, recuperaciones de pares y solicitudes de confirmaciÃ³n. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperaciÃ³n entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperaciÃ³n del servidor para cada cliente individual disminuye porque, con mÃ¡s clientes accediendo a un mÃ³dulo compartido de tamaÃ±o fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperaciÃ³n de pares en comparaciÃ³n con la recuperaciÃ³n directa, pero este beneficio se ve contrarrestado por los tiempos de confirmaciÃ³n aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relaciÃ³n con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de cachÃ© 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT funciÃ³n de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias tÃ­picas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Sorprendentemente, los resultados analÃ­ticos predicen la mejora medida muy de cerca, aunque son ligeramente mÃ¡s altos que los valores empÃ­ricos. La razÃ³n principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidaciÃ³n evitados, comparamos el rendimiento de cachÃ© caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interÃ©s de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un Ãºnico cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compaÃ±eros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compaÃ±eros con un grupo que contiene un Ãºnico escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuraciÃ³n simple es suficiente para mostrar el impacto de las tÃ©cnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de cachÃ© caliente de OO7. Obtenemos los nÃºmeros ejecutando 2000 transacciones para filtrar los fallos en frÃ­o y luego medimos el tiempo de las siguientes 1000 transacciones. AquÃ­ nuevamente, los nÃºmeros reportados se derivan de los resultados del experimento de la red de Ã¡rea local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalizaciÃ³n en comparaciÃ³n con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparaciÃ³n con la Base. Este beneficio se debe a la actualizaciÃ³n entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperaciÃ³n entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperaciÃ³n local evitando el retraso de la recuperaciÃ³n desde el servidor. El Ãºltimo es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperaciÃ³n de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperaciÃ³n de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualizaciÃ³n de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relaciÃ³n con Base, y Buddy Writer y Base en relaciÃ³n con Base) en un experimento de cachÃ© activa en funciÃ³n del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualizaciÃ³n entre pares domina el gasto general en la configuraciÃ³n de Writer incluso en redes de baja latencia (la actualizaciÃ³n entre pares incurre en un gasto mÃ­nimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Como en experimentos de cachÃ© frÃ­a, aquÃ­ los resultados analÃ­ticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pÃ©rdida de invalidaciÃ³n es mÃ­nimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de cachÃ© frÃ­a). Como en el caso de cachÃ© frÃ­a, la razÃ³n por la que el modelo analÃ­tico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÃ“N Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en una red de Ã¡rea extensa debido a la alta latencia de red. Este artÃ­culo describe BuddyCache, una nueva tÃ©cnica de almacenamiento en cachÃ© cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La tÃ©cnica mejora el rendimiento y proporciona propiedades sÃ³lidas de correcciÃ³n y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirecciÃ³n para obtener objetos faltantes directamente de las cachÃ©s de los miembros del grupo, y para admitir la actualizaciÃ³n entre pares, una nueva tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirecciÃ³n puede interferir con la disponibilidad del objeto. Solo commit es una nueva tÃ©cnica de validaciÃ³n que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validaciÃ³n detallada utilizando informaciÃ³n de versiÃ³n de grano grueso econÃ³mica. Hemos diseÃ±ado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analÃ­ticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Las principales contribuciones del artÃ­culo son: 1. extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementaciÃ³n del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluaciÃ³n del rendimiento basada en anÃ¡lisis y mediciones de los costos y beneficios de las nuevas tÃ©cnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. TambiÃ©n agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios Ãºtiles que mejoraron este artÃ­culo. 9. REFERENCIAS [1] emulab.net, la InstalaciÃ³n de EmulaciÃ³n de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. ReconstrucciÃ³n de fragmentos: Proporcionando coherencia de cachÃ© global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre GestiÃ³n de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: ComputaciÃ³n en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de cachÃ© hÃ­bridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. RecuperaciÃ³n rÃ¡pida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de cachÃ© en la World Wide Web. En la 17Âª Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluaciÃ³n del rendimiento del sistema de gestiÃ³n de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una cachÃ© de objetos jerÃ¡rquica en Internet. En la Conferencia TÃ©cnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachÃ©s de Internet escalables. Informe TÃ©cnico CS-1997-18, Departamento de Ciencias de la ComputaciÃ³n, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: CachÃ© de proxy cooperativa en una red de Ã¡rea amplia. En el Tercer Taller Internacional de CachÃ© de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. CachÃ© web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2Âº Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. CachÃ© cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilaciÃ³n y en tiempo de ejecuciÃ³n para una memoria compartida distribuida eficiente. En Actas de IEEE, EdiciÃ³n Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la cachÃ©: un protocolo de intercambio de cachÃ© web escalable de Ã¡rea amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. ImplementaciÃ³n de GestiÃ³n Global de Memoria en un ClÃºster de Estaciones de Trabajo. Actas del 15Âº Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: DiseÃ±o, ImplementaciÃ³n y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de cachÃ© transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, pÃ¡ginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. GestiÃ³n global de memoria para arquitecturas de sistemas de gestiÃ³n de bases de datos cliente-servidor. En Actas del 19Âº Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El BÃºfer de Objeto Modificado: Una TÃ©cnica de GestiÃ³n de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto TecnolÃ³gico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. GestiÃ³n de documentos replicados en un sistema de comunicaciÃ³n grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13Âª Conferencia Europea sobre ProgramaciÃ³n Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18Âº Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. ReplicaciÃ³n con marca de vista: un nuevo mÃ©todo de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de ComputaciÃ³n Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalaciÃ³n eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de MultidifusiÃ³n a Nivel de AplicaciÃ³n. En el 3er Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de cachÃ© cooperativa utilizando pistas. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en CachÃ© Global. Informe tÃ©cnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del CachÃ© de Proxies Web Cooperativos. En el 17Âº Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerÃ¡rquica de cachÃ© en una WAN. En el Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. ComparticiÃ³n adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÃ‰NDICE Este apÃ©ndice describe el protocolo de conmutaciÃ³n por error de BuddyCache. Para dar cabida a clientes heterogÃ©neos, incluidos los dispositivos portÃ¡tiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseÃ±o de BuddyCache asume que las cachÃ©s del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresÃ­a detecta el fallo de un cliente o un redireccionador intercambiando mensajes periÃ³dicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutaciÃ³n por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuraciÃ³n y reinicia el protocolo. El protocolo de reconfiguraciÃ³n del grupo es similar al presentado en [25]. AquÃ­ describimos cÃ³mo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de pÃ¡ginas redireccionadas y el reenvÃ­o de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachÃ©s. En caso de un fallo del cliente, el failover elimina las pÃ¡ginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmaciÃ³n, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en cachÃ© las pÃ¡ginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutaciÃ³n por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de pÃ¡ginas utilizando un protocolo similar al descrito en [6]. El redireccionador reciÃ©n reiniciado solicita a los miembros activos del grupo la lista de pÃ¡ginas que estÃ¡n almacenando en cachÃ© y el estado de estas pÃ¡ginas, es decir, si las pÃ¡ginas estÃ¡n completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperaciÃ³n perdida expirarÃ¡ en el cliente y serÃ¡ retransmitida. Una transacciÃ³n que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma despuÃ©s del cambio se trata como una transacciÃ³n regular; una transacciÃ³n que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciarÃ¡ la transacciÃ³n y la solicitud de confirmaciÃ³n serÃ¡ retransmitida despuÃ©s del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caÃ­do podrÃ­an evitar la recolecciÃ³n de basura de las invalidaciones pendientes en los servidores o la cachÃ© virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los nÃºmeros de versiÃ³n Ãºnicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validaciÃ³n de transacciones depende del protocolo de coherencia de cachÃ© para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutaciÃ³n por error de BuddyCache no compromete la correcciÃ³n del procedimiento de validaciÃ³n. Recuerda que la validaciÃ³n de transacciones de BuddyCache utiliza dos mecanismos complementarios, nÃºmeros de versiÃ³n de pÃ¡gina y confirmaciones de invalidaciÃ³n de los clientes, para verificar que una transacciÃ³n ha leÃ­do datos actualizados. La propagaciÃ³n de la confirmaciÃ³n de invalidaciÃ³n (y actualizaciÃ³n) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmaciÃ³n de una modificaciÃ³n (invalidaciÃ³n o actualizaciÃ³n) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en cachÃ© el objeto o bien ha instalado el valor mÃ¡s reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmaciÃ³n de un cliente para una transacciÃ³n T que lee un objeto o despuÃ©s de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidaciÃ³n no confirmada para o pendiente para este grupo, la versiÃ³n del objeto leÃ­da por la transacciÃ³n T estÃ¡ actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validaciÃ³n utilizando nÃºmeros de versiÃ³n. El registro de confirmaciÃ³n de transacciÃ³n contiene un nÃºmero de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n. El protocolo de nÃºmero de versiÃ³n mantiene la invariante V P que garantiza que el valor del objeto o leÃ­do por la transacciÃ³n corresponda al nÃºmero de versiÃ³n mÃ¡s alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificaciÃ³n anterior despuÃ©s de haber recibido una modificaciÃ³n posterior. La retransmisiÃ³n de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validaciÃ³n verifica que el nÃºmero de versiÃ³n en el registro de confirmaciÃ³n coincida con el nÃºmero de versiÃ³n en la invalidaciÃ³n pendiente no reconocida. Es fÃ¡cil ver que, dado que esta comprobaciÃ³n es una comprobaciÃ³n cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutaciÃ³n por error aÃºn no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "peer fetch": {
            "translated_key": "recuperaciÃ³n de pares",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: <br>peer fetch</br> a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the <br>peer fetch</br>.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for <br>peer fetch</br> changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for <br>peer fetch</br>.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of <br>peer fetch</br> and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect <br>peer fetch</br> to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, <br>peer fetch</br> allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, <br>peer fetch</br>, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by <br>peer fetch</br> depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting <br>peer fetch</br>, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: <br>peer fetch</br> 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the <br>peer fetch</br>, we measure the <br>peer fetch</br> latency (PeerFetch) at the requesting client and break down its component costs.",
                "In <br>peer fetch</br>, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the <br>peer fetch</br> costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch <br>peer fetch</br> Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch <br>peer fetch</br> Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to <br>peer fetch</br> avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by <br>peer fetch</br> relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch <br>peer fetch</br> Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch <br>peer fetch</br> Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to <br>peer fetch</br> that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, <br>peer fetch</br> allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the <br>peer fetch</br> in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: <br>peer fetch</br> a server sends background object invalidation messages to clients caching the containing pages.",
                "Only complete pages are used by the <br>peer fetch</br>.",
                "An invalidation renders a cached page unavailable for <br>peer fetch</br> changing the status of a complete page p into an incomplete.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for <br>peer fetch</br>.",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of <br>peer fetch</br> and peer update are due to avoided server interactions."
            ],
            "translated_annotated_samples": [
                "Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de <br>bÃºsqueda de pares</br> envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen.",
                "Solo se utilizan pÃ¡ginas completas por el proceso de <br>recuperaciÃ³n de pares</br>.",
                "Una invalidaciÃ³n hace que una pÃ¡gina en cachÃ© no estÃ© disponible para la <br>recuperaciÃ³n de pares</br>, cambiando el estado de una pÃ¡gina completa p a incompleta.",
                "Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma pÃ¡gina, la pÃ¡gina conserva su estado completo y permanece disponible para la <br>recuperaciÃ³n entre pares</br>.",
                "Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 AnÃ¡lisis Los beneficios de rendimiento de la <br>recuperaciÃ³n entre pares</br> y la actualizaciÃ³n entre pares se deben a la evitaciÃ³n de interacciones con el servidor."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de Ã¡rea amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de Ã¡rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil. Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en cachÃ© web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos. Sin embargo, las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica. La interacciÃ³n con el servidor aumenta la latencia. La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia. Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n. Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo. BuddyCache presenta dos desafÃ­os tÃ©cnicos principales. Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©. El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de almacenamiento en cachÃ© web cooperativos [11]. Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo. BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos. Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica. Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad? DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red. Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia. El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida. Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache. Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n. Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos. Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de Ã¡rea amplia. Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad. Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un Ãºnico servidor. Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web. El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en cachÃ© transaccional [19]. La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una transacciÃ³n, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador. El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado. AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©. Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina). La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente. El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento. A continuaciÃ³n, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene. La transacciÃ³n puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor. Sin embargo, antes de que una transacciÃ³n se confirme, debe ser validada; el servidor debe asegurarse de que la transacciÃ³n validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada. Si la validaciÃ³n falla, la transacciÃ³n se cancela. Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de <br>bÃºsqueda de pares</br> envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la cachÃ© y envÃ­an confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la cachÃ© del cliente, la confirmaciÃ³n de invalidaciÃ³n indica al servidor que un cliente sin invalidaciones pendientes ha leÃ­do objetos actualizados. Una invalidaciÃ³n no reconocida indica que un objeto obsoleto puede haber sido accedido en la cachÃ© del cliente. El procedimiento de validaciÃ³n en el servidor aborta una transacciÃ³n del cliente si este lee un objeto mientras hay una invalidaciÃ³n pendiente. El mecanismo de invalidaciÃ³n reconocido admite coherencia de cachÃ© a nivel de objeto sin directorios basados en objetos o nÃºmeros de versiÃ³n por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeÃ±os, ya que los objetos tÃ­picos son pequeÃ±os. Un objetivo importante del diseÃ±o de BuddyCache es mantener este beneficio. Dado que en BuddyCache una pÃ¡gina puede ser recuperada en una cachÃ© de cliente sin intervenciÃ³n del servidor (como se ilustra en la figura 2), los directorios de cachÃ© en los servidores llevan un registro de las pÃ¡ginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las pÃ¡ginas almacenadas en cachÃ© en cada cliente de un grupo. Los servidores envÃ­an al redireccionador invalidaciones para las pÃ¡ginas almacenadas en cachÃ© en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. ActualizaciÃ³n de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en cachÃ© por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interÃ©s potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de cachÃ© y las actualizaciones de cachÃ©. Los estudios de coherencia de cachÃ© en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualizaciÃ³n y la invalidaciÃ³n. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. AlmacÃ©n x 6. ActualizaciÃ³n x 3. CompromÃ©tete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares estÃ¡n fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeÃ±as, agrupadas y se envÃ­an junto con otros mensajes. AdemÃ¡s, los protocolos de invalidaciÃ³n se ajustan a la tendencia actual de hardware de aumentar los tamaÃ±os de cachÃ© del cliente. Es probable que las cachÃ©s mÃ¡s grandes contengan mucha mÃ¡s informaciÃ³n de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una red de Ã¡rea amplia serÃ­an derrochadores. Sin embargo, los protocolos de coherencia basados en invalidaciÃ³n pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interÃ©s para otro miembro del grupo. Con un protocolo basado en invalidaciÃ³n, la actualizaciÃ³n de un miembro invalidarÃ¡ la copia en cachÃ© de otro miembro, lo que provocarÃ¡ que este Ãºltimo realice una recuperaciÃ³n de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualizaciÃ³n e invalidaciÃ³n en entornos de redes de Ã¡rea amplia. Evita la penalizaciÃ³n de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalizaciÃ³n de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusiÃ³n localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en cachÃ© anteriores. La actualizaciÃ³n entre pares funciona de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que la transacciÃ³n se confirma, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n, y tambiÃ©n propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmaciÃ³n. 3.3 ConfirmaciÃ³n individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminaciÃ³n de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en cachÃ© transaccional, ya que un cliente que es lento para reconocer una invalidaciÃ³n o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacciÃ³n. Por ejemplo, un ingeniero que realiza una revisiÃ³n repetida al mismo objeto de diseÃ±o compartido (y por lo tanto tiene la Ãºltima versiÃ³n del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situaciÃ³n representada en la figura 4 donde el Cliente1 realiza una transacciÃ³n T que lee la Ãºltima versiÃ³n de un objeto x en la pÃ¡gina P recientemente modificada por el Cliente1. Si la solicitud de confirmaciÃ³n para T llega al servidor antes de que la confirmaciÃ³n colectiva de Cliente2 por la Ãºltima modificaciÃ³n de x llegue al servidor, el procedimiento de validaciÃ³n de OCC considera que x estÃ¡ obsoleto y aborta T (porque, como se explicÃ³ anteriormente, una invalidaciÃ³n no reconocida por un cliente actÃºa como indicaciÃ³n para el servidor de que el valor del objeto en cachÃ© estÃ¡ obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la correcciÃ³n del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asÃ­ncronas son una parte importante de la razÃ³n por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasiÃ³n de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envÃ­an y procesan de forma asÃ­ncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devoluciÃ³n de llamada jerÃ¡rquica [32], pero la naturaleza asincrÃ³nica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrÃ³nicas. El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a un cliente con objetos actualizados confirmar una transacciÃ³n incluso si la confirmaciÃ³n del grupo se retrasa debido a pares lentos o caÃ­dos. El protocolo requiere que los clientes incluyan informaciÃ³n adicional con los conjuntos de lectura de transacciones en el mensaje de confirmaciÃ³n, para indicar al servidor que los objetos leÃ­dos por la transacciÃ³n estÃ¡n actualizados. Los nÃºmeros de versiÃ³n de los objetos podrÃ­an proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionÃ³ anteriormente, mantener nÃºmeros de versiÃ³n por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaÃ±o de directorio) en todo el sistema de objetos cuando los objetos son pequeÃ±os [23]. En cambio, solo utiliza nÃºmeros de versiÃ³n de pÃ¡gina de grano grueso para identificar versiones de objetos de grano fino. El nÃºmero de versiÃ³n de una pÃ¡gina se incrementa en un servidor cuando una transacciÃ³n que modifica objetos en la pÃ¡gina se confirma. Las actualizaciones realizadas por una Ãºnica transacciÃ³n y las invalidaciones correspondientes son identificadas de manera Ãºnica por el nÃºmero de versiÃ³n de la pÃ¡gina modificada. Los nÃºmeros de versiÃ³n de la pÃ¡gina se propagan a los clientes en respuestas de recuperaciÃ³n, respuestas de confirmaciÃ³n y con invalidaciones, y los clientes incluyen los nÃºmeros de versiÃ³n de la pÃ¡gina en las solicitudes de confirmaciÃ³n enviadas a los servidores. Si una transacciÃ³n falla en la validaciÃ³n debido a la falta de reconocimiento de grupo, el servidor verifica los nÃºmeros de versiÃ³n de pÃ¡gina de los objetos en el conjunto de lectura de la transacciÃ³n y permite que la transacciÃ³n se confirme si el cliente ha leÃ­do desde la Ãºltima versiÃ³n de la pÃ¡gina. Los nÃºmeros de versiÃ³n de la pÃ¡gina permiten confirmaciones independientes, pero las verificaciones de versiÃ³n de pÃ¡gina solo detectan conflictos a nivel de pÃ¡gina. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La secciÃ³n 4 describe los detalles de la implementaciÃ³n del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 ConfiguraciÃ³n de Grupo La arquitectura BuddyCache admite mÃºltiples grupos de pares concurrentes. Potencialmente, puede ser mÃ¡s rÃ¡pido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podrÃ­a ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en cachÃ© de pares de mÃºltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en cachÃ© web, simplemente aumentar la poblaciÃ³n de clientes en una cachÃ© proxy a menudo aumenta la tasa general de aciertos en la cachÃ© [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacciÃ³n explÃ­cita entre clientes y la colaboraciÃ³n, lo que sugiere que es poco probable que ocurra la recuperaciÃ³n entre grupos. AdemÃ¡s, las mediciones de sistemas de almacenamiento en cachÃ© web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexiÃ³n de red entre los grupos de pares sea muy rÃ¡pida. Estamos principalmente interesados en entornos donde compaÃ±eros que colaboran estrechamente tienen una conectividad rÃ¡pida a corta distancia, pero la conexiÃ³n entre grupos de compaÃ±eros puede ser lenta. Como resultado, decidimos que el soporte para la recuperaciÃ³n entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compaÃ±eros con recursos heterogÃ©neos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compaÃ±eros o, cuando estÃ© disponible, en un nodo separado dentro de la infraestructura del sitio. AdemÃ¡s, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una cachÃ© de pares en espera para recibir pÃ¡ginas recuperadas por otros pares, emulando una cachÃ© central algo similar a una cachÃ© de proxy web regional. Desde el punto de vista del protocolo de coherencia de cachÃ© BuddyCache, sin embargo, un cachÃ© de compaÃ±ero en espera es equivalente a un cachÃ© de compaÃ±ero regular y, por lo tanto, no consideramos este caso por separado en la discusiÃ³n de este documento. 4. En esta secciÃ³n proporcionamos los detalles de la implementaciÃ³n de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en cachÃ© de estos objetos. Las aplicaciones se ejecutan en los clientes e interactÃºan con el sistema realizando llamadas a mÃ©todos de objetos en cachÃ©. Todas las llamadas a mÃ©todos ocurren dentro de transacciones atÃ³micas. Los clientes se comunican con los servidores para obtener pÃ¡ginas o realizar una transacciÃ³n. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volÃ¡til. El disco estÃ¡ organizado como una colecciÃ³n de pÃ¡ginas que son las unidades de acceso al disco. El registro estable guarda la informaciÃ³n de confirmaciÃ³n y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de cachÃ© y una cachÃ© de objetos modificados recuperable llamada MOB. El directorio lleva un registro de quÃ© pÃ¡ginas estÃ¡n almacenadas en cachÃ© por quÃ© clientes. El MOB contiene objetos recientemente modificados que aÃºn no han sido escritos de vuelta en sus pÃ¡ginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de cachÃ© base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la SecciÃ³n 3.1. Proporcionamos algunos de los detalles relevantes de la implementaciÃ³n del protocolo OCC. El cliente lleva un registro de los objetos que son leÃ­dos y modificados por su transacciÃ³n; envÃ­a esta informaciÃ³n, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacciÃ³n. Los servidores determinan si la confirmaciÃ³n es posible, utilizando un protocolo de confirmaciÃ³n de dos fases si la transacciÃ³n utilizÃ³ objetos en mÃºltiples servidores. Si la transacciÃ³n se lleva a cabo, las nuevas copias de los objetos modificados se aÃ±aden al registro y tambiÃ©n se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperaciÃ³n escaneando el registro. Dado que los objetos no estÃ¡n bloqueados antes de ser utilizados, una confirmaciÃ³n de transacciÃ³n puede hacer que las cachÃ©s contengan objetos obsoletos. Los servidores abortarÃ¡n una transacciÃ³n que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviÃ¡ndoles mensajes de invalidaciÃ³n; un servidor utiliza su directorio y la informaciÃ³n sobre la transacciÃ³n de confirmaciÃ³n para determinar quÃ© mensajes de invalidaciÃ³n enviar. Los mensajes de invalidaciÃ³n son pequeÃ±os porque simplemente identifican objetos obsoletos. AdemÃ¡s, se envÃ­an en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidaciÃ³n, elimina los objetos obsoletos de su cachÃ© y aborta la transacciÃ³n actual si los utilizÃ³. El cliente sigue conservando pÃ¡ginas que contienen objetos invalidados; estas pÃ¡ginas ahora estÃ¡n incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidaciÃ³n de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener pÃ¡ginas incompletas en la cachÃ© del cliente significa que el falso intercambio no conduce a fallos innecesarios en la cachÃ©. Los clientes reconocen las invalidaciones para indicar la eliminaciÃ³n de datos obsoletos, como se explica en la SecciÃ³n 3.1. Los mensajes de invalidaciÃ³n evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo asÃ­ el desperdicio de trabajo y trasladando la detecciÃ³n de abortos de los servidores a los clientes. Cuando una transacciÃ³n se aborta, su cliente restaura las copias en cachÃ© de los objetos modificados al estado que tenÃ­an antes de que la transacciÃ³n comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacciÃ³n. 4.3 RedirecciÃ³n El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de pÃ¡ginas disponibles en el grupo de pares y proporciona una redirecciÃ³n rÃ¡pida y centralizada de recuperaciÃ³n (ver figura 2) entre las cachÃ©s de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan pÃ¡ginas u objetos al incluir esa informaciÃ³n en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la cachÃ© de grupo, el redireccionador realiza un seguimiento del estado de las pÃ¡ginas. Una pÃ¡gina en cachÃ© estÃ¡ completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una pÃ¡gina estÃ¡n marcados como invÃ¡lidos. Solo se utilizan pÃ¡ginas completas por el proceso de <br>recuperaciÃ³n de pares</br>. El protocolo para mantener el estado de la pÃ¡gina cuando las pÃ¡ginas son actualizadas e invalidadas se describe en la SecciÃ³n 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una pÃ¡gina solicitada completa no estÃ¡ disponible en el grupo de pares o si un par necesita confirmar una transacciÃ³n, el redireccionador actÃºa como un proxy de servidor: reenvÃ­a la solicitud al servidor y luego reenvÃ­a la respuesta de vuelta al cliente. AdemÃ¡s, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualizaciÃ³n o informaciÃ³n de invalidaciÃ³n a los clientes que tienen en cachÃ© la pÃ¡gina modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la cachÃ© de grupo de pares combinada estÃ¡ desempeÃ±ando el papel de una Ãºnica cachÃ© de cliente en el sistema base. 4.4 ActualizaciÃ³n de pares La actualizaciÃ³n de pares se implementa de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que una transacciÃ³n se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacciÃ³n generan invalidaciones de objetos para cada grupo de cachÃ© que almacena pÃ¡ginas que contienen los objetos modificados (incluido el grupo que realiza la confirmaciÃ³n). Las invalidaciones se envÃ­an de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en cachÃ© los objetos modificados se deshagan de los datos obsoletos. En grupos de cachÃ© distintos al grupo de confirmaciÃ³n, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas, recopilan las confirmaciones de los clientes y, despuÃ©s de completar la recopilaciÃ³n, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacciÃ³n, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envÃ­an a los clientes que almacenan en cachÃ© esas pÃ¡ginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmaciÃ³n colectiva se propaga al servidor. Una invalidaciÃ³n hace que una pÃ¡gina en cachÃ© no estÃ© disponible para la <br>recuperaciÃ³n de pares</br>, cambiando el estado de una pÃ¡gina completa p a incompleta. Por el contrario, una actualizaciÃ³n de una pÃ¡gina completa conserva el estado completo de la pÃ¡gina. Como se muestra en los estudios de la reconstrucciÃ³n de fragmentos 31 [2], esta propagaciÃ³n de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma pÃ¡gina, la pÃ¡gina conserva su estado completo y permanece disponible para la <br>recuperaciÃ³n entre pares</br>. Por lo tanto, el efecto de la actualizaciÃ³n de pares es similar a la reconstrucciÃ³n de fragmentos ansiosa [2]. TambiÃ©n hemos considerado la posibilidad de permitir que un compaÃ±ero recupere una pÃ¡gina incompleta (con objetos invÃ¡lidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos invÃ¡lidos. 4.5 Vcache El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo mÃ¡s lentos (o fallidos). Como se explica en la SecciÃ³n 3.3, el protocolo de commit Ãºnico permite que una transacciÃ³n T pase la validaciÃ³n si la informaciÃ³n adicional de coherencia proporcionada por el cliente indica que la transacciÃ³n T ha leÃ­do objetos actualizados. Los clientes utilizan los nÃºmeros de versiÃ³n de la pÃ¡gina para proporcionar esta informaciÃ³n adicional de coherencia. Es decir, un cliente incluye el nÃºmero de versiÃ³n de la pÃ¡gina correspondiente a cada objeto en el conjunto de objetos leÃ­dos enviado en la solicitud de confirmaciÃ³n al servidor. Dado que a cada actualizaciÃ³n de objeto comprometido le corresponde un nÃºmero de versiÃ³n de pÃ¡gina Ãºnico, el nÃºmero de versiÃ³n de pÃ¡gina asociado con un objeto permite que el procedimiento de validaciÃ³n en el servidor verifique si la transacciÃ³n del cliente ha leÃ­do objetos actualizados. El uso de versiones de pÃ¡gina de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeÃ±os, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en cachÃ© a la versiÃ³n de pÃ¡gina identificadora (ObjectToVersion). El principal problema de implementaciÃ³n se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian nÃºmeros de versiÃ³n de pÃ¡gina con las invalidaciones. En el momento de la validaciÃ³n, si hay una invalidaciÃ³n no reconocida pendiente para un objeto x leÃ­do por una transacciÃ³n T, el procedimiento de validaciÃ³n verifica si el nÃºmero de versiÃ³n de x en el conjunto de lectura de Ts coincide con el nÃºmero de versiÃ³n de la invalidaciÃ³n pendiente mÃ¡s alta para x, en cuyo caso el valor del objeto estÃ¡ actualizado, de lo contrario, T falla en la validaciÃ³n. Observamos nuevamente que las verificaciones basadas en el nÃºmero de versiÃ³n de la pÃ¡gina y las verificaciones basadas en el reconocimiento de invalidaciÃ³n son complementarias en la validaciÃ³n de confirmaciÃ³n individual y ambas son necesarias. La verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina permite que la validaciÃ³n avance antes de que lleguen las confirmaciones de invalidaciÃ³n, pero por sÃ­ sola, una verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina detecta conflictos a nivel de pÃ¡gina y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cÃ³mo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un nÃºmero de versiÃ³n de la pÃ¡gina para cada pÃ¡gina en cachÃ©. El nÃºmero de versiÃ³n satisface la siguiente invariante V P sobre el estado de los objetos en una pÃ¡gina: si una pÃ¡gina en cachÃ© P tiene un nÃºmero de versiÃ³n v, entonces el valor de un objeto o en la pÃ¡gina en cachÃ© P es invÃ¡lido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacciÃ³n que estableciÃ³ el nÃºmero de versiÃ³n de P en v. Los nuevos valores de objetos y los nuevos nÃºmeros de versiÃ³n de pÃ¡gina llegan cuando un cliente obtiene una pÃ¡gina o cuando llega una respuesta de confirmaciÃ³n o invalidaciones para esta pÃ¡gina. Los nuevos valores del objeto modifican la pÃ¡gina y, por lo tanto, el nÃºmero de versiÃ³n de la pÃ¡gina necesita ser actualizado para mantener la invariante V P. Un nÃºmero de versiÃ³n de pÃ¡gina que llega cuando un cliente obtiene una pÃ¡gina, reemplaza la VersiÃ³n del Objeto x 8 Servidor de RedirecciÃ³n 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el nÃºmero de versiÃ³n de la pÃ¡gina para esta pÃ¡gina. Tal actualizaciÃ³n preserva el invariante V P. De manera similar, un nÃºmero de versiÃ³n de pÃ¡gina en secuencia que llega al cliente en un mensaje de confirmaciÃ³n o invalidaciÃ³n avanza el nÃºmero de versiÃ³n para toda la pÃ¡gina en cachÃ©, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus nÃºmeros de versiÃ³n de pÃ¡gina correspondientes tambiÃ©n pueden llegar al cliente fuera de secuencia, en cuyo caso la actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina podrÃ­a violar V P. Por ejemplo, una respuesta de confirmaciÃ³n para una transacciÃ³n que actualiza el objeto x en la pÃ¡gina P en el servidor S1, y el objeto y en la pÃ¡gina Q en el servidor S2, puede entregar un nuevo nÃºmero de versiÃ³n para P desde el coordinador de transacciones S1 antes de que llegue una invalidaciÃ³n generada para una transacciÃ³n anterior que ha modificado el objeto r en la pÃ¡gina P desde S1 (como se muestra en la figura 5). El protocolo de actualizaciÃ³n de cachÃ© garantiza que el valor de cualquier objeto o en una pÃ¡gina en cachÃ© P refleje la actualizaciÃ³n o invalidaciÃ³n con el nÃºmero de versiÃ³n observado mÃ¡s alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de nÃºmeros de versiÃ³n de pÃ¡gina, el cliente gestiona una pequeÃ±a cachÃ© de nÃºmeros de versiÃ³n vcache que mantiene el mapeo de un objeto a su nÃºmero de versiÃ³n de pÃ¡gina correspondiente para todas las actualizaciones de nÃºmeros de versiÃ³n reordenadas hasta que se ensamble una secuencia completa de nÃºmeros de versiÃ³n de pÃ¡gina. Cuando llegan los nÃºmeros de versiÃ³n faltantes para la pÃ¡gina y completan una secuencia, el nÃºmero de versiÃ³n de toda la pÃ¡gina se avanza. El mapeo de ObjectToVersion, incluyendo los nÃºmeros de versiÃ³n de vcache y pÃ¡gina, se utiliza en el momento de la confirmaciÃ³n de la transacciÃ³n para proporcionar nÃºmeros de versiÃ³n para el conjunto de objetos leÃ­dos de la siguiente manera. Si el objeto leÃ­do tiene una entrada en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n mÃ¡s alto en la vcache para este objeto. Si el objeto no estÃ¡ presente en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n de la pÃ¡gina en cachÃ© que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la cachÃ© del cliente, incluyendo los nÃºmeros de versiÃ³n de las pÃ¡ginas y la vcache. El cliente puede limitar el tamaÃ±o de la cachÃ© virtual segÃºn sea necesario, ya que volver a cargar una pÃ¡gina elimina todos los nÃºmeros de versiÃ³n de pÃ¡gina reordenados de la cachÃ© virtual. Sin embargo, esperamos que la reorganizaciÃ³n de nÃºmeros de versiÃ³n sea poco comÃºn y, por lo tanto, esperamos que la vcache sea muy pequeÃ±a. 5. Un grupo de clientes contiene mÃºltiples nodos de cliente y un objeto de pÃ¡gina de versiÃ³n redi32 VCache Cliente CachÃ© Cliente PÃ¡gina CachÃ© Figura 6: Mapa de Objeto a VersiÃ³n con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutaciÃ³n por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. AdemÃ¡s, el fallo del redireccionador deberÃ­a permitir que los clientes no afectados mantengan sus cachÃ©s intactas. Hemos diseÃ±ado un protocolo de conmutaciÃ³n por error para BuddyCache pero aÃºn no lo hemos implementado. El apÃ©ndice describe el protocolo. 6. La redirecciÃ³n de BuddyCache en la evaluaciÃ³n de rendimiento respalda los beneficios de evitar la comunicaciÃ³n con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes. Â¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 AnÃ¡lisis Los beneficios de rendimiento de la <br>recuperaciÃ³n entre pares</br> y la actualizaciÃ³n entre pares se deben a la evitaciÃ³n de interacciones con el servidor. ",
            "candidates": [],
            "error": [
                [
                    "bÃºsqueda de pares",
                    "recuperaciÃ³n de pares",
                    "recuperaciÃ³n de pares",
                    "recuperaciÃ³n entre pares",
                    "recuperaciÃ³n entre pares"
                ]
            ]
        },
        "multi-user oo7 benchmark": {
            "translated_key": "multiusuario OO7",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the <br>multi-user oo7 benchmark</br> [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "Our workloads are based on the <br>multi-user oo7 benchmark</br> [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application."
            ],
            "translated_annotated_samples": [
                "Nuestras cargas de trabajo se basan en el benchmark <br>multiusuario OO7</br> [8]; este benchmark estÃ¡ diseÃ±ado para capturar las caracterÃ­sticas de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicaciÃ³n especÃ­fica."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de Ã¡rea amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de Ã¡rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil. Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en cachÃ© web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos. Sin embargo, las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica. La interacciÃ³n con el servidor aumenta la latencia. La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia. Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n. Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo. BuddyCache presenta dos desafÃ­os tÃ©cnicos principales. Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©. El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de almacenamiento en cachÃ© web cooperativos [11]. Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo. BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos. Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica. Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad? DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red. Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia. El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida. Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache. Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n. Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos. Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de Ã¡rea amplia. Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad. Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un Ãºnico servidor. Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web. El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y tolerancia a fallos del protocolo de almacenamiento en cachÃ© transaccional [19]. La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y tolerancia a fallos garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una transacciÃ³n, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador. El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado. AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©. Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina). La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente. El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento. A continuaciÃ³n, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene. La transacciÃ³n puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor. Sin embargo, antes de que una transacciÃ³n se confirme, debe ser validada; el servidor debe asegurarse de que la transacciÃ³n validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada. Si la validaciÃ³n falla, la transacciÃ³n se cancela. Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de bÃºsqueda de pares envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la cachÃ© y envÃ­an confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la cachÃ© del cliente, la confirmaciÃ³n de invalidaciÃ³n indica al servidor que un cliente sin invalidaciones pendientes ha leÃ­do objetos actualizados. Una invalidaciÃ³n no reconocida indica que un objeto obsoleto puede haber sido accedido en la cachÃ© del cliente. El procedimiento de validaciÃ³n en el servidor aborta una transacciÃ³n del cliente si este lee un objeto mientras hay una invalidaciÃ³n pendiente. El mecanismo de invalidaciÃ³n reconocido admite coherencia de cachÃ© a nivel de objeto sin directorios basados en objetos o nÃºmeros de versiÃ³n por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeÃ±os, ya que los objetos tÃ­picos son pequeÃ±os. Un objetivo importante del diseÃ±o de BuddyCache es mantener este beneficio. Dado que en BuddyCache una pÃ¡gina puede ser recuperada en una cachÃ© de cliente sin intervenciÃ³n del servidor (como se ilustra en la figura 2), los directorios de cachÃ© en los servidores llevan un registro de las pÃ¡ginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las pÃ¡ginas almacenadas en cachÃ© en cada cliente de un grupo. Los servidores envÃ­an al redireccionador invalidaciones para las pÃ¡ginas almacenadas en cachÃ© en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. ActualizaciÃ³n de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en cachÃ© por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interÃ©s potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de cachÃ© y las actualizaciones de cachÃ©. Los estudios de coherencia de cachÃ© en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualizaciÃ³n y la invalidaciÃ³n. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. AlmacÃ©n x 6. ActualizaciÃ³n x 3. CompromÃ©tete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares estÃ¡n fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeÃ±as, agrupadas y se envÃ­an junto con otros mensajes. AdemÃ¡s, los protocolos de invalidaciÃ³n se ajustan a la tendencia actual de hardware de aumentar los tamaÃ±os de cachÃ© del cliente. Es probable que las cachÃ©s mÃ¡s grandes contengan mucha mÃ¡s informaciÃ³n de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una red de Ã¡rea amplia serÃ­an derrochadores. Sin embargo, los protocolos de coherencia basados en invalidaciÃ³n pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interÃ©s para otro miembro del grupo. Con un protocolo basado en invalidaciÃ³n, la actualizaciÃ³n de un miembro invalidarÃ¡ la copia en cachÃ© de otro miembro, lo que provocarÃ¡ que este Ãºltimo realice una recuperaciÃ³n de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualizaciÃ³n e invalidaciÃ³n en entornos de redes de Ã¡rea amplia. Evita la penalizaciÃ³n de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalizaciÃ³n de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusiÃ³n localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en cachÃ© anteriores. La actualizaciÃ³n entre pares funciona de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que la transacciÃ³n se confirma, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n, y tambiÃ©n propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmaciÃ³n. 3.3 ConfirmaciÃ³n individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminaciÃ³n de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en cachÃ© transaccional, ya que un cliente que es lento para reconocer una invalidaciÃ³n o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacciÃ³n. Por ejemplo, un ingeniero que realiza una revisiÃ³n repetida al mismo objeto de diseÃ±o compartido (y por lo tanto tiene la Ãºltima versiÃ³n del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situaciÃ³n representada en la figura 4 donde el Cliente1 realiza una transacciÃ³n T que lee la Ãºltima versiÃ³n de un objeto x en la pÃ¡gina P recientemente modificada por el Cliente1. Si la solicitud de confirmaciÃ³n para T llega al servidor antes de que la confirmaciÃ³n colectiva de Cliente2 por la Ãºltima modificaciÃ³n de x llegue al servidor, el procedimiento de validaciÃ³n de OCC considera que x estÃ¡ obsoleto y aborta T (porque, como se explicÃ³ anteriormente, una invalidaciÃ³n no reconocida por un cliente actÃºa como indicaciÃ³n para el servidor de que el valor del objeto en cachÃ© estÃ¡ obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la correcciÃ³n del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asÃ­ncronas son una parte importante de la razÃ³n por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasiÃ³n de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envÃ­an y procesan de forma asÃ­ncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devoluciÃ³n de llamada jerÃ¡rquica [32], pero la naturaleza asincrÃ³nica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrÃ³nicas. El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a un cliente con objetos actualizados confirmar una transacciÃ³n incluso si la confirmaciÃ³n del grupo se retrasa debido a pares lentos o caÃ­dos. El protocolo requiere que los clientes incluyan informaciÃ³n adicional con los conjuntos de lectura de transacciones en el mensaje de confirmaciÃ³n, para indicar al servidor que los objetos leÃ­dos por la transacciÃ³n estÃ¡n actualizados. Los nÃºmeros de versiÃ³n de los objetos podrÃ­an proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionÃ³ anteriormente, mantener nÃºmeros de versiÃ³n por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaÃ±o de directorio) en todo el sistema de objetos cuando los objetos son pequeÃ±os [23]. En cambio, solo utiliza nÃºmeros de versiÃ³n de pÃ¡gina de grano grueso para identificar versiones de objetos de grano fino. El nÃºmero de versiÃ³n de una pÃ¡gina se incrementa en un servidor cuando una transacciÃ³n que modifica objetos en la pÃ¡gina se confirma. Las actualizaciones realizadas por una Ãºnica transacciÃ³n y las invalidaciones correspondientes son identificadas de manera Ãºnica por el nÃºmero de versiÃ³n de la pÃ¡gina modificada. Los nÃºmeros de versiÃ³n de la pÃ¡gina se propagan a los clientes en respuestas de recuperaciÃ³n, respuestas de confirmaciÃ³n y con invalidaciones, y los clientes incluyen los nÃºmeros de versiÃ³n de la pÃ¡gina en las solicitudes de confirmaciÃ³n enviadas a los servidores. Si una transacciÃ³n falla en la validaciÃ³n debido a la falta de reconocimiento de grupo, el servidor verifica los nÃºmeros de versiÃ³n de pÃ¡gina de los objetos en el conjunto de lectura de la transacciÃ³n y permite que la transacciÃ³n se confirme si el cliente ha leÃ­do desde la Ãºltima versiÃ³n de la pÃ¡gina. Los nÃºmeros de versiÃ³n de la pÃ¡gina permiten confirmaciones independientes, pero las verificaciones de versiÃ³n de pÃ¡gina solo detectan conflictos a nivel de pÃ¡gina. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La secciÃ³n 4 describe los detalles de la implementaciÃ³n del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 ConfiguraciÃ³n de Grupo La arquitectura BuddyCache admite mÃºltiples grupos de pares concurrentes. Potencialmente, puede ser mÃ¡s rÃ¡pido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podrÃ­a ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en cachÃ© de pares de mÃºltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en cachÃ© web, simplemente aumentar la poblaciÃ³n de clientes en una cachÃ© proxy a menudo aumenta la tasa general de aciertos en la cachÃ© [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacciÃ³n explÃ­cita entre clientes y la colaboraciÃ³n, lo que sugiere que es poco probable que ocurra la recuperaciÃ³n entre grupos. AdemÃ¡s, las mediciones de sistemas de almacenamiento en cachÃ© web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexiÃ³n de red entre los grupos de pares sea muy rÃ¡pida. Estamos principalmente interesados en entornos donde compaÃ±eros que colaboran estrechamente tienen una conectividad rÃ¡pida a corta distancia, pero la conexiÃ³n entre grupos de compaÃ±eros puede ser lenta. Como resultado, decidimos que el soporte para la recuperaciÃ³n entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compaÃ±eros con recursos heterogÃ©neos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compaÃ±eros o, cuando estÃ© disponible, en un nodo separado dentro de la infraestructura del sitio. AdemÃ¡s, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una cachÃ© de pares en espera para recibir pÃ¡ginas recuperadas por otros pares, emulando una cachÃ© central algo similar a una cachÃ© de proxy web regional. Desde el punto de vista del protocolo de coherencia de cachÃ© BuddyCache, sin embargo, un cachÃ© de compaÃ±ero en espera es equivalente a un cachÃ© de compaÃ±ero regular y, por lo tanto, no consideramos este caso por separado en la discusiÃ³n de este documento. 4. En esta secciÃ³n proporcionamos los detalles de la implementaciÃ³n de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en cachÃ© de estos objetos. Las aplicaciones se ejecutan en los clientes e interactÃºan con el sistema realizando llamadas a mÃ©todos de objetos en cachÃ©. Todas las llamadas a mÃ©todos ocurren dentro de transacciones atÃ³micas. Los clientes se comunican con los servidores para obtener pÃ¡ginas o realizar una transacciÃ³n. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volÃ¡til. El disco estÃ¡ organizado como una colecciÃ³n de pÃ¡ginas que son las unidades de acceso al disco. El registro estable guarda la informaciÃ³n de confirmaciÃ³n y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de cachÃ© y una cachÃ© de objetos modificados recuperable llamada MOB. El directorio lleva un registro de quÃ© pÃ¡ginas estÃ¡n almacenadas en cachÃ© por quÃ© clientes. El MOB contiene objetos recientemente modificados que aÃºn no han sido escritos de vuelta en sus pÃ¡ginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de cachÃ© base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la SecciÃ³n 3.1. Proporcionamos algunos de los detalles relevantes de la implementaciÃ³n del protocolo OCC. El cliente lleva un registro de los objetos que son leÃ­dos y modificados por su transacciÃ³n; envÃ­a esta informaciÃ³n, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacciÃ³n. Los servidores determinan si la confirmaciÃ³n es posible, utilizando un protocolo de confirmaciÃ³n de dos fases si la transacciÃ³n utilizÃ³ objetos en mÃºltiples servidores. Si la transacciÃ³n se lleva a cabo, las nuevas copias de los objetos modificados se aÃ±aden al registro y tambiÃ©n se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperaciÃ³n escaneando el registro. Dado que los objetos no estÃ¡n bloqueados antes de ser utilizados, una confirmaciÃ³n de transacciÃ³n puede hacer que las cachÃ©s contengan objetos obsoletos. Los servidores abortarÃ¡n una transacciÃ³n que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviÃ¡ndoles mensajes de invalidaciÃ³n; un servidor utiliza su directorio y la informaciÃ³n sobre la transacciÃ³n de confirmaciÃ³n para determinar quÃ© mensajes de invalidaciÃ³n enviar. Los mensajes de invalidaciÃ³n son pequeÃ±os porque simplemente identifican objetos obsoletos. AdemÃ¡s, se envÃ­an en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidaciÃ³n, elimina los objetos obsoletos de su cachÃ© y aborta la transacciÃ³n actual si los utilizÃ³. El cliente sigue conservando pÃ¡ginas que contienen objetos invalidados; estas pÃ¡ginas ahora estÃ¡n incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidaciÃ³n de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener pÃ¡ginas incompletas en la cachÃ© del cliente significa que el falso intercambio no conduce a fallos innecesarios en la cachÃ©. Los clientes reconocen las invalidaciones para indicar la eliminaciÃ³n de datos obsoletos, como se explica en la SecciÃ³n 3.1. Los mensajes de invalidaciÃ³n evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo asÃ­ el desperdicio de trabajo y trasladando la detecciÃ³n de abortos de los servidores a los clientes. Cuando una transacciÃ³n se aborta, su cliente restaura las copias en cachÃ© de los objetos modificados al estado que tenÃ­an antes de que la transacciÃ³n comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacciÃ³n. 4.3 RedirecciÃ³n El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de pÃ¡ginas disponibles en el grupo de pares y proporciona una redirecciÃ³n rÃ¡pida y centralizada de recuperaciÃ³n (ver figura 2) entre las cachÃ©s de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan pÃ¡ginas u objetos al incluir esa informaciÃ³n en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la cachÃ© de grupo, el redireccionador realiza un seguimiento del estado de las pÃ¡ginas. Una pÃ¡gina en cachÃ© estÃ¡ completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una pÃ¡gina estÃ¡n marcados como invÃ¡lidos. Solo se utilizan pÃ¡ginas completas por el proceso de recuperaciÃ³n de pares. El protocolo para mantener el estado de la pÃ¡gina cuando las pÃ¡ginas son actualizadas e invalidadas se describe en la SecciÃ³n 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una pÃ¡gina solicitada completa no estÃ¡ disponible en el grupo de pares o si un par necesita confirmar una transacciÃ³n, el redireccionador actÃºa como un proxy de servidor: reenvÃ­a la solicitud al servidor y luego reenvÃ­a la respuesta de vuelta al cliente. AdemÃ¡s, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualizaciÃ³n o informaciÃ³n de invalidaciÃ³n a los clientes que tienen en cachÃ© la pÃ¡gina modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la cachÃ© de grupo de pares combinada estÃ¡ desempeÃ±ando el papel de una Ãºnica cachÃ© de cliente en el sistema base. 4.4 ActualizaciÃ³n de pares La actualizaciÃ³n de pares se implementa de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que una transacciÃ³n se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacciÃ³n generan invalidaciones de objetos para cada grupo de cachÃ© que almacena pÃ¡ginas que contienen los objetos modificados (incluido el grupo que realiza la confirmaciÃ³n). Las invalidaciones se envÃ­an de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en cachÃ© los objetos modificados se deshagan de los datos obsoletos. En grupos de cachÃ© distintos al grupo de confirmaciÃ³n, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas, recopilan las confirmaciones de los clientes y, despuÃ©s de completar la recopilaciÃ³n, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacciÃ³n, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envÃ­an a los clientes que almacenan en cachÃ© esas pÃ¡ginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmaciÃ³n colectiva se propaga al servidor. Una invalidaciÃ³n hace que una pÃ¡gina en cachÃ© no estÃ© disponible para la recuperaciÃ³n de pares, cambiando el estado de una pÃ¡gina completa p a incompleta. Por el contrario, una actualizaciÃ³n de una pÃ¡gina completa conserva el estado completo de la pÃ¡gina. Como se muestra en los estudios de la reconstrucciÃ³n de fragmentos 31 [2], esta propagaciÃ³n de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma pÃ¡gina, la pÃ¡gina conserva su estado completo y permanece disponible para la recuperaciÃ³n entre pares. Por lo tanto, el efecto de la actualizaciÃ³n de pares es similar a la reconstrucciÃ³n de fragmentos ansiosa [2]. TambiÃ©n hemos considerado la posibilidad de permitir que un compaÃ±ero recupere una pÃ¡gina incompleta (con objetos invÃ¡lidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos invÃ¡lidos. 4.5 Vcache El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo mÃ¡s lentos (o fallidos). Como se explica en la SecciÃ³n 3.3, el protocolo de commit Ãºnico permite que una transacciÃ³n T pase la validaciÃ³n si la informaciÃ³n adicional de coherencia proporcionada por el cliente indica que la transacciÃ³n T ha leÃ­do objetos actualizados. Los clientes utilizan los nÃºmeros de versiÃ³n de la pÃ¡gina para proporcionar esta informaciÃ³n adicional de coherencia. Es decir, un cliente incluye el nÃºmero de versiÃ³n de la pÃ¡gina correspondiente a cada objeto en el conjunto de objetos leÃ­dos enviado en la solicitud de confirmaciÃ³n al servidor. Dado que a cada actualizaciÃ³n de objeto comprometido le corresponde un nÃºmero de versiÃ³n de pÃ¡gina Ãºnico, el nÃºmero de versiÃ³n de pÃ¡gina asociado con un objeto permite que el procedimiento de validaciÃ³n en el servidor verifique si la transacciÃ³n del cliente ha leÃ­do objetos actualizados. El uso de versiones de pÃ¡gina de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeÃ±os, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en cachÃ© a la versiÃ³n de pÃ¡gina identificadora (ObjectToVersion). El principal problema de implementaciÃ³n se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian nÃºmeros de versiÃ³n de pÃ¡gina con las invalidaciones. En el momento de la validaciÃ³n, si hay una invalidaciÃ³n no reconocida pendiente para un objeto x leÃ­do por una transacciÃ³n T, el procedimiento de validaciÃ³n verifica si el nÃºmero de versiÃ³n de x en el conjunto de lectura de Ts coincide con el nÃºmero de versiÃ³n de la invalidaciÃ³n pendiente mÃ¡s alta para x, en cuyo caso el valor del objeto estÃ¡ actualizado, de lo contrario, T falla en la validaciÃ³n. Observamos nuevamente que las verificaciones basadas en el nÃºmero de versiÃ³n de la pÃ¡gina y las verificaciones basadas en el reconocimiento de invalidaciÃ³n son complementarias en la validaciÃ³n de confirmaciÃ³n individual y ambas son necesarias. La verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina permite que la validaciÃ³n avance antes de que lleguen las confirmaciones de invalidaciÃ³n, pero por sÃ­ sola, una verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina detecta conflictos a nivel de pÃ¡gina y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cÃ³mo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un nÃºmero de versiÃ³n de la pÃ¡gina para cada pÃ¡gina en cachÃ©. El nÃºmero de versiÃ³n satisface la siguiente invariante V P sobre el estado de los objetos en una pÃ¡gina: si una pÃ¡gina en cachÃ© P tiene un nÃºmero de versiÃ³n v, entonces el valor de un objeto o en la pÃ¡gina en cachÃ© P es invÃ¡lido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacciÃ³n que estableciÃ³ el nÃºmero de versiÃ³n de P en v. Los nuevos valores de objetos y los nuevos nÃºmeros de versiÃ³n de pÃ¡gina llegan cuando un cliente obtiene una pÃ¡gina o cuando llega una respuesta de confirmaciÃ³n o invalidaciones para esta pÃ¡gina. Los nuevos valores del objeto modifican la pÃ¡gina y, por lo tanto, el nÃºmero de versiÃ³n de la pÃ¡gina necesita ser actualizado para mantener la invariante V P. Un nÃºmero de versiÃ³n de pÃ¡gina que llega cuando un cliente obtiene una pÃ¡gina, reemplaza la VersiÃ³n del Objeto x 8 Servidor de RedirecciÃ³n 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el nÃºmero de versiÃ³n de la pÃ¡gina para esta pÃ¡gina. Tal actualizaciÃ³n preserva el invariante V P. De manera similar, un nÃºmero de versiÃ³n de pÃ¡gina en secuencia que llega al cliente en un mensaje de confirmaciÃ³n o invalidaciÃ³n avanza el nÃºmero de versiÃ³n para toda la pÃ¡gina en cachÃ©, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus nÃºmeros de versiÃ³n de pÃ¡gina correspondientes tambiÃ©n pueden llegar al cliente fuera de secuencia, en cuyo caso la actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina podrÃ­a violar V P. Por ejemplo, una respuesta de confirmaciÃ³n para una transacciÃ³n que actualiza el objeto x en la pÃ¡gina P en el servidor S1, y el objeto y en la pÃ¡gina Q en el servidor S2, puede entregar un nuevo nÃºmero de versiÃ³n para P desde el coordinador de transacciones S1 antes de que llegue una invalidaciÃ³n generada para una transacciÃ³n anterior que ha modificado el objeto r en la pÃ¡gina P desde S1 (como se muestra en la figura 5). El protocolo de actualizaciÃ³n de cachÃ© garantiza que el valor de cualquier objeto o en una pÃ¡gina en cachÃ© P refleje la actualizaciÃ³n o invalidaciÃ³n con el nÃºmero de versiÃ³n observado mÃ¡s alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de nÃºmeros de versiÃ³n de pÃ¡gina, el cliente gestiona una pequeÃ±a cachÃ© de nÃºmeros de versiÃ³n vcache que mantiene el mapeo de un objeto a su nÃºmero de versiÃ³n de pÃ¡gina correspondiente para todas las actualizaciones de nÃºmeros de versiÃ³n reordenadas hasta que se ensamble una secuencia completa de nÃºmeros de versiÃ³n de pÃ¡gina. Cuando llegan los nÃºmeros de versiÃ³n faltantes para la pÃ¡gina y completan una secuencia, el nÃºmero de versiÃ³n de toda la pÃ¡gina se avanza. El mapeo de ObjectToVersion, incluyendo los nÃºmeros de versiÃ³n de vcache y pÃ¡gina, se utiliza en el momento de la confirmaciÃ³n de la transacciÃ³n para proporcionar nÃºmeros de versiÃ³n para el conjunto de objetos leÃ­dos de la siguiente manera. Si el objeto leÃ­do tiene una entrada en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n mÃ¡s alto en la vcache para este objeto. Si el objeto no estÃ¡ presente en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n de la pÃ¡gina en cachÃ© que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la cachÃ© del cliente, incluyendo los nÃºmeros de versiÃ³n de las pÃ¡ginas y la vcache. El cliente puede limitar el tamaÃ±o de la cachÃ© virtual segÃºn sea necesario, ya que volver a cargar una pÃ¡gina elimina todos los nÃºmeros de versiÃ³n de pÃ¡gina reordenados de la cachÃ© virtual. Sin embargo, esperamos que la reorganizaciÃ³n de nÃºmeros de versiÃ³n sea poco comÃºn y, por lo tanto, esperamos que la vcache sea muy pequeÃ±a. 5. Un grupo de clientes contiene mÃºltiples nodos de cliente y un objeto de pÃ¡gina de versiÃ³n redi32 VCache Cliente CachÃ© Cliente PÃ¡gina CachÃ© Figura 6: Mapa de Objeto a VersiÃ³n con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutaciÃ³n por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. AdemÃ¡s, el fallo del redireccionador deberÃ­a permitir que los clientes no afectados mantengan sus cachÃ©s intactas. Hemos diseÃ±ado un protocolo de conmutaciÃ³n por error para BuddyCache pero aÃºn no lo hemos implementado. El apÃ©ndice describe el protocolo. 6. La redirecciÃ³n de BuddyCache en la evaluaciÃ³n de rendimiento respalda los beneficios de evitar la comunicaciÃ³n con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes. Â¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 AnÃ¡lisis Los beneficios de rendimiento de la recuperaciÃ³n entre pares y la actualizaciÃ³n entre pares se deben a la evitaciÃ³n de interacciones con el servidor. Esta secciÃ³n presenta un modelo de rendimiento analÃ­tico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la cachÃ© del cliente. Estos pueden ser fallos frÃ­os, fallos de invalidaciÃ³n y fallos de capacidad. Nuestro anÃ¡lisis se centra en los fallos por frÃ­o y los fallos por invalidaciÃ³n, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frÃ­o. AdemÃ¡s, las tendencias tecnolÃ³gicas indican que la capacidad de memoria y almacenamiento seguirÃ¡ creciendo y, por lo tanto, es probable que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ©. Los fallos de cachÃ© del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuraciÃ³n de cachÃ©. Nuestro anÃ¡lisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validaciÃ³n. Para estudiar el beneficio de evitar fallos en frÃ­o, consideramos el rendimiento de la cachÃ© en frÃ­o en una carga de trabajo de solo lectura (sin fallos de invalidaciÃ³n). Esperamos que la recuperaciÃ³n entre pares mejore el costo de latencia para las solicitudes de cachÃ© frÃ­a del cliente al recuperar objetos de la cachÃ© cercana. Evaluamos cÃ³mo el costo de redirecciÃ³n afecta este beneficio al comparar y analizar el rendimiento de una aplicaciÃ³n que se ejecuta en un sistema de almacenamiento con BuddyCache y sin Ã©l (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidaciÃ³n, consideramos el rendimiento de la cachÃ© caliente en una carga de trabajo con modificaciones (sin fallos en frÃ­o). En las cachÃ©s calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualizaciÃ³n entre pares permite que un cliente acceda a un objeto modificado por un compaÃ±ero colaborador cercano sin el retraso impuesto por los protocolos de invalidaciÃ³n Ãºnicamente. En grupos donde los compaÃ±eros comparten un interÃ©s de solo lectura en los objetos modificados, la recuperaciÃ³n entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compaÃ±ero colaborador lo tenga, lo que evita el retraso de la recuperaciÃ³n del servidor sin el alto costo impuesto por los protocolos de solo actualizaciÃ³n. Las tendencias tecnolÃ³gicas indican que ambos beneficios seguirÃ¡n siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualizaciÃ³n Ãºnicamente. Sin embargo, la tendencia hacia cachÃ©s cada vez mÃ¡s grandes, que se actualizan cuando los objetos en cachÃ© son modificados, hace que los protocolos basados en invalidaciÃ³n sean mÃ¡s atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicaciÃ³n que se ejecuta sin BuddyCache y una aplicaciÃ³n que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compaÃ±ero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compaÃ±ero fuera del grupo. La actualizaciÃ³n entre pares tambiÃ©n puede evitar fallos de invalidaciÃ³n debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma pÃ¡gina de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseÃ±o del objeto, y tambiÃ©n porque este beneficio se puede derivar dado el Ã­ndice de aciertos en cachÃ© y la contenciÃ³n de la carga de trabajo. 6.1.1 El Modelo El modelo considera cÃ³mo el tiempo para completar una ejecuciÃ³n con y sin BuddyCache se ve afectado por los fallos de invalidaciÃ³n y los fallos en frÃ­o. Considerando k clientes ejecutÃ¡ndose concurrentemente accediendo de manera uniforme a un conjunto compartido de N pÃ¡ginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacciÃ³n y realizar cÃ¡lculos en una transacciÃ³n, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin Ã©l (Base). Para simplificar, nuestro modelo asume que los tiempos de bÃºsqueda y confirmaciÃ³n son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del nÃºmero total de clientes en el sistema. El nÃºmero de fallos evitados por la recuperaciÃ³n entre pares depende de k, el nÃºmero de clientes en la BuddyCache, y del interÃ©s conjunto de los clientes en los datos compartidos. En una ejecuciÃ³n especÃ­fica de BuddyCache, se modela mediante la variable r, definida como el nÃºmero de solicitudes que llegan al redireccionador para una versiÃ³n dada de la pÃ¡gina P (es decir, hasta que un objeto en la pÃ¡gina se invalida). Considera una ejecuciÃ³n con fallos en frÃ­o. Un cliente comienza con una cachÃ© frÃ­a y ejecuta una carga de trabajo de solo lectura hasta que accede a las N pÃ¡ginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la cachÃ© del cliente es lo suficientemente grande como para contener N pÃ¡ginas. En BC, los frÃ­os fallos para la pÃ¡gina P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consideremos a continuaciÃ³n una ejecuciÃ³n con fallos de invalidaciÃ³n. Un cliente comienza con una cachÃ© caliente que contiene el conjunto de trabajo de N pÃ¡ginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualizaciÃ³n entre pares elimina todos los fallos de invalidaciÃ³n. En un grupo que contiene solo lectores (BCR), durante una ejecuciÃ³n en estado estable con actualizaciones uniformes, una transacciÃ³n del cliente tiene fallos de invalidaciÃ³n faltantes. Considera la secuencia de r fallos de cliente en la pÃ¡gina P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la pÃ¡gina P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frÃ­o, r â‰¤ k porque la segunda invalidaciÃ³n deshabilita la redirecciÃ³n para P hasta que el prÃ³ximo fallo en P provoque una recuperaciÃ³n del servidor. Suponiendo un acceso uniforme, un fallo de invalidaciÃ³n del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperaciÃ³n del servidor), y una probabilidad de (1 âˆ’ 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacciÃ³n Ãºnica en los sistemas Base, BCR y BCW. En los experimentos descritos a continuaciÃ³n, medimos los parÃ¡metros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalizaciÃ³n derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalizaciÃ³n y beneficios medidos directamente en los experimentos. 6.2 ConfiguraciÃ³n Experimental Antes de presentar nuestros resultados, describimos nuestra configuraciÃ³n experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectÃ¡ndose directamente a los servidores. El sistema Buddy ejecuta nuestra implementaciÃ³n del prototipo de BuddyCache en Thor, admitiendo la recuperaciÃ³n de pares, la actualizaciÃ³n de pares y la confirmaciÃ³n en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark <br>multiusuario OO7</br> [8]; este benchmark estÃ¡ diseÃ±ado para capturar las caracterÃ­sticas de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicaciÃ³n especÃ­fica. Utilizamos OO7 porque es un punto de referencia estÃ¡ndar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un Ã¡rbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un grÃ¡fico de partes atÃ³micas vinculadas por objetos de conexiÃ³n; cada parte atÃ³mica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atÃ³micas por parte compuesta. La base de datos multiusuario asigna a cada cliente un mÃ³dulo privado que consiste en un Ã¡rbol de objetos de ensamblaje, y agrega un mÃ³dulo compartido adicional que escala proporcionalmente al nÃºmero de clientes. Esperamos que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ© y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la cachÃ©. Dado que el objetivo de nuestro estudio es evaluar quÃ© tan efectivamente nuestras tÃ©cnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras tÃ©cnicas tienen en los fallos de cachÃ© frÃ­o y de consistencia de cachÃ©, y aislar tanto como sea posible el efecto de los fallos de capacidad de cachÃ©. Para mantener la duraciÃ³n de nuestros experimentos razonable, utilizamos cachÃ©s pequeÃ±os. El benchmark OO7 genera mÃ³dulos de base de datos de tamaÃ±o predefinido. En nuestra implementaciÃ³n de OO7, el tamaÃ±o del mÃ³dulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la cachÃ©, utilizamos un Ãºnico mÃ³dulo privado y elegimos un tamaÃ±o de cachÃ© de 40MB para cada cliente. La base de datos OO7 se genera con mÃ³dulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos estÃ¡n agrupados en pÃ¡ginas de 8K, que tambiÃ©n son la unidad de transferencia en las solicitudes de recuperaciÃ³n. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro anÃ¡lisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idÃ©ntico a T1 excepto que modifica todas las partes atÃ³micas en un solo compuesto. Una transacciÃ³n Ãºnica incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo mÃ³dulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacciÃ³n, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de bÃºsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una cachÃ© de 50MB (de los cuales 6MB se utilizaron para el bÃºfer de objetos modificados), el cliente tenÃ­a una cachÃ© de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos bÃ¡sicos Esta secciÃ³n analiza el costo bÃ¡sico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 RedirecciÃ³n Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtenciÃ³n del servidor), el costo adicional de la redirecciÃ³n incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperaciÃ³n o confirmaciÃ³n del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmaciÃ³n y recuperaciÃ³n del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de Ã¡rea rÃ¡pida. Todos los nÃºmeros fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirecciÃ³n al cruzar el redireccionador no es muy alto, incluso en una red de Ã¡rea local. El costo de la confirmaciÃ³n aumenta con el nÃºmero de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperaciÃ³n no aumenta tanto porque la cachÃ© del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la cachÃ© del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperaciÃ³n entre pares, medimos la latencia de la recuperaciÃ³n entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperaciÃ³n entre pares, el costo de la redirecciÃ³n incluye, ademÃ¡s del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este Ãºltimo incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la pÃ¡gina solicitada. Medimos directamente el tiempo para copiar y desenrollar la pÃ¡gina solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperaciÃ³n de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador mÃ¡s un viaje de ida y vuelta a travÃ©s de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud mÃ¡s un viaje de ida y vuelta a travÃ©s de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando estÃ¡ bloqueado esperando una respuesta de bÃºsqueda o confirmaciÃ³n. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podrÃ­a ser mitigado por una implementaciÃ³n multi-hilo en un sistema con programaciÃ³n preemptiva. 6.3.2 VersiÃ³n de CachÃ© El commit en solitario permite que un cliente rÃ¡pido que modifica un objeto haga un commit de forma independiente a un compaÃ±ero lento. El mecanismo de confirmaciÃ³n Ãºnica introduce un procesamiento adicional en el servidor durante la validaciÃ³n de la transacciÃ³n, y un procesamiento adicional en el cliente durante la confirmaciÃ³n de la transacciÃ³n y en el momento del procesamiento de actualizaciÃ³n o invalidaciÃ³n. Los gastos generales del lado del servidor son mÃ­nimos y consisten en una actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina en el momento de la confirmaciÃ³n, y una comparaciÃ³n del nÃºmero de versiÃ³n en el momento de la validaciÃ³n de la transacciÃ³n. La cachÃ© de versiÃ³n tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacciÃ³n accede a objetos en mÃºltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor Ãºnico y, por lo tanto, el tiempo de confirmaciÃ³n adicional de la gestiÃ³n de la cachÃ© de versiones en el cliente no contribuye a los resultados presentados en la secciÃ³n a continuaciÃ³n. Para medir estos costos adicionales del lado del cliente en un sistema de mÃºltiples servidores, instrumentamos la implementaciÃ³n de la cachÃ© de versiones para ejecutarse con una traza de carga de trabajo que incluÃ­a invalidaciones reordenadas y cronometramos las operaciones bÃ¡sicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operaciÃ³n de bÃºsqueda de cachÃ© de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n en el momento de preparaciÃ³n de la solicitud de compromiso, y una operaciÃ³n de inserciÃ³n de cachÃ© de versiÃ³n para cada objeto actualizado por una transacciÃ³n en el momento de procesamiento de la respuesta de compromiso, pero solo si la pÃ¡gina actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmaciÃ³n se mantengan al mÃ­nimo, ya que el cliente estÃ¡ esperando de forma sÃ­ncrona la finalizaciÃ³n de la confirmaciÃ³n. Las mediciones muestran que en el peor de los casos, cuando llega un gran nÃºmero de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en pÃ¡ginas reordenadas, el costo de actualizar la cachÃ© de versiÃ³n es de 0.6 ms. El costo de tiempo de invalidaciÃ³n es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementaciÃ³n de la cachÃ© de versiones para reducir aÃºn mÃ¡s estos costos. 6.4 Rendimiento general Esta secciÃ³n examina las mejoras de rendimiento observadas por una aplicaciÃ³n que ejecuta el benchmark OO7 con un BuddyCache en una red de Ã¡rea amplia. 6.4.1 Fallos en frÃ­o Para evaluar las mejoras de rendimiento al evitar fallos en frÃ­o, comparamos el rendimiento de la cachÃ© en frÃ­o del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecuciÃ³n de los sistemas en el entorno de la red de Ã¡rea local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de Ã¡rea amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en cachÃ© frÃ­a. Los nÃºmeros fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frÃ­o solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frÃ­o solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparaciÃ³n con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cÃ¡lculos para el cliente, solicitudes de recuperaciÃ³n directa, recuperaciones de pares y solicitudes de confirmaciÃ³n. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperaciÃ³n entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperaciÃ³n del servidor para cada cliente individual disminuye porque, con mÃ¡s clientes accediendo a un mÃ³dulo compartido de tamaÃ±o fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperaciÃ³n de pares en comparaciÃ³n con la recuperaciÃ³n directa, pero este beneficio se ve contrarrestado por los tiempos de confirmaciÃ³n aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relaciÃ³n con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de cachÃ© 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT funciÃ³n de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias tÃ­picas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Sorprendentemente, los resultados analÃ­ticos predicen la mejora medida muy de cerca, aunque son ligeramente mÃ¡s altos que los valores empÃ­ricos. La razÃ³n principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidaciÃ³n evitados, comparamos el rendimiento de cachÃ© caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interÃ©s de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un Ãºnico cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compaÃ±eros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compaÃ±eros con un grupo que contiene un Ãºnico escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuraciÃ³n simple es suficiente para mostrar el impacto de las tÃ©cnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de cachÃ© caliente de OO7. Obtenemos los nÃºmeros ejecutando 2000 transacciones para filtrar los fallos en frÃ­o y luego medimos el tiempo de las siguientes 1000 transacciones. AquÃ­ nuevamente, los nÃºmeros reportados se derivan de los resultados del experimento de la red de Ã¡rea local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalizaciÃ³n en comparaciÃ³n con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparaciÃ³n con la Base. Este beneficio se debe a la actualizaciÃ³n entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperaciÃ³n entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperaciÃ³n local evitando el retraso de la recuperaciÃ³n desde el servidor. El Ãºltimo es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperaciÃ³n de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperaciÃ³n de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualizaciÃ³n de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relaciÃ³n con Base, y Buddy Writer y Base en relaciÃ³n con Base) en un experimento de cachÃ© activa en funciÃ³n del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualizaciÃ³n entre pares domina el gasto general en la configuraciÃ³n de Writer incluso en redes de baja latencia (la actualizaciÃ³n entre pares incurre en un gasto mÃ­nimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Como en experimentos de cachÃ© frÃ­a, aquÃ­ los resultados analÃ­ticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pÃ©rdida de invalidaciÃ³n es mÃ­nimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de cachÃ© frÃ­a). Como en el caso de cachÃ© frÃ­a, la razÃ³n por la que el modelo analÃ­tico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÃ“N Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en una red de Ã¡rea extensa debido a la alta latencia de red. Este artÃ­culo describe BuddyCache, una nueva tÃ©cnica de almacenamiento en cachÃ© cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La tÃ©cnica mejora el rendimiento y proporciona propiedades sÃ³lidas de correcciÃ³n y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirecciÃ³n para obtener objetos faltantes directamente de las cachÃ©s de los miembros del grupo, y para admitir la actualizaciÃ³n entre pares, una nueva tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirecciÃ³n puede interferir con la disponibilidad del objeto. Solo commit es una nueva tÃ©cnica de validaciÃ³n que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validaciÃ³n detallada utilizando informaciÃ³n de versiÃ³n de grano grueso econÃ³mica. Hemos diseÃ±ado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analÃ­ticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Las principales contribuciones del artÃ­culo son: 1. extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementaciÃ³n del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluaciÃ³n del rendimiento basada en anÃ¡lisis y mediciones de los costos y beneficios de las nuevas tÃ©cnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. TambiÃ©n agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios Ãºtiles que mejoraron este artÃ­culo. 9. REFERENCIAS [1] emulab.net, la InstalaciÃ³n de EmulaciÃ³n de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. ReconstrucciÃ³n de fragmentos: Proporcionando coherencia de cachÃ© global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre GestiÃ³n de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: ComputaciÃ³n en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de cachÃ© hÃ­bridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. RecuperaciÃ³n rÃ¡pida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de cachÃ© en la World Wide Web. En la 17Âª Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluaciÃ³n del rendimiento del sistema de gestiÃ³n de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una cachÃ© de objetos jerÃ¡rquica en Internet. En la Conferencia TÃ©cnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachÃ©s de Internet escalables. Informe TÃ©cnico CS-1997-18, Departamento de Ciencias de la ComputaciÃ³n, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: CachÃ© de proxy cooperativa en una red de Ã¡rea amplia. En el Tercer Taller Internacional de CachÃ© de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. CachÃ© web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2Âº Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. CachÃ© cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilaciÃ³n y en tiempo de ejecuciÃ³n para una memoria compartida distribuida eficiente. En Actas de IEEE, EdiciÃ³n Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la cachÃ©: un protocolo de intercambio de cachÃ© web escalable de Ã¡rea amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. ImplementaciÃ³n de GestiÃ³n Global de Memoria en un ClÃºster de Estaciones de Trabajo. Actas del 15Âº Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: DiseÃ±o, ImplementaciÃ³n y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de cachÃ© transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, pÃ¡ginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. GestiÃ³n global de memoria para arquitecturas de sistemas de gestiÃ³n de bases de datos cliente-servidor. En Actas del 19Âº Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El BÃºfer de Objeto Modificado: Una TÃ©cnica de GestiÃ³n de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto TecnolÃ³gico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. GestiÃ³n de documentos replicados en un sistema de comunicaciÃ³n grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13Âª Conferencia Europea sobre ProgramaciÃ³n Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18Âº Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. ReplicaciÃ³n con marca de vista: un nuevo mÃ©todo de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de ComputaciÃ³n Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalaciÃ³n eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de MultidifusiÃ³n a Nivel de AplicaciÃ³n. En el 3er Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de cachÃ© cooperativa utilizando pistas. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en CachÃ© Global. Informe tÃ©cnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del CachÃ© de Proxies Web Cooperativos. En el 17Âº Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerÃ¡rquica de cachÃ© en una WAN. En el Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. ComparticiÃ³n adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÃ‰NDICE Este apÃ©ndice describe el protocolo de conmutaciÃ³n por error de BuddyCache. Para dar cabida a clientes heterogÃ©neos, incluidos los dispositivos portÃ¡tiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseÃ±o de BuddyCache asume que las cachÃ©s del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresÃ­a detecta el fallo de un cliente o un redireccionador intercambiando mensajes periÃ³dicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutaciÃ³n por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuraciÃ³n y reinicia el protocolo. El protocolo de reconfiguraciÃ³n del grupo es similar al presentado en [25]. AquÃ­ describimos cÃ³mo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de pÃ¡ginas redireccionadas y el reenvÃ­o de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachÃ©s. En caso de un fallo del cliente, el failover elimina las pÃ¡ginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmaciÃ³n, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en cachÃ© las pÃ¡ginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutaciÃ³n por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de pÃ¡ginas utilizando un protocolo similar al descrito en [6]. El redireccionador reciÃ©n reiniciado solicita a los miembros activos del grupo la lista de pÃ¡ginas que estÃ¡n almacenando en cachÃ© y el estado de estas pÃ¡ginas, es decir, si las pÃ¡ginas estÃ¡n completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperaciÃ³n perdida expirarÃ¡ en el cliente y serÃ¡ retransmitida. Una transacciÃ³n que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma despuÃ©s del cambio se trata como una transacciÃ³n regular; una transacciÃ³n que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciarÃ¡ la transacciÃ³n y la solicitud de confirmaciÃ³n serÃ¡ retransmitida despuÃ©s del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caÃ­do podrÃ­an evitar la recolecciÃ³n de basura de las invalidaciones pendientes en los servidores o la cachÃ© virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los nÃºmeros de versiÃ³n Ãºnicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validaciÃ³n de transacciones depende del protocolo de coherencia de cachÃ© para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutaciÃ³n por error de BuddyCache no compromete la correcciÃ³n del procedimiento de validaciÃ³n. Recuerda que la validaciÃ³n de transacciones de BuddyCache utiliza dos mecanismos complementarios, nÃºmeros de versiÃ³n de pÃ¡gina y confirmaciones de invalidaciÃ³n de los clientes, para verificar que una transacciÃ³n ha leÃ­do datos actualizados. La propagaciÃ³n de la confirmaciÃ³n de invalidaciÃ³n (y actualizaciÃ³n) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmaciÃ³n de una modificaciÃ³n (invalidaciÃ³n o actualizaciÃ³n) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en cachÃ© el objeto o bien ha instalado el valor mÃ¡s reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmaciÃ³n de un cliente para una transacciÃ³n T que lee un objeto o despuÃ©s de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidaciÃ³n no confirmada para o pendiente para este grupo, la versiÃ³n del objeto leÃ­da por la transacciÃ³n T estÃ¡ actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validaciÃ³n utilizando nÃºmeros de versiÃ³n. El registro de confirmaciÃ³n de transacciÃ³n contiene un nÃºmero de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n. El protocolo de nÃºmero de versiÃ³n mantiene la invariante V P que garantiza que el valor del objeto o leÃ­do por la transacciÃ³n corresponda al nÃºmero de versiÃ³n mÃ¡s alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificaciÃ³n anterior despuÃ©s de haber recibido una modificaciÃ³n posterior. La retransmisiÃ³n de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validaciÃ³n verifica que el nÃºmero de versiÃ³n en el registro de confirmaciÃ³n coincida con el nÃºmero de versiÃ³n en la invalidaciÃ³n pendiente no reconocida. Es fÃ¡cil ver que, dado que esta comprobaciÃ³n es una comprobaciÃ³n cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutaciÃ³n por error aÃºn no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "cooperative cache": {
            "translated_key": "cachÃ© cooperativo",
            "is_in_text": false,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "fine-grain share": {
            "translated_key": "participaciÃ³n detallada",
            "is_in_text": false,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and fault-tolerance properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and fault-tolerance properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "fault-tolerance": {
            "translated_key": "tolerancia a fallos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications in a WAN âˆ— Magnus E. Bjornsson and Liuba Shrira Department of Computer Science Brandeis University Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu ABSTRACT Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area networks because of high network latency.",
                "BuddyCache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers.",
                "We have implemented a BuddyCache prototype and evaluated its performance.",
                "Analytical results, confirmed by measurements of the BuddyCache prototype using the multiuser 007 benchmark indicate that for typical Internet latencies, e.g. ranging from 40 to 80 milliseconds round trip time to the storage server, peers using BuddyCache can reduce by up to 50% the latency of access to shared objects compared to accessing the remote servers directly.",
                "Categories and Subject Descriptors C.2.4 [Computer Systems Organization]: Distributed Systems General Terms Design, Performance 1.",
                "INTRODUCTION Improvements in network connectivity erode the distinction between local and wide-area computing and, increasingly, users expect their work environment to follow them wherever they go.",
                "Nevertheless, distributed applications may perform poorly in wide-area network environments.",
                "Network bandwidth problems will improve in the foreseeable future, but improvement in network latency is fundamentally limited.",
                "BuddyCache is a new object caching technique that addresses the network latency problem for collaborative applications in wide-area network environment.",
                "Collaborative applications provide a shared work environment for groups of networked users collaborating on a common task, for example a team of engineers jointly overseeing a construction project.",
                "Strong-consistency collaborative applications, for example CAD systems, use client/server transactional object storage systems to ensure consistent access to shared persistent data.",
                "Up to now however, users have rarely considered running consistent network storage systems over wide-area networks as performance would be unacceptable [24].",
                "For transactional storage systems, the high cost of wide-area network interactions to maintain data consistency is the main cost limiting the performance and therefore, in wide-area network environments, collaborative applications have been adapted to use weaker consistency storage systems [22].",
                "Adapting an application to use weak consistency storage system requires significant effort since the application needs to be rewritten to deal with a different storage system semantics.",
                "If shared persistent objects could be accessed with low-latency, a new field of distributed strong-consistency applications could be opened.",
                "Cooperative web caching [10, 11, 15] is a well-known approach to reducing client interaction with a server by allowing one client to obtain missing objects from a another client instead of the server.",
                "Collaborative applications seem a particularly good match to benefit from this approach since one of the hard problems, namely determining what objects are cached where, becomes easy in small groups typical of collaborative settings.",
                "However, cooperative web caching techniques do not provide two important properties needed by collaborative applications, strong consistency and efficient 26 access to fine-grained objects.",
                "Cooperative object caching systems [2] provide these properties.",
                "However, they rely on interaction with the server to provide fine-grain cache coherence that avoids the problem of false sharing when accesses to unrelated objects appear to conflict because they occur on the same physical page.",
                "Interaction with the server increases latency.",
                "The contribution of this work is extending cooperative caching techniques to provide strong consistency and efficient access to fine-grain objects in wide-area environments.",
                "Consider a team of engineers employed by a construction company overseeing a remote project and working in a shed at the construction site.",
                "The engineers use a collaborative CAD application to revise and update complex project design documents.",
                "The shared documents are stored in transactional repository servers at the company home site.",
                "The engineers use workstations running repository clients.",
                "The workstations are interconnected by a fast local Ethernet but the network connection to the home repository servers is slow.",
                "To improve access latency, clients fetch objects from repository servers and cache and access them locally.",
                "A coherence protocol ensures that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborative application is coordinating with the servers consistent access to shared objects.",
                "With BuddyCache, a group of close-by collaborating clients, connected to storage repository via a high-latency link, can avoid interactions with the server if needed objects, updates or coherency information are available in some client in the group.",
                "BuddyCache presents two main technical challenges.",
                "One challenge is how to provide efficient access to shared finegrained objects in the collaborative group without imposing performance overhead on the entire caching system.",
                "The other challenge is to support fine-grain cache coherence in the presence of slow and failed nodes.",
                "BuddyCache uses a redirection approach similar to one used in cooperative web caching systems [11].",
                "A redirector server, interposed between the clients and the remote servers, runs on the same network as the collaborating group and, when possible, replaces the function of the remote servers.",
                "If the client request can not be served locally, the redirector forwards it to a remote server.",
                "When one of the clients in the group fetches a shared object from the repository, the object is likely to be needed by other clients.",
                "BuddyCache redirects subsequent requests for this object to the caching client.",
                "Similarly, when a client creates or modifies a shared object, the new data is likely to be of potential interest to all group members.",
                "BuddyCache uses redirection to support peer update, a lightweight application-level multicast technique that provides group members with consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Nevertheless, in a transactional system, redirection interferes with shared object availability.",
                "Solo commit, is a validation technique used by BuddyCache to avoid the undesirable client dependencies that reduce object availability when some client nodes in the group are slow, or clients fail independently.",
                "A salient feature of solo commit is supporting fine-grained validation using inexpensive coarse-grained coherence information.",
                "Since redirection supports the performance benefits of reducing interaction with the server but introduces extra processing cost due to availability mechanisms and request forwarding, this raises the question is the cure worse than the disease?",
                "We designed and implemented a BuddyCache prototype and studied its performance benefits and costs using analytical modeling and system measurements.",
                "We compared the storage system performance with and without BuddyCache and considered how the cost-benefit balance is affected by network latency.",
                "Analytical results, supported by measurements based on the multi-user 007 benchmark, indicate that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "These strong performance gains could make transactional object storage systems more attractive for collaborative applications in wide-area environments. 2.",
                "RELATED WORK Cooperative caching techniques [20, 16, 13, 2, 28] provide access to client caches to avoid high disk access latency in an environment where servers and clients run on a fast local area network.",
                "These techniques use the server to provide redirection and do not consider issues of high network latency.",
                "Multiprocessor systems and distributed shared memory systems [14, 4, 17, 18, 5] use fine-grain coherence techniques to avoid the performance penalty of false sharing but do not address issues of availability when nodes fail.",
                "Cooperative Web caching techniques, (e.g. [11, 15]) investigate issues of maintaining a directory of objects cached in nearby proxy caches in wide-area environment, using distributed directory protocols for tracking cache changes.",
                "This work does not consider issues of consistent concurrent updates to shared fine-grained objects.",
                "Cheriton and Li propose MMO [12] a hybrid web coherence protocol that combines invalidations with updates using multicast delivery channels and receiver-reliable protocol, exploiting locality in a way similar to BuddyCache.",
                "This multicast transport level solution is geared to the single writer semantics of web objects.",
                "In contrast, BuddyCache uses application level multicast and a sender-reliable coherence protocol to provide similar access latency improvements for transactional objects.",
                "Application level multicast solution in a middle-ware system was described by Pendarakis, Shi and Verma in [27].",
                "The schema supports small multi-sender groups appropriate for collaborative applications and considers coherence issues in the presence of failures but does not support strong consistency or fine-grained sharing.",
                "Yin, Alvisi, Dahlin and Lin [32, 31] present a hierarchical WAN cache coherence scheme.",
                "The protocol uses leases to provide fault-tolerant call-backs and takes advantage of nearby caches to reduce the cost of lease extensions.",
                "The study uses simulation to investigate latency and fault tolerance issues in hierarchical avoidance-based coherence scheme.",
                "In contrast, our work uses implementation and analysis to evaluate the costs and benefits of redirection and fine grained updates in an optimistic system.",
                "Anderson, Eastham and Vahdat in WebFS [29] present a global file system coherence protocol that allows clients to choose 27 on per file basis between receiving updates or invalidations.",
                "Updates and invalidations are multicast on separate channels and clients subscribe to one of the channels.",
                "The protocol exploits application specific methods e.g. last-writer-wins policy for broadcast applications, to deal with concurrent updates but is limited to file systems.",
                "Mazieres studies a bandwidth saving technique [24] to detect and avoid repeated file fragment transfers across a WAN when fragments are available in a local cache.",
                "BuddyCache provides similar bandwidth improvements when objects are available in the group cache. 3.",
                "BUDDYCACHE High network latency imposes performance penalty for transactional applications accessing shared persistent objects in wide-area network environment.",
                "This section describes the BuddyCache approach for reducing the network latency penalty in collaborative applications and explains the main design decisions.",
                "We consider a system in which a distributed transactional object repository stores objects in highly reliable servers, perhaps outsourced in data-centers connected via high-bandwidth reliable networks.",
                "Collaborating clients interconnected via a fast local network, connect via high-latency, possibly satellite, links to the servers at the data-centers to access shared persistent objects.",
                "The servers provide disk storage for the persistent objects.",
                "A persistent object is owned by a single server.",
                "Objects may be small (order of 100 bytes for programming language objects [23]).",
                "To amortize the cost of disk and network transfer objects are grouped into physical pages.",
                "To improve object access latency, clients fetch the objects from the servers and cache and access them locally.",
                "A transactional cache coherence protocol runs at clients and servers to ensure that client caches remain consistent when objects are modified.",
                "The performance problem facing the collaborating client group is the high latency of coordinating consistent access to the shared objects.",
                "BuddyCache architecture is based on a request redirection server, interposed between the clients and the remote servers.",
                "The interposed server (the redirector) runs on the same network as the collaborative group and, when possible, replaces the function of the remote servers.",
                "If the client request can be served locally, the interaction with the server is avoided.",
                "If the client request can not be served locally, redirector forwards it to a remote server.",
                "Redirection approach has been used to improve the performance of web caching protocols.",
                "BuddyCache redirector supports the correctness, availability and <br>fault-tolerance</br> properties of transactional caching protocol [19].",
                "The correctness property ensures onecopy serializability of the objects committed by the client transactions.",
                "The availability and <br>fault-tolerance</br> properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects.",
                "The three types of client server interactions in a transactional caching protocol are the commit of a transaction, the fetch of an object missing in a client cache, and the exchange of cache coherence information.",
                "BuddyCache avoids interactions with the server when a missing object, or cache coherence information needed by a client is available within the collaborating group.",
                "The redirector always interacts with the servers at commit time because only storage servers provide transaction durability in a way that ensures committed Client Redirector Client Client Buddy Group Client Redirector Client Client Buddy Group Servers Figure 1: BuddyCache. data remains available in the presence of client or redirector failures.",
                "Figure 1 shows the overall BuddyCache architecture. 3.1 Cache Coherence The redirector maintains a directory of pages cached at each client to provide cooperative caching [20, 16, 13, 2, 28], redirecting a client fetch request to another client that caches the requested object.",
                "In addition, redirector manages cache coherence.",
                "Several efficient transactional cache coherence protocols [19] exist for persistent object storage systems.",
                "Protocols make different choices in granularity of data transfers and granularity of cache consistency.",
                "The current best-performing protocols use page granularity transfers when clients fetch missing objects from a server and object granularity coherence to avoid false (page-level) conflicts.",
                "The transactional caching taxonomy [19] proposed by Carey, Franklin and Livny classifies the coherence protocols into two main categories according to whether a protocol avoids or detects access to stale objects in the client cache.",
                "The BuddyCache approach could be applied to both categories with different performance costs and benefits in each category.",
                "We chose to investigate BuddyCache in the context of OCC [3], the current best performing detection-based protocol.",
                "We chose OCC because it is simple, performs well in high-latency networks, has been implemented and we had access to the implementation.",
                "We are investigating BuddyCache with PSAA [33], the best performing avoidancebased protocol.",
                "Below we outline the OCC protocol [3].",
                "The OCC protocol uses object-level coherence.",
                "When a client requests a missing object, the server transfers the containing page.",
                "Transaction can read and update locally cached objects without server intervention.",
                "However, before a transaction commits it must be validated; the server must make sure the validating transaction has not read a stale version of some object that was updated by a successfully committed or validated transaction.",
                "If validation fails, the transaction is aborted.",
                "To reduce the number and cost of aborts, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figure 2: Peer fetch a server sends background object invalidation messages to clients caching the containing pages.",
                "When clients receive invalidations they remove stale objects from the cache and send background acknowledgments to let server know about this.",
                "Since invalidations remove stale objects from the client cache, invalidation acknowledgment indicates to the server that a client with no outstanding invalidations has read upto-date objects.",
                "An unacknowledged invalidation indicates a stale object may have been accessed in the client cache.",
                "The validation procedure at the server aborts a client transaction if a client reads an object while an invalidation is outstanding.",
                "The acknowledged invalidation mechanism supports object-level cache coherence without object-based directories or per-object version numbers.",
                "Avoiding per-object overheads is very important to reduce performance penalties [3] of managing many small objects, since typical objects are small.",
                "An important BuddyCache design goal is to maintain this benefit.",
                "Since in BuddyCache a page can be fetched into a client cache without server intervention (as illustrated in figure 2), cache directories at the servers keep track of pages cached in each collaborating group rather than each client.",
                "Redirector keeps track of pages cached in each client in a group.",
                "Servers send to the redirector invalidations for pages cached in the entire group.",
                "The redirector propagates invalidations from servers to affected clients.",
                "When all affected clients acknowledge invalidations, redirector can propagate the group acknowledgment to the server. 3.2 Light-weight Peer Update When one of the clients in the collaborative group creates or modifies shared objects, the copies cached by any other client become stale but the new data is likely to be of potential interest to the group members.",
                "The goal in BuddyCache is to provide group members with efficient and consistent access to updates committed within the group without imposing extra overhead on other parts of the storage system.",
                "The two possible approaches to deal with stale data are cache invalidations and cache updates.",
                "Cache coherence studies in web systems (e.g. [7]) DSM systems (e.g. [5]), and transactional object systems (e.g. [19]) compare the benefits of update and invalidation.",
                "The studies show the Committing Client Server Redirector x2.",
                "Store x 6.",
                "Update x 3.",
                "Commit x 4.",
                "Commit OK 5.",
                "Commit OK1.",
                "Commit x Figure 3: Peer update. benefits are strongly workload-dependent.",
                "In general, invalidation-based coherence protocols are efficient since invalidations are small, batched and piggybacked on other messages.",
                "Moreover, invalidation protocols match the current hardware trend for increasing client cache sizes.",
                "Larger caches are likely to contain much more data than is actively used.",
                "Update-based protocols that propagate updates to low-interest objects in a wide-area network would be wasteful.",
                "Nevertheless, invalidation-based coherence protocols can perform poorly in high-latency networks [12] if the objects new value is likely to be of interest to another group member.",
                "With an invalidation-based protocol, one members update will invalidate another members cached copy, causing the latter to perform a high-latency fetch of the new value from the server.",
                "BuddyCache circumvents this well-known bandwidth vs. latency trade-off imposed by update and invalidation protocols in wide-area network environments.",
                "It avoids the latency penalty of invalidations by using the redirector to retain and propagate updates committed by one client to other clients within the group.",
                "This avoids the bandwidth penalty of updates because servers propagate invalidations to the redirectors.",
                "As far as we know, this use of localized multicast in BuddyCache redirector is new and has not been used in earlier caching systems.",
                "The peer update works as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinating server.",
                "After the transaction commits, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client, and also propagates the retained committed updates to the clients caching the modified pages (see figure 3).",
                "Since the groups outside the BuddyCache propagate invalidations, there is no extra overhead outside the committing group. 3.3 Solo commit In the OCC protocol, clients acknowledge server invalidations (or updates) to indicate removal of stale data.",
                "The straightforward group acknowledgement protocol where redirector collects and propagates a collective acknowledge29 Redirector commit ok ABORT Client 1 Client 2 Server commit (P(x)) commit (P(x)) ok + inv(P(x)) inv(P(x)) commit(P(x)) commit(P(x)) ack(P(x)) ack(P(x)) Figure 4: Validation with Slow Peers ment to the server, interferes with the availability property of the transactional caching protocol [19] since a client that is slow to acknowledge an invalidation or has failed can delay a group acknowledgement and prevent another client in the group from committing a transaction.",
                "E.g. an engineer that commits a repeated revision to the same shared design object (and therefore holds the latest version of the object) may need to abort if the group acknowledgement has not propagated to the server.",
                "Consider a situation depicted in figure 4 where Client1 commits a transaction T that reads the latest version of an object x on page P recently modified by Client1.",
                "If the commit request for T reaches the server before the collective acknowledgement from Client2 for the last modification of x arrives at the server, the OCC validation procedure considers x to be stale and aborts T (because, as explained above, an invalidation unacknowledged by a client, acts as indication to the server that the cached object value is stale at the client).",
                "Note that while invalidations are not required for the correctness of the OCC protocol, they are very important for the performance since they reduce the performance penalties of aborts and false sharing.",
                "The asynchronous invalidations are an important part of the reason OCC has competitive performance with PSAA [33], the best performing avoidance-based protocol [3].",
                "Nevertheless, since invalidations are sent and processed asynchronously, invalidation processing may be arbitrarily delayed at a client.",
                "Lease-based schemes (time-out based) have been proposed to improve the availability of hierarchical callback-based coherence protocols [32] but the asynchronous nature of invalidations makes the lease-based approaches inappropriate for asynchronous invalidations.",
                "The Solo commit validation protocol allows a client with up-to-date objects to commit a transaction even if the group acknowledgement is delayed due to slow or crashed peers.",
                "The protocol requires clients to include extra information with the transaction read sets in the commit message, to indicate to the server the objects read by the transaction are up-to-date.",
                "Object version numbers could provide a simple way to track up-to-date objects but, as mentioned above, maintaining per object version numbers imposes unacceptably high overheads (in disk storage, I/O costs and directory size) on the entire object system when objects are small [23].",
                "Instead, solo commit uses coarse-grain page version numbers to identify fine-grain object versions.",
                "A page version number is incremented at a server when at transaction that modifies objects on the page commits.",
                "Updates committed by a single transaction and corresponding invalidations are therefore uniquely identified by the modified page version number.",
                "Page version numbers are propagated to clients in fetch replies, commit replies and with invalidations, and clients include page version numbers in commit requests sent to the servers.",
                "If a transaction fails validation due to missing group acknowledgement, the server checks page version numbers of the objects in the transaction read set and allows the transaction to commit if the client has read from the latest page version.",
                "The page version numbers enable independent commits but page version checks only detect page-level conflicts.",
                "To detect object-level conflicts and avoid the problem of false sharing we need the acknowledged invalidations.",
                "Section 4 describes the details of the implementation of solo commit support for fine-grain sharing. 3.4 Group Configuration The BuddyCache architecture supports multiple concurrent peer groups.",
                "Potentially, it may be faster to access data cached in another peer group than to access a remote server.",
                "In such case extending BuddyCache protocols to support multi-level peer caching could be worthwhile.",
                "We have not pursued this possibility for several reasons.",
                "In web caching workloads, simply increasing the population of clients in a proxy cache often increases the overall cache hit rate [30].",
                "In BuddyCache applications, however, we expect sharing to result mainly from explicit client interaction and collaboration, suggesting that inter-group fetching is unlikely to occur.",
                "Moreover, measurements from multi-level web caching systems [9] indicate that a multilevel system may not be advantageous unless the network connection between the peer groups is very fast.",
                "We are primarily interested in environments where closely collaborating peers have fast close-range connectivity, but the connection between peer groups may be slow.",
                "As a result, we decided that support for inter-group fetching in BuddyCache is not a high priority right now.",
                "To support heterogenous resource-rich and resource-poor peers, the BuddyCache redirector can be configured to run either in one of the peer nodes or, when available, in a separate node within the site infrastructure.",
                "Moreover, in a resource-rich infrastructure node, the redirector can be configured as a stand-by peer cache to receive pages fetched by other peers, emulating a central cache somewhat similar to a regional web proxy cache.",
                "From the BuddyCache cache coherence protocol point of view, however, such a stand-by peer cache is equivalent to a regular peer cache and therefore we do not consider this case separately in the discussion in this paper. 4.",
                "IMPLEMENTATION In this section we provide the details of the BuddyCache implementation.",
                "We have implemented BuddyCache in the Thor client/server object-oriented database [23].",
                "Thor supports high performance access to distributed objects and therefore provides a good test platform to investigate BuddyCache performance. 30 4.1 Base Storage System Thor servers provide persistent storage for objects and clients cache copies of these objects.",
                "Applications run at the clients and interact with the system by making calls on methods of cached objects.",
                "All method calls occur within atomic transactions.",
                "Clients communicate with servers to fetch pages or to commit a transaction.",
                "The servers have a disk for storing persistent objects, a stable transaction log, and volatile memory.",
                "The disk is organized as a collection of pages which are the units of disk access.",
                "The stable log holds commit information and object modifications for committed transactions.",
                "The server memory contains cache directory and a recoverable modified object cache called the MOB.",
                "The directory keeps track of which pages are cached by which clients.",
                "The MOB holds recently modified objects that have not yet been written back to their pages on disk.",
                "As MOB fills up, a background process propagates modified objects to the disk [21, 26]. 4.2 Base Cache Coherence Transactions are serialized using optimistic concurrency control OCC [3] described in Section 3.1.",
                "We provide some of the relevant OCC protocol implementation details.",
                "The client keeps track of objects that are read and modified by its transaction; it sends this information, along with new copies of modified objects, to the servers when it tries to commit the transaction.",
                "The servers determine whether the commit is possible, using a two-phase commit protocol if the transaction used objects at multiple servers.",
                "If the transaction commits, the new copies of modified objects are appended to the log and also inserted in the MOB.",
                "The MOB is recoverable, i.e. if the server crashes, the MOB is reconstructed at recovery by scanning the log.",
                "Since objects are not locked before being used, a transaction commit can cause caches to contain obsolete objects.",
                "Servers will abort a transaction that used obsolete objects.",
                "However, to reduce the probability of aborts, servers notify clients when their objects become obsolete by sending them invalidation messages; a server uses its directory and the information about the committing transaction to determine what invalidation messages to send.",
                "Invalidation messages are small because they simply identify obsolete objects.",
                "Furthermore, they are sent in the background, batched and piggybacked on other messages.",
                "When a client receives an invalidation message, it removes obsolete objects from its cache and aborts the current transaction if it used them.",
                "The client continues to retain pages containing invalidated objects; these pages are now incomplete with holes in place of the invalidated objects.",
                "Performing invalidation on an object basis means that false sharing does not cause unnecessary aborts; keeping incomplete pages in the client cache means that false sharing does not lead to unnecessary cache misses.",
                "Clients acknowledge invalidations to indicate removal of stale data as explained in Section 3.1.",
                "Invalidation messages prevent some aborts, and accelerate those that must happen - thus wasting less work and oï¬„oading detection of aborts from servers to clients.",
                "When a transaction aborts, its client restores the cached copies of modified objects to the state they had before the transaction started; this is possible because a client makes a copy of an object the first time it is modified by a transaction. 4.3 Redirection The redirector runs on the same local network as the peer group, in one of the peer nodes, or in a special node within the infrastructure.",
                "It maintains a directory of pages available in the peer group and provides fast centralized fetch redirection (see figure 2) between the peer caches.",
                "To improve performance, clients inform the redirector when they evict pages or objects by piggybacking that information on messages sent to the redirector.",
                "To ensure up-to-date objects are fetched from the group cache the redirector tracks the status of the pages.",
                "A cached page is either complete in which case it contains consistent values for all the objects, or incomplete, in which case some of the objects on a page are marked invalid.",
                "Only complete pages are used by the peer fetch.",
                "The protocol for maintaining page status when pages are updated and invalidated is described in Section 4.4.",
                "When a client request has to be processed at the servers, e.g., a complete requested page is unavailable in the peer group or a peer needs to commit a transaction, the redirector acts as a server proxy: it forwards the request to the server, and then forwards the reply back to the client.",
                "In addition, in response to invalidations sent by a server, the redirector distributes the update or invalidation information to clients caching the modified page and, after all clients acknowledge, propagates the group acknowledgment back to the server (see figure 3).",
                "The redirector-server protocol is, in effect, the client-server protocol used in the base Thor storage system, where the combined peer group cache is playing the role of a single client cache in the base system. 4.4 Peer Update The peer update is implemented as follows.",
                "An update commit request from a client arriving at the redirector contains the object updates.",
                "Redirector retains the updates and propagates the request to the coordinator server.",
                "After a transaction commits, using a two phase commit if needed, the coordinator server sends a commit reply to the redirector of the committing client group.",
                "The redirector forwards the reply to the committing client.",
                "It waits for the invalidations to arrive to propagate corresponding retained (committed) updates to the clients caching the modified pages (see figure 3.)",
                "Participating servers that are home to objects modified by the transaction generate object invalidations for each cache group that caches pages containing the modified objects (including the committing group).",
                "The invalidations are sent lazily to the redirectors to ensure that all the clients in the groups caching the modified objects get rid of the stale data.",
                "In cache groups other than the committing group, redirectors propagates the invalidations to all the clients caching the modified pages, collect the client acknowledgments and after completing the collection, propagate collective acknowledgments back to the server.",
                "Within the committing client group, the arriving invalidations are not propagated.",
                "Instead, updates are sent to clients caching those objects pages, the updates are acknowledged by the client, and the collective acknowledgment is propagated to the server.",
                "An invalidation renders a cached page unavailable for peer fetch changing the status of a complete page p into an incomplete.",
                "In contrast, an update of a complete page preserves the complete page status.",
                "As shown by studies of the 31 fragment reconstruction [2], such update propagation allows to avoid the performance penalties of false sharing.",
                "That is, when clients within a group modify different objects on the same page, the page retains its complete status and remains available for peer fetch.",
                "Therefore, the effect of peer update is similar to eager fragment reconstruction [2].",
                "We have also considered the possibility of allowing a peer to fetch an incomplete page (with invalid objects marked accordingly) but decided against this possibility because of the extra complexity involved in tracking invalid objects. 4.5 Vcache The solo commit validation protocol allows clients with up-to-date objects to commit independently of slower (or failed) group members.",
                "As explained in Section 3.3, the solo commit protocol allows a transaction T to pass validation if extra coherence information supplied by the client indicates that transaction T has read up-to-date objects.",
                "Clients use page version numbers to provide this extra coherence information.",
                "That is, a client includes the page version number corresponding to each object in the read object set sent in the commit request to the server.",
                "Since a unique page version number corresponds to each committed object update, the page version number associated with an object allows the validation procedure at the server to check if the client transaction has read up-to-date objects.",
                "The use of coarse-grain page versions to identify object versions avoids the high penalty of maintaining persistent object versions for small objects, but requires an extra protocol at the client to maintain the mapping from a cached object to the identifying page version (ObjectToVersion).",
                "The main implementation issue is concerned with maintaining this mapping efficiently.",
                "At the server side, when modifications commit, servers associate page version numbers with the invalidations.",
                "At validation time, if an unacknowledged invalidation is pending for an object x read by a transaction T, the validation procedure checks if the version number for x in Ts read set matches the version number for highest pending invalidation for x, in which case the object value is current, otherwise T fails validation.",
                "We note again that the page version number-based checks, and the invalidation acknowledgment-based checks are complimentary in the solo commit validation and both are needed.",
                "The page version number check allows the validation to proceed before invalidation acknowledgments arrive but by itself a page version number check detects page-level conflicts and is not sufficient to support fine-grain coherence without the object-level invalidations.",
                "We now describe how the client manages the mapping ObjectToVersion.",
                "The client maintains a page version number for each cached page.",
                "The version number satisfies the following invariant V P about the state of objects on a page: if a cached page P has a version number v, then the value of an object o on a cached page P is either invalid or it reflects at least the modifications committed by transactions preceding the transaction that set Ps version number to v. New object values and new page version numbers arrive when a client fetches a page or when a commit reply or invalidations arrive for this page.",
                "The new object values modify the page and, therefore, the page version number needs to be updated to maintain the invariant V P. A page version number that arrives when a client fetches a page, replaces Object Version x 8 Redirector Server 1Client 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Server 2 Figure 5: Reordered Invalidations the page version number for this page.",
                "Such an update preserves the invariant V P. Similarly, an in-sequence page version number arriving at the client in a commit or invalidation message advances the version number for the entire cached page, without violating V P. However, invalidations or updates and their corresponding page version numbers can also arrive at the client out of sequence, in which case updating the page version number could violate V P. For example, a commit reply for a transaction that updates object x on page P in server S1, and object y on page Q in server S2, may deliver a new version number for P from the transaction coordinator S1 before an invalidation generated for an earlier transaction that has modified object r on page P arrives from S1 (as shown in figure 5).",
                "The cache update protocol ensures that the value of any object o in a cached page P reflects the update or invalidation with the highest observed version number.",
                "That is, obsolete updates or invalidations received out of sequence do not affect the value of an object.",
                "To maintain the ObjectToVersion mapping and the invariant V P in the presence of out-of-sequence arrival of page version numbers, the client manages a small version number cache vcache that maintains the mapping from an object into its corresponding page version number for all reordered version number updates until a complete page version number sequence is assembled.",
                "When the missing version numbers for the page arrive and complete a sequence, the version number for the entire page is advanced.",
                "The ObjectToVersion mapping, including the vcache and page version numbers, is used at transaction commit time to provide version numbers for the read object set as follows.",
                "If the read object has an entry in the vcache, its version number is equal to the highest version number in the vcache for this object.",
                "If the object is not present in the vcache, its version number is equal the version number of its containing cached page.",
                "Figure 6 shows the ObjectToVersion mapping in the client cache, including the page version numbers for pages and the vcache.",
                "Client can limit vcache size as needed since re-fetching a page removes all reordered page version numbers from the vcache.",
                "However, we expect version number reordering to be uncommon and therefore expect the vcache to be very small. 5.",
                "BUDDYCACHE FAILOVER A client group contains multiple client nodes and a redi32 VersionPageObject Version VCache Client Cache Client Page Cache Figure 6: ObjectToVersion map with vcache rector that can fail independently.",
                "The goal of the failover protocol is to reconfigure the BuddyCache in the case of a node failure, so that the failure of one node does not disrupt other clients from accessing shared objects.",
                "Moreover, the failure of the redirector should allow unaffected clients to keep their caches intact.",
                "We have designed a failover protocols for BuddyCache but have not implemented it yet.",
                "The appendix outlines the protocol. 6.",
                "PERFORMANCE EVALUATION BuddyCache redirection supports the performance benefits of avoiding communication with the servers but introduces extra processing cost due to availability mechanisms and request forwarding.",
                "Is the cure worse then the disease?",
                "To answer the question, we have implemented a BuddyCache prototype for the OCC protocol and conducted experiments to analyze the performance benefits and costs over a range of network latencies. 6.1 Analysis The performance benefits of peer fetch and peer update are due to avoided server interactions.",
                "This section presents a simple analytical performance model for this benefit.",
                "The avoided server interactions correspond to different types of client cache misses.",
                "These can be cold misses, invalidation misses and capacity misses.",
                "Our analysis focuses on cold misses and invalidation misses, since the benefit of avoiding capacity misses can be derived from the cold misses.",
                "Moreover, technology trends indicate that memory and storage capacity will continue to grow and therefore a typical BuddyCache configuration is likely not to be cache limited.",
                "The client cache misses are determined by several variables, including the workload and the cache configuration.",
                "Our analysis tries, as much as possible, to separate these variables so they can be controlled in the validation experiments.",
                "To study the benefit of avoiding cold misses, we consider cold cache performance in a read-only workload (no invalidation misses).",
                "We expect peer fetch to improve the latency cost for client cold cache misses by fetching objects from nearby cache.",
                "We evaluate how the redirection cost affects this benefit by comparing and analyzing the performance of an application running in a storage system with BuddyCache and without (called Base).",
                "To study the benefit of avoiding invalidation misses, we consider hot cache performance in a workload with modifications (with no cold misses).",
                "In hot caches we expect BuddyCache to provide two complementary benefits, both of which reduce the latency of access to shared modified objects.",
                "Peer update lets a client access an object modified by a nearby collaborating peer without the delay imposed by invalidation-only protocols.",
                "In groups where peers share a read-only interest in the modified objects, peer fetch allows a client to access a modified object as soon as a collaborating peer has it, which avoids the delay of server fetch without the high cost imposed by the update-only protocols.",
                "Technology trends indicate that both benefits will remain important in the foreseeable future.",
                "The trend toward increase in available network bandwidth decreases the cost of the update-only protocols.",
                "However, the trend toward increasingly large caches, that are updated when cached objects are modified, makes invalidation-base protocols more attractive.",
                "To evaluate these two benefits we consider the performance of an application running without BuddyCache with an application running BuddyCache in two configurations.",
                "One, where a peer in the group modifies the objects, and another where the objects are modified by a peer outside the group.",
                "Peer update can also avoid invalidation misses due to false-sharing, introduced when multiple peers update different objects on the same page concurrently.",
                "We do not analyze this benefit (demonstrated by earlier work [2]) because our benchmarks do not allow us to control object layout, and also because this benefit can be derived given the cache hit rate and workload contention. 6.1.1 The Model The model considers how the time to complete an execution with and without BuddyCache is affected by invalidation misses and cold misses.",
                "Consider k clients running concurrently accessing uniformly a shared set of N pages in BuddyCache (BC) and Base.",
                "Let tfetch(S), tredirect(S), tcommit(S), and tcompute(S) be the time it takes a client to, respectively, fetch from server, peer fetch, commit a transaction and compute in a transaction, in a system S, where S is either a system with BuddyCache (BC) or without (Base).",
                "For simplicity, our model assumes the fetch and commit times are constant.",
                "In general they may vary with the server load, e.g. they depend on the total number of clients in the system.",
                "The number of misses avoided by peer fetch depends on k, the number of clients in the BuddyCache, and on the client co-interest in the shared data.",
                "In a specific BuddyCache execution it is modeled by the variable r, defined as a number of fetches arriving at the redirector for a given version of page P (i.e. until an object on the page is invalidated).",
                "Consider an execution with cold misses.",
                "A client starts with a cold cache and runs read-only workload until it accesses all N pages while committing l transactions.",
                "We assume there are no capacity misses, i.e. the client cache is large enough to hold N pages.",
                "In BC, r cold misses for page P reach the redirector.",
                "The first of the misses fetches P from the server, and the subsequent r âˆ’ 1 misses are redirected.",
                "Since each client accesses the entire shared set r = k. Let Tcold(Base) and Tcold(BC) be the time it takes to complete the l transactions in Base and BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consider next an execution with invalidation misses.",
                "A client starts with a hot cache containing the working set of N pages.",
                "We focus on a simple case where one client (writer) runs a workload with modifications, and the other clients (readers) run a read-only workload.",
                "In a group containing the writer (BCW ), peer update eliminates all invalidation misses.",
                "In a group containing only readers (BCR), during a steady state execution with uniform updates, a client transaction has missinv invalidation misses.",
                "Consider the sequence of r client misses on page P that arrive at the redirector in BCR between two consequent invalidations of page P. The first miss goes to the server, and the r âˆ’ 1 subsequent misses are redirected.",
                "Unlike with cold misses, r â‰¤ k because the second invalidation disables redirection for P until the next miss on P causes a server fetch.",
                "Assuming uniform access, a client invalidation miss has a chance of 1/r to be the first miss (resulting in server fetch), and a chance of (1 âˆ’ 1/r) to be redirected.",
                "Let Tinval(Base), Tinval(BCR) and Tinval(BCW ) be the time it takes to complete a single transaction in the Base, BCR and BCW systems.",
                "Tinval(Base) = missinv âˆ— tfetch(Base) +tcompute + tcommit(Base) (3) Tinval(BCR) = missinv âˆ— ( 1 r âˆ— tfetch(BCR) +(1 âˆ’ 1 r ) âˆ— tredirect(BCR)) +tcompute + tcommit(BCR) (4) Tinval(BCW ) = tcompute + tcommit(BCW ) (5) In the experiments described below, we measure the parameters N, r, missinv, tfetch(S), tredirect(S), tcommit(S), and tcompute(S).",
                "We compute the completion times derived using the above model and derive the benefits.",
                "We then validate the model by comparing the derived values to the completion times and benefits measured directly in the experiments. 6.2 Experimental Setup Before presenting our results we describe our experimental setup.",
                "We use two systems in our experiments.",
                "The Base system runs Thor distributed object storage system [23] with clients connecting directly to the servers.",
                "The Buddy system runs our implementation of BuddyCache prototype in Thor, supporting peer fetch, peer update, and solo commit, but not the failover.",
                "Our workloads are based on the multi-user OO7 benchmark [8]; this benchmark is intended to capture the characteristics of many different multi-user CAD/CAM/CASE applications, but does not model any specific application.",
                "We use OO7 because it is a standard benchmark for measuring object storage system performance.",
                "The OO7 database contains a tree of assembly objects with leaves pointing to three composite parts chosen randomly from among 500 such objects.",
                "Each composite part contains a graph of atomic parts linked by connection objects; each atomic part has 3 outgoing connections.",
                "We use a medium database that has 200 atomic parts per composite part.",
                "The multi-user database allocates for each client a private module consisting of one tree of assembly objects, and adds an extra shared module that scales proportionally to the number of clients.",
                "We expect a typical BuddyCache configuration not to be cache limited and therefore focus on workloads where the objects in the client working set fit in the cache.",
                "Since the goal of our study is to evaluate how effectively our techniques deal with access to shared objects, in our study we limit client access to shared data only.",
                "This allows us to study the effect our techniques have on cold cache and cache consistency misses and isolate as much as possible the effect of cache capacity misses.",
                "To keep the length of our experiments reasonable, we use small caches.",
                "The OO7 benchmark generates database modules of predefined size.",
                "In our implementation of OO7, the private module size is about 38MB.",
                "To make sure that the entire working set fits into the cache we use a single private module and choose a cache size of 40MB for each client.",
                "The OO7 database is generated with modules for 3 clients, only one of which is used in our experiments as we explain above.",
                "The objects in the database are clustered in 8K pages, which are also the unit of transfer in the fetch requests.",
                "We consider two types of transaction workloads in our analysis, read-only and read-write.",
                "In OO7 benchmark, read-only transactions use the T1 traversal that performs a depth-first traversal of entire composite part graph.",
                "Write transactions use the T2b traversal that is identical to T1 except that it modifies all the atomic parts in a single composite.",
                "A single transaction includes one traversal and there is no sleep time between transactions.",
                "Both read-only and read-write transactions always work with data from the same module.",
                "Clients running read-write transactions dont modify in every transaction, instead they have a 50% probability of running read-only transactions.",
                "The database was stored by a server on a 40GB IBM 7200RPM hard drive, with a 8.5 average seek time and 40 MB/sec data transfer rates.",
                "In Base system clients connect directly to the database.",
                "In Buddy system clients connect to the redirector that connects to the database.",
                "We run the experiments with 1-10 clients in Base, and one or two 1-10 client groups in Buddy.",
                "The server, the clients and the redirectors ran on a 850MHz Intel Pentium III processor based PC, 512MB of memory, and Linux Red Hat 6.2.",
                "They were connected by a 100Mb/s Ethernet.",
                "The server was configured with a 50MB cache (of which 6MB were used for the modified object buffer), the client had a 40MB cache.",
                "The experiments ran in Utah experimental testbed emulab.net [1]. 34 Latency [ms] Base Buddy 3 group 5 group 3 group 5 group Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Table 1: Commit and Server fetch Operation Latency [ms] PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Table 2: Peer fetch 6.3 Basic Costs This section analyzes the basic cost of the requests in the Buddy system during the OO7 runs. 6.3.1 Redirection Fetch and commit requests in the BuddyCache cross the redirector, a cost not incurred in the Base system.",
                "For a request redirected to the server (server fetch) the extra cost of redirection includes a local request from the client to redirector on the way to and from the server.",
                "We evaluate this latency overhead indirectly by comparing the measured latency of the Buddy system server fetch or commit request with the measured latency of the corresponding request in the Base system.",
                "Table 1 shows the latency for the commit and server fetch requests in the Base and Buddy system for 3 client and 5 client groups in a fast local area network.",
                "All the numbers were computed by averaging measured request latency over 1000 requests.",
                "The measurements show that the redirection cost of crossing the redirector in not very high even in a local area network.",
                "The commit cost increases with the number of clients since commits are processed sequentially.",
                "The fetch cost does not increase as much because the server cache reduces this cost.",
                "In a large system with many groups, however, the server cache becomes less efficient.",
                "To evaluate the overheads of the peer fetch, we measure the peer fetch latency (PeerFetch) at the requesting client and break down its component costs.",
                "In peer fetch, the cost of the redirection includes, in addition to the local network request cost, the CPU processing latency of crossing the redirector and crossing the helper, the latter including the time to process the help request and the time to copy, and unswizzle the requested page.",
                "We directly measured the time to copy and unswizzle the requested page at the helper, (CopyUnswizzle), and timed the crossing times using a null crossing request.",
                "Table 2 summarizes the latencies that allows us to break down the peer fetch costs.",
                "CrossRedirector, includes the CPU latency of crossing the redirector plus a local network round-trip and is measured by timing a round-trip null request issued by a client to the redirector.",
                "AlertHelper, includes the time for the helper to notice the request plus a network roundtrip, and is measured by timing a round-trip null request issued from an auxiliary client to the helper client.",
                "The local network latency is fixed and less than 0.1 ms.",
                "The AlertHelper latency which includes the elapsed time from the help request arrival until the start of help request processing is highly variable and therefore contributes to the high variability of the PeerFetch time.",
                "This is because the client in Buddy system is currently single threaded and therefore only starts processing a help request when blocked waiting for a fetch- or commit reply.",
                "This overhead is not inherent to the BuddyCache architecture and could be mitigated by a multi-threaded implementation in a system with pre-emptive scheduling. 6.3.2 Version Cache The solo commit allows a fast client modifying an object to commit independently of a slow peer.",
                "The solo commit mechanism introduces extra processing at the server at transaction validation time, and extra processing at the client at transaction commit time and at update or invalidation processing time.",
                "The server side overheads are minimal and consist of a page version number update at commit time, and a version number comparison at transaction validation time.",
                "The version cache has an entry only when invalidations or updates arrive out of order.",
                "This may happen when a transaction accesses objects in multiple servers.",
                "Our experiments run in a single server system and therefore, the commit time overhead of version cache management at the client does not contribute in the results presented in the section below.",
                "To gauge these client side overheads in a multiple server system, we instrumented the version cache implementation to run with a workload trace that included reordered invalidations and timed the basic operations.",
                "The extra client commit time processing includes a version cache lookup operation for each object read by the transaction at commit request preparation time, and a version cache insert operation for each object updated by a transaction at commit reply processing time, but only if the updated page is missing some earlier invalidations or updates.",
                "It is important that the extra commit time costs are kept to a minimum since client is synchronously waiting for the commit completion.",
                "The measurements show that in the worst case, when a large number of invalidations arrive out of order, and about half of the objects modified by T2a (200 objects) reside on reordered pages, the cost of updating the version cache is 0.6 ms.",
                "The invalidation time cost are comparable, but since invalidations and updates are processed in the background this cost is less important for the overall performance.",
                "We are currently working on optimizing the version cache implementation to further reduce these costs. 6.4 Overall Performance This section examines the performance gains seen by an application running OO7 benchmark with a BuddyCache in a wide area network. 6.4.1 Cold Misses To evaluate the performance gains from avoiding cold misses we compare the cold cache performance of OO7 benchmark running read-only workload in the Buddy and Base systems.",
                "We derive the times by timing the execution of the systems in the local area network environment and substituting 40 ms and 80 ms delays for the requests crossing the redirector and the server to estimate the performance in the wide-area-network.",
                "Figures 7 and 8 show the overall time to complete 1000 cold cache transactions.",
                "The numbers were 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 7: Breakdown for cold read-only 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clients 5 Clients 10 Clients [ms] CPU Commit Server Fetch Peer Fetch Figure 8: Breakdown for cold read-only 80ms RTT obtained by averaging the overall time of each client in the group.",
                "The results show that in a 40 ms network Buddy system reduces significantly the overall time compared to the Base system, providing a 39% improvement in a three client group, 46% improvement in the five client group and 56% improvement in the ten client case.",
                "The overall time includes time spent performing client computation, direct fetch requests, peer fetches, and commit requests.",
                "In the three client group, Buddy and Base incur almost the same commit cost and therefore the entire performance benefit of Buddy is due to peer fetch avoiding direct fetches.",
                "In the five and ten client group the server fetch cost for individual client decreases because with more clients faulting in a fixed size shared module into BuddyCache, each client needs to perform less server fetches.",
                "Figure 8 shows the overall time and cost break down in the 80 ms network.",
                "The BuddyCache provides similar performance improvements as with the 40ms network.",
                "Higher network latency increases the relative performance advantage provided by peer fetch relative to direct fetch but this benefit is offset by the increased commit times.",
                "Figure 9 shows the relative latency improvement provided by BuddyCache (computed as the overall measured time difference between Buddy and Base relative to Base) as a -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] 3 Clients 3 Clients (Perf model) 5 Clients 5 Clients (Perf model) 10 Clients 10 FEs (perf model) Figure 9: Cold miss benefit 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 10: Breakdown for hot read-write 40ms RTT function of network latency, with a fixed server load.",
                "The cost of the extra mechanism dominates BuddyCache benefit when network latency is low.",
                "At typical Internet latencies 20ms-60ms the benefit increases with latency and levels off around 60ms with significant (up to 62% for ten clients) improvement.",
                "Figure 9 includes both the measured improvement and the improvement derived using the analytical model.Remarkably, the analytical results predict the measured improvement very closely, albeit being somewhat higher than the empirical values.",
                "The main reason why the simplified model works well is it captures the dominant performance component, network latency cost. 6.4.2 Invalidation Misses To evaluate the performance benefits provided by BuddyCache due to avoided invalidation misses, we compared the hot cache performance of the Base system with two different Buddy system configurations.",
                "One of the Buddy system configurations represents a collaborating peer group modifying shared objects (Writer group), the other represents a group where the peers share a read-only interest in the modified objects (Reader group) and the writer resides outside the BuddyCache group.",
                "In each of the three systems, a single client runs a readwrite workload (writer) and three other clients run read-only workload (readers).",
                "Buddy system with one group contain36 0 5 0 100 150 200 250 300 Base Buddy Reader Buddy Writer [ms] CPU Commit Server Fetch Peer Fetch Figure 11: Breakdown for hot read-write 80ms RTT ing a single reader and another group containing two readers and one writer models the Writer group.",
                "Buddy system with one group containing a single writer and another group running three readers models the Reader group.",
                "In Base, one writer and three readers access the server directly.",
                "This simple configuration is sufficient to show the impact of BuddyCache techniques.",
                "Figures 10 and 11 show the overall time to complete 1000 hot cache OO7 read-only transactions.",
                "We obtain the numbers by running 2000 transactions to filter out cold misses and then time the next 1000 transactions.",
                "Here again, the reported numbers are derived from the local area network experiment results.",
                "The results show that the BuddyCache reduces significantly the completion time compared to the Base system.",
                "In a 40 ms network, the overall time in the Writer group improves by 62% compared to Base.",
                "This benefit is due to peer update that avoids all misses due to updates.",
                "The overall time in the Reader group improves by 30% and is due to peer fetch that allows a client to access an invalidated object at the cost of a local fetch avoiding the delay of fetching from the server.",
                "The latter is an important benefit because it shows that on workloads with updates, peer fetch allows an invalidation-based protocol to provide some of the benefits of update-based protocol.",
                "Note that the performance benefit delivered by the peer fetch in the Reader group is approximately 50% less than the performance benefit delivered by peer update in the Writer group.",
                "This difference is similar in 80ms network.",
                "Figure 12 shows the relative latency improvement provided by BuddyCache in Buddy Reader and Buddy Writer configurations (computed as the overall time difference between BuddyReader and Base relative to Base, and Buddy Writer and Base relative to Base) in a hot cache experiment as a function of increasing network latency, for fixed server load.",
                "The peer update benefit dominates overhead in Writer configuration even in low-latency network (peer update incurs minimal overhead) and offers significant 44-64% improvement for entire latency range.",
                "The figure includes both the measured improvement and the improvement derived using the analytical model.",
                "As in cold cache experiments, here the analytical results predict the measured improvement closely.",
                "The difference is -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latency [ms] Benefits[%] Buddy Reader Buddy Reader (perf model) Buddy Writer Buddy Writer (perf model) Figure 12: Invalidation miss benefit minimal in the writer group, and somewhat higher in the reader group (consistent with the results in the cold cache experiments).",
                "As in cold cache case, the reason why the simplified analytical model works well is because it captures the costs of network latency, the dominant performance cost. 7.",
                "CONCLUSION Collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task.",
                "They require strong consistency for shared persistent data and efficient access to fine-grained objects.",
                "These properties are difficult to provide in wide-area network because of high network latency.",
                "This paper described BuddyCache, a new transactional cooperative caching [20, 16, 13, 2, 28] technique that improves the latency of access to shared persistent objects for collaborative strong-consistency applications in high-latency network environments.",
                "The technique improves performance yet provides strong correctness and availability properties in the presence of node failures and slow clients.",
                "BuddyCache uses redirection to fetch missing objects directly from group members caches, and to support peer update, a new lightweight application-level multicast technique that gives group members consistent access to the new data committed within the collaborating group without imposing extra overhead outside the group.",
                "Redirection, however, can interfere with object availability.",
                "Solo commit, is a new validation technique that allows a client in a group to commit independently of slow or failed peers.",
                "It provides fine-grained validation using inexpensive coarse-grain version information.",
                "We have designed and implemented BuddyCache prototype in Thor distributed transactional object storage system [23] and evaluated the benefits and costs of the system over a range of network latencies.",
                "Analytical results, supported by the system measurements using the multi-user 007 benchmark indicate, that for typical Internet latencies BuddyCache provides significant performance benefits, e.g. for latencies ranging from 40 to 80 milliseconds round trip time, clients using the BuddyCache can reduce by up to 50% the latency of access to shared objects compared to the clients accessing the repository directly.",
                "The main contributions of the paper are: 1. extending cooperative caching techniques to support 37 fine-grain strong-consistency access in high-latency environments, 2. an implementation of the system prototype that yields strong performance gains over the base system, 3. analytical and measurement based performance evaluation of the costs and benefits of the new techniques capturing the dominant performance cost, high network latency. 8.",
                "ACKNOWLEDGMENTS We are grateful to Jay Lepreau and the staff of Utah experimental testbed emulab.net [1], especially Leigh Stoller, for hosting the experiments and the help with the testbed.",
                "We also thank Jeff Chase, Maurice Herlihy, Butler Lampson and the OOPSLA reviewers for the useful comments that improved this paper. 9.",
                "REFERENCES [1] emulab.net, the Utah Network Emulation Facility. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari, and L. Shrira.",
                "Fragment Reconstruction: Providing Global Cache Coherence in a Transactional Storage System.",
                "Proceedings of the International Conference on Distributed Computing Systems, May 1997. [3] A. Adya, R. Gruber, B. Liskov, and U. Maheshwari.",
                "Efficient optimistic concurrencty control using loosely synchronized clocks.",
                "In Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1995. [4] C. Amza, A.L.",
                "Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel.",
                "Treadmarks: Shared memory computing on networks of workstations.",
                "IEEE Computer, 29(2), February 1996. [5] C. Anderson and A. Karlin.",
                "Two Adaptive Hybrid Cache Coherency Protocols.",
                "In Proceedings of the 2nd IEEE Symposium on High-Performance Computer Architecture (HPCA 96), February 1996. [6] M. Baker.",
                "Fast Crash Recovery in Distributed File Systems.",
                "PhD thesis, University of California at Berkeley, 1994. [7] P. Cao and C. Liu.",
                "Maintaining Strong Cache Consistency in the World Wide Web.",
                "In 17th International Conference on Distributed Computing Systems., April 1998. [8] M. Carey, D. J. Dewitt, C. Kant, and J. F. Naughton.",
                "A Status Report on the OO7 OODBMS Benchmarking Effort.",
                "In Proceedings of OOPSLA, October 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell, and C. Neerdaels.",
                "A Hierarchical Internet Object Cache.",
                "In USENIX Annual Technical Conference, January 1995. [10] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Directory Structures for Scalable Internet Caches.",
                "Technical Report CS-1997-18, Dept. of Computer Science, Duke University, November 1997. [11] J.",
                "Chase, S. Gadde, and M. Rabinovich.",
                "Not All Hits Are Created Equal: Cooperative Proxy Caching Over a Wide-Area Network.",
                "In Third International WWW Caching Workshop, June 1998. [12] D. R. Cheriton and D. Li.",
                "Scalable Web Caching of Frequently Updated Objects using Reliable Multicast. 2nd USENIX Symposium on Internet Technologies and Systems, October 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A. Patterson.",
                "Cooperative caching: Using remote client memory to improve file system performance.",
                "Proceedings of the USENIX Conference on Operating Systems Design and Implementation, November 1994. [14] S. Dwarkadas, H. Lu, A.L.",
                "Cox, R. Rajamony, and W. Zwaenepoel.",
                "Combining Compile-Time and Run-Time Support for Efficient Software Distributed Shared Memory.",
                "In Proceedings of IEEE, Special Issue on Distributed Shared Memory, March 1999. [15] Li Fan, Pei Cao, Jussara Almeida, and Andrei Broder.",
                "Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol.",
                "In Proceedings of ACM SIGCOMM, September 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin, and H. Levy.",
                "Implementing Global Memory Management in a Workstation Cluster.",
                "Proceedings of the 15th ACM Symposium on Operating Systems Principles, December 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya, and H. M. Levy.",
                "Integrating Coherency and Recoverablity in Distributed Systems.",
                "In Proceedings of the First Usenix Symposium on Operating sustems Design and Implementation, May 1994. [18] P. Ferreira and M. Shapiro et al.",
                "PerDiS: Design, Implementation, and Use of a PERsistent DIstributed Store.",
                "In Recent Advances in Distributed Systems, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey, and M. Livny.",
                "Transactional Client-Server Cache Consistency: Alternatives and Performance.",
                "In ACM Transactions on Database Systems, volume 22, pages 315-363, September 1997. [20] Michael Franklin, Michael Carey, and Miron Livny.",
                "Global Memory Management for Client-Server DBMS Architectures.",
                "In Proceedings of the 19th Intl.",
                "Conference on Very Large Data Bases (VLDB), August 1992. [21] S. Ghemawat.",
                "The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases.",
                "PhD thesis, Massachusetts Institute of Technology, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie, and I. Greif.",
                "Replicated document management in a group communication system.",
                "In Proceedings of the ACM CSCW Conference, September 1988. [23] B. Liskov, M. Castro, L. Shrira, and A. Adya.",
                "Providing Persistent Objects in Distributed Systems.",
                "In Proceedings of the 13th European Conference on Object-Oriented Programming (ECOOP 99), June 1999. [24] A. Muthitacharoen, B. Chen, and D. Mazieres.",
                "A Low-bandwidth Network File System.",
                "In 18th ACM Symposium on Operating Systems Principles, October 2001. [25] B. Oki and B. Liskov.",
                "Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems.",
                "In Proc. of ACM Symposium on Principles of Distributed 38 Computing, August 1988. [26] J. OToole and L. Shrira.",
                "Opportunistic Log: Efficient Installation Reads in a Reliable Object Server.",
                "In Usenix Symposium on Operation Systems Design and Implementation, November 1994. [27] D. Pendarakis, S. Shi, and D. Verma.",
                "ALMI: An Application Level Multicast Infrastructure.",
                "In 3rd USENIX Symposium on Internet Technologies and Systems, March 2001. [28] P. Sarkar and J. Hartman.",
                "Efficient Cooperative Caching Using Hints.",
                "In Usenix Symposium on Operation Systems Design and Implementation, October 1996. [29] A. M. Vahdat, P. C. Eastham, and T. E Anderson.",
                "WebFS: A Global Cache Coherent File System.",
                "Technical report, University of California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin, and H. Levy.",
                "On the Scale and Performance of Cooperative Web Proxy Caching.",
                "In 17th ACM Symposium on Operating Systems Principles, December 1999. [31] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Hierarchical Cache Consistency in a WAN.",
                "In USENIX Symposium on Internet Technologies and Systems, October 1999. [32] J. Yin, L. Alvisi, M. Dahlin, and C. Lin.",
                "Volume Leases for Consistency in Large-Scale Systems.",
                "IEEE Transactions on Knowledge and Data Engineering, 11(4), July/August 1999. [33] M. Zaharioudakis, M. J. Carey, and M. J. Franklin.",
                "Adaptive, Fine-Grained Sharing in a Client-Server OODBMS: A Callback-Based Approach.",
                "ACM Transactions on Database Systems, 22:570-627, December 1997. 10.",
                "APPENDIX This appendix outlines the BuddyCache failover protocol.",
                "To accommodate heterogeneous clients including resourcepoor hand-helds we do not require the availability of persistent storage in the BuddyCache peer group.",
                "The BuddyCache design assumes that the client caches and the redirector data structures do not survive node failures.",
                "A failure of a client or a redirector is detected by a membership protocol that exchanges periodic I am alive messages between group members and initiates a failover protocol.",
                "The failover determines the active group participants, re-elects a redirector if needed, reinitializes the BuddyCache data structures in the new configuration and restarts the protocol.",
                "The group reconfiguration protocol is similar to the one presented in [25].",
                "Here we describe how the failover manages the BuddyCache state.",
                "To restart the BuddyCache protocol, the failover needs to resynchronize the redirector page directory and clientserver request forwarding so that active clients can continue running transactions using their caches.",
                "In the case of a client failure, the failover removes the crashed client pages from the directory.",
                "Any response to an earlier request initiated by the failed client is ignored except a commit reply, in which case the redirector distributes the retained committed updates to active clients caching the modified pages.",
                "In the case of a redirector failure, the failover protocol reinitializes sessions with the servers and clients, and rebuilds the page directory using a protocol similar to one in [6].",
                "The newly restarted redirector asks the active group members for the list of pages they are caching and the status of these pages, i.e. whether the pages are complete or incomplete.",
                "Requests outstanding at the redirector at the time of the crash may be lost.",
                "A lost fetch request will time out at the client and will be retransmitted.",
                "A transaction running at the client during a failover and committing after the failover is treated as a regular transaction, a transaction trying to commit during a failover is aborted by the failover protocol.",
                "A client will restart the transaction and the commit request will be retransmitted after the failover.",
                "Invalidations, updates or collected update acknowledgements lost at the crashed redirector could prevent the garbage collection of pending invalidations at the servers or the vcache in the clients.",
                "Therefore, servers detecting a redirector crash retransmit unacknowledged invalidations and commit replies.",
                "Unique version numbers in invalidations and updates ensure that duplicate retransmitted requests are detected and discarded.",
                "Since the transaction validation procedure depends on the cache coherence protocol to ensure that transactions do not read stale data, we now need to argue that BuddyCache failover protocol does not compromise the correctness of the validation procedure.",
                "Recall that BuddyCache transaction validation uses two complementary mechanisms, page version numbers and invalidation acknowledgements from the clients, to check that a transaction has read up-to-date data.",
                "The redirector-based invalidation (and update) acknowledgement propagation ensures the following invariant.",
                "When a server receives an acknowledgement for an object o modification (invalidation or update) from a client group, any client in the group caching the object o has either installed the latest value of object o, or has invalidated o.",
                "Therefore, if a server receives a commit request from a client for a transaction T reading an object o after a failover in the client group, and the server has no unacknowledged invalidation for o pending for this group, the version of the object read by the transaction T is up-to-date independently of client or redirector failures.",
                "Now consider the validation using version numbers.",
                "The transaction commit record contains a version number for each object read by the transaction.",
                "The version number protocol maintains the invariant V P that ensures that the value of object o read by the transaction corresponds to the highest version number for o received by the client.",
                "The invariant holds since the client never applies an earlier modification after a later modification has been received.",
                "Retransmition of invalidations and updates maintains this invariant.",
                "The validation procedure checks that the version number in the commit record matches the version number in the unacknowledged outstanding invalidation.",
                "It is straightforward to see that since this check is an end-to-end client-server check it is unaffected by client or redirector failure.",
                "The failover protocol has not been implemented yet. 39"
            ],
            "original_annotated_samples": [
                "BuddyCache redirector supports the correctness, availability and <br>fault-tolerance</br> properties of transactional caching protocol [19].",
                "The availability and <br>fault-tolerance</br> properties ensure that a crashed or slow client does not disrupt any other clients access to persistent objects."
            ],
            "translated_annotated_samples": [
                "El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y <br>tolerancia a fallos</br> del protocolo de almacenamiento en cachÃ© transaccional [19].",
                "Las propiedades de disponibilidad y <br>tolerancia a fallos</br> garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes."
            ],
            "translated_text": "BuddyCache: Almacenamiento de objetos de alto rendimiento para aplicaciones colaborativas de consistencia fuerte en una WAN âˆ— Magnus E. Bjornsson y Liuba Shrira Departamento de Ciencias de la ComputaciÃ³n Universidad Brandeis Waltham, MA 02454-9110 {magnus, liuba}@cs.brandeis.edu RESUMEN Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en redes de Ã¡rea extensa debido a la alta latencia de red. BuddyCache es un nuevo enfoque de almacenamiento en cachÃ© transaccional que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. El desafÃ­o es mejorar el rendimiento al tiempo que se proporcionan las propiedades de correcciÃ³n y disponibilidad de un protocolo de almacenamiento en cachÃ© transaccional en presencia de fallos de nodos y pares lentos. Hemos implementado un prototipo de BuddyCache y evaluado su rendimiento. Los resultados analÃ­ticos, confirmados por las mediciones del prototipo de BuddyCache utilizando el benchmark multiusuario 007, indican que para latencias tÃ­picas de Internet, por ejemplo, que van desde 40 a 80 milisegundos de tiempo de ida y vuelta al servidor de almacenamiento, los pares que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con acceder directamente a los servidores remotos. CategorÃ­as y Descriptores de Asignaturas C.2.4 [OrganizaciÃ³n de Sistemas InformÃ¡ticos]: Sistemas Distribuidos TÃ©rminos Generales DiseÃ±o, Rendimiento 1. INTRODUCCIÃ“N Las mejoras en la conectividad de redes erosionan la distinciÃ³n entre la computaciÃ³n local y de Ã¡rea amplia y, cada vez mÃ¡s, los usuarios esperan que su entorno de trabajo los siga a donde quiera que vayan. Sin embargo, las aplicaciones distribuidas pueden tener un rendimiento deficiente en entornos de redes de Ã¡rea amplia. Los problemas de ancho de banda de la red mejorarÃ¡n en un futuro previsible, pero la mejora en la latencia de la red estÃ¡ fundamentalmente limitada. BuddyCache es una nueva tÃ©cnica de almacenamiento en cachÃ© de objetos que aborda el problema de la latencia de red para aplicaciones colaborativas en un entorno de red de Ã¡rea amplia. Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de usuarios en red que colaboran en una tarea comÃºn, por ejemplo, un equipo de ingenieros supervisando conjuntamente un proyecto de construcciÃ³n. Las aplicaciones colaborativas de alta consistencia, como los sistemas CAD, utilizan sistemas de almacenamiento de objetos transaccionales cliente/servidor para garantizar un acceso consistente a datos persistentes compartidos. Hasta ahora, sin embargo, los usuarios rara vez han considerado ejecutar sistemas de almacenamiento de red consistentes a travÃ©s de redes de Ã¡rea amplia, ya que el rendimiento serÃ­a inaceptable [24]. Para los sistemas de almacenamiento transaccional, el alto costo de las interacciones en redes de Ã¡rea amplia para mantener la consistencia de los datos es el principal costo que limita el rendimiento y, por lo tanto, en entornos de redes de Ã¡rea amplia, las aplicaciones colaborativas se han adaptado para utilizar sistemas de almacenamiento con una consistencia mÃ¡s dÃ©bil. Adaptar una aplicaciÃ³n para utilizar un sistema de almacenamiento de consistencia dÃ©bil requiere un esfuerzo significativo, ya que la aplicaciÃ³n necesita ser reescrita para manejar la semÃ¡ntica de un sistema de almacenamiento diferente. Si los objetos persistentes compartidos pudieran ser accedidos con baja latencia, se podrÃ­a abrir un nuevo campo de aplicaciones distribuidas de consistencia fuerte. El almacenamiento en cachÃ© web cooperativo [10, 11, 15] es un enfoque bien conocido para reducir la interacciÃ³n del cliente con un servidor al permitir que un cliente obtenga objetos faltantes de otro cliente en lugar del servidor. Las aplicaciones colaborativas parecen ser una combinaciÃ³n especialmente buena para beneficiarse de este enfoque, ya que uno de los problemas difÃ­ciles, a saber, determinar quÃ© objetos estÃ¡n almacenados en quÃ© lugar, se vuelve fÃ¡cil en grupos pequeÃ±os tÃ­picos de entornos colaborativos. Sin embargo, las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo no proporcionan dos propiedades importantes necesarias para aplicaciones colaborativas, consistencia fuerte y acceso eficiente a objetos de granularidad fina. Los sistemas de almacenamiento en cachÃ© de objetos cooperativos proporcionan estas propiedades. Sin embargo, dependen de la interacciÃ³n con el servidor para proporcionar coherencia de cachÃ© de grano fino que evita el problema de compartir falso cuando los accesos a objetos no relacionados parecen entrar en conflicto porque ocurren en la misma pÃ¡gina fÃ­sica. La interacciÃ³n con el servidor aumenta la latencia. La contribuciÃ³n de este trabajo es extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para proporcionar consistencia fuerte y acceso eficiente a objetos de grano fino en entornos de Ã¡rea amplia. Considera un equipo de ingenieros empleados por una empresa de construcciÃ³n supervisando un proyecto remoto y trabajando en un cobertizo en el sitio de construcciÃ³n. Los ingenieros utilizan una aplicaciÃ³n CAD colaborativa para revisar y actualizar documentos de diseÃ±o de proyectos complejos. Los documentos compartidos se almacenan en servidores de repositorio transaccional en el sitio principal de la empresa. Los ingenieros utilizan estaciones de trabajo con clientes de repositorio. Las estaciones de trabajo estÃ¡n interconectadas por un Ethernet local rÃ¡pido, pero la conexiÃ³n de red a los servidores del repositorio en casa es lenta. Para mejorar la latencia de acceso, los clientes recuperan objetos de los servidores de repositorio y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia garantiza que las cachÃ©s de los clientes permanezcan consistentes cuando los objetos son modificados. El problema de rendimiento que enfrenta la aplicaciÃ³n colaborativa es coordinar el acceso consistente de los servidores a los objetos compartidos. Con BuddyCache, un grupo de clientes cercanos que colaboran entre sÃ­, conectados a un repositorio de almacenamiento a travÃ©s de un enlace de alta latencia, pueden evitar interacciones con el servidor si los objetos necesarios, actualizaciones o informaciÃ³n de coherencia estÃ¡n disponibles en algÃºn cliente del grupo. BuddyCache presenta dos desafÃ­os tÃ©cnicos principales. Uno de los desafÃ­os es cÃ³mo proporcionar un acceso eficiente a objetos compartidos de grano fino en el grupo colaborativo sin imponer una sobrecarga de rendimiento en todo el sistema de almacenamiento en cachÃ©. El otro desafÃ­o es mantener la coherencia de cachÃ© de grano fino en presencia de nodos lentos y fallidos. BuddyCache utiliza un enfoque de redirecciÃ³n similar al utilizado en sistemas de almacenamiento en cachÃ© web cooperativos [11]. Un servidor de redirecciÃ³n, intercalado entre los clientes y los servidores remotos, se ejecuta en la misma red que el grupo colaborador y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. Cuando uno de los clientes del grupo obtiene un objeto compartido del repositorio, es probable que otros clientes tambiÃ©n lo necesiten. BuddyCache redirige las solicitudes posteriores de este objeto al cliente de almacenamiento en cachÃ©. De manera similar, cuando un cliente crea o modifica un objeto compartido, es probable que los nuevos datos sean de interÃ©s potencial para todos los miembros del grupo. BuddyCache utiliza la redirecciÃ³n para admitir la actualizaciÃ³n entre pares, una tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que proporciona a los miembros del grupo un acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, en un sistema transaccional, la redirecciÃ³n interfiere con la disponibilidad de objetos compartidos. Solo commit, es una tÃ©cnica de validaciÃ³n utilizada por BuddyCache para evitar las dependencias no deseadas del cliente que reducen la disponibilidad del objeto cuando algunos nodos clientes en el grupo son lentos, o los clientes fallan de forma independiente. Una caracterÃ­stica destacada de la confirmaciÃ³n individual es el soporte de validaciÃ³n detallada utilizando informaciÃ³n de coherencia de grano grueso econÃ³mica. Dado que la redirecciÃ³n respalda los beneficios de rendimiento al reducir la interacciÃ³n con el servidor pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes, surge la pregunta: Â¿es peor el remedio que la enfermedad? DiseÃ±amos e implementamos un prototipo de BuddyCache y estudiamos sus beneficios de rendimiento y costos utilizando modelado analÃ­tico y mediciones del sistema. Comparamos el rendimiento del sistema de almacenamiento con y sin BuddyCache y consideramos cÃ³mo la relaciÃ³n costo-beneficio se ve afectada por la latencia de red. Los resultados analÃ­ticos, respaldados por mediciones basadas en el benchmark multi-usuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos de rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Estos sÃ³lidos avances en el rendimiento podrÃ­an hacer que los sistemas de almacenamiento de objetos transaccionales sean mÃ¡s atractivos para aplicaciones colaborativas en entornos de Ã¡rea amplia. El trabajo relacionado Las tÃ©cnicas de almacenamiento en cachÃ© cooperativo [20, 16, 13, 2, 28] proporcionan acceso a las cachÃ©s de los clientes para evitar la alta latencia de acceso al disco en un entorno donde los servidores y los clientes se ejecutan en una red de Ã¡rea local rÃ¡pida. Estas tÃ©cnicas utilizan el servidor para proporcionar redirecciÃ³n y no consideran problemas de alta latencia de red. Los sistemas multiprocesador y los sistemas de memoria compartida distribuida utilizan tÃ©cnicas de coherencia de grano fino para evitar la penalizaciÃ³n de rendimiento por compartir falsa, pero no abordan los problemas de disponibilidad cuando los nodos fallan. Las tÃ©cnicas de almacenamiento en cachÃ© web cooperativo, (por ejemplo, [11, 15]), investigan cuestiones relacionadas con el mantenimiento de un directorio de objetos almacenados en cachÃ©s proxy cercanas en un entorno de Ã¡rea amplia, utilizando protocolos de directorio distribuido para rastrear cambios en la cachÃ©. Este trabajo no considera problemas de actualizaciones concurrentes consistentes en objetos compartidos de granularidad fina. Cheriton y Li proponen MMO [12], un protocolo hÃ­brido de coherencia web que combina invalidaciones con actualizaciones utilizando canales de entrega multicast y un protocolo de recepciÃ³n confiable, explotando la localidad de una manera similar a BuddyCache. Esta soluciÃ³n de nivel de transporte multicast estÃ¡ diseÃ±ada para la semÃ¡ntica de escritura Ãºnica de objetos web. Por el contrario, BuddyCache utiliza multicast a nivel de aplicaciÃ³n y un protocolo de coherencia confiable del remitente para ofrecer mejoras similares en la latencia de acceso para objetos transaccionales. La soluciÃ³n de multidifusiÃ³n a nivel de aplicaciÃ³n en un sistema de middleware fue descrita por Pendarakis, Shi y Verma en [27]. El esquema admite grupos pequeÃ±os de mÃºltiples remitentes adecuados para aplicaciones colaborativas y considera problemas de coherencia en presencia de fallos, pero no admite consistencia fuerte ni comparticiÃ³n detallada. Yin, Alvisi, Dahlin y Lin [32, 31] presentan un esquema jerÃ¡rquico de coherencia de cachÃ© en WAN. El protocolo utiliza arrendamientos para proporcionar devoluciones de llamadas tolerantes a fallos y aprovecha las cachÃ©s cercanas para reducir el costo de las extensiones de arrendamiento. El estudio utiliza simulaciÃ³n para investigar problemas de latencia y tolerancia a fallos en un esquema de coherencia jerÃ¡rquica basado en la evitaciÃ³n. Por el contrario, nuestro trabajo utiliza la implementaciÃ³n y el anÃ¡lisis para evaluar los costos y beneficios de la redirecciÃ³n y las actualizaciones detalladas en un sistema optimista. Anderson, Eastham y Vahdat en WebFS [29] presentan un protocolo de coherencia de sistema de archivos global que permite a los clientes elegir entre recibir actualizaciones o invalidaciones en una base por archivo. Las actualizaciones y las invalidaciones se transmiten por multidifusiÃ³n en canales separados y los clientes se suscriben a uno de los canales. El protocolo explota mÃ©todos especÃ­ficos de aplicaciÃ³n, por ejemplo, la polÃ­tica de Ãºltimo escritor en aplicaciones de difusiÃ³n, para manejar actualizaciones concurrentes pero estÃ¡ limitado a sistemas de archivos. Mazieres estudia una tÃ©cnica de ahorro de ancho de banda [24] para detectar y evitar transferencias repetidas de fragmentos de archivos a travÃ©s de una WAN cuando los fragmentos estÃ¡n disponibles en una cachÃ© local. BuddyCache proporciona mejoras similares en el ancho de banda cuando los objetos estÃ¡n disponibles en la cachÃ© de grupo. 3. La alta latencia de red de BUDDYCACHE impone una penalizaciÃ³n de rendimiento para aplicaciones transaccionales que acceden a objetos persistentes compartidos en un entorno de red de Ã¡rea amplia. Esta secciÃ³n describe el enfoque de BuddyCache para reducir la penalizaciÃ³n de latencia de red en aplicaciones colaborativas y explica las principales decisiones de diseÃ±o. Consideramos un sistema en el que un repositorio de objetos transaccionales distribuido almacena objetos en servidores altamente confiables, quizÃ¡s subcontratados en centros de datos conectados a travÃ©s de redes confiables de alta velocidad. Clientes colaboradores interconectados a travÃ©s de una red local rÃ¡pida se conectan a los servidores en los centros de datos a travÃ©s de enlaces de alta latencia, posiblemente satelitales, para acceder a objetos persistentes compartidos. Los servidores proporcionan almacenamiento en disco para los objetos persistentes. Un objeto persistente es propiedad de un Ãºnico servidor. Los objetos pueden ser pequeÃ±os (del orden de 100 bytes para objetos de lenguajes de programaciÃ³n [23]). Para amortizar el costo de disco y transferencia de red, los objetos se agrupan en pÃ¡ginas fÃ­sicas. Para mejorar la latencia de acceso a los objetos, los clientes recuperan los objetos de los servidores y los almacenan en cachÃ© para acceder a ellos localmente. Un protocolo de coherencia de cachÃ© transaccional se ejecuta en clientes y servidores para garantizar que las cachÃ©s de los clientes permanezcan consistentes cuando se modifican los objetos. El problema de rendimiento que enfrenta el grupo de clientes colaboradores es la alta latencia al coordinar el acceso consistente a los objetos compartidos. La arquitectura de BuddyCache se basa en un servidor de redirecciÃ³n de solicitudes, intercalado entre los clientes y los servidores remotos. El servidor intermedio (el redireccionador) se ejecuta en la misma red que el grupo colaborativo y, cuando es posible, reemplaza la funciÃ³n de los servidores remotos. Si la solicitud del cliente puede ser atendida localmente, se evita la interacciÃ³n con el servidor. Si la solicitud del cliente no puede ser atendida localmente, el redireccionador la envÃ­a a un servidor remoto. El enfoque de redirecciÃ³n se ha utilizado para mejorar el rendimiento de los protocolos de almacenamiento en cachÃ© web. El redireccionador de BuddyCache admite las propiedades de correcciÃ³n, disponibilidad y <br>tolerancia a fallos</br> del protocolo de almacenamiento en cachÃ© transaccional [19]. La propiedad de correcciÃ³n garantiza la serializaciÃ³n de una copia de los objetos comprometidos por las transacciones del cliente. Las propiedades de disponibilidad y <br>tolerancia a fallos</br> garantizan que un cliente que se haya bloqueado o que funcione lentamente no interrumpa el acceso de otros clientes a los objetos persistentes. Los tres tipos de interacciones cliente-servidor en un protocolo de almacenamiento en cachÃ© transaccional son la confirmaciÃ³n de una transacciÃ³n, la recuperaciÃ³n de un objeto faltante en la cachÃ© del cliente y el intercambio de informaciÃ³n de coherencia de cachÃ©. BuddyCache evita las interacciones con el servidor cuando un objeto faltante, o la informaciÃ³n de coherencia de cachÃ© necesaria por un cliente estÃ¡ disponible dentro del grupo colaborador. El redireccionador siempre interactÃºa con los servidores en el momento de la confirmaciÃ³n porque solo los servidores de almacenamiento proporcionan durabilidad de transacciones de una manera que garantiza que los datos comprometidos permanezcan disponibles en presencia de fallos del cliente o del redireccionador. La Figura 1 muestra la arquitectura general de BuddyCache. 3.1 Coherencia de la cachÃ© El redireccionador mantiene un directorio de pÃ¡ginas almacenadas en cachÃ© en cada cliente para proporcionar una cachÃ© cooperativa [20, 16, 13, 2, 28], redirigiendo una solicitud de recuperaciÃ³n de un cliente a otro cliente que almacena en cachÃ© el objeto solicitado. AdemÃ¡s, el redireccionador gestiona la coherencia de la cachÃ©. Varios protocolos eficientes de coherencia de cachÃ© transaccional [19] existen para sistemas de almacenamiento de objetos persistentes. Los protocolos hacen diferentes elecciones en la granularidad de las transferencias de datos y la granularidad de la consistencia de la cachÃ©. Los protocolos actuales de mejor rendimiento utilizan transferencias de granularidad de pÃ¡gina cuando los clientes recuperan objetos faltantes de un servidor y coherencia de granularidad de objeto para evitar conflictos falsos (a nivel de pÃ¡gina). La taxonomÃ­a de almacenamiento en cachÃ© transaccional [19] propuesta por Carey, Franklin y Livny clasifica los protocolos de coherencia en dos categorÃ­as principales segÃºn si un protocolo evita o detecta el acceso a objetos obsoletos en la cachÃ© del cliente. El enfoque BuddyCache podrÃ­a aplicarse a ambas categorÃ­as con diferentes costos de rendimiento y beneficios en cada categorÃ­a. Decidimos investigar BuddyCache en el contexto de OCC [3], el protocolo basado en detecciÃ³n de mejor rendimiento actual. Elegimos OCC porque es simple, funciona bien en redes de alta latencia, ha sido implementado y tenÃ­amos acceso a la implementaciÃ³n. Estamos investigando BuddyCache con PSAA [33], el protocolo basado en evitaciÃ³n de mejor rendimiento. A continuaciÃ³n, detallamos el protocolo OCC [3]. El protocolo OCC utiliza coherencia a nivel de objeto. Cuando un cliente solicita un objeto faltante, el servidor transfiere la pÃ¡gina que lo contiene. La transacciÃ³n puede leer y actualizar objetos almacenados en cachÃ© localmente sin intervenciÃ³n del servidor. Sin embargo, antes de que una transacciÃ³n se confirme, debe ser validada; el servidor debe asegurarse de que la transacciÃ³n validadora no haya leÃ­do una versiÃ³n obsoleta de algÃºn objeto que fue actualizado por una transacciÃ³n exitosamente confirmada o validada. Si la validaciÃ³n falla, la transacciÃ³n se cancela. Para reducir el nÃºmero y el costo de las interrupciones, 28 Helper Requester A:p Fetch pPeer fetch p Page p Redirector Figura 2: El servidor de bÃºsqueda de pares envÃ­a mensajes de invalidaciÃ³n de objetos en segundo plano a los clientes que almacenan en cachÃ© las pÃ¡ginas que los contienen. Cuando los clientes reciben invalidaciones, eliminan objetos obsoletos de la cachÃ© y envÃ­an confirmaciones en segundo plano para informar al servidor al respecto. Dado que las invalidaciones eliminan objetos obsoletos de la cachÃ© del cliente, la confirmaciÃ³n de invalidaciÃ³n indica al servidor que un cliente sin invalidaciones pendientes ha leÃ­do objetos actualizados. Una invalidaciÃ³n no reconocida indica que un objeto obsoleto puede haber sido accedido en la cachÃ© del cliente. El procedimiento de validaciÃ³n en el servidor aborta una transacciÃ³n del cliente si este lee un objeto mientras hay una invalidaciÃ³n pendiente. El mecanismo de invalidaciÃ³n reconocido admite coherencia de cachÃ© a nivel de objeto sin directorios basados en objetos o nÃºmeros de versiÃ³n por objeto. Evitar los costos adicionales por objeto es muy importante para reducir las penalizaciones de rendimiento [3] al gestionar muchos objetos pequeÃ±os, ya que los objetos tÃ­picos son pequeÃ±os. Un objetivo importante del diseÃ±o de BuddyCache es mantener este beneficio. Dado que en BuddyCache una pÃ¡gina puede ser recuperada en una cachÃ© de cliente sin intervenciÃ³n del servidor (como se ilustra en la figura 2), los directorios de cachÃ© en los servidores llevan un registro de las pÃ¡ginas almacenadas en cada grupo colaborador en lugar de en cada cliente. El redireccionador lleva un registro de las pÃ¡ginas almacenadas en cachÃ© en cada cliente de un grupo. Los servidores envÃ­an al redireccionador invalidaciones para las pÃ¡ginas almacenadas en cachÃ© en todo el grupo. El redireccionador propaga invalidaciones desde los servidores a los clientes afectados. Cuando todos los clientes afectados reconocen las invalidaciones, el redireccionador puede propagar el reconocimiento grupal al servidor. ActualizaciÃ³n de pares ligera Cuando uno de los clientes en el grupo colaborativo crea o modifica objetos compartidos, las copias almacenadas en cachÃ© por cualquier otro cliente se vuelven obsoletas, pero es probable que los nuevos datos sean de interÃ©s potencial para los miembros del grupo. El objetivo en BuddyCache es proporcionar a los miembros del grupo un acceso eficiente y consistente a las actualizaciones realizadas dentro del grupo sin imponer una carga adicional en otras partes del sistema de almacenamiento. Los dos enfoques posibles para tratar con datos obsoletos son las invalidaciones de cachÃ© y las actualizaciones de cachÃ©. Los estudios de coherencia de cachÃ© en sistemas web (por ejemplo, [7]), sistemas DSM (por ejemplo, [5]), y sistemas de objetos transaccionales (por ejemplo, [19]) comparan los beneficios de la actualizaciÃ³n y la invalidaciÃ³n. Los estudios muestran el redireccionador del servidor del cliente comprometido x2. AlmacÃ©n x 6. ActualizaciÃ³n x 3. CompromÃ©tete x 4. Compromiso OK 5. Comprometer OK1. La figura 3 muestra que los beneficios del compromiso de pares estÃ¡n fuertemente influenciados por la carga de trabajo. En general, los protocolos de coherencia basados en invalidaciones son eficientes ya que las invalidaciones son pequeÃ±as, agrupadas y se envÃ­an junto con otros mensajes. AdemÃ¡s, los protocolos de invalidaciÃ³n se ajustan a la tendencia actual de hardware de aumentar los tamaÃ±os de cachÃ© del cliente. Es probable que las cachÃ©s mÃ¡s grandes contengan mucha mÃ¡s informaciÃ³n de la que se utiliza activamente. Los protocolos basados en actualizaciones que propagan actualizaciones a objetos de bajo interÃ©s en una red de Ã¡rea amplia serÃ­an derrochadores. Sin embargo, los protocolos de coherencia basados en invalidaciÃ³n pueden tener un rendimiento deficiente en redes de alta latencia [12] si es probable que el nuevo valor de los objetos sea de interÃ©s para otro miembro del grupo. Con un protocolo basado en invalidaciÃ³n, la actualizaciÃ³n de un miembro invalidarÃ¡ la copia en cachÃ© de otro miembro, lo que provocarÃ¡ que este Ãºltimo realice una recuperaciÃ³n de alto retardo del nuevo valor desde el servidor. BuddyCache evita este conocido compromiso entre ancho de banda y latencia impuesto por los protocolos de actualizaciÃ³n e invalidaciÃ³n en entornos de redes de Ã¡rea amplia. Evita la penalizaciÃ³n de latencia de las invalidaciones al utilizar el redireccionador para retener y propagar las actualizaciones realizadas por un cliente a otros clientes dentro del grupo. Esto evita la penalizaciÃ³n de ancho de banda de las actualizaciones porque los servidores propagan las invalidaciones a los redireccionadores. Hasta donde sabemos, este uso de multidifusiÃ³n localizada en el redireccionador de BuddyCache es nuevo y no ha sido utilizado en sistemas de almacenamiento en cachÃ© anteriores. La actualizaciÃ³n entre pares funciona de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que la transacciÃ³n se confirma, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n, y tambiÃ©n propaga las actualizaciones comprometidas retenidas a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Dado que los grupos fuera del BuddyCache propagan invalidaciones, no hay sobrecarga adicional fuera del grupo que realiza la confirmaciÃ³n. 3.3 ConfirmaciÃ³n individual En el protocolo OCC, los clientes reconocen las invalidaciones del servidor (o actualizaciones) para indicar la eliminaciÃ³n de datos obsoletos. El protocolo de reconocimiento de grupo directo donde el redireccionador recopila y propaga un reconocimiento colectivo, interfiere con la propiedad de disponibilidad del protocolo de almacenamiento en cachÃ© transaccional, ya que un cliente que es lento para reconocer una invalidaciÃ³n o ha fallado puede retrasar un reconocimiento de grupo y evitar que otro cliente en el grupo confirme una transacciÃ³n. Por ejemplo, un ingeniero que realiza una revisiÃ³n repetida al mismo objeto de diseÃ±o compartido (y por lo tanto tiene la Ãºltima versiÃ³n del objeto) puede necesitar abortar si el reconocimiento del grupo no se ha propagado al servidor. Considera una situaciÃ³n representada en la figura 4 donde el Cliente1 realiza una transacciÃ³n T que lee la Ãºltima versiÃ³n de un objeto x en la pÃ¡gina P recientemente modificada por el Cliente1. Si la solicitud de confirmaciÃ³n para T llega al servidor antes de que la confirmaciÃ³n colectiva de Cliente2 por la Ãºltima modificaciÃ³n de x llegue al servidor, el procedimiento de validaciÃ³n de OCC considera que x estÃ¡ obsoleto y aborta T (porque, como se explicÃ³ anteriormente, una invalidaciÃ³n no reconocida por un cliente actÃºa como indicaciÃ³n para el servidor de que el valor del objeto en cachÃ© estÃ¡ obsoleto en el cliente). Es importante tener en cuenta que si bien las invalidaciones no son necesarias para la correcciÃ³n del protocolo OCC, son muy importantes para el rendimiento, ya que reducen las penalizaciones de rendimiento de las cancelaciones y el falso intercambio de datos. Las invalidaciones asÃ­ncronas son una parte importante de la razÃ³n por la que OCC tiene un rendimiento competitivo con PSAA [33], el protocolo basado en evasiÃ³n de mejor rendimiento [3]. Sin embargo, dado que las invalidaciones se envÃ­an y procesan de forma asÃ­ncrona, el procesamiento de las invalidaciones puede retrasarse arbitrariamente en un cliente. Se han propuesto esquemas basados en arrendamiento (basados en tiempo de espera) para mejorar la disponibilidad de protocolos de coherencia basados en devoluciÃ³n de llamada jerÃ¡rquica [32], pero la naturaleza asincrÃ³nica de las invalidaciones hace que los enfoques basados en arrendamiento sean inapropiados para invalidaciones asincrÃ³nicas. El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a un cliente con objetos actualizados confirmar una transacciÃ³n incluso si la confirmaciÃ³n del grupo se retrasa debido a pares lentos o caÃ­dos. El protocolo requiere que los clientes incluyan informaciÃ³n adicional con los conjuntos de lectura de transacciones en el mensaje de confirmaciÃ³n, para indicar al servidor que los objetos leÃ­dos por la transacciÃ³n estÃ¡n actualizados. Los nÃºmeros de versiÃ³n de los objetos podrÃ­an proporcionar una forma sencilla de rastrear objetos actualizados, pero, como se mencionÃ³ anteriormente, mantener nÃºmeros de versiÃ³n por objeto impone costos excesivamente altos (en almacenamiento en disco, costos de E/S y tamaÃ±o de directorio) en todo el sistema de objetos cuando los objetos son pequeÃ±os [23]. En cambio, solo utiliza nÃºmeros de versiÃ³n de pÃ¡gina de grano grueso para identificar versiones de objetos de grano fino. El nÃºmero de versiÃ³n de una pÃ¡gina se incrementa en un servidor cuando una transacciÃ³n que modifica objetos en la pÃ¡gina se confirma. Las actualizaciones realizadas por una Ãºnica transacciÃ³n y las invalidaciones correspondientes son identificadas de manera Ãºnica por el nÃºmero de versiÃ³n de la pÃ¡gina modificada. Los nÃºmeros de versiÃ³n de la pÃ¡gina se propagan a los clientes en respuestas de recuperaciÃ³n, respuestas de confirmaciÃ³n y con invalidaciones, y los clientes incluyen los nÃºmeros de versiÃ³n de la pÃ¡gina en las solicitudes de confirmaciÃ³n enviadas a los servidores. Si una transacciÃ³n falla en la validaciÃ³n debido a la falta de reconocimiento de grupo, el servidor verifica los nÃºmeros de versiÃ³n de pÃ¡gina de los objetos en el conjunto de lectura de la transacciÃ³n y permite que la transacciÃ³n se confirme si el cliente ha leÃ­do desde la Ãºltima versiÃ³n de la pÃ¡gina. Los nÃºmeros de versiÃ³n de la pÃ¡gina permiten confirmaciones independientes, pero las verificaciones de versiÃ³n de pÃ¡gina solo detectan conflictos a nivel de pÃ¡gina. Para detectar conflictos a nivel de objeto y evitar el problema de compartir datos incorrectos, necesitamos las invalidaciones reconocidas. La secciÃ³n 4 describe los detalles de la implementaciÃ³n del soporte de compromiso individual para el intercambio de granularidad fina. 3.4 ConfiguraciÃ³n de Grupo La arquitectura BuddyCache admite mÃºltiples grupos de pares concurrentes. Potencialmente, puede ser mÃ¡s rÃ¡pido acceder a los datos almacenados en otro grupo de pares que acceder a un servidor remoto. En tal caso, podrÃ­a ser valioso extender los protocolos de BuddyCache para admitir el almacenamiento en cachÃ© de pares de mÃºltiples niveles. No hemos seguido esta posibilidad por varias razones. En las cargas de trabajo de almacenamiento en cachÃ© web, simplemente aumentar la poblaciÃ³n de clientes en una cachÃ© proxy a menudo aumenta la tasa general de aciertos en la cachÃ© [30]. En las aplicaciones de BuddyCache, sin embargo, esperamos que el intercambio se produzca principalmente a partir de la interacciÃ³n explÃ­cita entre clientes y la colaboraciÃ³n, lo que sugiere que es poco probable que ocurra la recuperaciÃ³n entre grupos. AdemÃ¡s, las mediciones de sistemas de almacenamiento en cachÃ© web multinivel [9] indican que un sistema multinivel puede no ser ventajoso a menos que la conexiÃ³n de red entre los grupos de pares sea muy rÃ¡pida. Estamos principalmente interesados en entornos donde compaÃ±eros que colaboran estrechamente tienen una conectividad rÃ¡pida a corta distancia, pero la conexiÃ³n entre grupos de compaÃ±eros puede ser lenta. Como resultado, decidimos que el soporte para la recuperaciÃ³n entre grupos en BuddyCache no es una alta prioridad en este momento. Para apoyar a compaÃ±eros con recursos heterogÃ©neos ricos y pobres en recursos, el redireccionador BuddyCache se puede configurar para ejecutarse ya sea en uno de los nodos de compaÃ±eros o, cuando estÃ© disponible, en un nodo separado dentro de la infraestructura del sitio. AdemÃ¡s, en un nodo de infraestructura rico en recursos, el redireccionador se puede configurar como una cachÃ© de pares en espera para recibir pÃ¡ginas recuperadas por otros pares, emulando una cachÃ© central algo similar a una cachÃ© de proxy web regional. Desde el punto de vista del protocolo de coherencia de cachÃ© BuddyCache, sin embargo, un cachÃ© de compaÃ±ero en espera es equivalente a un cachÃ© de compaÃ±ero regular y, por lo tanto, no consideramos este caso por separado en la discusiÃ³n de este documento. 4. En esta secciÃ³n proporcionamos los detalles de la implementaciÃ³n de BuddyCache. Hemos implementado BuddyCache en la base de datos orientada a objetos cliente/servidor Thor [23]. Thor soporta un acceso de alto rendimiento a objetos distribuidos y, por lo tanto, proporciona una buena plataforma de pruebas para investigar el rendimiento de BuddyCache. 30 4.1 Sistema de Almacenamiento Base Los servidores de Thor proporcionan almacenamiento persistente para objetos y los clientes almacenan copias en cachÃ© de estos objetos. Las aplicaciones se ejecutan en los clientes e interactÃºan con el sistema realizando llamadas a mÃ©todos de objetos en cachÃ©. Todas las llamadas a mÃ©todos ocurren dentro de transacciones atÃ³micas. Los clientes se comunican con los servidores para obtener pÃ¡ginas o realizar una transacciÃ³n. Los servidores tienen un disco para almacenar objetos persistentes, un registro de transacciones estable y memoria volÃ¡til. El disco estÃ¡ organizado como una colecciÃ³n de pÃ¡ginas que son las unidades de acceso al disco. El registro estable guarda la informaciÃ³n de confirmaciÃ³n y las modificaciones de objetos para transacciones confirmadas. La memoria del servidor contiene un directorio de cachÃ© y una cachÃ© de objetos modificados recuperable llamada MOB. El directorio lleva un registro de quÃ© pÃ¡ginas estÃ¡n almacenadas en cachÃ© por quÃ© clientes. El MOB contiene objetos recientemente modificados que aÃºn no han sido escritos de vuelta en sus pÃ¡ginas en disco. A medida que MOB se llena, un proceso en segundo plano propaga objetos modificados al disco [21, 26]. 4.2 Las transacciones de coherencia de cachÃ© base se serializan utilizando el control de concurrencia optimista OCC [3] descrito en la SecciÃ³n 3.1. Proporcionamos algunos de los detalles relevantes de la implementaciÃ³n del protocolo OCC. El cliente lleva un registro de los objetos que son leÃ­dos y modificados por su transacciÃ³n; envÃ­a esta informaciÃ³n, junto con nuevas copias de los objetos modificados, a los servidores cuando intenta confirmar la transacciÃ³n. Los servidores determinan si la confirmaciÃ³n es posible, utilizando un protocolo de confirmaciÃ³n de dos fases si la transacciÃ³n utilizÃ³ objetos en mÃºltiples servidores. Si la transacciÃ³n se lleva a cabo, las nuevas copias de los objetos modificados se aÃ±aden al registro y tambiÃ©n se insertan en el MOB. El MOB es recuperable, es decir, si el servidor se cae, el MOB se reconstruye durante la recuperaciÃ³n escaneando el registro. Dado que los objetos no estÃ¡n bloqueados antes de ser utilizados, una confirmaciÃ³n de transacciÃ³n puede hacer que las cachÃ©s contengan objetos obsoletos. Los servidores abortarÃ¡n una transacciÃ³n que haya utilizado objetos obsoletos. Sin embargo, para reducir la probabilidad de abortos, los servidores notifican a los clientes cuando sus objetos se vuelven obsoletos enviÃ¡ndoles mensajes de invalidaciÃ³n; un servidor utiliza su directorio y la informaciÃ³n sobre la transacciÃ³n de confirmaciÃ³n para determinar quÃ© mensajes de invalidaciÃ³n enviar. Los mensajes de invalidaciÃ³n son pequeÃ±os porque simplemente identifican objetos obsoletos. AdemÃ¡s, se envÃ­an en segundo plano, agrupados y transportados junto con otros mensajes. Cuando un cliente recibe un mensaje de invalidaciÃ³n, elimina los objetos obsoletos de su cachÃ© y aborta la transacciÃ³n actual si los utilizÃ³. El cliente sigue conservando pÃ¡ginas que contienen objetos invalidados; estas pÃ¡ginas ahora estÃ¡n incompletas con agujeros en lugar de los objetos invalidados. Realizar la invalidaciÃ³n de forma individual en un objeto significa que el falso intercambio no provoca abortos innecesarios; mantener pÃ¡ginas incompletas en la cachÃ© del cliente significa que el falso intercambio no conduce a fallos innecesarios en la cachÃ©. Los clientes reconocen las invalidaciones para indicar la eliminaciÃ³n de datos obsoletos, como se explica en la SecciÃ³n 3.1. Los mensajes de invalidaciÃ³n evitan algunos abortos y aceleran aquellos que deben ocurrir, reduciendo asÃ­ el desperdicio de trabajo y trasladando la detecciÃ³n de abortos de los servidores a los clientes. Cuando una transacciÃ³n se aborta, su cliente restaura las copias en cachÃ© de los objetos modificados al estado que tenÃ­an antes de que la transacciÃ³n comenzara; esto es posible porque un cliente hace una copia de un objeto la primera vez que es modificado por una transacciÃ³n. 4.3 RedirecciÃ³n El redireccionador se ejecuta en la misma red local que el grupo de pares, en uno de los nodos pares, o en un nodo especial dentro de la infraestructura. Mantiene un directorio de pÃ¡ginas disponibles en el grupo de pares y proporciona una redirecciÃ³n rÃ¡pida y centralizada de recuperaciÃ³n (ver figura 2) entre las cachÃ©s de pares. Para mejorar el rendimiento, los clientes informan al redireccionador cuando eliminan pÃ¡ginas u objetos al incluir esa informaciÃ³n en los mensajes enviados al redireccionador. Para asegurar que los objetos actualizados se obtengan de la cachÃ© de grupo, el redireccionador realiza un seguimiento del estado de las pÃ¡ginas. Una pÃ¡gina en cachÃ© estÃ¡ completa cuando contiene valores consistentes para todos los objetos, o incompleta, cuando algunos de los objetos en una pÃ¡gina estÃ¡n marcados como invÃ¡lidos. Solo se utilizan pÃ¡ginas completas por el proceso de recuperaciÃ³n de pares. El protocolo para mantener el estado de la pÃ¡gina cuando las pÃ¡ginas son actualizadas e invalidadas se describe en la SecciÃ³n 4.4. Cuando una solicitud de un cliente debe ser procesada en los servidores, por ejemplo, si una pÃ¡gina solicitada completa no estÃ¡ disponible en el grupo de pares o si un par necesita confirmar una transacciÃ³n, el redireccionador actÃºa como un proxy de servidor: reenvÃ­a la solicitud al servidor y luego reenvÃ­a la respuesta de vuelta al cliente. AdemÃ¡s, en respuesta a las invalidaciones enviadas por un servidor, el redireccionador distribuye la actualizaciÃ³n o informaciÃ³n de invalidaciÃ³n a los clientes que tienen en cachÃ© la pÃ¡gina modificada y, una vez que todos los clientes lo confirman, propaga el acuse de recibo del grupo de vuelta al servidor (ver figura 3). El protocolo servidor-redireccionador es, en efecto, el protocolo cliente-servidor utilizado en el sistema de almacenamiento base Thor, donde la cachÃ© de grupo de pares combinada estÃ¡ desempeÃ±ando el papel de una Ãºnica cachÃ© de cliente en el sistema base. 4.4 ActualizaciÃ³n de pares La actualizaciÃ³n de pares se implementa de la siguiente manera. Una solicitud de actualizaciÃ³n de confirmaciÃ³n de un cliente que llega al redireccionador contiene las actualizaciones del objeto. El redireccionador retiene las actualizaciones y propaga la solicitud al servidor coordinador. DespuÃ©s de que una transacciÃ³n se confirma, utilizando un compromiso de dos fases si es necesario, el servidor coordinador envÃ­a una respuesta de confirmaciÃ³n al redirigente del grupo de clientes que estÃ¡n confirmando. El redireccionador reenvÃ­a la respuesta al cliente que realiza la confirmaciÃ³n. Espera a que lleguen las invalidaciones para propagar las actualizaciones retenidas (comprometidas) correspondientes a los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas (ver figura 3). Los servidores participantes que albergan objetos modificados por la transacciÃ³n generan invalidaciones de objetos para cada grupo de cachÃ© que almacena pÃ¡ginas que contienen los objetos modificados (incluido el grupo que realiza la confirmaciÃ³n). Las invalidaciones se envÃ­an de forma perezosa a los redireccionadores para asegurar que todos los clientes en los grupos que almacenan en cachÃ© los objetos modificados se deshagan de los datos obsoletos. En grupos de cachÃ© distintos al grupo de confirmaciÃ³n, los redireccionadores propagan las invalidaciones a todos los clientes que almacenan en cachÃ© las pÃ¡ginas modificadas, recopilan las confirmaciones de los clientes y, despuÃ©s de completar la recopilaciÃ³n, propagan las confirmaciones colectivas de vuelta al servidor. Dentro del grupo de clientes que realizan la transacciÃ³n, las invalidaciones que llegan no se propagan. En cambio, las actualizaciones se envÃ­an a los clientes que almacenan en cachÃ© esas pÃ¡ginas de objetos, las actualizaciones son confirmadas por el cliente y la confirmaciÃ³n colectiva se propaga al servidor. Una invalidaciÃ³n hace que una pÃ¡gina en cachÃ© no estÃ© disponible para la recuperaciÃ³n de pares, cambiando el estado de una pÃ¡gina completa p a incompleta. Por el contrario, una actualizaciÃ³n de una pÃ¡gina completa conserva el estado completo de la pÃ¡gina. Como se muestra en los estudios de la reconstrucciÃ³n de fragmentos 31 [2], esta propagaciÃ³n de actualizaciones permite evitar las penalizaciones de rendimiento causadas por el falso compartimiento. Es decir, cuando los clientes dentro de un grupo modifican diferentes objetos en la misma pÃ¡gina, la pÃ¡gina conserva su estado completo y permanece disponible para la recuperaciÃ³n entre pares. Por lo tanto, el efecto de la actualizaciÃ³n de pares es similar a la reconstrucciÃ³n de fragmentos ansiosa [2]. TambiÃ©n hemos considerado la posibilidad de permitir que un compaÃ±ero recupere una pÃ¡gina incompleta (con objetos invÃ¡lidos marcados en consecuencia) pero decidimos rechazar esta posibilidad debido a la complejidad adicional involucrada en el seguimiento de objetos invÃ¡lidos. 4.5 Vcache El protocolo de validaciÃ³n de confirmaciÃ³n en solitario permite a los clientes con objetos actualizados confirmar de forma independiente de los miembros del grupo mÃ¡s lentos (o fallidos). Como se explica en la SecciÃ³n 3.3, el protocolo de commit Ãºnico permite que una transacciÃ³n T pase la validaciÃ³n si la informaciÃ³n adicional de coherencia proporcionada por el cliente indica que la transacciÃ³n T ha leÃ­do objetos actualizados. Los clientes utilizan los nÃºmeros de versiÃ³n de la pÃ¡gina para proporcionar esta informaciÃ³n adicional de coherencia. Es decir, un cliente incluye el nÃºmero de versiÃ³n de la pÃ¡gina correspondiente a cada objeto en el conjunto de objetos leÃ­dos enviado en la solicitud de confirmaciÃ³n al servidor. Dado que a cada actualizaciÃ³n de objeto comprometido le corresponde un nÃºmero de versiÃ³n de pÃ¡gina Ãºnico, el nÃºmero de versiÃ³n de pÃ¡gina asociado con un objeto permite que el procedimiento de validaciÃ³n en el servidor verifique si la transacciÃ³n del cliente ha leÃ­do objetos actualizados. El uso de versiones de pÃ¡gina de grano grueso para identificar versiones de objetos evita el alto costo de mantener versiones de objetos persistentes para objetos pequeÃ±os, pero requiere un protocolo adicional en el cliente para mantener el mapeo de un objeto en cachÃ© a la versiÃ³n de pÃ¡gina identificadora (ObjectToVersion). El principal problema de implementaciÃ³n se refiere a mantener este mapeo de manera eficiente. En el lado del servidor, cuando se realizan modificaciones, los servidores asocian nÃºmeros de versiÃ³n de pÃ¡gina con las invalidaciones. En el momento de la validaciÃ³n, si hay una invalidaciÃ³n no reconocida pendiente para un objeto x leÃ­do por una transacciÃ³n T, el procedimiento de validaciÃ³n verifica si el nÃºmero de versiÃ³n de x en el conjunto de lectura de Ts coincide con el nÃºmero de versiÃ³n de la invalidaciÃ³n pendiente mÃ¡s alta para x, en cuyo caso el valor del objeto estÃ¡ actualizado, de lo contrario, T falla en la validaciÃ³n. Observamos nuevamente que las verificaciones basadas en el nÃºmero de versiÃ³n de la pÃ¡gina y las verificaciones basadas en el reconocimiento de invalidaciÃ³n son complementarias en la validaciÃ³n de confirmaciÃ³n individual y ambas son necesarias. La verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina permite que la validaciÃ³n avance antes de que lleguen las confirmaciones de invalidaciÃ³n, pero por sÃ­ sola, una verificaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina detecta conflictos a nivel de pÃ¡gina y no es suficiente para admitir una coherencia detallada sin las invalidaciones a nivel de objeto. Ahora describimos cÃ³mo el cliente gestiona el mapeo ObjectToVersion. El cliente mantiene un nÃºmero de versiÃ³n de la pÃ¡gina para cada pÃ¡gina en cachÃ©. El nÃºmero de versiÃ³n satisface la siguiente invariante V P sobre el estado de los objetos en una pÃ¡gina: si una pÃ¡gina en cachÃ© P tiene un nÃºmero de versiÃ³n v, entonces el valor de un objeto o en la pÃ¡gina en cachÃ© P es invÃ¡lido o refleja al menos las modificaciones realizadas por transacciones anteriores a la transacciÃ³n que estableciÃ³ el nÃºmero de versiÃ³n de P en v. Los nuevos valores de objetos y los nuevos nÃºmeros de versiÃ³n de pÃ¡gina llegan cuando un cliente obtiene una pÃ¡gina o cuando llega una respuesta de confirmaciÃ³n o invalidaciones para esta pÃ¡gina. Los nuevos valores del objeto modifican la pÃ¡gina y, por lo tanto, el nÃºmero de versiÃ³n de la pÃ¡gina necesita ser actualizado para mantener la invariante V P. Un nÃºmero de versiÃ³n de pÃ¡gina que llega cuando un cliente obtiene una pÃ¡gina, reemplaza la VersiÃ³n del Objeto x 8 Servidor de RedirecciÃ³n 1 Cliente 1 com(P(x,6),Q(y,9)) com(P(x,6),Q(y,9)) ok(P(x,8),Q(y,10)) ok(P(x,8),Q(y,10)) inv(Q(s,11)) inv(Q(s,11)) inv(P(r,7) inv(P(r,7) Servidor 2 Figura 5: Invalideces Reordenadas el nÃºmero de versiÃ³n de la pÃ¡gina para esta pÃ¡gina. Tal actualizaciÃ³n preserva el invariante V P. De manera similar, un nÃºmero de versiÃ³n de pÃ¡gina en secuencia que llega al cliente en un mensaje de confirmaciÃ³n o invalidaciÃ³n avanza el nÃºmero de versiÃ³n para toda la pÃ¡gina en cachÃ©, sin violar V P. Sin embargo, las invalidaciones o actualizaciones y sus nÃºmeros de versiÃ³n de pÃ¡gina correspondientes tambiÃ©n pueden llegar al cliente fuera de secuencia, en cuyo caso la actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina podrÃ­a violar V P. Por ejemplo, una respuesta de confirmaciÃ³n para una transacciÃ³n que actualiza el objeto x en la pÃ¡gina P en el servidor S1, y el objeto y en la pÃ¡gina Q en el servidor S2, puede entregar un nuevo nÃºmero de versiÃ³n para P desde el coordinador de transacciones S1 antes de que llegue una invalidaciÃ³n generada para una transacciÃ³n anterior que ha modificado el objeto r en la pÃ¡gina P desde S1 (como se muestra en la figura 5). El protocolo de actualizaciÃ³n de cachÃ© garantiza que el valor de cualquier objeto o en una pÃ¡gina en cachÃ© P refleje la actualizaciÃ³n o invalidaciÃ³n con el nÃºmero de versiÃ³n observado mÃ¡s alto. Es decir, las actualizaciones obsoletas o invalidaciones recibidas fuera de secuencia no afectan el valor de un objeto. Para mantener el mapeo de ObjectToVersion y la invariante V P en presencia de la llegada desordenada de nÃºmeros de versiÃ³n de pÃ¡gina, el cliente gestiona una pequeÃ±a cachÃ© de nÃºmeros de versiÃ³n vcache que mantiene el mapeo de un objeto a su nÃºmero de versiÃ³n de pÃ¡gina correspondiente para todas las actualizaciones de nÃºmeros de versiÃ³n reordenadas hasta que se ensamble una secuencia completa de nÃºmeros de versiÃ³n de pÃ¡gina. Cuando llegan los nÃºmeros de versiÃ³n faltantes para la pÃ¡gina y completan una secuencia, el nÃºmero de versiÃ³n de toda la pÃ¡gina se avanza. El mapeo de ObjectToVersion, incluyendo los nÃºmeros de versiÃ³n de vcache y pÃ¡gina, se utiliza en el momento de la confirmaciÃ³n de la transacciÃ³n para proporcionar nÃºmeros de versiÃ³n para el conjunto de objetos leÃ­dos de la siguiente manera. Si el objeto leÃ­do tiene una entrada en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n mÃ¡s alto en la vcache para este objeto. Si el objeto no estÃ¡ presente en la vcache, su nÃºmero de versiÃ³n es igual al nÃºmero de versiÃ³n de la pÃ¡gina en cachÃ© que lo contiene. La Figura 6 muestra el mapeo de ObjectToVersion en la cachÃ© del cliente, incluyendo los nÃºmeros de versiÃ³n de las pÃ¡ginas y la vcache. El cliente puede limitar el tamaÃ±o de la cachÃ© virtual segÃºn sea necesario, ya que volver a cargar una pÃ¡gina elimina todos los nÃºmeros de versiÃ³n de pÃ¡gina reordenados de la cachÃ© virtual. Sin embargo, esperamos que la reorganizaciÃ³n de nÃºmeros de versiÃ³n sea poco comÃºn y, por lo tanto, esperamos que la vcache sea muy pequeÃ±a. 5. Un grupo de clientes contiene mÃºltiples nodos de cliente y un objeto de pÃ¡gina de versiÃ³n redi32 VCache Cliente CachÃ© Cliente PÃ¡gina CachÃ© Figura 6: Mapa de Objeto a VersiÃ³n con vcache rector que puede fallar de forma independiente. El objetivo del protocolo de conmutaciÃ³n por error es reconfigurar la BuddyCache en caso de fallo de un nodo, de modo que el fallo de un nodo no interrumpa a otros clientes en el acceso a objetos compartidos. AdemÃ¡s, el fallo del redireccionador deberÃ­a permitir que los clientes no afectados mantengan sus cachÃ©s intactas. Hemos diseÃ±ado un protocolo de conmutaciÃ³n por error para BuddyCache pero aÃºn no lo hemos implementado. El apÃ©ndice describe el protocolo. 6. La redirecciÃ³n de BuddyCache en la evaluaciÃ³n de rendimiento respalda los beneficios de evitar la comunicaciÃ³n con los servidores, pero introduce un costo adicional de procesamiento debido a los mecanismos de disponibilidad y reenvÃ­o de solicitudes. Â¿Es la cura peor que la enfermedad? Para responder a la pregunta, hemos implementado un prototipo de BuddyCache para el protocolo OCC y realizado experimentos para analizar los beneficios de rendimiento y costos en una variedad de latencias de red. 6.1 AnÃ¡lisis Los beneficios de rendimiento de la recuperaciÃ³n entre pares y la actualizaciÃ³n entre pares se deben a la evitaciÃ³n de interacciones con el servidor. Esta secciÃ³n presenta un modelo de rendimiento analÃ­tico simple para este beneficio. Las interacciones del servidor evitadas corresponden a diferentes tipos de fallos en la cachÃ© del cliente. Estos pueden ser fallos frÃ­os, fallos de invalidaciÃ³n y fallos de capacidad. Nuestro anÃ¡lisis se centra en los fallos por frÃ­o y los fallos por invalidaciÃ³n, ya que el beneficio de evitar los fallos de capacidad se puede derivar de los fallos por frÃ­o. AdemÃ¡s, las tendencias tecnolÃ³gicas indican que la capacidad de memoria y almacenamiento seguirÃ¡ creciendo y, por lo tanto, es probable que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ©. Los fallos de cachÃ© del cliente son determinados por varias variables, incluyendo la carga de trabajo y la configuraciÃ³n de cachÃ©. Nuestro anÃ¡lisis intenta, tanto como sea posible, separar estas variables para que puedan ser controladas en los experimentos de validaciÃ³n. Para estudiar el beneficio de evitar fallos en frÃ­o, consideramos el rendimiento de la cachÃ© en frÃ­o en una carga de trabajo de solo lectura (sin fallos de invalidaciÃ³n). Esperamos que la recuperaciÃ³n entre pares mejore el costo de latencia para las solicitudes de cachÃ© frÃ­a del cliente al recuperar objetos de la cachÃ© cercana. Evaluamos cÃ³mo el costo de redirecciÃ³n afecta este beneficio al comparar y analizar el rendimiento de una aplicaciÃ³n que se ejecuta en un sistema de almacenamiento con BuddyCache y sin Ã©l (llamado Base). Para estudiar el beneficio de evitar los fallos de invalidaciÃ³n, consideramos el rendimiento de la cachÃ© caliente en una carga de trabajo con modificaciones (sin fallos en frÃ­o). En las cachÃ©s calientes esperamos que BuddyCache proporcione dos beneficios complementarios, ambos de los cuales reducen la latencia de acceso a objetos modificados compartidos. La actualizaciÃ³n entre pares permite que un cliente acceda a un objeto modificado por un compaÃ±ero colaborador cercano sin el retraso impuesto por los protocolos de invalidaciÃ³n Ãºnicamente. En grupos donde los compaÃ±eros comparten un interÃ©s de solo lectura en los objetos modificados, la recuperaciÃ³n entre pares permite que un cliente acceda a un objeto modificado tan pronto como un compaÃ±ero colaborador lo tenga, lo que evita el retraso de la recuperaciÃ³n del servidor sin el alto costo impuesto por los protocolos de solo actualizaciÃ³n. Las tendencias tecnolÃ³gicas indican que ambos beneficios seguirÃ¡n siendo importantes en el futuro previsible. La tendencia hacia el aumento en el ancho de banda de la red disponible disminuye el costo de los protocolos de actualizaciÃ³n Ãºnicamente. Sin embargo, la tendencia hacia cachÃ©s cada vez mÃ¡s grandes, que se actualizan cuando los objetos en cachÃ© son modificados, hace que los protocolos basados en invalidaciÃ³n sean mÃ¡s atractivos. Para evaluar estos dos beneficios consideramos el rendimiento de una aplicaciÃ³n que se ejecuta sin BuddyCache y una aplicaciÃ³n que se ejecuta con BuddyCache en dos configuraciones. Uno, donde un compaÃ±ero en el grupo modifica los objetos, y otro donde los objetos son modificados por un compaÃ±ero fuera del grupo. La actualizaciÃ³n entre pares tambiÃ©n puede evitar fallos de invalidaciÃ³n debido a falsos compartidos, que se producen cuando varios pares actualizan diferentes objetos en la misma pÃ¡gina de forma concurrente. No analizamos este beneficio (demostrado por trabajos anteriores [2]) porque nuestros puntos de referencia no nos permiten controlar el diseÃ±o del objeto, y tambiÃ©n porque este beneficio se puede derivar dado el Ã­ndice de aciertos en cachÃ© y la contenciÃ³n de la carga de trabajo. 6.1.1 El Modelo El modelo considera cÃ³mo el tiempo para completar una ejecuciÃ³n con y sin BuddyCache se ve afectado por los fallos de invalidaciÃ³n y los fallos en frÃ­o. Considerando k clientes ejecutÃ¡ndose concurrentemente accediendo de manera uniforme a un conjunto compartido de N pÃ¡ginas en BuddyCache (BC) y Base. Que tfetch(S), tredirect(S), tcommit(S) y tcompute(S) sean el tiempo que tarda un cliente en, respectivamente, obtener datos del servidor, obtener datos de un par, confirmar una transacciÃ³n y realizar cÃ¡lculos en una transacciÃ³n, en un sistema S, donde S es un sistema con BuddyCache (BC) o sin Ã©l (Base). Para simplificar, nuestro modelo asume que los tiempos de bÃºsqueda y confirmaciÃ³n son constantes. En general, pueden variar con la carga del servidor, por ejemplo, dependen del nÃºmero total de clientes en el sistema. El nÃºmero de fallos evitados por la recuperaciÃ³n entre pares depende de k, el nÃºmero de clientes en la BuddyCache, y del interÃ©s conjunto de los clientes en los datos compartidos. En una ejecuciÃ³n especÃ­fica de BuddyCache, se modela mediante la variable r, definida como el nÃºmero de solicitudes que llegan al redireccionador para una versiÃ³n dada de la pÃ¡gina P (es decir, hasta que un objeto en la pÃ¡gina se invalida). Considera una ejecuciÃ³n con fallos en frÃ­o. Un cliente comienza con una cachÃ© frÃ­a y ejecuta una carga de trabajo de solo lectura hasta que accede a las N pÃ¡ginas mientras realiza l transacciones. Suponemos que no hay fallos de capacidad, es decir, que la cachÃ© del cliente es lo suficientemente grande como para contener N pÃ¡ginas. En BC, los frÃ­os fallos para la pÃ¡gina P llegan al redireccionador. El primer fallo obtiene P del servidor, y los r - 1 fallos subsiguientes son redirigidos. Dado que cada cliente accede al conjunto compartido completo r = k. Sea Tcold(Base) y Tcold(BC) el tiempo que se tarda en completar las l transacciones en Base y BC. 33 Tcold(Base) = N âˆ— tfetch(Base) +(tcompute + tcommit(Base)) âˆ— l (1) Tcold(BC) = N âˆ— 1 k âˆ— tfetch(BC) + (1 âˆ’ 1 k ) âˆ— tredirect +(tcompute + tcommit(BC)) âˆ— l (2) Consideremos a continuaciÃ³n una ejecuciÃ³n con fallos de invalidaciÃ³n. Un cliente comienza con una cachÃ© caliente que contiene el conjunto de trabajo de N pÃ¡ginas. Nos enfocamos en un caso simple donde un cliente (escritor) ejecuta una carga de trabajo con modificaciones, y los otros clientes (lectores) ejecutan una carga de trabajo de solo lectura. En un grupo que contiene al escritor (BCW), la actualizaciÃ³n entre pares elimina todos los fallos de invalidaciÃ³n. En un grupo que contiene solo lectores (BCR), durante una ejecuciÃ³n en estado estable con actualizaciones uniformes, una transacciÃ³n del cliente tiene fallos de invalidaciÃ³n faltantes. Considera la secuencia de r fallos de cliente en la pÃ¡gina P que llegan al redireccionador en BCR entre dos invalidaciones consecutivas de la pÃ¡gina P. El primer fallo va al servidor, y los r - 1 fallos subsiguientes son redirigidos. A diferencia de los fallos en frÃ­o, r â‰¤ k porque la segunda invalidaciÃ³n deshabilita la redirecciÃ³n para P hasta que el prÃ³ximo fallo en P provoque una recuperaciÃ³n del servidor. Suponiendo un acceso uniforme, un fallo de invalidaciÃ³n del cliente tiene una probabilidad de 1/r de ser el primer fallo (resultando en una recuperaciÃ³n del servidor), y una probabilidad de (1 âˆ’ 1/r) de ser redirigido. Que Tinval(Base), Tinval(BCR) y Tinval(BCW) sean el tiempo que se tarda en completar una transacciÃ³n Ãºnica en los sistemas Base, BCR y BCW. En los experimentos descritos a continuaciÃ³n, medimos los parÃ¡metros N, r, missinv, tfetch(S), tredirect(S), tcommit(S) y tcompute(S). Calculamos los tiempos de finalizaciÃ³n derivados utilizando el modelo anterior y derivamos los beneficios. Luego validamos el modelo comparando los valores derivados con los tiempos de finalizaciÃ³n y beneficios medidos directamente en los experimentos. 6.2 ConfiguraciÃ³n Experimental Antes de presentar nuestros resultados, describimos nuestra configuraciÃ³n experimental. Utilizamos dos sistemas en nuestros experimentos. El sistema Base ejecuta el sistema de almacenamiento de objetos distribuidos Thor [23] con clientes conectÃ¡ndose directamente a los servidores. El sistema Buddy ejecuta nuestra implementaciÃ³n del prototipo de BuddyCache en Thor, admitiendo la recuperaciÃ³n de pares, la actualizaciÃ³n de pares y la confirmaciÃ³n en solitario, pero no el failover. Nuestras cargas de trabajo se basan en el benchmark multiusuario OO7 [8]; este benchmark estÃ¡ diseÃ±ado para capturar las caracterÃ­sticas de muchas aplicaciones CAD/CAM/CASE multiusuario diferentes, pero no modela ninguna aplicaciÃ³n especÃ­fica. Utilizamos OO7 porque es un punto de referencia estÃ¡ndar para medir el rendimiento del sistema de almacenamiento de objetos. La base de datos OO7 contiene un Ã¡rbol de objetos de ensamblaje con hojas que apuntan a tres partes compuestas elegidas al azar de entre 500 objetos similares. Cada parte compuesta contiene un grÃ¡fico de partes atÃ³micas vinculadas por objetos de conexiÃ³n; cada parte atÃ³mica tiene 3 conexiones salientes. Utilizamos una base de datos mediana que tiene 200 partes atÃ³micas por parte compuesta. La base de datos multiusuario asigna a cada cliente un mÃ³dulo privado que consiste en un Ã¡rbol de objetos de ensamblaje, y agrega un mÃ³dulo compartido adicional que escala proporcionalmente al nÃºmero de clientes. Esperamos que una configuraciÃ³n tÃ­pica de BuddyCache no estÃ© limitada por la cachÃ© y, por lo tanto, nos enfocamos en cargas de trabajo donde los objetos en el conjunto de trabajo del cliente encajen en la cachÃ©. Dado que el objetivo de nuestro estudio es evaluar quÃ© tan efectivamente nuestras tÃ©cnicas manejan el acceso a objetos compartidos, en nuestro estudio limitamos el acceso de los clientes solo a los datos compartidos. Esto nos permite estudiar el efecto que nuestras tÃ©cnicas tienen en los fallos de cachÃ© frÃ­o y de consistencia de cachÃ©, y aislar tanto como sea posible el efecto de los fallos de capacidad de cachÃ©. Para mantener la duraciÃ³n de nuestros experimentos razonable, utilizamos cachÃ©s pequeÃ±os. El benchmark OO7 genera mÃ³dulos de base de datos de tamaÃ±o predefinido. En nuestra implementaciÃ³n de OO7, el tamaÃ±o del mÃ³dulo privado es de aproximadamente 38MB. Para asegurarnos de que todo el conjunto de trabajo quepa en la cachÃ©, utilizamos un Ãºnico mÃ³dulo privado y elegimos un tamaÃ±o de cachÃ© de 40MB para cada cliente. La base de datos OO7 se genera con mÃ³dulos para 3 clientes, de los cuales solo uno se utiliza en nuestros experimentos, como explicamos anteriormente. Los objetos en la base de datos estÃ¡n agrupados en pÃ¡ginas de 8K, que tambiÃ©n son la unidad de transferencia en las solicitudes de recuperaciÃ³n. Consideramos dos tipos de cargas de trabajo de transacciones en nuestro anÃ¡lisis, solo lectura y lectura-escritura. En la prueba de referencia de OO7, las transacciones de solo lectura utilizan el recorrido T1 que realiza un recorrido en profundidad del grafo completo de partes compuestas. Las transacciones de escritura utilizan el recorrido T2b que es idÃ©ntico a T1 excepto que modifica todas las partes atÃ³micas en un solo compuesto. Una transacciÃ³n Ãºnica incluye un recorrido y no hay tiempo de espera entre transacciones. Tanto las transacciones de solo lectura como las de lectura y escritura siempre trabajan con datos del mismo mÃ³dulo. Los clientes que ejecutan transacciones de lectura-escritura no modifican en cada transacciÃ³n, en cambio, tienen un 50% de probabilidad de ejecutar transacciones de solo lectura. La base de datos fue almacenada por un servidor en un disco duro IBM de 40GB y 7200RPM, con un tiempo de bÃºsqueda promedio de 8.5 y tasas de transferencia de datos de 40 MB/seg. En el sistema Base, los clientes se conectan directamente a la base de datos. En el sistema Buddy, los clientes se conectan al redireccionador que se conecta a la base de datos. Realizamos los experimentos con 1-10 clientes en Base, y uno o dos grupos de 1-10 clientes en Buddy. El servidor, los clientes y los redireccionadores funcionaban en un PC basado en un procesador Intel Pentium III de 850MHz, con 512MB de memoria, y Linux Red Hat 6.2. Estaban conectados por un Ethernet de 100Mb/s. El servidor fue configurado con una cachÃ© de 50MB (de los cuales 6MB se utilizaron para el bÃºfer de objetos modificados), el cliente tenÃ­a una cachÃ© de 40MB. Los experimentos se llevaron a cabo en el banco de pruebas experimental de Utah emulab.net [1]. 34 Latencia [ms] Base Buddy 3 grupo 5 grupo 3 grupo 5 grupo Fetch 1.3 1.4 2.4 2.6 Commit 2.5 5.5 2.4 5.7 Tabla 1: Latencia de operaciones de Commit y Fetch de servidor PeerFetch 1.8 - 5.5 âˆ’AlertHelper 0.3 - 4.6 âˆ’CopyUnswizzle 0.24 âˆ’CrossRedirector 0.16 Tabla 2: Fetch de pares 6.3 Costos bÃ¡sicos Esta secciÃ³n analiza el costo bÃ¡sico de las solicitudes en el sistema Buddy durante las ejecuciones de OO7. 6.3.1 RedirecciÃ³n Las solicitudes de Fetch y Commit en el BuddyCache cruzan el redireccionador, un costo no incurrido en el sistema Base. Para una solicitud redirigida al servidor (obtenciÃ³n del servidor), el costo adicional de la redirecciÃ³n incluye una solicitud local del cliente al redireccionador en el camino de ida y vuelta al servidor. Evaluamos este sobrecosto de latencia de forma indirecta al comparar la latencia medida de la solicitud de recuperaciÃ³n o confirmaciÃ³n del servidor del sistema Buddy con la latencia medida de la solicitud correspondiente en el sistema Base. La Tabla 1 muestra la latencia para las solicitudes de confirmaciÃ³n y recuperaciÃ³n del servidor en el sistema Base y Buddy para grupos de 3 clientes y 5 clientes en una red local de Ã¡rea rÃ¡pida. Todos los nÃºmeros fueron calculados promediando la latencia de las solicitudes medidas durante 1000 peticiones. Las mediciones muestran que el costo de redirecciÃ³n al cruzar el redireccionador no es muy alto, incluso en una red de Ã¡rea local. El costo de la confirmaciÃ³n aumenta con el nÃºmero de clientes ya que las confirmaciones se procesan de forma secuencial. El costo de recuperaciÃ³n no aumenta tanto porque la cachÃ© del servidor reduce este costo. En un sistema grande con muchos grupos, sin embargo, la cachÃ© del servidor se vuelve menos eficiente. Para evaluar los costos adicionales de la recuperaciÃ³n entre pares, medimos la latencia de la recuperaciÃ³n entre pares (PeerFetch) en el cliente solicitante y desglosamos sus costos componentes. En la recuperaciÃ³n entre pares, el costo de la redirecciÃ³n incluye, ademÃ¡s del costo de la solicitud de la red local, la latencia de procesamiento de la CPU al atravesar el redireccionador y el ayudante, este Ãºltimo incluyendo el tiempo para procesar la solicitud de ayuda y el tiempo para copiar y desenrollar la pÃ¡gina solicitada. Medimos directamente el tiempo para copiar y desenrollar la pÃ¡gina solicitada en el ayudante (CopyUnswizzle), y cronometramos los tiempos de cruce utilizando una solicitud de cruce nula. La Tabla 2 resume las latencias que nos permiten desglosar los costos de recuperaciÃ³n de pares. CrossRedirector incluye la latencia de la CPU al cruzar el redireccionador mÃ¡s un viaje de ida y vuelta a travÃ©s de la red local y se mide cronometrando una solicitud nula de ida y vuelta emitida por un cliente al redireccionador. AlertHelper incluye el tiempo que el ayudante tarda en notar la solicitud mÃ¡s un viaje de ida y vuelta a travÃ©s de la red, y se mide cronometrando una solicitud nula de ida y vuelta emitida desde un cliente auxiliar al cliente ayudante. La latencia de la red local es fija y menor a 0.1 ms. La latencia de AlertHelper, que incluye el tiempo transcurrido desde la llegada de la solicitud de ayuda hasta el inicio del procesamiento de la solicitud de ayuda, es altamente variable y, por lo tanto, contribuye a la alta variabilidad del tiempo de PeerFetch. Esto se debe a que el cliente en el sistema Buddy actualmente es de un solo hilo y, por lo tanto, solo comienza a procesar una solicitud de ayuda cuando estÃ¡ bloqueado esperando una respuesta de bÃºsqueda o confirmaciÃ³n. Este sobrecosto no es inherente a la arquitectura de BuddyCache y podrÃ­a ser mitigado por una implementaciÃ³n multi-hilo en un sistema con programaciÃ³n preemptiva. 6.3.2 VersiÃ³n de CachÃ© El commit en solitario permite que un cliente rÃ¡pido que modifica un objeto haga un commit de forma independiente a un compaÃ±ero lento. El mecanismo de confirmaciÃ³n Ãºnica introduce un procesamiento adicional en el servidor durante la validaciÃ³n de la transacciÃ³n, y un procesamiento adicional en el cliente durante la confirmaciÃ³n de la transacciÃ³n y en el momento del procesamiento de actualizaciÃ³n o invalidaciÃ³n. Los gastos generales del lado del servidor son mÃ­nimos y consisten en una actualizaciÃ³n del nÃºmero de versiÃ³n de la pÃ¡gina en el momento de la confirmaciÃ³n, y una comparaciÃ³n del nÃºmero de versiÃ³n en el momento de la validaciÃ³n de la transacciÃ³n. La cachÃ© de versiÃ³n tiene una entrada solo cuando las invalidaciones o actualizaciones llegan fuera de orden. Esto puede ocurrir cuando una transacciÃ³n accede a objetos en mÃºltiples servidores. Nuestros experimentos se ejecutan en un sistema de servidor Ãºnico y, por lo tanto, el tiempo de confirmaciÃ³n adicional de la gestiÃ³n de la cachÃ© de versiones en el cliente no contribuye a los resultados presentados en la secciÃ³n a continuaciÃ³n. Para medir estos costos adicionales del lado del cliente en un sistema de mÃºltiples servidores, instrumentamos la implementaciÃ³n de la cachÃ© de versiones para ejecutarse con una traza de carga de trabajo que incluÃ­a invalidaciones reordenadas y cronometramos las operaciones bÃ¡sicas. El procesamiento adicional del tiempo de compromiso del cliente incluye una operaciÃ³n de bÃºsqueda de cachÃ© de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n en el momento de preparaciÃ³n de la solicitud de compromiso, y una operaciÃ³n de inserciÃ³n de cachÃ© de versiÃ³n para cada objeto actualizado por una transacciÃ³n en el momento de procesamiento de la respuesta de compromiso, pero solo si la pÃ¡gina actualizada carece de algunas invalidaciones o actualizaciones anteriores. Es importante que los costos adicionales de tiempo de confirmaciÃ³n se mantengan al mÃ­nimo, ya que el cliente estÃ¡ esperando de forma sÃ­ncrona la finalizaciÃ³n de la confirmaciÃ³n. Las mediciones muestran que en el peor de los casos, cuando llega un gran nÃºmero de invalidaciones fuera de orden, y aproximadamente la mitad de los objetos modificados por T2a (200 objetos) residen en pÃ¡ginas reordenadas, el costo de actualizar la cachÃ© de versiÃ³n es de 0.6 ms. El costo de tiempo de invalidaciÃ³n es comparable, pero dado que las invalidaciones y actualizaciones se procesan en segundo plano, este costo es menos importante para el rendimiento general. Actualmente estamos trabajando en optimizar la implementaciÃ³n de la cachÃ© de versiones para reducir aÃºn mÃ¡s estos costos. 6.4 Rendimiento general Esta secciÃ³n examina las mejoras de rendimiento observadas por una aplicaciÃ³n que ejecuta el benchmark OO7 con un BuddyCache en una red de Ã¡rea amplia. 6.4.1 Fallos en frÃ­o Para evaluar las mejoras de rendimiento al evitar fallos en frÃ­o, comparamos el rendimiento de la cachÃ© en frÃ­o del benchmark OO7 ejecutando una carga de trabajo de solo lectura en los sistemas Buddy y Base. Derivamos los tiempos cronometrando la ejecuciÃ³n de los sistemas en el entorno de la red de Ã¡rea local y sustituyendo retrasos de 40 ms y 80 ms para las solicitudes que cruzan el redireccionador y el servidor para estimar el rendimiento en la red de Ã¡rea amplia. Las figuras 7 y 8 muestran el tiempo total para completar 1000 transacciones en cachÃ© frÃ­a. Los nÃºmeros fueron 35 0 5 0 100 150 200 250 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 7: Desglose para lectura en frÃ­o solo lectura 40ms RTT 0 5 0 100 150 200 250 300 350 400 Base Buddy Base Buddy Base Buddy 3 Clientes 5 Clientes 10 Clientes [ms] CPU Commit Servidor Fetch Peer Fetch Figura 8: Desglose para lectura en frÃ­o solo lectura 80ms RTT obtenido promediando el tiempo total de cada cliente en el grupo. Los resultados muestran que en una red de 40 ms, el sistema Buddy reduce significativamente el tiempo total en comparaciÃ³n con el sistema Base, proporcionando una mejora del 39% en un grupo de tres clientes, del 46% en un grupo de cinco clientes y del 56% en el caso de diez clientes. El tiempo total incluye el tiempo dedicado a realizar cÃ¡lculos para el cliente, solicitudes de recuperaciÃ³n directa, recuperaciones de pares y solicitudes de confirmaciÃ³n. En el grupo de tres clientes, Buddy y Base incurren en casi el mismo costo de compromiso, por lo tanto, todo el beneficio de rendimiento de Buddy se debe a la recuperaciÃ³n entre pares evitando recuperaciones directas. En el grupo de clientes de cinco y diez, el costo de recuperaciÃ³n del servidor para cada cliente individual disminuye porque, con mÃ¡s clientes accediendo a un mÃ³dulo compartido de tamaÃ±o fijo en BuddyCache, cada cliente necesita realizar menos recuperaciones del servidor. La Figura 8 muestra el desglose general del tiempo y costos en la red de 80 ms. El BuddyCache proporciona mejoras de rendimiento similares a las obtenidas con una red de 40ms. El aumento de la latencia de red incrementa la ventaja de rendimiento relativa proporcionada por la recuperaciÃ³n de pares en comparaciÃ³n con la recuperaciÃ³n directa, pero este beneficio se ve contrarrestado por los tiempos de confirmaciÃ³n aumentados. La Figura 9 muestra la mejora relativa de latencia proporcionada por BuddyCache (calculada como la diferencia de tiempo medida general entre Buddy y Base en relaciÃ³n con Base) como un -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] 3 Clientes 3 Clientes (Modelo de rendimiento) 5 Clientes 5 Clientes (Modelo de rendimiento) 10 Clientes 10 FEs (Modelo de rendimiento) Figura 9: Beneficio de falta de cachÃ© 0 2 0 4 0 6 0 8 0 100 120 140 Base Buddy Lector Buddy Escritor [ms] CPU Commit Servidor Fetch Peer Fetch Figura 10: Desglose para lectura-escritura en caliente 40ms RTT funciÃ³n de latencia de red, con una carga fija de servidor. El costo del mecanismo adicional domina el beneficio de BuddyCache cuando la latencia de red es baja. En latencias tÃ­picas de Internet de 20 ms a 60 ms, el beneficio aumenta con la latencia y se estabiliza alrededor de los 60 ms con una mejora significativa (de hasta un 62% para diez clientes). La Figura 9 incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Sorprendentemente, los resultados analÃ­ticos predicen la mejora medida muy de cerca, aunque son ligeramente mÃ¡s altos que los valores empÃ­ricos. La razÃ³n principal por la que el modelo simplificado funciona bien es que captura el componente de rendimiento dominante, el costo de latencia de red. Para evaluar los beneficios de rendimiento proporcionados por BuddyCache debido a los fallos de invalidaciÃ³n evitados, comparamos el rendimiento de cachÃ© caliente del sistema Base con dos configuraciones diferentes del sistema Buddy. Una de las configuraciones del sistema Buddy representa un grupo de pares colaboradores que modifican objetos compartidos (grupo de escritores), mientras que la otra representa un grupo donde los pares comparten un interÃ©s de solo lectura en los objetos modificados (grupo de lectores) y el escritor reside fuera del grupo BuddyCache. En cada uno de los tres sistemas, un Ãºnico cliente ejecuta una carga de trabajo de lectura y escritura (escritor) y otros tres clientes ejecutan una carga de trabajo de solo lectura (lectores). El sistema de compaÃ±eros con un grupo que contiene un lector base, un lector y un escritor, y otro grupo que contiene dos lectores y un escritor modela el grupo de escritores. El sistema de compaÃ±eros con un grupo que contiene un Ãºnico escritor y otro grupo con tres lectores modela al grupo de Lectores. En Base, un escritor y tres lectores acceden directamente al servidor. Esta configuraciÃ³n simple es suficiente para mostrar el impacto de las tÃ©cnicas de BuddyCache. Las figuras 10 y 11 muestran el tiempo total para completar 1000 transacciones de solo lectura de cachÃ© caliente de OO7. Obtenemos los nÃºmeros ejecutando 2000 transacciones para filtrar los fallos en frÃ­o y luego medimos el tiempo de las siguientes 1000 transacciones. AquÃ­ nuevamente, los nÃºmeros reportados se derivan de los resultados del experimento de la red de Ã¡rea local. Los resultados muestran que el BuddyCache reduce significativamente el tiempo de finalizaciÃ³n en comparaciÃ³n con el sistema Base. En una red de 40 ms, el tiempo total en el grupo de Escritores mejora un 62% en comparaciÃ³n con la Base. Este beneficio se debe a la actualizaciÃ³n entre pares que evita todas las omisiones debido a actualizaciones. El tiempo total en el grupo de Lectores mejora en un 30% y se debe a la recuperaciÃ³n entre pares que permite a un cliente acceder a un objeto invalidado a cambio de una recuperaciÃ³n local evitando el retraso de la recuperaciÃ³n desde el servidor. El Ãºltimo es un beneficio importante porque demuestra que en cargas de trabajo con actualizaciones, la recuperaciÃ³n de pares permite que un protocolo basado en invalidaciones proporcione algunos de los beneficios de un protocolo basado en actualizaciones. Ten en cuenta que el beneficio de rendimiento proporcionado por la recuperaciÃ³n de pares en el grupo de Lectores es aproximadamente un 50% menor que el beneficio de rendimiento proporcionado por la actualizaciÃ³n de pares en el grupo de Escritores. Esta diferencia es similar en una red de 80ms. La Figura 12 muestra la mejora relativa de latencia proporcionada por BuddyCache en las configuraciones de Buddy Reader y Buddy Writer (calculada como la diferencia de tiempo total entre BuddyReader y Base en relaciÃ³n con Base, y Buddy Writer y Base en relaciÃ³n con Base) en un experimento de cachÃ© activa en funciÃ³n del aumento de la latencia de red, para una carga de servidor fija. El beneficio de actualizaciÃ³n entre pares domina el gasto general en la configuraciÃ³n de Writer incluso en redes de baja latencia (la actualizaciÃ³n entre pares incurre en un gasto mÃ­nimo) y ofrece una mejora significativa del 44 al 64% para todo el rango de latencia. La figura incluye tanto la mejora medida como la mejora derivada utilizando el modelo analÃ­tico. Como en experimentos de cachÃ© frÃ­a, aquÃ­ los resultados analÃ­ticos predicen de cerca la mejora medida. La diferencia es -10% 0% 10% 20% 30% 40% 50% 60% 70% 1 5 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 100 Latencia [ms] Beneficios[%] Buddy Reader Buddy Reader (modelo de rendimiento) Buddy Writer Buddy Writer (modelo de rendimiento) Figura 12: El beneficio de pÃ©rdida de invalidaciÃ³n es mÃ­nimo en el grupo de escritores y algo mayor en el grupo de lectores (coherente con los resultados en los experimentos de cachÃ© frÃ­a). Como en el caso de cachÃ© frÃ­a, la razÃ³n por la que el modelo analÃ­tico simplificado funciona bien es porque captura los costos de la latencia de red, el costo de rendimiento dominante. 7. CONCLUSIÃ“N Las aplicaciones colaborativas proporcionan un entorno de trabajo compartido para grupos de clientes en red que colaboran en una tarea comÃºn. Requieren una consistencia sÃ³lida para datos persistentes compartidos y un acceso eficiente a objetos de grano fino. Estas propiedades son difÃ­ciles de proporcionar en una red de Ã¡rea extensa debido a la alta latencia de red. Este artÃ­culo describe BuddyCache, una nueva tÃ©cnica de almacenamiento en cachÃ© cooperativo transaccional [20, 16, 13, 2, 28] que mejora la latencia de acceso a objetos persistentes compartidos para aplicaciones colaborativas de alta consistencia en entornos de red de alta latencia. La tÃ©cnica mejora el rendimiento y proporciona propiedades sÃ³lidas de correcciÃ³n y disponibilidad en presencia de fallos de nodos y clientes lentos. BuddyCache utiliza la redirecciÃ³n para obtener objetos faltantes directamente de las cachÃ©s de los miembros del grupo, y para admitir la actualizaciÃ³n entre pares, una nueva tÃ©cnica de multidifusiÃ³n a nivel de aplicaciÃ³n ligera que brinda a los miembros del grupo acceso consistente a los nuevos datos comprometidos dentro del grupo colaborador sin imponer una sobrecarga adicional fuera del grupo. Sin embargo, la redirecciÃ³n puede interferir con la disponibilidad del objeto. Solo commit es una nueva tÃ©cnica de validaciÃ³n que permite a un cliente en un grupo comprometerse de forma independiente de los pares lentos o fallidos. Proporciona una validaciÃ³n detallada utilizando informaciÃ³n de versiÃ³n de grano grueso econÃ³mica. Hemos diseÃ±ado e implementado el prototipo de BuddyCache en el sistema de almacenamiento de objetos transaccionales distribuidos Thor [23] y hemos evaluado los beneficios y costos del sistema en una variedad de latencias de red. Los resultados analÃ­ticos, respaldados por las mediciones del sistema utilizando el benchmark multiusuario 007, indican que para las latencias tÃ­picas de Internet, BuddyCache proporciona beneficios significativos en el rendimiento, por ejemplo, para latencias que van desde 40 a 80 milisegundos de tiempo de ida y vuelta, los clientes que utilizan BuddyCache pueden reducir hasta un 50% la latencia de acceso a objetos compartidos en comparaciÃ³n con los clientes que acceden directamente al repositorio. Las principales contribuciones del artÃ­culo son: 1. extender las tÃ©cnicas de almacenamiento en cachÃ© cooperativo para admitir 37 accesos de consistencia fuerte de grano fino en entornos de alta latencia, 2. una implementaciÃ³n del prototipo del sistema que proporciona fuertes mejoras de rendimiento sobre el sistema base, 3. evaluaciÃ³n del rendimiento basada en anÃ¡lisis y mediciones de los costos y beneficios de las nuevas tÃ©cnicas que capturan el costo de rendimiento dominante, la alta latencia de red. AGRADECIMIENTOS Agradecemos a Jay Lepreau y al personal de Utah experimental testbed emulab.net [1], especialmente a Leigh Stoller, por hospedar los experimentos y la ayuda con el banco de pruebas. TambiÃ©n agradecemos a Jeff Chase, Maurice Herlihy, Butler Lampson y a los revisores de OOPSLA por los comentarios Ãºtiles que mejoraron este artÃ­culo. 9. REFERENCIAS [1] emulab.net, la InstalaciÃ³n de EmulaciÃ³n de Red de Utah. http://www.emulab.net. [2] A. Adya, M. Castro, B. Liskov, U. Maheshwari y L. Shrira. ReconstrucciÃ³n de fragmentos: Proporcionando coherencia de cachÃ© global en un sistema de almacenamiento transaccional. Actas de la Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, mayo de 1997. [3] A. Adya, R. Gruber, B. Liskov y U. Maheshwari. Control de concurrencia optimista eficiente utilizando relojes ligeramente sincronizados. En Actas de la Conferencia Internacional de ACM SIGMOD sobre GestiÃ³n de Datos, mayo de 1995. [4] C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu y W. Zwaenepoel. Huellas de pisadas: ComputaciÃ³n en memoria compartida en redes de estaciones de trabajo. IEEE Computer, 29(2), febrero de 1996. [5] C. Anderson y A. Karlin. Dos protocolos de coherencia de cachÃ© hÃ­bridos adaptativos. En Actas del 2do Simposio IEEE sobre Arquitectura de Computadoras de Alto Rendimiento (HPCA 96), febrero de 1996. [6] M. Baker. RecuperaciÃ³n rÃ¡pida de fallos en sistemas de archivos distribuidos. Tesis doctoral, Universidad de California en Berkeley, 1994. [7] P. Cao y C. Liu. Manteniendo una fuerte consistencia de cachÃ© en la World Wide Web. En la 17Âª Conferencia Internacional sobre Sistemas de ComputaciÃ³n Distribuida, abril de 1998. [8] M. Carey, D. J. Dewitt, C. Kant y J. F. Naughton. Un informe de estado sobre el esfuerzo de evaluaciÃ³n del rendimiento del sistema de gestiÃ³n de bases de datos orientado a objetos OO7. En Actas de OOPSLA, octubre de 1994. [9] A. Chankhunthod, M. Schwartz, P. Danzig, K. Worrell y C. Neerdaels. Una cachÃ© de objetos jerÃ¡rquica en Internet. En la Conferencia TÃ©cnica Anual de USENIX, en enero de 1995. [10] J. Chase, S. Gadde y M. Rabinovich. Estructuras de directorios para cachÃ©s de Internet escalables. Informe TÃ©cnico CS-1997-18, Departamento de Ciencias de la ComputaciÃ³n, Universidad de Duke, noviembre de 1997. [11] J. Chase, S. Gadde y M. Rabinovich. No todos los aciertos son iguales: CachÃ© de proxy cooperativa en una red de Ã¡rea amplia. En el Tercer Taller Internacional de CachÃ© de la WWW, junio de 1998. [12] D. R. Cheriton y D. Li. CachÃ© web escalable de objetos actualizados con frecuencia utilizando multicast fiable. 2Âº Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [13] M. D. Dahlin, R. Y. Wang, T. E. Anderson y D. A. Patterson. CachÃ© cooperativa: Utilizando la memoria del cliente remoto para mejorar el rendimiento del sistema de archivos. Actas de la Conferencia USENIX sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [14] S. Dwarkadas, H. Lu, A.L. Cox, R. Rajamony y W. Zwaenepoel. Combinando el soporte en tiempo de compilaciÃ³n y en tiempo de ejecuciÃ³n para una memoria compartida distribuida eficiente. En Actas de IEEE, EdiciÃ³n Especial sobre Memoria Compartida Distribuida, marzo de 1999. [15] Li Fan, Pei Cao, Jussara Almeida y Andrei Broder. Resumen de la cachÃ©: un protocolo de intercambio de cachÃ© web escalable de Ã¡rea amplia. En Actas de ACM SIGCOMM, septiembre de 1998. [16] M. Feeley, W. Morgan, F. Pighin, A. Karlin y H. Levy. ImplementaciÃ³n de GestiÃ³n Global de Memoria en un ClÃºster de Estaciones de Trabajo. Actas del 15Âº Simposio de Principios de Sistemas Operativos de la ACM, diciembre de 1995. [17] M. J. Feeley, J. S. Chase, V. R. Narasayya y H. M. Levy. Integrando coherencia y recuperabilidad en sistemas distribuidos. En Actas del Primer Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, mayo de 1994. [18] P. Ferreira y M. Shapiro et al. PerDiS: DiseÃ±o, ImplementaciÃ³n y Uso de una Tienda Distribuida Persistente. En Avances Recientes en Sistemas Distribuidos, LNCS 1752, Springer-Verlag, 1999. [19] M. J. Franklin, M. Carey y M. Livny. Coherencia de cachÃ© transaccional cliente-servidor: alternativas y rendimiento. En ACM Transactions on Database Systems, volumen 22, pÃ¡ginas 315-363, septiembre de 1997. [20] Michael Franklin, Michael Carey y Miron Livny. GestiÃ³n global de memoria para arquitecturas de sistemas de gestiÃ³n de bases de datos cliente-servidor. En Actas del 19Âº Congreso Internacional. Conferencia sobre Bases de Datos Muy Grandes (VLDB), agosto de 1992. [21] S. Ghemawat. El BÃºfer de Objeto Modificado: Una TÃ©cnica de GestiÃ³n de Almacenamiento para Bases de Datos Orientadas a Objetos. Tesis doctoral, Instituto TecnolÃ³gico de Massachusetts, 1997. [22] L. Kawell, S. Beckhardt, T. Halvorsen, R. Ozzie e I. Greif. GestiÃ³n de documentos replicados en un sistema de comunicaciÃ³n grupal. En Actas de la Conferencia ACM CSCW, septiembre de 1988. [23] B. Liskov, M. Castro, L. Shrira y A. Adya. Proporcionando objetos persistentes en sistemas distribuidos. En Actas de la 13Âª Conferencia Europea sobre ProgramaciÃ³n Orientada a Objetos (ECOOP 99), junio de 1999. [24] A. Muthitacharoen, B. Chen y D. Mazieres. Un sistema de archivos de red de baja capacidad de banda. En el 18Âº Simposio ACM sobre Principios de Sistemas Operativos, octubre de 2001. [25] B. Oki y B. Liskov. ReplicaciÃ³n con marca de vista: un nuevo mÃ©todo de copia primaria para soportar sistemas distribuidos altamente disponibles. En Proc. del Simposio de la ACM sobre Principios de ComputaciÃ³n Distribuida, agosto de 1988. [26] J. OToole y L. Shrira. Registro oportunista: Lecturas de instalaciÃ³n eficientes en un servidor de objetos confiable. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, noviembre de 1994. [27] D. Pendarakis, S. Shi y D. Verma. ALMI: Una Infraestructura de MultidifusiÃ³n a Nivel de AplicaciÃ³n. En el 3er Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, marzo de 2001. [28] P. Sarkar y J. Hartman. Uso eficiente de cachÃ© cooperativa utilizando pistas. En el Simposio Usenix sobre DiseÃ±o e ImplementaciÃ³n de Sistemas Operativos, octubre de 1996. [29] A. M. Vahdat, P. C. Eastham y T. E Anderson. WebFS: Un Sistema de Archivos Coherente en CachÃ© Global. Informe tÃ©cnico, Universidad de California, Berkeley, 1996. [30] A. Wolman, G. Voelker, N. Sharma, N. Cardwell, A. Karlin y H. Levy. Sobre la Escala y el Rendimiento del CachÃ© de Proxies Web Cooperativos. En el 17Âº Simposio ACM sobre Principios de Sistemas Operativos, diciembre de 1999. [31] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Consistencia jerÃ¡rquica de cachÃ© en una WAN. En el Simposio USENIX sobre TecnologÃ­as y Sistemas de Internet, octubre de 1999. [32] J. Yin, L. Alvisi, M. Dahlin y C. Lin. Arrendamientos de volumen para consistencia en sistemas a gran escala. IEEE Transactions on Knowledge and Data Engineering, 11(4), julio/agosto de 1999. [33] M. Zaharioudakis, M. J. Carey y M. J. Franklin. ComparticiÃ³n adaptable y detallada en un OODBMS cliente-servidor: Un enfoque basado en callbacks. ACM Transactions on Database Systems, 22:570-627, diciembre de 1997. 10. APÃ‰NDICE Este apÃ©ndice describe el protocolo de conmutaciÃ³n por error de BuddyCache. Para dar cabida a clientes heterogÃ©neos, incluidos los dispositivos portÃ¡tiles con recursos limitados, no requerimos la disponibilidad de almacenamiento persistente en el grupo de pares BuddyCache. El diseÃ±o de BuddyCache asume que las cachÃ©s del cliente y las estructuras de datos del redireccionador no sobreviven a fallos de nodos. Un protocolo de membresÃ­a detecta el fallo de un cliente o un redireccionador intercambiando mensajes periÃ³dicos de \"Estoy vivo\" entre los miembros del grupo e inicia un protocolo de conmutaciÃ³n por error. El failover determina los participantes del grupo activo, reelige un redireccionador si es necesario, reinicializa las estructuras de datos de BuddyCache en la nueva configuraciÃ³n y reinicia el protocolo. El protocolo de reconfiguraciÃ³n del grupo es similar al presentado en [25]. AquÃ­ describimos cÃ³mo el failover gestiona el estado de BuddyCache. Para reiniciar el protocolo BuddyCache, el failover necesita resincronizar el directorio de pÃ¡ginas redireccionadas y el reenvÃ­o de solicitudes entre el cliente y el servidor para que los clientes activos puedan seguir ejecutando transacciones utilizando sus cachÃ©s. En caso de un fallo del cliente, el failover elimina las pÃ¡ginas del cliente que se han bloqueado del directorio. Cualquier respuesta a una solicitud anterior iniciada por el cliente fallido es ignorada, excepto una respuesta de confirmaciÃ³n, en cuyo caso el redireccionador distribuye las actualizaciones comprometidas retenidas a los clientes activos que almacenan en cachÃ© las pÃ¡ginas modificadas. En caso de un fallo del redireccionador, el protocolo de conmutaciÃ³n por error reinicializa las sesiones con los servidores y clientes, y reconstruye el directorio de pÃ¡ginas utilizando un protocolo similar al descrito en [6]. El redireccionador reciÃ©n reiniciado solicita a los miembros activos del grupo la lista de pÃ¡ginas que estÃ¡n almacenando en cachÃ© y el estado de estas pÃ¡ginas, es decir, si las pÃ¡ginas estÃ¡n completas o incompletas. Las solicitudes pendientes en el redireccionador en el momento del fallo pueden perderse. Una solicitud de recuperaciÃ³n perdida expirarÃ¡ en el cliente y serÃ¡ retransmitida. Una transacciÃ³n que se ejecuta en el cliente durante un cambio a un sistema de respaldo y se confirma despuÃ©s del cambio se trata como una transacciÃ³n regular; una transacciÃ³n que intenta confirmarse durante un cambio a un sistema de respaldo es abortada por el protocolo de cambio a un sistema de respaldo. Un cliente reiniciarÃ¡ la transacciÃ³n y la solicitud de confirmaciÃ³n serÃ¡ retransmitida despuÃ©s del cambio de servidor. Las invalidaciones, actualizaciones o acuses de recibo de actualizaciones perdidos en el redireccionador caÃ­do podrÃ­an evitar la recolecciÃ³n de basura de las invalidaciones pendientes en los servidores o la cachÃ© virtual en los clientes. Por lo tanto, los servidores que detectan un fallo del redireccionador retransmiten invalidaciones no reconocidas y confirman respuestas. Los nÃºmeros de versiÃ³n Ãºnicos en las invalidaciones y actualizaciones garantizan que las solicitudes retransmitidas duplicadas sean detectadas y descartadas. Dado que el procedimiento de validaciÃ³n de transacciones depende del protocolo de coherencia de cachÃ© para garantizar que las transacciones no lean datos obsoletos, ahora necesitamos argumentar que el protocolo de conmutaciÃ³n por error de BuddyCache no compromete la correcciÃ³n del procedimiento de validaciÃ³n. Recuerda que la validaciÃ³n de transacciones de BuddyCache utiliza dos mecanismos complementarios, nÃºmeros de versiÃ³n de pÃ¡gina y confirmaciones de invalidaciÃ³n de los clientes, para verificar que una transacciÃ³n ha leÃ­do datos actualizados. La propagaciÃ³n de la confirmaciÃ³n de invalidaciÃ³n (y actualizaciÃ³n) basada en el redireccionador garantiza la siguiente invariante. Cuando un servidor recibe una confirmaciÃ³n de una modificaciÃ³n (invalidaciÃ³n o actualizaciÃ³n) de un objeto por parte de un grupo de clientes, cualquier cliente en el grupo que tenga en cachÃ© el objeto o bien ha instalado el valor mÃ¡s reciente del objeto o lo ha invalidado. Por lo tanto, si un servidor recibe una solicitud de confirmaciÃ³n de un cliente para una transacciÃ³n T que lee un objeto o despuÃ©s de un cambio de servidor en el grupo de clientes, y el servidor no tiene ninguna invalidaciÃ³n no confirmada para o pendiente para este grupo, la versiÃ³n del objeto leÃ­da por la transacciÃ³n T estÃ¡ actualizada independientemente de fallos en el cliente o en el redireccionador. Ahora considera la validaciÃ³n utilizando nÃºmeros de versiÃ³n. El registro de confirmaciÃ³n de transacciÃ³n contiene un nÃºmero de versiÃ³n para cada objeto leÃ­do por la transacciÃ³n. El protocolo de nÃºmero de versiÃ³n mantiene la invariante V P que garantiza que el valor del objeto o leÃ­do por la transacciÃ³n corresponda al nÃºmero de versiÃ³n mÃ¡s alto para o recibido por el cliente. La invariante se mantiene ya que el cliente nunca aplica una modificaciÃ³n anterior despuÃ©s de haber recibido una modificaciÃ³n posterior. La retransmisiÃ³n de invalidaciones y actualizaciones mantiene esta invariante. El procedimiento de validaciÃ³n verifica que el nÃºmero de versiÃ³n en el registro de confirmaciÃ³n coincida con el nÃºmero de versiÃ³n en la invalidaciÃ³n pendiente no reconocida. Es fÃ¡cil ver que, dado que esta comprobaciÃ³n es una comprobaciÃ³n cliente-servidor de extremo a extremo, no se ve afectada por fallos del cliente o del redireccionador. El protocolo de conmutaciÃ³n por error aÃºn no ha sido implementado. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}