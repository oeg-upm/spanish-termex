{
    "id": "J-45",
    "original_text": "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings. We illustrate our approach with a design task from a supply-chain trading competition. Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient. Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect. More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent. Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1. MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game. TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain. The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year. As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation. During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0. Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory. Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13]. After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement. The task facing game organizers can be viewed as a problem in mechanism design. The designers have certain game features under their control, and a set of objectives regarding game outcomes. Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game. Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option. We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems. In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders. These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods. Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition. In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament. Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9]. The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking. Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations. Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose. The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options. Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment. Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design. In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem. Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted. Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise. We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used. Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem. Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available. Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions. We believe that most realistic problems are too complex to be amenable to exact analysis. Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2. PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players. Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players. We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am. It is often convenient to refer to a strategy of player i separately from that of the remaining players. To accommodate this, we use a−i to denote the joint strategy of all players other than player i. Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A. An s ∈ S is called a mixed strategy profile. When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i). When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i. We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously. This is appropriate for our current study, which treats strategies (agent programs) as atomic actions. We could capture finer-grained decisions about action over time in the extensive form. Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection). Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context. We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}. We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies. Faced with a game, an agent would ideally play its best strategy given those played by the other agents. A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium. DEFINITION 1. A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium. We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy. Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ . In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical. DEFINITION 2. A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3. THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game. The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ. All the participant agents observe the mechanism parameter θ and move simultaneously thereafter. For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules. Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}]. We refer to Γθ as a game induced by θ. Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR. Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria. However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available. For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary. DEFINITION 3. A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V . We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}. For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)). Using an aggregation function yields a more compact representation of strategy profiles. For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter. If all we care about is the total value played, we may take φ(a) = Pm i=1 ai. If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise. For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure. Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem. Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12]. However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets. Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs. We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}. Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.) In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4. EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations. Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence. Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above. Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail. Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium. In doing so, we consider several questions raised during and after the tournament. First, does increasing storage costs actually reduce day-0 procurement? Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational? And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been? It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data. We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament. We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium). All other behavior is based on the behavior of Deep Maize and is identical for all agents. This choice can provide only an estimate of the actual tournament behavior of a typical agent. However, we believe that the general form of the results should be robust to changes in the full agent behavior. We model the designers welfare function as a threshold on the sum of day-0 purchases. Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture). The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function. The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ . Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance. Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)). If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ. Thus, we need methods for approximating Nash equilibria for infinite games. Below, we describe the two methods we used in our study. The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives. Our approach takes as given some set of design options, in this case defined by the storage cost parameter. In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17]. Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model. In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time. One advantage of this method is that it can be applied to any data set and does not require the use of a simulator. Thus, we can apply it when Ds = ∅. If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR). We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19]. The quadratic regression model makes it possible to compute equilibria of the learned game analytically. For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game. The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation. DEFINITION 4. A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy. We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ). DEFINITION 5. The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}. We say that a is a candidate δ-equilibrium for δ ≥ ˆ. When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium. Our search method operates by exploring deviations from candidate equilibria. We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria. DEFINITION 6. For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ. We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ). In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ. This definition allows us to exploit structure arising from the aggregation function. If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds. In particular, if one is an equilibrium, the other may be as well. We present some theoretical support for this method of estimating the set of Nash equilibria below. Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation. In this work, we instead concentrate on search in strategy profile space. egy profiles. We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost. Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}. Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ. Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months. For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do. Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6. The results are shown in Figure 1. As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game. In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do. The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch. The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2. First, we note that the addition of the search data narrows the range of potential equilibria substantially. Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close. Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do. The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax. This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs. It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100. The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3. This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game. The maximum prediction is considerably higher at 4.5. In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9]. Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing. However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible. To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set. Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α. Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320. The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch. Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320. Strategy profiles explored are presented in terms of the corresponding values of φ(a). The gray region corresponds to ˆφ∗ (320) with δ =2.5M. The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200. Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2. Furthermore, payoffs to agents are almost always negative at θ = 320. Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed. Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result. We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter. That our predictions tend to underestimate tournament outcomes reinforces this conclusion. To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04. All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence. These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game. In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects. Suppose that all agents have finite (and small) pure strategy sets, A. Thus, it is feasible to sample the entire payoff matrix of the game. Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable. We designate the known variance of ˜ξi(a) by σ2 i (a). Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)). We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a. We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1). We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium. If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1. Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)). The proofs of this and all subsequent results are in the Appendix. The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function. Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ. Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}. The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria. Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled. We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium! Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game. If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium. The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled. Particularly, we would like to say something about what happens for the settings of θ for which we have no data. To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320]. We now define each subset j to be the interval between two points for which we have produced data. Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above. We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α. PROPOSITION 2. Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment. Instead, we take this as another piece of evidence to complement our findings. Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ. Thus, we are faced with a task of estimating it from data. Here, we tried three methods of doing this. The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval. This produces the most conservative bound, and in many situations it is unlikely to be informative. An alternative method is to take an upper bound on slope obtained within each subinterval using the available data. This produces a much less conservative upper bound on probabilities. However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving. A final method that we tried is a compromise between the two above. Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj. The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals. The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3. In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2. Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2. As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here. However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job. Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence. Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets). Nor can we expect ever to obtain enough evidence to make completely objective conclusions. Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5. CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower. As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs. We also assume that un,i(a) are independent for all a ∈ A and i ∈ I. We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}]. Similarly, we define n(r) to be (r) with respect to the game Γn. In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game. We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum. THEOREM 3. Suppose that |I| < ∞, |A| < ∞. Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ. If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4. For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s. PROOF. Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1. By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken. As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria. First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α. Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function. Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain. Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective. Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game. This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings. We first note that the function (s) is continuous in a finite game. LEMMA 5. Let S be a mixed strategy set defined on a finite game. Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation. First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y). Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ). Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ. Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ. Note that h(Nδ, N) = δ. We can then prove the following general result. THEOREM 6. Suppose |I| < ∞ and |A| < ∞. Then almost surely h(Nn, N) converges to 0. We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely. Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ). THEOREM 7. Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite. Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ. Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria. In fact, ˆθ → θ∗ a.s. in each of these cases. The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria. However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6. RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10]. Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant. In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality. Several related approaches to search for the best mechanism exist in the Computer Science literature. Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge. When payoff functions of players are unknown, a search using simulations has been explored as an alternative. One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria. An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming. In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning. Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7. CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design. We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game. We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available. Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired. A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods. In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact. Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence. In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer. In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability. The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains. The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings. Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work. This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8. REFERENCES [1] R. Arunachalam and N. M. Sadeh. The supply chain trading agent competition. Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz. A stochastic programming approach to scheduling in TAC SCM. In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang. Generalized confidence intervals for the largest value of some functions of parameters under normality. Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff. Evolution of market mechanism through a continuous space of auction-types. In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan. Active learning with statistical models. Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm. An algorithm for automatically designing deterministic mechanisms without payments. In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman. Evolutionary games in economics. Econometrica, 59(3):637-666, May 1991. [8] R. Keener. Statistical Theory: A Medley of Core Topics. University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman. An analysis of the 2004 supply chain management trading agent competition. In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J. Green. Microeconomic Theory. Oxford University Press, 1995. [11] R. B. Myerson. Optimal auction design. Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim. Simulation optimization. In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone. TacTex-03: A supply chain management agent. SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney. Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs. In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar. Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design. In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney. Using genetic programming to optimise pricing rules for a double-auction market. In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh. Learning payoff functions in infinite games. In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart. Analyzing complex strategic interactions in multi-agent systems. In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni. Strategic interactions in a supply chain game. Computational Intelligence, 21(1):1-26, February 2005. APPENDIX A. PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du. A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai. Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai). To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]). The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR. Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively. Let x∗ be the point at which these lines intersect. Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A . By substituting the expressions for cR and cL, we get the desired result. Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}. Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}. We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ. To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0. Putting everything together yields the desired result. A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|. To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|. Thus, the claim holds. By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A. That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α. Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum. Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|. An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i. Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞. Then V (b) = maxa∈A f(a, b) is uniformly continuous in b. To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ. Now take δ = mina∈A δ(a). Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ. Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)]. By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result. A.5 Proof of Theorem 6 Choose δ > 0. First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0. Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact. As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem. That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ. Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows. A.6 Proof of Theorem 7 Fix θ and choose δ > 0. Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < . By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1. Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < . Let us assume without loss of generality that there is a unique optimal choice of θ. Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ). Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ). Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1. Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315",
    "original_translation": "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismos empíricos. En la continuación, desarrollamos algunos métodos generales para el diseño empírico de mecanismos y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto. En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2. Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores. Ri es el conjunto de estrategias disponibles para el jugador i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×. . .×Am. A menudo es conveniente referirse a la estrategia del jugador i por separado de la de los demás jugadores. Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama un perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i). Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el jugador i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada jugador i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i. Podemos extender esta definición a estrategias mixtas asumiendo que ui son utilidades de von Neumann-Morgenstern (vNM) de la siguiente manera: ui(s) = Es[ui], donde Es es la expectativa tomada con respecto a la distribución de probabilidad del juego inducida por la estrategia mixta de los jugadores s. Al emplear la forma normal, modelamos a los agentes jugando una única acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones más detalladas sobre la acción a lo largo del tiempo en la forma extensiva. Aunque cualquier juego extenso puede ser reformulado en forma normal, hacerlo puede sacrificar la concisión y difuminar distinciones relevantes (por ejemplo, la perfección en subjuegos). Ocasionalmente, escribimos ui(x, y) para indicar que x ∈ Ai o Si y y ∈ A−i o S−i dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u(·) = {u1(·), . . . , um(·)}. Definimos una función, : R → R, interpretada como el beneficio máximo que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) donde r pertenece a algún conjunto de estrategias, R, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada aquellas jugadas por los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un equilibrio de Nash. DEFINICIÓN 1. Un perfil estratégico r = (r1, . . . , rm) constituye un equilibrio de Nash del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). Cuando r ∈ A, lo anterior define un equilibrio de Nash de estrategia pura; de lo contrario, la definición describe un equilibrio de Nash de estrategia mixta. A menudo recurrimos al concepto de un equilibrio aproximado, o equilibrio de Nash, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita. Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un equilibrio de Nash si (r) ≤ . En este estudio dedicamos especial atención a los juegos que presentan simetría en cuanto a los pagos, lo que hace que los agentes sean estratégicamente idénticos. DEFINICIÓN 2. Un juego [I, {Ri}, {ui(r)}] es simétrico si para todo i, j ∈ I, (a) Ri = Rj y (b) ui(ri, r−i) = uj (rj, r−j) siempre que ri = rj y r−i = r−j. EL MODELO Modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un juego de dos etapas. El diseñador comienza seleccionando primero un valor, θ, de un conjunto de configuraciones de mecanismos permitidas, Θ. Todos los agentes participantes observan el parámetro θ del mecanismo y se mueven simultáneamente después. Por ejemplo, el diseñador podría estar decidiendo entre mecanismos de subasta de sobre cerrado de precio único y de precio único, con la presunción de que una vez tomada la decisión, los postores participarán con pleno conocimiento de las reglas de la subasta. Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como Γθ = [I, {Ri}, {ui(r, θ)}]. Nos referimos a Γθ como un juego inducido por θ. Sea N(θ) el conjunto de perfiles estratégicos considerados soluciones del juego Γθ.3. Supongamos que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, W(r, θ), dependiente del parámetro del mecanismo y del juego resultante, r. Definimos una medida pesimista, W( ˆR, θ) = inf{W(r, θ) : r ∈ ˆR}, que representa el bienestar en el peor de los casos del juego inducido por θ, asumiendo que los agentes juegan alguna estrategia conjunta en ˆR. Normalmente nos preocupamos por W (N(θ), θ), el resultado en el peor de los casos de jugar alguna solución. En algunos problemas podemos obtener una considerable ventaja al utilizar una función de agregación para mapear el resultado del bienestar de un juego. Generalmente adoptamos el equilibrio de Nash como concepto de solución, y por lo tanto tomamos N(θ) como el conjunto de equilibrios. Sin embargo, gran parte de la metodología desarrollada aquí podría ser utilizada con criterios alternativos para derivar el comportamiento del agente a partir de una definición del juego. Nuevamente, existen alternativas disponibles. Por ejemplo, si se tiene una distribución de probabilidad sobre el conjunto de soluciones N(θ), sería natural tomar la expectativa de W(r, θ) en su lugar. 307 especificado en términos de estrategias de agentes a un resultado de bienestar equivalente especificado en términos de un resumen de menor dimensión. DEFINICIÓN 3. Una función φ: R1 × · · · × Rm → Rq es una función de agregación si m ≥ q y W(r, θ) = V(φ(r), θ) para alguna función V. Sobrecargamos el símbolo de función para aplicar a conjuntos de perfiles estratégicos: φ( ˆR) = {φ(r) : r ∈ ˆR}. Para mayor comodidad en la exposición, escribimos φ∗ (θ) para denotar φ(N(θ)). El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia. Por ejemplo, supongamos, como en nuestra aplicación a continuación, que la estrategia de un agente está definida por un parámetro numérico. Si todo lo que nos importa es el valor total jugado, podemos tomar φ(a) = Πm i=1 ai. Si hemos elegido nuestro agregador cuidadosamente, también podemos capturar estructuras que de otra manera no serían evidentes. Por ejemplo, φ∗ (θ) podría estar disminuyendo en θ, mientras que N(θ) podría tener una estructura más compleja. Dada una descripción de la correspondencia de solución N(θ) (equivalentemente, φ∗(θ)), el diseñador se enfrenta a un problema estándar de optimización. Alternativamente, dado un simulador que pudiera producir una muestra imparcial de la distribución de W (N(θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12]. Sin embargo, incluso para un juego Γθ con pagos conocidos, puede resultar computacionalmente intratable resolver los equilibrios de Nash, especialmente si el juego tiene conjuntos de estrategias grandes o infinitos. Además, deseamos estudiar juegos en los que los pagos no se dan explícitamente, sino que deben determinarse a partir de simulaciones u otra experiencia con el juego. Por lo tanto, asumimos que se nos proporciona un conjunto de datos (posiblemente ruidoso) de realizaciones de pagos: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, donde para cada punto de datos θi es el ajuste observado del parámetro del mecanismo, ai es el perfil de estrategia pura observado de los participantes, y Ui es la realización correspondiente de los pagos de los agentes. También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}. Sea D = {Do, Ds} el conjunto de datos combinado. (Ya sea que Do o Ds puedan ser nulos para un problema particular). En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos empíricos de teoría de juegos, para responder preguntas sobre el diseño del escenario TAC/SCM. 4. ANÁLISIS DE DISEÑO EMPÍRICO Dado que nuestros datos se presentan en forma de experiencia de pago y no como el valor de una función objetivo para configuraciones dadas de la variable de control, ya no podemos confiar en los métodos para optimizar funciones utilizando simulaciones. De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia del equilibrio de Nash. Además, no podemos depender directamente de los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilístico adaptados a nuestra configuración de problema. 4.1 Problema de Diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente. Recuerde que durante el torneo de 2004, los diseñadores del juego de la cadena de suministro optaron por aumentar drásticamente los costos de almacenamiento como medida para frenar las compras del día 0, con poco éxito. Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y la cantidad agregada de componentes adquiridos el día 0 en equilibrio. Esto suele ser el caso en juegos reales de interés, donde descripciones en lenguaje natural o algorítmicas pueden sustituir a una especificación formal de estrategias y funciones de pago. Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo. ¿Primero, ¿el aumento de los costos de almacenamiento realmente reduce la adquisición en el día 0? ¿Fue racional la adquisición excesiva observada durante el día 0 del torneo de 2004? Y en tercer lugar, ¿podría haber reducido de manera suficiente los costos de almacenamiento la adquisición del día 0 a un nivel aceptable, y en tal caso, cuál debería haber sido el ajuste de los costos de almacenamiento? Es esta tercera pregunta la que define el aspecto del diseño de mecanismos de nuestro análisis. Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de los agentes, la función de bienestar de los diseñadores, el espacio de parámetros del mecanismo y la fuente de datos. Restringimos las estrategias de los agentes para que sean un multiplicador de la cantidad de solicitudes del día 0 de uno de los finalistas, Deep Maize, en el torneo TAC/SCM de 2004. Lo restringimos aún más al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias por encima de 1.5 son extremadamente agresivas (por lo tanto, poco probables de proporcionar desviaciones refutadoras más allá de las disponibles en las estrategias incluidas, y ciertamente no forman parte de ningún equilibrio deseable). Todo otro comportamiento se basa en el comportamiento de Deep Maize y es idéntico para todos los agentes. Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico. Sin embargo, creemos que la forma general de los resultados debería ser robusta ante cambios en el comportamiento completo del agente. Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0. Sea φ(a) = Σ6 i=1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego particular de la cadena de suministro (para perfiles de estrategia mixta s, tomamos la esperanza de φ con respecto a la mezcla). La función de bienestar de los diseñadores W (N(θ), θ) se define entonces como I{sup{φ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de adquisición en el día 0 y I es la función indicadora. El diseñador selecciona un valor θ de costos de almacenamiento, expresado como un porcentaje anual del valor base de los componentes en el inventario (cobrado diariamente), del conjunto Θ = R+. Dado que la decisión de los diseñadores depende solo de φ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación. 4.2 Estimación de equilibrios de Nash El objetivo de los agentes de TAC/SCM es maximizar los beneficios obtenidos en una instancia del juego. Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, U(a)). Si también hemos fijado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de jugadores y sus correspondientes pagos, y, en consecuencia, para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios de Nash de cada juego Γθ. Por lo tanto, necesitamos métodos para aproximar equilibrios de Nash en juegos infinitos. A continuación, describimos los dos métodos que utilizamos en nuestro estudio. El primero ha sido explorado empíricamente anteriormente, mientras que el segundo se introduce aquí como el método específicamente diseñado para aproximar un conjunto de equilibrios de Nash. 4.2.1 Aproximación de la Función de Pago El primer método para estimar equilibrios de Nash basado en datos utiliza aprendizaje supervisado para aproximar las funciones de pago de mech6. No abordamos si y cómo otras medidas (por ejemplo, restringir directamente la adquisición) podrían haber logrado los objetivos de diseño. Nuestro enfoque considera como dado un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento. En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con un crecimiento de complejidad correspondiente. 308 participantes del mecanismo de un conjunto de datos de experiencia de juego [17]. Una vez que las funciones de pago aproximadas estén disponibles para todos los jugadores, los equilibrios de Nash pueden encontrarse ya sea de forma analítica o aproximada utilizando técnicas numéricas, dependiendo del modelo de aprendizaje. En lo que sigue, estimamos solo un equilibrio de Nash de muestra utilizando esta técnica, aunque esta restricción puede eliminarse a expensas de un tiempo de cálculo adicional. Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador. Por lo tanto, podemos aplicarlo cuando Ds = ∅. Si hay un simulador disponible, podemos generar datos adicionales para aumentar la confianza en nuestras estimaciones iniciales. Probamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado local (LWA) y regresión lineal ponderada localmente (LWLR). También utilizamos variables de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis empírico previo de teoría de juegos de TAC/SCM-03 [19]. El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido de forma analítica. Para los otros métodos aplicamos dinámica replicadora [7] a una aproximación discreta del juego aprendido. El total esperado de adquisiciones del día 0 en equilibrio se tomó como la estimación de un resultado. 4.2.2 Búsqueda en el Espacio de Perfiles de Estrategia Cuando tenemos acceso a un simulador, también podemos utilizar la búsqueda dirigida a través del espacio de perfiles para estimar el conjunto de equilibrios de Nash, que describimos aquí después de presentar alguna notación adicional. DEFINICIÓN 4. Un vecino estratégico de un perfil de estrategia pura a es un perfil que es idéntico a a en todo menos en una estrategia. Definimos Snb(a, D) como el conjunto de todos los vecinos estratégicos de a disponibles en el conjunto de datos D. De manera similar, definimos Snb(a, ˜D) como todos los vecinos estratégicos de a que no están en D. Finalmente, para cualquier a ∈ Snb(a, D) definimos al agente que se desvía como i(a, a). DEFINICIÓN 5. La -ligadura, ˆ, de un perfil de estrategia pura a se define como maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}. Decimos que a es un candidato a δ-equilibrio para δ ≥ ˆ. Cuando Snb(a, ˜D) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), a se confirma como un equilibrio de Nash ˆ. Nuestro método de búsqueda opera explorando desviaciones de los equilibrios candidatos. Nos referimos a esto como BestFirstSearch, ya que selecciona con probabilidad uno un perfil de estrategia a ∈ Snb(a, ˜D) que tiene el menor ˆin D. Finalmente definimos un estimador para un conjunto de equilibrios de Nash. DEFINICIÓN 6. Para un conjunto K, define Co(K) como la envoltura convexa de K. Sea Bδ el conjunto de candidatos en el nivel δ. Definimos ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) para un δ fijo como un estimador de φ∗ (θ). En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles estratégicos agregados con límite inferior -bound por debajo de un δ fijo. Esta definición nos permite explotar la estructura que surge de la función de agregación. Si dos perfiles son cercanos en términos de valores de agregación, es probable que tengan límites similares. En particular, si uno está en equilibrio, el otro también puede estarlo. Presentamos un respaldo teórico para este método de estimación del conjunto de equilibrios de Nash a continuación. Dado que el juego en el que estamos interesados es infinito, es necesario terminar BestFirstSearch antes de explorar todo el espacio de strat7. Por ejemplo, podemos utilizar técnicas de aprendizaje activo [5] para mejorar la calidad de la aproximación de la función de recompensa. En este trabajo, nos concentramos en la búsqueda en el espacio de perfiles estratégicos. Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos. Generación de datos Nuestros datos fueron recopilados simulando juegos TAC/SCM en una versión local del servidor TAC/SCM de 2004, que tiene una configuración para el costo de almacenamiento. Las estrategias de los agentes en juegos simulados fueron seleccionadas del conjunto {0, 0.3, 0.6, . . . , 1.5} con el fin de tener una probabilidad positiva de generar vecinos estratégicos. Se generó un conjunto de datos base Do mediante el muestreo de 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}. Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varios defectos. Utilizamos la búsqueda para generar un conjunto de datos simulados Ds, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ. Dado que el costo de la simulación es extremadamente alto (un juego tarda casi 1 hora en ejecutarse), pudimos ejecutar un total de 2670 juegos en el transcurso de más de seis meses. Para hacer una comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategias conjuntas finitas restringidas para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces). 4.4 Resultados 4.4.1 Análisis del conjunto de datos base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos base Do. Además, generamos una estimación de la correspondencia del equilibrio de Nash, ˆφ∗ (θ), aplicando la Definición 6 con δ = 2.5E6. Los resultados se muestran en la Figura 1. Como podemos ver, la correspondencia ˆφ∗ (θ) tiene poco poder predictivo basado en Do, y no revela ninguna estructura interesante sobre el juego. Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición Total Día 0 LWA LWLR QR BaselineMin BaselineMax Figura 1: Estimaciones de adquisición del día 0 agregadas basadas en Do. La correspondencia ˆφ∗ (θ) es el intervalo entre BaselineMin y BaselineMax. En general, la búsqueda se detiene una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para obtener conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego. Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash a permanecer en este subconjunto discreto de [0,1.5]. Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron accidentes, problemas de conectividad de red y otras anomalías obvias), el juego sería descartado. Análisis de los datos de búsqueda Para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ∗ (θ) (nuevamente, usando δ =2.5E6) en el conjunto de datos D = {Do, Ds}, donde Ds es datos generados a través de la aplicación de BestFirstSearch. Los resultados de esta estimación se representan gráficamente frente a los resultados de los métodos de aprendizaje entrenados en Do 11 en la Figura 2. Primero, observamos que la adición de los datos de búsqueda reduce considerablemente el rango de posibles equilibrios. Además, las predicciones puntuales reales de los métodos de aprendizaje y aquellas basadas en límites después de la búsqueda son razonablemente cercanas. Combinar la evidencia recopilada de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquiera de los métodos utilizados de forma aislada. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición del Día 0 LWA LWLR QR Búsqueda Mínima Búsqueda Máxima Figura 2: Estimaciones agregadas de adquisición del día 0 basadas en la búsqueda en el espacio de perfiles de estrategia en comparación con técnicas de aproximación de funciones entrenadas en Do. La correspondencia ˆφ∗ (θ) para D = {Do, Ds} es el intervalo entre SearchMin y SearchMax. Esta evidencia respalda la intuición inicial de que la adquisición del día 0 debería disminuir con los costos de almacenamiento. También confirma que los altos niveles de adquisición en el día 0 son una respuesta racional al entorno del torneo de 2004 con un costo promedio de almacenamiento, que corresponde a θ = 100. La predicción mínima para la adquisición agregada en este nivel de costos de almacenamiento, dada por cualquier método experimental, es aproximadamente 3. Esto es bastante alto, ya que corresponde a un compromiso esperado del 1/3 de la capacidad total del proveedor para todo el juego. La predicción máxima es considerablemente mayor a 4.5. En la competencia actual de 2004, la adquisición total del día 0 equivalía a 5.71 en la escala utilizada aquí [9]. Nuestras predicciones subestiman este resultado en cierta medida, pero muestran que cualquier resultado racional probablemente tendría una alta adquisición en el día 0. 4.4.3 Extrapolando la Correspondencia de la Solución Tenemos evidencia razonablemente sólida de que la correspondencia del resultado está disminuyendo. Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento a un valor que reduciría la adquisición del día 0 en equilibrio, o concluir que esto no es posible. Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día 0. No está claro cuán significativos serían los resultados del aprendizaje si se agregaran Ds al conjunto de datos de entrenamiento. De hecho, los datos adicionales pueden aumentar realmente la varianza del aprendizaje. Recuerde que el objetivo de los diseñadores es incentivar la adquisición agregada del día 0 que esté por debajo del umbral α. Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultados estimada a partir de D que produce θ = 320. Los datos para θ = 320 fueron recopilados de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos por 33 iteraciones de BestFirstSearch. La Figura 3 muestra los límites detallados para todos los perfiles en términos de sus valores correspondientes de φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Límites de ε de Adquisición Total Día-0 Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320. Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ(a). La región gris corresponde a ˆφ∗ (320) con δ = 2.5M. El conjunto estimado de resultados agregados del día 0 es muy cercano al de θ = 200, lo que indica que hay poco beneficio adicional al aumentar los costos de almacenamiento por encima de 200. Observa que incluso el límite inferior de nuestro conjunto estimado de equilibrios de Nash está muy por encima de la adquisición objetivo del día 0 de 2. Además, las recompensas para los agentes son casi siempre negativas en θ = 320. Por consiguiente, aumentar los costos aún más sería indeseable incluso si finalmente se pudiera reducir la adquisición en el día 0. Dado que tenemos una confianza razonable de que φ∗ (θ) está disminuyendo en θ, tampoco esperamos que establecer θ en algún lugar entre 200 y 320 logre el resultado deseado. Concluimos que es poco probable que la adquisición del día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento. Que nuestras predicciones tienden a subestimar los resultados del torneo refuerza esta conclusión. Para lograr la reducción deseada en la adquisición del día 0 se requiere rediseñar otros aspectos del mecanismo. 4.5 Análisis Probabilístico Nuestro análisis empírico ha producido evidencia en apoyo a la conclusión de que ninguna configuración razonable del costo de almacenamiento probablemente sería suficiente para frenar la adquisición excesiva del día 0 en TAC/SCM 04. Toda esta evidencia ha sido en forma de simple interpolación y extrapolación de estimaciones de la correspondencia del equilibrio de Nash. Estas estimaciones se basan en simular instancias del juego y están sujetas a ruido de muestreo contribuido por los diversos elementos estocásticos del juego. En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos -bound a tales efectos estocásticos. Supongamos que todos los agentes tienen conjuntos de estrategias puras finitos (y pequeños), A. Por lo tanto, es factible muestrear toda la matriz de pagos del juego. Además, supongamos que el ruido es aditivo con media cero en promedio durante todo el juego, por lo que en la práctica probablemente querríamos que el umbral sea aún más bajo. 310 y varianza finita, es decir, Ui(a) = ui(a) + ˜ξi(a), donde Ui(a) es la ganancia observada para i cuando se jugó a, ui(a) es la ganancia correspondiente real, y ˜ξi(a) es una variable aleatoria normal con media cero. Designamos la varianza conocida de ˜ξi(a) como σ2 i (a). Por lo tanto, asumimos que ˜ξi(a) es normal con distribución N(0, σ2 i (a)). Tomamos ¯ui(a) como la media muestral de todos los Ui(a) en D, y seguimos a Chang y Huang [3] al asumir que tenemos una priori impropia sobre las ganancias reales ui(a) y el muestreo fue independiente para todos i y a. También confiamos en su resultado de que ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] son independientes con distribuciones posteriores N(¯ui(a), σ2 i (a)/ni(a)), donde ni(a) es el número de muestras tomadas de los pagos para i en el perfil puro a, y Zi(a) ∼ N(0, 1). Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio de Nash -Nash. Si ui(·)|¯ui(·) son independientes para todo i ∈ I y a ∈ A, tenemos el siguiente resultado (a partir de este punto omitimos la condición sobre ¯ui(·) por brevedad): PROPOSICIÓN 1. Para todo \\( i \\in I \\), \\( \\max_{b \\in A_i} u_i(b, a_{-i}) - u_i(a) \\leq \\varepsilon \\), donde \\( \\varepsilon = \\int_{Y_i} \\int_{Z} \\int_{R} \\int_{Y} \\int_{b \\in A_i \\backslash a_i} \\Pr(u_i(b, a_{-i}) \\leq u + \\varepsilon) f_{u_i(a)}(u) du \\), donde \\( f_{u_i(a)}(u) \\) es la función de densidad de probabilidad de \\( N(\\overline{u_i(a)}, \\sigma_i(a)) \\). Las pruebas de este y todos los resultados posteriores se encuentran en el Apéndice. La distribución posterior de la media óptima de n muestras, derivada por Chang y Huang [3], es Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) donde a ∈ A y Φ(·) es la función de distribución N(0, 1). Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilístico que (a) ≤ γ para un γ dado. Ahora, consideramos casos de datos incompletos y utilizamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en los datos) en la distribución de sup{φ∗ (θ)} e inf{φ∗ (θ)} (asumiendo que ambos son alcanzables): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, donde x es un número real y ≤D indica que el límite superior solo considera estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} y {inf{φ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf{φ∗ (θ)} ≤ x}. Los valores así derivados comprenden las Tablas 1 y 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Tabla 1: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando N(θ) es un conjunto de equilibrios de Nash. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Tabla 2: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {150, 200, 320} cuando N(θ) es un conjunto de equilibrios de Nash. Las Tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ(a) < 2.7 es poco probable para cualquier θ del cual tengamos datos, aunque este juicio, como mencionamos, se refiere únicamente a los perfiles que hemos muestreado realmente. Podemos entonces aceptar esto como otra pieza de evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, parece poco probable que el diseñador logre su objetivo incluso si pudiera persuadir a los participantes a jugar un equilibrio deseable. La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM de 2004 eran, de hecho, racionales al adquirir grandes cantidades de componentes al comienzo del juego. Si observamos la tercera columna de esta tabla, que corresponde a θ = 100, podemos deducir que ningún perfil a en nuestros datos con φ(a) < 3 es muy probable que se juegue en equilibrio. Los límites anteriores proporcionan algunas pruebas generales, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos muestreado. Particularmente, nos gustaría decir algo sobre lo que sucede en los ajustes de θ para los cuales no tenemos datos. Para derivar un límite probabilístico aproximado sobre la probabilidad de que ningún θ ∈ Θ haya logrado el objetivo del diseñador, sea ∪J j=1Θj una partición de Θ, y asuma que la función sup{φ∗ (θ)} satisface la condición de Lipschitz con constante de Lipschitz Aj en cada subconjunto Θj. Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a Θ = [0, 320]. Ahora definimos cada subconjunto j como el intervalo entre dos puntos para los cuales hemos producido datos. Por lo tanto, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], con j variando entre 1 y 5, correspondiendo a los subintervalos anteriores. Denotaremos cada Θj por (aj, bj]. Luego, la siguiente proposición nos da una cota superior aproximada sobre la probabilidad de que sup{φ∗ (θ)} ≤ α. PROPOSICIÓN 2. Debido a que nuestros límites son aproximados, no podemos utilizarlos como una evaluación probabilística concluyente. En cambio, tomamos esto como otra pieza de evidencia para complementar nuestros hallazgos. Aunque podamos asumir que una función que aproximamos a partir de datos es Lipschitz continua, rara vez conocemos en realidad la constante de Lipschitz para cualquier subconjunto de Θ. Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de los datos. Aquí, probamos tres métodos para hacer esto. El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subintervalo. Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo. Un método alternativo es tomar un límite superior en la pendiente obtenida dentro de cada subintervalo utilizando los datos disponibles. Esto produce un límite superior de probabilidades mucho menos conservador. Sin embargo, dado que el límite superior real suele ser mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso. Un último método que intentamos es un compromiso entre los dos anteriores. En lugar de tomar el límite superior conservador basado en datos sobre todo el dominio de la función Θ, tomamos el promedio de los límites superiores obtenidos en cada Θj. El límite en un intervalo se toma como el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos. Los resultados de evaluar la expresión para Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3. En términos de nuestras afirmaciones en maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Tabla 3: Límite superior aproximado de la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con un objetivo α = 2. Se utilizan diferentes métodos para aproximar el límite superior de la pendiente en cada subintervalo j. En este trabajo, la expresión proporciona un límite superior a la probabilidad de que alguna configuración de θ (es decir, costo de almacenamiento) en el intervalo [0,320] resulte en una adquisición total del día 0 que no sea mayor en ningún equilibrio que el objetivo especificado por α y tomado aquí como 2. Como sospechábamos, el enfoque más conservador para estimar el límite superior de la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí. Sin embargo, los otros dos enfoques de estimación, encontrados en las columnas dos y tres de la Tabla 3, sugieren que de hecho estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría funcionado. Dada la tremenda dificultad del problema, este resultado es muy sólido. Aun así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia. Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y los conjuntos de estrategias). Tampoco podemos esperar obtener nunca suficiente evidencia para llegar a conclusiones completamente objetivas. En cambio, el enfoque que defendemos aquí es recopilar la mayor cantidad de evidencia posible dadas las limitaciones de recursos, y tomar la decisión más convincente basada en esta evidencia, si es posible. RESULTADOS DE CONVERGENCIA En este punto, exploramos abstractamente si una elección de parámetro de diseño basada en datos de pago puede ser asintóticamente confiable. Dado que no teníamos todas las desviaciones posibles para cualquier perfil disponible en los datos, los verdaderos límites superiores pueden ser aún más bajos. Por conveniencia, utilizaremos la notación un,i(a) para referirnos a una función de pago del jugador i basada en un promedio sobre n muestras i.i.d. de la distribución de pagos. También asumimos que un,i(a) son independientes para todo a ∈ A e i ∈ I. Utilizaremos la notación Γn para referirnos al juego [I, R, {ui,n(·)}], mientras que Γ denotará el juego subyacente, [I, R, {ui(·)}]. De manera similar, definimos n(r) como (r) con respecto al juego Γn. En esta sección, demostramos que n(s) → (s) casi seguramente de forma uniforme en el espacio de estrategias mixtas para cualquier juego finito, y, además, que todas las equilibrios de Nash en estrategias mixtas en juegos empíricos eventualmente se acercan arbitrariamente a algunas estrategias de equilibrio de Nash en el juego subyacente. Utilizamos estos resultados para demostrar que bajo ciertas condiciones, la elección óptima del parámetro de diseño basada en datos empíricos converge casi seguramente al óptimo real. TEOREMA 3. Supongamos que |I| < ∞, |A| < ∞. Entonces n(s) → (s) casi seguramente uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios de Nash de Γ. Si definimos Nn,γ = {s ∈ S : n(s) ≤ γ}, tenemos el siguiente corolario del Teorema 3: COROLARIO 4. Para todo γ > 0, existe un M tal que para todo n ≥ M, N ⊂ Nn,γ casi seguramente. PRUEBA. Dado que n(s) = 0 para todo s ∈ N, podemos encontrar un M lo suficientemente grande tal que Pr{supn≥M sups∈N n(s) < γ} = 1. Según el Corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier > 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios de Nash empíricos si se han tomado suficientes muestras. Como mostramos ahora, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un límite no nulo como una estimación del conjunto de equilibrios de Nash. Primero, supongamos que concluimos que para una configuración particular de θ, sup{ˆφ∗ (θ)} ≤ α. Entonces, dado que para cualquier fijo > 0, N(θ) ⊂ Nn, (θ) cuando n es suficientemente grande, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α para cualquier n de este tipo. Así, dado que definimos la función de bienestar del diseñador como I{sup{φ∗ (θ)} ≤ α} en nuestro dominio de interés, la elección empírica de θ satisface el objetivo del diseñador, maximizando así su función de bienestar. Alternativamente, supongamos que concluimos que inf{ˆφ∗ (θ)} > α para cada θ en el dominio. Entonces, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, para todo θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo del diseñador. Ahora, demostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de Γn está cerca de algún equilibrio de Nash del juego subyacente. Este resultado nos llevará a considerar la convergencia de los optimizadores basados en datos empíricos a los ajustes óptimos reales de los parámetros del mecanismo. Primero notamos que la función (s) es continua en un juego finito. LEMMA 5. \n\nLEMMA 5. Sea S un conjunto de estrategias mixtas definido en un juego finito. Entonces: S → R es continua. Para la exposición que sigue, necesitamos un poco de notación adicional. Primero, sea (Z, d) un espacio métrico, y X, Y ⊂ Z y definamos la distancia de Hausdorff dirigida de X a Y como h(X, Y) = sup x∈X inf y∈Y d(x, y). Observa que U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ). Además, define BS(x, δ) como una bola abierta en S ⊂ Z con centro en x ∈ S y radio δ. Ahora, dejemos que Nn denote todos los equilibrios de Nash del juego Γn y sea Nδ = [ x∈N BS(x, δ), es decir, la unión de bolas abiertas de radio δ con centros en los equilibrios de Nash de Γ. Ten en cuenta que h(Nδ, N) = δ. Podemos entonces demostrar el siguiente resultado general. TEOREMA 6. Supongamos que |I| < ∞ y |A| < ∞. Entonces casi con seguridad h(Nn, N) converge a 0. Ahora demostraremos que en el caso especial cuando Θ y A son finitos y cada Γθ tiene un equilibrio de Nash único, las estimaciones ˆθ del parámetro óptimo del diseñador convergen a un optimizador real casi seguramente. Sea ˆθ = arg maxθ∈Θ W (Nn(θ), θ), donde n es el número de veces que se muestreó cada perfil puro en Γθ para cada θ, y sea θ∗ = arg maxθ∈Θ W (N(θ), θ). TEOREMA 7. Supongamos que |N(θ)| = 1 para todo θ ∈ Θ y supongamos que Θ y A son finitos. Sea W (s, θ) continua en el único s∗ (θ) ∈ N(θ) para cada θ ∈ Θ. Entonces ˆθ es un estimador consistente de θ∗ si W (N(θ), θ) se define como un supremo, ínfimo o esperanza sobre el conjunto de equilibrios de Nash. De hecho, ˆθ → θ∗ casi seguramente en cada uno de estos casos. La limitación del resultado anterior es que, dentro de nuestro marco de trabajo, el diseñador no tiene forma de saber o asegurar que Γθ tenga equilibrios únicos. Sin embargo, sí proporciona cierta justificación teórica para seguir el diseño de esta manera, y quizás servirá como guía para obtener resultados más generales en el futuro. 6. TRABAJO RELACIONADO La literatura de diseño de mecanismos en Economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10]. Además, existe una extensa literatura sobre el diseño óptimo de subastas [10], del cual el trabajo de Roger Myerson [11] es, quizás, el más relevante. En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y teniendo en cuenta restricciones como la compatibilidad de incentivos y la racionalidad individual. Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de Ciencias de la Computación. Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros relevantes del juego son conocimiento común. Cuando las funciones de pago de los jugadores son desconocidas, se ha explorado la realización de búsquedas mediante simulaciones como alternativa. Un enfoque en esa dirección, tomado en [4] y [15], es coevolucionar el parámetro del mecanismo y las estrategias de los agentes, utilizando alguna noción de utilidad social y pagos de los agentes como criterios de aptitud. Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética. En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron un resultado de un juego inducido por un parámetro del mecanismo como el resultado del aprendizaje conjunto de los agentes. Más recientemente, Phelps et al. [14] compararon dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en juegos definidos por estrategias heurísticas, como en [18]. 7. CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el diseño empírico de mecanismos. Definimos un modelo formal de teoría de juegos de interacción entre el diseñador y los participantes del mecanismo como un juego de dos etapas. También describimos en cierta generalidad los métodos para estimar una función de equilibrio de Nash de muestra cuando los datos son extremadamente escasos, o una correspondencia de equilibrio de Nash cuando hay más datos disponibles. Nuestras técnicas están diseñadas específicamente para abordar problemas en los que tanto el espacio de parámetros del mecanismo como los conjuntos de estrategias de los agentes son infinitos y solo se puede adquirir un conjunto de datos relativamente pequeño. Un problema de diseño difícil en el juego TAC/SCM que la comunidad de TAC ha estado ansiosa por abordar nos brinda un escenario para probar nuestros métodos. Al aplicar el análisis empírico del juego al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos. Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia del equilibrio de Nash. Al final, podemos intentar proporcionar suficiente evidencia para prescribir una configuración de parámetros, o sugerir que no es posible encontrar una configuración que satisfaga al diseñador. En el caso de TAC/SCM, nuestra evidencia sugiere bastante claramente que el costo de almacenamiento no pudo haber sido ajustado de manera efectiva en el torneo de 2004 para frenar la adquisición excesiva del día 0 sin efectos perjudiciales en la rentabilidad general. El éxito de nuestro análisis en este entorno extremadamente complejo con altos costos de simulación nos hace ser optimistas de que nuestros métodos pueden brindar orientación en la toma de decisiones de diseño de mecanismos en otros dominios desafiantes. Los resultados teóricos confirman algunas intuiciones detrás de los métodos de diseño de mecanismos empíricos que hemos introducido, y aumentan nuestra confianza en que nuestro marco puede ser efectivo para estimar la mejor elección de parámetros del mecanismo en entornos relativamente generales. Agradecimientos Agradecemos a Terence Kelly, Matthew Rudary y Satinder Singh por sus útiles comentarios sobre versiones anteriores de este trabajo. Este trabajo fue apoyado en parte por la subvención de la NSF IIS-0205435 y el programa de razonamiento estratégico DARPA REAL. 8. REFERENCIAS [1] R. Arunachalam y N. M. Sadeh. La competencia de agentes de comercio de la cadena de suministro. Investigación y aplicaciones del comercio electrónico, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy y M. Tschantz. Un enfoque de programación estocástica para la planificación en TAC SCM. En la Quinta Conferencia ACM sobre Comercio Electrónico, páginas 152-159, Nueva York, 2004. [3] Y.-P. Chang y W.-T. Huang. Intervalos de confianza generalizados para el valor más grande de algunas funciones de parámetros bajo normalidad. Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.\nEstadística Sinica, 10:1369-1383, 2000. [4] D. Cliff. Evolución del mecanismo de mercado a través de un espacio continuo de tipos de subasta. En el Congreso de Computación Evolutiva de 2002. [5] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [6] V. Conitzer y T. Sandholm. Un algoritmo para diseñar automáticamente mecanismos determinísticos sin pagos. En la Tercera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagente, páginas 128-135, 2004. [7] D. Friedman. Juegos evolutivos en economía. Econometrica, 59(3):637-666, mayo de 1991. [8] R. Keener. Teoría Estadística: Una Mezcla de Temas Fundamentales. Departamento de Estadística de la Universidad de Michigan, 2004. [9] C. Kiekintveld, Y. Vorobeychik y M. P. Wellman. Un análisis de la competencia de agentes comerciales de gestión de la cadena de suministro de 2004. En el taller IJCAI-05 sobre Diseño y Análisis de Agentes de Negociación, Edimburgo, 2005. [10] A. Mas-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [11] R. B. Myerson.\nEditorial de la Universidad de Oxford, 1995. [11] R. B. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6(1):58-73, febrero de 1981. [12] S. Olafsson y J. Kim. Optimización de simulación. En E. Yucesan, C.-H. Chen, J. Snowdon y J. Charnes, editores, Conferencia de Simulación de Invierno 2002, 2002. [13] D. Pardoe y P. Stone. TacTex-03: Un agente de gestión de la cadena de suministro. SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, y P. McBurney. Agentes automatizados versus humanos virtuales: una comparación teórica evolutiva de dos diseños de mercado de subasta doble. En Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney y E. Sklar. Co-evolución de mecanismos de subasta y estrategias de negociación: hacia un enfoque novedoso para el diseño microeconómico. En el taller ECOMAS 2002, 2002. [16] S. Phelps, S. Parsons, E. Sklar y P. McBurney. Utilizando programación genética para optimizar reglas de precios para un mercado de subasta doble. En Taller sobre Agentes para el Comercio Electrónico, 2003. [17] Y. Vorobeychik, M. P. Wellman y S. Singh. Aprendiendo funciones de pago en juegos infinitos. En la Decimonovena Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro y J. O. Kephart. Analizando interacciones estratégicas complejas en sistemas multiagente. En el taller AAAI-02 sobre agentes teóricos de juegos y de toma de decisiones, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld y V. Soni. Interacciones estratégicas en un juego de cadena de suministro. Inteligencia Computacional, 21(1):1-26, febrero de 2005. APÉNDICE A. PRUEBAS A.1 Prueba de la Proposición 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du. A.2 Prueba de la Proposición 2 Primero, supongamos que alguna función, f(x), definida en [ai, bi], satisface la condición de Lipschitz en (ai, bi] con una constante de Lipschitz Ai. Entonces se cumple la siguiente afirmación: Afirmación: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai). Para demostrar esta afirmación, observe que la intersección de las líneas en f(ai) y f(bi) con pendientes -Ai y Ai respectivamente determinará el límite inferior del mínimo de f(x) en [ai, bi] (que es un límite inferior del ínfimo de f(x) en (ai, bj]). La línea en f(ai) está determinada por f(ai) = −Aiai + cL y la línea en f(bi) está determinada por f(bi) = Aibi + cR. Por lo tanto, las intercepciones son cL = f(ai) + Aiai y cR = f(bi) + Aibi respectivamente. Sea x∗ el punto en el que estas líneas se cruzan. Entonces, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A. Al sustituir las expresiones de cR y cL, obtenemos el resultado deseado. Ahora, la subaditividad nos da Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, y, por la afirmación, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}. Dado que tenemos un número finito de puntos en el conjunto de datos para cada θ, podemos obtener la siguiente expresión: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}. Ahora podemos restringir nuestra atención en obtener una cota superior en Pr{sup{φ∗ (θ)} = y} para un θ fijo. Para hacer esto, observe que Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} por subaditividad y el hecho de que un perfil a es un equilibrio de Nash si y solo si (a) = 0. Poner todo junto produce el resultado deseado. Prueba de Teorema 3 En primer lugar, necesitaremos el siguiente hecho: Afirmación: Dada una función fi(x) y un conjunto X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|. Para demostrar esta afirmación, observe que | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) si maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) si maxx f2(x) ≥ maxx f1(x) En el primer caso, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 De manera similar, en el segundo caso, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|. Por lo tanto, la afirmación se mantiene. Por la Ley Fuerte de los Grandes Números, un,i(a) → ui(a) casi seguramente para todo i ∈ I, a ∈ A. Es decir, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, o, equivalentemente [8], para cualquier α > 0 y δ > 0, existe M(i, a) > 0 tal que Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Al tomar M = maxi∈I maxa∈A M(i, a), tenemos que Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Así, por la afirmación, para cualquier n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ con una probabilidad de al menos 1 − α. Ten en cuenta que dado que s−i(a) y s(a) están acotados entre 0 y 1, pudimos eliminarlos de las expresiones anteriores para obtener una cota que será válida independientemente de la elección particular de s. Además, dado que el resultado anterior se puede obtener para un α arbitrario > 0 y δ > 0, tenemos que Pr{limn→∞ n(s) = (s)} = 1 uniformemente en S. A.4 Prueba del Lema 5 Demostramos el resultado utilizando la continuidad uniforme de ui(s) y la preservación de la continuidad bajo el máximo. Afirmación: Una función f : Rk → R definida por f(t) = Σi=1k zi ti, donde zi son constantes en R, es uniformemente continua en t. La afirmación se sigue porque |f(t)−f(t )| = | Σi=1k zi(ti−ti)| ≤ Σi=1k |zi||ti − ti|. Un resultado inmediato de esto para nuestros propósitos es que ui(s) es uniformemente continua en s y ui(ai, s−i) es uniformemente continua en s−i. Afirmación: Sea f(a, b) uniformemente continua en b ∈ B para cada a ∈ A, con |A| < ∞. Entonces V (b) = maxa∈A f(a, b) es uniformemente continua en b. Para demostrar esto, toma γ > 0 y deja que b, b ∈ B tal que b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ. Ahora toma δ = mina∈A δ(a). Entonces, cada vez que b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ. Ahora, recuerda que (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)]. Según las afirmaciones anteriores, maxai∈Ai ui(ai, s−i) es uniformemente continua en s−i y ui(s) es uniformemente continua en s. Dado que la diferencia de dos funciones uniformemente continuas es uniformemente continua, y dado que esta continuidad se conserva bajo el máximo según nuestra segunda afirmación, obtenemos el resultado deseado. Prueba de Teorema 6. Elija δ > 0. Primero, necesitamos asegurarnos de que se cumple la siguiente afirmación: Afirmación: ¯ = mins∈S\\Nδ (s) existe y ¯ > 0. Dado que Nδ es un subconjunto abierto de S compacto, se sigue que S \\ Nδ es compacto. Como también habíamos demostrado en el Lema 5 que (s) es continua, la existencia se sigue del teorema de Weierstrass. Es claro que ¯ > 0 ya que (s) = 0 si y solo si s es un equilibrio de Nash de Γ. Ahora, por el Teorema 3, para cualquier α > 0 existe un M tal que Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. En consecuencia, para cualquier δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Dado que esto se cumple para un α arbitrario > 0 y δ > 0, se obtiene el resultado deseado. Prueba de Teorema 7. Fija θ y elige δ > 0. Dado que W (s, θ) es continua en s∗ (θ), dado > 0 existe δ > 0 tal que para cada s que esté dentro de δ de s∗ (θ), |W (s, θ) - W (s∗ (θ), θ)| < . Según el Teorema 6, podemos encontrar M(θ) lo suficientemente grande para que todos los s ∈ Nn estén dentro de δ de s∗ (θ) para todo n ≥ M(θ) con probabilidad 1. Por consiguiente, para cualquier > 0 podemos encontrar M(θ) lo suficientemente grande tal que con probabilidad 1 tengamos supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < . Asumamos sin pérdida de generalidad que hay una elección óptima única de θ. Ahora, dado que el conjunto Θ es finito, también existe la segunda mejor opción de θ (si solo hay un θ ∈ Θ, esta discusión no tiene sentido de todos modos): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ). Supongamos sin pérdida de generalidad que θ∗∗ también es único y sea ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ). Entonces, si dejamos < ∆/2 y dejamos que M = maxθ∈Θ M(θ), donde cada M(θ) es lo suficientemente grande como para que supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., la elección óptima de θ basada en cualquier equilibrio empírico será θ∗ con probabilidad 1. Por lo tanto, en particular, dado cualquier distribución de probabilidad sobre equilibrios empíricos, la mejor elección de θ será θ∗ con probabilidad 1 (similarmente, si tomamos el supremo o el ínfimo de W (Nn(θ), θ) sobre el conjunto de equilibrios empíricos al construir la función objetivo).",
    "original_sentences": [
        "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
        "We illustrate our approach with a design task from a supply-chain trading competition.",
        "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
        "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
        "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
        "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
        "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
        "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
        "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
        "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
        "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
        "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
        "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
        "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
        "The task facing game organizers can be viewed as a problem in mechanism design.",
        "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
        "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
        "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
        "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
        "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
        "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
        "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
        "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
        "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
        "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
        "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
        "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
        "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
        "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
        "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
        "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
        "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
        "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
        "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
        "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
        "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
        "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
        "We believe that most realistic problems are too complex to be amenable to exact analysis.",
        "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
        "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
        "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
        "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
        "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
        "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
        "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
        "An s ∈ S is called a mixed strategy profile.",
        "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
        "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
        "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
        "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
        "We could capture finer-grained decisions about action over time in the extensive form.",
        "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
        "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
        "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
        "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
        "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
        "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
        "DEFINITION 1.",
        "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
        "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
        "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
        "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
        "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
        "DEFINITION 2.",
        "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
        "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
        "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
        "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
        "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
        "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
        "We refer to Γθ as a game induced by θ.",
        "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
        "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
        "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
        "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
        "DEFINITION 3.",
        "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
        "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
        "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
        "Using an aggregation function yields a more compact representation of strategy profiles.",
        "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
        "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
        "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
        "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
        "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
        "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
        "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
        "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
        "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
        "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
        "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
        "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
        "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
        "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
        "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
        "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
        "In doing so, we consider several questions raised during and after the tournament.",
        "First, does increasing storage costs actually reduce day-0 procurement?",
        "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
        "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
        "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
        "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
        "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
        "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
        "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
        "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
        "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
        "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
        "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
        "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
        "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
        "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
        "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
        "Thus, we need methods for approximating Nash equilibria for infinite games.",
        "Below, we describe the two methods we used in our study.",
        "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
        "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
        "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
        "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
        "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
        "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
        "Thus, we can apply it when Ds = ∅.",
        "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
        "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
        "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
        "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
        "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
        "DEFINITION 4.",
        "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
        "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
        "DEFINITION 5.",
        "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
        "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
        "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
        "Our search method operates by exploring deviations from candidate equilibria.",
        "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
        "DEFINITION 6.",
        "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
        "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
        "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
        "This definition allows us to exploit structure arising from the aggregation function.",
        "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
        "In particular, if one is an equilibrium, the other may be as well.",
        "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
        "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
        "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
        "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
        "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
        "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
        "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
        "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
        "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
        "The results are shown in Figure 1.",
        "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
        "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
        "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
        "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
        "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
        "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
        "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
        "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
        "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
        "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
        "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
        "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
        "The maximum prediction is considerably higher at 4.5.",
        "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
        "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
        "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
        "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
        "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
        "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
        "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
        "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
        "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
        "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
        "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
        "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
        "Furthermore, payoffs to agents are almost always negative at θ = 320.",
        "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
        "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
        "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
        "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
        "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
        "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
        "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
        "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
        "Suppose that all agents have finite (and small) pure strategy sets, A.",
        "Thus, it is feasible to sample the entire payoff matrix of the game.",
        "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
        "We designate the known variance of ˜ξi(a) by σ2 i (a).",
        "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
        "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
        "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
        "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
        "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
        "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
        "The proofs of this and all subsequent results are in the Appendix.",
        "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
        "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
        "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
        "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
        "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
        "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
        "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
        "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
        "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
        "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
        "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
        "We now define each subset j to be the interval between two points for which we have produced data.",
        "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
        "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
        "PROPOSITION 2.",
        "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
        "Instead, we take this as another piece of evidence to complement our findings.",
        "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
        "Thus, we are faced with a task of estimating it from data.",
        "Here, we tried three methods of doing this.",
        "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
        "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
        "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
        "This produces a much less conservative upper bound on probabilities.",
        "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
        "A final method that we tried is a compromise between the two above.",
        "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
        "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
        "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
        "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
        "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
        "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
        "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
        "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
        "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
        "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
        "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
        "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
        "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
        "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
        "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
        "Similarly, we define n(r) to be (r) with respect to the game Γn.",
        "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
        "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
        "THEOREM 3.",
        "Suppose that |I| < ∞, |A| < ∞.",
        "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
        "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
        "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
        "PROOF.",
        "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
        "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
        "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
        "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
        "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
        "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
        "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
        "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
        "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
        "We first note that the function (s) is continuous in a finite game.",
        "LEMMA 5.",
        "Let S be a mixed strategy set defined on a finite game.",
        "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
        "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
        "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
        "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
        "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
        "Note that h(Nδ, N) = δ.",
        "We can then prove the following general result.",
        "THEOREM 6.",
        "Suppose |I| < ∞ and |A| < ∞.",
        "Then almost surely h(Nn, N) converges to 0.",
        "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
        "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
        "THEOREM 7.",
        "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
        "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
        "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
        "In fact, ˆθ → θ∗ a.s. in each of these cases.",
        "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
        "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
        "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
        "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
        "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
        "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
        "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
        "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
        "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
        "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
        "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
        "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
        "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
        "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
        "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
        "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
        "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
        "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
        "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
        "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
        "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
        "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
        "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
        "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
        "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
        "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
        "The supply chain trading agent competition.",
        "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
        "A stochastic programming approach to scheduling in TAC SCM.",
        "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
        "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
        "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
        "Evolution of market mechanism through a continuous space of auction-types.",
        "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
        "Active learning with statistical models.",
        "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
        "An algorithm for automatically designing deterministic mechanisms without payments.",
        "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
        "Evolutionary games in economics.",
        "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
        "Statistical Theory: A Medley of Core Topics.",
        "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
        "An analysis of the 2004 supply chain management trading agent competition.",
        "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
        "Green.",
        "Microeconomic Theory.",
        "Oxford University Press, 1995. [11] R. B. Myerson.",
        "Optimal auction design.",
        "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
        "Simulation optimization.",
        "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
        "TacTex-03: A supply chain management agent.",
        "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
        "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
        "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
        "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
        "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
        "Using genetic programming to optimise pricing rules for a double-auction market.",
        "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
        "Learning payoff functions in infinite games.",
        "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
        "Analyzing complex strategic interactions in multi-agent systems.",
        "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
        "Strategic interactions in a supply chain game.",
        "Computational Intelligence, 21(1):1-26, February 2005.",
        "APPENDIX A.",
        "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
        "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
        "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
        "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
        "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
        "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
        "Let x∗ be the point at which these lines intersect.",
        "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
        "By substituting the expressions for cR and cL, we get the desired result.",
        "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
        "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
        "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
        "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
        "Putting everything together yields the desired result.",
        "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
        "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
        "Thus, the claim holds.",
        "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
        "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
        "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
        "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
        "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
        "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
        "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
        "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
        "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
        "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
        "Now take δ = mina∈A δ(a).",
        "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
        "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
        "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
        "A.5 Proof of Theorem 6 Choose δ > 0.",
        "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
        "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
        "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
        "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
        "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
        "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
        "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
        "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
        "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
        "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
        "Let us assume without loss of generality that there is a unique optimal choice of θ.",
        "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
        "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
        "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
        "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
    ],
    "translated_text_sentences": [
        "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo.",
        "Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro.",
        "Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes.",
        "Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado.",
        "Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente.",
        "Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1.",
        "MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004.",
        "TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro.",
        "Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado.",
        "Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación.",
        "Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0.",
        "Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario.",
        "Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes.",
        "Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0.",
        "La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos.",
        "Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego.",
        "A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual.",
        "Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción.",
        "Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos.",
        "En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0.",
        "Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados.",
        "A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004.",
        "En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo.",
        "Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9].",
        "La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa.",
        "Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados.",
        "Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito.",
        "El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño.",
        "Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento.",
        "Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismos empíricos.",
        "En la continuación, desarrollamos algunos métodos generales para el diseño empírico de mecanismos y los aplicamos al problema de rediseño TAC/SCM.",
        "Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado.",
        "Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento.",
        "También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados.",
        "Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema.",
        "En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores.",
        "Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones.",
        "Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto.",
        "En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2.",
        "Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores.",
        "Ri es el conjunto de estrategias disponibles para el jugador i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los jugadores.",
        "Designamos el conjunto de estrategias puras disponibles para el jugador i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×. . .×Am.",
        "A menudo es conveniente referirse a la estrategia del jugador i por separado de la de los demás jugadores.",
        "Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i.",
        "Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A.",
        "Un s ∈ S se llama un perfil de estrategia mixta.",
        "Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i).",
        "Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el jugador i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada jugador i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i.",
        "Podemos extender esta definición a estrategias mixtas asumiendo que ui son utilidades de von Neumann-Morgenstern (vNM) de la siguiente manera: ui(s) = Es[ui], donde Es es la expectativa tomada con respecto a la distribución de probabilidad del juego inducida por la estrategia mixta de los jugadores s. Al emplear la forma normal, modelamos a los agentes jugando una única acción, con decisiones tomadas simultáneamente.",
        "Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas.",
        "Podríamos capturar decisiones más detalladas sobre la acción a lo largo del tiempo en la forma extensiva.",
        "Aunque cualquier juego extenso puede ser reformulado en forma normal, hacerlo puede sacrificar la concisión y difuminar distinciones relevantes (por ejemplo, la perfección en subjuegos).",
        "Ocasionalmente, escribimos ui(x, y) para indicar que x ∈ Ai o Si y y ∈ A−i o S−i dependiendo del contexto.",
        "También expresamos el conjunto de funciones de utilidad de todos los jugadores como u(·) = {u1(·), . . . , um(·)}.",
        "Definimos una función, : R → R, interpretada como el beneficio máximo que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) donde r pertenece a algún conjunto de estrategias, R, de estrategias puras o mixtas.",
        "Ante un juego, un agente idealmente jugaría su mejor estrategia dada aquellas jugadas por los otros agentes.",
        "Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un equilibrio de Nash.",
        "DEFINICIÓN 1.",
        "Un perfil estratégico r = (r1, . . . , rm) constituye un equilibrio de Nash del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
        "Cuando r ∈ A, lo anterior define un equilibrio de Nash de estrategia pura; de lo contrario, la definición describe un equilibrio de Nash de estrategia mixta.",
        "A menudo recurrimos al concepto de un equilibrio aproximado, o equilibrio de Nash, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita.",
        "Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un equilibrio de Nash si (r) ≤ .",
        "En este estudio dedicamos especial atención a los juegos que presentan simetría en cuanto a los pagos, lo que hace que los agentes sean estratégicamente idénticos.",
        "DEFINICIÓN 2.",
        "Un juego [I, {Ri}, {ui(r)}] es simétrico si para todo i, j ∈ I, (a) Ri = Rj y (b) ui(ri, r−i) = uj (rj, r−j) siempre que ri = rj y r−i = r−j.",
        "EL MODELO Modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un juego de dos etapas.",
        "El diseñador comienza seleccionando primero un valor, θ, de un conjunto de configuraciones de mecanismos permitidas, Θ.",
        "Todos los agentes participantes observan el parámetro θ del mecanismo y se mueven simultáneamente después.",
        "Por ejemplo, el diseñador podría estar decidiendo entre mecanismos de subasta de sobre cerrado de precio único y de precio único, con la presunción de que una vez tomada la decisión, los postores participarán con pleno conocimiento de las reglas de la subasta.",
        "Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como Γθ = [I, {Ri}, {ui(r, θ)}].",
        "Nos referimos a Γθ como un juego inducido por θ.",
        "Sea N(θ) el conjunto de perfiles estratégicos considerados soluciones del juego Γθ.3. Supongamos que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, W(r, θ), dependiente del parámetro del mecanismo y del juego resultante, r. Definimos una medida pesimista, W( ˆR, θ) = inf{W(r, θ) : r ∈ ˆR}, que representa el bienestar en el peor de los casos del juego inducido por θ, asumiendo que los agentes juegan alguna estrategia conjunta en ˆR.",
        "Normalmente nos preocupamos por W (N(θ), θ), el resultado en el peor de los casos de jugar alguna solución. En algunos problemas podemos obtener una considerable ventaja al utilizar una función de agregación para mapear el resultado del bienestar de un juego. Generalmente adoptamos el equilibrio de Nash como concepto de solución, y por lo tanto tomamos N(θ) como el conjunto de equilibrios.",
        "Sin embargo, gran parte de la metodología desarrollada aquí podría ser utilizada con criterios alternativos para derivar el comportamiento del agente a partir de una definición del juego. Nuevamente, existen alternativas disponibles.",
        "Por ejemplo, si se tiene una distribución de probabilidad sobre el conjunto de soluciones N(θ), sería natural tomar la expectativa de W(r, θ) en su lugar. 307 especificado en términos de estrategias de agentes a un resultado de bienestar equivalente especificado en términos de un resumen de menor dimensión.",
        "DEFINICIÓN 3.",
        "Una función φ: R1 × · · · × Rm → Rq es una función de agregación si m ≥ q y W(r, θ) = V(φ(r), θ) para alguna función V.",
        "Sobrecargamos el símbolo de función para aplicar a conjuntos de perfiles estratégicos: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
        "Para mayor comodidad en la exposición, escribimos φ∗ (θ) para denotar φ(N(θ)).",
        "El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia.",
        "Por ejemplo, supongamos, como en nuestra aplicación a continuación, que la estrategia de un agente está definida por un parámetro numérico.",
        "Si todo lo que nos importa es el valor total jugado, podemos tomar φ(a) = Πm i=1 ai.",
        "Si hemos elegido nuestro agregador cuidadosamente, también podemos capturar estructuras que de otra manera no serían evidentes.",
        "Por ejemplo, φ∗ (θ) podría estar disminuyendo en θ, mientras que N(θ) podría tener una estructura más compleja.",
        "Dada una descripción de la correspondencia de solución N(θ) (equivalentemente, φ∗(θ)), el diseñador se enfrenta a un problema estándar de optimización.",
        "Alternativamente, dado un simulador que pudiera producir una muestra imparcial de la distribución de W (N(θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12].",
        "Sin embargo, incluso para un juego Γθ con pagos conocidos, puede resultar computacionalmente intratable resolver los equilibrios de Nash, especialmente si el juego tiene conjuntos de estrategias grandes o infinitos.",
        "Además, deseamos estudiar juegos en los que los pagos no se dan explícitamente, sino que deben determinarse a partir de simulaciones u otra experiencia con el juego. Por lo tanto, asumimos que se nos proporciona un conjunto de datos (posiblemente ruidoso) de realizaciones de pagos: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, donde para cada punto de datos θi es el ajuste observado del parámetro del mecanismo, ai es el perfil de estrategia pura observado de los participantes, y Ui es la realización correspondiente de los pagos de los agentes.",
        "También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
        "Sea D = {Do, Ds} el conjunto de datos combinado. (Ya sea que Do o Ds puedan ser nulos para un problema particular).",
        "En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos empíricos de teoría de juegos, para responder preguntas sobre el diseño del escenario TAC/SCM. 4.",
        "ANÁLISIS DE DISEÑO EMPÍRICO Dado que nuestros datos se presentan en forma de experiencia de pago y no como el valor de una función objetivo para configuraciones dadas de la variable de control, ya no podemos confiar en los métodos para optimizar funciones utilizando simulaciones.",
        "De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia del equilibrio de Nash.",
        "Además, no podemos depender directamente de los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilístico adaptados a nuestra configuración de problema. 4.1 Problema de Diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente.",
        "Recuerde que durante el torneo de 2004, los diseñadores del juego de la cadena de suministro optaron por aumentar drásticamente los costos de almacenamiento como medida para frenar las compras del día 0, con poco éxito.",
        "Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y la cantidad agregada de componentes adquiridos el día 0 en equilibrio. Esto suele ser el caso en juegos reales de interés, donde descripciones en lenguaje natural o algorítmicas pueden sustituir a una especificación formal de estrategias y funciones de pago.",
        "Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo.",
        "¿Primero, ¿el aumento de los costos de almacenamiento realmente reduce la adquisición en el día 0?",
        "¿Fue racional la adquisición excesiva observada durante el día 0 del torneo de 2004?",
        "Y en tercer lugar, ¿podría haber reducido de manera suficiente los costos de almacenamiento la adquisición del día 0 a un nivel aceptable, y en tal caso, cuál debería haber sido el ajuste de los costos de almacenamiento?",
        "Es esta tercera pregunta la que define el aspecto del diseño de mecanismos de nuestro análisis. Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de los agentes, la función de bienestar de los diseñadores, el espacio de parámetros del mecanismo y la fuente de datos.",
        "Restringimos las estrategias de los agentes para que sean un multiplicador de la cantidad de solicitudes del día 0 de uno de los finalistas, Deep Maize, en el torneo TAC/SCM de 2004.",
        "Lo restringimos aún más al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias por encima de 1.5 son extremadamente agresivas (por lo tanto, poco probables de proporcionar desviaciones refutadoras más allá de las disponibles en las estrategias incluidas, y ciertamente no forman parte de ningún equilibrio deseable).",
        "Todo otro comportamiento se basa en el comportamiento de Deep Maize y es idéntico para todos los agentes.",
        "Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico.",
        "Sin embargo, creemos que la forma general de los resultados debería ser robusta ante cambios en el comportamiento completo del agente.",
        "Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0.",
        "Sea φ(a) = Σ6 i=1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego particular de la cadena de suministro (para perfiles de estrategia mixta s, tomamos la esperanza de φ con respecto a la mezcla).",
        "La función de bienestar de los diseñadores W (N(θ), θ) se define entonces como I{sup{φ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de adquisición en el día 0 y I es la función indicadora.",
        "El diseñador selecciona un valor θ de costos de almacenamiento, expresado como un porcentaje anual del valor base de los componentes en el inventario (cobrado diariamente), del conjunto Θ = R+.",
        "Dado que la decisión de los diseñadores depende solo de φ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación. 4.2 Estimación de equilibrios de Nash El objetivo de los agentes de TAC/SCM es maximizar los beneficios obtenidos en una instancia del juego.",
        "Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, U(a)).",
        "Si también hemos fijado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de jugadores y sus correspondientes pagos, y, en consecuencia, para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios de Nash de cada juego Γθ.",
        "Por lo tanto, necesitamos métodos para aproximar equilibrios de Nash en juegos infinitos.",
        "A continuación, describimos los dos métodos que utilizamos en nuestro estudio.",
        "El primero ha sido explorado empíricamente anteriormente, mientras que el segundo se introduce aquí como el método específicamente diseñado para aproximar un conjunto de equilibrios de Nash. 4.2.1 Aproximación de la Función de Pago El primer método para estimar equilibrios de Nash basado en datos utiliza aprendizaje supervisado para aproximar las funciones de pago de mech6. No abordamos si y cómo otras medidas (por ejemplo, restringir directamente la adquisición) podrían haber logrado los objetivos de diseño.",
        "Nuestro enfoque considera como dado un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento.",
        "En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con un crecimiento de complejidad correspondiente. 308 participantes del mecanismo de un conjunto de datos de experiencia de juego [17].",
        "Una vez que las funciones de pago aproximadas estén disponibles para todos los jugadores, los equilibrios de Nash pueden encontrarse ya sea de forma analítica o aproximada utilizando técnicas numéricas, dependiendo del modelo de aprendizaje.",
        "En lo que sigue, estimamos solo un equilibrio de Nash de muestra utilizando esta técnica, aunque esta restricción puede eliminarse a expensas de un tiempo de cálculo adicional.",
        "Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador.",
        "Por lo tanto, podemos aplicarlo cuando Ds = ∅.",
        "Si hay un simulador disponible, podemos generar datos adicionales para aumentar la confianza en nuestras estimaciones iniciales. Probamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado local (LWA) y regresión lineal ponderada localmente (LWLR).",
        "También utilizamos variables de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis empírico previo de teoría de juegos de TAC/SCM-03 [19].",
        "El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido de forma analítica.",
        "Para los otros métodos aplicamos dinámica replicadora [7] a una aproximación discreta del juego aprendido.",
        "El total esperado de adquisiciones del día 0 en equilibrio se tomó como la estimación de un resultado. 4.2.2 Búsqueda en el Espacio de Perfiles de Estrategia Cuando tenemos acceso a un simulador, también podemos utilizar la búsqueda dirigida a través del espacio de perfiles para estimar el conjunto de equilibrios de Nash, que describimos aquí después de presentar alguna notación adicional.",
        "DEFINICIÓN 4.",
        "Un vecino estratégico de un perfil de estrategia pura a es un perfil que es idéntico a a en todo menos en una estrategia.",
        "Definimos Snb(a, D) como el conjunto de todos los vecinos estratégicos de a disponibles en el conjunto de datos D. De manera similar, definimos Snb(a, ˜D) como todos los vecinos estratégicos de a que no están en D. Finalmente, para cualquier a ∈ Snb(a, D) definimos al agente que se desvía como i(a, a).",
        "DEFINICIÓN 5.",
        "La -ligadura, ˆ, de un perfil de estrategia pura a se define como maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
        "Decimos que a es un candidato a δ-equilibrio para δ ≥ ˆ.",
        "Cuando Snb(a, ˜D) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), a se confirma como un equilibrio de Nash ˆ.",
        "Nuestro método de búsqueda opera explorando desviaciones de los equilibrios candidatos.",
        "Nos referimos a esto como BestFirstSearch, ya que selecciona con probabilidad uno un perfil de estrategia a ∈ Snb(a, ˜D) que tiene el menor ˆin D. Finalmente definimos un estimador para un conjunto de equilibrios de Nash.",
        "DEFINICIÓN 6.",
        "Para un conjunto K, define Co(K) como la envoltura convexa de K. Sea Bδ el conjunto de candidatos en el nivel δ.",
        "Definimos ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) para un δ fijo como un estimador de φ∗ (θ).",
        "En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles estratégicos agregados con límite inferior -bound por debajo de un δ fijo.",
        "Esta definición nos permite explotar la estructura que surge de la función de agregación.",
        "Si dos perfiles son cercanos en términos de valores de agregación, es probable que tengan límites similares.",
        "En particular, si uno está en equilibrio, el otro también puede estarlo.",
        "Presentamos un respaldo teórico para este método de estimación del conjunto de equilibrios de Nash a continuación.",
        "Dado que el juego en el que estamos interesados es infinito, es necesario terminar BestFirstSearch antes de explorar todo el espacio de strat7. Por ejemplo, podemos utilizar técnicas de aprendizaje activo [5] para mejorar la calidad de la aproximación de la función de recompensa.",
        "En este trabajo, nos concentramos en la búsqueda en el espacio de perfiles estratégicos.",
        "Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos. Generación de datos Nuestros datos fueron recopilados simulando juegos TAC/SCM en una versión local del servidor TAC/SCM de 2004, que tiene una configuración para el costo de almacenamiento.",
        "Las estrategias de los agentes en juegos simulados fueron seleccionadas del conjunto {0, 0.3, 0.6, . . . , 1.5} con el fin de tener una probabilidad positiva de generar vecinos estratégicos. Se generó un conjunto de datos base Do mediante el muestreo de 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}.",
        "Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varios defectos. Utilizamos la búsqueda para generar un conjunto de datos simulados Ds, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ.",
        "Dado que el costo de la simulación es extremadamente alto (un juego tarda casi 1 hora en ejecutarse), pudimos ejecutar un total de 2670 juegos en el transcurso de más de seis meses.",
        "Para hacer una comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategias conjuntas finitas restringidas para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces). 4.4 Resultados 4.4.1 Análisis del conjunto de datos base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos base Do.",
        "Además, generamos una estimación de la correspondencia del equilibrio de Nash, ˆφ∗ (θ), aplicando la Definición 6 con δ = 2.5E6.",
        "Los resultados se muestran en la Figura 1.",
        "Como podemos ver, la correspondencia ˆφ∗ (θ) tiene poco poder predictivo basado en Do, y no revela ninguna estructura interesante sobre el juego.",
        "Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición Total Día 0 LWA LWLR QR BaselineMin BaselineMax Figura 1: Estimaciones de adquisición del día 0 agregadas basadas en Do.",
        "La correspondencia ˆφ∗ (θ) es el intervalo entre BaselineMin y BaselineMax. En general, la búsqueda se detiene una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para obtener conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego. Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash a permanecer en este subconjunto discreto de [0,1.5]. Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron accidentes, problemas de conectividad de red y otras anomalías obvias), el juego sería descartado. Análisis de los datos de búsqueda Para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ∗ (θ) (nuevamente, usando δ =2.5E6) en el conjunto de datos D = {Do, Ds}, donde Ds es datos generados a través de la aplicación de BestFirstSearch.",
        "Los resultados de esta estimación se representan gráficamente frente a los resultados de los métodos de aprendizaje entrenados en Do 11 en la Figura 2.",
        "Primero, observamos que la adición de los datos de búsqueda reduce considerablemente el rango de posibles equilibrios.",
        "Además, las predicciones puntuales reales de los métodos de aprendizaje y aquellas basadas en límites después de la búsqueda son razonablemente cercanas.",
        "Combinar la evidencia recopilada de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquiera de los métodos utilizados de forma aislada. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición del Día 0 LWA LWLR QR Búsqueda Mínima Búsqueda Máxima Figura 2: Estimaciones agregadas de adquisición del día 0 basadas en la búsqueda en el espacio de perfiles de estrategia en comparación con técnicas de aproximación de funciones entrenadas en Do.",
        "La correspondencia ˆφ∗ (θ) para D = {Do, Ds} es el intervalo entre SearchMin y SearchMax.",
        "Esta evidencia respalda la intuición inicial de que la adquisición del día 0 debería disminuir con los costos de almacenamiento.",
        "También confirma que los altos niveles de adquisición en el día 0 son una respuesta racional al entorno del torneo de 2004 con un costo promedio de almacenamiento, que corresponde a θ = 100.",
        "La predicción mínima para la adquisición agregada en este nivel de costos de almacenamiento, dada por cualquier método experimental, es aproximadamente 3.",
        "Esto es bastante alto, ya que corresponde a un compromiso esperado del 1/3 de la capacidad total del proveedor para todo el juego.",
        "La predicción máxima es considerablemente mayor a 4.5.",
        "En la competencia actual de 2004, la adquisición total del día 0 equivalía a 5.71 en la escala utilizada aquí [9].",
        "Nuestras predicciones subestiman este resultado en cierta medida, pero muestran que cualquier resultado racional probablemente tendría una alta adquisición en el día 0. 4.4.3 Extrapolando la Correspondencia de la Solución Tenemos evidencia razonablemente sólida de que la correspondencia del resultado está disminuyendo.",
        "Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento a un valor que reduciría la adquisición del día 0 en equilibrio, o concluir que esto no es posible.",
        "Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día 0. No está claro cuán significativos serían los resultados del aprendizaje si se agregaran Ds al conjunto de datos de entrenamiento.",
        "De hecho, los datos adicionales pueden aumentar realmente la varianza del aprendizaje. Recuerde que el objetivo de los diseñadores es incentivar la adquisición agregada del día 0 que esté por debajo del umbral α.",
        "Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultados estimada a partir de D que produce θ = 320.",
        "Los datos para θ = 320 fueron recopilados de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos por 33 iteraciones de BestFirstSearch.",
        "La Figura 3 muestra los límites detallados para todos los perfiles en términos de sus valores correspondientes de φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Límites de ε de Adquisición Total Día-0 Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320.",
        "Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ(a).",
        "La región gris corresponde a ˆφ∗ (320) con δ = 2.5M.",
        "El conjunto estimado de resultados agregados del día 0 es muy cercano al de θ = 200, lo que indica que hay poco beneficio adicional al aumentar los costos de almacenamiento por encima de 200.",
        "Observa que incluso el límite inferior de nuestro conjunto estimado de equilibrios de Nash está muy por encima de la adquisición objetivo del día 0 de 2.",
        "Además, las recompensas para los agentes son casi siempre negativas en θ = 320.",
        "Por consiguiente, aumentar los costos aún más sería indeseable incluso si finalmente se pudiera reducir la adquisición en el día 0.",
        "Dado que tenemos una confianza razonable de que φ∗ (θ) está disminuyendo en θ, tampoco esperamos que establecer θ en algún lugar entre 200 y 320 logre el resultado deseado.",
        "Concluimos que es poco probable que la adquisición del día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento.",
        "Que nuestras predicciones tienden a subestimar los resultados del torneo refuerza esta conclusión.",
        "Para lograr la reducción deseada en la adquisición del día 0 se requiere rediseñar otros aspectos del mecanismo. 4.5 Análisis Probabilístico Nuestro análisis empírico ha producido evidencia en apoyo a la conclusión de que ninguna configuración razonable del costo de almacenamiento probablemente sería suficiente para frenar la adquisición excesiva del día 0 en TAC/SCM 04.",
        "Toda esta evidencia ha sido en forma de simple interpolación y extrapolación de estimaciones de la correspondencia del equilibrio de Nash.",
        "Estas estimaciones se basan en simular instancias del juego y están sujetas a ruido de muestreo contribuido por los diversos elementos estocásticos del juego.",
        "En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos -bound a tales efectos estocásticos.",
        "Supongamos que todos los agentes tienen conjuntos de estrategias puras finitos (y pequeños), A.",
        "Por lo tanto, es factible muestrear toda la matriz de pagos del juego.",
        "Además, supongamos que el ruido es aditivo con media cero en promedio durante todo el juego, por lo que en la práctica probablemente querríamos que el umbral sea aún más bajo. 310 y varianza finita, es decir, Ui(a) = ui(a) + ˜ξi(a), donde Ui(a) es la ganancia observada para i cuando se jugó a, ui(a) es la ganancia correspondiente real, y ˜ξi(a) es una variable aleatoria normal con media cero.",
        "Designamos la varianza conocida de ˜ξi(a) como σ2 i (a).",
        "Por lo tanto, asumimos que ˜ξi(a) es normal con distribución N(0, σ2 i (a)).",
        "Tomamos ¯ui(a) como la media muestral de todos los Ui(a) en D, y seguimos a Chang y Huang [3] al asumir que tenemos una priori impropia sobre las ganancias reales ui(a) y el muestreo fue independiente para todos i y a.",
        "También confiamos en su resultado de que ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] son independientes con distribuciones posteriores N(¯ui(a), σ2 i (a)/ni(a)), donde ni(a) es el número de muestras tomadas de los pagos para i en el perfil puro a, y Zi(a) ∼ N(0, 1).",
        "Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio de Nash -Nash.",
        "Si ui(·)|¯ui(·) son independientes para todo i ∈ I y a ∈ A, tenemos el siguiente resultado (a partir de este punto omitimos la condición sobre ¯ui(·) por brevedad): PROPOSICIÓN 1.",
        "Para todo \\( i \\in I \\), \\( \\max_{b \\in A_i} u_i(b, a_{-i}) - u_i(a) \\leq \\varepsilon \\), donde \\( \\varepsilon = \\int_{Y_i} \\int_{Z} \\int_{R} \\int_{Y} \\int_{b \\in A_i \\backslash a_i} \\Pr(u_i(b, a_{-i}) \\leq u + \\varepsilon) f_{u_i(a)}(u) du \\), donde \\( f_{u_i(a)}(u) \\) es la función de densidad de probabilidad de \\( N(\\overline{u_i(a)}, \\sigma_i(a)) \\).",
        "Las pruebas de este y todos los resultados posteriores se encuentran en el Apéndice.",
        "La distribución posterior de la media óptima de n muestras, derivada por Chang y Huang [3], es Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) donde a ∈ A y Φ(·) es la función de distribución N(0, 1).",
        "Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilístico que (a) ≤ γ para un γ dado.",
        "Ahora, consideramos casos de datos incompletos y utilizamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en los datos) en la distribución de sup{φ∗ (θ)} e inf{φ∗ (θ)} (asumiendo que ambos son alcanzables): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, donde x es un número real y ≤D indica que el límite superior solo considera estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} y {inf{φ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf{φ∗ (θ)} ≤ x}.",
        "Los valores así derivados comprenden las Tablas 1 y 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Tabla 1: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando N(θ) es un conjunto de equilibrios de Nash. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Tabla 2: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {150, 200, 320} cuando N(θ) es un conjunto de equilibrios de Nash.",
        "Las Tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ(a) < 2.7 es poco probable para cualquier θ del cual tengamos datos, aunque este juicio, como mencionamos, se refiere únicamente a los perfiles que hemos muestreado realmente.",
        "Podemos entonces aceptar esto como otra pieza de evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, parece poco probable que el diseñador logre su objetivo incluso si pudiera persuadir a los participantes a jugar un equilibrio deseable.",
        "La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM de 2004 eran, de hecho, racionales al adquirir grandes cantidades de componentes al comienzo del juego.",
        "Si observamos la tercera columna de esta tabla, que corresponde a θ = 100, podemos deducir que ningún perfil a en nuestros datos con φ(a) < 3 es muy probable que se juegue en equilibrio.",
        "Los límites anteriores proporcionan algunas pruebas generales, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos muestreado.",
        "Particularmente, nos gustaría decir algo sobre lo que sucede en los ajustes de θ para los cuales no tenemos datos.",
        "Para derivar un límite probabilístico aproximado sobre la probabilidad de que ningún θ ∈ Θ haya logrado el objetivo del diseñador, sea ∪J j=1Θj una partición de Θ, y asuma que la función sup{φ∗ (θ)} satisface la condición de Lipschitz con constante de Lipschitz Aj en cada subconjunto Θj. Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a Θ = [0, 320].",
        "Ahora definimos cada subconjunto j como el intervalo entre dos puntos para los cuales hemos producido datos.",
        "Por lo tanto, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], con j variando entre 1 y 5, correspondiendo a los subintervalos anteriores.",
        "Denotaremos cada Θj por (aj, bj]. Luego, la siguiente proposición nos da una cota superior aproximada sobre la probabilidad de que sup{φ∗ (θ)} ≤ α.",
        "PROPOSICIÓN 2.",
        "Debido a que nuestros límites son aproximados, no podemos utilizarlos como una evaluación probabilística concluyente.",
        "En cambio, tomamos esto como otra pieza de evidencia para complementar nuestros hallazgos.",
        "Aunque podamos asumir que una función que aproximamos a partir de datos es Lipschitz continua, rara vez conocemos en realidad la constante de Lipschitz para cualquier subconjunto de Θ.",
        "Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de los datos.",
        "Aquí, probamos tres métodos para hacer esto.",
        "El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subintervalo.",
        "Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo.",
        "Un método alternativo es tomar un límite superior en la pendiente obtenida dentro de cada subintervalo utilizando los datos disponibles.",
        "Esto produce un límite superior de probabilidades mucho menos conservador.",
        "Sin embargo, dado que el límite superior real suele ser mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso.",
        "Un último método que intentamos es un compromiso entre los dos anteriores.",
        "En lugar de tomar el límite superior conservador basado en datos sobre todo el dominio de la función Θ, tomamos el promedio de los límites superiores obtenidos en cada Θj.",
        "El límite en un intervalo se toma como el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos.",
        "Los resultados de evaluar la expresión para Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3.",
        "En términos de nuestras afirmaciones en maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Tabla 3: Límite superior aproximado de la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con un objetivo α = 2.",
        "Se utilizan diferentes métodos para aproximar el límite superior de la pendiente en cada subintervalo j. En este trabajo, la expresión proporciona un límite superior a la probabilidad de que alguna configuración de θ (es decir, costo de almacenamiento) en el intervalo [0,320] resulte en una adquisición total del día 0 que no sea mayor en ningún equilibrio que el objetivo especificado por α y tomado aquí como 2.",
        "Como sospechábamos, el enfoque más conservador para estimar el límite superior de la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí.",
        "Sin embargo, los otros dos enfoques de estimación, encontrados en las columnas dos y tres de la Tabla 3, sugieren que de hecho estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría funcionado.",
        "Dada la tremenda dificultad del problema, este resultado es muy sólido. Aun así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia.",
        "Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y los conjuntos de estrategias).",
        "Tampoco podemos esperar obtener nunca suficiente evidencia para llegar a conclusiones completamente objetivas.",
        "En cambio, el enfoque que defendemos aquí es recopilar la mayor cantidad de evidencia posible dadas las limitaciones de recursos, y tomar la decisión más convincente basada en esta evidencia, si es posible.",
        "RESULTADOS DE CONVERGENCIA En este punto, exploramos abstractamente si una elección de parámetro de diseño basada en datos de pago puede ser asintóticamente confiable. Dado que no teníamos todas las desviaciones posibles para cualquier perfil disponible en los datos, los verdaderos límites superiores pueden ser aún más bajos.",
        "Por conveniencia, utilizaremos la notación un,i(a) para referirnos a una función de pago del jugador i basada en un promedio sobre n muestras i.i.d. de la distribución de pagos.",
        "También asumimos que un,i(a) son independientes para todo a ∈ A e i ∈ I.",
        "Utilizaremos la notación Γn para referirnos al juego [I, R, {ui,n(·)}], mientras que Γ denotará el juego subyacente, [I, R, {ui(·)}].",
        "De manera similar, definimos n(r) como (r) con respecto al juego Γn.",
        "En esta sección, demostramos que n(s) → (s) casi seguramente de forma uniforme en el espacio de estrategias mixtas para cualquier juego finito, y, además, que todas las equilibrios de Nash en estrategias mixtas en juegos empíricos eventualmente se acercan arbitrariamente a algunas estrategias de equilibrio de Nash en el juego subyacente.",
        "Utilizamos estos resultados para demostrar que bajo ciertas condiciones, la elección óptima del parámetro de diseño basada en datos empíricos converge casi seguramente al óptimo real.",
        "TEOREMA 3.",
        "Supongamos que |I| < ∞, |A| < ∞.",
        "Entonces n(s) → (s) casi seguramente uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios de Nash de Γ.",
        "Si definimos Nn,γ = {s ∈ S : n(s) ≤ γ}, tenemos el siguiente corolario del Teorema 3: COROLARIO 4.",
        "Para todo γ > 0, existe un M tal que para todo n ≥ M, N ⊂ Nn,γ casi seguramente.",
        "PRUEBA.",
        "Dado que n(s) = 0 para todo s ∈ N, podemos encontrar un M lo suficientemente grande tal que Pr{supn≥M sups∈N n(s) < γ} = 1.",
        "Según el Corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier > 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios de Nash empíricos si se han tomado suficientes muestras.",
        "Como mostramos ahora, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un límite no nulo como una estimación del conjunto de equilibrios de Nash.",
        "Primero, supongamos que concluimos que para una configuración particular de θ, sup{ˆφ∗ (θ)} ≤ α.",
        "Entonces, dado que para cualquier fijo > 0, N(θ) ⊂ Nn, (θ) cuando n es suficientemente grande, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α para cualquier n de este tipo. Así, dado que definimos la función de bienestar del diseñador como I{sup{φ∗ (θ)} ≤ α} en nuestro dominio de interés, la elección empírica de θ satisface el objetivo del diseñador, maximizando así su función de bienestar.",
        "Alternativamente, supongamos que concluimos que inf{ˆφ∗ (θ)} > α para cada θ en el dominio.",
        "Entonces, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, para todo θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo del diseñador.",
        "Ahora, demostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de Γn está cerca de algún equilibrio de Nash del juego subyacente.",
        "Este resultado nos llevará a considerar la convergencia de los optimizadores basados en datos empíricos a los ajustes óptimos reales de los parámetros del mecanismo.",
        "Primero notamos que la función (s) es continua en un juego finito.",
        "LEMMA 5. \n\nLEMMA 5.",
        "Sea S un conjunto de estrategias mixtas definido en un juego finito.",
        "Entonces: S → R es continua. Para la exposición que sigue, necesitamos un poco de notación adicional.",
        "Primero, sea (Z, d) un espacio métrico, y X, Y ⊂ Z y definamos la distancia de Hausdorff dirigida de X a Y como h(X, Y) = sup x∈X inf y∈Y d(x, y).",
        "Observa que U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
        "Además, define BS(x, δ) como una bola abierta en S ⊂ Z con centro en x ∈ S y radio δ.",
        "Ahora, dejemos que Nn denote todos los equilibrios de Nash del juego Γn y sea Nδ = [ x∈N BS(x, δ), es decir, la unión de bolas abiertas de radio δ con centros en los equilibrios de Nash de Γ.",
        "Ten en cuenta que h(Nδ, N) = δ.",
        "Podemos entonces demostrar el siguiente resultado general.",
        "TEOREMA 6.",
        "Supongamos que |I| < ∞ y |A| < ∞.",
        "Entonces casi con seguridad h(Nn, N) converge a 0.",
        "Ahora demostraremos que en el caso especial cuando Θ y A son finitos y cada Γθ tiene un equilibrio de Nash único, las estimaciones ˆθ del parámetro óptimo del diseñador convergen a un optimizador real casi seguramente.",
        "Sea ˆθ = arg maxθ∈Θ W (Nn(θ), θ), donde n es el número de veces que se muestreó cada perfil puro en Γθ para cada θ, y sea θ∗ = arg maxθ∈Θ W (N(θ), θ).",
        "TEOREMA 7.",
        "Supongamos que |N(θ)| = 1 para todo θ ∈ Θ y supongamos que Θ y A son finitos.",
        "Sea W (s, θ) continua en el único s∗ (θ) ∈ N(θ) para cada θ ∈ Θ.",
        "Entonces ˆθ es un estimador consistente de θ∗ si W (N(θ), θ) se define como un supremo, ínfimo o esperanza sobre el conjunto de equilibrios de Nash.",
        "De hecho, ˆθ → θ∗ casi seguramente en cada uno de estos casos.",
        "La limitación del resultado anterior es que, dentro de nuestro marco de trabajo, el diseñador no tiene forma de saber o asegurar que Γθ tenga equilibrios únicos.",
        "Sin embargo, sí proporciona cierta justificación teórica para seguir el diseño de esta manera, y quizás servirá como guía para obtener resultados más generales en el futuro. 6.",
        "TRABAJO RELACIONADO La literatura de diseño de mecanismos en Economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10].",
        "Además, existe una extensa literatura sobre el diseño óptimo de subastas [10], del cual el trabajo de Roger Myerson [11] es, quizás, el más relevante.",
        "En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y teniendo en cuenta restricciones como la compatibilidad de incentivos y la racionalidad individual.",
        "Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de Ciencias de la Computación.",
        "Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros relevantes del juego son conocimiento común.",
        "Cuando las funciones de pago de los jugadores son desconocidas, se ha explorado la realización de búsquedas mediante simulaciones como alternativa.",
        "Un enfoque en esa dirección, tomado en [4] y [15], es coevolucionar el parámetro del mecanismo y las estrategias de los agentes, utilizando alguna noción de utilidad social y pagos de los agentes como criterios de aptitud.",
        "Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética.",
        "En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron un resultado de un juego inducido por un parámetro del mecanismo como el resultado del aprendizaje conjunto de los agentes.",
        "Más recientemente, Phelps et al. [14] compararon dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en juegos definidos por estrategias heurísticas, como en [18]. 7.",
        "CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el diseño empírico de mecanismos.",
        "Definimos un modelo formal de teoría de juegos de interacción entre el diseñador y los participantes del mecanismo como un juego de dos etapas.",
        "También describimos en cierta generalidad los métodos para estimar una función de equilibrio de Nash de muestra cuando los datos son extremadamente escasos, o una correspondencia de equilibrio de Nash cuando hay más datos disponibles.",
        "Nuestras técnicas están diseñadas específicamente para abordar problemas en los que tanto el espacio de parámetros del mecanismo como los conjuntos de estrategias de los agentes son infinitos y solo se puede adquirir un conjunto de datos relativamente pequeño.",
        "Un problema de diseño difícil en el juego TAC/SCM que la comunidad de TAC ha estado ansiosa por abordar nos brinda un escenario para probar nuestros métodos.",
        "Al aplicar el análisis empírico del juego al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos.",
        "Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia del equilibrio de Nash.",
        "Al final, podemos intentar proporcionar suficiente evidencia para prescribir una configuración de parámetros, o sugerir que no es posible encontrar una configuración que satisfaga al diseñador.",
        "En el caso de TAC/SCM, nuestra evidencia sugiere bastante claramente que el costo de almacenamiento no pudo haber sido ajustado de manera efectiva en el torneo de 2004 para frenar la adquisición excesiva del día 0 sin efectos perjudiciales en la rentabilidad general.",
        "El éxito de nuestro análisis en este entorno extremadamente complejo con altos costos de simulación nos hace ser optimistas de que nuestros métodos pueden brindar orientación en la toma de decisiones de diseño de mecanismos en otros dominios desafiantes.",
        "Los resultados teóricos confirman algunas intuiciones detrás de los métodos de diseño de mecanismos empíricos que hemos introducido, y aumentan nuestra confianza en que nuestro marco puede ser efectivo para estimar la mejor elección de parámetros del mecanismo en entornos relativamente generales.",
        "Agradecimientos Agradecemos a Terence Kelly, Matthew Rudary y Satinder Singh por sus útiles comentarios sobre versiones anteriores de este trabajo.",
        "Este trabajo fue apoyado en parte por la subvención de la NSF IIS-0205435 y el programa de razonamiento estratégico DARPA REAL. 8.",
        "REFERENCIAS [1] R. Arunachalam y N. M. Sadeh.",
        "La competencia de agentes de comercio de la cadena de suministro.",
        "Investigación y aplicaciones del comercio electrónico, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy y M. Tschantz.",
        "Un enfoque de programación estocástica para la planificación en TAC SCM.",
        "En la Quinta Conferencia ACM sobre Comercio Electrónico, páginas 152-159, Nueva York, 2004. [3] Y.-P. Chang y W.-T. Huang.",
        "Intervalos de confianza generalizados para el valor más grande de algunas funciones de parámetros bajo normalidad.",
        "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.\nEstadística Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
        "Evolución del mecanismo de mercado a través de un espacio continuo de tipos de subasta.",
        "En el Congreso de Computación Evolutiva de 2002. [5] D. A. Cohn, Z. Ghahramani y M. I. Jordan.",
        "Aprendizaje activo con modelos estadísticos.",
        "Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [6] V. Conitzer y T. Sandholm.",
        "Un algoritmo para diseñar automáticamente mecanismos determinísticos sin pagos.",
        "En la Tercera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagente, páginas 128-135, 2004. [7] D. Friedman.",
        "Juegos evolutivos en economía.",
        "Econometrica, 59(3):637-666, mayo de 1991. [8] R. Keener.",
        "Teoría Estadística: Una Mezcla de Temas Fundamentales.",
        "Departamento de Estadística de la Universidad de Michigan, 2004. [9] C. Kiekintveld, Y. Vorobeychik y M. P. Wellman.",
        "Un análisis de la competencia de agentes comerciales de gestión de la cadena de suministro de 2004.",
        "En el taller IJCAI-05 sobre Diseño y Análisis de Agentes de Negociación, Edimburgo, 2005. [10] A. Mas-Colell, M. Whinston y J.",
        "Verde.",
        "Teoría microeconómica.",
        "Oxford University Press, 1995. [11] R. B. Myerson.\nEditorial de la Universidad de Oxford, 1995. [11] R. B. Myerson.",
        "Diseño óptimo de subasta.",
        "Matemáticas de la Investigación de Operaciones, 6(1):58-73, febrero de 1981. [12] S. Olafsson y J. Kim.",
        "Optimización de simulación.",
        "En E. Yucesan, C.-H. Chen, J. Snowdon y J. Charnes, editores, Conferencia de Simulación de Invierno 2002, 2002. [13] D. Pardoe y P. Stone.",
        "TacTex-03: Un agente de gestión de la cadena de suministro.",
        "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, y P. McBurney.",
        "Agentes automatizados versus humanos virtuales: una comparación teórica evolutiva de dos diseños de mercado de subasta doble.",
        "En Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney y E. Sklar.",
        "Co-evolución de mecanismos de subasta y estrategias de negociación: hacia un enfoque novedoso para el diseño microeconómico.",
        "En el taller ECOMAS 2002, 2002. [16] S. Phelps, S. Parsons, E. Sklar y P. McBurney.",
        "Utilizando programación genética para optimizar reglas de precios para un mercado de subasta doble.",
        "En Taller sobre Agentes para el Comercio Electrónico, 2003. [17] Y. Vorobeychik, M. P. Wellman y S. Singh.",
        "Aprendiendo funciones de pago en juegos infinitos.",
        "En la Decimonovena Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro y J. O. Kephart.",
        "Analizando interacciones estratégicas complejas en sistemas multiagente.",
        "En el taller AAAI-02 sobre agentes teóricos de juegos y de toma de decisiones, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld y V. Soni.",
        "Interacciones estratégicas en un juego de cadena de suministro.",
        "Inteligencia Computacional, 21(1):1-26, febrero de 2005.",
        "APÉNDICE A.",
        "PRUEBAS A.1 Prueba de la Proposición 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
        "A.2 Prueba de la Proposición 2 Primero, supongamos que alguna función, f(x), definida en [ai, bi], satisface la condición de Lipschitz en (ai, bi] con una constante de Lipschitz Ai.",
        "Entonces se cumple la siguiente afirmación: Afirmación: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
        "Para demostrar esta afirmación, observe que la intersección de las líneas en f(ai) y f(bi) con pendientes -Ai y Ai respectivamente determinará el límite inferior del mínimo de f(x) en [ai, bi] (que es un límite inferior del ínfimo de f(x) en (ai, bj]).",
        "La línea en f(ai) está determinada por f(ai) = −Aiai + cL y la línea en f(bi) está determinada por f(bi) = Aibi + cR.",
        "Por lo tanto, las intercepciones son cL = f(ai) + Aiai y cR = f(bi) + Aibi respectivamente.",
        "Sea x∗ el punto en el que estas líneas se cruzan.",
        "Entonces, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A.",
        "Al sustituir las expresiones de cR y cL, obtenemos el resultado deseado.",
        "Ahora, la subaditividad nos da Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, y, por la afirmación, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
        "Dado que tenemos un número finito de puntos en el conjunto de datos para cada θ, podemos obtener la siguiente expresión: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
        "Ahora podemos restringir nuestra atención en obtener una cota superior en Pr{sup{φ∗ (θ)} = y} para un θ fijo.",
        "Para hacer esto, observe que Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} por subaditividad y el hecho de que un perfil a es un equilibrio de Nash si y solo si (a) = 0.",
        "Poner todo junto produce el resultado deseado.",
        "Prueba de Teorema 3 En primer lugar, necesitaremos el siguiente hecho: Afirmación: Dada una función fi(x) y un conjunto X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
        "Para demostrar esta afirmación, observe que | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) si maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) si maxx f2(x) ≥ maxx f1(x) En el primer caso, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 De manera similar, en el segundo caso, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
        "Por lo tanto, la afirmación se mantiene.",
        "Por la Ley Fuerte de los Grandes Números, un,i(a) → ui(a) casi seguramente para todo i ∈ I, a ∈ A.",
        "Es decir, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, o, equivalentemente [8], para cualquier α > 0 y δ > 0, existe M(i, a) > 0 tal que Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
        "Al tomar M = maxi∈I maxa∈A M(i, a), tenemos que Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
        "Así, por la afirmación, para cualquier n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ con una probabilidad de al menos 1 − α.",
        "Ten en cuenta que dado que s−i(a) y s(a) están acotados entre 0 y 1, pudimos eliminarlos de las expresiones anteriores para obtener una cota que será válida independientemente de la elección particular de s. Además, dado que el resultado anterior se puede obtener para un α arbitrario > 0 y δ > 0, tenemos que Pr{limn→∞ n(s) = (s)} = 1 uniformemente en S. A.4 Prueba del Lema 5 Demostramos el resultado utilizando la continuidad uniforme de ui(s) y la preservación de la continuidad bajo el máximo.",
        "Afirmación: Una función f : Rk → R definida por f(t) = Σi=1k zi ti, donde zi son constantes en R, es uniformemente continua en t. La afirmación se sigue porque |f(t)−f(t )| = | Σi=1k zi(ti−ti)| ≤ Σi=1k |zi||ti − ti|.",
        "Un resultado inmediato de esto para nuestros propósitos es que ui(s) es uniformemente continua en s y ui(ai, s−i) es uniformemente continua en s−i.",
        "Afirmación: Sea f(a, b) uniformemente continua en b ∈ B para cada a ∈ A, con |A| < ∞.",
        "Entonces V (b) = maxa∈A f(a, b) es uniformemente continua en b.",
        "Para demostrar esto, toma γ > 0 y deja que b, b ∈ B tal que b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
        "Ahora toma δ = mina∈A δ(a).",
        "Entonces, cada vez que b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
        "Ahora, recuerda que (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
        "Según las afirmaciones anteriores, maxai∈Ai ui(ai, s−i) es uniformemente continua en s−i y ui(s) es uniformemente continua en s. Dado que la diferencia de dos funciones uniformemente continuas es uniformemente continua, y dado que esta continuidad se conserva bajo el máximo según nuestra segunda afirmación, obtenemos el resultado deseado.",
        "Prueba de Teorema 6. Elija δ > 0.",
        "Primero, necesitamos asegurarnos de que se cumple la siguiente afirmación: Afirmación: ¯ = mins∈S\\Nδ (s) existe y ¯ > 0.",
        "Dado que Nδ es un subconjunto abierto de S compacto, se sigue que S \\ Nδ es compacto.",
        "Como también habíamos demostrado en el Lema 5 que (s) es continua, la existencia se sigue del teorema de Weierstrass.",
        "Es claro que ¯ > 0 ya que (s) = 0 si y solo si s es un equilibrio de Nash de Γ.",
        "Ahora, por el Teorema 3, para cualquier α > 0 existe un M tal que Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. En consecuencia, para cualquier δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
        "Dado que esto se cumple para un α arbitrario > 0 y δ > 0, se obtiene el resultado deseado.",
        "Prueba de Teorema 7. Fija θ y elige δ > 0.",
        "Dado que W (s, θ) es continua en s∗ (θ), dado > 0 existe δ > 0 tal que para cada s que esté dentro de δ de s∗ (θ), |W (s, θ) - W (s∗ (θ), θ)| < .",
        "Según el Teorema 6, podemos encontrar M(θ) lo suficientemente grande para que todos los s ∈ Nn estén dentro de δ de s∗ (θ) para todo n ≥ M(θ) con probabilidad 1.",
        "Por consiguiente, para cualquier > 0 podemos encontrar M(θ) lo suficientemente grande tal que con probabilidad 1 tengamos supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
        "Asumamos sin pérdida de generalidad que hay una elección óptima única de θ.",
        "Ahora, dado que el conjunto Θ es finito, también existe la segunda mejor opción de θ (si solo hay un θ ∈ Θ, esta discusión no tiene sentido de todos modos): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
        "Supongamos sin pérdida de generalidad que θ∗∗ también es único y sea ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
        "Entonces, si dejamos < ∆/2 y dejamos que M = maxθ∈Θ M(θ), donde cada M(θ) es lo suficientemente grande como para que supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., la elección óptima de θ basada en cualquier equilibrio empírico será θ∗ con probabilidad 1.",
        "Por lo tanto, en particular, dado cualquier distribución de probabilidad sobre equilibrios empíricos, la mejor elección de θ será θ∗ con probabilidad 1 (similarmente, si tomamos el supremo o el ínfimo de W (Nn(θ), θ) sobre el conjunto de equilibrios empíricos al construir la función objetivo)."
    ],
    "error_count": 2,
    "keys": {
        "outcome features of interest": {
            "translated_key": "características del resultado de interés",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate <br>outcome features of interest</br> as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate <br>outcome features of interest</br> as a function of mechanism parameter settings."
            ],
            "translated_annotated_samples": [
                "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las <br>características del resultado de interés</br> como una función de la configuración de los parámetros del mecanismo."
            ],
            "translated_text": "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las <br>características del resultado de interés</br> como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismos empíricos. En la continuación, desarrollamos algunos métodos generales para el diseño empírico de mecanismos y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto. En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2. Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores. Ri es el conjunto de estrategias disponibles para el jugador i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×. . .×Am. A menudo es conveniente referirse a la estrategia del jugador i por separado de la de los demás jugadores. Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama un perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i). Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el jugador i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada jugador i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i. Podemos extender esta definición a estrategias mixtas asumiendo que ui son utilidades de von Neumann-Morgenstern (vNM) de la siguiente manera: ui(s) = Es[ui], donde Es es la expectativa tomada con respecto a la distribución de probabilidad del juego inducida por la estrategia mixta de los jugadores s. Al emplear la forma normal, modelamos a los agentes jugando una única acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones más detalladas sobre la acción a lo largo del tiempo en la forma extensiva. Aunque cualquier juego extenso puede ser reformulado en forma normal, hacerlo puede sacrificar la concisión y difuminar distinciones relevantes (por ejemplo, la perfección en subjuegos). Ocasionalmente, escribimos ui(x, y) para indicar que x ∈ Ai o Si y y ∈ A−i o S−i dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u(·) = {u1(·), . . . , um(·)}. Definimos una función, : R → R, interpretada como el beneficio máximo que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) donde r pertenece a algún conjunto de estrategias, R, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada aquellas jugadas por los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un equilibrio de Nash. DEFINICIÓN 1. Un perfil estratégico r = (r1, . . . , rm) constituye un equilibrio de Nash del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). Cuando r ∈ A, lo anterior define un equilibrio de Nash de estrategia pura; de lo contrario, la definición describe un equilibrio de Nash de estrategia mixta. A menudo recurrimos al concepto de un equilibrio aproximado, o equilibrio de Nash, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita. Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un equilibrio de Nash si (r) ≤ . En este estudio dedicamos especial atención a los juegos que presentan simetría en cuanto a los pagos, lo que hace que los agentes sean estratégicamente idénticos. DEFINICIÓN 2. Un juego [I, {Ri}, {ui(r)}] es simétrico si para todo i, j ∈ I, (a) Ri = Rj y (b) ui(ri, r−i) = uj (rj, r−j) siempre que ri = rj y r−i = r−j. EL MODELO Modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un juego de dos etapas. El diseñador comienza seleccionando primero un valor, θ, de un conjunto de configuraciones de mecanismos permitidas, Θ. Todos los agentes participantes observan el parámetro θ del mecanismo y se mueven simultáneamente después. Por ejemplo, el diseñador podría estar decidiendo entre mecanismos de subasta de sobre cerrado de precio único y de precio único, con la presunción de que una vez tomada la decisión, los postores participarán con pleno conocimiento de las reglas de la subasta. Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como Γθ = [I, {Ri}, {ui(r, θ)}]. Nos referimos a Γθ como un juego inducido por θ. Sea N(θ) el conjunto de perfiles estratégicos considerados soluciones del juego Γθ.3. Supongamos que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, W(r, θ), dependiente del parámetro del mecanismo y del juego resultante, r. Definimos una medida pesimista, W( ˆR, θ) = inf{W(r, θ) : r ∈ ˆR}, que representa el bienestar en el peor de los casos del juego inducido por θ, asumiendo que los agentes juegan alguna estrategia conjunta en ˆR. Normalmente nos preocupamos por W (N(θ), θ), el resultado en el peor de los casos de jugar alguna solución. En algunos problemas podemos obtener una considerable ventaja al utilizar una función de agregación para mapear el resultado del bienestar de un juego. Generalmente adoptamos el equilibrio de Nash como concepto de solución, y por lo tanto tomamos N(θ) como el conjunto de equilibrios. Sin embargo, gran parte de la metodología desarrollada aquí podría ser utilizada con criterios alternativos para derivar el comportamiento del agente a partir de una definición del juego. Nuevamente, existen alternativas disponibles. Por ejemplo, si se tiene una distribución de probabilidad sobre el conjunto de soluciones N(θ), sería natural tomar la expectativa de W(r, θ) en su lugar. 307 especificado en términos de estrategias de agentes a un resultado de bienestar equivalente especificado en términos de un resumen de menor dimensión. DEFINICIÓN 3. Una función φ: R1 × · · · × Rm → Rq es una función de agregación si m ≥ q y W(r, θ) = V(φ(r), θ) para alguna función V. Sobrecargamos el símbolo de función para aplicar a conjuntos de perfiles estratégicos: φ( ˆR) = {φ(r) : r ∈ ˆR}. Para mayor comodidad en la exposición, escribimos φ∗ (θ) para denotar φ(N(θ)). El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia. Por ejemplo, supongamos, como en nuestra aplicación a continuación, que la estrategia de un agente está definida por un parámetro numérico. Si todo lo que nos importa es el valor total jugado, podemos tomar φ(a) = Πm i=1 ai. Si hemos elegido nuestro agregador cuidadosamente, también podemos capturar estructuras que de otra manera no serían evidentes. Por ejemplo, φ∗ (θ) podría estar disminuyendo en θ, mientras que N(θ) podría tener una estructura más compleja. Dada una descripción de la correspondencia de solución N(θ) (equivalentemente, φ∗(θ)), el diseñador se enfrenta a un problema estándar de optimización. Alternativamente, dado un simulador que pudiera producir una muestra imparcial de la distribución de W (N(θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12]. Sin embargo, incluso para un juego Γθ con pagos conocidos, puede resultar computacionalmente intratable resolver los equilibrios de Nash, especialmente si el juego tiene conjuntos de estrategias grandes o infinitos. Además, deseamos estudiar juegos en los que los pagos no se dan explícitamente, sino que deben determinarse a partir de simulaciones u otra experiencia con el juego. Por lo tanto, asumimos que se nos proporciona un conjunto de datos (posiblemente ruidoso) de realizaciones de pagos: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, donde para cada punto de datos θi es el ajuste observado del parámetro del mecanismo, ai es el perfil de estrategia pura observado de los participantes, y Ui es la realización correspondiente de los pagos de los agentes. También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}. Sea D = {Do, Ds} el conjunto de datos combinado. (Ya sea que Do o Ds puedan ser nulos para un problema particular). En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos empíricos de teoría de juegos, para responder preguntas sobre el diseño del escenario TAC/SCM. 4. ANÁLISIS DE DISEÑO EMPÍRICO Dado que nuestros datos se presentan en forma de experiencia de pago y no como el valor de una función objetivo para configuraciones dadas de la variable de control, ya no podemos confiar en los métodos para optimizar funciones utilizando simulaciones. De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia del equilibrio de Nash. Además, no podemos depender directamente de los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilístico adaptados a nuestra configuración de problema. 4.1 Problema de Diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente. Recuerde que durante el torneo de 2004, los diseñadores del juego de la cadena de suministro optaron por aumentar drásticamente los costos de almacenamiento como medida para frenar las compras del día 0, con poco éxito. Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y la cantidad agregada de componentes adquiridos el día 0 en equilibrio. Esto suele ser el caso en juegos reales de interés, donde descripciones en lenguaje natural o algorítmicas pueden sustituir a una especificación formal de estrategias y funciones de pago. Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo. ¿Primero, ¿el aumento de los costos de almacenamiento realmente reduce la adquisición en el día 0? ¿Fue racional la adquisición excesiva observada durante el día 0 del torneo de 2004? Y en tercer lugar, ¿podría haber reducido de manera suficiente los costos de almacenamiento la adquisición del día 0 a un nivel aceptable, y en tal caso, cuál debería haber sido el ajuste de los costos de almacenamiento? Es esta tercera pregunta la que define el aspecto del diseño de mecanismos de nuestro análisis. Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de los agentes, la función de bienestar de los diseñadores, el espacio de parámetros del mecanismo y la fuente de datos. Restringimos las estrategias de los agentes para que sean un multiplicador de la cantidad de solicitudes del día 0 de uno de los finalistas, Deep Maize, en el torneo TAC/SCM de 2004. Lo restringimos aún más al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias por encima de 1.5 son extremadamente agresivas (por lo tanto, poco probables de proporcionar desviaciones refutadoras más allá de las disponibles en las estrategias incluidas, y ciertamente no forman parte de ningún equilibrio deseable). Todo otro comportamiento se basa en el comportamiento de Deep Maize y es idéntico para todos los agentes. Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico. Sin embargo, creemos que la forma general de los resultados debería ser robusta ante cambios en el comportamiento completo del agente. Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0. Sea φ(a) = Σ6 i=1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego particular de la cadena de suministro (para perfiles de estrategia mixta s, tomamos la esperanza de φ con respecto a la mezcla). La función de bienestar de los diseñadores W (N(θ), θ) se define entonces como I{sup{φ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de adquisición en el día 0 y I es la función indicadora. El diseñador selecciona un valor θ de costos de almacenamiento, expresado como un porcentaje anual del valor base de los componentes en el inventario (cobrado diariamente), del conjunto Θ = R+. Dado que la decisión de los diseñadores depende solo de φ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación. 4.2 Estimación de equilibrios de Nash El objetivo de los agentes de TAC/SCM es maximizar los beneficios obtenidos en una instancia del juego. Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, U(a)). Si también hemos fijado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de jugadores y sus correspondientes pagos, y, en consecuencia, para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios de Nash de cada juego Γθ. Por lo tanto, necesitamos métodos para aproximar equilibrios de Nash en juegos infinitos. A continuación, describimos los dos métodos que utilizamos en nuestro estudio. El primero ha sido explorado empíricamente anteriormente, mientras que el segundo se introduce aquí como el método específicamente diseñado para aproximar un conjunto de equilibrios de Nash. 4.2.1 Aproximación de la Función de Pago El primer método para estimar equilibrios de Nash basado en datos utiliza aprendizaje supervisado para aproximar las funciones de pago de mech6. No abordamos si y cómo otras medidas (por ejemplo, restringir directamente la adquisición) podrían haber logrado los objetivos de diseño. Nuestro enfoque considera como dado un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento. En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con un crecimiento de complejidad correspondiente. 308 participantes del mecanismo de un conjunto de datos de experiencia de juego [17]. Una vez que las funciones de pago aproximadas estén disponibles para todos los jugadores, los equilibrios de Nash pueden encontrarse ya sea de forma analítica o aproximada utilizando técnicas numéricas, dependiendo del modelo de aprendizaje. En lo que sigue, estimamos solo un equilibrio de Nash de muestra utilizando esta técnica, aunque esta restricción puede eliminarse a expensas de un tiempo de cálculo adicional. Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador. Por lo tanto, podemos aplicarlo cuando Ds = ∅. Si hay un simulador disponible, podemos generar datos adicionales para aumentar la confianza en nuestras estimaciones iniciales. Probamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado local (LWA) y regresión lineal ponderada localmente (LWLR). También utilizamos variables de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis empírico previo de teoría de juegos de TAC/SCM-03 [19]. El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido de forma analítica. Para los otros métodos aplicamos dinámica replicadora [7] a una aproximación discreta del juego aprendido. El total esperado de adquisiciones del día 0 en equilibrio se tomó como la estimación de un resultado. 4.2.2 Búsqueda en el Espacio de Perfiles de Estrategia Cuando tenemos acceso a un simulador, también podemos utilizar la búsqueda dirigida a través del espacio de perfiles para estimar el conjunto de equilibrios de Nash, que describimos aquí después de presentar alguna notación adicional. DEFINICIÓN 4. Un vecino estratégico de un perfil de estrategia pura a es un perfil que es idéntico a a en todo menos en una estrategia. Definimos Snb(a, D) como el conjunto de todos los vecinos estratégicos de a disponibles en el conjunto de datos D. De manera similar, definimos Snb(a, ˜D) como todos los vecinos estratégicos de a que no están en D. Finalmente, para cualquier a ∈ Snb(a, D) definimos al agente que se desvía como i(a, a). DEFINICIÓN 5. La -ligadura, ˆ, de un perfil de estrategia pura a se define como maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}. Decimos que a es un candidato a δ-equilibrio para δ ≥ ˆ. Cuando Snb(a, ˜D) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), a se confirma como un equilibrio de Nash ˆ. Nuestro método de búsqueda opera explorando desviaciones de los equilibrios candidatos. Nos referimos a esto como BestFirstSearch, ya que selecciona con probabilidad uno un perfil de estrategia a ∈ Snb(a, ˜D) que tiene el menor ˆin D. Finalmente definimos un estimador para un conjunto de equilibrios de Nash. DEFINICIÓN 6. Para un conjunto K, define Co(K) como la envoltura convexa de K. Sea Bδ el conjunto de candidatos en el nivel δ. Definimos ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) para un δ fijo como un estimador de φ∗ (θ). En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles estratégicos agregados con límite inferior -bound por debajo de un δ fijo. Esta definición nos permite explotar la estructura que surge de la función de agregación. Si dos perfiles son cercanos en términos de valores de agregación, es probable que tengan límites similares. En particular, si uno está en equilibrio, el otro también puede estarlo. Presentamos un respaldo teórico para este método de estimación del conjunto de equilibrios de Nash a continuación. Dado que el juego en el que estamos interesados es infinito, es necesario terminar BestFirstSearch antes de explorar todo el espacio de strat7. Por ejemplo, podemos utilizar técnicas de aprendizaje activo [5] para mejorar la calidad de la aproximación de la función de recompensa. En este trabajo, nos concentramos en la búsqueda en el espacio de perfiles estratégicos. Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos. Generación de datos Nuestros datos fueron recopilados simulando juegos TAC/SCM en una versión local del servidor TAC/SCM de 2004, que tiene una configuración para el costo de almacenamiento. Las estrategias de los agentes en juegos simulados fueron seleccionadas del conjunto {0, 0.3, 0.6, . . . , 1.5} con el fin de tener una probabilidad positiva de generar vecinos estratégicos. Se generó un conjunto de datos base Do mediante el muestreo de 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}. Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varios defectos. Utilizamos la búsqueda para generar un conjunto de datos simulados Ds, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ. Dado que el costo de la simulación es extremadamente alto (un juego tarda casi 1 hora en ejecutarse), pudimos ejecutar un total de 2670 juegos en el transcurso de más de seis meses. Para hacer una comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategias conjuntas finitas restringidas para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces). 4.4 Resultados 4.4.1 Análisis del conjunto de datos base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos base Do. Además, generamos una estimación de la correspondencia del equilibrio de Nash, ˆφ∗ (θ), aplicando la Definición 6 con δ = 2.5E6. Los resultados se muestran en la Figura 1. Como podemos ver, la correspondencia ˆφ∗ (θ) tiene poco poder predictivo basado en Do, y no revela ninguna estructura interesante sobre el juego. Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición Total Día 0 LWA LWLR QR BaselineMin BaselineMax Figura 1: Estimaciones de adquisición del día 0 agregadas basadas en Do. La correspondencia ˆφ∗ (θ) es el intervalo entre BaselineMin y BaselineMax. En general, la búsqueda se detiene una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para obtener conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego. Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash a permanecer en este subconjunto discreto de [0,1.5]. Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron accidentes, problemas de conectividad de red y otras anomalías obvias), el juego sería descartado. Análisis de los datos de búsqueda Para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ∗ (θ) (nuevamente, usando δ =2.5E6) en el conjunto de datos D = {Do, Ds}, donde Ds es datos generados a través de la aplicación de BestFirstSearch. Los resultados de esta estimación se representan gráficamente frente a los resultados de los métodos de aprendizaje entrenados en Do 11 en la Figura 2. Primero, observamos que la adición de los datos de búsqueda reduce considerablemente el rango de posibles equilibrios. Además, las predicciones puntuales reales de los métodos de aprendizaje y aquellas basadas en límites después de la búsqueda son razonablemente cercanas. Combinar la evidencia recopilada de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquiera de los métodos utilizados de forma aislada. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición del Día 0 LWA LWLR QR Búsqueda Mínima Búsqueda Máxima Figura 2: Estimaciones agregadas de adquisición del día 0 basadas en la búsqueda en el espacio de perfiles de estrategia en comparación con técnicas de aproximación de funciones entrenadas en Do. La correspondencia ˆφ∗ (θ) para D = {Do, Ds} es el intervalo entre SearchMin y SearchMax. Esta evidencia respalda la intuición inicial de que la adquisición del día 0 debería disminuir con los costos de almacenamiento. También confirma que los altos niveles de adquisición en el día 0 son una respuesta racional al entorno del torneo de 2004 con un costo promedio de almacenamiento, que corresponde a θ = 100. La predicción mínima para la adquisición agregada en este nivel de costos de almacenamiento, dada por cualquier método experimental, es aproximadamente 3. Esto es bastante alto, ya que corresponde a un compromiso esperado del 1/3 de la capacidad total del proveedor para todo el juego. La predicción máxima es considerablemente mayor a 4.5. En la competencia actual de 2004, la adquisición total del día 0 equivalía a 5.71 en la escala utilizada aquí [9]. Nuestras predicciones subestiman este resultado en cierta medida, pero muestran que cualquier resultado racional probablemente tendría una alta adquisición en el día 0. 4.4.3 Extrapolando la Correspondencia de la Solución Tenemos evidencia razonablemente sólida de que la correspondencia del resultado está disminuyendo. Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento a un valor que reduciría la adquisición del día 0 en equilibrio, o concluir que esto no es posible. Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día 0. No está claro cuán significativos serían los resultados del aprendizaje si se agregaran Ds al conjunto de datos de entrenamiento. De hecho, los datos adicionales pueden aumentar realmente la varianza del aprendizaje. Recuerde que el objetivo de los diseñadores es incentivar la adquisición agregada del día 0 que esté por debajo del umbral α. Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultados estimada a partir de D que produce θ = 320. Los datos para θ = 320 fueron recopilados de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos por 33 iteraciones de BestFirstSearch. La Figura 3 muestra los límites detallados para todos los perfiles en términos de sus valores correspondientes de φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Límites de ε de Adquisición Total Día-0 Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320. Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ(a). La región gris corresponde a ˆφ∗ (320) con δ = 2.5M. El conjunto estimado de resultados agregados del día 0 es muy cercano al de θ = 200, lo que indica que hay poco beneficio adicional al aumentar los costos de almacenamiento por encima de 200. Observa que incluso el límite inferior de nuestro conjunto estimado de equilibrios de Nash está muy por encima de la adquisición objetivo del día 0 de 2. Además, las recompensas para los agentes son casi siempre negativas en θ = 320. Por consiguiente, aumentar los costos aún más sería indeseable incluso si finalmente se pudiera reducir la adquisición en el día 0. Dado que tenemos una confianza razonable de que φ∗ (θ) está disminuyendo en θ, tampoco esperamos que establecer θ en algún lugar entre 200 y 320 logre el resultado deseado. Concluimos que es poco probable que la adquisición del día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento. Que nuestras predicciones tienden a subestimar los resultados del torneo refuerza esta conclusión. Para lograr la reducción deseada en la adquisición del día 0 se requiere rediseñar otros aspectos del mecanismo. 4.5 Análisis Probabilístico Nuestro análisis empírico ha producido evidencia en apoyo a la conclusión de que ninguna configuración razonable del costo de almacenamiento probablemente sería suficiente para frenar la adquisición excesiva del día 0 en TAC/SCM 04. Toda esta evidencia ha sido en forma de simple interpolación y extrapolación de estimaciones de la correspondencia del equilibrio de Nash. Estas estimaciones se basan en simular instancias del juego y están sujetas a ruido de muestreo contribuido por los diversos elementos estocásticos del juego. En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos -bound a tales efectos estocásticos. Supongamos que todos los agentes tienen conjuntos de estrategias puras finitos (y pequeños), A. Por lo tanto, es factible muestrear toda la matriz de pagos del juego. Además, supongamos que el ruido es aditivo con media cero en promedio durante todo el juego, por lo que en la práctica probablemente querríamos que el umbral sea aún más bajo. 310 y varianza finita, es decir, Ui(a) = ui(a) + ˜ξi(a), donde Ui(a) es la ganancia observada para i cuando se jugó a, ui(a) es la ganancia correspondiente real, y ˜ξi(a) es una variable aleatoria normal con media cero. Designamos la varianza conocida de ˜ξi(a) como σ2 i (a). Por lo tanto, asumimos que ˜ξi(a) es normal con distribución N(0, σ2 i (a)). Tomamos ¯ui(a) como la media muestral de todos los Ui(a) en D, y seguimos a Chang y Huang [3] al asumir que tenemos una priori impropia sobre las ganancias reales ui(a) y el muestreo fue independiente para todos i y a. También confiamos en su resultado de que ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] son independientes con distribuciones posteriores N(¯ui(a), σ2 i (a)/ni(a)), donde ni(a) es el número de muestras tomadas de los pagos para i en el perfil puro a, y Zi(a) ∼ N(0, 1). Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio de Nash -Nash. Si ui(·)|¯ui(·) son independientes para todo i ∈ I y a ∈ A, tenemos el siguiente resultado (a partir de este punto omitimos la condición sobre ¯ui(·) por brevedad): PROPOSICIÓN 1. Para todo \\( i \\in I \\), \\( \\max_{b \\in A_i} u_i(b, a_{-i}) - u_i(a) \\leq \\varepsilon \\), donde \\( \\varepsilon = \\int_{Y_i} \\int_{Z} \\int_{R} \\int_{Y} \\int_{b \\in A_i \\backslash a_i} \\Pr(u_i(b, a_{-i}) \\leq u + \\varepsilon) f_{u_i(a)}(u) du \\), donde \\( f_{u_i(a)}(u) \\) es la función de densidad de probabilidad de \\( N(\\overline{u_i(a)}, \\sigma_i(a)) \\). Las pruebas de este y todos los resultados posteriores se encuentran en el Apéndice. La distribución posterior de la media óptima de n muestras, derivada por Chang y Huang [3], es Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) donde a ∈ A y Φ(·) es la función de distribución N(0, 1). Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilístico que (a) ≤ γ para un γ dado. Ahora, consideramos casos de datos incompletos y utilizamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en los datos) en la distribución de sup{φ∗ (θ)} e inf{φ∗ (θ)} (asumiendo que ambos son alcanzables): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, donde x es un número real y ≤D indica que el límite superior solo considera estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} y {inf{φ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf{φ∗ (θ)} ≤ x}. Los valores así derivados comprenden las Tablas 1 y 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Tabla 1: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando N(θ) es un conjunto de equilibrios de Nash. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Tabla 2: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {150, 200, 320} cuando N(θ) es un conjunto de equilibrios de Nash. Las Tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ(a) < 2.7 es poco probable para cualquier θ del cual tengamos datos, aunque este juicio, como mencionamos, se refiere únicamente a los perfiles que hemos muestreado realmente. Podemos entonces aceptar esto como otra pieza de evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, parece poco probable que el diseñador logre su objetivo incluso si pudiera persuadir a los participantes a jugar un equilibrio deseable. La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM de 2004 eran, de hecho, racionales al adquirir grandes cantidades de componentes al comienzo del juego. Si observamos la tercera columna de esta tabla, que corresponde a θ = 100, podemos deducir que ningún perfil a en nuestros datos con φ(a) < 3 es muy probable que se juegue en equilibrio. Los límites anteriores proporcionan algunas pruebas generales, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos muestreado. Particularmente, nos gustaría decir algo sobre lo que sucede en los ajustes de θ para los cuales no tenemos datos. Para derivar un límite probabilístico aproximado sobre la probabilidad de que ningún θ ∈ Θ haya logrado el objetivo del diseñador, sea ∪J j=1Θj una partición de Θ, y asuma que la función sup{φ∗ (θ)} satisface la condición de Lipschitz con constante de Lipschitz Aj en cada subconjunto Θj. Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a Θ = [0, 320]. Ahora definimos cada subconjunto j como el intervalo entre dos puntos para los cuales hemos producido datos. Por lo tanto, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], con j variando entre 1 y 5, correspondiendo a los subintervalos anteriores. Denotaremos cada Θj por (aj, bj]. Luego, la siguiente proposición nos da una cota superior aproximada sobre la probabilidad de que sup{φ∗ (θ)} ≤ α. PROPOSICIÓN 2. Debido a que nuestros límites son aproximados, no podemos utilizarlos como una evaluación probabilística concluyente. En cambio, tomamos esto como otra pieza de evidencia para complementar nuestros hallazgos. Aunque podamos asumir que una función que aproximamos a partir de datos es Lipschitz continua, rara vez conocemos en realidad la constante de Lipschitz para cualquier subconjunto de Θ. Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de los datos. Aquí, probamos tres métodos para hacer esto. El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subintervalo. Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo. Un método alternativo es tomar un límite superior en la pendiente obtenida dentro de cada subintervalo utilizando los datos disponibles. Esto produce un límite superior de probabilidades mucho menos conservador. Sin embargo, dado que el límite superior real suele ser mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso. Un último método que intentamos es un compromiso entre los dos anteriores. En lugar de tomar el límite superior conservador basado en datos sobre todo el dominio de la función Θ, tomamos el promedio de los límites superiores obtenidos en cada Θj. El límite en un intervalo se toma como el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos. Los resultados de evaluar la expresión para Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3. En términos de nuestras afirmaciones en maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Tabla 3: Límite superior aproximado de la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con un objetivo α = 2. Se utilizan diferentes métodos para aproximar el límite superior de la pendiente en cada subintervalo j. En este trabajo, la expresión proporciona un límite superior a la probabilidad de que alguna configuración de θ (es decir, costo de almacenamiento) en el intervalo [0,320] resulte en una adquisición total del día 0 que no sea mayor en ningún equilibrio que el objetivo especificado por α y tomado aquí como 2. Como sospechábamos, el enfoque más conservador para estimar el límite superior de la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí. Sin embargo, los otros dos enfoques de estimación, encontrados en las columnas dos y tres de la Tabla 3, sugieren que de hecho estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría funcionado. Dada la tremenda dificultad del problema, este resultado es muy sólido. Aun así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia. Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y los conjuntos de estrategias). Tampoco podemos esperar obtener nunca suficiente evidencia para llegar a conclusiones completamente objetivas. En cambio, el enfoque que defendemos aquí es recopilar la mayor cantidad de evidencia posible dadas las limitaciones de recursos, y tomar la decisión más convincente basada en esta evidencia, si es posible. RESULTADOS DE CONVERGENCIA En este punto, exploramos abstractamente si una elección de parámetro de diseño basada en datos de pago puede ser asintóticamente confiable. Dado que no teníamos todas las desviaciones posibles para cualquier perfil disponible en los datos, los verdaderos límites superiores pueden ser aún más bajos. Por conveniencia, utilizaremos la notación un,i(a) para referirnos a una función de pago del jugador i basada en un promedio sobre n muestras i.i.d. de la distribución de pagos. También asumimos que un,i(a) son independientes para todo a ∈ A e i ∈ I. Utilizaremos la notación Γn para referirnos al juego [I, R, {ui,n(·)}], mientras que Γ denotará el juego subyacente, [I, R, {ui(·)}]. De manera similar, definimos n(r) como (r) con respecto al juego Γn. En esta sección, demostramos que n(s) → (s) casi seguramente de forma uniforme en el espacio de estrategias mixtas para cualquier juego finito, y, además, que todas las equilibrios de Nash en estrategias mixtas en juegos empíricos eventualmente se acercan arbitrariamente a algunas estrategias de equilibrio de Nash en el juego subyacente. Utilizamos estos resultados para demostrar que bajo ciertas condiciones, la elección óptima del parámetro de diseño basada en datos empíricos converge casi seguramente al óptimo real. TEOREMA 3. Supongamos que |I| < ∞, |A| < ∞. Entonces n(s) → (s) casi seguramente uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios de Nash de Γ. Si definimos Nn,γ = {s ∈ S : n(s) ≤ γ}, tenemos el siguiente corolario del Teorema 3: COROLARIO 4. Para todo γ > 0, existe un M tal que para todo n ≥ M, N ⊂ Nn,γ casi seguramente. PRUEBA. Dado que n(s) = 0 para todo s ∈ N, podemos encontrar un M lo suficientemente grande tal que Pr{supn≥M sups∈N n(s) < γ} = 1. Según el Corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier > 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios de Nash empíricos si se han tomado suficientes muestras. Como mostramos ahora, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un límite no nulo como una estimación del conjunto de equilibrios de Nash. Primero, supongamos que concluimos que para una configuración particular de θ, sup{ˆφ∗ (θ)} ≤ α. Entonces, dado que para cualquier fijo > 0, N(θ) ⊂ Nn, (θ) cuando n es suficientemente grande, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α para cualquier n de este tipo. Así, dado que definimos la función de bienestar del diseñador como I{sup{φ∗ (θ)} ≤ α} en nuestro dominio de interés, la elección empírica de θ satisface el objetivo del diseñador, maximizando así su función de bienestar. Alternativamente, supongamos que concluimos que inf{ˆφ∗ (θ)} > α para cada θ en el dominio. Entonces, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, para todo θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo del diseñador. Ahora, demostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de Γn está cerca de algún equilibrio de Nash del juego subyacente. Este resultado nos llevará a considerar la convergencia de los optimizadores basados en datos empíricos a los ajustes óptimos reales de los parámetros del mecanismo. Primero notamos que la función (s) es continua en un juego finito. LEMMA 5. \n\nLEMMA 5. Sea S un conjunto de estrategias mixtas definido en un juego finito. Entonces: S → R es continua. Para la exposición que sigue, necesitamos un poco de notación adicional. Primero, sea (Z, d) un espacio métrico, y X, Y ⊂ Z y definamos la distancia de Hausdorff dirigida de X a Y como h(X, Y) = sup x∈X inf y∈Y d(x, y). Observa que U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ). Además, define BS(x, δ) como una bola abierta en S ⊂ Z con centro en x ∈ S y radio δ. Ahora, dejemos que Nn denote todos los equilibrios de Nash del juego Γn y sea Nδ = [ x∈N BS(x, δ), es decir, la unión de bolas abiertas de radio δ con centros en los equilibrios de Nash de Γ. Ten en cuenta que h(Nδ, N) = δ. Podemos entonces demostrar el siguiente resultado general. TEOREMA 6. Supongamos que |I| < ∞ y |A| < ∞. Entonces casi con seguridad h(Nn, N) converge a 0. Ahora demostraremos que en el caso especial cuando Θ y A son finitos y cada Γθ tiene un equilibrio de Nash único, las estimaciones ˆθ del parámetro óptimo del diseñador convergen a un optimizador real casi seguramente. Sea ˆθ = arg maxθ∈Θ W (Nn(θ), θ), donde n es el número de veces que se muestreó cada perfil puro en Γθ para cada θ, y sea θ∗ = arg maxθ∈Θ W (N(θ), θ). TEOREMA 7. Supongamos que |N(θ)| = 1 para todo θ ∈ Θ y supongamos que Θ y A son finitos. Sea W (s, θ) continua en el único s∗ (θ) ∈ N(θ) para cada θ ∈ Θ. Entonces ˆθ es un estimador consistente de θ∗ si W (N(θ), θ) se define como un supremo, ínfimo o esperanza sobre el conjunto de equilibrios de Nash. De hecho, ˆθ → θ∗ casi seguramente en cada uno de estos casos. La limitación del resultado anterior es que, dentro de nuestro marco de trabajo, el diseñador no tiene forma de saber o asegurar que Γθ tenga equilibrios únicos. Sin embargo, sí proporciona cierta justificación teórica para seguir el diseño de esta manera, y quizás servirá como guía para obtener resultados más generales en el futuro. 6. TRABAJO RELACIONADO La literatura de diseño de mecanismos en Economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10]. Además, existe una extensa literatura sobre el diseño óptimo de subastas [10], del cual el trabajo de Roger Myerson [11] es, quizás, el más relevante. En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y teniendo en cuenta restricciones como la compatibilidad de incentivos y la racionalidad individual. Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de Ciencias de la Computación. Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros relevantes del juego son conocimiento común. Cuando las funciones de pago de los jugadores son desconocidas, se ha explorado la realización de búsquedas mediante simulaciones como alternativa. Un enfoque en esa dirección, tomado en [4] y [15], es coevolucionar el parámetro del mecanismo y las estrategias de los agentes, utilizando alguna noción de utilidad social y pagos de los agentes como criterios de aptitud. Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética. En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron un resultado de un juego inducido por un parámetro del mecanismo como el resultado del aprendizaje conjunto de los agentes. Más recientemente, Phelps et al. [14] compararon dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en juegos definidos por estrategias heurísticas, como en [18]. 7. CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el diseño empírico de mecanismos. Definimos un modelo formal de teoría de juegos de interacción entre el diseñador y los participantes del mecanismo como un juego de dos etapas. También describimos en cierta generalidad los métodos para estimar una función de equilibrio de Nash de muestra cuando los datos son extremadamente escasos, o una correspondencia de equilibrio de Nash cuando hay más datos disponibles. Nuestras técnicas están diseñadas específicamente para abordar problemas en los que tanto el espacio de parámetros del mecanismo como los conjuntos de estrategias de los agentes son infinitos y solo se puede adquirir un conjunto de datos relativamente pequeño. Un problema de diseño difícil en el juego TAC/SCM que la comunidad de TAC ha estado ansiosa por abordar nos brinda un escenario para probar nuestros métodos. Al aplicar el análisis empírico del juego al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos. Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia del equilibrio de Nash. Al final, podemos intentar proporcionar suficiente evidencia para prescribir una configuración de parámetros, o sugerir que no es posible encontrar una configuración que satisfaga al diseñador. En el caso de TAC/SCM, nuestra evidencia sugiere bastante claramente que el costo de almacenamiento no pudo haber sido ajustado de manera efectiva en el torneo de 2004 para frenar la adquisición excesiva del día 0 sin efectos perjudiciales en la rentabilidad general. El éxito de nuestro análisis en este entorno extremadamente complejo con altos costos de simulación nos hace ser optimistas de que nuestros métodos pueden brindar orientación en la toma de decisiones de diseño de mecanismos en otros dominios desafiantes. Los resultados teóricos confirman algunas intuiciones detrás de los métodos de diseño de mecanismos empíricos que hemos introducido, y aumentan nuestra confianza en que nuestro marco puede ser efectivo para estimar la mejor elección de parámetros del mecanismo en entornos relativamente generales. Agradecimientos Agradecemos a Terence Kelly, Matthew Rudary y Satinder Singh por sus útiles comentarios sobre versiones anteriores de este trabajo. Este trabajo fue apoyado en parte por la subvención de la NSF IIS-0205435 y el programa de razonamiento estratégico DARPA REAL. 8. REFERENCIAS [1] R. Arunachalam y N. M. Sadeh. La competencia de agentes de comercio de la cadena de suministro. Investigación y aplicaciones del comercio electrónico, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy y M. Tschantz. Un enfoque de programación estocástica para la planificación en TAC SCM. En la Quinta Conferencia ACM sobre Comercio Electrónico, páginas 152-159, Nueva York, 2004. [3] Y.-P. Chang y W.-T. Huang. Intervalos de confianza generalizados para el valor más grande de algunas funciones de parámetros bajo normalidad. Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.\nEstadística Sinica, 10:1369-1383, 2000. [4] D. Cliff. Evolución del mecanismo de mercado a través de un espacio continuo de tipos de subasta. En el Congreso de Computación Evolutiva de 2002. [5] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [6] V. Conitzer y T. Sandholm. Un algoritmo para diseñar automáticamente mecanismos determinísticos sin pagos. En la Tercera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagente, páginas 128-135, 2004. [7] D. Friedman. Juegos evolutivos en economía. Econometrica, 59(3):637-666, mayo de 1991. [8] R. Keener. Teoría Estadística: Una Mezcla de Temas Fundamentales. Departamento de Estadística de la Universidad de Michigan, 2004. [9] C. Kiekintveld, Y. Vorobeychik y M. P. Wellman. Un análisis de la competencia de agentes comerciales de gestión de la cadena de suministro de 2004. En el taller IJCAI-05 sobre Diseño y Análisis de Agentes de Negociación, Edimburgo, 2005. [10] A. Mas-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [11] R. B. Myerson.\nEditorial de la Universidad de Oxford, 1995. [11] R. B. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6(1):58-73, febrero de 1981. [12] S. Olafsson y J. Kim. Optimización de simulación. En E. Yucesan, C.-H. Chen, J. Snowdon y J. Charnes, editores, Conferencia de Simulación de Invierno 2002, 2002. [13] D. Pardoe y P. Stone. TacTex-03: Un agente de gestión de la cadena de suministro. SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, y P. McBurney. Agentes automatizados versus humanos virtuales: una comparación teórica evolutiva de dos diseños de mercado de subasta doble. En Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney y E. Sklar. Co-evolución de mecanismos de subasta y estrategias de negociación: hacia un enfoque novedoso para el diseño microeconómico. En el taller ECOMAS 2002, 2002. [16] S. Phelps, S. Parsons, E. Sklar y P. McBurney. Utilizando programación genética para optimizar reglas de precios para un mercado de subasta doble. En Taller sobre Agentes para el Comercio Electrónico, 2003. [17] Y. Vorobeychik, M. P. Wellman y S. Singh. Aprendiendo funciones de pago en juegos infinitos. En la Decimonovena Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro y J. O. Kephart. Analizando interacciones estratégicas complejas en sistemas multiagente. En el taller AAAI-02 sobre agentes teóricos de juegos y de toma de decisiones, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld y V. Soni. Interacciones estratégicas en un juego de cadena de suministro. Inteligencia Computacional, 21(1):1-26, febrero de 2005. APÉNDICE A. PRUEBAS A.1 Prueba de la Proposición 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du. A.2 Prueba de la Proposición 2 Primero, supongamos que alguna función, f(x), definida en [ai, bi], satisface la condición de Lipschitz en (ai, bi] con una constante de Lipschitz Ai. Entonces se cumple la siguiente afirmación: Afirmación: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai). Para demostrar esta afirmación, observe que la intersección de las líneas en f(ai) y f(bi) con pendientes -Ai y Ai respectivamente determinará el límite inferior del mínimo de f(x) en [ai, bi] (que es un límite inferior del ínfimo de f(x) en (ai, bj]). La línea en f(ai) está determinada por f(ai) = −Aiai + cL y la línea en f(bi) está determinada por f(bi) = Aibi + cR. Por lo tanto, las intercepciones son cL = f(ai) + Aiai y cR = f(bi) + Aibi respectivamente. Sea x∗ el punto en el que estas líneas se cruzan. Entonces, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A. Al sustituir las expresiones de cR y cL, obtenemos el resultado deseado. Ahora, la subaditividad nos da Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, y, por la afirmación, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}. Dado que tenemos un número finito de puntos en el conjunto de datos para cada θ, podemos obtener la siguiente expresión: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}. Ahora podemos restringir nuestra atención en obtener una cota superior en Pr{sup{φ∗ (θ)} = y} para un θ fijo. Para hacer esto, observe que Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} por subaditividad y el hecho de que un perfil a es un equilibrio de Nash si y solo si (a) = 0. Poner todo junto produce el resultado deseado. Prueba de Teorema 3 En primer lugar, necesitaremos el siguiente hecho: Afirmación: Dada una función fi(x) y un conjunto X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|. Para demostrar esta afirmación, observe que | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) si maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) si maxx f2(x) ≥ maxx f1(x) En el primer caso, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 De manera similar, en el segundo caso, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|. Por lo tanto, la afirmación se mantiene. Por la Ley Fuerte de los Grandes Números, un,i(a) → ui(a) casi seguramente para todo i ∈ I, a ∈ A. Es decir, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, o, equivalentemente [8], para cualquier α > 0 y δ > 0, existe M(i, a) > 0 tal que Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Al tomar M = maxi∈I maxa∈A M(i, a), tenemos que Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Así, por la afirmación, para cualquier n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ con una probabilidad de al menos 1 − α. Ten en cuenta que dado que s−i(a) y s(a) están acotados entre 0 y 1, pudimos eliminarlos de las expresiones anteriores para obtener una cota que será válida independientemente de la elección particular de s. Además, dado que el resultado anterior se puede obtener para un α arbitrario > 0 y δ > 0, tenemos que Pr{limn→∞ n(s) = (s)} = 1 uniformemente en S. A.4 Prueba del Lema 5 Demostramos el resultado utilizando la continuidad uniforme de ui(s) y la preservación de la continuidad bajo el máximo. Afirmación: Una función f : Rk → R definida por f(t) = Σi=1k zi ti, donde zi son constantes en R, es uniformemente continua en t. La afirmación se sigue porque |f(t)−f(t )| = | Σi=1k zi(ti−ti)| ≤ Σi=1k |zi||ti − ti|. Un resultado inmediato de esto para nuestros propósitos es que ui(s) es uniformemente continua en s y ui(ai, s−i) es uniformemente continua en s−i. Afirmación: Sea f(a, b) uniformemente continua en b ∈ B para cada a ∈ A, con |A| < ∞. Entonces V (b) = maxa∈A f(a, b) es uniformemente continua en b. Para demostrar esto, toma γ > 0 y deja que b, b ∈ B tal que b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ. Ahora toma δ = mina∈A δ(a). Entonces, cada vez que b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ. Ahora, recuerda que (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)]. Según las afirmaciones anteriores, maxai∈Ai ui(ai, s−i) es uniformemente continua en s−i y ui(s) es uniformemente continua en s. Dado que la diferencia de dos funciones uniformemente continuas es uniformemente continua, y dado que esta continuidad se conserva bajo el máximo según nuestra segunda afirmación, obtenemos el resultado deseado. Prueba de Teorema 6. Elija δ > 0. Primero, necesitamos asegurarnos de que se cumple la siguiente afirmación: Afirmación: ¯ = mins∈S\\Nδ (s) existe y ¯ > 0. Dado que Nδ es un subconjunto abierto de S compacto, se sigue que S \\ Nδ es compacto. Como también habíamos demostrado en el Lema 5 que (s) es continua, la existencia se sigue del teorema de Weierstrass. Es claro que ¯ > 0 ya que (s) = 0 si y solo si s es un equilibrio de Nash de Γ. Ahora, por el Teorema 3, para cualquier α > 0 existe un M tal que Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. En consecuencia, para cualquier δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Dado que esto se cumple para un α arbitrario > 0 y δ > 0, se obtiene el resultado deseado. Prueba de Teorema 7. Fija θ y elige δ > 0. Dado que W (s, θ) es continua en s∗ (θ), dado > 0 existe δ > 0 tal que para cada s que esté dentro de δ de s∗ (θ), |W (s, θ) - W (s∗ (θ), θ)| < . Según el Teorema 6, podemos encontrar M(θ) lo suficientemente grande para que todos los s ∈ Nn estén dentro de δ de s∗ (θ) para todo n ≥ M(θ) con probabilidad 1. Por consiguiente, para cualquier > 0 podemos encontrar M(θ) lo suficientemente grande tal que con probabilidad 1 tengamos supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < . Asumamos sin pérdida de generalidad que hay una elección óptima única de θ. Ahora, dado que el conjunto Θ es finito, también existe la segunda mejor opción de θ (si solo hay un θ ∈ Θ, esta discusión no tiene sentido de todos modos): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ). Supongamos sin pérdida de generalidad que θ∗∗ también es único y sea ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ). Entonces, si dejamos < ∆/2 y dejamos que M = maxθ∈Θ M(θ), donde cada M(θ) es lo suficientemente grande como para que supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., la elección óptima de θ basada en cualquier equilibrio empírico será θ∗ con probabilidad 1. Por lo tanto, en particular, dado cualquier distribución de probabilidad sobre equilibrios empíricos, la mejor elección de θ será θ∗ con probabilidad 1 (similarmente, si tomamos el supremo o el ínfimo de W (Nn(θ), θ) sobre el conjunto de equilibrios empíricos al construir la función objetivo). ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "interest outcome feature": {
            "translated_key": "característica del resultado de interés",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "supply-chain trading": {
            "translated_key": "cadena de suministro",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a <br>supply-chain trading</br> competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [
                "We illustrate our approach with a design task from a <br>supply-chain trading</br> competition."
            ],
            "translated_annotated_samples": [
                "Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la <br>cadena de suministro</br>."
            ],
            "translated_text": "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la <br>cadena de suministro</br>. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismos empíricos. En la continuación, desarrollamos algunos métodos generales para el diseño empírico de mecanismos y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto. En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2. Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores. Ri es el conjunto de estrategias disponibles para el jugador i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×. . .×Am. A menudo es conveniente referirse a la estrategia del jugador i por separado de la de los demás jugadores. Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama un perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i). Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el jugador i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada jugador i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i. Podemos extender esta definición a estrategias mixtas asumiendo que ui son utilidades de von Neumann-Morgenstern (vNM) de la siguiente manera: ui(s) = Es[ui], donde Es es la expectativa tomada con respecto a la distribución de probabilidad del juego inducida por la estrategia mixta de los jugadores s. Al emplear la forma normal, modelamos a los agentes jugando una única acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones más detalladas sobre la acción a lo largo del tiempo en la forma extensiva. Aunque cualquier juego extenso puede ser reformulado en forma normal, hacerlo puede sacrificar la concisión y difuminar distinciones relevantes (por ejemplo, la perfección en subjuegos). Ocasionalmente, escribimos ui(x, y) para indicar que x ∈ Ai o Si y y ∈ A−i o S−i dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u(·) = {u1(·), . . . , um(·)}. Definimos una función, : R → R, interpretada como el beneficio máximo que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) donde r pertenece a algún conjunto de estrategias, R, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada aquellas jugadas por los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un equilibrio de Nash. DEFINICIÓN 1. Un perfil estratégico r = (r1, . . . , rm) constituye un equilibrio de Nash del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). Cuando r ∈ A, lo anterior define un equilibrio de Nash de estrategia pura; de lo contrario, la definición describe un equilibrio de Nash de estrategia mixta. A menudo recurrimos al concepto de un equilibrio aproximado, o equilibrio de Nash, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita. Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un equilibrio de Nash si (r) ≤ . En este estudio dedicamos especial atención a los juegos que presentan simetría en cuanto a los pagos, lo que hace que los agentes sean estratégicamente idénticos. DEFINICIÓN 2. Un juego [I, {Ri}, {ui(r)}] es simétrico si para todo i, j ∈ I, (a) Ri = Rj y (b) ui(ri, r−i) = uj (rj, r−j) siempre que ri = rj y r−i = r−j. EL MODELO Modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un juego de dos etapas. El diseñador comienza seleccionando primero un valor, θ, de un conjunto de configuraciones de mecanismos permitidas, Θ. Todos los agentes participantes observan el parámetro θ del mecanismo y se mueven simultáneamente después. Por ejemplo, el diseñador podría estar decidiendo entre mecanismos de subasta de sobre cerrado de precio único y de precio único, con la presunción de que una vez tomada la decisión, los postores participarán con pleno conocimiento de las reglas de la subasta. Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como Γθ = [I, {Ri}, {ui(r, θ)}]. Nos referimos a Γθ como un juego inducido por θ. Sea N(θ) el conjunto de perfiles estratégicos considerados soluciones del juego Γθ.3. Supongamos que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, W(r, θ), dependiente del parámetro del mecanismo y del juego resultante, r. Definimos una medida pesimista, W( ˆR, θ) = inf{W(r, θ) : r ∈ ˆR}, que representa el bienestar en el peor de los casos del juego inducido por θ, asumiendo que los agentes juegan alguna estrategia conjunta en ˆR. Normalmente nos preocupamos por W (N(θ), θ), el resultado en el peor de los casos de jugar alguna solución. En algunos problemas podemos obtener una considerable ventaja al utilizar una función de agregación para mapear el resultado del bienestar de un juego. Generalmente adoptamos el equilibrio de Nash como concepto de solución, y por lo tanto tomamos N(θ) como el conjunto de equilibrios. Sin embargo, gran parte de la metodología desarrollada aquí podría ser utilizada con criterios alternativos para derivar el comportamiento del agente a partir de una definición del juego. Nuevamente, existen alternativas disponibles. Por ejemplo, si se tiene una distribución de probabilidad sobre el conjunto de soluciones N(θ), sería natural tomar la expectativa de W(r, θ) en su lugar. 307 especificado en términos de estrategias de agentes a un resultado de bienestar equivalente especificado en términos de un resumen de menor dimensión. DEFINICIÓN 3. Una función φ: R1 × · · · × Rm → Rq es una función de agregación si m ≥ q y W(r, θ) = V(φ(r), θ) para alguna función V. Sobrecargamos el símbolo de función para aplicar a conjuntos de perfiles estratégicos: φ( ˆR) = {φ(r) : r ∈ ˆR}. Para mayor comodidad en la exposición, escribimos φ∗ (θ) para denotar φ(N(θ)). El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia. Por ejemplo, supongamos, como en nuestra aplicación a continuación, que la estrategia de un agente está definida por un parámetro numérico. Si todo lo que nos importa es el valor total jugado, podemos tomar φ(a) = Πm i=1 ai. Si hemos elegido nuestro agregador cuidadosamente, también podemos capturar estructuras que de otra manera no serían evidentes. Por ejemplo, φ∗ (θ) podría estar disminuyendo en θ, mientras que N(θ) podría tener una estructura más compleja. Dada una descripción de la correspondencia de solución N(θ) (equivalentemente, φ∗(θ)), el diseñador se enfrenta a un problema estándar de optimización. Alternativamente, dado un simulador que pudiera producir una muestra imparcial de la distribución de W (N(θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12]. Sin embargo, incluso para un juego Γθ con pagos conocidos, puede resultar computacionalmente intratable resolver los equilibrios de Nash, especialmente si el juego tiene conjuntos de estrategias grandes o infinitos. Además, deseamos estudiar juegos en los que los pagos no se dan explícitamente, sino que deben determinarse a partir de simulaciones u otra experiencia con el juego. Por lo tanto, asumimos que se nos proporciona un conjunto de datos (posiblemente ruidoso) de realizaciones de pagos: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, donde para cada punto de datos θi es el ajuste observado del parámetro del mecanismo, ai es el perfil de estrategia pura observado de los participantes, y Ui es la realización correspondiente de los pagos de los agentes. También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}. Sea D = {Do, Ds} el conjunto de datos combinado. (Ya sea que Do o Ds puedan ser nulos para un problema particular). En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos empíricos de teoría de juegos, para responder preguntas sobre el diseño del escenario TAC/SCM. 4. ANÁLISIS DE DISEÑO EMPÍRICO Dado que nuestros datos se presentan en forma de experiencia de pago y no como el valor de una función objetivo para configuraciones dadas de la variable de control, ya no podemos confiar en los métodos para optimizar funciones utilizando simulaciones. De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia del equilibrio de Nash. Además, no podemos depender directamente de los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilístico adaptados a nuestra configuración de problema. 4.1 Problema de Diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente. Recuerde que durante el torneo de 2004, los diseñadores del juego de la cadena de suministro optaron por aumentar drásticamente los costos de almacenamiento como medida para frenar las compras del día 0, con poco éxito. Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y la cantidad agregada de componentes adquiridos el día 0 en equilibrio. Esto suele ser el caso en juegos reales de interés, donde descripciones en lenguaje natural o algorítmicas pueden sustituir a una especificación formal de estrategias y funciones de pago. Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo. ¿Primero, ¿el aumento de los costos de almacenamiento realmente reduce la adquisición en el día 0? ¿Fue racional la adquisición excesiva observada durante el día 0 del torneo de 2004? Y en tercer lugar, ¿podría haber reducido de manera suficiente los costos de almacenamiento la adquisición del día 0 a un nivel aceptable, y en tal caso, cuál debería haber sido el ajuste de los costos de almacenamiento? Es esta tercera pregunta la que define el aspecto del diseño de mecanismos de nuestro análisis. Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de los agentes, la función de bienestar de los diseñadores, el espacio de parámetros del mecanismo y la fuente de datos. Restringimos las estrategias de los agentes para que sean un multiplicador de la cantidad de solicitudes del día 0 de uno de los finalistas, Deep Maize, en el torneo TAC/SCM de 2004. Lo restringimos aún más al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias por encima de 1.5 son extremadamente agresivas (por lo tanto, poco probables de proporcionar desviaciones refutadoras más allá de las disponibles en las estrategias incluidas, y ciertamente no forman parte de ningún equilibrio deseable). Todo otro comportamiento se basa en el comportamiento de Deep Maize y es idéntico para todos los agentes. Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico. Sin embargo, creemos que la forma general de los resultados debería ser robusta ante cambios en el comportamiento completo del agente. Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0. Sea φ(a) = Σ6 i=1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego particular de la cadena de suministro (para perfiles de estrategia mixta s, tomamos la esperanza de φ con respecto a la mezcla). La función de bienestar de los diseñadores W (N(θ), θ) se define entonces como I{sup{φ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de adquisición en el día 0 y I es la función indicadora. El diseñador selecciona un valor θ de costos de almacenamiento, expresado como un porcentaje anual del valor base de los componentes en el inventario (cobrado diariamente), del conjunto Θ = R+. Dado que la decisión de los diseñadores depende solo de φ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación. 4.2 Estimación de equilibrios de Nash El objetivo de los agentes de TAC/SCM es maximizar los beneficios obtenidos en una instancia del juego. Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, U(a)). Si también hemos fijado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de jugadores y sus correspondientes pagos, y, en consecuencia, para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios de Nash de cada juego Γθ. Por lo tanto, necesitamos métodos para aproximar equilibrios de Nash en juegos infinitos. A continuación, describimos los dos métodos que utilizamos en nuestro estudio. El primero ha sido explorado empíricamente anteriormente, mientras que el segundo se introduce aquí como el método específicamente diseñado para aproximar un conjunto de equilibrios de Nash. 4.2.1 Aproximación de la Función de Pago El primer método para estimar equilibrios de Nash basado en datos utiliza aprendizaje supervisado para aproximar las funciones de pago de mech6. No abordamos si y cómo otras medidas (por ejemplo, restringir directamente la adquisición) podrían haber logrado los objetivos de diseño. Nuestro enfoque considera como dado un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento. En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con un crecimiento de complejidad correspondiente. 308 participantes del mecanismo de un conjunto de datos de experiencia de juego [17]. Una vez que las funciones de pago aproximadas estén disponibles para todos los jugadores, los equilibrios de Nash pueden encontrarse ya sea de forma analítica o aproximada utilizando técnicas numéricas, dependiendo del modelo de aprendizaje. En lo que sigue, estimamos solo un equilibrio de Nash de muestra utilizando esta técnica, aunque esta restricción puede eliminarse a expensas de un tiempo de cálculo adicional. Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador. Por lo tanto, podemos aplicarlo cuando Ds = ∅. Si hay un simulador disponible, podemos generar datos adicionales para aumentar la confianza en nuestras estimaciones iniciales. Probamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado local (LWA) y regresión lineal ponderada localmente (LWLR). También utilizamos variables de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis empírico previo de teoría de juegos de TAC/SCM-03 [19]. El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido de forma analítica. Para los otros métodos aplicamos dinámica replicadora [7] a una aproximación discreta del juego aprendido. El total esperado de adquisiciones del día 0 en equilibrio se tomó como la estimación de un resultado. 4.2.2 Búsqueda en el Espacio de Perfiles de Estrategia Cuando tenemos acceso a un simulador, también podemos utilizar la búsqueda dirigida a través del espacio de perfiles para estimar el conjunto de equilibrios de Nash, que describimos aquí después de presentar alguna notación adicional. DEFINICIÓN 4. Un vecino estratégico de un perfil de estrategia pura a es un perfil que es idéntico a a en todo menos en una estrategia. Definimos Snb(a, D) como el conjunto de todos los vecinos estratégicos de a disponibles en el conjunto de datos D. De manera similar, definimos Snb(a, ˜D) como todos los vecinos estratégicos de a que no están en D. Finalmente, para cualquier a ∈ Snb(a, D) definimos al agente que se desvía como i(a, a). DEFINICIÓN 5. La -ligadura, ˆ, de un perfil de estrategia pura a se define como maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}. Decimos que a es un candidato a δ-equilibrio para δ ≥ ˆ. Cuando Snb(a, ˜D) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), a se confirma como un equilibrio de Nash ˆ. Nuestro método de búsqueda opera explorando desviaciones de los equilibrios candidatos. Nos referimos a esto como BestFirstSearch, ya que selecciona con probabilidad uno un perfil de estrategia a ∈ Snb(a, ˜D) que tiene el menor ˆin D. Finalmente definimos un estimador para un conjunto de equilibrios de Nash. DEFINICIÓN 6. Para un conjunto K, define Co(K) como la envoltura convexa de K. Sea Bδ el conjunto de candidatos en el nivel δ. Definimos ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) para un δ fijo como un estimador de φ∗ (θ). En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles estratégicos agregados con límite inferior -bound por debajo de un δ fijo. Esta definición nos permite explotar la estructura que surge de la función de agregación. Si dos perfiles son cercanos en términos de valores de agregación, es probable que tengan límites similares. En particular, si uno está en equilibrio, el otro también puede estarlo. Presentamos un respaldo teórico para este método de estimación del conjunto de equilibrios de Nash a continuación. Dado que el juego en el que estamos interesados es infinito, es necesario terminar BestFirstSearch antes de explorar todo el espacio de strat7. Por ejemplo, podemos utilizar técnicas de aprendizaje activo [5] para mejorar la calidad de la aproximación de la función de recompensa. En este trabajo, nos concentramos en la búsqueda en el espacio de perfiles estratégicos. Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos. Generación de datos Nuestros datos fueron recopilados simulando juegos TAC/SCM en una versión local del servidor TAC/SCM de 2004, que tiene una configuración para el costo de almacenamiento. Las estrategias de los agentes en juegos simulados fueron seleccionadas del conjunto {0, 0.3, 0.6, . . . , 1.5} con el fin de tener una probabilidad positiva de generar vecinos estratégicos. Se generó un conjunto de datos base Do mediante el muestreo de 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}. Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varios defectos. Utilizamos la búsqueda para generar un conjunto de datos simulados Ds, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ. Dado que el costo de la simulación es extremadamente alto (un juego tarda casi 1 hora en ejecutarse), pudimos ejecutar un total de 2670 juegos en el transcurso de más de seis meses. Para hacer una comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategias conjuntas finitas restringidas para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces). 4.4 Resultados 4.4.1 Análisis del conjunto de datos base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos base Do. Además, generamos una estimación de la correspondencia del equilibrio de Nash, ˆφ∗ (θ), aplicando la Definición 6 con δ = 2.5E6. Los resultados se muestran en la Figura 1. Como podemos ver, la correspondencia ˆφ∗ (θ) tiene poco poder predictivo basado en Do, y no revela ninguna estructura interesante sobre el juego. Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición Total Día 0 LWA LWLR QR BaselineMin BaselineMax Figura 1: Estimaciones de adquisición del día 0 agregadas basadas en Do. La correspondencia ˆφ∗ (θ) es el intervalo entre BaselineMin y BaselineMax. En general, la búsqueda se detiene una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para obtener conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego. Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash a permanecer en este subconjunto discreto de [0,1.5]. Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron accidentes, problemas de conectividad de red y otras anomalías obvias), el juego sería descartado. Análisis de los datos de búsqueda Para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ∗ (θ) (nuevamente, usando δ =2.5E6) en el conjunto de datos D = {Do, Ds}, donde Ds es datos generados a través de la aplicación de BestFirstSearch. Los resultados de esta estimación se representan gráficamente frente a los resultados de los métodos de aprendizaje entrenados en Do 11 en la Figura 2. Primero, observamos que la adición de los datos de búsqueda reduce considerablemente el rango de posibles equilibrios. Además, las predicciones puntuales reales de los métodos de aprendizaje y aquellas basadas en límites después de la búsqueda son razonablemente cercanas. Combinar la evidencia recopilada de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquiera de los métodos utilizados de forma aislada. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición del Día 0 LWA LWLR QR Búsqueda Mínima Búsqueda Máxima Figura 2: Estimaciones agregadas de adquisición del día 0 basadas en la búsqueda en el espacio de perfiles de estrategia en comparación con técnicas de aproximación de funciones entrenadas en Do. La correspondencia ˆφ∗ (θ) para D = {Do, Ds} es el intervalo entre SearchMin y SearchMax. Esta evidencia respalda la intuición inicial de que la adquisición del día 0 debería disminuir con los costos de almacenamiento. También confirma que los altos niveles de adquisición en el día 0 son una respuesta racional al entorno del torneo de 2004 con un costo promedio de almacenamiento, que corresponde a θ = 100. La predicción mínima para la adquisición agregada en este nivel de costos de almacenamiento, dada por cualquier método experimental, es aproximadamente 3. Esto es bastante alto, ya que corresponde a un compromiso esperado del 1/3 de la capacidad total del proveedor para todo el juego. La predicción máxima es considerablemente mayor a 4.5. En la competencia actual de 2004, la adquisición total del día 0 equivalía a 5.71 en la escala utilizada aquí [9]. Nuestras predicciones subestiman este resultado en cierta medida, pero muestran que cualquier resultado racional probablemente tendría una alta adquisición en el día 0. 4.4.3 Extrapolando la Correspondencia de la Solución Tenemos evidencia razonablemente sólida de que la correspondencia del resultado está disminuyendo. Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento a un valor que reduciría la adquisición del día 0 en equilibrio, o concluir que esto no es posible. Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día 0. No está claro cuán significativos serían los resultados del aprendizaje si se agregaran Ds al conjunto de datos de entrenamiento. De hecho, los datos adicionales pueden aumentar realmente la varianza del aprendizaje. Recuerde que el objetivo de los diseñadores es incentivar la adquisición agregada del día 0 que esté por debajo del umbral α. Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultados estimada a partir de D que produce θ = 320. Los datos para θ = 320 fueron recopilados de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos por 33 iteraciones de BestFirstSearch. La Figura 3 muestra los límites detallados para todos los perfiles en términos de sus valores correspondientes de φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Límites de ε de Adquisición Total Día-0 Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320. Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ(a). La región gris corresponde a ˆφ∗ (320) con δ = 2.5M. El conjunto estimado de resultados agregados del día 0 es muy cercano al de θ = 200, lo que indica que hay poco beneficio adicional al aumentar los costos de almacenamiento por encima de 200. Observa que incluso el límite inferior de nuestro conjunto estimado de equilibrios de Nash está muy por encima de la adquisición objetivo del día 0 de 2. Además, las recompensas para los agentes son casi siempre negativas en θ = 320. Por consiguiente, aumentar los costos aún más sería indeseable incluso si finalmente se pudiera reducir la adquisición en el día 0. Dado que tenemos una confianza razonable de que φ∗ (θ) está disminuyendo en θ, tampoco esperamos que establecer θ en algún lugar entre 200 y 320 logre el resultado deseado. Concluimos que es poco probable que la adquisición del día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento. Que nuestras predicciones tienden a subestimar los resultados del torneo refuerza esta conclusión. Para lograr la reducción deseada en la adquisición del día 0 se requiere rediseñar otros aspectos del mecanismo. 4.5 Análisis Probabilístico Nuestro análisis empírico ha producido evidencia en apoyo a la conclusión de que ninguna configuración razonable del costo de almacenamiento probablemente sería suficiente para frenar la adquisición excesiva del día 0 en TAC/SCM 04. Toda esta evidencia ha sido en forma de simple interpolación y extrapolación de estimaciones de la correspondencia del equilibrio de Nash. Estas estimaciones se basan en simular instancias del juego y están sujetas a ruido de muestreo contribuido por los diversos elementos estocásticos del juego. En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos -bound a tales efectos estocásticos. Supongamos que todos los agentes tienen conjuntos de estrategias puras finitos (y pequeños), A. Por lo tanto, es factible muestrear toda la matriz de pagos del juego. Además, supongamos que el ruido es aditivo con media cero en promedio durante todo el juego, por lo que en la práctica probablemente querríamos que el umbral sea aún más bajo. 310 y varianza finita, es decir, Ui(a) = ui(a) + ˜ξi(a), donde Ui(a) es la ganancia observada para i cuando se jugó a, ui(a) es la ganancia correspondiente real, y ˜ξi(a) es una variable aleatoria normal con media cero. Designamos la varianza conocida de ˜ξi(a) como σ2 i (a). Por lo tanto, asumimos que ˜ξi(a) es normal con distribución N(0, σ2 i (a)). Tomamos ¯ui(a) como la media muestral de todos los Ui(a) en D, y seguimos a Chang y Huang [3] al asumir que tenemos una priori impropia sobre las ganancias reales ui(a) y el muestreo fue independiente para todos i y a. También confiamos en su resultado de que ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] son independientes con distribuciones posteriores N(¯ui(a), σ2 i (a)/ni(a)), donde ni(a) es el número de muestras tomadas de los pagos para i en el perfil puro a, y Zi(a) ∼ N(0, 1). Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio de Nash -Nash. Si ui(·)|¯ui(·) son independientes para todo i ∈ I y a ∈ A, tenemos el siguiente resultado (a partir de este punto omitimos la condición sobre ¯ui(·) por brevedad): PROPOSICIÓN 1. Para todo \\( i \\in I \\), \\( \\max_{b \\in A_i} u_i(b, a_{-i}) - u_i(a) \\leq \\varepsilon \\), donde \\( \\varepsilon = \\int_{Y_i} \\int_{Z} \\int_{R} \\int_{Y} \\int_{b \\in A_i \\backslash a_i} \\Pr(u_i(b, a_{-i}) \\leq u + \\varepsilon) f_{u_i(a)}(u) du \\), donde \\( f_{u_i(a)}(u) \\) es la función de densidad de probabilidad de \\( N(\\overline{u_i(a)}, \\sigma_i(a)) \\). Las pruebas de este y todos los resultados posteriores se encuentran en el Apéndice. La distribución posterior de la media óptima de n muestras, derivada por Chang y Huang [3], es Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) donde a ∈ A y Φ(·) es la función de distribución N(0, 1). Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilístico que (a) ≤ γ para un γ dado. Ahora, consideramos casos de datos incompletos y utilizamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en los datos) en la distribución de sup{φ∗ (θ)} e inf{φ∗ (θ)} (asumiendo que ambos son alcanzables): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, donde x es un número real y ≤D indica que el límite superior solo considera estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} y {inf{φ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf{φ∗ (θ)} ≤ x}. Los valores así derivados comprenden las Tablas 1 y 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Tabla 1: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando N(θ) es un conjunto de equilibrios de Nash. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Tabla 2: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {150, 200, 320} cuando N(θ) es un conjunto de equilibrios de Nash. Las Tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ(a) < 2.7 es poco probable para cualquier θ del cual tengamos datos, aunque este juicio, como mencionamos, se refiere únicamente a los perfiles que hemos muestreado realmente. Podemos entonces aceptar esto como otra pieza de evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, parece poco probable que el diseñador logre su objetivo incluso si pudiera persuadir a los participantes a jugar un equilibrio deseable. La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM de 2004 eran, de hecho, racionales al adquirir grandes cantidades de componentes al comienzo del juego. Si observamos la tercera columna de esta tabla, que corresponde a θ = 100, podemos deducir que ningún perfil a en nuestros datos con φ(a) < 3 es muy probable que se juegue en equilibrio. Los límites anteriores proporcionan algunas pruebas generales, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos muestreado. Particularmente, nos gustaría decir algo sobre lo que sucede en los ajustes de θ para los cuales no tenemos datos. Para derivar un límite probabilístico aproximado sobre la probabilidad de que ningún θ ∈ Θ haya logrado el objetivo del diseñador, sea ∪J j=1Θj una partición de Θ, y asuma que la función sup{φ∗ (θ)} satisface la condición de Lipschitz con constante de Lipschitz Aj en cada subconjunto Θj. Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a Θ = [0, 320]. Ahora definimos cada subconjunto j como el intervalo entre dos puntos para los cuales hemos producido datos. Por lo tanto, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], con j variando entre 1 y 5, correspondiendo a los subintervalos anteriores. Denotaremos cada Θj por (aj, bj]. Luego, la siguiente proposición nos da una cota superior aproximada sobre la probabilidad de que sup{φ∗ (θ)} ≤ α. PROPOSICIÓN 2. Debido a que nuestros límites son aproximados, no podemos utilizarlos como una evaluación probabilística concluyente. En cambio, tomamos esto como otra pieza de evidencia para complementar nuestros hallazgos. Aunque podamos asumir que una función que aproximamos a partir de datos es Lipschitz continua, rara vez conocemos en realidad la constante de Lipschitz para cualquier subconjunto de Θ. Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de los datos. Aquí, probamos tres métodos para hacer esto. El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subintervalo. Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo. Un método alternativo es tomar un límite superior en la pendiente obtenida dentro de cada subintervalo utilizando los datos disponibles. Esto produce un límite superior de probabilidades mucho menos conservador. Sin embargo, dado que el límite superior real suele ser mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso. Un último método que intentamos es un compromiso entre los dos anteriores. En lugar de tomar el límite superior conservador basado en datos sobre todo el dominio de la función Θ, tomamos el promedio de los límites superiores obtenidos en cada Θj. El límite en un intervalo se toma como el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos. Los resultados de evaluar la expresión para Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3. En términos de nuestras afirmaciones en maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Tabla 3: Límite superior aproximado de la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con un objetivo α = 2. Se utilizan diferentes métodos para aproximar el límite superior de la pendiente en cada subintervalo j. En este trabajo, la expresión proporciona un límite superior a la probabilidad de que alguna configuración de θ (es decir, costo de almacenamiento) en el intervalo [0,320] resulte en una adquisición total del día 0 que no sea mayor en ningún equilibrio que el objetivo especificado por α y tomado aquí como 2. Como sospechábamos, el enfoque más conservador para estimar el límite superior de la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí. Sin embargo, los otros dos enfoques de estimación, encontrados en las columnas dos y tres de la Tabla 3, sugieren que de hecho estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría funcionado. Dada la tremenda dificultad del problema, este resultado es muy sólido. Aun así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia. Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y los conjuntos de estrategias). Tampoco podemos esperar obtener nunca suficiente evidencia para llegar a conclusiones completamente objetivas. En cambio, el enfoque que defendemos aquí es recopilar la mayor cantidad de evidencia posible dadas las limitaciones de recursos, y tomar la decisión más convincente basada en esta evidencia, si es posible. RESULTADOS DE CONVERGENCIA En este punto, exploramos abstractamente si una elección de parámetro de diseño basada en datos de pago puede ser asintóticamente confiable. Dado que no teníamos todas las desviaciones posibles para cualquier perfil disponible en los datos, los verdaderos límites superiores pueden ser aún más bajos. Por conveniencia, utilizaremos la notación un,i(a) para referirnos a una función de pago del jugador i basada en un promedio sobre n muestras i.i.d. de la distribución de pagos. También asumimos que un,i(a) son independientes para todo a ∈ A e i ∈ I. Utilizaremos la notación Γn para referirnos al juego [I, R, {ui,n(·)}], mientras que Γ denotará el juego subyacente, [I, R, {ui(·)}]. De manera similar, definimos n(r) como (r) con respecto al juego Γn. En esta sección, demostramos que n(s) → (s) casi seguramente de forma uniforme en el espacio de estrategias mixtas para cualquier juego finito, y, además, que todas las equilibrios de Nash en estrategias mixtas en juegos empíricos eventualmente se acercan arbitrariamente a algunas estrategias de equilibrio de Nash en el juego subyacente. Utilizamos estos resultados para demostrar que bajo ciertas condiciones, la elección óptima del parámetro de diseño basada en datos empíricos converge casi seguramente al óptimo real. TEOREMA 3. Supongamos que |I| < ∞, |A| < ∞. Entonces n(s) → (s) casi seguramente uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios de Nash de Γ. Si definimos Nn,γ = {s ∈ S : n(s) ≤ γ}, tenemos el siguiente corolario del Teorema 3: COROLARIO 4. Para todo γ > 0, existe un M tal que para todo n ≥ M, N ⊂ Nn,γ casi seguramente. PRUEBA. Dado que n(s) = 0 para todo s ∈ N, podemos encontrar un M lo suficientemente grande tal que Pr{supn≥M sups∈N n(s) < γ} = 1. Según el Corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier > 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios de Nash empíricos si se han tomado suficientes muestras. Como mostramos ahora, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un límite no nulo como una estimación del conjunto de equilibrios de Nash. Primero, supongamos que concluimos que para una configuración particular de θ, sup{ˆφ∗ (θ)} ≤ α. Entonces, dado que para cualquier fijo > 0, N(θ) ⊂ Nn, (θ) cuando n es suficientemente grande, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α para cualquier n de este tipo. Así, dado que definimos la función de bienestar del diseñador como I{sup{φ∗ (θ)} ≤ α} en nuestro dominio de interés, la elección empírica de θ satisface el objetivo del diseñador, maximizando así su función de bienestar. Alternativamente, supongamos que concluimos que inf{ˆφ∗ (θ)} > α para cada θ en el dominio. Entonces, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, para todo θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo del diseñador. Ahora, demostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de Γn está cerca de algún equilibrio de Nash del juego subyacente. Este resultado nos llevará a considerar la convergencia de los optimizadores basados en datos empíricos a los ajustes óptimos reales de los parámetros del mecanismo. Primero notamos que la función (s) es continua en un juego finito. LEMMA 5. \n\nLEMMA 5. Sea S un conjunto de estrategias mixtas definido en un juego finito. Entonces: S → R es continua. Para la exposición que sigue, necesitamos un poco de notación adicional. Primero, sea (Z, d) un espacio métrico, y X, Y ⊂ Z y definamos la distancia de Hausdorff dirigida de X a Y como h(X, Y) = sup x∈X inf y∈Y d(x, y). Observa que U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ). Además, define BS(x, δ) como una bola abierta en S ⊂ Z con centro en x ∈ S y radio δ. Ahora, dejemos que Nn denote todos los equilibrios de Nash del juego Γn y sea Nδ = [ x∈N BS(x, δ), es decir, la unión de bolas abiertas de radio δ con centros en los equilibrios de Nash de Γ. Ten en cuenta que h(Nδ, N) = δ. Podemos entonces demostrar el siguiente resultado general. TEOREMA 6. Supongamos que |I| < ∞ y |A| < ∞. Entonces casi con seguridad h(Nn, N) converge a 0. Ahora demostraremos que en el caso especial cuando Θ y A son finitos y cada Γθ tiene un equilibrio de Nash único, las estimaciones ˆθ del parámetro óptimo del diseñador convergen a un optimizador real casi seguramente. Sea ˆθ = arg maxθ∈Θ W (Nn(θ), θ), donde n es el número de veces que se muestreó cada perfil puro en Γθ para cada θ, y sea θ∗ = arg maxθ∈Θ W (N(θ), θ). TEOREMA 7. Supongamos que |N(θ)| = 1 para todo θ ∈ Θ y supongamos que Θ y A son finitos. Sea W (s, θ) continua en el único s∗ (θ) ∈ N(θ) para cada θ ∈ Θ. Entonces ˆθ es un estimador consistente de θ∗ si W (N(θ), θ) se define como un supremo, ínfimo o esperanza sobre el conjunto de equilibrios de Nash. De hecho, ˆθ → θ∗ casi seguramente en cada uno de estos casos. La limitación del resultado anterior es que, dentro de nuestro marco de trabajo, el diseñador no tiene forma de saber o asegurar que Γθ tenga equilibrios únicos. Sin embargo, sí proporciona cierta justificación teórica para seguir el diseño de esta manera, y quizás servirá como guía para obtener resultados más generales en el futuro. 6. TRABAJO RELACIONADO La literatura de diseño de mecanismos en Economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10]. Además, existe una extensa literatura sobre el diseño óptimo de subastas [10], del cual el trabajo de Roger Myerson [11] es, quizás, el más relevante. En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y teniendo en cuenta restricciones como la compatibilidad de incentivos y la racionalidad individual. Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de Ciencias de la Computación. Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros relevantes del juego son conocimiento común. Cuando las funciones de pago de los jugadores son desconocidas, se ha explorado la realización de búsquedas mediante simulaciones como alternativa. Un enfoque en esa dirección, tomado en [4] y [15], es coevolucionar el parámetro del mecanismo y las estrategias de los agentes, utilizando alguna noción de utilidad social y pagos de los agentes como criterios de aptitud. Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética. En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron un resultado de un juego inducido por un parámetro del mecanismo como el resultado del aprendizaje conjunto de los agentes. Más recientemente, Phelps et al. [14] compararon dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en juegos definidos por estrategias heurísticas, como en [18]. 7. CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el diseño empírico de mecanismos. Definimos un modelo formal de teoría de juegos de interacción entre el diseñador y los participantes del mecanismo como un juego de dos etapas. También describimos en cierta generalidad los métodos para estimar una función de equilibrio de Nash de muestra cuando los datos son extremadamente escasos, o una correspondencia de equilibrio de Nash cuando hay más datos disponibles. Nuestras técnicas están diseñadas específicamente para abordar problemas en los que tanto el espacio de parámetros del mecanismo como los conjuntos de estrategias de los agentes son infinitos y solo se puede adquirir un conjunto de datos relativamente pequeño. Un problema de diseño difícil en el juego TAC/SCM que la comunidad de TAC ha estado ansiosa por abordar nos brinda un escenario para probar nuestros métodos. Al aplicar el análisis empírico del juego al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos. Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia del equilibrio de Nash. Al final, podemos intentar proporcionar suficiente evidencia para prescribir una configuración de parámetros, o sugerir que no es posible encontrar una configuración que satisfaga al diseñador. En el caso de TAC/SCM, nuestra evidencia sugiere bastante claramente que el costo de almacenamiento no pudo haber sido ajustado de manera efectiva en el torneo de 2004 para frenar la adquisición excesiva del día 0 sin efectos perjudiciales en la rentabilidad general. El éxito de nuestro análisis en este entorno extremadamente complejo con altos costos de simulación nos hace ser optimistas de que nuestros métodos pueden brindar orientación en la toma de decisiones de diseño de mecanismos en otros dominios desafiantes. Los resultados teóricos confirman algunas intuiciones detrás de los métodos de diseño de mecanismos empíricos que hemos introducido, y aumentan nuestra confianza en que nuestro marco puede ser efectivo para estimar la mejor elección de parámetros del mecanismo en entornos relativamente generales. Agradecimientos Agradecemos a Terence Kelly, Matthew Rudary y Satinder Singh por sus útiles comentarios sobre versiones anteriores de este trabajo. Este trabajo fue apoyado en parte por la subvención de la NSF IIS-0205435 y el programa de razonamiento estratégico DARPA REAL. 8. REFERENCIAS [1] R. Arunachalam y N. M. Sadeh. La competencia de agentes de comercio de la cadena de suministro. Investigación y aplicaciones del comercio electrónico, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy y M. Tschantz. Un enfoque de programación estocástica para la planificación en TAC SCM. En la Quinta Conferencia ACM sobre Comercio Electrónico, páginas 152-159, Nueva York, 2004. [3] Y.-P. Chang y W.-T. Huang. Intervalos de confianza generalizados para el valor más grande de algunas funciones de parámetros bajo normalidad. Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.\nEstadística Sinica, 10:1369-1383, 2000. [4] D. Cliff. Evolución del mecanismo de mercado a través de un espacio continuo de tipos de subasta. En el Congreso de Computación Evolutiva de 2002. [5] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [6] V. Conitzer y T. Sandholm. Un algoritmo para diseñar automáticamente mecanismos determinísticos sin pagos. En la Tercera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagente, páginas 128-135, 2004. [7] D. Friedman. Juegos evolutivos en economía. Econometrica, 59(3):637-666, mayo de 1991. [8] R. Keener. Teoría Estadística: Una Mezcla de Temas Fundamentales. Departamento de Estadística de la Universidad de Michigan, 2004. [9] C. Kiekintveld, Y. Vorobeychik y M. P. Wellman. Un análisis de la competencia de agentes comerciales de gestión de la cadena de suministro de 2004. En el taller IJCAI-05 sobre Diseño y Análisis de Agentes de Negociación, Edimburgo, 2005. [10] A. Mas-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [11] R. B. Myerson.\nEditorial de la Universidad de Oxford, 1995. [11] R. B. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6(1):58-73, febrero de 1981. [12] S. Olafsson y J. Kim. Optimización de simulación. En E. Yucesan, C.-H. Chen, J. Snowdon y J. Charnes, editores, Conferencia de Simulación de Invierno 2002, 2002. [13] D. Pardoe y P. Stone. TacTex-03: Un agente de gestión de la cadena de suministro. SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, y P. McBurney. Agentes automatizados versus humanos virtuales: una comparación teórica evolutiva de dos diseños de mercado de subasta doble. En Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney y E. Sklar. Co-evolución de mecanismos de subasta y estrategias de negociación: hacia un enfoque novedoso para el diseño microeconómico. En el taller ECOMAS 2002, 2002. [16] S. Phelps, S. Parsons, E. Sklar y P. McBurney. Utilizando programación genética para optimizar reglas de precios para un mercado de subasta doble. En Taller sobre Agentes para el Comercio Electrónico, 2003. [17] Y. Vorobeychik, M. P. Wellman y S. Singh. Aprendiendo funciones de pago en juegos infinitos. En la Decimonovena Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro y J. O. Kephart. Analizando interacciones estratégicas complejas en sistemas multiagente. En el taller AAAI-02 sobre agentes teóricos de juegos y de toma de decisiones, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld y V. Soni. Interacciones estratégicas en un juego de cadena de suministro. Inteligencia Computacional, 21(1):1-26, febrero de 2005. APÉNDICE A. PRUEBAS A.1 Prueba de la Proposición 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du. A.2 Prueba de la Proposición 2 Primero, supongamos que alguna función, f(x), definida en [ai, bi], satisface la condición de Lipschitz en (ai, bi] con una constante de Lipschitz Ai. Entonces se cumple la siguiente afirmación: Afirmación: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai). Para demostrar esta afirmación, observe que la intersección de las líneas en f(ai) y f(bi) con pendientes -Ai y Ai respectivamente determinará el límite inferior del mínimo de f(x) en [ai, bi] (que es un límite inferior del ínfimo de f(x) en (ai, bj]). La línea en f(ai) está determinada por f(ai) = −Aiai + cL y la línea en f(bi) está determinada por f(bi) = Aibi + cR. Por lo tanto, las intercepciones son cL = f(ai) + Aiai y cR = f(bi) + Aibi respectivamente. Sea x∗ el punto en el que estas líneas se cruzan. Entonces, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A. Al sustituir las expresiones de cR y cL, obtenemos el resultado deseado. Ahora, la subaditividad nos da Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, y, por la afirmación, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}. Dado que tenemos un número finito de puntos en el conjunto de datos para cada θ, podemos obtener la siguiente expresión: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}. Ahora podemos restringir nuestra atención en obtener una cota superior en Pr{sup{φ∗ (θ)} = y} para un θ fijo. Para hacer esto, observe que Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} por subaditividad y el hecho de que un perfil a es un equilibrio de Nash si y solo si (a) = 0. Poner todo junto produce el resultado deseado. Prueba de Teorema 3 En primer lugar, necesitaremos el siguiente hecho: Afirmación: Dada una función fi(x) y un conjunto X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|. Para demostrar esta afirmación, observe que | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) si maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) si maxx f2(x) ≥ maxx f1(x) En el primer caso, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 De manera similar, en el segundo caso, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|. Por lo tanto, la afirmación se mantiene. Por la Ley Fuerte de los Grandes Números, un,i(a) → ui(a) casi seguramente para todo i ∈ I, a ∈ A. Es decir, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, o, equivalentemente [8], para cualquier α > 0 y δ > 0, existe M(i, a) > 0 tal que Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Al tomar M = maxi∈I maxa∈A M(i, a), tenemos que Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Así, por la afirmación, para cualquier n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ con una probabilidad de al menos 1 − α. Ten en cuenta que dado que s−i(a) y s(a) están acotados entre 0 y 1, pudimos eliminarlos de las expresiones anteriores para obtener una cota que será válida independientemente de la elección particular de s. Además, dado que el resultado anterior se puede obtener para un α arbitrario > 0 y δ > 0, tenemos que Pr{limn→∞ n(s) = (s)} = 1 uniformemente en S. A.4 Prueba del Lema 5 Demostramos el resultado utilizando la continuidad uniforme de ui(s) y la preservación de la continuidad bajo el máximo. Afirmación: Una función f : Rk → R definida por f(t) = Σi=1k zi ti, donde zi son constantes en R, es uniformemente continua en t. La afirmación se sigue porque |f(t)−f(t )| = | Σi=1k zi(ti−ti)| ≤ Σi=1k |zi||ti − ti|. Un resultado inmediato de esto para nuestros propósitos es que ui(s) es uniformemente continua en s y ui(ai, s−i) es uniformemente continua en s−i. Afirmación: Sea f(a, b) uniformemente continua en b ∈ B para cada a ∈ A, con |A| < ∞. Entonces V (b) = maxa∈A f(a, b) es uniformemente continua en b. Para demostrar esto, toma γ > 0 y deja que b, b ∈ B tal que b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ. Ahora toma δ = mina∈A δ(a). Entonces, cada vez que b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ. Ahora, recuerda que (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)]. Según las afirmaciones anteriores, maxai∈Ai ui(ai, s−i) es uniformemente continua en s−i y ui(s) es uniformemente continua en s. Dado que la diferencia de dos funciones uniformemente continuas es uniformemente continua, y dado que esta continuidad se conserva bajo el máximo según nuestra segunda afirmación, obtenemos el resultado deseado. Prueba de Teorema 6. Elija δ > 0. Primero, necesitamos asegurarnos de que se cumple la siguiente afirmación: Afirmación: ¯ = mins∈S\\Nδ (s) existe y ¯ > 0. Dado que Nδ es un subconjunto abierto de S compacto, se sigue que S \\ Nδ es compacto. Como también habíamos demostrado en el Lema 5 que (s) es continua, la existencia se sigue del teorema de Weierstrass. Es claro que ¯ > 0 ya que (s) = 0 si y solo si s es un equilibrio de Nash de Γ. Ahora, por el Teorema 3, para cualquier α > 0 existe un M tal que Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. En consecuencia, para cualquier δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Dado que esto se cumple para un α arbitrario > 0 y δ > 0, se obtiene el resultado deseado. Prueba de Teorema 7. Fija θ y elige δ > 0. Dado que W (s, θ) es continua en s∗ (θ), dado > 0 existe δ > 0 tal que para cada s que esté dentro de δ de s∗ (θ), |W (s, θ) - W (s∗ (θ), θ)| < . Según el Teorema 6, podemos encontrar M(θ) lo suficientemente grande para que todos los s ∈ Nn estén dentro de δ de s∗ (θ) para todo n ≥ M(θ) con probabilidad 1. Por consiguiente, para cualquier > 0 podemos encontrar M(θ) lo suficientemente grande tal que con probabilidad 1 tengamos supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < . Asumamos sin pérdida de generalidad que hay una elección óptima única de θ. Ahora, dado que el conjunto Θ es finito, también existe la segunda mejor opción de θ (si solo hay un θ ∈ Θ, esta discusión no tiene sentido de todos modos): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ). Supongamos sin pérdida de generalidad que θ∗∗ también es único y sea ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ). Entonces, si dejamos < ∆/2 y dejamos que M = maxθ∈Θ M(θ), donde cada M(θ) es lo suficientemente grande como para que supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., la elección óptima de θ basada en cualquier equilibrio empírico será θ∗ con probabilidad 1. Por lo tanto, en particular, dado cualquier distribución de probabilidad sobre equilibrios empíricos, la mejor elección de θ será θ∗ con probabilidad 1 (similarmente, si tomamos el supremo o el ínfimo de W (Nn(θ), θ) sobre el conjunto de equilibrios empíricos al construir la función objetivo). ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "empirical mechanism": {
            "translated_key": "diseño empírico de mecanismos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>empirical mechanism</br> Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our <br>empirical mechanism</br> analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as <br>empirical mechanism</br> design.",
                "In the sequel, we develop some general methods for <br>empirical mechanism</br> design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for <br>empirical mechanism</br> design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the <br>empirical mechanism</br> design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [
                "<br>empirical mechanism</br> Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "Our <br>empirical mechanism</br> analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as <br>empirical mechanism</br> design.",
                "In the sequel, we develop some general methods for <br>empirical mechanism</br> design and apply them to the TAC/SCM redesign problem.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for <br>empirical mechanism</br> design."
            ],
            "translated_annotated_samples": [
                "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo.",
                "Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado.",
                "Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de <br>mecanismos empíricos</br>.",
                "En la continuación, desarrollamos algunos métodos generales para el <br>diseño empírico de mecanismos</br> y los aplicamos al problema de rediseño TAC/SCM.",
                "CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el <br>diseño empírico de mecanismos</br>."
            ],
            "translated_text": "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de <br>mecanismos empíricos</br>. En la continuación, desarrollamos algunos métodos generales para el <br>diseño empírico de mecanismos</br> y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto. En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2. Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores. Ri es el conjunto de estrategias disponibles para el jugador i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×. . .×Am. A menudo es conveniente referirse a la estrategia del jugador i por separado de la de los demás jugadores. Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama un perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i). Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el jugador i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada jugador i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i. Podemos extender esta definición a estrategias mixtas asumiendo que ui son utilidades de von Neumann-Morgenstern (vNM) de la siguiente manera: ui(s) = Es[ui], donde Es es la expectativa tomada con respecto a la distribución de probabilidad del juego inducida por la estrategia mixta de los jugadores s. Al emplear la forma normal, modelamos a los agentes jugando una única acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones más detalladas sobre la acción a lo largo del tiempo en la forma extensiva. Aunque cualquier juego extenso puede ser reformulado en forma normal, hacerlo puede sacrificar la concisión y difuminar distinciones relevantes (por ejemplo, la perfección en subjuegos). Ocasionalmente, escribimos ui(x, y) para indicar que x ∈ Ai o Si y y ∈ A−i o S−i dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u(·) = {u1(·), . . . , um(·)}. Definimos una función, : R → R, interpretada como el beneficio máximo que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) donde r pertenece a algún conjunto de estrategias, R, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada aquellas jugadas por los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un equilibrio de Nash. DEFINICIÓN 1. Un perfil estratégico r = (r1, . . . , rm) constituye un equilibrio de Nash del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). Cuando r ∈ A, lo anterior define un equilibrio de Nash de estrategia pura; de lo contrario, la definición describe un equilibrio de Nash de estrategia mixta. A menudo recurrimos al concepto de un equilibrio aproximado, o equilibrio de Nash, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita. Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un equilibrio de Nash si (r) ≤ . En este estudio dedicamos especial atención a los juegos que presentan simetría en cuanto a los pagos, lo que hace que los agentes sean estratégicamente idénticos. DEFINICIÓN 2. Un juego [I, {Ri}, {ui(r)}] es simétrico si para todo i, j ∈ I, (a) Ri = Rj y (b) ui(ri, r−i) = uj (rj, r−j) siempre que ri = rj y r−i = r−j. EL MODELO Modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un juego de dos etapas. El diseñador comienza seleccionando primero un valor, θ, de un conjunto de configuraciones de mecanismos permitidas, Θ. Todos los agentes participantes observan el parámetro θ del mecanismo y se mueven simultáneamente después. Por ejemplo, el diseñador podría estar decidiendo entre mecanismos de subasta de sobre cerrado de precio único y de precio único, con la presunción de que una vez tomada la decisión, los postores participarán con pleno conocimiento de las reglas de la subasta. Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como Γθ = [I, {Ri}, {ui(r, θ)}]. Nos referimos a Γθ como un juego inducido por θ. Sea N(θ) el conjunto de perfiles estratégicos considerados soluciones del juego Γθ.3. Supongamos que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, W(r, θ), dependiente del parámetro del mecanismo y del juego resultante, r. Definimos una medida pesimista, W( ˆR, θ) = inf{W(r, θ) : r ∈ ˆR}, que representa el bienestar en el peor de los casos del juego inducido por θ, asumiendo que los agentes juegan alguna estrategia conjunta en ˆR. Normalmente nos preocupamos por W (N(θ), θ), el resultado en el peor de los casos de jugar alguna solución. En algunos problemas podemos obtener una considerable ventaja al utilizar una función de agregación para mapear el resultado del bienestar de un juego. Generalmente adoptamos el equilibrio de Nash como concepto de solución, y por lo tanto tomamos N(θ) como el conjunto de equilibrios. Sin embargo, gran parte de la metodología desarrollada aquí podría ser utilizada con criterios alternativos para derivar el comportamiento del agente a partir de una definición del juego. Nuevamente, existen alternativas disponibles. Por ejemplo, si se tiene una distribución de probabilidad sobre el conjunto de soluciones N(θ), sería natural tomar la expectativa de W(r, θ) en su lugar. 307 especificado en términos de estrategias de agentes a un resultado de bienestar equivalente especificado en términos de un resumen de menor dimensión. DEFINICIÓN 3. Una función φ: R1 × · · · × Rm → Rq es una función de agregación si m ≥ q y W(r, θ) = V(φ(r), θ) para alguna función V. Sobrecargamos el símbolo de función para aplicar a conjuntos de perfiles estratégicos: φ( ˆR) = {φ(r) : r ∈ ˆR}. Para mayor comodidad en la exposición, escribimos φ∗ (θ) para denotar φ(N(θ)). El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia. Por ejemplo, supongamos, como en nuestra aplicación a continuación, que la estrategia de un agente está definida por un parámetro numérico. Si todo lo que nos importa es el valor total jugado, podemos tomar φ(a) = Πm i=1 ai. Si hemos elegido nuestro agregador cuidadosamente, también podemos capturar estructuras que de otra manera no serían evidentes. Por ejemplo, φ∗ (θ) podría estar disminuyendo en θ, mientras que N(θ) podría tener una estructura más compleja. Dada una descripción de la correspondencia de solución N(θ) (equivalentemente, φ∗(θ)), el diseñador se enfrenta a un problema estándar de optimización. Alternativamente, dado un simulador que pudiera producir una muestra imparcial de la distribución de W (N(θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12]. Sin embargo, incluso para un juego Γθ con pagos conocidos, puede resultar computacionalmente intratable resolver los equilibrios de Nash, especialmente si el juego tiene conjuntos de estrategias grandes o infinitos. Además, deseamos estudiar juegos en los que los pagos no se dan explícitamente, sino que deben determinarse a partir de simulaciones u otra experiencia con el juego. Por lo tanto, asumimos que se nos proporciona un conjunto de datos (posiblemente ruidoso) de realizaciones de pagos: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, donde para cada punto de datos θi es el ajuste observado del parámetro del mecanismo, ai es el perfil de estrategia pura observado de los participantes, y Ui es la realización correspondiente de los pagos de los agentes. También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}. Sea D = {Do, Ds} el conjunto de datos combinado. (Ya sea que Do o Ds puedan ser nulos para un problema particular). En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos empíricos de teoría de juegos, para responder preguntas sobre el diseño del escenario TAC/SCM. 4. ANÁLISIS DE DISEÑO EMPÍRICO Dado que nuestros datos se presentan en forma de experiencia de pago y no como el valor de una función objetivo para configuraciones dadas de la variable de control, ya no podemos confiar en los métodos para optimizar funciones utilizando simulaciones. De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia del equilibrio de Nash. Además, no podemos depender directamente de los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilístico adaptados a nuestra configuración de problema. 4.1 Problema de Diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente. Recuerde que durante el torneo de 2004, los diseñadores del juego de la cadena de suministro optaron por aumentar drásticamente los costos de almacenamiento como medida para frenar las compras del día 0, con poco éxito. Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y la cantidad agregada de componentes adquiridos el día 0 en equilibrio. Esto suele ser el caso en juegos reales de interés, donde descripciones en lenguaje natural o algorítmicas pueden sustituir a una especificación formal de estrategias y funciones de pago. Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo. ¿Primero, ¿el aumento de los costos de almacenamiento realmente reduce la adquisición en el día 0? ¿Fue racional la adquisición excesiva observada durante el día 0 del torneo de 2004? Y en tercer lugar, ¿podría haber reducido de manera suficiente los costos de almacenamiento la adquisición del día 0 a un nivel aceptable, y en tal caso, cuál debería haber sido el ajuste de los costos de almacenamiento? Es esta tercera pregunta la que define el aspecto del diseño de mecanismos de nuestro análisis. Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de los agentes, la función de bienestar de los diseñadores, el espacio de parámetros del mecanismo y la fuente de datos. Restringimos las estrategias de los agentes para que sean un multiplicador de la cantidad de solicitudes del día 0 de uno de los finalistas, Deep Maize, en el torneo TAC/SCM de 2004. Lo restringimos aún más al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias por encima de 1.5 son extremadamente agresivas (por lo tanto, poco probables de proporcionar desviaciones refutadoras más allá de las disponibles en las estrategias incluidas, y ciertamente no forman parte de ningún equilibrio deseable). Todo otro comportamiento se basa en el comportamiento de Deep Maize y es idéntico para todos los agentes. Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico. Sin embargo, creemos que la forma general de los resultados debería ser robusta ante cambios en el comportamiento completo del agente. Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0. Sea φ(a) = Σ6 i=1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego particular de la cadena de suministro (para perfiles de estrategia mixta s, tomamos la esperanza de φ con respecto a la mezcla). La función de bienestar de los diseñadores W (N(θ), θ) se define entonces como I{sup{φ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de adquisición en el día 0 y I es la función indicadora. El diseñador selecciona un valor θ de costos de almacenamiento, expresado como un porcentaje anual del valor base de los componentes en el inventario (cobrado diariamente), del conjunto Θ = R+. Dado que la decisión de los diseñadores depende solo de φ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación. 4.2 Estimación de equilibrios de Nash El objetivo de los agentes de TAC/SCM es maximizar los beneficios obtenidos en una instancia del juego. Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, U(a)). Si también hemos fijado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de jugadores y sus correspondientes pagos, y, en consecuencia, para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios de Nash de cada juego Γθ. Por lo tanto, necesitamos métodos para aproximar equilibrios de Nash en juegos infinitos. A continuación, describimos los dos métodos que utilizamos en nuestro estudio. El primero ha sido explorado empíricamente anteriormente, mientras que el segundo se introduce aquí como el método específicamente diseñado para aproximar un conjunto de equilibrios de Nash. 4.2.1 Aproximación de la Función de Pago El primer método para estimar equilibrios de Nash basado en datos utiliza aprendizaje supervisado para aproximar las funciones de pago de mech6. No abordamos si y cómo otras medidas (por ejemplo, restringir directamente la adquisición) podrían haber logrado los objetivos de diseño. Nuestro enfoque considera como dado un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento. En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con un crecimiento de complejidad correspondiente. 308 participantes del mecanismo de un conjunto de datos de experiencia de juego [17]. Una vez que las funciones de pago aproximadas estén disponibles para todos los jugadores, los equilibrios de Nash pueden encontrarse ya sea de forma analítica o aproximada utilizando técnicas numéricas, dependiendo del modelo de aprendizaje. En lo que sigue, estimamos solo un equilibrio de Nash de muestra utilizando esta técnica, aunque esta restricción puede eliminarse a expensas de un tiempo de cálculo adicional. Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador. Por lo tanto, podemos aplicarlo cuando Ds = ∅. Si hay un simulador disponible, podemos generar datos adicionales para aumentar la confianza en nuestras estimaciones iniciales. Probamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado local (LWA) y regresión lineal ponderada localmente (LWLR). También utilizamos variables de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis empírico previo de teoría de juegos de TAC/SCM-03 [19]. El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido de forma analítica. Para los otros métodos aplicamos dinámica replicadora [7] a una aproximación discreta del juego aprendido. El total esperado de adquisiciones del día 0 en equilibrio se tomó como la estimación de un resultado. 4.2.2 Búsqueda en el Espacio de Perfiles de Estrategia Cuando tenemos acceso a un simulador, también podemos utilizar la búsqueda dirigida a través del espacio de perfiles para estimar el conjunto de equilibrios de Nash, que describimos aquí después de presentar alguna notación adicional. DEFINICIÓN 4. Un vecino estratégico de un perfil de estrategia pura a es un perfil que es idéntico a a en todo menos en una estrategia. Definimos Snb(a, D) como el conjunto de todos los vecinos estratégicos de a disponibles en el conjunto de datos D. De manera similar, definimos Snb(a, ˜D) como todos los vecinos estratégicos de a que no están en D. Finalmente, para cualquier a ∈ Snb(a, D) definimos al agente que se desvía como i(a, a). DEFINICIÓN 5. La -ligadura, ˆ, de un perfil de estrategia pura a se define como maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}. Decimos que a es un candidato a δ-equilibrio para δ ≥ ˆ. Cuando Snb(a, ˜D) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), a se confirma como un equilibrio de Nash ˆ. Nuestro método de búsqueda opera explorando desviaciones de los equilibrios candidatos. Nos referimos a esto como BestFirstSearch, ya que selecciona con probabilidad uno un perfil de estrategia a ∈ Snb(a, ˜D) que tiene el menor ˆin D. Finalmente definimos un estimador para un conjunto de equilibrios de Nash. DEFINICIÓN 6. Para un conjunto K, define Co(K) como la envoltura convexa de K. Sea Bδ el conjunto de candidatos en el nivel δ. Definimos ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) para un δ fijo como un estimador de φ∗ (θ). En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles estratégicos agregados con límite inferior -bound por debajo de un δ fijo. Esta definición nos permite explotar la estructura que surge de la función de agregación. Si dos perfiles son cercanos en términos de valores de agregación, es probable que tengan límites similares. En particular, si uno está en equilibrio, el otro también puede estarlo. Presentamos un respaldo teórico para este método de estimación del conjunto de equilibrios de Nash a continuación. Dado que el juego en el que estamos interesados es infinito, es necesario terminar BestFirstSearch antes de explorar todo el espacio de strat7. Por ejemplo, podemos utilizar técnicas de aprendizaje activo [5] para mejorar la calidad de la aproximación de la función de recompensa. En este trabajo, nos concentramos en la búsqueda en el espacio de perfiles estratégicos. Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos. Generación de datos Nuestros datos fueron recopilados simulando juegos TAC/SCM en una versión local del servidor TAC/SCM de 2004, que tiene una configuración para el costo de almacenamiento. Las estrategias de los agentes en juegos simulados fueron seleccionadas del conjunto {0, 0.3, 0.6, . . . , 1.5} con el fin de tener una probabilidad positiva de generar vecinos estratégicos. Se generó un conjunto de datos base Do mediante el muestreo de 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}. Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varios defectos. Utilizamos la búsqueda para generar un conjunto de datos simulados Ds, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ. Dado que el costo de la simulación es extremadamente alto (un juego tarda casi 1 hora en ejecutarse), pudimos ejecutar un total de 2670 juegos en el transcurso de más de seis meses. Para hacer una comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategias conjuntas finitas restringidas para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces). 4.4 Resultados 4.4.1 Análisis del conjunto de datos base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos base Do. Además, generamos una estimación de la correspondencia del equilibrio de Nash, ˆφ∗ (θ), aplicando la Definición 6 con δ = 2.5E6. Los resultados se muestran en la Figura 1. Como podemos ver, la correspondencia ˆφ∗ (θ) tiene poco poder predictivo basado en Do, y no revela ninguna estructura interesante sobre el juego. Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición Total Día 0 LWA LWLR QR BaselineMin BaselineMax Figura 1: Estimaciones de adquisición del día 0 agregadas basadas en Do. La correspondencia ˆφ∗ (θ) es el intervalo entre BaselineMin y BaselineMax. En general, la búsqueda se detiene una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para obtener conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego. Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash a permanecer en este subconjunto discreto de [0,1.5]. Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron accidentes, problemas de conectividad de red y otras anomalías obvias), el juego sería descartado. Análisis de los datos de búsqueda Para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ∗ (θ) (nuevamente, usando δ =2.5E6) en el conjunto de datos D = {Do, Ds}, donde Ds es datos generados a través de la aplicación de BestFirstSearch. Los resultados de esta estimación se representan gráficamente frente a los resultados de los métodos de aprendizaje entrenados en Do 11 en la Figura 2. Primero, observamos que la adición de los datos de búsqueda reduce considerablemente el rango de posibles equilibrios. Además, las predicciones puntuales reales de los métodos de aprendizaje y aquellas basadas en límites después de la búsqueda son razonablemente cercanas. Combinar la evidencia recopilada de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquiera de los métodos utilizados de forma aislada. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición del Día 0 LWA LWLR QR Búsqueda Mínima Búsqueda Máxima Figura 2: Estimaciones agregadas de adquisición del día 0 basadas en la búsqueda en el espacio de perfiles de estrategia en comparación con técnicas de aproximación de funciones entrenadas en Do. La correspondencia ˆφ∗ (θ) para D = {Do, Ds} es el intervalo entre SearchMin y SearchMax. Esta evidencia respalda la intuición inicial de que la adquisición del día 0 debería disminuir con los costos de almacenamiento. También confirma que los altos niveles de adquisición en el día 0 son una respuesta racional al entorno del torneo de 2004 con un costo promedio de almacenamiento, que corresponde a θ = 100. La predicción mínima para la adquisición agregada en este nivel de costos de almacenamiento, dada por cualquier método experimental, es aproximadamente 3. Esto es bastante alto, ya que corresponde a un compromiso esperado del 1/3 de la capacidad total del proveedor para todo el juego. La predicción máxima es considerablemente mayor a 4.5. En la competencia actual de 2004, la adquisición total del día 0 equivalía a 5.71 en la escala utilizada aquí [9]. Nuestras predicciones subestiman este resultado en cierta medida, pero muestran que cualquier resultado racional probablemente tendría una alta adquisición en el día 0. 4.4.3 Extrapolando la Correspondencia de la Solución Tenemos evidencia razonablemente sólida de que la correspondencia del resultado está disminuyendo. Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento a un valor que reduciría la adquisición del día 0 en equilibrio, o concluir que esto no es posible. Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día 0. No está claro cuán significativos serían los resultados del aprendizaje si se agregaran Ds al conjunto de datos de entrenamiento. De hecho, los datos adicionales pueden aumentar realmente la varianza del aprendizaje. Recuerde que el objetivo de los diseñadores es incentivar la adquisición agregada del día 0 que esté por debajo del umbral α. Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultados estimada a partir de D que produce θ = 320. Los datos para θ = 320 fueron recopilados de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos por 33 iteraciones de BestFirstSearch. La Figura 3 muestra los límites detallados para todos los perfiles en términos de sus valores correspondientes de φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Límites de ε de Adquisición Total Día-0 Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320. Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ(a). La región gris corresponde a ˆφ∗ (320) con δ = 2.5M. El conjunto estimado de resultados agregados del día 0 es muy cercano al de θ = 200, lo que indica que hay poco beneficio adicional al aumentar los costos de almacenamiento por encima de 200. Observa que incluso el límite inferior de nuestro conjunto estimado de equilibrios de Nash está muy por encima de la adquisición objetivo del día 0 de 2. Además, las recompensas para los agentes son casi siempre negativas en θ = 320. Por consiguiente, aumentar los costos aún más sería indeseable incluso si finalmente se pudiera reducir la adquisición en el día 0. Dado que tenemos una confianza razonable de que φ∗ (θ) está disminuyendo en θ, tampoco esperamos que establecer θ en algún lugar entre 200 y 320 logre el resultado deseado. Concluimos que es poco probable que la adquisición del día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento. Que nuestras predicciones tienden a subestimar los resultados del torneo refuerza esta conclusión. Para lograr la reducción deseada en la adquisición del día 0 se requiere rediseñar otros aspectos del mecanismo. 4.5 Análisis Probabilístico Nuestro análisis empírico ha producido evidencia en apoyo a la conclusión de que ninguna configuración razonable del costo de almacenamiento probablemente sería suficiente para frenar la adquisición excesiva del día 0 en TAC/SCM 04. Toda esta evidencia ha sido en forma de simple interpolación y extrapolación de estimaciones de la correspondencia del equilibrio de Nash. Estas estimaciones se basan en simular instancias del juego y están sujetas a ruido de muestreo contribuido por los diversos elementos estocásticos del juego. En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos -bound a tales efectos estocásticos. Supongamos que todos los agentes tienen conjuntos de estrategias puras finitos (y pequeños), A. Por lo tanto, es factible muestrear toda la matriz de pagos del juego. Además, supongamos que el ruido es aditivo con media cero en promedio durante todo el juego, por lo que en la práctica probablemente querríamos que el umbral sea aún más bajo. 310 y varianza finita, es decir, Ui(a) = ui(a) + ˜ξi(a), donde Ui(a) es la ganancia observada para i cuando se jugó a, ui(a) es la ganancia correspondiente real, y ˜ξi(a) es una variable aleatoria normal con media cero. Designamos la varianza conocida de ˜ξi(a) como σ2 i (a). Por lo tanto, asumimos que ˜ξi(a) es normal con distribución N(0, σ2 i (a)). Tomamos ¯ui(a) como la media muestral de todos los Ui(a) en D, y seguimos a Chang y Huang [3] al asumir que tenemos una priori impropia sobre las ganancias reales ui(a) y el muestreo fue independiente para todos i y a. También confiamos en su resultado de que ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] son independientes con distribuciones posteriores N(¯ui(a), σ2 i (a)/ni(a)), donde ni(a) es el número de muestras tomadas de los pagos para i en el perfil puro a, y Zi(a) ∼ N(0, 1). Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio de Nash -Nash. Si ui(·)|¯ui(·) son independientes para todo i ∈ I y a ∈ A, tenemos el siguiente resultado (a partir de este punto omitimos la condición sobre ¯ui(·) por brevedad): PROPOSICIÓN 1. Para todo \\( i \\in I \\), \\( \\max_{b \\in A_i} u_i(b, a_{-i}) - u_i(a) \\leq \\varepsilon \\), donde \\( \\varepsilon = \\int_{Y_i} \\int_{Z} \\int_{R} \\int_{Y} \\int_{b \\in A_i \\backslash a_i} \\Pr(u_i(b, a_{-i}) \\leq u + \\varepsilon) f_{u_i(a)}(u) du \\), donde \\( f_{u_i(a)}(u) \\) es la función de densidad de probabilidad de \\( N(\\overline{u_i(a)}, \\sigma_i(a)) \\). Las pruebas de este y todos los resultados posteriores se encuentran en el Apéndice. La distribución posterior de la media óptima de n muestras, derivada por Chang y Huang [3], es Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) donde a ∈ A y Φ(·) es la función de distribución N(0, 1). Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilístico que (a) ≤ γ para un γ dado. Ahora, consideramos casos de datos incompletos y utilizamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en los datos) en la distribución de sup{φ∗ (θ)} e inf{φ∗ (θ)} (asumiendo que ambos son alcanzables): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, donde x es un número real y ≤D indica que el límite superior solo considera estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} y {inf{φ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf{φ∗ (θ)} ≤ x}. Los valores así derivados comprenden las Tablas 1 y 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Tabla 1: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando N(θ) es un conjunto de equilibrios de Nash. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Tabla 2: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {150, 200, 320} cuando N(θ) es un conjunto de equilibrios de Nash. Las Tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ(a) < 2.7 es poco probable para cualquier θ del cual tengamos datos, aunque este juicio, como mencionamos, se refiere únicamente a los perfiles que hemos muestreado realmente. Podemos entonces aceptar esto como otra pieza de evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, parece poco probable que el diseñador logre su objetivo incluso si pudiera persuadir a los participantes a jugar un equilibrio deseable. La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM de 2004 eran, de hecho, racionales al adquirir grandes cantidades de componentes al comienzo del juego. Si observamos la tercera columna de esta tabla, que corresponde a θ = 100, podemos deducir que ningún perfil a en nuestros datos con φ(a) < 3 es muy probable que se juegue en equilibrio. Los límites anteriores proporcionan algunas pruebas generales, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos muestreado. Particularmente, nos gustaría decir algo sobre lo que sucede en los ajustes de θ para los cuales no tenemos datos. Para derivar un límite probabilístico aproximado sobre la probabilidad de que ningún θ ∈ Θ haya logrado el objetivo del diseñador, sea ∪J j=1Θj una partición de Θ, y asuma que la función sup{φ∗ (θ)} satisface la condición de Lipschitz con constante de Lipschitz Aj en cada subconjunto Θj. Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a Θ = [0, 320]. Ahora definimos cada subconjunto j como el intervalo entre dos puntos para los cuales hemos producido datos. Por lo tanto, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], con j variando entre 1 y 5, correspondiendo a los subintervalos anteriores. Denotaremos cada Θj por (aj, bj]. Luego, la siguiente proposición nos da una cota superior aproximada sobre la probabilidad de que sup{φ∗ (θ)} ≤ α. PROPOSICIÓN 2. Debido a que nuestros límites son aproximados, no podemos utilizarlos como una evaluación probabilística concluyente. En cambio, tomamos esto como otra pieza de evidencia para complementar nuestros hallazgos. Aunque podamos asumir que una función que aproximamos a partir de datos es Lipschitz continua, rara vez conocemos en realidad la constante de Lipschitz para cualquier subconjunto de Θ. Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de los datos. Aquí, probamos tres métodos para hacer esto. El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subintervalo. Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo. Un método alternativo es tomar un límite superior en la pendiente obtenida dentro de cada subintervalo utilizando los datos disponibles. Esto produce un límite superior de probabilidades mucho menos conservador. Sin embargo, dado que el límite superior real suele ser mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso. Un último método que intentamos es un compromiso entre los dos anteriores. En lugar de tomar el límite superior conservador basado en datos sobre todo el dominio de la función Θ, tomamos el promedio de los límites superiores obtenidos en cada Θj. El límite en un intervalo se toma como el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos. Los resultados de evaluar la expresión para Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3. En términos de nuestras afirmaciones en maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Tabla 3: Límite superior aproximado de la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con un objetivo α = 2. Se utilizan diferentes métodos para aproximar el límite superior de la pendiente en cada subintervalo j. En este trabajo, la expresión proporciona un límite superior a la probabilidad de que alguna configuración de θ (es decir, costo de almacenamiento) en el intervalo [0,320] resulte en una adquisición total del día 0 que no sea mayor en ningún equilibrio que el objetivo especificado por α y tomado aquí como 2. Como sospechábamos, el enfoque más conservador para estimar el límite superior de la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí. Sin embargo, los otros dos enfoques de estimación, encontrados en las columnas dos y tres de la Tabla 3, sugieren que de hecho estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría funcionado. Dada la tremenda dificultad del problema, este resultado es muy sólido. Aun así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia. Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y los conjuntos de estrategias). Tampoco podemos esperar obtener nunca suficiente evidencia para llegar a conclusiones completamente objetivas. En cambio, el enfoque que defendemos aquí es recopilar la mayor cantidad de evidencia posible dadas las limitaciones de recursos, y tomar la decisión más convincente basada en esta evidencia, si es posible. RESULTADOS DE CONVERGENCIA En este punto, exploramos abstractamente si una elección de parámetro de diseño basada en datos de pago puede ser asintóticamente confiable. Dado que no teníamos todas las desviaciones posibles para cualquier perfil disponible en los datos, los verdaderos límites superiores pueden ser aún más bajos. Por conveniencia, utilizaremos la notación un,i(a) para referirnos a una función de pago del jugador i basada en un promedio sobre n muestras i.i.d. de la distribución de pagos. También asumimos que un,i(a) son independientes para todo a ∈ A e i ∈ I. Utilizaremos la notación Γn para referirnos al juego [I, R, {ui,n(·)}], mientras que Γ denotará el juego subyacente, [I, R, {ui(·)}]. De manera similar, definimos n(r) como (r) con respecto al juego Γn. En esta sección, demostramos que n(s) → (s) casi seguramente de forma uniforme en el espacio de estrategias mixtas para cualquier juego finito, y, además, que todas las equilibrios de Nash en estrategias mixtas en juegos empíricos eventualmente se acercan arbitrariamente a algunas estrategias de equilibrio de Nash en el juego subyacente. Utilizamos estos resultados para demostrar que bajo ciertas condiciones, la elección óptima del parámetro de diseño basada en datos empíricos converge casi seguramente al óptimo real. TEOREMA 3. Supongamos que |I| < ∞, |A| < ∞. Entonces n(s) → (s) casi seguramente uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios de Nash de Γ. Si definimos Nn,γ = {s ∈ S : n(s) ≤ γ}, tenemos el siguiente corolario del Teorema 3: COROLARIO 4. Para todo γ > 0, existe un M tal que para todo n ≥ M, N ⊂ Nn,γ casi seguramente. PRUEBA. Dado que n(s) = 0 para todo s ∈ N, podemos encontrar un M lo suficientemente grande tal que Pr{supn≥M sups∈N n(s) < γ} = 1. Según el Corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier > 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios de Nash empíricos si se han tomado suficientes muestras. Como mostramos ahora, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un límite no nulo como una estimación del conjunto de equilibrios de Nash. Primero, supongamos que concluimos que para una configuración particular de θ, sup{ˆφ∗ (θ)} ≤ α. Entonces, dado que para cualquier fijo > 0, N(θ) ⊂ Nn, (θ) cuando n es suficientemente grande, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α para cualquier n de este tipo. Así, dado que definimos la función de bienestar del diseñador como I{sup{φ∗ (θ)} ≤ α} en nuestro dominio de interés, la elección empírica de θ satisface el objetivo del diseñador, maximizando así su función de bienestar. Alternativamente, supongamos que concluimos que inf{ˆφ∗ (θ)} > α para cada θ en el dominio. Entonces, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, para todo θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo del diseñador. Ahora, demostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de Γn está cerca de algún equilibrio de Nash del juego subyacente. Este resultado nos llevará a considerar la convergencia de los optimizadores basados en datos empíricos a los ajustes óptimos reales de los parámetros del mecanismo. Primero notamos que la función (s) es continua en un juego finito. LEMMA 5. \n\nLEMMA 5. Sea S un conjunto de estrategias mixtas definido en un juego finito. Entonces: S → R es continua. Para la exposición que sigue, necesitamos un poco de notación adicional. Primero, sea (Z, d) un espacio métrico, y X, Y ⊂ Z y definamos la distancia de Hausdorff dirigida de X a Y como h(X, Y) = sup x∈X inf y∈Y d(x, y). Observa que U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ). Además, define BS(x, δ) como una bola abierta en S ⊂ Z con centro en x ∈ S y radio δ. Ahora, dejemos que Nn denote todos los equilibrios de Nash del juego Γn y sea Nδ = [ x∈N BS(x, δ), es decir, la unión de bolas abiertas de radio δ con centros en los equilibrios de Nash de Γ. Ten en cuenta que h(Nδ, N) = δ. Podemos entonces demostrar el siguiente resultado general. TEOREMA 6. Supongamos que |I| < ∞ y |A| < ∞. Entonces casi con seguridad h(Nn, N) converge a 0. Ahora demostraremos que en el caso especial cuando Θ y A son finitos y cada Γθ tiene un equilibrio de Nash único, las estimaciones ˆθ del parámetro óptimo del diseñador convergen a un optimizador real casi seguramente. Sea ˆθ = arg maxθ∈Θ W (Nn(θ), θ), donde n es el número de veces que se muestreó cada perfil puro en Γθ para cada θ, y sea θ∗ = arg maxθ∈Θ W (N(θ), θ). TEOREMA 7. Supongamos que |N(θ)| = 1 para todo θ ∈ Θ y supongamos que Θ y A son finitos. Sea W (s, θ) continua en el único s∗ (θ) ∈ N(θ) para cada θ ∈ Θ. Entonces ˆθ es un estimador consistente de θ∗ si W (N(θ), θ) se define como un supremo, ínfimo o esperanza sobre el conjunto de equilibrios de Nash. De hecho, ˆθ → θ∗ casi seguramente en cada uno de estos casos. La limitación del resultado anterior es que, dentro de nuestro marco de trabajo, el diseñador no tiene forma de saber o asegurar que Γθ tenga equilibrios únicos. Sin embargo, sí proporciona cierta justificación teórica para seguir el diseño de esta manera, y quizás servirá como guía para obtener resultados más generales en el futuro. 6. TRABAJO RELACIONADO La literatura de diseño de mecanismos en Economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10]. Además, existe una extensa literatura sobre el diseño óptimo de subastas [10], del cual el trabajo de Roger Myerson [11] es, quizás, el más relevante. En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y teniendo en cuenta restricciones como la compatibilidad de incentivos y la racionalidad individual. Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de Ciencias de la Computación. Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros relevantes del juego son conocimiento común. Cuando las funciones de pago de los jugadores son desconocidas, se ha explorado la realización de búsquedas mediante simulaciones como alternativa. Un enfoque en esa dirección, tomado en [4] y [15], es coevolucionar el parámetro del mecanismo y las estrategias de los agentes, utilizando alguna noción de utilidad social y pagos de los agentes como criterios de aptitud. Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética. En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron un resultado de un juego inducido por un parámetro del mecanismo como el resultado del aprendizaje conjunto de los agentes. Más recientemente, Phelps et al. [14] compararon dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en juegos definidos por estrategias heurísticas, como en [18]. 7. CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el <br>diseño empírico de mecanismos</br>. ",
            "candidates": [],
            "error": [
                [
                    "mecanismos empíricos",
                    "diseño empírico de mecanismos",
                    "diseño empírico de mecanismos"
                ]
            ]
        },
        "parameter setting": {
            "translated_key": "ajuste óptimo de parámetros",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism <br>parameter setting</br> based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism <br>parameter setting</br>, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a <br>parameter setting</br>, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [
                "More generally, we show that under certain conditions, the estimator of optimal mechanism <br>parameter setting</br> based on empirical data is consistent.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism <br>parameter setting</br>, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "In the end, we can try to provide enough evidence to either prescribe a <br>parameter setting</br>, or suggest that no setting is possible that will satisfy the designer."
            ],
            "translated_annotated_samples": [
                "Más generalmente, demostramos que bajo ciertas condiciones, el estimador del <br>ajuste óptimo de parámetros</br> del mecanismo basado en datos empíricos es consistente.",
                "Además, deseamos estudiar juegos en los que los pagos no se dan explícitamente, sino que deben determinarse a partir de simulaciones u otra experiencia con el juego. Por lo tanto, asumimos que se nos proporciona un conjunto de datos (posiblemente ruidoso) de realizaciones de pagos: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, donde para cada punto de datos θi es el <br>ajuste observado del parámetro del mecanismo</br>, ai es el perfil de estrategia pura observado de los participantes, y Ui es la realización correspondiente de los pagos de los agentes.",
                "Al final, podemos intentar proporcionar suficiente evidencia para prescribir una <br>configuración de parámetros</br>, o sugerir que no es posible encontrar una configuración que satisfaga al diseñador."
            ],
            "translated_text": "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del <br>ajuste óptimo de parámetros</br> del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismos empíricos. En la continuación, desarrollamos algunos métodos generales para el diseño empírico de mecanismos y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto. En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2. Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores. Ri es el conjunto de estrategias disponibles para el jugador i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×. . .×Am. A menudo es conveniente referirse a la estrategia del jugador i por separado de la de los demás jugadores. Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama un perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i). Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el jugador i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada jugador i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i. Podemos extender esta definición a estrategias mixtas asumiendo que ui son utilidades de von Neumann-Morgenstern (vNM) de la siguiente manera: ui(s) = Es[ui], donde Es es la expectativa tomada con respecto a la distribución de probabilidad del juego inducida por la estrategia mixta de los jugadores s. Al emplear la forma normal, modelamos a los agentes jugando una única acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones más detalladas sobre la acción a lo largo del tiempo en la forma extensiva. Aunque cualquier juego extenso puede ser reformulado en forma normal, hacerlo puede sacrificar la concisión y difuminar distinciones relevantes (por ejemplo, la perfección en subjuegos). Ocasionalmente, escribimos ui(x, y) para indicar que x ∈ Ai o Si y y ∈ A−i o S−i dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u(·) = {u1(·), . . . , um(·)}. Definimos una función, : R → R, interpretada como el beneficio máximo que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) donde r pertenece a algún conjunto de estrategias, R, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada aquellas jugadas por los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un equilibrio de Nash. DEFINICIÓN 1. Un perfil estratégico r = (r1, . . . , rm) constituye un equilibrio de Nash del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). Cuando r ∈ A, lo anterior define un equilibrio de Nash de estrategia pura; de lo contrario, la definición describe un equilibrio de Nash de estrategia mixta. A menudo recurrimos al concepto de un equilibrio aproximado, o equilibrio de Nash, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita. Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un equilibrio de Nash si (r) ≤ . En este estudio dedicamos especial atención a los juegos que presentan simetría en cuanto a los pagos, lo que hace que los agentes sean estratégicamente idénticos. DEFINICIÓN 2. Un juego [I, {Ri}, {ui(r)}] es simétrico si para todo i, j ∈ I, (a) Ri = Rj y (b) ui(ri, r−i) = uj (rj, r−j) siempre que ri = rj y r−i = r−j. EL MODELO Modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un juego de dos etapas. El diseñador comienza seleccionando primero un valor, θ, de un conjunto de configuraciones de mecanismos permitidas, Θ. Todos los agentes participantes observan el parámetro θ del mecanismo y se mueven simultáneamente después. Por ejemplo, el diseñador podría estar decidiendo entre mecanismos de subasta de sobre cerrado de precio único y de precio único, con la presunción de que una vez tomada la decisión, los postores participarán con pleno conocimiento de las reglas de la subasta. Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como Γθ = [I, {Ri}, {ui(r, θ)}]. Nos referimos a Γθ como un juego inducido por θ. Sea N(θ) el conjunto de perfiles estratégicos considerados soluciones del juego Γθ.3. Supongamos que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, W(r, θ), dependiente del parámetro del mecanismo y del juego resultante, r. Definimos una medida pesimista, W( ˆR, θ) = inf{W(r, θ) : r ∈ ˆR}, que representa el bienestar en el peor de los casos del juego inducido por θ, asumiendo que los agentes juegan alguna estrategia conjunta en ˆR. Normalmente nos preocupamos por W (N(θ), θ), el resultado en el peor de los casos de jugar alguna solución. En algunos problemas podemos obtener una considerable ventaja al utilizar una función de agregación para mapear el resultado del bienestar de un juego. Generalmente adoptamos el equilibrio de Nash como concepto de solución, y por lo tanto tomamos N(θ) como el conjunto de equilibrios. Sin embargo, gran parte de la metodología desarrollada aquí podría ser utilizada con criterios alternativos para derivar el comportamiento del agente a partir de una definición del juego. Nuevamente, existen alternativas disponibles. Por ejemplo, si se tiene una distribución de probabilidad sobre el conjunto de soluciones N(θ), sería natural tomar la expectativa de W(r, θ) en su lugar. 307 especificado en términos de estrategias de agentes a un resultado de bienestar equivalente especificado en términos de un resumen de menor dimensión. DEFINICIÓN 3. Una función φ: R1 × · · · × Rm → Rq es una función de agregación si m ≥ q y W(r, θ) = V(φ(r), θ) para alguna función V. Sobrecargamos el símbolo de función para aplicar a conjuntos de perfiles estratégicos: φ( ˆR) = {φ(r) : r ∈ ˆR}. Para mayor comodidad en la exposición, escribimos φ∗ (θ) para denotar φ(N(θ)). El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia. Por ejemplo, supongamos, como en nuestra aplicación a continuación, que la estrategia de un agente está definida por un parámetro numérico. Si todo lo que nos importa es el valor total jugado, podemos tomar φ(a) = Πm i=1 ai. Si hemos elegido nuestro agregador cuidadosamente, también podemos capturar estructuras que de otra manera no serían evidentes. Por ejemplo, φ∗ (θ) podría estar disminuyendo en θ, mientras que N(θ) podría tener una estructura más compleja. Dada una descripción de la correspondencia de solución N(θ) (equivalentemente, φ∗(θ)), el diseñador se enfrenta a un problema estándar de optimización. Alternativamente, dado un simulador que pudiera producir una muestra imparcial de la distribución de W (N(θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12]. Sin embargo, incluso para un juego Γθ con pagos conocidos, puede resultar computacionalmente intratable resolver los equilibrios de Nash, especialmente si el juego tiene conjuntos de estrategias grandes o infinitos. Además, deseamos estudiar juegos en los que los pagos no se dan explícitamente, sino que deben determinarse a partir de simulaciones u otra experiencia con el juego. Por lo tanto, asumimos que se nos proporciona un conjunto de datos (posiblemente ruidoso) de realizaciones de pagos: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, donde para cada punto de datos θi es el <br>ajuste observado del parámetro del mecanismo</br>, ai es el perfil de estrategia pura observado de los participantes, y Ui es la realización correspondiente de los pagos de los agentes. También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}. Sea D = {Do, Ds} el conjunto de datos combinado. (Ya sea que Do o Ds puedan ser nulos para un problema particular). En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos empíricos de teoría de juegos, para responder preguntas sobre el diseño del escenario TAC/SCM. 4. ANÁLISIS DE DISEÑO EMPÍRICO Dado que nuestros datos se presentan en forma de experiencia de pago y no como el valor de una función objetivo para configuraciones dadas de la variable de control, ya no podemos confiar en los métodos para optimizar funciones utilizando simulaciones. De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia del equilibrio de Nash. Además, no podemos depender directamente de los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilístico adaptados a nuestra configuración de problema. 4.1 Problema de Diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente. Recuerde que durante el torneo de 2004, los diseñadores del juego de la cadena de suministro optaron por aumentar drásticamente los costos de almacenamiento como medida para frenar las compras del día 0, con poco éxito. Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y la cantidad agregada de componentes adquiridos el día 0 en equilibrio. Esto suele ser el caso en juegos reales de interés, donde descripciones en lenguaje natural o algorítmicas pueden sustituir a una especificación formal de estrategias y funciones de pago. Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo. ¿Primero, ¿el aumento de los costos de almacenamiento realmente reduce la adquisición en el día 0? ¿Fue racional la adquisición excesiva observada durante el día 0 del torneo de 2004? Y en tercer lugar, ¿podría haber reducido de manera suficiente los costos de almacenamiento la adquisición del día 0 a un nivel aceptable, y en tal caso, cuál debería haber sido el ajuste de los costos de almacenamiento? Es esta tercera pregunta la que define el aspecto del diseño de mecanismos de nuestro análisis. Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de los agentes, la función de bienestar de los diseñadores, el espacio de parámetros del mecanismo y la fuente de datos. Restringimos las estrategias de los agentes para que sean un multiplicador de la cantidad de solicitudes del día 0 de uno de los finalistas, Deep Maize, en el torneo TAC/SCM de 2004. Lo restringimos aún más al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias por encima de 1.5 son extremadamente agresivas (por lo tanto, poco probables de proporcionar desviaciones refutadoras más allá de las disponibles en las estrategias incluidas, y ciertamente no forman parte de ningún equilibrio deseable). Todo otro comportamiento se basa en el comportamiento de Deep Maize y es idéntico para todos los agentes. Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico. Sin embargo, creemos que la forma general de los resultados debería ser robusta ante cambios en el comportamiento completo del agente. Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0. Sea φ(a) = Σ6 i=1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego particular de la cadena de suministro (para perfiles de estrategia mixta s, tomamos la esperanza de φ con respecto a la mezcla). La función de bienestar de los diseñadores W (N(θ), θ) se define entonces como I{sup{φ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de adquisición en el día 0 y I es la función indicadora. El diseñador selecciona un valor θ de costos de almacenamiento, expresado como un porcentaje anual del valor base de los componentes en el inventario (cobrado diariamente), del conjunto Θ = R+. Dado que la decisión de los diseñadores depende solo de φ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación. 4.2 Estimación de equilibrios de Nash El objetivo de los agentes de TAC/SCM es maximizar los beneficios obtenidos en una instancia del juego. Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, U(a)). Si también hemos fijado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de jugadores y sus correspondientes pagos, y, en consecuencia, para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios de Nash de cada juego Γθ. Por lo tanto, necesitamos métodos para aproximar equilibrios de Nash en juegos infinitos. A continuación, describimos los dos métodos que utilizamos en nuestro estudio. El primero ha sido explorado empíricamente anteriormente, mientras que el segundo se introduce aquí como el método específicamente diseñado para aproximar un conjunto de equilibrios de Nash. 4.2.1 Aproximación de la Función de Pago El primer método para estimar equilibrios de Nash basado en datos utiliza aprendizaje supervisado para aproximar las funciones de pago de mech6. No abordamos si y cómo otras medidas (por ejemplo, restringir directamente la adquisición) podrían haber logrado los objetivos de diseño. Nuestro enfoque considera como dado un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento. En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con un crecimiento de complejidad correspondiente. 308 participantes del mecanismo de un conjunto de datos de experiencia de juego [17]. Una vez que las funciones de pago aproximadas estén disponibles para todos los jugadores, los equilibrios de Nash pueden encontrarse ya sea de forma analítica o aproximada utilizando técnicas numéricas, dependiendo del modelo de aprendizaje. En lo que sigue, estimamos solo un equilibrio de Nash de muestra utilizando esta técnica, aunque esta restricción puede eliminarse a expensas de un tiempo de cálculo adicional. Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador. Por lo tanto, podemos aplicarlo cuando Ds = ∅. Si hay un simulador disponible, podemos generar datos adicionales para aumentar la confianza en nuestras estimaciones iniciales. Probamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado local (LWA) y regresión lineal ponderada localmente (LWLR). También utilizamos variables de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis empírico previo de teoría de juegos de TAC/SCM-03 [19]. El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido de forma analítica. Para los otros métodos aplicamos dinámica replicadora [7] a una aproximación discreta del juego aprendido. El total esperado de adquisiciones del día 0 en equilibrio se tomó como la estimación de un resultado. 4.2.2 Búsqueda en el Espacio de Perfiles de Estrategia Cuando tenemos acceso a un simulador, también podemos utilizar la búsqueda dirigida a través del espacio de perfiles para estimar el conjunto de equilibrios de Nash, que describimos aquí después de presentar alguna notación adicional. DEFINICIÓN 4. Un vecino estratégico de un perfil de estrategia pura a es un perfil que es idéntico a a en todo menos en una estrategia. Definimos Snb(a, D) como el conjunto de todos los vecinos estratégicos de a disponibles en el conjunto de datos D. De manera similar, definimos Snb(a, ˜D) como todos los vecinos estratégicos de a que no están en D. Finalmente, para cualquier a ∈ Snb(a, D) definimos al agente que se desvía como i(a, a). DEFINICIÓN 5. La -ligadura, ˆ, de un perfil de estrategia pura a se define como maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}. Decimos que a es un candidato a δ-equilibrio para δ ≥ ˆ. Cuando Snb(a, ˜D) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), a se confirma como un equilibrio de Nash ˆ. Nuestro método de búsqueda opera explorando desviaciones de los equilibrios candidatos. Nos referimos a esto como BestFirstSearch, ya que selecciona con probabilidad uno un perfil de estrategia a ∈ Snb(a, ˜D) que tiene el menor ˆin D. Finalmente definimos un estimador para un conjunto de equilibrios de Nash. DEFINICIÓN 6. Para un conjunto K, define Co(K) como la envoltura convexa de K. Sea Bδ el conjunto de candidatos en el nivel δ. Definimos ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) para un δ fijo como un estimador de φ∗ (θ). En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles estratégicos agregados con límite inferior -bound por debajo de un δ fijo. Esta definición nos permite explotar la estructura que surge de la función de agregación. Si dos perfiles son cercanos en términos de valores de agregación, es probable que tengan límites similares. En particular, si uno está en equilibrio, el otro también puede estarlo. Presentamos un respaldo teórico para este método de estimación del conjunto de equilibrios de Nash a continuación. Dado que el juego en el que estamos interesados es infinito, es necesario terminar BestFirstSearch antes de explorar todo el espacio de strat7. Por ejemplo, podemos utilizar técnicas de aprendizaje activo [5] para mejorar la calidad de la aproximación de la función de recompensa. En este trabajo, nos concentramos en la búsqueda en el espacio de perfiles estratégicos. Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos. Generación de datos Nuestros datos fueron recopilados simulando juegos TAC/SCM en una versión local del servidor TAC/SCM de 2004, que tiene una configuración para el costo de almacenamiento. Las estrategias de los agentes en juegos simulados fueron seleccionadas del conjunto {0, 0.3, 0.6, . . . , 1.5} con el fin de tener una probabilidad positiva de generar vecinos estratégicos. Se generó un conjunto de datos base Do mediante el muestreo de 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}. Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varios defectos. Utilizamos la búsqueda para generar un conjunto de datos simulados Ds, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ. Dado que el costo de la simulación es extremadamente alto (un juego tarda casi 1 hora en ejecutarse), pudimos ejecutar un total de 2670 juegos en el transcurso de más de seis meses. Para hacer una comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategias conjuntas finitas restringidas para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces). 4.4 Resultados 4.4.1 Análisis del conjunto de datos base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos base Do. Además, generamos una estimación de la correspondencia del equilibrio de Nash, ˆφ∗ (θ), aplicando la Definición 6 con δ = 2.5E6. Los resultados se muestran en la Figura 1. Como podemos ver, la correspondencia ˆφ∗ (θ) tiene poco poder predictivo basado en Do, y no revela ninguna estructura interesante sobre el juego. Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición Total Día 0 LWA LWLR QR BaselineMin BaselineMax Figura 1: Estimaciones de adquisición del día 0 agregadas basadas en Do. La correspondencia ˆφ∗ (θ) es el intervalo entre BaselineMin y BaselineMax. En general, la búsqueda se detiene una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para obtener conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego. Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash a permanecer en este subconjunto discreto de [0,1.5]. Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron accidentes, problemas de conectividad de red y otras anomalías obvias), el juego sería descartado. Análisis de los datos de búsqueda Para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ∗ (θ) (nuevamente, usando δ =2.5E6) en el conjunto de datos D = {Do, Ds}, donde Ds es datos generados a través de la aplicación de BestFirstSearch. Los resultados de esta estimación se representan gráficamente frente a los resultados de los métodos de aprendizaje entrenados en Do 11 en la Figura 2. Primero, observamos que la adición de los datos de búsqueda reduce considerablemente el rango de posibles equilibrios. Además, las predicciones puntuales reales de los métodos de aprendizaje y aquellas basadas en límites después de la búsqueda son razonablemente cercanas. Combinar la evidencia recopilada de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquiera de los métodos utilizados de forma aislada. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición del Día 0 LWA LWLR QR Búsqueda Mínima Búsqueda Máxima Figura 2: Estimaciones agregadas de adquisición del día 0 basadas en la búsqueda en el espacio de perfiles de estrategia en comparación con técnicas de aproximación de funciones entrenadas en Do. La correspondencia ˆφ∗ (θ) para D = {Do, Ds} es el intervalo entre SearchMin y SearchMax. Esta evidencia respalda la intuición inicial de que la adquisición del día 0 debería disminuir con los costos de almacenamiento. También confirma que los altos niveles de adquisición en el día 0 son una respuesta racional al entorno del torneo de 2004 con un costo promedio de almacenamiento, que corresponde a θ = 100. La predicción mínima para la adquisición agregada en este nivel de costos de almacenamiento, dada por cualquier método experimental, es aproximadamente 3. Esto es bastante alto, ya que corresponde a un compromiso esperado del 1/3 de la capacidad total del proveedor para todo el juego. La predicción máxima es considerablemente mayor a 4.5. En la competencia actual de 2004, la adquisición total del día 0 equivalía a 5.71 en la escala utilizada aquí [9]. Nuestras predicciones subestiman este resultado en cierta medida, pero muestran que cualquier resultado racional probablemente tendría una alta adquisición en el día 0. 4.4.3 Extrapolando la Correspondencia de la Solución Tenemos evidencia razonablemente sólida de que la correspondencia del resultado está disminuyendo. Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento a un valor que reduciría la adquisición del día 0 en equilibrio, o concluir que esto no es posible. Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día 0. No está claro cuán significativos serían los resultados del aprendizaje si se agregaran Ds al conjunto de datos de entrenamiento. De hecho, los datos adicionales pueden aumentar realmente la varianza del aprendizaje. Recuerde que el objetivo de los diseñadores es incentivar la adquisición agregada del día 0 que esté por debajo del umbral α. Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultados estimada a partir de D que produce θ = 320. Los datos para θ = 320 fueron recopilados de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos por 33 iteraciones de BestFirstSearch. La Figura 3 muestra los límites detallados para todos los perfiles en términos de sus valores correspondientes de φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Límites de ε de Adquisición Total Día-0 Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320. Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ(a). La región gris corresponde a ˆφ∗ (320) con δ = 2.5M. El conjunto estimado de resultados agregados del día 0 es muy cercano al de θ = 200, lo que indica que hay poco beneficio adicional al aumentar los costos de almacenamiento por encima de 200. Observa que incluso el límite inferior de nuestro conjunto estimado de equilibrios de Nash está muy por encima de la adquisición objetivo del día 0 de 2. Además, las recompensas para los agentes son casi siempre negativas en θ = 320. Por consiguiente, aumentar los costos aún más sería indeseable incluso si finalmente se pudiera reducir la adquisición en el día 0. Dado que tenemos una confianza razonable de que φ∗ (θ) está disminuyendo en θ, tampoco esperamos que establecer θ en algún lugar entre 200 y 320 logre el resultado deseado. Concluimos que es poco probable que la adquisición del día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento. Que nuestras predicciones tienden a subestimar los resultados del torneo refuerza esta conclusión. Para lograr la reducción deseada en la adquisición del día 0 se requiere rediseñar otros aspectos del mecanismo. 4.5 Análisis Probabilístico Nuestro análisis empírico ha producido evidencia en apoyo a la conclusión de que ninguna configuración razonable del costo de almacenamiento probablemente sería suficiente para frenar la adquisición excesiva del día 0 en TAC/SCM 04. Toda esta evidencia ha sido en forma de simple interpolación y extrapolación de estimaciones de la correspondencia del equilibrio de Nash. Estas estimaciones se basan en simular instancias del juego y están sujetas a ruido de muestreo contribuido por los diversos elementos estocásticos del juego. En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos -bound a tales efectos estocásticos. Supongamos que todos los agentes tienen conjuntos de estrategias puras finitos (y pequeños), A. Por lo tanto, es factible muestrear toda la matriz de pagos del juego. Además, supongamos que el ruido es aditivo con media cero en promedio durante todo el juego, por lo que en la práctica probablemente querríamos que el umbral sea aún más bajo. 310 y varianza finita, es decir, Ui(a) = ui(a) + ˜ξi(a), donde Ui(a) es la ganancia observada para i cuando se jugó a, ui(a) es la ganancia correspondiente real, y ˜ξi(a) es una variable aleatoria normal con media cero. Designamos la varianza conocida de ˜ξi(a) como σ2 i (a). Por lo tanto, asumimos que ˜ξi(a) es normal con distribución N(0, σ2 i (a)). Tomamos ¯ui(a) como la media muestral de todos los Ui(a) en D, y seguimos a Chang y Huang [3] al asumir que tenemos una priori impropia sobre las ganancias reales ui(a) y el muestreo fue independiente para todos i y a. También confiamos en su resultado de que ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] son independientes con distribuciones posteriores N(¯ui(a), σ2 i (a)/ni(a)), donde ni(a) es el número de muestras tomadas de los pagos para i en el perfil puro a, y Zi(a) ∼ N(0, 1). Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio de Nash -Nash. Si ui(·)|¯ui(·) son independientes para todo i ∈ I y a ∈ A, tenemos el siguiente resultado (a partir de este punto omitimos la condición sobre ¯ui(·) por brevedad): PROPOSICIÓN 1. Para todo \\( i \\in I \\), \\( \\max_{b \\in A_i} u_i(b, a_{-i}) - u_i(a) \\leq \\varepsilon \\), donde \\( \\varepsilon = \\int_{Y_i} \\int_{Z} \\int_{R} \\int_{Y} \\int_{b \\in A_i \\backslash a_i} \\Pr(u_i(b, a_{-i}) \\leq u + \\varepsilon) f_{u_i(a)}(u) du \\), donde \\( f_{u_i(a)}(u) \\) es la función de densidad de probabilidad de \\( N(\\overline{u_i(a)}, \\sigma_i(a)) \\). Las pruebas de este y todos los resultados posteriores se encuentran en el Apéndice. La distribución posterior de la media óptima de n muestras, derivada por Chang y Huang [3], es Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) donde a ∈ A y Φ(·) es la función de distribución N(0, 1). Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilístico que (a) ≤ γ para un γ dado. Ahora, consideramos casos de datos incompletos y utilizamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en los datos) en la distribución de sup{φ∗ (θ)} e inf{φ∗ (θ)} (asumiendo que ambos son alcanzables): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, donde x es un número real y ≤D indica que el límite superior solo considera estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} y {inf{φ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf{φ∗ (θ)} ≤ x}. Los valores así derivados comprenden las Tablas 1 y 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Tabla 1: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando N(θ) es un conjunto de equilibrios de Nash. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Tabla 2: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {150, 200, 320} cuando N(θ) es un conjunto de equilibrios de Nash. Las Tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ(a) < 2.7 es poco probable para cualquier θ del cual tengamos datos, aunque este juicio, como mencionamos, se refiere únicamente a los perfiles que hemos muestreado realmente. Podemos entonces aceptar esto como otra pieza de evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, parece poco probable que el diseñador logre su objetivo incluso si pudiera persuadir a los participantes a jugar un equilibrio deseable. La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM de 2004 eran, de hecho, racionales al adquirir grandes cantidades de componentes al comienzo del juego. Si observamos la tercera columna de esta tabla, que corresponde a θ = 100, podemos deducir que ningún perfil a en nuestros datos con φ(a) < 3 es muy probable que se juegue en equilibrio. Los límites anteriores proporcionan algunas pruebas generales, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos muestreado. Particularmente, nos gustaría decir algo sobre lo que sucede en los ajustes de θ para los cuales no tenemos datos. Para derivar un límite probabilístico aproximado sobre la probabilidad de que ningún θ ∈ Θ haya logrado el objetivo del diseñador, sea ∪J j=1Θj una partición de Θ, y asuma que la función sup{φ∗ (θ)} satisface la condición de Lipschitz con constante de Lipschitz Aj en cada subconjunto Θj. Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a Θ = [0, 320]. Ahora definimos cada subconjunto j como el intervalo entre dos puntos para los cuales hemos producido datos. Por lo tanto, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], con j variando entre 1 y 5, correspondiendo a los subintervalos anteriores. Denotaremos cada Θj por (aj, bj]. Luego, la siguiente proposición nos da una cota superior aproximada sobre la probabilidad de que sup{φ∗ (θ)} ≤ α. PROPOSICIÓN 2. Debido a que nuestros límites son aproximados, no podemos utilizarlos como una evaluación probabilística concluyente. En cambio, tomamos esto como otra pieza de evidencia para complementar nuestros hallazgos. Aunque podamos asumir que una función que aproximamos a partir de datos es Lipschitz continua, rara vez conocemos en realidad la constante de Lipschitz para cualquier subconjunto de Θ. Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de los datos. Aquí, probamos tres métodos para hacer esto. El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subintervalo. Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo. Un método alternativo es tomar un límite superior en la pendiente obtenida dentro de cada subintervalo utilizando los datos disponibles. Esto produce un límite superior de probabilidades mucho menos conservador. Sin embargo, dado que el límite superior real suele ser mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso. Un último método que intentamos es un compromiso entre los dos anteriores. En lugar de tomar el límite superior conservador basado en datos sobre todo el dominio de la función Θ, tomamos el promedio de los límites superiores obtenidos en cada Θj. El límite en un intervalo se toma como el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos. Los resultados de evaluar la expresión para Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3. En términos de nuestras afirmaciones en maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Tabla 3: Límite superior aproximado de la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con un objetivo α = 2. Se utilizan diferentes métodos para aproximar el límite superior de la pendiente en cada subintervalo j. En este trabajo, la expresión proporciona un límite superior a la probabilidad de que alguna configuración de θ (es decir, costo de almacenamiento) en el intervalo [0,320] resulte en una adquisición total del día 0 que no sea mayor en ningún equilibrio que el objetivo especificado por α y tomado aquí como 2. Como sospechábamos, el enfoque más conservador para estimar el límite superior de la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí. Sin embargo, los otros dos enfoques de estimación, encontrados en las columnas dos y tres de la Tabla 3, sugieren que de hecho estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría funcionado. Dada la tremenda dificultad del problema, este resultado es muy sólido. Aun así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia. Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y los conjuntos de estrategias). Tampoco podemos esperar obtener nunca suficiente evidencia para llegar a conclusiones completamente objetivas. En cambio, el enfoque que defendemos aquí es recopilar la mayor cantidad de evidencia posible dadas las limitaciones de recursos, y tomar la decisión más convincente basada en esta evidencia, si es posible. RESULTADOS DE CONVERGENCIA En este punto, exploramos abstractamente si una elección de parámetro de diseño basada en datos de pago puede ser asintóticamente confiable. Dado que no teníamos todas las desviaciones posibles para cualquier perfil disponible en los datos, los verdaderos límites superiores pueden ser aún más bajos. Por conveniencia, utilizaremos la notación un,i(a) para referirnos a una función de pago del jugador i basada en un promedio sobre n muestras i.i.d. de la distribución de pagos. También asumimos que un,i(a) son independientes para todo a ∈ A e i ∈ I. Utilizaremos la notación Γn para referirnos al juego [I, R, {ui,n(·)}], mientras que Γ denotará el juego subyacente, [I, R, {ui(·)}]. De manera similar, definimos n(r) como (r) con respecto al juego Γn. En esta sección, demostramos que n(s) → (s) casi seguramente de forma uniforme en el espacio de estrategias mixtas para cualquier juego finito, y, además, que todas las equilibrios de Nash en estrategias mixtas en juegos empíricos eventualmente se acercan arbitrariamente a algunas estrategias de equilibrio de Nash en el juego subyacente. Utilizamos estos resultados para demostrar que bajo ciertas condiciones, la elección óptima del parámetro de diseño basada en datos empíricos converge casi seguramente al óptimo real. TEOREMA 3. Supongamos que |I| < ∞, |A| < ∞. Entonces n(s) → (s) casi seguramente uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios de Nash de Γ. Si definimos Nn,γ = {s ∈ S : n(s) ≤ γ}, tenemos el siguiente corolario del Teorema 3: COROLARIO 4. Para todo γ > 0, existe un M tal que para todo n ≥ M, N ⊂ Nn,γ casi seguramente. PRUEBA. Dado que n(s) = 0 para todo s ∈ N, podemos encontrar un M lo suficientemente grande tal que Pr{supn≥M sups∈N n(s) < γ} = 1. Según el Corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier > 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios de Nash empíricos si se han tomado suficientes muestras. Como mostramos ahora, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un límite no nulo como una estimación del conjunto de equilibrios de Nash. Primero, supongamos que concluimos que para una configuración particular de θ, sup{ˆφ∗ (θ)} ≤ α. Entonces, dado que para cualquier fijo > 0, N(θ) ⊂ Nn, (θ) cuando n es suficientemente grande, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α para cualquier n de este tipo. Así, dado que definimos la función de bienestar del diseñador como I{sup{φ∗ (θ)} ≤ α} en nuestro dominio de interés, la elección empírica de θ satisface el objetivo del diseñador, maximizando así su función de bienestar. Alternativamente, supongamos que concluimos que inf{ˆφ∗ (θ)} > α para cada θ en el dominio. Entonces, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, para todo θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo del diseñador. Ahora, demostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de Γn está cerca de algún equilibrio de Nash del juego subyacente. Este resultado nos llevará a considerar la convergencia de los optimizadores basados en datos empíricos a los ajustes óptimos reales de los parámetros del mecanismo. Primero notamos que la función (s) es continua en un juego finito. LEMMA 5. \n\nLEMMA 5. Sea S un conjunto de estrategias mixtas definido en un juego finito. Entonces: S → R es continua. Para la exposición que sigue, necesitamos un poco de notación adicional. Primero, sea (Z, d) un espacio métrico, y X, Y ⊂ Z y definamos la distancia de Hausdorff dirigida de X a Y como h(X, Y) = sup x∈X inf y∈Y d(x, y). Observa que U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ). Además, define BS(x, δ) como una bola abierta en S ⊂ Z con centro en x ∈ S y radio δ. Ahora, dejemos que Nn denote todos los equilibrios de Nash del juego Γn y sea Nδ = [ x∈N BS(x, δ), es decir, la unión de bolas abiertas de radio δ con centros en los equilibrios de Nash de Γ. Ten en cuenta que h(Nδ, N) = δ. Podemos entonces demostrar el siguiente resultado general. TEOREMA 6. Supongamos que |I| < ∞ y |A| < ∞. Entonces casi con seguridad h(Nn, N) converge a 0. Ahora demostraremos que en el caso especial cuando Θ y A son finitos y cada Γθ tiene un equilibrio de Nash único, las estimaciones ˆθ del parámetro óptimo del diseñador convergen a un optimizador real casi seguramente. Sea ˆθ = arg maxθ∈Θ W (Nn(θ), θ), donde n es el número de veces que se muestreó cada perfil puro en Γθ para cada θ, y sea θ∗ = arg maxθ∈Θ W (N(θ), θ). TEOREMA 7. Supongamos que |N(θ)| = 1 para todo θ ∈ Θ y supongamos que Θ y A son finitos. Sea W (s, θ) continua en el único s∗ (θ) ∈ N(θ) para cada θ ∈ Θ. Entonces ˆθ es un estimador consistente de θ∗ si W (N(θ), θ) se define como un supremo, ínfimo o esperanza sobre el conjunto de equilibrios de Nash. De hecho, ˆθ → θ∗ casi seguramente en cada uno de estos casos. La limitación del resultado anterior es que, dentro de nuestro marco de trabajo, el diseñador no tiene forma de saber o asegurar que Γθ tenga equilibrios únicos. Sin embargo, sí proporciona cierta justificación teórica para seguir el diseño de esta manera, y quizás servirá como guía para obtener resultados más generales en el futuro. 6. TRABAJO RELACIONADO La literatura de diseño de mecanismos en Economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10]. Además, existe una extensa literatura sobre el diseño óptimo de subastas [10], del cual el trabajo de Roger Myerson [11] es, quizás, el más relevante. En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y teniendo en cuenta restricciones como la compatibilidad de incentivos y la racionalidad individual. Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de Ciencias de la Computación. Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros relevantes del juego son conocimiento común. Cuando las funciones de pago de los jugadores son desconocidas, se ha explorado la realización de búsquedas mediante simulaciones como alternativa. Un enfoque en esa dirección, tomado en [4] y [15], es coevolucionar el parámetro del mecanismo y las estrategias de los agentes, utilizando alguna noción de utilidad social y pagos de los agentes como criterios de aptitud. Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética. En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron un resultado de un juego inducido por un parámetro del mecanismo como el resultado del aprendizaje conjunto de los agentes. Más recientemente, Phelps et al. [14] compararon dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en juegos definidos por estrategias heurísticas, como en [18]. 7. CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el diseño empírico de mecanismos. Definimos un modelo formal de teoría de juegos de interacción entre el diseñador y los participantes del mecanismo como un juego de dos etapas. También describimos en cierta generalidad los métodos para estimar una función de equilibrio de Nash de muestra cuando los datos son extremadamente escasos, o una correspondencia de equilibrio de Nash cuando hay más datos disponibles. Nuestras técnicas están diseñadas específicamente para abordar problemas en los que tanto el espacio de parámetros del mecanismo como los conjuntos de estrategias de los agentes son infinitos y solo se puede adquirir un conjunto de datos relativamente pequeño. Un problema de diseño difícil en el juego TAC/SCM que la comunidad de TAC ha estado ansiosa por abordar nos brinda un escenario para probar nuestros métodos. Al aplicar el análisis empírico del juego al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos. Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia del equilibrio de Nash. Al final, podemos intentar proporcionar suficiente evidencia para prescribir una <br>configuración de parámetros</br>, o sugerir que no es posible encontrar una configuración que satisfaga al diseñador. En el caso de TAC/SCM, nuestra evidencia sugiere bastante claramente que el costo de almacenamiento no pudo haber sido ajustado de manera efectiva en el torneo de 2004 para frenar la adquisición excesiva del día 0 sin efectos perjudiciales en la rentabilidad general. El éxito de nuestro análisis en este entorno extremadamente complejo con altos costos de simulación nos hace ser optimistas de que nuestros métodos pueden brindar orientación en la toma de decisiones de diseño de mecanismos en otros dominios desafiantes. Los resultados teóricos confirman algunas intuiciones detrás de los métodos de diseño de mecanismos empíricos que hemos introducido, y aumentan nuestra confianza en que nuestro marco puede ser efectivo para estimar la mejor elección de parámetros del mecanismo en entornos relativamente generales. Agradecimientos Agradecemos a Terence Kelly, Matthew Rudary y Satinder Singh por sus útiles comentarios sobre versiones anteriores de este trabajo. Este trabajo fue apoyado en parte por la subvención de la NSF IIS-0205435 y el programa de razonamiento estratégico DARPA REAL. 8. REFERENCIAS [1] R. Arunachalam y N. M. Sadeh. La competencia de agentes de comercio de la cadena de suministro. Investigación y aplicaciones del comercio electrónico, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy y M. Tschantz. Un enfoque de programación estocástica para la planificación en TAC SCM. En la Quinta Conferencia ACM sobre Comercio Electrónico, páginas 152-159, Nueva York, 2004. [3] Y.-P. Chang y W.-T. Huang. Intervalos de confianza generalizados para el valor más grande de algunas funciones de parámetros bajo normalidad. Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.\nEstadística Sinica, 10:1369-1383, 2000. [4] D. Cliff. Evolución del mecanismo de mercado a través de un espacio continuo de tipos de subasta. En el Congreso de Computación Evolutiva de 2002. [5] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [6] V. Conitzer y T. Sandholm. Un algoritmo para diseñar automáticamente mecanismos determinísticos sin pagos. En la Tercera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagente, páginas 128-135, 2004. [7] D. Friedman. Juegos evolutivos en economía. Econometrica, 59(3):637-666, mayo de 1991. [8] R. Keener. Teoría Estadística: Una Mezcla de Temas Fundamentales. Departamento de Estadística de la Universidad de Michigan, 2004. [9] C. Kiekintveld, Y. Vorobeychik y M. P. Wellman. Un análisis de la competencia de agentes comerciales de gestión de la cadena de suministro de 2004. En el taller IJCAI-05 sobre Diseño y Análisis de Agentes de Negociación, Edimburgo, 2005. [10] A. Mas-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [11] R. B. Myerson.\nEditorial de la Universidad de Oxford, 1995. [11] R. B. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6(1):58-73, febrero de 1981. [12] S. Olafsson y J. Kim. Optimización de simulación. En E. Yucesan, C.-H. Chen, J. Snowdon y J. Charnes, editores, Conferencia de Simulación de Invierno 2002, 2002. [13] D. Pardoe y P. Stone. TacTex-03: Un agente de gestión de la cadena de suministro. SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, y P. McBurney. Agentes automatizados versus humanos virtuales: una comparación teórica evolutiva de dos diseños de mercado de subasta doble. En Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney y E. Sklar. Co-evolución de mecanismos de subasta y estrategias de negociación: hacia un enfoque novedoso para el diseño microeconómico. En el taller ECOMAS 2002, 2002. [16] S. Phelps, S. Parsons, E. Sklar y P. McBurney. Utilizando programación genética para optimizar reglas de precios para un mercado de subasta doble. En Taller sobre Agentes para el Comercio Electrónico, 2003. [17] Y. Vorobeychik, M. P. Wellman y S. Singh. Aprendiendo funciones de pago en juegos infinitos. En la Decimonovena Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro y J. O. Kephart. Analizando interacciones estratégicas complejas en sistemas multiagente. En el taller AAAI-02 sobre agentes teóricos de juegos y de toma de decisiones, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld y V. Soni. Interacciones estratégicas en un juego de cadena de suministro. Inteligencia Computacional, 21(1):1-26, febrero de 2005. APÉNDICE A. PRUEBAS A.1 Prueba de la Proposición 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du. A.2 Prueba de la Proposición 2 Primero, supongamos que alguna función, f(x), definida en [ai, bi], satisface la condición de Lipschitz en (ai, bi] con una constante de Lipschitz Ai. Entonces se cumple la siguiente afirmación: Afirmación: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai). Para demostrar esta afirmación, observe que la intersección de las líneas en f(ai) y f(bi) con pendientes -Ai y Ai respectivamente determinará el límite inferior del mínimo de f(x) en [ai, bi] (que es un límite inferior del ínfimo de f(x) en (ai, bj]). La línea en f(ai) está determinada por f(ai) = −Aiai + cL y la línea en f(bi) está determinada por f(bi) = Aibi + cR. Por lo tanto, las intercepciones son cL = f(ai) + Aiai y cR = f(bi) + Aibi respectivamente. Sea x∗ el punto en el que estas líneas se cruzan. Entonces, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A. Al sustituir las expresiones de cR y cL, obtenemos el resultado deseado. Ahora, la subaditividad nos da Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, y, por la afirmación, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}. Dado que tenemos un número finito de puntos en el conjunto de datos para cada θ, podemos obtener la siguiente expresión: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}. Ahora podemos restringir nuestra atención en obtener una cota superior en Pr{sup{φ∗ (θ)} = y} para un θ fijo. Para hacer esto, observe que Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} por subaditividad y el hecho de que un perfil a es un equilibrio de Nash si y solo si (a) = 0. Poner todo junto produce el resultado deseado. Prueba de Teorema 3 En primer lugar, necesitaremos el siguiente hecho: Afirmación: Dada una función fi(x) y un conjunto X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|. Para demostrar esta afirmación, observe que | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) si maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) si maxx f2(x) ≥ maxx f1(x) En el primer caso, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 De manera similar, en el segundo caso, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|. Por lo tanto, la afirmación se mantiene. Por la Ley Fuerte de los Grandes Números, un,i(a) → ui(a) casi seguramente para todo i ∈ I, a ∈ A. Es decir, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, o, equivalentemente [8], para cualquier α > 0 y δ > 0, existe M(i, a) > 0 tal que Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Al tomar M = maxi∈I maxa∈A M(i, a), tenemos que Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Así, por la afirmación, para cualquier n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ con una probabilidad de al menos 1 − α. Ten en cuenta que dado que s−i(a) y s(a) están acotados entre 0 y 1, pudimos eliminarlos de las expresiones anteriores para obtener una cota que será válida independientemente de la elección particular de s. Además, dado que el resultado anterior se puede obtener para un α arbitrario > 0 y δ > 0, tenemos que Pr{limn→∞ n(s) = (s)} = 1 uniformemente en S. A.4 Prueba del Lema 5 Demostramos el resultado utilizando la continuidad uniforme de ui(s) y la preservación de la continuidad bajo el máximo. Afirmación: Una función f : Rk → R definida por f(t) = Σi=1k zi ti, donde zi son constantes en R, es uniformemente continua en t. La afirmación se sigue porque |f(t)−f(t )| = | Σi=1k zi(ti−ti)| ≤ Σi=1k |zi||ti − ti|. Un resultado inmediato de esto para nuestros propósitos es que ui(s) es uniformemente continua en s y ui(ai, s−i) es uniformemente continua en s−i. Afirmación: Sea f(a, b) uniformemente continua en b ∈ B para cada a ∈ A, con |A| < ∞. Entonces V (b) = maxa∈A f(a, b) es uniformemente continua en b. Para demostrar esto, toma γ > 0 y deja que b, b ∈ B tal que b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ. Ahora toma δ = mina∈A δ(a). Entonces, cada vez que b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ. Ahora, recuerda que (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)]. Según las afirmaciones anteriores, maxai∈Ai ui(ai, s−i) es uniformemente continua en s−i y ui(s) es uniformemente continua en s. Dado que la diferencia de dos funciones uniformemente continuas es uniformemente continua, y dado que esta continuidad se conserva bajo el máximo según nuestra segunda afirmación, obtenemos el resultado deseado. Prueba de Teorema 6. Elija δ > 0. Primero, necesitamos asegurarnos de que se cumple la siguiente afirmación: Afirmación: ¯ = mins∈S\\Nδ (s) existe y ¯ > 0. Dado que Nδ es un subconjunto abierto de S compacto, se sigue que S \\ Nδ es compacto. Como también habíamos demostrado en el Lema 5 que (s) es continua, la existencia se sigue del teorema de Weierstrass. Es claro que ¯ > 0 ya que (s) = 0 si y solo si s es un equilibrio de Nash de Γ. Ahora, por el Teorema 3, para cualquier α > 0 existe un M tal que Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. En consecuencia, para cualquier δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Dado que esto se cumple para un α arbitrario > 0 y δ > 0, se obtiene el resultado deseado. Prueba de Teorema 7. Fija θ y elige δ > 0. Dado que W (s, θ) es continua en s∗ (θ), dado > 0 existe δ > 0 tal que para cada s que esté dentro de δ de s∗ (θ), |W (s, θ) - W (s∗ (θ), θ)| < . Según el Teorema 6, podemos encontrar M(θ) lo suficientemente grande para que todos los s ∈ Nn estén dentro de δ de s∗ (θ) para todo n ≥ M(θ) con probabilidad 1. Por consiguiente, para cualquier > 0 podemos encontrar M(θ) lo suficientemente grande tal que con probabilidad 1 tengamos supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < . Asumamos sin pérdida de generalidad que hay una elección óptima única de θ. Ahora, dado que el conjunto Θ es finito, también existe la segunda mejor opción de θ (si solo hay un θ ∈ Θ, esta discusión no tiene sentido de todos modos): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ). Supongamos sin pérdida de generalidad que θ∗∗ también es único y sea ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ). Entonces, si dejamos < ∆/2 y dejamos que M = maxθ∈Θ M(θ), donde cada M(θ) es lo suficientemente grande como para que supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., la elección óptima de θ basada en cualquier equilibrio empírico será θ∗ con probabilidad 1. Por lo tanto, en particular, dado cualquier distribución de probabilidad sobre equilibrios empíricos, la mejor elección de θ será θ∗ con probabilidad 1 (similarmente, si tomamos el supremo o el ínfimo de W (Nn(θ), θ) sobre el conjunto de equilibrios empíricos al construir la función objetivo). ",
            "candidates": [],
            "error": [
                [
                    "ajuste óptimo de parámetros",
                    "ajuste observado del parámetro del mecanismo",
                    "configuración de parámetros"
                ]
            ]
        },
        "observed behavior": {
            "translated_key": "comportamiento observado",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the <br>observed behavior</br> and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the <br>observed behavior</br> and indicating that no reasonable parameter settings would have been likely to achieve the desired effect."
            ],
            "translated_annotated_samples": [
                "Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el <br>comportamiento observado</br> e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado."
            ],
            "translated_text": "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el <br>comportamiento observado</br> e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismos empíricos. En la continuación, desarrollamos algunos métodos generales para el diseño empírico de mecanismos y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto. En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2. Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores. Ri es el conjunto de estrategias disponibles para el jugador i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×. . .×Am. A menudo es conveniente referirse a la estrategia del jugador i por separado de la de los demás jugadores. Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama un perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i). Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el jugador i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada jugador i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i. Podemos extender esta definición a estrategias mixtas asumiendo que ui son utilidades de von Neumann-Morgenstern (vNM) de la siguiente manera: ui(s) = Es[ui], donde Es es la expectativa tomada con respecto a la distribución de probabilidad del juego inducida por la estrategia mixta de los jugadores s. Al emplear la forma normal, modelamos a los agentes jugando una única acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones más detalladas sobre la acción a lo largo del tiempo en la forma extensiva. Aunque cualquier juego extenso puede ser reformulado en forma normal, hacerlo puede sacrificar la concisión y difuminar distinciones relevantes (por ejemplo, la perfección en subjuegos). Ocasionalmente, escribimos ui(x, y) para indicar que x ∈ Ai o Si y y ∈ A−i o S−i dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u(·) = {u1(·), . . . , um(·)}. Definimos una función, : R → R, interpretada como el beneficio máximo que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) donde r pertenece a algún conjunto de estrategias, R, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada aquellas jugadas por los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un equilibrio de Nash. DEFINICIÓN 1. Un perfil estratégico r = (r1, . . . , rm) constituye un equilibrio de Nash del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). Cuando r ∈ A, lo anterior define un equilibrio de Nash de estrategia pura; de lo contrario, la definición describe un equilibrio de Nash de estrategia mixta. A menudo recurrimos al concepto de un equilibrio aproximado, o equilibrio de Nash, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita. Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un equilibrio de Nash si (r) ≤ . En este estudio dedicamos especial atención a los juegos que presentan simetría en cuanto a los pagos, lo que hace que los agentes sean estratégicamente idénticos. DEFINICIÓN 2. Un juego [I, {Ri}, {ui(r)}] es simétrico si para todo i, j ∈ I, (a) Ri = Rj y (b) ui(ri, r−i) = uj (rj, r−j) siempre que ri = rj y r−i = r−j. EL MODELO Modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un juego de dos etapas. El diseñador comienza seleccionando primero un valor, θ, de un conjunto de configuraciones de mecanismos permitidas, Θ. Todos los agentes participantes observan el parámetro θ del mecanismo y se mueven simultáneamente después. Por ejemplo, el diseñador podría estar decidiendo entre mecanismos de subasta de sobre cerrado de precio único y de precio único, con la presunción de que una vez tomada la decisión, los postores participarán con pleno conocimiento de las reglas de la subasta. Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como Γθ = [I, {Ri}, {ui(r, θ)}]. Nos referimos a Γθ como un juego inducido por θ. Sea N(θ) el conjunto de perfiles estratégicos considerados soluciones del juego Γθ.3. Supongamos que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, W(r, θ), dependiente del parámetro del mecanismo y del juego resultante, r. Definimos una medida pesimista, W( ˆR, θ) = inf{W(r, θ) : r ∈ ˆR}, que representa el bienestar en el peor de los casos del juego inducido por θ, asumiendo que los agentes juegan alguna estrategia conjunta en ˆR. Normalmente nos preocupamos por W (N(θ), θ), el resultado en el peor de los casos de jugar alguna solución. En algunos problemas podemos obtener una considerable ventaja al utilizar una función de agregación para mapear el resultado del bienestar de un juego. Generalmente adoptamos el equilibrio de Nash como concepto de solución, y por lo tanto tomamos N(θ) como el conjunto de equilibrios. Sin embargo, gran parte de la metodología desarrollada aquí podría ser utilizada con criterios alternativos para derivar el comportamiento del agente a partir de una definición del juego. Nuevamente, existen alternativas disponibles. Por ejemplo, si se tiene una distribución de probabilidad sobre el conjunto de soluciones N(θ), sería natural tomar la expectativa de W(r, θ) en su lugar. 307 especificado en términos de estrategias de agentes a un resultado de bienestar equivalente especificado en términos de un resumen de menor dimensión. DEFINICIÓN 3. Una función φ: R1 × · · · × Rm → Rq es una función de agregación si m ≥ q y W(r, θ) = V(φ(r), θ) para alguna función V. Sobrecargamos el símbolo de función para aplicar a conjuntos de perfiles estratégicos: φ( ˆR) = {φ(r) : r ∈ ˆR}. Para mayor comodidad en la exposición, escribimos φ∗ (θ) para denotar φ(N(θ)). El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia. Por ejemplo, supongamos, como en nuestra aplicación a continuación, que la estrategia de un agente está definida por un parámetro numérico. Si todo lo que nos importa es el valor total jugado, podemos tomar φ(a) = Πm i=1 ai. Si hemos elegido nuestro agregador cuidadosamente, también podemos capturar estructuras que de otra manera no serían evidentes. Por ejemplo, φ∗ (θ) podría estar disminuyendo en θ, mientras que N(θ) podría tener una estructura más compleja. Dada una descripción de la correspondencia de solución N(θ) (equivalentemente, φ∗(θ)), el diseñador se enfrenta a un problema estándar de optimización. Alternativamente, dado un simulador que pudiera producir una muestra imparcial de la distribución de W (N(θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12]. Sin embargo, incluso para un juego Γθ con pagos conocidos, puede resultar computacionalmente intratable resolver los equilibrios de Nash, especialmente si el juego tiene conjuntos de estrategias grandes o infinitos. Además, deseamos estudiar juegos en los que los pagos no se dan explícitamente, sino que deben determinarse a partir de simulaciones u otra experiencia con el juego. Por lo tanto, asumimos que se nos proporciona un conjunto de datos (posiblemente ruidoso) de realizaciones de pagos: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, donde para cada punto de datos θi es el ajuste observado del parámetro del mecanismo, ai es el perfil de estrategia pura observado de los participantes, y Ui es la realización correspondiente de los pagos de los agentes. También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}. Sea D = {Do, Ds} el conjunto de datos combinado. (Ya sea que Do o Ds puedan ser nulos para un problema particular). En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos empíricos de teoría de juegos, para responder preguntas sobre el diseño del escenario TAC/SCM. 4. ANÁLISIS DE DISEÑO EMPÍRICO Dado que nuestros datos se presentan en forma de experiencia de pago y no como el valor de una función objetivo para configuraciones dadas de la variable de control, ya no podemos confiar en los métodos para optimizar funciones utilizando simulaciones. De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia del equilibrio de Nash. Además, no podemos depender directamente de los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilístico adaptados a nuestra configuración de problema. 4.1 Problema de Diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente. Recuerde que durante el torneo de 2004, los diseñadores del juego de la cadena de suministro optaron por aumentar drásticamente los costos de almacenamiento como medida para frenar las compras del día 0, con poco éxito. Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y la cantidad agregada de componentes adquiridos el día 0 en equilibrio. Esto suele ser el caso en juegos reales de interés, donde descripciones en lenguaje natural o algorítmicas pueden sustituir a una especificación formal de estrategias y funciones de pago. Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo. ¿Primero, ¿el aumento de los costos de almacenamiento realmente reduce la adquisición en el día 0? ¿Fue racional la adquisición excesiva observada durante el día 0 del torneo de 2004? Y en tercer lugar, ¿podría haber reducido de manera suficiente los costos de almacenamiento la adquisición del día 0 a un nivel aceptable, y en tal caso, cuál debería haber sido el ajuste de los costos de almacenamiento? Es esta tercera pregunta la que define el aspecto del diseño de mecanismos de nuestro análisis. Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de los agentes, la función de bienestar de los diseñadores, el espacio de parámetros del mecanismo y la fuente de datos. Restringimos las estrategias de los agentes para que sean un multiplicador de la cantidad de solicitudes del día 0 de uno de los finalistas, Deep Maize, en el torneo TAC/SCM de 2004. Lo restringimos aún más al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias por encima de 1.5 son extremadamente agresivas (por lo tanto, poco probables de proporcionar desviaciones refutadoras más allá de las disponibles en las estrategias incluidas, y ciertamente no forman parte de ningún equilibrio deseable). Todo otro comportamiento se basa en el comportamiento de Deep Maize y es idéntico para todos los agentes. Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico. Sin embargo, creemos que la forma general de los resultados debería ser robusta ante cambios en el comportamiento completo del agente. Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0. Sea φ(a) = Σ6 i=1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego particular de la cadena de suministro (para perfiles de estrategia mixta s, tomamos la esperanza de φ con respecto a la mezcla). La función de bienestar de los diseñadores W (N(θ), θ) se define entonces como I{sup{φ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de adquisición en el día 0 y I es la función indicadora. El diseñador selecciona un valor θ de costos de almacenamiento, expresado como un porcentaje anual del valor base de los componentes en el inventario (cobrado diariamente), del conjunto Θ = R+. Dado que la decisión de los diseñadores depende solo de φ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación. 4.2 Estimación de equilibrios de Nash El objetivo de los agentes de TAC/SCM es maximizar los beneficios obtenidos en una instancia del juego. Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, U(a)). Si también hemos fijado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de jugadores y sus correspondientes pagos, y, en consecuencia, para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios de Nash de cada juego Γθ. Por lo tanto, necesitamos métodos para aproximar equilibrios de Nash en juegos infinitos. A continuación, describimos los dos métodos que utilizamos en nuestro estudio. El primero ha sido explorado empíricamente anteriormente, mientras que el segundo se introduce aquí como el método específicamente diseñado para aproximar un conjunto de equilibrios de Nash. 4.2.1 Aproximación de la Función de Pago El primer método para estimar equilibrios de Nash basado en datos utiliza aprendizaje supervisado para aproximar las funciones de pago de mech6. No abordamos si y cómo otras medidas (por ejemplo, restringir directamente la adquisición) podrían haber logrado los objetivos de diseño. Nuestro enfoque considera como dado un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento. En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con un crecimiento de complejidad correspondiente. 308 participantes del mecanismo de un conjunto de datos de experiencia de juego [17]. Una vez que las funciones de pago aproximadas estén disponibles para todos los jugadores, los equilibrios de Nash pueden encontrarse ya sea de forma analítica o aproximada utilizando técnicas numéricas, dependiendo del modelo de aprendizaje. En lo que sigue, estimamos solo un equilibrio de Nash de muestra utilizando esta técnica, aunque esta restricción puede eliminarse a expensas de un tiempo de cálculo adicional. Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador. Por lo tanto, podemos aplicarlo cuando Ds = ∅. Si hay un simulador disponible, podemos generar datos adicionales para aumentar la confianza en nuestras estimaciones iniciales. Probamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado local (LWA) y regresión lineal ponderada localmente (LWLR). También utilizamos variables de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis empírico previo de teoría de juegos de TAC/SCM-03 [19]. El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido de forma analítica. Para los otros métodos aplicamos dinámica replicadora [7] a una aproximación discreta del juego aprendido. El total esperado de adquisiciones del día 0 en equilibrio se tomó como la estimación de un resultado. 4.2.2 Búsqueda en el Espacio de Perfiles de Estrategia Cuando tenemos acceso a un simulador, también podemos utilizar la búsqueda dirigida a través del espacio de perfiles para estimar el conjunto de equilibrios de Nash, que describimos aquí después de presentar alguna notación adicional. DEFINICIÓN 4. Un vecino estratégico de un perfil de estrategia pura a es un perfil que es idéntico a a en todo menos en una estrategia. Definimos Snb(a, D) como el conjunto de todos los vecinos estratégicos de a disponibles en el conjunto de datos D. De manera similar, definimos Snb(a, ˜D) como todos los vecinos estratégicos de a que no están en D. Finalmente, para cualquier a ∈ Snb(a, D) definimos al agente que se desvía como i(a, a). DEFINICIÓN 5. La -ligadura, ˆ, de un perfil de estrategia pura a se define como maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}. Decimos que a es un candidato a δ-equilibrio para δ ≥ ˆ. Cuando Snb(a, ˜D) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), a se confirma como un equilibrio de Nash ˆ. Nuestro método de búsqueda opera explorando desviaciones de los equilibrios candidatos. Nos referimos a esto como BestFirstSearch, ya que selecciona con probabilidad uno un perfil de estrategia a ∈ Snb(a, ˜D) que tiene el menor ˆin D. Finalmente definimos un estimador para un conjunto de equilibrios de Nash. DEFINICIÓN 6. Para un conjunto K, define Co(K) como la envoltura convexa de K. Sea Bδ el conjunto de candidatos en el nivel δ. Definimos ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) para un δ fijo como un estimador de φ∗ (θ). En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles estratégicos agregados con límite inferior -bound por debajo de un δ fijo. Esta definición nos permite explotar la estructura que surge de la función de agregación. Si dos perfiles son cercanos en términos de valores de agregación, es probable que tengan límites similares. En particular, si uno está en equilibrio, el otro también puede estarlo. Presentamos un respaldo teórico para este método de estimación del conjunto de equilibrios de Nash a continuación. Dado que el juego en el que estamos interesados es infinito, es necesario terminar BestFirstSearch antes de explorar todo el espacio de strat7. Por ejemplo, podemos utilizar técnicas de aprendizaje activo [5] para mejorar la calidad de la aproximación de la función de recompensa. En este trabajo, nos concentramos en la búsqueda en el espacio de perfiles estratégicos. Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos. Generación de datos Nuestros datos fueron recopilados simulando juegos TAC/SCM en una versión local del servidor TAC/SCM de 2004, que tiene una configuración para el costo de almacenamiento. Las estrategias de los agentes en juegos simulados fueron seleccionadas del conjunto {0, 0.3, 0.6, . . . , 1.5} con el fin de tener una probabilidad positiva de generar vecinos estratégicos. Se generó un conjunto de datos base Do mediante el muestreo de 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}. Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varios defectos. Utilizamos la búsqueda para generar un conjunto de datos simulados Ds, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ. Dado que el costo de la simulación es extremadamente alto (un juego tarda casi 1 hora en ejecutarse), pudimos ejecutar un total de 2670 juegos en el transcurso de más de seis meses. Para hacer una comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategias conjuntas finitas restringidas para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces). 4.4 Resultados 4.4.1 Análisis del conjunto de datos base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos base Do. Además, generamos una estimación de la correspondencia del equilibrio de Nash, ˆφ∗ (θ), aplicando la Definición 6 con δ = 2.5E6. Los resultados se muestran en la Figura 1. Como podemos ver, la correspondencia ˆφ∗ (θ) tiene poco poder predictivo basado en Do, y no revela ninguna estructura interesante sobre el juego. Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición Total Día 0 LWA LWLR QR BaselineMin BaselineMax Figura 1: Estimaciones de adquisición del día 0 agregadas basadas en Do. La correspondencia ˆφ∗ (θ) es el intervalo entre BaselineMin y BaselineMax. En general, la búsqueda se detiene una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para obtener conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego. Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash a permanecer en este subconjunto discreto de [0,1.5]. Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron accidentes, problemas de conectividad de red y otras anomalías obvias), el juego sería descartado. Análisis de los datos de búsqueda Para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ∗ (θ) (nuevamente, usando δ =2.5E6) en el conjunto de datos D = {Do, Ds}, donde Ds es datos generados a través de la aplicación de BestFirstSearch. Los resultados de esta estimación se representan gráficamente frente a los resultados de los métodos de aprendizaje entrenados en Do 11 en la Figura 2. Primero, observamos que la adición de los datos de búsqueda reduce considerablemente el rango de posibles equilibrios. Además, las predicciones puntuales reales de los métodos de aprendizaje y aquellas basadas en límites después de la búsqueda son razonablemente cercanas. Combinar la evidencia recopilada de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquiera de los métodos utilizados de forma aislada. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición del Día 0 LWA LWLR QR Búsqueda Mínima Búsqueda Máxima Figura 2: Estimaciones agregadas de adquisición del día 0 basadas en la búsqueda en el espacio de perfiles de estrategia en comparación con técnicas de aproximación de funciones entrenadas en Do. La correspondencia ˆφ∗ (θ) para D = {Do, Ds} es el intervalo entre SearchMin y SearchMax. Esta evidencia respalda la intuición inicial de que la adquisición del día 0 debería disminuir con los costos de almacenamiento. También confirma que los altos niveles de adquisición en el día 0 son una respuesta racional al entorno del torneo de 2004 con un costo promedio de almacenamiento, que corresponde a θ = 100. La predicción mínima para la adquisición agregada en este nivel de costos de almacenamiento, dada por cualquier método experimental, es aproximadamente 3. Esto es bastante alto, ya que corresponde a un compromiso esperado del 1/3 de la capacidad total del proveedor para todo el juego. La predicción máxima es considerablemente mayor a 4.5. En la competencia actual de 2004, la adquisición total del día 0 equivalía a 5.71 en la escala utilizada aquí [9]. Nuestras predicciones subestiman este resultado en cierta medida, pero muestran que cualquier resultado racional probablemente tendría una alta adquisición en el día 0. 4.4.3 Extrapolando la Correspondencia de la Solución Tenemos evidencia razonablemente sólida de que la correspondencia del resultado está disminuyendo. Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento a un valor que reduciría la adquisición del día 0 en equilibrio, o concluir que esto no es posible. Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día 0. No está claro cuán significativos serían los resultados del aprendizaje si se agregaran Ds al conjunto de datos de entrenamiento. De hecho, los datos adicionales pueden aumentar realmente la varianza del aprendizaje. Recuerde que el objetivo de los diseñadores es incentivar la adquisición agregada del día 0 que esté por debajo del umbral α. Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultados estimada a partir de D que produce θ = 320. Los datos para θ = 320 fueron recopilados de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos por 33 iteraciones de BestFirstSearch. La Figura 3 muestra los límites detallados para todos los perfiles en términos de sus valores correspondientes de φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Límites de ε de Adquisición Total Día-0 Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320. Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ(a). La región gris corresponde a ˆφ∗ (320) con δ = 2.5M. El conjunto estimado de resultados agregados del día 0 es muy cercano al de θ = 200, lo que indica que hay poco beneficio adicional al aumentar los costos de almacenamiento por encima de 200. Observa que incluso el límite inferior de nuestro conjunto estimado de equilibrios de Nash está muy por encima de la adquisición objetivo del día 0 de 2. Además, las recompensas para los agentes son casi siempre negativas en θ = 320. Por consiguiente, aumentar los costos aún más sería indeseable incluso si finalmente se pudiera reducir la adquisición en el día 0. Dado que tenemos una confianza razonable de que φ∗ (θ) está disminuyendo en θ, tampoco esperamos que establecer θ en algún lugar entre 200 y 320 logre el resultado deseado. Concluimos que es poco probable que la adquisición del día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento. Que nuestras predicciones tienden a subestimar los resultados del torneo refuerza esta conclusión. Para lograr la reducción deseada en la adquisición del día 0 se requiere rediseñar otros aspectos del mecanismo. 4.5 Análisis Probabilístico Nuestro análisis empírico ha producido evidencia en apoyo a la conclusión de que ninguna configuración razonable del costo de almacenamiento probablemente sería suficiente para frenar la adquisición excesiva del día 0 en TAC/SCM 04. Toda esta evidencia ha sido en forma de simple interpolación y extrapolación de estimaciones de la correspondencia del equilibrio de Nash. Estas estimaciones se basan en simular instancias del juego y están sujetas a ruido de muestreo contribuido por los diversos elementos estocásticos del juego. En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos -bound a tales efectos estocásticos. Supongamos que todos los agentes tienen conjuntos de estrategias puras finitos (y pequeños), A. Por lo tanto, es factible muestrear toda la matriz de pagos del juego. Además, supongamos que el ruido es aditivo con media cero en promedio durante todo el juego, por lo que en la práctica probablemente querríamos que el umbral sea aún más bajo. 310 y varianza finita, es decir, Ui(a) = ui(a) + ˜ξi(a), donde Ui(a) es la ganancia observada para i cuando se jugó a, ui(a) es la ganancia correspondiente real, y ˜ξi(a) es una variable aleatoria normal con media cero. Designamos la varianza conocida de ˜ξi(a) como σ2 i (a). Por lo tanto, asumimos que ˜ξi(a) es normal con distribución N(0, σ2 i (a)). Tomamos ¯ui(a) como la media muestral de todos los Ui(a) en D, y seguimos a Chang y Huang [3] al asumir que tenemos una priori impropia sobre las ganancias reales ui(a) y el muestreo fue independiente para todos i y a. También confiamos en su resultado de que ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] son independientes con distribuciones posteriores N(¯ui(a), σ2 i (a)/ni(a)), donde ni(a) es el número de muestras tomadas de los pagos para i en el perfil puro a, y Zi(a) ∼ N(0, 1). Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio de Nash -Nash. Si ui(·)|¯ui(·) son independientes para todo i ∈ I y a ∈ A, tenemos el siguiente resultado (a partir de este punto omitimos la condición sobre ¯ui(·) por brevedad): PROPOSICIÓN 1. Para todo \\( i \\in I \\), \\( \\max_{b \\in A_i} u_i(b, a_{-i}) - u_i(a) \\leq \\varepsilon \\), donde \\( \\varepsilon = \\int_{Y_i} \\int_{Z} \\int_{R} \\int_{Y} \\int_{b \\in A_i \\backslash a_i} \\Pr(u_i(b, a_{-i}) \\leq u + \\varepsilon) f_{u_i(a)}(u) du \\), donde \\( f_{u_i(a)}(u) \\) es la función de densidad de probabilidad de \\( N(\\overline{u_i(a)}, \\sigma_i(a)) \\). Las pruebas de este y todos los resultados posteriores se encuentran en el Apéndice. La distribución posterior de la media óptima de n muestras, derivada por Chang y Huang [3], es Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) donde a ∈ A y Φ(·) es la función de distribución N(0, 1). Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilístico que (a) ≤ γ para un γ dado. Ahora, consideramos casos de datos incompletos y utilizamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en los datos) en la distribución de sup{φ∗ (θ)} e inf{φ∗ (θ)} (asumiendo que ambos son alcanzables): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, donde x es un número real y ≤D indica que el límite superior solo considera estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} y {inf{φ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf{φ∗ (θ)} ≤ x}. Los valores así derivados comprenden las Tablas 1 y 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Tabla 1: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando N(θ) es un conjunto de equilibrios de Nash. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Tabla 2: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {150, 200, 320} cuando N(θ) es un conjunto de equilibrios de Nash. Las Tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ(a) < 2.7 es poco probable para cualquier θ del cual tengamos datos, aunque este juicio, como mencionamos, se refiere únicamente a los perfiles que hemos muestreado realmente. Podemos entonces aceptar esto como otra pieza de evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, parece poco probable que el diseñador logre su objetivo incluso si pudiera persuadir a los participantes a jugar un equilibrio deseable. La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM de 2004 eran, de hecho, racionales al adquirir grandes cantidades de componentes al comienzo del juego. Si observamos la tercera columna de esta tabla, que corresponde a θ = 100, podemos deducir que ningún perfil a en nuestros datos con φ(a) < 3 es muy probable que se juegue en equilibrio. Los límites anteriores proporcionan algunas pruebas generales, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos muestreado. Particularmente, nos gustaría decir algo sobre lo que sucede en los ajustes de θ para los cuales no tenemos datos. Para derivar un límite probabilístico aproximado sobre la probabilidad de que ningún θ ∈ Θ haya logrado el objetivo del diseñador, sea ∪J j=1Θj una partición de Θ, y asuma que la función sup{φ∗ (θ)} satisface la condición de Lipschitz con constante de Lipschitz Aj en cada subconjunto Θj. Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a Θ = [0, 320]. Ahora definimos cada subconjunto j como el intervalo entre dos puntos para los cuales hemos producido datos. Por lo tanto, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], con j variando entre 1 y 5, correspondiendo a los subintervalos anteriores. Denotaremos cada Θj por (aj, bj]. Luego, la siguiente proposición nos da una cota superior aproximada sobre la probabilidad de que sup{φ∗ (θ)} ≤ α. PROPOSICIÓN 2. Debido a que nuestros límites son aproximados, no podemos utilizarlos como una evaluación probabilística concluyente. En cambio, tomamos esto como otra pieza de evidencia para complementar nuestros hallazgos. Aunque podamos asumir que una función que aproximamos a partir de datos es Lipschitz continua, rara vez conocemos en realidad la constante de Lipschitz para cualquier subconjunto de Θ. Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de los datos. Aquí, probamos tres métodos para hacer esto. El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subintervalo. Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo. Un método alternativo es tomar un límite superior en la pendiente obtenida dentro de cada subintervalo utilizando los datos disponibles. Esto produce un límite superior de probabilidades mucho menos conservador. Sin embargo, dado que el límite superior real suele ser mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso. Un último método que intentamos es un compromiso entre los dos anteriores. En lugar de tomar el límite superior conservador basado en datos sobre todo el dominio de la función Θ, tomamos el promedio de los límites superiores obtenidos en cada Θj. El límite en un intervalo se toma como el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos. Los resultados de evaluar la expresión para Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3. En términos de nuestras afirmaciones en maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Tabla 3: Límite superior aproximado de la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con un objetivo α = 2. Se utilizan diferentes métodos para aproximar el límite superior de la pendiente en cada subintervalo j. En este trabajo, la expresión proporciona un límite superior a la probabilidad de que alguna configuración de θ (es decir, costo de almacenamiento) en el intervalo [0,320] resulte en una adquisición total del día 0 que no sea mayor en ningún equilibrio que el objetivo especificado por α y tomado aquí como 2. Como sospechábamos, el enfoque más conservador para estimar el límite superior de la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí. Sin embargo, los otros dos enfoques de estimación, encontrados en las columnas dos y tres de la Tabla 3, sugieren que de hecho estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría funcionado. Dada la tremenda dificultad del problema, este resultado es muy sólido. Aun así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia. Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y los conjuntos de estrategias). Tampoco podemos esperar obtener nunca suficiente evidencia para llegar a conclusiones completamente objetivas. En cambio, el enfoque que defendemos aquí es recopilar la mayor cantidad de evidencia posible dadas las limitaciones de recursos, y tomar la decisión más convincente basada en esta evidencia, si es posible. RESULTADOS DE CONVERGENCIA En este punto, exploramos abstractamente si una elección de parámetro de diseño basada en datos de pago puede ser asintóticamente confiable. Dado que no teníamos todas las desviaciones posibles para cualquier perfil disponible en los datos, los verdaderos límites superiores pueden ser aún más bajos. Por conveniencia, utilizaremos la notación un,i(a) para referirnos a una función de pago del jugador i basada en un promedio sobre n muestras i.i.d. de la distribución de pagos. También asumimos que un,i(a) son independientes para todo a ∈ A e i ∈ I. Utilizaremos la notación Γn para referirnos al juego [I, R, {ui,n(·)}], mientras que Γ denotará el juego subyacente, [I, R, {ui(·)}]. De manera similar, definimos n(r) como (r) con respecto al juego Γn. En esta sección, demostramos que n(s) → (s) casi seguramente de forma uniforme en el espacio de estrategias mixtas para cualquier juego finito, y, además, que todas las equilibrios de Nash en estrategias mixtas en juegos empíricos eventualmente se acercan arbitrariamente a algunas estrategias de equilibrio de Nash en el juego subyacente. Utilizamos estos resultados para demostrar que bajo ciertas condiciones, la elección óptima del parámetro de diseño basada en datos empíricos converge casi seguramente al óptimo real. TEOREMA 3. Supongamos que |I| < ∞, |A| < ∞. Entonces n(s) → (s) casi seguramente uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios de Nash de Γ. Si definimos Nn,γ = {s ∈ S : n(s) ≤ γ}, tenemos el siguiente corolario del Teorema 3: COROLARIO 4. Para todo γ > 0, existe un M tal que para todo n ≥ M, N ⊂ Nn,γ casi seguramente. PRUEBA. Dado que n(s) = 0 para todo s ∈ N, podemos encontrar un M lo suficientemente grande tal que Pr{supn≥M sups∈N n(s) < γ} = 1. Según el Corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier > 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios de Nash empíricos si se han tomado suficientes muestras. Como mostramos ahora, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un límite no nulo como una estimación del conjunto de equilibrios de Nash. Primero, supongamos que concluimos que para una configuración particular de θ, sup{ˆφ∗ (θ)} ≤ α. Entonces, dado que para cualquier fijo > 0, N(θ) ⊂ Nn, (θ) cuando n es suficientemente grande, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α para cualquier n de este tipo. Así, dado que definimos la función de bienestar del diseñador como I{sup{φ∗ (θ)} ≤ α} en nuestro dominio de interés, la elección empírica de θ satisface el objetivo del diseñador, maximizando así su función de bienestar. Alternativamente, supongamos que concluimos que inf{ˆφ∗ (θ)} > α para cada θ en el dominio. Entonces, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, para todo θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo del diseñador. Ahora, demostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de Γn está cerca de algún equilibrio de Nash del juego subyacente. Este resultado nos llevará a considerar la convergencia de los optimizadores basados en datos empíricos a los ajustes óptimos reales de los parámetros del mecanismo. Primero notamos que la función (s) es continua en un juego finito. LEMMA 5. \n\nLEMMA 5. Sea S un conjunto de estrategias mixtas definido en un juego finito. Entonces: S → R es continua. Para la exposición que sigue, necesitamos un poco de notación adicional. Primero, sea (Z, d) un espacio métrico, y X, Y ⊂ Z y definamos la distancia de Hausdorff dirigida de X a Y como h(X, Y) = sup x∈X inf y∈Y d(x, y). Observa que U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ). Además, define BS(x, δ) como una bola abierta en S ⊂ Z con centro en x ∈ S y radio δ. Ahora, dejemos que Nn denote todos los equilibrios de Nash del juego Γn y sea Nδ = [ x∈N BS(x, δ), es decir, la unión de bolas abiertas de radio δ con centros en los equilibrios de Nash de Γ. Ten en cuenta que h(Nδ, N) = δ. Podemos entonces demostrar el siguiente resultado general. TEOREMA 6. Supongamos que |I| < ∞ y |A| < ∞. Entonces casi con seguridad h(Nn, N) converge a 0. Ahora demostraremos que en el caso especial cuando Θ y A son finitos y cada Γθ tiene un equilibrio de Nash único, las estimaciones ˆθ del parámetro óptimo del diseñador convergen a un optimizador real casi seguramente. Sea ˆθ = arg maxθ∈Θ W (Nn(θ), θ), donde n es el número de veces que se muestreó cada perfil puro en Γθ para cada θ, y sea θ∗ = arg maxθ∈Θ W (N(θ), θ). TEOREMA 7. Supongamos que |N(θ)| = 1 para todo θ ∈ Θ y supongamos que Θ y A son finitos. Sea W (s, θ) continua en el único s∗ (θ) ∈ N(θ) para cada θ ∈ Θ. Entonces ˆθ es un estimador consistente de θ∗ si W (N(θ), θ) se define como un supremo, ínfimo o esperanza sobre el conjunto de equilibrios de Nash. De hecho, ˆθ → θ∗ casi seguramente en cada uno de estos casos. La limitación del resultado anterior es que, dentro de nuestro marco de trabajo, el diseñador no tiene forma de saber o asegurar que Γθ tenga equilibrios únicos. Sin embargo, sí proporciona cierta justificación teórica para seguir el diseño de esta manera, y quizás servirá como guía para obtener resultados más generales en el futuro. 6. TRABAJO RELACIONADO La literatura de diseño de mecanismos en Economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10]. Además, existe una extensa literatura sobre el diseño óptimo de subastas [10], del cual el trabajo de Roger Myerson [11] es, quizás, el más relevante. En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y teniendo en cuenta restricciones como la compatibilidad de incentivos y la racionalidad individual. Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de Ciencias de la Computación. Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros relevantes del juego son conocimiento común. Cuando las funciones de pago de los jugadores son desconocidas, se ha explorado la realización de búsquedas mediante simulaciones como alternativa. Un enfoque en esa dirección, tomado en [4] y [15], es coevolucionar el parámetro del mecanismo y las estrategias de los agentes, utilizando alguna noción de utilidad social y pagos de los agentes como criterios de aptitud. Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética. En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron un resultado de un juego inducido por un parámetro del mecanismo como el resultado del aprendizaje conjunto de los agentes. Más recientemente, Phelps et al. [14] compararon dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en juegos definidos por estrategias heurísticas, como en [18]. 7. CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el diseño empírico de mecanismos. Definimos un modelo formal de teoría de juegos de interacción entre el diseñador y los participantes del mecanismo como un juego de dos etapas. También describimos en cierta generalidad los métodos para estimar una función de equilibrio de Nash de muestra cuando los datos son extremadamente escasos, o una correspondencia de equilibrio de Nash cuando hay más datos disponibles. Nuestras técnicas están diseñadas específicamente para abordar problemas en los que tanto el espacio de parámetros del mecanismo como los conjuntos de estrategias de los agentes son infinitos y solo se puede adquirir un conjunto de datos relativamente pequeño. Un problema de diseño difícil en el juego TAC/SCM que la comunidad de TAC ha estado ansiosa por abordar nos brinda un escenario para probar nuestros métodos. Al aplicar el análisis empírico del juego al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos. Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia del equilibrio de Nash. Al final, podemos intentar proporcionar suficiente evidencia para prescribir una configuración de parámetros, o sugerir que no es posible encontrar una configuración que satisfaga al diseñador. En el caso de TAC/SCM, nuestra evidencia sugiere bastante claramente que el costo de almacenamiento no pudo haber sido ajustado de manera efectiva en el torneo de 2004 para frenar la adquisición excesiva del día 0 sin efectos perjudiciales en la rentabilidad general. El éxito de nuestro análisis en este entorno extremadamente complejo con altos costos de simulación nos hace ser optimistas de que nuestros métodos pueden brindar orientación en la toma de decisiones de diseño de mecanismos en otros dominios desafiantes. Los resultados teóricos confirman algunas intuiciones detrás de los métodos de diseño de mecanismos empíricos que hemos introducido, y aumentan nuestra confianza en que nuestro marco puede ser efectivo para estimar la mejor elección de parámetros del mecanismo en entornos relativamente generales. Agradecimientos Agradecemos a Terence Kelly, Matthew Rudary y Satinder Singh por sus útiles comentarios sobre versiones anteriores de este trabajo. Este trabajo fue apoyado en parte por la subvención de la NSF IIS-0205435 y el programa de razonamiento estratégico DARPA REAL. 8. REFERENCIAS [1] R. Arunachalam y N. M. Sadeh. La competencia de agentes de comercio de la cadena de suministro. Investigación y aplicaciones del comercio electrónico, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy y M. Tschantz. Un enfoque de programación estocástica para la planificación en TAC SCM. En la Quinta Conferencia ACM sobre Comercio Electrónico, páginas 152-159, Nueva York, 2004. [3] Y.-P. Chang y W.-T. Huang. Intervalos de confianza generalizados para el valor más grande de algunas funciones de parámetros bajo normalidad. Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.\nEstadística Sinica, 10:1369-1383, 2000. [4] D. Cliff. Evolución del mecanismo de mercado a través de un espacio continuo de tipos de subasta. En el Congreso de Computación Evolutiva de 2002. [5] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [6] V. Conitzer y T. Sandholm. Un algoritmo para diseñar automáticamente mecanismos determinísticos sin pagos. En la Tercera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagente, páginas 128-135, 2004. [7] D. Friedman. Juegos evolutivos en economía. Econometrica, 59(3):637-666, mayo de 1991. [8] R. Keener. Teoría Estadística: Una Mezcla de Temas Fundamentales. Departamento de Estadística de la Universidad de Michigan, 2004. [9] C. Kiekintveld, Y. Vorobeychik y M. P. Wellman. Un análisis de la competencia de agentes comerciales de gestión de la cadena de suministro de 2004. En el taller IJCAI-05 sobre Diseño y Análisis de Agentes de Negociación, Edimburgo, 2005. [10] A. Mas-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [11] R. B. Myerson.\nEditorial de la Universidad de Oxford, 1995. [11] R. B. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6(1):58-73, febrero de 1981. [12] S. Olafsson y J. Kim. Optimización de simulación. En E. Yucesan, C.-H. Chen, J. Snowdon y J. Charnes, editores, Conferencia de Simulación de Invierno 2002, 2002. [13] D. Pardoe y P. Stone. TacTex-03: Un agente de gestión de la cadena de suministro. SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, y P. McBurney. Agentes automatizados versus humanos virtuales: una comparación teórica evolutiva de dos diseños de mercado de subasta doble. En Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney y E. Sklar. Co-evolución de mecanismos de subasta y estrategias de negociación: hacia un enfoque novedoso para el diseño microeconómico. En el taller ECOMAS 2002, 2002. [16] S. Phelps, S. Parsons, E. Sklar y P. McBurney. Utilizando programación genética para optimizar reglas de precios para un mercado de subasta doble. En Taller sobre Agentes para el Comercio Electrónico, 2003. [17] Y. Vorobeychik, M. P. Wellman y S. Singh. Aprendiendo funciones de pago en juegos infinitos. En la Decimonovena Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro y J. O. Kephart. Analizando interacciones estratégicas complejas en sistemas multiagente. En el taller AAAI-02 sobre agentes teóricos de juegos y de toma de decisiones, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld y V. Soni. Interacciones estratégicas en un juego de cadena de suministro. Inteligencia Computacional, 21(1):1-26, febrero de 2005. APÉNDICE A. PRUEBAS A.1 Prueba de la Proposición 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du. A.2 Prueba de la Proposición 2 Primero, supongamos que alguna función, f(x), definida en [ai, bi], satisface la condición de Lipschitz en (ai, bi] con una constante de Lipschitz Ai. Entonces se cumple la siguiente afirmación: Afirmación: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai). Para demostrar esta afirmación, observe que la intersección de las líneas en f(ai) y f(bi) con pendientes -Ai y Ai respectivamente determinará el límite inferior del mínimo de f(x) en [ai, bi] (que es un límite inferior del ínfimo de f(x) en (ai, bj]). La línea en f(ai) está determinada por f(ai) = −Aiai + cL y la línea en f(bi) está determinada por f(bi) = Aibi + cR. Por lo tanto, las intercepciones son cL = f(ai) + Aiai y cR = f(bi) + Aibi respectivamente. Sea x∗ el punto en el que estas líneas se cruzan. Entonces, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A. Al sustituir las expresiones de cR y cL, obtenemos el resultado deseado. Ahora, la subaditividad nos da Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, y, por la afirmación, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}. Dado que tenemos un número finito de puntos en el conjunto de datos para cada θ, podemos obtener la siguiente expresión: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}. Ahora podemos restringir nuestra atención en obtener una cota superior en Pr{sup{φ∗ (θ)} = y} para un θ fijo. Para hacer esto, observe que Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} por subaditividad y el hecho de que un perfil a es un equilibrio de Nash si y solo si (a) = 0. Poner todo junto produce el resultado deseado. Prueba de Teorema 3 En primer lugar, necesitaremos el siguiente hecho: Afirmación: Dada una función fi(x) y un conjunto X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|. Para demostrar esta afirmación, observe que | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) si maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) si maxx f2(x) ≥ maxx f1(x) En el primer caso, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 De manera similar, en el segundo caso, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|. Por lo tanto, la afirmación se mantiene. Por la Ley Fuerte de los Grandes Números, un,i(a) → ui(a) casi seguramente para todo i ∈ I, a ∈ A. Es decir, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, o, equivalentemente [8], para cualquier α > 0 y δ > 0, existe M(i, a) > 0 tal que Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Al tomar M = maxi∈I maxa∈A M(i, a), tenemos que Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Así, por la afirmación, para cualquier n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ con una probabilidad de al menos 1 − α. Ten en cuenta que dado que s−i(a) y s(a) están acotados entre 0 y 1, pudimos eliminarlos de las expresiones anteriores para obtener una cota que será válida independientemente de la elección particular de s. Además, dado que el resultado anterior se puede obtener para un α arbitrario > 0 y δ > 0, tenemos que Pr{limn→∞ n(s) = (s)} = 1 uniformemente en S. A.4 Prueba del Lema 5 Demostramos el resultado utilizando la continuidad uniforme de ui(s) y la preservación de la continuidad bajo el máximo. Afirmación: Una función f : Rk → R definida por f(t) = Σi=1k zi ti, donde zi son constantes en R, es uniformemente continua en t. La afirmación se sigue porque |f(t)−f(t )| = | Σi=1k zi(ti−ti)| ≤ Σi=1k |zi||ti − ti|. Un resultado inmediato de esto para nuestros propósitos es que ui(s) es uniformemente continua en s y ui(ai, s−i) es uniformemente continua en s−i. Afirmación: Sea f(a, b) uniformemente continua en b ∈ B para cada a ∈ A, con |A| < ∞. Entonces V (b) = maxa∈A f(a, b) es uniformemente continua en b. Para demostrar esto, toma γ > 0 y deja que b, b ∈ B tal que b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ. Ahora toma δ = mina∈A δ(a). Entonces, cada vez que b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ. Ahora, recuerda que (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)]. Según las afirmaciones anteriores, maxai∈Ai ui(ai, s−i) es uniformemente continua en s−i y ui(s) es uniformemente continua en s. Dado que la diferencia de dos funciones uniformemente continuas es uniformemente continua, y dado que esta continuidad se conserva bajo el máximo según nuestra segunda afirmación, obtenemos el resultado deseado. Prueba de Teorema 6. Elija δ > 0. Primero, necesitamos asegurarnos de que se cumple la siguiente afirmación: Afirmación: ¯ = mins∈S\\Nδ (s) existe y ¯ > 0. Dado que Nδ es un subconjunto abierto de S compacto, se sigue que S \\ Nδ es compacto. Como también habíamos demostrado en el Lema 5 que (s) es continua, la existencia se sigue del teorema de Weierstrass. Es claro que ¯ > 0 ya que (s) = 0 si y solo si s es un equilibrio de Nash de Γ. Ahora, por el Teorema 3, para cualquier α > 0 existe un M tal que Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. En consecuencia, para cualquier δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Dado que esto se cumple para un α arbitrario > 0 y δ > 0, se obtiene el resultado deseado. Prueba de Teorema 7. Fija θ y elige δ > 0. Dado que W (s, θ) es continua en s∗ (θ), dado > 0 existe δ > 0 tal que para cada s que esté dentro de δ de s∗ (θ), |W (s, θ) - W (s∗ (θ), θ)| < . Según el Teorema 6, podemos encontrar M(θ) lo suficientemente grande para que todos los s ∈ Nn estén dentro de δ de s∗ (θ) para todo n ≥ M(θ) con probabilidad 1. Por consiguiente, para cualquier > 0 podemos encontrar M(θ) lo suficientemente grande tal que con probabilidad 1 tengamos supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < . Asumamos sin pérdida de generalidad que hay una elección óptima única de θ. Ahora, dado que el conjunto Θ es finito, también existe la segunda mejor opción de θ (si solo hay un θ ∈ Θ, esta discusión no tiene sentido de todos modos): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ). Supongamos sin pérdida de generalidad que θ∗∗ también es único y sea ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ). Entonces, si dejamos < ∆/2 y dejamos que M = maxθ∈Θ M(θ), donde cada M(θ) es lo suficientemente grande como para que supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., la elección óptima de θ basada en cualquier equilibrio empírico será θ∗ con probabilidad 1. Por lo tanto, en particular, dado cualquier distribución de probabilidad sobre equilibrios empíricos, la mejor elección de θ será θ∗ con probabilidad 1 (similarmente, si tomamos el supremo o el ínfimo de W (Nn(θ), θ) sobre el conjunto de equilibrios empíricos al construir la función objetivo). ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "two-stage game": {
            "translated_key": "juego de dos etapas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a <br>two-stage game</br>.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a <br>two-stage game</br>.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a <br>two-stage game</br>.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a <br>two-stage game</br>."
            ],
            "translated_annotated_samples": [
                "EL MODELO Modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un <br>juego de dos etapas</br>.",
                "Definimos un modelo formal de teoría de juegos de interacción entre el diseñador y los participantes del mecanismo como un <br>juego de dos etapas</br>."
            ],
            "translated_text": "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismos empíricos. En la continuación, desarrollamos algunos métodos generales para el diseño empírico de mecanismos y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto. En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2. Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores. Ri es el conjunto de estrategias disponibles para el jugador i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×. . .×Am. A menudo es conveniente referirse a la estrategia del jugador i por separado de la de los demás jugadores. Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama un perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i). Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el jugador i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada jugador i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i. Podemos extender esta definición a estrategias mixtas asumiendo que ui son utilidades de von Neumann-Morgenstern (vNM) de la siguiente manera: ui(s) = Es[ui], donde Es es la expectativa tomada con respecto a la distribución de probabilidad del juego inducida por la estrategia mixta de los jugadores s. Al emplear la forma normal, modelamos a los agentes jugando una única acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones más detalladas sobre la acción a lo largo del tiempo en la forma extensiva. Aunque cualquier juego extenso puede ser reformulado en forma normal, hacerlo puede sacrificar la concisión y difuminar distinciones relevantes (por ejemplo, la perfección en subjuegos). Ocasionalmente, escribimos ui(x, y) para indicar que x ∈ Ai o Si y y ∈ A−i o S−i dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u(·) = {u1(·), . . . , um(·)}. Definimos una función, : R → R, interpretada como el beneficio máximo que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) donde r pertenece a algún conjunto de estrategias, R, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada aquellas jugadas por los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un equilibrio de Nash. DEFINICIÓN 1. Un perfil estratégico r = (r1, . . . , rm) constituye un equilibrio de Nash del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). Cuando r ∈ A, lo anterior define un equilibrio de Nash de estrategia pura; de lo contrario, la definición describe un equilibrio de Nash de estrategia mixta. A menudo recurrimos al concepto de un equilibrio aproximado, o equilibrio de Nash, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita. Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un equilibrio de Nash si (r) ≤ . En este estudio dedicamos especial atención a los juegos que presentan simetría en cuanto a los pagos, lo que hace que los agentes sean estratégicamente idénticos. DEFINICIÓN 2. Un juego [I, {Ri}, {ui(r)}] es simétrico si para todo i, j ∈ I, (a) Ri = Rj y (b) ui(ri, r−i) = uj (rj, r−j) siempre que ri = rj y r−i = r−j. EL MODELO Modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un <br>juego de dos etapas</br>. El diseñador comienza seleccionando primero un valor, θ, de un conjunto de configuraciones de mecanismos permitidas, Θ. Todos los agentes participantes observan el parámetro θ del mecanismo y se mueven simultáneamente después. Por ejemplo, el diseñador podría estar decidiendo entre mecanismos de subasta de sobre cerrado de precio único y de precio único, con la presunción de que una vez tomada la decisión, los postores participarán con pleno conocimiento de las reglas de la subasta. Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como Γθ = [I, {Ri}, {ui(r, θ)}]. Nos referimos a Γθ como un juego inducido por θ. Sea N(θ) el conjunto de perfiles estratégicos considerados soluciones del juego Γθ.3. Supongamos que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, W(r, θ), dependiente del parámetro del mecanismo y del juego resultante, r. Definimos una medida pesimista, W( ˆR, θ) = inf{W(r, θ) : r ∈ ˆR}, que representa el bienestar en el peor de los casos del juego inducido por θ, asumiendo que los agentes juegan alguna estrategia conjunta en ˆR. Normalmente nos preocupamos por W (N(θ), θ), el resultado en el peor de los casos de jugar alguna solución. En algunos problemas podemos obtener una considerable ventaja al utilizar una función de agregación para mapear el resultado del bienestar de un juego. Generalmente adoptamos el equilibrio de Nash como concepto de solución, y por lo tanto tomamos N(θ) como el conjunto de equilibrios. Sin embargo, gran parte de la metodología desarrollada aquí podría ser utilizada con criterios alternativos para derivar el comportamiento del agente a partir de una definición del juego. Nuevamente, existen alternativas disponibles. Por ejemplo, si se tiene una distribución de probabilidad sobre el conjunto de soluciones N(θ), sería natural tomar la expectativa de W(r, θ) en su lugar. 307 especificado en términos de estrategias de agentes a un resultado de bienestar equivalente especificado en términos de un resumen de menor dimensión. DEFINICIÓN 3. Una función φ: R1 × · · · × Rm → Rq es una función de agregación si m ≥ q y W(r, θ) = V(φ(r), θ) para alguna función V. Sobrecargamos el símbolo de función para aplicar a conjuntos de perfiles estratégicos: φ( ˆR) = {φ(r) : r ∈ ˆR}. Para mayor comodidad en la exposición, escribimos φ∗ (θ) para denotar φ(N(θ)). El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia. Por ejemplo, supongamos, como en nuestra aplicación a continuación, que la estrategia de un agente está definida por un parámetro numérico. Si todo lo que nos importa es el valor total jugado, podemos tomar φ(a) = Πm i=1 ai. Si hemos elegido nuestro agregador cuidadosamente, también podemos capturar estructuras que de otra manera no serían evidentes. Por ejemplo, φ∗ (θ) podría estar disminuyendo en θ, mientras que N(θ) podría tener una estructura más compleja. Dada una descripción de la correspondencia de solución N(θ) (equivalentemente, φ∗(θ)), el diseñador se enfrenta a un problema estándar de optimización. Alternativamente, dado un simulador que pudiera producir una muestra imparcial de la distribución de W (N(θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12]. Sin embargo, incluso para un juego Γθ con pagos conocidos, puede resultar computacionalmente intratable resolver los equilibrios de Nash, especialmente si el juego tiene conjuntos de estrategias grandes o infinitos. Además, deseamos estudiar juegos en los que los pagos no se dan explícitamente, sino que deben determinarse a partir de simulaciones u otra experiencia con el juego. Por lo tanto, asumimos que se nos proporciona un conjunto de datos (posiblemente ruidoso) de realizaciones de pagos: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, donde para cada punto de datos θi es el ajuste observado del parámetro del mecanismo, ai es el perfil de estrategia pura observado de los participantes, y Ui es la realización correspondiente de los pagos de los agentes. También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}. Sea D = {Do, Ds} el conjunto de datos combinado. (Ya sea que Do o Ds puedan ser nulos para un problema particular). En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos empíricos de teoría de juegos, para responder preguntas sobre el diseño del escenario TAC/SCM. 4. ANÁLISIS DE DISEÑO EMPÍRICO Dado que nuestros datos se presentan en forma de experiencia de pago y no como el valor de una función objetivo para configuraciones dadas de la variable de control, ya no podemos confiar en los métodos para optimizar funciones utilizando simulaciones. De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia del equilibrio de Nash. Además, no podemos depender directamente de los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilístico adaptados a nuestra configuración de problema. 4.1 Problema de Diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente. Recuerde que durante el torneo de 2004, los diseñadores del juego de la cadena de suministro optaron por aumentar drásticamente los costos de almacenamiento como medida para frenar las compras del día 0, con poco éxito. Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y la cantidad agregada de componentes adquiridos el día 0 en equilibrio. Esto suele ser el caso en juegos reales de interés, donde descripciones en lenguaje natural o algorítmicas pueden sustituir a una especificación formal de estrategias y funciones de pago. Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo. ¿Primero, ¿el aumento de los costos de almacenamiento realmente reduce la adquisición en el día 0? ¿Fue racional la adquisición excesiva observada durante el día 0 del torneo de 2004? Y en tercer lugar, ¿podría haber reducido de manera suficiente los costos de almacenamiento la adquisición del día 0 a un nivel aceptable, y en tal caso, cuál debería haber sido el ajuste de los costos de almacenamiento? Es esta tercera pregunta la que define el aspecto del diseño de mecanismos de nuestro análisis. Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de los agentes, la función de bienestar de los diseñadores, el espacio de parámetros del mecanismo y la fuente de datos. Restringimos las estrategias de los agentes para que sean un multiplicador de la cantidad de solicitudes del día 0 de uno de los finalistas, Deep Maize, en el torneo TAC/SCM de 2004. Lo restringimos aún más al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias por encima de 1.5 son extremadamente agresivas (por lo tanto, poco probables de proporcionar desviaciones refutadoras más allá de las disponibles en las estrategias incluidas, y ciertamente no forman parte de ningún equilibrio deseable). Todo otro comportamiento se basa en el comportamiento de Deep Maize y es idéntico para todos los agentes. Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico. Sin embargo, creemos que la forma general de los resultados debería ser robusta ante cambios en el comportamiento completo del agente. Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0. Sea φ(a) = Σ6 i=1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego particular de la cadena de suministro (para perfiles de estrategia mixta s, tomamos la esperanza de φ con respecto a la mezcla). La función de bienestar de los diseñadores W (N(θ), θ) se define entonces como I{sup{φ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de adquisición en el día 0 y I es la función indicadora. El diseñador selecciona un valor θ de costos de almacenamiento, expresado como un porcentaje anual del valor base de los componentes en el inventario (cobrado diariamente), del conjunto Θ = R+. Dado que la decisión de los diseñadores depende solo de φ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación. 4.2 Estimación de equilibrios de Nash El objetivo de los agentes de TAC/SCM es maximizar los beneficios obtenidos en una instancia del juego. Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, U(a)). Si también hemos fijado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de jugadores y sus correspondientes pagos, y, en consecuencia, para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios de Nash de cada juego Γθ. Por lo tanto, necesitamos métodos para aproximar equilibrios de Nash en juegos infinitos. A continuación, describimos los dos métodos que utilizamos en nuestro estudio. El primero ha sido explorado empíricamente anteriormente, mientras que el segundo se introduce aquí como el método específicamente diseñado para aproximar un conjunto de equilibrios de Nash. 4.2.1 Aproximación de la Función de Pago El primer método para estimar equilibrios de Nash basado en datos utiliza aprendizaje supervisado para aproximar las funciones de pago de mech6. No abordamos si y cómo otras medidas (por ejemplo, restringir directamente la adquisición) podrían haber logrado los objetivos de diseño. Nuestro enfoque considera como dado un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento. En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con un crecimiento de complejidad correspondiente. 308 participantes del mecanismo de un conjunto de datos de experiencia de juego [17]. Una vez que las funciones de pago aproximadas estén disponibles para todos los jugadores, los equilibrios de Nash pueden encontrarse ya sea de forma analítica o aproximada utilizando técnicas numéricas, dependiendo del modelo de aprendizaje. En lo que sigue, estimamos solo un equilibrio de Nash de muestra utilizando esta técnica, aunque esta restricción puede eliminarse a expensas de un tiempo de cálculo adicional. Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador. Por lo tanto, podemos aplicarlo cuando Ds = ∅. Si hay un simulador disponible, podemos generar datos adicionales para aumentar la confianza en nuestras estimaciones iniciales. Probamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado local (LWA) y regresión lineal ponderada localmente (LWLR). También utilizamos variables de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis empírico previo de teoría de juegos de TAC/SCM-03 [19]. El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido de forma analítica. Para los otros métodos aplicamos dinámica replicadora [7] a una aproximación discreta del juego aprendido. El total esperado de adquisiciones del día 0 en equilibrio se tomó como la estimación de un resultado. 4.2.2 Búsqueda en el Espacio de Perfiles de Estrategia Cuando tenemos acceso a un simulador, también podemos utilizar la búsqueda dirigida a través del espacio de perfiles para estimar el conjunto de equilibrios de Nash, que describimos aquí después de presentar alguna notación adicional. DEFINICIÓN 4. Un vecino estratégico de un perfil de estrategia pura a es un perfil que es idéntico a a en todo menos en una estrategia. Definimos Snb(a, D) como el conjunto de todos los vecinos estratégicos de a disponibles en el conjunto de datos D. De manera similar, definimos Snb(a, ˜D) como todos los vecinos estratégicos de a que no están en D. Finalmente, para cualquier a ∈ Snb(a, D) definimos al agente que se desvía como i(a, a). DEFINICIÓN 5. La -ligadura, ˆ, de un perfil de estrategia pura a se define como maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}. Decimos que a es un candidato a δ-equilibrio para δ ≥ ˆ. Cuando Snb(a, ˜D) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), a se confirma como un equilibrio de Nash ˆ. Nuestro método de búsqueda opera explorando desviaciones de los equilibrios candidatos. Nos referimos a esto como BestFirstSearch, ya que selecciona con probabilidad uno un perfil de estrategia a ∈ Snb(a, ˜D) que tiene el menor ˆin D. Finalmente definimos un estimador para un conjunto de equilibrios de Nash. DEFINICIÓN 6. Para un conjunto K, define Co(K) como la envoltura convexa de K. Sea Bδ el conjunto de candidatos en el nivel δ. Definimos ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) para un δ fijo como un estimador de φ∗ (θ). En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles estratégicos agregados con límite inferior -bound por debajo de un δ fijo. Esta definición nos permite explotar la estructura que surge de la función de agregación. Si dos perfiles son cercanos en términos de valores de agregación, es probable que tengan límites similares. En particular, si uno está en equilibrio, el otro también puede estarlo. Presentamos un respaldo teórico para este método de estimación del conjunto de equilibrios de Nash a continuación. Dado que el juego en el que estamos interesados es infinito, es necesario terminar BestFirstSearch antes de explorar todo el espacio de strat7. Por ejemplo, podemos utilizar técnicas de aprendizaje activo [5] para mejorar la calidad de la aproximación de la función de recompensa. En este trabajo, nos concentramos en la búsqueda en el espacio de perfiles estratégicos. Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos. Generación de datos Nuestros datos fueron recopilados simulando juegos TAC/SCM en una versión local del servidor TAC/SCM de 2004, que tiene una configuración para el costo de almacenamiento. Las estrategias de los agentes en juegos simulados fueron seleccionadas del conjunto {0, 0.3, 0.6, . . . , 1.5} con el fin de tener una probabilidad positiva de generar vecinos estratégicos. Se generó un conjunto de datos base Do mediante el muestreo de 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}. Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varios defectos. Utilizamos la búsqueda para generar un conjunto de datos simulados Ds, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ. Dado que el costo de la simulación es extremadamente alto (un juego tarda casi 1 hora en ejecutarse), pudimos ejecutar un total de 2670 juegos en el transcurso de más de seis meses. Para hacer una comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategias conjuntas finitas restringidas para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces). 4.4 Resultados 4.4.1 Análisis del conjunto de datos base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos base Do. Además, generamos una estimación de la correspondencia del equilibrio de Nash, ˆφ∗ (θ), aplicando la Definición 6 con δ = 2.5E6. Los resultados se muestran en la Figura 1. Como podemos ver, la correspondencia ˆφ∗ (θ) tiene poco poder predictivo basado en Do, y no revela ninguna estructura interesante sobre el juego. Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición Total Día 0 LWA LWLR QR BaselineMin BaselineMax Figura 1: Estimaciones de adquisición del día 0 agregadas basadas en Do. La correspondencia ˆφ∗ (θ) es el intervalo entre BaselineMin y BaselineMax. En general, la búsqueda se detiene una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para obtener conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego. Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash a permanecer en este subconjunto discreto de [0,1.5]. Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron accidentes, problemas de conectividad de red y otras anomalías obvias), el juego sería descartado. Análisis de los datos de búsqueda Para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ∗ (θ) (nuevamente, usando δ =2.5E6) en el conjunto de datos D = {Do, Ds}, donde Ds es datos generados a través de la aplicación de BestFirstSearch. Los resultados de esta estimación se representan gráficamente frente a los resultados de los métodos de aprendizaje entrenados en Do 11 en la Figura 2. Primero, observamos que la adición de los datos de búsqueda reduce considerablemente el rango de posibles equilibrios. Además, las predicciones puntuales reales de los métodos de aprendizaje y aquellas basadas en límites después de la búsqueda son razonablemente cercanas. Combinar la evidencia recopilada de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquiera de los métodos utilizados de forma aislada. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición del Día 0 LWA LWLR QR Búsqueda Mínima Búsqueda Máxima Figura 2: Estimaciones agregadas de adquisición del día 0 basadas en la búsqueda en el espacio de perfiles de estrategia en comparación con técnicas de aproximación de funciones entrenadas en Do. La correspondencia ˆφ∗ (θ) para D = {Do, Ds} es el intervalo entre SearchMin y SearchMax. Esta evidencia respalda la intuición inicial de que la adquisición del día 0 debería disminuir con los costos de almacenamiento. También confirma que los altos niveles de adquisición en el día 0 son una respuesta racional al entorno del torneo de 2004 con un costo promedio de almacenamiento, que corresponde a θ = 100. La predicción mínima para la adquisición agregada en este nivel de costos de almacenamiento, dada por cualquier método experimental, es aproximadamente 3. Esto es bastante alto, ya que corresponde a un compromiso esperado del 1/3 de la capacidad total del proveedor para todo el juego. La predicción máxima es considerablemente mayor a 4.5. En la competencia actual de 2004, la adquisición total del día 0 equivalía a 5.71 en la escala utilizada aquí [9]. Nuestras predicciones subestiman este resultado en cierta medida, pero muestran que cualquier resultado racional probablemente tendría una alta adquisición en el día 0. 4.4.3 Extrapolando la Correspondencia de la Solución Tenemos evidencia razonablemente sólida de que la correspondencia del resultado está disminuyendo. Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento a un valor que reduciría la adquisición del día 0 en equilibrio, o concluir que esto no es posible. Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día 0. No está claro cuán significativos serían los resultados del aprendizaje si se agregaran Ds al conjunto de datos de entrenamiento. De hecho, los datos adicionales pueden aumentar realmente la varianza del aprendizaje. Recuerde que el objetivo de los diseñadores es incentivar la adquisición agregada del día 0 que esté por debajo del umbral α. Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultados estimada a partir de D que produce θ = 320. Los datos para θ = 320 fueron recopilados de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos por 33 iteraciones de BestFirstSearch. La Figura 3 muestra los límites detallados para todos los perfiles en términos de sus valores correspondientes de φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Límites de ε de Adquisición Total Día-0 Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320. Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ(a). La región gris corresponde a ˆφ∗ (320) con δ = 2.5M. El conjunto estimado de resultados agregados del día 0 es muy cercano al de θ = 200, lo que indica que hay poco beneficio adicional al aumentar los costos de almacenamiento por encima de 200. Observa que incluso el límite inferior de nuestro conjunto estimado de equilibrios de Nash está muy por encima de la adquisición objetivo del día 0 de 2. Además, las recompensas para los agentes son casi siempre negativas en θ = 320. Por consiguiente, aumentar los costos aún más sería indeseable incluso si finalmente se pudiera reducir la adquisición en el día 0. Dado que tenemos una confianza razonable de que φ∗ (θ) está disminuyendo en θ, tampoco esperamos que establecer θ en algún lugar entre 200 y 320 logre el resultado deseado. Concluimos que es poco probable que la adquisición del día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento. Que nuestras predicciones tienden a subestimar los resultados del torneo refuerza esta conclusión. Para lograr la reducción deseada en la adquisición del día 0 se requiere rediseñar otros aspectos del mecanismo. 4.5 Análisis Probabilístico Nuestro análisis empírico ha producido evidencia en apoyo a la conclusión de que ninguna configuración razonable del costo de almacenamiento probablemente sería suficiente para frenar la adquisición excesiva del día 0 en TAC/SCM 04. Toda esta evidencia ha sido en forma de simple interpolación y extrapolación de estimaciones de la correspondencia del equilibrio de Nash. Estas estimaciones se basan en simular instancias del juego y están sujetas a ruido de muestreo contribuido por los diversos elementos estocásticos del juego. En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos -bound a tales efectos estocásticos. Supongamos que todos los agentes tienen conjuntos de estrategias puras finitos (y pequeños), A. Por lo tanto, es factible muestrear toda la matriz de pagos del juego. Además, supongamos que el ruido es aditivo con media cero en promedio durante todo el juego, por lo que en la práctica probablemente querríamos que el umbral sea aún más bajo. 310 y varianza finita, es decir, Ui(a) = ui(a) + ˜ξi(a), donde Ui(a) es la ganancia observada para i cuando se jugó a, ui(a) es la ganancia correspondiente real, y ˜ξi(a) es una variable aleatoria normal con media cero. Designamos la varianza conocida de ˜ξi(a) como σ2 i (a). Por lo tanto, asumimos que ˜ξi(a) es normal con distribución N(0, σ2 i (a)). Tomamos ¯ui(a) como la media muestral de todos los Ui(a) en D, y seguimos a Chang y Huang [3] al asumir que tenemos una priori impropia sobre las ganancias reales ui(a) y el muestreo fue independiente para todos i y a. También confiamos en su resultado de que ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] son independientes con distribuciones posteriores N(¯ui(a), σ2 i (a)/ni(a)), donde ni(a) es el número de muestras tomadas de los pagos para i en el perfil puro a, y Zi(a) ∼ N(0, 1). Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio de Nash -Nash. Si ui(·)|¯ui(·) son independientes para todo i ∈ I y a ∈ A, tenemos el siguiente resultado (a partir de este punto omitimos la condición sobre ¯ui(·) por brevedad): PROPOSICIÓN 1. Para todo \\( i \\in I \\), \\( \\max_{b \\in A_i} u_i(b, a_{-i}) - u_i(a) \\leq \\varepsilon \\), donde \\( \\varepsilon = \\int_{Y_i} \\int_{Z} \\int_{R} \\int_{Y} \\int_{b \\in A_i \\backslash a_i} \\Pr(u_i(b, a_{-i}) \\leq u + \\varepsilon) f_{u_i(a)}(u) du \\), donde \\( f_{u_i(a)}(u) \\) es la función de densidad de probabilidad de \\( N(\\overline{u_i(a)}, \\sigma_i(a)) \\). Las pruebas de este y todos los resultados posteriores se encuentran en el Apéndice. La distribución posterior de la media óptima de n muestras, derivada por Chang y Huang [3], es Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) donde a ∈ A y Φ(·) es la función de distribución N(0, 1). Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilístico que (a) ≤ γ para un γ dado. Ahora, consideramos casos de datos incompletos y utilizamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en los datos) en la distribución de sup{φ∗ (θ)} e inf{φ∗ (θ)} (asumiendo que ambos son alcanzables): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, donde x es un número real y ≤D indica que el límite superior solo considera estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} y {inf{φ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf{φ∗ (θ)} ≤ x}. Los valores así derivados comprenden las Tablas 1 y 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Tabla 1: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando N(θ) es un conjunto de equilibrios de Nash. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Tabla 2: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {150, 200, 320} cuando N(θ) es un conjunto de equilibrios de Nash. Las Tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ(a) < 2.7 es poco probable para cualquier θ del cual tengamos datos, aunque este juicio, como mencionamos, se refiere únicamente a los perfiles que hemos muestreado realmente. Podemos entonces aceptar esto como otra pieza de evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, parece poco probable que el diseñador logre su objetivo incluso si pudiera persuadir a los participantes a jugar un equilibrio deseable. La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM de 2004 eran, de hecho, racionales al adquirir grandes cantidades de componentes al comienzo del juego. Si observamos la tercera columna de esta tabla, que corresponde a θ = 100, podemos deducir que ningún perfil a en nuestros datos con φ(a) < 3 es muy probable que se juegue en equilibrio. Los límites anteriores proporcionan algunas pruebas generales, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos muestreado. Particularmente, nos gustaría decir algo sobre lo que sucede en los ajustes de θ para los cuales no tenemos datos. Para derivar un límite probabilístico aproximado sobre la probabilidad de que ningún θ ∈ Θ haya logrado el objetivo del diseñador, sea ∪J j=1Θj una partición de Θ, y asuma que la función sup{φ∗ (θ)} satisface la condición de Lipschitz con constante de Lipschitz Aj en cada subconjunto Θj. Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a Θ = [0, 320]. Ahora definimos cada subconjunto j como el intervalo entre dos puntos para los cuales hemos producido datos. Por lo tanto, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], con j variando entre 1 y 5, correspondiendo a los subintervalos anteriores. Denotaremos cada Θj por (aj, bj]. Luego, la siguiente proposición nos da una cota superior aproximada sobre la probabilidad de que sup{φ∗ (θ)} ≤ α. PROPOSICIÓN 2. Debido a que nuestros límites son aproximados, no podemos utilizarlos como una evaluación probabilística concluyente. En cambio, tomamos esto como otra pieza de evidencia para complementar nuestros hallazgos. Aunque podamos asumir que una función que aproximamos a partir de datos es Lipschitz continua, rara vez conocemos en realidad la constante de Lipschitz para cualquier subconjunto de Θ. Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de los datos. Aquí, probamos tres métodos para hacer esto. El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subintervalo. Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo. Un método alternativo es tomar un límite superior en la pendiente obtenida dentro de cada subintervalo utilizando los datos disponibles. Esto produce un límite superior de probabilidades mucho menos conservador. Sin embargo, dado que el límite superior real suele ser mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso. Un último método que intentamos es un compromiso entre los dos anteriores. En lugar de tomar el límite superior conservador basado en datos sobre todo el dominio de la función Θ, tomamos el promedio de los límites superiores obtenidos en cada Θj. El límite en un intervalo se toma como el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos. Los resultados de evaluar la expresión para Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3. En términos de nuestras afirmaciones en maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Tabla 3: Límite superior aproximado de la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con un objetivo α = 2. Se utilizan diferentes métodos para aproximar el límite superior de la pendiente en cada subintervalo j. En este trabajo, la expresión proporciona un límite superior a la probabilidad de que alguna configuración de θ (es decir, costo de almacenamiento) en el intervalo [0,320] resulte en una adquisición total del día 0 que no sea mayor en ningún equilibrio que el objetivo especificado por α y tomado aquí como 2. Como sospechábamos, el enfoque más conservador para estimar el límite superior de la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí. Sin embargo, los otros dos enfoques de estimación, encontrados en las columnas dos y tres de la Tabla 3, sugieren que de hecho estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría funcionado. Dada la tremenda dificultad del problema, este resultado es muy sólido. Aun así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia. Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y los conjuntos de estrategias). Tampoco podemos esperar obtener nunca suficiente evidencia para llegar a conclusiones completamente objetivas. En cambio, el enfoque que defendemos aquí es recopilar la mayor cantidad de evidencia posible dadas las limitaciones de recursos, y tomar la decisión más convincente basada en esta evidencia, si es posible. RESULTADOS DE CONVERGENCIA En este punto, exploramos abstractamente si una elección de parámetro de diseño basada en datos de pago puede ser asintóticamente confiable. Dado que no teníamos todas las desviaciones posibles para cualquier perfil disponible en los datos, los verdaderos límites superiores pueden ser aún más bajos. Por conveniencia, utilizaremos la notación un,i(a) para referirnos a una función de pago del jugador i basada en un promedio sobre n muestras i.i.d. de la distribución de pagos. También asumimos que un,i(a) son independientes para todo a ∈ A e i ∈ I. Utilizaremos la notación Γn para referirnos al juego [I, R, {ui,n(·)}], mientras que Γ denotará el juego subyacente, [I, R, {ui(·)}]. De manera similar, definimos n(r) como (r) con respecto al juego Γn. En esta sección, demostramos que n(s) → (s) casi seguramente de forma uniforme en el espacio de estrategias mixtas para cualquier juego finito, y, además, que todas las equilibrios de Nash en estrategias mixtas en juegos empíricos eventualmente se acercan arbitrariamente a algunas estrategias de equilibrio de Nash en el juego subyacente. Utilizamos estos resultados para demostrar que bajo ciertas condiciones, la elección óptima del parámetro de diseño basada en datos empíricos converge casi seguramente al óptimo real. TEOREMA 3. Supongamos que |I| < ∞, |A| < ∞. Entonces n(s) → (s) casi seguramente uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios de Nash de Γ. Si definimos Nn,γ = {s ∈ S : n(s) ≤ γ}, tenemos el siguiente corolario del Teorema 3: COROLARIO 4. Para todo γ > 0, existe un M tal que para todo n ≥ M, N ⊂ Nn,γ casi seguramente. PRUEBA. Dado que n(s) = 0 para todo s ∈ N, podemos encontrar un M lo suficientemente grande tal que Pr{supn≥M sups∈N n(s) < γ} = 1. Según el Corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier > 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios de Nash empíricos si se han tomado suficientes muestras. Como mostramos ahora, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un límite no nulo como una estimación del conjunto de equilibrios de Nash. Primero, supongamos que concluimos que para una configuración particular de θ, sup{ˆφ∗ (θ)} ≤ α. Entonces, dado que para cualquier fijo > 0, N(θ) ⊂ Nn, (θ) cuando n es suficientemente grande, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α para cualquier n de este tipo. Así, dado que definimos la función de bienestar del diseñador como I{sup{φ∗ (θ)} ≤ α} en nuestro dominio de interés, la elección empírica de θ satisface el objetivo del diseñador, maximizando así su función de bienestar. Alternativamente, supongamos que concluimos que inf{ˆφ∗ (θ)} > α para cada θ en el dominio. Entonces, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, para todo θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo del diseñador. Ahora, demostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de Γn está cerca de algún equilibrio de Nash del juego subyacente. Este resultado nos llevará a considerar la convergencia de los optimizadores basados en datos empíricos a los ajustes óptimos reales de los parámetros del mecanismo. Primero notamos que la función (s) es continua en un juego finito. LEMMA 5. \n\nLEMMA 5. Sea S un conjunto de estrategias mixtas definido en un juego finito. Entonces: S → R es continua. Para la exposición que sigue, necesitamos un poco de notación adicional. Primero, sea (Z, d) un espacio métrico, y X, Y ⊂ Z y definamos la distancia de Hausdorff dirigida de X a Y como h(X, Y) = sup x∈X inf y∈Y d(x, y). Observa que U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ). Además, define BS(x, δ) como una bola abierta en S ⊂ Z con centro en x ∈ S y radio δ. Ahora, dejemos que Nn denote todos los equilibrios de Nash del juego Γn y sea Nδ = [ x∈N BS(x, δ), es decir, la unión de bolas abiertas de radio δ con centros en los equilibrios de Nash de Γ. Ten en cuenta que h(Nδ, N) = δ. Podemos entonces demostrar el siguiente resultado general. TEOREMA 6. Supongamos que |I| < ∞ y |A| < ∞. Entonces casi con seguridad h(Nn, N) converge a 0. Ahora demostraremos que en el caso especial cuando Θ y A son finitos y cada Γθ tiene un equilibrio de Nash único, las estimaciones ˆθ del parámetro óptimo del diseñador convergen a un optimizador real casi seguramente. Sea ˆθ = arg maxθ∈Θ W (Nn(θ), θ), donde n es el número de veces que se muestreó cada perfil puro en Γθ para cada θ, y sea θ∗ = arg maxθ∈Θ W (N(θ), θ). TEOREMA 7. Supongamos que |N(θ)| = 1 para todo θ ∈ Θ y supongamos que Θ y A son finitos. Sea W (s, θ) continua en el único s∗ (θ) ∈ N(θ) para cada θ ∈ Θ. Entonces ˆθ es un estimador consistente de θ∗ si W (N(θ), θ) se define como un supremo, ínfimo o esperanza sobre el conjunto de equilibrios de Nash. De hecho, ˆθ → θ∗ casi seguramente en cada uno de estos casos. La limitación del resultado anterior es que, dentro de nuestro marco de trabajo, el diseñador no tiene forma de saber o asegurar que Γθ tenga equilibrios únicos. Sin embargo, sí proporciona cierta justificación teórica para seguir el diseño de esta manera, y quizás servirá como guía para obtener resultados más generales en el futuro. 6. TRABAJO RELACIONADO La literatura de diseño de mecanismos en Economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10]. Además, existe una extensa literatura sobre el diseño óptimo de subastas [10], del cual el trabajo de Roger Myerson [11] es, quizás, el más relevante. En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y teniendo en cuenta restricciones como la compatibilidad de incentivos y la racionalidad individual. Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de Ciencias de la Computación. Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros relevantes del juego son conocimiento común. Cuando las funciones de pago de los jugadores son desconocidas, se ha explorado la realización de búsquedas mediante simulaciones como alternativa. Un enfoque en esa dirección, tomado en [4] y [15], es coevolucionar el parámetro del mecanismo y las estrategias de los agentes, utilizando alguna noción de utilidad social y pagos de los agentes como criterios de aptitud. Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética. En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron un resultado de un juego inducido por un parámetro del mecanismo como el resultado del aprendizaje conjunto de los agentes. Más recientemente, Phelps et al. [14] compararon dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en juegos definidos por estrategias heurísticas, como en [18]. 7. CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el diseño empírico de mecanismos. Definimos un modelo formal de teoría de juegos de interacción entre el diseñador y los participantes del mecanismo como un <br>juego de dos etapas</br>. También describimos en cierta generalidad los métodos para estimar una función de equilibrio de Nash de muestra cuando los datos son extremadamente escasos, o una correspondencia de equilibrio de Nash cuando hay más datos disponibles. Nuestras técnicas están diseñadas específicamente para abordar problemas en los que tanto el espacio de parámetros del mecanismo como los conjuntos de estrategias de los agentes son infinitos y solo se puede adquirir un conjunto de datos relativamente pequeño. Un problema de diseño difícil en el juego TAC/SCM que la comunidad de TAC ha estado ansiosa por abordar nos brinda un escenario para probar nuestros métodos. Al aplicar el análisis empírico del juego al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos. Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia del equilibrio de Nash. Al final, podemos intentar proporcionar suficiente evidencia para prescribir una configuración de parámetros, o sugerir que no es posible encontrar una configuración que satisfaga al diseñador. En el caso de TAC/SCM, nuestra evidencia sugiere bastante claramente que el costo de almacenamiento no pudo haber sido ajustado de manera efectiva en el torneo de 2004 para frenar la adquisición excesiva del día 0 sin efectos perjudiciales en la rentabilidad general. El éxito de nuestro análisis en este entorno extremadamente complejo con altos costos de simulación nos hace ser optimistas de que nuestros métodos pueden brindar orientación en la toma de decisiones de diseño de mecanismos en otros dominios desafiantes. Los resultados teóricos confirman algunas intuiciones detrás de los métodos de diseño de mecanismos empíricos que hemos introducido, y aumentan nuestra confianza en que nuestro marco puede ser efectivo para estimar la mejor elección de parámetros del mecanismo en entornos relativamente generales. Agradecimientos Agradecemos a Terence Kelly, Matthew Rudary y Satinder Singh por sus útiles comentarios sobre versiones anteriores de este trabajo. Este trabajo fue apoyado en parte por la subvención de la NSF IIS-0205435 y el programa de razonamiento estratégico DARPA REAL. 8. REFERENCIAS [1] R. Arunachalam y N. M. Sadeh. La competencia de agentes de comercio de la cadena de suministro. Investigación y aplicaciones del comercio electrónico, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy y M. Tschantz. Un enfoque de programación estocástica para la planificación en TAC SCM. En la Quinta Conferencia ACM sobre Comercio Electrónico, páginas 152-159, Nueva York, 2004. [3] Y.-P. Chang y W.-T. Huang. Intervalos de confianza generalizados para el valor más grande de algunas funciones de parámetros bajo normalidad. Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.\nEstadística Sinica, 10:1369-1383, 2000. [4] D. Cliff. Evolución del mecanismo de mercado a través de un espacio continuo de tipos de subasta. En el Congreso de Computación Evolutiva de 2002. [5] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [6] V. Conitzer y T. Sandholm. Un algoritmo para diseñar automáticamente mecanismos determinísticos sin pagos. En la Tercera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagente, páginas 128-135, 2004. [7] D. Friedman. Juegos evolutivos en economía. Econometrica, 59(3):637-666, mayo de 1991. [8] R. Keener. Teoría Estadística: Una Mezcla de Temas Fundamentales. Departamento de Estadística de la Universidad de Michigan, 2004. [9] C. Kiekintveld, Y. Vorobeychik y M. P. Wellman. Un análisis de la competencia de agentes comerciales de gestión de la cadena de suministro de 2004. En el taller IJCAI-05 sobre Diseño y Análisis de Agentes de Negociación, Edimburgo, 2005. [10] A. Mas-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [11] R. B. Myerson.\nEditorial de la Universidad de Oxford, 1995. [11] R. B. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6(1):58-73, febrero de 1981. [12] S. Olafsson y J. Kim. Optimización de simulación. En E. Yucesan, C.-H. Chen, J. Snowdon y J. Charnes, editores, Conferencia de Simulación de Invierno 2002, 2002. [13] D. Pardoe y P. Stone. TacTex-03: Un agente de gestión de la cadena de suministro. SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, y P. McBurney. Agentes automatizados versus humanos virtuales: una comparación teórica evolutiva de dos diseños de mercado de subasta doble. En Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney y E. Sklar. Co-evolución de mecanismos de subasta y estrategias de negociación: hacia un enfoque novedoso para el diseño microeconómico. En el taller ECOMAS 2002, 2002. [16] S. Phelps, S. Parsons, E. Sklar y P. McBurney. Utilizando programación genética para optimizar reglas de precios para un mercado de subasta doble. En Taller sobre Agentes para el Comercio Electrónico, 2003. [17] Y. Vorobeychik, M. P. Wellman y S. Singh. Aprendiendo funciones de pago en juegos infinitos. En la Decimonovena Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro y J. O. Kephart. Analizando interacciones estratégicas complejas en sistemas multiagente. En el taller AAAI-02 sobre agentes teóricos de juegos y de toma de decisiones, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld y V. Soni. Interacciones estratégicas en un juego de cadena de suministro. Inteligencia Computacional, 21(1):1-26, febrero de 2005. APÉNDICE A. PRUEBAS A.1 Prueba de la Proposición 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du. A.2 Prueba de la Proposición 2 Primero, supongamos que alguna función, f(x), definida en [ai, bi], satisface la condición de Lipschitz en (ai, bi] con una constante de Lipschitz Ai. Entonces se cumple la siguiente afirmación: Afirmación: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai). Para demostrar esta afirmación, observe que la intersección de las líneas en f(ai) y f(bi) con pendientes -Ai y Ai respectivamente determinará el límite inferior del mínimo de f(x) en [ai, bi] (que es un límite inferior del ínfimo de f(x) en (ai, bj]). La línea en f(ai) está determinada por f(ai) = −Aiai + cL y la línea en f(bi) está determinada por f(bi) = Aibi + cR. Por lo tanto, las intercepciones son cL = f(ai) + Aiai y cR = f(bi) + Aibi respectivamente. Sea x∗ el punto en el que estas líneas se cruzan. Entonces, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A. Al sustituir las expresiones de cR y cL, obtenemos el resultado deseado. Ahora, la subaditividad nos da Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, y, por la afirmación, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}. Dado que tenemos un número finito de puntos en el conjunto de datos para cada θ, podemos obtener la siguiente expresión: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}. Ahora podemos restringir nuestra atención en obtener una cota superior en Pr{sup{φ∗ (θ)} = y} para un θ fijo. Para hacer esto, observe que Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} por subaditividad y el hecho de que un perfil a es un equilibrio de Nash si y solo si (a) = 0. Poner todo junto produce el resultado deseado. Prueba de Teorema 3 En primer lugar, necesitaremos el siguiente hecho: Afirmación: Dada una función fi(x) y un conjunto X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|. Para demostrar esta afirmación, observe que | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) si maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) si maxx f2(x) ≥ maxx f1(x) En el primer caso, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 De manera similar, en el segundo caso, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|. Por lo tanto, la afirmación se mantiene. Por la Ley Fuerte de los Grandes Números, un,i(a) → ui(a) casi seguramente para todo i ∈ I, a ∈ A. Es decir, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, o, equivalentemente [8], para cualquier α > 0 y δ > 0, existe M(i, a) > 0 tal que Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Al tomar M = maxi∈I maxa∈A M(i, a), tenemos que Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Así, por la afirmación, para cualquier n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ con una probabilidad de al menos 1 − α. Ten en cuenta que dado que s−i(a) y s(a) están acotados entre 0 y 1, pudimos eliminarlos de las expresiones anteriores para obtener una cota que será válida independientemente de la elección particular de s. Además, dado que el resultado anterior se puede obtener para un α arbitrario > 0 y δ > 0, tenemos que Pr{limn→∞ n(s) = (s)} = 1 uniformemente en S. A.4 Prueba del Lema 5 Demostramos el resultado utilizando la continuidad uniforme de ui(s) y la preservación de la continuidad bajo el máximo. Afirmación: Una función f : Rk → R definida por f(t) = Σi=1k zi ti, donde zi son constantes en R, es uniformemente continua en t. La afirmación se sigue porque |f(t)−f(t )| = | Σi=1k zi(ti−ti)| ≤ Σi=1k |zi||ti − ti|. Un resultado inmediato de esto para nuestros propósitos es que ui(s) es uniformemente continua en s y ui(ai, s−i) es uniformemente continua en s−i. Afirmación: Sea f(a, b) uniformemente continua en b ∈ B para cada a ∈ A, con |A| < ∞. Entonces V (b) = maxa∈A f(a, b) es uniformemente continua en b. Para demostrar esto, toma γ > 0 y deja que b, b ∈ B tal que b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ. Ahora toma δ = mina∈A δ(a). Entonces, cada vez que b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ. Ahora, recuerda que (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)]. Según las afirmaciones anteriores, maxai∈Ai ui(ai, s−i) es uniformemente continua en s−i y ui(s) es uniformemente continua en s. Dado que la diferencia de dos funciones uniformemente continuas es uniformemente continua, y dado que esta continuidad se conserva bajo el máximo según nuestra segunda afirmación, obtenemos el resultado deseado. Prueba de Teorema 6. Elija δ > 0. Primero, necesitamos asegurarnos de que se cumple la siguiente afirmación: Afirmación: ¯ = mins∈S\\Nδ (s) existe y ¯ > 0. Dado que Nδ es un subconjunto abierto de S compacto, se sigue que S \\ Nδ es compacto. Como también habíamos demostrado en el Lema 5 que (s) es continua, la existencia se sigue del teorema de Weierstrass. Es claro que ¯ > 0 ya que (s) = 0 si y solo si s es un equilibrio de Nash de Γ. Ahora, por el Teorema 3, para cualquier α > 0 existe un M tal que Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. En consecuencia, para cualquier δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Dado que esto se cumple para un α arbitrario > 0 y δ > 0, se obtiene el resultado deseado. Prueba de Teorema 7. Fija θ y elige δ > 0. Dado que W (s, θ) es continua en s∗ (θ), dado > 0 existe δ > 0 tal que para cada s que esté dentro de δ de s∗ (θ), |W (s, θ) - W (s∗ (θ), θ)| < . Según el Teorema 6, podemos encontrar M(θ) lo suficientemente grande para que todos los s ∈ Nn estén dentro de δ de s∗ (θ) para todo n ≥ M(θ) con probabilidad 1. Por consiguiente, para cualquier > 0 podemos encontrar M(θ) lo suficientemente grande tal que con probabilidad 1 tengamos supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < . Asumamos sin pérdida de generalidad que hay una elección óptima única de θ. Ahora, dado que el conjunto Θ es finito, también existe la segunda mejor opción de θ (si solo hay un θ ∈ Θ, esta discusión no tiene sentido de todos modos): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ). Supongamos sin pérdida de generalidad que θ∗∗ también es único y sea ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ). Entonces, si dejamos < ∆/2 y dejamos que M = maxθ∈Θ M(θ), donde cada M(θ) es lo suficientemente grande como para que supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., la elección óptima de θ basada en cualquier equilibrio empírico será θ∗ con probabilidad 1. Por lo tanto, en particular, dado cualquier distribución de probabilidad sobre equilibrios empíricos, la mejor elección de θ será θ∗ con probabilidad 1 (similarmente, si tomamos el supremo o el ínfimo de W (Nn(θ), θ) sobre el conjunto de equilibrios empíricos al construir la función objetivo). ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "player": {
            "translated_key": "jugador",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to <br>player</br> i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to <br>player</br> i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of <br>player</br> i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than <br>player</br> i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability <br>player</br> i plays ai under s. Next, we define the payoff (utility) function of each <br>player</br> i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any <br>player</br> can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of <br>player</br> i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [
                "Ri is the set of strategies available to <br>player</br> i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to <br>player</br> i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of <br>player</br> i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than <br>player</br> i.",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability <br>player</br> i plays ai under s. Next, we define the payoff (utility) function of each <br>player</br> i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i."
            ],
            "translated_annotated_samples": [
                "Ri es el conjunto de estrategias disponibles para el <br>jugador</br> i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los <br>jugador</br>es.",
                "Designamos el conjunto de estrategias puras disponibles para el <br>jugador</br> i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los <br>jugador</br>es por A = A1 ×. . .×Am.",
                "A menudo es conveniente referirse a la estrategia del <br>jugador</br> i por separado de la de los demás <br>jugador</br>es.",
                "Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los <br>jugador</br>es que no sean el <br>jugador</br> i.",
                "Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el <br>jugador</br> i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada <br>jugador</br> i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i."
            ],
            "translated_text": "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismos empíricos. En la continuación, desarrollamos algunos métodos generales para el diseño empírico de mecanismos y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto. En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2. Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores. Ri es el conjunto de estrategias disponibles para el <br>jugador</br> i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los <br>jugador</br>es. Designamos el conjunto de estrategias puras disponibles para el <br>jugador</br> i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los <br>jugador</br>es por A = A1 ×. . .×Am. A menudo es conveniente referirse a la estrategia del <br>jugador</br> i por separado de la de los demás <br>jugador</br>es. Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los <br>jugador</br>es que no sean el <br>jugador</br> i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama un perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i). Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el <br>jugador</br> i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada <br>jugador</br> i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "participant": {
            "translated_key": "participantes",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the <br>participant</br> agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [
                "All the <br>participant</br> agents observe the mechanism parameter θ and move simultaneously thereafter."
            ],
            "translated_annotated_samples": [
                "Todos los agentes <br>participantes</br> observan el parámetro θ del mecanismo y se mueven simultáneamente después."
            ],
            "translated_text": "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismos empíricos. En la continuación, desarrollamos algunos métodos generales para el diseño empírico de mecanismos y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto. En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2. Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores. Ri es el conjunto de estrategias disponibles para el jugador i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×. . .×Am. A menudo es conveniente referirse a la estrategia del jugador i por separado de la de los demás jugadores. Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama un perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i). Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el jugador i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada jugador i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i. Podemos extender esta definición a estrategias mixtas asumiendo que ui son utilidades de von Neumann-Morgenstern (vNM) de la siguiente manera: ui(s) = Es[ui], donde Es es la expectativa tomada con respecto a la distribución de probabilidad del juego inducida por la estrategia mixta de los jugadores s. Al emplear la forma normal, modelamos a los agentes jugando una única acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones más detalladas sobre la acción a lo largo del tiempo en la forma extensiva. Aunque cualquier juego extenso puede ser reformulado en forma normal, hacerlo puede sacrificar la concisión y difuminar distinciones relevantes (por ejemplo, la perfección en subjuegos). Ocasionalmente, escribimos ui(x, y) para indicar que x ∈ Ai o Si y y ∈ A−i o S−i dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u(·) = {u1(·), . . . , um(·)}. Definimos una función, : R → R, interpretada como el beneficio máximo que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) donde r pertenece a algún conjunto de estrategias, R, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada aquellas jugadas por los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un equilibrio de Nash. DEFINICIÓN 1. Un perfil estratégico r = (r1, . . . , rm) constituye un equilibrio de Nash del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). Cuando r ∈ A, lo anterior define un equilibrio de Nash de estrategia pura; de lo contrario, la definición describe un equilibrio de Nash de estrategia mixta. A menudo recurrimos al concepto de un equilibrio aproximado, o equilibrio de Nash, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita. Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un equilibrio de Nash si (r) ≤ . En este estudio dedicamos especial atención a los juegos que presentan simetría en cuanto a los pagos, lo que hace que los agentes sean estratégicamente idénticos. DEFINICIÓN 2. Un juego [I, {Ri}, {ui(r)}] es simétrico si para todo i, j ∈ I, (a) Ri = Rj y (b) ui(ri, r−i) = uj (rj, r−j) siempre que ri = rj y r−i = r−j. EL MODELO Modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un juego de dos etapas. El diseñador comienza seleccionando primero un valor, θ, de un conjunto de configuraciones de mecanismos permitidas, Θ. Todos los agentes <br>participantes</br> observan el parámetro θ del mecanismo y se mueven simultáneamente después. Por ejemplo, el diseñador podría estar decidiendo entre mecanismos de subasta de sobre cerrado de precio único y de precio único, con la presunción de que una vez tomada la decisión, los postores participarán con pleno conocimiento de las reglas de la subasta. Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como Γθ = [I, {Ri}, {ui(r, θ)}]. Nos referimos a Γθ como un juego inducido por θ. Sea N(θ) el conjunto de perfiles estratégicos considerados soluciones del juego Γθ.3. Supongamos que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, W(r, θ), dependiente del parámetro del mecanismo y del juego resultante, r. Definimos una medida pesimista, W( ˆR, θ) = inf{W(r, θ) : r ∈ ˆR}, que representa el bienestar en el peor de los casos del juego inducido por θ, asumiendo que los agentes juegan alguna estrategia conjunta en ˆR. Normalmente nos preocupamos por W (N(θ), θ), el resultado en el peor de los casos de jugar alguna solución. En algunos problemas podemos obtener una considerable ventaja al utilizar una función de agregación para mapear el resultado del bienestar de un juego. Generalmente adoptamos el equilibrio de Nash como concepto de solución, y por lo tanto tomamos N(θ) como el conjunto de equilibrios. Sin embargo, gran parte de la metodología desarrollada aquí podría ser utilizada con criterios alternativos para derivar el comportamiento del agente a partir de una definición del juego. Nuevamente, existen alternativas disponibles. Por ejemplo, si se tiene una distribución de probabilidad sobre el conjunto de soluciones N(θ), sería natural tomar la expectativa de W(r, θ) en su lugar. 307 especificado en términos de estrategias de agentes a un resultado de bienestar equivalente especificado en términos de un resumen de menor dimensión. DEFINICIÓN 3. Una función φ: R1 × · · · × Rm → Rq es una función de agregación si m ≥ q y W(r, θ) = V(φ(r), θ) para alguna función V. Sobrecargamos el símbolo de función para aplicar a conjuntos de perfiles estratégicos: φ( ˆR) = {φ(r) : r ∈ ˆR}. Para mayor comodidad en la exposición, escribimos φ∗ (θ) para denotar φ(N(θ)). El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia. Por ejemplo, supongamos, como en nuestra aplicación a continuación, que la estrategia de un agente está definida por un parámetro numérico. Si todo lo que nos importa es el valor total jugado, podemos tomar φ(a) = Πm i=1 ai. Si hemos elegido nuestro agregador cuidadosamente, también podemos capturar estructuras que de otra manera no serían evidentes. Por ejemplo, φ∗ (θ) podría estar disminuyendo en θ, mientras que N(θ) podría tener una estructura más compleja. Dada una descripción de la correspondencia de solución N(θ) (equivalentemente, φ∗(θ)), el diseñador se enfrenta a un problema estándar de optimización. Alternativamente, dado un simulador que pudiera producir una muestra imparcial de la distribución de W (N(θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12]. Sin embargo, incluso para un juego Γθ con pagos conocidos, puede resultar computacionalmente intratable resolver los equilibrios de Nash, especialmente si el juego tiene conjuntos de estrategias grandes o infinitos. Además, deseamos estudiar juegos en los que los pagos no se dan explícitamente, sino que deben determinarse a partir de simulaciones u otra experiencia con el juego. Por lo tanto, asumimos que se nos proporciona un conjunto de datos (posiblemente ruidoso) de realizaciones de pagos: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, donde para cada punto de datos θi es el ajuste observado del parámetro del mecanismo, ai es el perfil de estrategia pura observado de los participantes, y Ui es la realización correspondiente de los pagos de los agentes. También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}. Sea D = {Do, Ds} el conjunto de datos combinado. (Ya sea que Do o Ds puedan ser nulos para un problema particular). En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos empíricos de teoría de juegos, para responder preguntas sobre el diseño del escenario TAC/SCM. 4. ANÁLISIS DE DISEÑO EMPÍRICO Dado que nuestros datos se presentan en forma de experiencia de pago y no como el valor de una función objetivo para configuraciones dadas de la variable de control, ya no podemos confiar en los métodos para optimizar funciones utilizando simulaciones. De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia del equilibrio de Nash. Además, no podemos depender directamente de los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilístico adaptados a nuestra configuración de problema. 4.1 Problema de Diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente. Recuerde que durante el torneo de 2004, los diseñadores del juego de la cadena de suministro optaron por aumentar drásticamente los costos de almacenamiento como medida para frenar las compras del día 0, con poco éxito. Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y la cantidad agregada de componentes adquiridos el día 0 en equilibrio. Esto suele ser el caso en juegos reales de interés, donde descripciones en lenguaje natural o algorítmicas pueden sustituir a una especificación formal de estrategias y funciones de pago. Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo. ¿Primero, ¿el aumento de los costos de almacenamiento realmente reduce la adquisición en el día 0? ¿Fue racional la adquisición excesiva observada durante el día 0 del torneo de 2004? Y en tercer lugar, ¿podría haber reducido de manera suficiente los costos de almacenamiento la adquisición del día 0 a un nivel aceptable, y en tal caso, cuál debería haber sido el ajuste de los costos de almacenamiento? Es esta tercera pregunta la que define el aspecto del diseño de mecanismos de nuestro análisis. Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de los agentes, la función de bienestar de los diseñadores, el espacio de parámetros del mecanismo y la fuente de datos. Restringimos las estrategias de los agentes para que sean un multiplicador de la cantidad de solicitudes del día 0 de uno de los finalistas, Deep Maize, en el torneo TAC/SCM de 2004. Lo restringimos aún más al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias por encima de 1.5 son extremadamente agresivas (por lo tanto, poco probables de proporcionar desviaciones refutadoras más allá de las disponibles en las estrategias incluidas, y ciertamente no forman parte de ningún equilibrio deseable). Todo otro comportamiento se basa en el comportamiento de Deep Maize y es idéntico para todos los agentes. Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico. Sin embargo, creemos que la forma general de los resultados debería ser robusta ante cambios en el comportamiento completo del agente. Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0. Sea φ(a) = Σ6 i=1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego particular de la cadena de suministro (para perfiles de estrategia mixta s, tomamos la esperanza de φ con respecto a la mezcla). La función de bienestar de los diseñadores W (N(θ), θ) se define entonces como I{sup{φ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de adquisición en el día 0 y I es la función indicadora. El diseñador selecciona un valor θ de costos de almacenamiento, expresado como un porcentaje anual del valor base de los componentes en el inventario (cobrado diariamente), del conjunto Θ = R+. Dado que la decisión de los diseñadores depende solo de φ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación. 4.2 Estimación de equilibrios de Nash El objetivo de los agentes de TAC/SCM es maximizar los beneficios obtenidos en una instancia del juego. Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, U(a)). Si también hemos fijado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de jugadores y sus correspondientes pagos, y, en consecuencia, para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios de Nash de cada juego Γθ. Por lo tanto, necesitamos métodos para aproximar equilibrios de Nash en juegos infinitos. A continuación, describimos los dos métodos que utilizamos en nuestro estudio. El primero ha sido explorado empíricamente anteriormente, mientras que el segundo se introduce aquí como el método específicamente diseñado para aproximar un conjunto de equilibrios de Nash. 4.2.1 Aproximación de la Función de Pago El primer método para estimar equilibrios de Nash basado en datos utiliza aprendizaje supervisado para aproximar las funciones de pago de mech6. No abordamos si y cómo otras medidas (por ejemplo, restringir directamente la adquisición) podrían haber logrado los objetivos de diseño. Nuestro enfoque considera como dado un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento. En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con un crecimiento de complejidad correspondiente. 308 participantes del mecanismo de un conjunto de datos de experiencia de juego [17]. Una vez que las funciones de pago aproximadas estén disponibles para todos los jugadores, los equilibrios de Nash pueden encontrarse ya sea de forma analítica o aproximada utilizando técnicas numéricas, dependiendo del modelo de aprendizaje. En lo que sigue, estimamos solo un equilibrio de Nash de muestra utilizando esta técnica, aunque esta restricción puede eliminarse a expensas de un tiempo de cálculo adicional. Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador. Por lo tanto, podemos aplicarlo cuando Ds = ∅. Si hay un simulador disponible, podemos generar datos adicionales para aumentar la confianza en nuestras estimaciones iniciales. Probamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado local (LWA) y regresión lineal ponderada localmente (LWLR). También utilizamos variables de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis empírico previo de teoría de juegos de TAC/SCM-03 [19]. El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido de forma analítica. Para los otros métodos aplicamos dinámica replicadora [7] a una aproximación discreta del juego aprendido. El total esperado de adquisiciones del día 0 en equilibrio se tomó como la estimación de un resultado. 4.2.2 Búsqueda en el Espacio de Perfiles de Estrategia Cuando tenemos acceso a un simulador, también podemos utilizar la búsqueda dirigida a través del espacio de perfiles para estimar el conjunto de equilibrios de Nash, que describimos aquí después de presentar alguna notación adicional. DEFINICIÓN 4. Un vecino estratégico de un perfil de estrategia pura a es un perfil que es idéntico a a en todo menos en una estrategia. Definimos Snb(a, D) como el conjunto de todos los vecinos estratégicos de a disponibles en el conjunto de datos D. De manera similar, definimos Snb(a, ˜D) como todos los vecinos estratégicos de a que no están en D. Finalmente, para cualquier a ∈ Snb(a, D) definimos al agente que se desvía como i(a, a). DEFINICIÓN 5. La -ligadura, ˆ, de un perfil de estrategia pura a se define como maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}. Decimos que a es un candidato a δ-equilibrio para δ ≥ ˆ. Cuando Snb(a, ˜D) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), a se confirma como un equilibrio de Nash ˆ. Nuestro método de búsqueda opera explorando desviaciones de los equilibrios candidatos. Nos referimos a esto como BestFirstSearch, ya que selecciona con probabilidad uno un perfil de estrategia a ∈ Snb(a, ˜D) que tiene el menor ˆin D. Finalmente definimos un estimador para un conjunto de equilibrios de Nash. DEFINICIÓN 6. Para un conjunto K, define Co(K) como la envoltura convexa de K. Sea Bδ el conjunto de candidatos en el nivel δ. Definimos ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) para un δ fijo como un estimador de φ∗ (θ). En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles estratégicos agregados con límite inferior -bound por debajo de un δ fijo. Esta definición nos permite explotar la estructura que surge de la función de agregación. Si dos perfiles son cercanos en términos de valores de agregación, es probable que tengan límites similares. En particular, si uno está en equilibrio, el otro también puede estarlo. Presentamos un respaldo teórico para este método de estimación del conjunto de equilibrios de Nash a continuación. Dado que el juego en el que estamos interesados es infinito, es necesario terminar BestFirstSearch antes de explorar todo el espacio de strat7. Por ejemplo, podemos utilizar técnicas de aprendizaje activo [5] para mejorar la calidad de la aproximación de la función de recompensa. En este trabajo, nos concentramos en la búsqueda en el espacio de perfiles estratégicos. Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos. Generación de datos Nuestros datos fueron recopilados simulando juegos TAC/SCM en una versión local del servidor TAC/SCM de 2004, que tiene una configuración para el costo de almacenamiento. Las estrategias de los agentes en juegos simulados fueron seleccionadas del conjunto {0, 0.3, 0.6, . . . , 1.5} con el fin de tener una probabilidad positiva de generar vecinos estratégicos. Se generó un conjunto de datos base Do mediante el muestreo de 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}. Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varios defectos. Utilizamos la búsqueda para generar un conjunto de datos simulados Ds, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ. Dado que el costo de la simulación es extremadamente alto (un juego tarda casi 1 hora en ejecutarse), pudimos ejecutar un total de 2670 juegos en el transcurso de más de seis meses. Para hacer una comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategias conjuntas finitas restringidas para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces). 4.4 Resultados 4.4.1 Análisis del conjunto de datos base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos base Do. Además, generamos una estimación de la correspondencia del equilibrio de Nash, ˆφ∗ (θ), aplicando la Definición 6 con δ = 2.5E6. Los resultados se muestran en la Figura 1. Como podemos ver, la correspondencia ˆφ∗ (θ) tiene poco poder predictivo basado en Do, y no revela ninguna estructura interesante sobre el juego. Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición Total Día 0 LWA LWLR QR BaselineMin BaselineMax Figura 1: Estimaciones de adquisición del día 0 agregadas basadas en Do. La correspondencia ˆφ∗ (θ) es el intervalo entre BaselineMin y BaselineMax. En general, la búsqueda se detiene una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para obtener conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego. Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash a permanecer en este subconjunto discreto de [0,1.5]. Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron accidentes, problemas de conectividad de red y otras anomalías obvias), el juego sería descartado. Análisis de los datos de búsqueda Para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ∗ (θ) (nuevamente, usando δ =2.5E6) en el conjunto de datos D = {Do, Ds}, donde Ds es datos generados a través de la aplicación de BestFirstSearch. Los resultados de esta estimación se representan gráficamente frente a los resultados de los métodos de aprendizaje entrenados en Do 11 en la Figura 2. Primero, observamos que la adición de los datos de búsqueda reduce considerablemente el rango de posibles equilibrios. Además, las predicciones puntuales reales de los métodos de aprendizaje y aquellas basadas en límites después de la búsqueda son razonablemente cercanas. Combinar la evidencia recopilada de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquiera de los métodos utilizados de forma aislada. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición del Día 0 LWA LWLR QR Búsqueda Mínima Búsqueda Máxima Figura 2: Estimaciones agregadas de adquisición del día 0 basadas en la búsqueda en el espacio de perfiles de estrategia en comparación con técnicas de aproximación de funciones entrenadas en Do. La correspondencia ˆφ∗ (θ) para D = {Do, Ds} es el intervalo entre SearchMin y SearchMax. Esta evidencia respalda la intuición inicial de que la adquisición del día 0 debería disminuir con los costos de almacenamiento. También confirma que los altos niveles de adquisición en el día 0 son una respuesta racional al entorno del torneo de 2004 con un costo promedio de almacenamiento, que corresponde a θ = 100. La predicción mínima para la adquisición agregada en este nivel de costos de almacenamiento, dada por cualquier método experimental, es aproximadamente 3. Esto es bastante alto, ya que corresponde a un compromiso esperado del 1/3 de la capacidad total del proveedor para todo el juego. La predicción máxima es considerablemente mayor a 4.5. En la competencia actual de 2004, la adquisición total del día 0 equivalía a 5.71 en la escala utilizada aquí [9]. Nuestras predicciones subestiman este resultado en cierta medida, pero muestran que cualquier resultado racional probablemente tendría una alta adquisición en el día 0. 4.4.3 Extrapolando la Correspondencia de la Solución Tenemos evidencia razonablemente sólida de que la correspondencia del resultado está disminuyendo. Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento a un valor que reduciría la adquisición del día 0 en equilibrio, o concluir que esto no es posible. Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día 0. No está claro cuán significativos serían los resultados del aprendizaje si se agregaran Ds al conjunto de datos de entrenamiento. De hecho, los datos adicionales pueden aumentar realmente la varianza del aprendizaje. Recuerde que el objetivo de los diseñadores es incentivar la adquisición agregada del día 0 que esté por debajo del umbral α. Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultados estimada a partir de D que produce θ = 320. Los datos para θ = 320 fueron recopilados de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos por 33 iteraciones de BestFirstSearch. La Figura 3 muestra los límites detallados para todos los perfiles en términos de sus valores correspondientes de φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Límites de ε de Adquisición Total Día-0 Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320. Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ(a). La región gris corresponde a ˆφ∗ (320) con δ = 2.5M. El conjunto estimado de resultados agregados del día 0 es muy cercano al de θ = 200, lo que indica que hay poco beneficio adicional al aumentar los costos de almacenamiento por encima de 200. Observa que incluso el límite inferior de nuestro conjunto estimado de equilibrios de Nash está muy por encima de la adquisición objetivo del día 0 de 2. Además, las recompensas para los agentes son casi siempre negativas en θ = 320. Por consiguiente, aumentar los costos aún más sería indeseable incluso si finalmente se pudiera reducir la adquisición en el día 0. Dado que tenemos una confianza razonable de que φ∗ (θ) está disminuyendo en θ, tampoco esperamos que establecer θ en algún lugar entre 200 y 320 logre el resultado deseado. Concluimos que es poco probable que la adquisición del día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento. Que nuestras predicciones tienden a subestimar los resultados del torneo refuerza esta conclusión. Para lograr la reducción deseada en la adquisición del día 0 se requiere rediseñar otros aspectos del mecanismo. 4.5 Análisis Probabilístico Nuestro análisis empírico ha producido evidencia en apoyo a la conclusión de que ninguna configuración razonable del costo de almacenamiento probablemente sería suficiente para frenar la adquisición excesiva del día 0 en TAC/SCM 04. Toda esta evidencia ha sido en forma de simple interpolación y extrapolación de estimaciones de la correspondencia del equilibrio de Nash. Estas estimaciones se basan en simular instancias del juego y están sujetas a ruido de muestreo contribuido por los diversos elementos estocásticos del juego. En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos -bound a tales efectos estocásticos. Supongamos que todos los agentes tienen conjuntos de estrategias puras finitos (y pequeños), A. Por lo tanto, es factible muestrear toda la matriz de pagos del juego. Además, supongamos que el ruido es aditivo con media cero en promedio durante todo el juego, por lo que en la práctica probablemente querríamos que el umbral sea aún más bajo. 310 y varianza finita, es decir, Ui(a) = ui(a) + ˜ξi(a), donde Ui(a) es la ganancia observada para i cuando se jugó a, ui(a) es la ganancia correspondiente real, y ˜ξi(a) es una variable aleatoria normal con media cero. Designamos la varianza conocida de ˜ξi(a) como σ2 i (a). Por lo tanto, asumimos que ˜ξi(a) es normal con distribución N(0, σ2 i (a)). Tomamos ¯ui(a) como la media muestral de todos los Ui(a) en D, y seguimos a Chang y Huang [3] al asumir que tenemos una priori impropia sobre las ganancias reales ui(a) y el muestreo fue independiente para todos i y a. También confiamos en su resultado de que ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] son independientes con distribuciones posteriores N(¯ui(a), σ2 i (a)/ni(a)), donde ni(a) es el número de muestras tomadas de los pagos para i en el perfil puro a, y Zi(a) ∼ N(0, 1). Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio de Nash -Nash. Si ui(·)|¯ui(·) son independientes para todo i ∈ I y a ∈ A, tenemos el siguiente resultado (a partir de este punto omitimos la condición sobre ¯ui(·) por brevedad): PROPOSICIÓN 1. Para todo \\( i \\in I \\), \\( \\max_{b \\in A_i} u_i(b, a_{-i}) - u_i(a) \\leq \\varepsilon \\), donde \\( \\varepsilon = \\int_{Y_i} \\int_{Z} \\int_{R} \\int_{Y} \\int_{b \\in A_i \\backslash a_i} \\Pr(u_i(b, a_{-i}) \\leq u + \\varepsilon) f_{u_i(a)}(u) du \\), donde \\( f_{u_i(a)}(u) \\) es la función de densidad de probabilidad de \\( N(\\overline{u_i(a)}, \\sigma_i(a)) \\). Las pruebas de este y todos los resultados posteriores se encuentran en el Apéndice. La distribución posterior de la media óptima de n muestras, derivada por Chang y Huang [3], es Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) donde a ∈ A y Φ(·) es la función de distribución N(0, 1). Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilístico que (a) ≤ γ para un γ dado. Ahora, consideramos casos de datos incompletos y utilizamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en los datos) en la distribución de sup{φ∗ (θ)} e inf{φ∗ (θ)} (asumiendo que ambos son alcanzables): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, donde x es un número real y ≤D indica que el límite superior solo considera estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} y {inf{φ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf{φ∗ (θ)} ≤ x}. Los valores así derivados comprenden las Tablas 1 y 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Tabla 1: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando N(θ) es un conjunto de equilibrios de Nash. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Tabla 2: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {150, 200, 320} cuando N(θ) es un conjunto de equilibrios de Nash. Las Tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ(a) < 2.7 es poco probable para cualquier θ del cual tengamos datos, aunque este juicio, como mencionamos, se refiere únicamente a los perfiles que hemos muestreado realmente. Podemos entonces aceptar esto como otra pieza de evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, parece poco probable que el diseñador logre su objetivo incluso si pudiera persuadir a los participantes a jugar un equilibrio deseable. La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM de 2004 eran, de hecho, racionales al adquirir grandes cantidades de componentes al comienzo del juego. Si observamos la tercera columna de esta tabla, que corresponde a θ = 100, podemos deducir que ningún perfil a en nuestros datos con φ(a) < 3 es muy probable que se juegue en equilibrio. Los límites anteriores proporcionan algunas pruebas generales, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos muestreado. Particularmente, nos gustaría decir algo sobre lo que sucede en los ajustes de θ para los cuales no tenemos datos. Para derivar un límite probabilístico aproximado sobre la probabilidad de que ningún θ ∈ Θ haya logrado el objetivo del diseñador, sea ∪J j=1Θj una partición de Θ, y asuma que la función sup{φ∗ (θ)} satisface la condición de Lipschitz con constante de Lipschitz Aj en cada subconjunto Θj. Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a Θ = [0, 320]. Ahora definimos cada subconjunto j como el intervalo entre dos puntos para los cuales hemos producido datos. Por lo tanto, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], con j variando entre 1 y 5, correspondiendo a los subintervalos anteriores. Denotaremos cada Θj por (aj, bj]. Luego, la siguiente proposición nos da una cota superior aproximada sobre la probabilidad de que sup{φ∗ (θ)} ≤ α. PROPOSICIÓN 2. Debido a que nuestros límites son aproximados, no podemos utilizarlos como una evaluación probabilística concluyente. En cambio, tomamos esto como otra pieza de evidencia para complementar nuestros hallazgos. Aunque podamos asumir que una función que aproximamos a partir de datos es Lipschitz continua, rara vez conocemos en realidad la constante de Lipschitz para cualquier subconjunto de Θ. Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de los datos. Aquí, probamos tres métodos para hacer esto. El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subintervalo. Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo. Un método alternativo es tomar un límite superior en la pendiente obtenida dentro de cada subintervalo utilizando los datos disponibles. Esto produce un límite superior de probabilidades mucho menos conservador. Sin embargo, dado que el límite superior real suele ser mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso. Un último método que intentamos es un compromiso entre los dos anteriores. En lugar de tomar el límite superior conservador basado en datos sobre todo el dominio de la función Θ, tomamos el promedio de los límites superiores obtenidos en cada Θj. El límite en un intervalo se toma como el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos. Los resultados de evaluar la expresión para Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3. En términos de nuestras afirmaciones en maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Tabla 3: Límite superior aproximado de la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con un objetivo α = 2. Se utilizan diferentes métodos para aproximar el límite superior de la pendiente en cada subintervalo j. En este trabajo, la expresión proporciona un límite superior a la probabilidad de que alguna configuración de θ (es decir, costo de almacenamiento) en el intervalo [0,320] resulte en una adquisición total del día 0 que no sea mayor en ningún equilibrio que el objetivo especificado por α y tomado aquí como 2. Como sospechábamos, el enfoque más conservador para estimar el límite superior de la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí. Sin embargo, los otros dos enfoques de estimación, encontrados en las columnas dos y tres de la Tabla 3, sugieren que de hecho estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría funcionado. Dada la tremenda dificultad del problema, este resultado es muy sólido. Aun así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia. Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y los conjuntos de estrategias). Tampoco podemos esperar obtener nunca suficiente evidencia para llegar a conclusiones completamente objetivas. En cambio, el enfoque que defendemos aquí es recopilar la mayor cantidad de evidencia posible dadas las limitaciones de recursos, y tomar la decisión más convincente basada en esta evidencia, si es posible. RESULTADOS DE CONVERGENCIA En este punto, exploramos abstractamente si una elección de parámetro de diseño basada en datos de pago puede ser asintóticamente confiable. Dado que no teníamos todas las desviaciones posibles para cualquier perfil disponible en los datos, los verdaderos límites superiores pueden ser aún más bajos. Por conveniencia, utilizaremos la notación un,i(a) para referirnos a una función de pago del jugador i basada en un promedio sobre n muestras i.i.d. de la distribución de pagos. También asumimos que un,i(a) son independientes para todo a ∈ A e i ∈ I. Utilizaremos la notación Γn para referirnos al juego [I, R, {ui,n(·)}], mientras que Γ denotará el juego subyacente, [I, R, {ui(·)}]. De manera similar, definimos n(r) como (r) con respecto al juego Γn. En esta sección, demostramos que n(s) → (s) casi seguramente de forma uniforme en el espacio de estrategias mixtas para cualquier juego finito, y, además, que todas las equilibrios de Nash en estrategias mixtas en juegos empíricos eventualmente se acercan arbitrariamente a algunas estrategias de equilibrio de Nash en el juego subyacente. Utilizamos estos resultados para demostrar que bajo ciertas condiciones, la elección óptima del parámetro de diseño basada en datos empíricos converge casi seguramente al óptimo real. TEOREMA 3. Supongamos que |I| < ∞, |A| < ∞. Entonces n(s) → (s) casi seguramente uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios de Nash de Γ. Si definimos Nn,γ = {s ∈ S : n(s) ≤ γ}, tenemos el siguiente corolario del Teorema 3: COROLARIO 4. Para todo γ > 0, existe un M tal que para todo n ≥ M, N ⊂ Nn,γ casi seguramente. PRUEBA. Dado que n(s) = 0 para todo s ∈ N, podemos encontrar un M lo suficientemente grande tal que Pr{supn≥M sups∈N n(s) < γ} = 1. Según el Corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier > 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios de Nash empíricos si se han tomado suficientes muestras. Como mostramos ahora, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un límite no nulo como una estimación del conjunto de equilibrios de Nash. Primero, supongamos que concluimos que para una configuración particular de θ, sup{ˆφ∗ (θ)} ≤ α. Entonces, dado que para cualquier fijo > 0, N(θ) ⊂ Nn, (θ) cuando n es suficientemente grande, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α para cualquier n de este tipo. Así, dado que definimos la función de bienestar del diseñador como I{sup{φ∗ (θ)} ≤ α} en nuestro dominio de interés, la elección empírica de θ satisface el objetivo del diseñador, maximizando así su función de bienestar. Alternativamente, supongamos que concluimos que inf{ˆφ∗ (θ)} > α para cada θ en el dominio. Entonces, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, para todo θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo del diseñador. Ahora, demostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de Γn está cerca de algún equilibrio de Nash del juego subyacente. Este resultado nos llevará a considerar la convergencia de los optimizadores basados en datos empíricos a los ajustes óptimos reales de los parámetros del mecanismo. Primero notamos que la función (s) es continua en un juego finito. LEMMA 5. \n\nLEMMA 5. Sea S un conjunto de estrategias mixtas definido en un juego finito. Entonces: S → R es continua. Para la exposición que sigue, necesitamos un poco de notación adicional. Primero, sea (Z, d) un espacio métrico, y X, Y ⊂ Z y definamos la distancia de Hausdorff dirigida de X a Y como h(X, Y) = sup x∈X inf y∈Y d(x, y). Observa que U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ). Además, define BS(x, δ) como una bola abierta en S ⊂ Z con centro en x ∈ S y radio δ. Ahora, dejemos que Nn denote todos los equilibrios de Nash del juego Γn y sea Nδ = [ x∈N BS(x, δ), es decir, la unión de bolas abiertas de radio δ con centros en los equilibrios de Nash de Γ. Ten en cuenta que h(Nδ, N) = δ. Podemos entonces demostrar el siguiente resultado general. TEOREMA 6. Supongamos que |I| < ∞ y |A| < ∞. Entonces casi con seguridad h(Nn, N) converge a 0. Ahora demostraremos que en el caso especial cuando Θ y A son finitos y cada Γθ tiene un equilibrio de Nash único, las estimaciones ˆθ del parámetro óptimo del diseñador convergen a un optimizador real casi seguramente. Sea ˆθ = arg maxθ∈Θ W (Nn(θ), θ), donde n es el número de veces que se muestreó cada perfil puro en Γθ para cada θ, y sea θ∗ = arg maxθ∈Θ W (N(θ), θ). TEOREMA 7. Supongamos que |N(θ)| = 1 para todo θ ∈ Θ y supongamos que Θ y A son finitos. Sea W (s, θ) continua en el único s∗ (θ) ∈ N(θ) para cada θ ∈ Θ. Entonces ˆθ es un estimador consistente de θ∗ si W (N(θ), θ) se define como un supremo, ínfimo o esperanza sobre el conjunto de equilibrios de Nash. De hecho, ˆθ → θ∗ casi seguramente en cada uno de estos casos. La limitación del resultado anterior es que, dentro de nuestro marco de trabajo, el diseñador no tiene forma de saber o asegurar que Γθ tenga equilibrios únicos. Sin embargo, sí proporciona cierta justificación teórica para seguir el diseño de esta manera, y quizás servirá como guía para obtener resultados más generales en el futuro. 6. TRABAJO RELACIONADO La literatura de diseño de mecanismos en Economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10]. Además, existe una extensa literatura sobre el diseño óptimo de subastas [10], del cual el trabajo de Roger Myerson [11] es, quizás, el más relevante. En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y teniendo en cuenta restricciones como la compatibilidad de incentivos y la racionalidad individual. Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de Ciencias de la Computación. Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros relevantes del juego son conocimiento común. Cuando las funciones de pago de los jugadores son desconocidas, se ha explorado la realización de búsquedas mediante simulaciones como alternativa. Un enfoque en esa dirección, tomado en [4] y [15], es coevolucionar el parámetro del mecanismo y las estrategias de los agentes, utilizando alguna noción de utilidad social y pagos de los agentes como criterios de aptitud. Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética. En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron un resultado de un juego inducido por un parámetro del mecanismo como el resultado del aprendizaje conjunto de los agentes. Más recientemente, Phelps et al. [14] compararon dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en juegos definidos por estrategias heurísticas, como en [18]. 7. CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el diseño empírico de mecanismos. Definimos un modelo formal de teoría de juegos de interacción entre el diseñador y los participantes del mecanismo como un juego de dos etapas. También describimos en cierta generalidad los métodos para estimar una función de equilibrio de Nash de muestra cuando los datos son extremadamente escasos, o una correspondencia de equilibrio de Nash cuando hay más datos disponibles. Nuestras técnicas están diseñadas específicamente para abordar problemas en los que tanto el espacio de parámetros del mecanismo como los conjuntos de estrategias de los agentes son infinitos y solo se puede adquirir un conjunto de datos relativamente pequeño. Un problema de diseño difícil en el juego TAC/SCM que la comunidad de TAC ha estado ansiosa por abordar nos brinda un escenario para probar nuestros métodos. Al aplicar el análisis empírico del juego al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos. Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia del equilibrio de Nash. Al final, podemos intentar proporcionar suficiente evidencia para prescribir una configuración de parámetros, o sugerir que no es posible encontrar una configuración que satisfaga al diseñador. En el caso de TAC/SCM, nuestra evidencia sugiere bastante claramente que el costo de almacenamiento no pudo haber sido ajustado de manera efectiva en el torneo de 2004 para frenar la adquisición excesiva del día 0 sin efectos perjudiciales en la rentabilidad general. El éxito de nuestro análisis en este entorno extremadamente complejo con altos costos de simulación nos hace ser optimistas de que nuestros métodos pueden brindar orientación en la toma de decisiones de diseño de mecanismos en otros dominios desafiantes. Los resultados teóricos confirman algunas intuiciones detrás de los métodos de diseño de mecanismos empíricos que hemos introducido, y aumentan nuestra confianza en que nuestro marco puede ser efectivo para estimar la mejor elección de parámetros del mecanismo en entornos relativamente generales. Agradecimientos Agradecemos a Terence Kelly, Matthew Rudary y Satinder Singh por sus útiles comentarios sobre versiones anteriores de este trabajo. Este trabajo fue apoyado en parte por la subvención de la NSF IIS-0205435 y el programa de razonamiento estratégico DARPA REAL. 8. REFERENCIAS [1] R. Arunachalam y N. M. Sadeh. La competencia de agentes de comercio de la cadena de suministro. Investigación y aplicaciones del comercio electrónico, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy y M. Tschantz. Un enfoque de programación estocástica para la planificación en TAC SCM. En la Quinta Conferencia ACM sobre Comercio Electrónico, páginas 152-159, Nueva York, 2004. [3] Y.-P. Chang y W.-T. Huang. Intervalos de confianza generalizados para el valor más grande de algunas funciones de parámetros bajo normalidad. Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.\nEstadística Sinica, 10:1369-1383, 2000. [4] D. Cliff. Evolución del mecanismo de mercado a través de un espacio continuo de tipos de subasta. En el Congreso de Computación Evolutiva de 2002. [5] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [6] V. Conitzer y T. Sandholm. Un algoritmo para diseñar automáticamente mecanismos determinísticos sin pagos. En la Tercera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagente, páginas 128-135, 2004. [7] D. Friedman. Juegos evolutivos en economía. Econometrica, 59(3):637-666, mayo de 1991. [8] R. Keener. Teoría Estadística: Una Mezcla de Temas Fundamentales. Departamento de Estadística de la Universidad de Michigan, 2004. [9] C. Kiekintveld, Y. Vorobeychik y M. P. Wellman. Un análisis de la competencia de agentes comerciales de gestión de la cadena de suministro de 2004. En el taller IJCAI-05 sobre Diseño y Análisis de Agentes de Negociación, Edimburgo, 2005. [10] A. Mas-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [11] R. B. Myerson.\nEditorial de la Universidad de Oxford, 1995. [11] R. B. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6(1):58-73, febrero de 1981. [12] S. Olafsson y J. Kim. Optimización de simulación. En E. Yucesan, C.-H. Chen, J. Snowdon y J. Charnes, editores, Conferencia de Simulación de Invierno 2002, 2002. [13] D. Pardoe y P. Stone. TacTex-03: Un agente de gestión de la cadena de suministro. SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, y P. McBurney. Agentes automatizados versus humanos virtuales: una comparación teórica evolutiva de dos diseños de mercado de subasta doble. En Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney y E. Sklar. Co-evolución de mecanismos de subasta y estrategias de negociación: hacia un enfoque novedoso para el diseño microeconómico. En el taller ECOMAS 2002, 2002. [16] S. Phelps, S. Parsons, E. Sklar y P. McBurney. Utilizando programación genética para optimizar reglas de precios para un mercado de subasta doble. En Taller sobre Agentes para el Comercio Electrónico, 2003. [17] Y. Vorobeychik, M. P. Wellman y S. Singh. Aprendiendo funciones de pago en juegos infinitos. En la Decimonovena Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro y J. O. Kephart. Analizando interacciones estratégicas complejas en sistemas multiagente. En el taller AAAI-02 sobre agentes teóricos de juegos y de toma de decisiones, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld y V. Soni. Interacciones estratégicas en un juego de cadena de suministro. Inteligencia Computacional, 21(1):1-26, febrero de 2005. APÉNDICE A. PRUEBAS A.1 Prueba de la Proposición 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du. A.2 Prueba de la Proposición 2 Primero, supongamos que alguna función, f(x), definida en [ai, bi], satisface la condición de Lipschitz en (ai, bi] con una constante de Lipschitz Ai. Entonces se cumple la siguiente afirmación: Afirmación: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai). Para demostrar esta afirmación, observe que la intersección de las líneas en f(ai) y f(bi) con pendientes -Ai y Ai respectivamente determinará el límite inferior del mínimo de f(x) en [ai, bi] (que es un límite inferior del ínfimo de f(x) en (ai, bj]). La línea en f(ai) está determinada por f(ai) = −Aiai + cL y la línea en f(bi) está determinada por f(bi) = Aibi + cR. Por lo tanto, las intercepciones son cL = f(ai) + Aiai y cR = f(bi) + Aibi respectivamente. Sea x∗ el punto en el que estas líneas se cruzan. Entonces, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A. Al sustituir las expresiones de cR y cL, obtenemos el resultado deseado. Ahora, la subaditividad nos da Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, y, por la afirmación, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}. Dado que tenemos un número finito de puntos en el conjunto de datos para cada θ, podemos obtener la siguiente expresión: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}. Ahora podemos restringir nuestra atención en obtener una cota superior en Pr{sup{φ∗ (θ)} = y} para un θ fijo. Para hacer esto, observe que Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} por subaditividad y el hecho de que un perfil a es un equilibrio de Nash si y solo si (a) = 0. Poner todo junto produce el resultado deseado. Prueba de Teorema 3 En primer lugar, necesitaremos el siguiente hecho: Afirmación: Dada una función fi(x) y un conjunto X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|. Para demostrar esta afirmación, observe que | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) si maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) si maxx f2(x) ≥ maxx f1(x) En el primer caso, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 De manera similar, en el segundo caso, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|. Por lo tanto, la afirmación se mantiene. Por la Ley Fuerte de los Grandes Números, un,i(a) → ui(a) casi seguramente para todo i ∈ I, a ∈ A. Es decir, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, o, equivalentemente [8], para cualquier α > 0 y δ > 0, existe M(i, a) > 0 tal que Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Al tomar M = maxi∈I maxa∈A M(i, a), tenemos que Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Así, por la afirmación, para cualquier n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ con una probabilidad de al menos 1 − α. Ten en cuenta que dado que s−i(a) y s(a) están acotados entre 0 y 1, pudimos eliminarlos de las expresiones anteriores para obtener una cota que será válida independientemente de la elección particular de s. Además, dado que el resultado anterior se puede obtener para un α arbitrario > 0 y δ > 0, tenemos que Pr{limn→∞ n(s) = (s)} = 1 uniformemente en S. A.4 Prueba del Lema 5 Demostramos el resultado utilizando la continuidad uniforme de ui(s) y la preservación de la continuidad bajo el máximo. Afirmación: Una función f : Rk → R definida por f(t) = Σi=1k zi ti, donde zi son constantes en R, es uniformemente continua en t. La afirmación se sigue porque |f(t)−f(t )| = | Σi=1k zi(ti−ti)| ≤ Σi=1k |zi||ti − ti|. Un resultado inmediato de esto para nuestros propósitos es que ui(s) es uniformemente continua en s y ui(ai, s−i) es uniformemente continua en s−i. Afirmación: Sea f(a, b) uniformemente continua en b ∈ B para cada a ∈ A, con |A| < ∞. Entonces V (b) = maxa∈A f(a, b) es uniformemente continua en b. Para demostrar esto, toma γ > 0 y deja que b, b ∈ B tal que b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ. Ahora toma δ = mina∈A δ(a). Entonces, cada vez que b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ. Ahora, recuerda que (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)]. Según las afirmaciones anteriores, maxai∈Ai ui(ai, s−i) es uniformemente continua en s−i y ui(s) es uniformemente continua en s. Dado que la diferencia de dos funciones uniformemente continuas es uniformemente continua, y dado que esta continuidad se conserva bajo el máximo según nuestra segunda afirmación, obtenemos el resultado deseado. Prueba de Teorema 6. Elija δ > 0. Primero, necesitamos asegurarnos de que se cumple la siguiente afirmación: Afirmación: ¯ = mins∈S\\Nδ (s) existe y ¯ > 0. Dado que Nδ es un subconjunto abierto de S compacto, se sigue que S \\ Nδ es compacto. Como también habíamos demostrado en el Lema 5 que (s) es continua, la existencia se sigue del teorema de Weierstrass. Es claro que ¯ > 0 ya que (s) = 0 si y solo si s es un equilibrio de Nash de Γ. Ahora, por el Teorema 3, para cualquier α > 0 existe un M tal que Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. En consecuencia, para cualquier δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Dado que esto se cumple para un α arbitrario > 0 y δ > 0, se obtiene el resultado deseado. Prueba de Teorema 7. Fija θ y elige δ > 0. Dado que W (s, θ) es continua en s∗ (θ), dado > 0 existe δ > 0 tal que para cada s que esté dentro de δ de s∗ (θ), |W (s, θ) - W (s∗ (θ), θ)| < . Según el Teorema 6, podemos encontrar M(θ) lo suficientemente grande para que todos los s ∈ Nn estén dentro de δ de s∗ (θ) para todo n ≥ M(θ) con probabilidad 1. Por consiguiente, para cualquier > 0 podemos encontrar M(θ) lo suficientemente grande tal que con probabilidad 1 tengamos supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < . Asumamos sin pérdida de generalidad que hay una elección óptima única de θ. Ahora, dado que el conjunto Θ es finito, también existe la segunda mejor opción de θ (si solo hay un θ ∈ Θ, esta discusión no tiene sentido de todos modos): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ). Supongamos sin pérdida de generalidad que θ∗∗ también es único y sea ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ). Entonces, si dejamos < ∆/2 y dejamos que M = maxθ∈Θ M(θ), donde cada M(θ) es lo suficientemente grande como para que supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., la elección óptima de θ basada en cualquier equilibrio empírico será θ∗ con probabilidad 1. Por lo tanto, en particular, dado cualquier distribución de probabilidad sobre equilibrios empíricos, la mejor elección de θ será θ∗ con probabilidad 1 (similarmente, si tomamos el supremo o el ínfimo de W (Nn(θ), θ) sobre el conjunto de equilibrios empíricos al construir la función objetivo). ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "gametheoretic model": {
            "translated_key": "teoría de juegos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal <br>gametheoretic model</br> of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [
                "We defined a formal <br>gametheoretic model</br> of interaction between the designer and the participants of the mechanism as a two-stage game."
            ],
            "translated_annotated_samples": [
                "Definimos un modelo formal de <br>teoría de juegos</br> de interacción entre el diseñador y los participantes del mecanismo como un juego de dos etapas."
            ],
            "translated_text": "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismos empíricos. En la continuación, desarrollamos algunos métodos generales para el diseño empírico de mecanismos y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto. En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2. Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores. Ri es el conjunto de estrategias disponibles para el jugador i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×. . .×Am. A menudo es conveniente referirse a la estrategia del jugador i por separado de la de los demás jugadores. Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama un perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i). Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el jugador i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada jugador i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i. Podemos extender esta definición a estrategias mixtas asumiendo que ui son utilidades de von Neumann-Morgenstern (vNM) de la siguiente manera: ui(s) = Es[ui], donde Es es la expectativa tomada con respecto a la distribución de probabilidad del juego inducida por la estrategia mixta de los jugadores s. Al emplear la forma normal, modelamos a los agentes jugando una única acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones más detalladas sobre la acción a lo largo del tiempo en la forma extensiva. Aunque cualquier juego extenso puede ser reformulado en forma normal, hacerlo puede sacrificar la concisión y difuminar distinciones relevantes (por ejemplo, la perfección en subjuegos). Ocasionalmente, escribimos ui(x, y) para indicar que x ∈ Ai o Si y y ∈ A−i o S−i dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u(·) = {u1(·), . . . , um(·)}. Definimos una función, : R → R, interpretada como el beneficio máximo que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) donde r pertenece a algún conjunto de estrategias, R, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada aquellas jugadas por los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un equilibrio de Nash. DEFINICIÓN 1. Un perfil estratégico r = (r1, . . . , rm) constituye un equilibrio de Nash del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). Cuando r ∈ A, lo anterior define un equilibrio de Nash de estrategia pura; de lo contrario, la definición describe un equilibrio de Nash de estrategia mixta. A menudo recurrimos al concepto de un equilibrio aproximado, o equilibrio de Nash, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita. Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un equilibrio de Nash si (r) ≤ . En este estudio dedicamos especial atención a los juegos que presentan simetría en cuanto a los pagos, lo que hace que los agentes sean estratégicamente idénticos. DEFINICIÓN 2. Un juego [I, {Ri}, {ui(r)}] es simétrico si para todo i, j ∈ I, (a) Ri = Rj y (b) ui(ri, r−i) = uj (rj, r−j) siempre que ri = rj y r−i = r−j. EL MODELO Modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un juego de dos etapas. El diseñador comienza seleccionando primero un valor, θ, de un conjunto de configuraciones de mecanismos permitidas, Θ. Todos los agentes participantes observan el parámetro θ del mecanismo y se mueven simultáneamente después. Por ejemplo, el diseñador podría estar decidiendo entre mecanismos de subasta de sobre cerrado de precio único y de precio único, con la presunción de que una vez tomada la decisión, los postores participarán con pleno conocimiento de las reglas de la subasta. Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como Γθ = [I, {Ri}, {ui(r, θ)}]. Nos referimos a Γθ como un juego inducido por θ. Sea N(θ) el conjunto de perfiles estratégicos considerados soluciones del juego Γθ.3. Supongamos que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, W(r, θ), dependiente del parámetro del mecanismo y del juego resultante, r. Definimos una medida pesimista, W( ˆR, θ) = inf{W(r, θ) : r ∈ ˆR}, que representa el bienestar en el peor de los casos del juego inducido por θ, asumiendo que los agentes juegan alguna estrategia conjunta en ˆR. Normalmente nos preocupamos por W (N(θ), θ), el resultado en el peor de los casos de jugar alguna solución. En algunos problemas podemos obtener una considerable ventaja al utilizar una función de agregación para mapear el resultado del bienestar de un juego. Generalmente adoptamos el equilibrio de Nash como concepto de solución, y por lo tanto tomamos N(θ) como el conjunto de equilibrios. Sin embargo, gran parte de la metodología desarrollada aquí podría ser utilizada con criterios alternativos para derivar el comportamiento del agente a partir de una definición del juego. Nuevamente, existen alternativas disponibles. Por ejemplo, si se tiene una distribución de probabilidad sobre el conjunto de soluciones N(θ), sería natural tomar la expectativa de W(r, θ) en su lugar. 307 especificado en términos de estrategias de agentes a un resultado de bienestar equivalente especificado en términos de un resumen de menor dimensión. DEFINICIÓN 3. Una función φ: R1 × · · · × Rm → Rq es una función de agregación si m ≥ q y W(r, θ) = V(φ(r), θ) para alguna función V. Sobrecargamos el símbolo de función para aplicar a conjuntos de perfiles estratégicos: φ( ˆR) = {φ(r) : r ∈ ˆR}. Para mayor comodidad en la exposición, escribimos φ∗ (θ) para denotar φ(N(θ)). El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia. Por ejemplo, supongamos, como en nuestra aplicación a continuación, que la estrategia de un agente está definida por un parámetro numérico. Si todo lo que nos importa es el valor total jugado, podemos tomar φ(a) = Πm i=1 ai. Si hemos elegido nuestro agregador cuidadosamente, también podemos capturar estructuras que de otra manera no serían evidentes. Por ejemplo, φ∗ (θ) podría estar disminuyendo en θ, mientras que N(θ) podría tener una estructura más compleja. Dada una descripción de la correspondencia de solución N(θ) (equivalentemente, φ∗(θ)), el diseñador se enfrenta a un problema estándar de optimización. Alternativamente, dado un simulador que pudiera producir una muestra imparcial de la distribución de W (N(θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12]. Sin embargo, incluso para un juego Γθ con pagos conocidos, puede resultar computacionalmente intratable resolver los equilibrios de Nash, especialmente si el juego tiene conjuntos de estrategias grandes o infinitos. Además, deseamos estudiar juegos en los que los pagos no se dan explícitamente, sino que deben determinarse a partir de simulaciones u otra experiencia con el juego. Por lo tanto, asumimos que se nos proporciona un conjunto de datos (posiblemente ruidoso) de realizaciones de pagos: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, donde para cada punto de datos θi es el ajuste observado del parámetro del mecanismo, ai es el perfil de estrategia pura observado de los participantes, y Ui es la realización correspondiente de los pagos de los agentes. También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}. Sea D = {Do, Ds} el conjunto de datos combinado. (Ya sea que Do o Ds puedan ser nulos para un problema particular). En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos empíricos de teoría de juegos, para responder preguntas sobre el diseño del escenario TAC/SCM. 4. ANÁLISIS DE DISEÑO EMPÍRICO Dado que nuestros datos se presentan en forma de experiencia de pago y no como el valor de una función objetivo para configuraciones dadas de la variable de control, ya no podemos confiar en los métodos para optimizar funciones utilizando simulaciones. De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia del equilibrio de Nash. Además, no podemos depender directamente de los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilístico adaptados a nuestra configuración de problema. 4.1 Problema de Diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente. Recuerde que durante el torneo de 2004, los diseñadores del juego de la cadena de suministro optaron por aumentar drásticamente los costos de almacenamiento como medida para frenar las compras del día 0, con poco éxito. Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y la cantidad agregada de componentes adquiridos el día 0 en equilibrio. Esto suele ser el caso en juegos reales de interés, donde descripciones en lenguaje natural o algorítmicas pueden sustituir a una especificación formal de estrategias y funciones de pago. Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo. ¿Primero, ¿el aumento de los costos de almacenamiento realmente reduce la adquisición en el día 0? ¿Fue racional la adquisición excesiva observada durante el día 0 del torneo de 2004? Y en tercer lugar, ¿podría haber reducido de manera suficiente los costos de almacenamiento la adquisición del día 0 a un nivel aceptable, y en tal caso, cuál debería haber sido el ajuste de los costos de almacenamiento? Es esta tercera pregunta la que define el aspecto del diseño de mecanismos de nuestro análisis. Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de los agentes, la función de bienestar de los diseñadores, el espacio de parámetros del mecanismo y la fuente de datos. Restringimos las estrategias de los agentes para que sean un multiplicador de la cantidad de solicitudes del día 0 de uno de los finalistas, Deep Maize, en el torneo TAC/SCM de 2004. Lo restringimos aún más al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias por encima de 1.5 son extremadamente agresivas (por lo tanto, poco probables de proporcionar desviaciones refutadoras más allá de las disponibles en las estrategias incluidas, y ciertamente no forman parte de ningún equilibrio deseable). Todo otro comportamiento se basa en el comportamiento de Deep Maize y es idéntico para todos los agentes. Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico. Sin embargo, creemos que la forma general de los resultados debería ser robusta ante cambios en el comportamiento completo del agente. Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0. Sea φ(a) = Σ6 i=1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego particular de la cadena de suministro (para perfiles de estrategia mixta s, tomamos la esperanza de φ con respecto a la mezcla). La función de bienestar de los diseñadores W (N(θ), θ) se define entonces como I{sup{φ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de adquisición en el día 0 y I es la función indicadora. El diseñador selecciona un valor θ de costos de almacenamiento, expresado como un porcentaje anual del valor base de los componentes en el inventario (cobrado diariamente), del conjunto Θ = R+. Dado que la decisión de los diseñadores depende solo de φ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación. 4.2 Estimación de equilibrios de Nash El objetivo de los agentes de TAC/SCM es maximizar los beneficios obtenidos en una instancia del juego. Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, U(a)). Si también hemos fijado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de jugadores y sus correspondientes pagos, y, en consecuencia, para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios de Nash de cada juego Γθ. Por lo tanto, necesitamos métodos para aproximar equilibrios de Nash en juegos infinitos. A continuación, describimos los dos métodos que utilizamos en nuestro estudio. El primero ha sido explorado empíricamente anteriormente, mientras que el segundo se introduce aquí como el método específicamente diseñado para aproximar un conjunto de equilibrios de Nash. 4.2.1 Aproximación de la Función de Pago El primer método para estimar equilibrios de Nash basado en datos utiliza aprendizaje supervisado para aproximar las funciones de pago de mech6. No abordamos si y cómo otras medidas (por ejemplo, restringir directamente la adquisición) podrían haber logrado los objetivos de diseño. Nuestro enfoque considera como dado un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento. En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con un crecimiento de complejidad correspondiente. 308 participantes del mecanismo de un conjunto de datos de experiencia de juego [17]. Una vez que las funciones de pago aproximadas estén disponibles para todos los jugadores, los equilibrios de Nash pueden encontrarse ya sea de forma analítica o aproximada utilizando técnicas numéricas, dependiendo del modelo de aprendizaje. En lo que sigue, estimamos solo un equilibrio de Nash de muestra utilizando esta técnica, aunque esta restricción puede eliminarse a expensas de un tiempo de cálculo adicional. Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador. Por lo tanto, podemos aplicarlo cuando Ds = ∅. Si hay un simulador disponible, podemos generar datos adicionales para aumentar la confianza en nuestras estimaciones iniciales. Probamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado local (LWA) y regresión lineal ponderada localmente (LWLR). También utilizamos variables de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis empírico previo de teoría de juegos de TAC/SCM-03 [19]. El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido de forma analítica. Para los otros métodos aplicamos dinámica replicadora [7] a una aproximación discreta del juego aprendido. El total esperado de adquisiciones del día 0 en equilibrio se tomó como la estimación de un resultado. 4.2.2 Búsqueda en el Espacio de Perfiles de Estrategia Cuando tenemos acceso a un simulador, también podemos utilizar la búsqueda dirigida a través del espacio de perfiles para estimar el conjunto de equilibrios de Nash, que describimos aquí después de presentar alguna notación adicional. DEFINICIÓN 4. Un vecino estratégico de un perfil de estrategia pura a es un perfil que es idéntico a a en todo menos en una estrategia. Definimos Snb(a, D) como el conjunto de todos los vecinos estratégicos de a disponibles en el conjunto de datos D. De manera similar, definimos Snb(a, ˜D) como todos los vecinos estratégicos de a que no están en D. Finalmente, para cualquier a ∈ Snb(a, D) definimos al agente que se desvía como i(a, a). DEFINICIÓN 5. La -ligadura, ˆ, de un perfil de estrategia pura a se define como maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}. Decimos que a es un candidato a δ-equilibrio para δ ≥ ˆ. Cuando Snb(a, ˜D) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), a se confirma como un equilibrio de Nash ˆ. Nuestro método de búsqueda opera explorando desviaciones de los equilibrios candidatos. Nos referimos a esto como BestFirstSearch, ya que selecciona con probabilidad uno un perfil de estrategia a ∈ Snb(a, ˜D) que tiene el menor ˆin D. Finalmente definimos un estimador para un conjunto de equilibrios de Nash. DEFINICIÓN 6. Para un conjunto K, define Co(K) como la envoltura convexa de K. Sea Bδ el conjunto de candidatos en el nivel δ. Definimos ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) para un δ fijo como un estimador de φ∗ (θ). En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles estratégicos agregados con límite inferior -bound por debajo de un δ fijo. Esta definición nos permite explotar la estructura que surge de la función de agregación. Si dos perfiles son cercanos en términos de valores de agregación, es probable que tengan límites similares. En particular, si uno está en equilibrio, el otro también puede estarlo. Presentamos un respaldo teórico para este método de estimación del conjunto de equilibrios de Nash a continuación. Dado que el juego en el que estamos interesados es infinito, es necesario terminar BestFirstSearch antes de explorar todo el espacio de strat7. Por ejemplo, podemos utilizar técnicas de aprendizaje activo [5] para mejorar la calidad de la aproximación de la función de recompensa. En este trabajo, nos concentramos en la búsqueda en el espacio de perfiles estratégicos. Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos. Generación de datos Nuestros datos fueron recopilados simulando juegos TAC/SCM en una versión local del servidor TAC/SCM de 2004, que tiene una configuración para el costo de almacenamiento. Las estrategias de los agentes en juegos simulados fueron seleccionadas del conjunto {0, 0.3, 0.6, . . . , 1.5} con el fin de tener una probabilidad positiva de generar vecinos estratégicos. Se generó un conjunto de datos base Do mediante el muestreo de 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}. Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varios defectos. Utilizamos la búsqueda para generar un conjunto de datos simulados Ds, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ. Dado que el costo de la simulación es extremadamente alto (un juego tarda casi 1 hora en ejecutarse), pudimos ejecutar un total de 2670 juegos en el transcurso de más de seis meses. Para hacer una comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategias conjuntas finitas restringidas para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces). 4.4 Resultados 4.4.1 Análisis del conjunto de datos base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos base Do. Además, generamos una estimación de la correspondencia del equilibrio de Nash, ˆφ∗ (θ), aplicando la Definición 6 con δ = 2.5E6. Los resultados se muestran en la Figura 1. Como podemos ver, la correspondencia ˆφ∗ (θ) tiene poco poder predictivo basado en Do, y no revela ninguna estructura interesante sobre el juego. Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición Total Día 0 LWA LWLR QR BaselineMin BaselineMax Figura 1: Estimaciones de adquisición del día 0 agregadas basadas en Do. La correspondencia ˆφ∗ (θ) es el intervalo entre BaselineMin y BaselineMax. En general, la búsqueda se detiene una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para obtener conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego. Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash a permanecer en este subconjunto discreto de [0,1.5]. Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron accidentes, problemas de conectividad de red y otras anomalías obvias), el juego sería descartado. Análisis de los datos de búsqueda Para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ∗ (θ) (nuevamente, usando δ =2.5E6) en el conjunto de datos D = {Do, Ds}, donde Ds es datos generados a través de la aplicación de BestFirstSearch. Los resultados de esta estimación se representan gráficamente frente a los resultados de los métodos de aprendizaje entrenados en Do 11 en la Figura 2. Primero, observamos que la adición de los datos de búsqueda reduce considerablemente el rango de posibles equilibrios. Además, las predicciones puntuales reales de los métodos de aprendizaje y aquellas basadas en límites después de la búsqueda son razonablemente cercanas. Combinar la evidencia recopilada de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquiera de los métodos utilizados de forma aislada. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición del Día 0 LWA LWLR QR Búsqueda Mínima Búsqueda Máxima Figura 2: Estimaciones agregadas de adquisición del día 0 basadas en la búsqueda en el espacio de perfiles de estrategia en comparación con técnicas de aproximación de funciones entrenadas en Do. La correspondencia ˆφ∗ (θ) para D = {Do, Ds} es el intervalo entre SearchMin y SearchMax. Esta evidencia respalda la intuición inicial de que la adquisición del día 0 debería disminuir con los costos de almacenamiento. También confirma que los altos niveles de adquisición en el día 0 son una respuesta racional al entorno del torneo de 2004 con un costo promedio de almacenamiento, que corresponde a θ = 100. La predicción mínima para la adquisición agregada en este nivel de costos de almacenamiento, dada por cualquier método experimental, es aproximadamente 3. Esto es bastante alto, ya que corresponde a un compromiso esperado del 1/3 de la capacidad total del proveedor para todo el juego. La predicción máxima es considerablemente mayor a 4.5. En la competencia actual de 2004, la adquisición total del día 0 equivalía a 5.71 en la escala utilizada aquí [9]. Nuestras predicciones subestiman este resultado en cierta medida, pero muestran que cualquier resultado racional probablemente tendría una alta adquisición en el día 0. 4.4.3 Extrapolando la Correspondencia de la Solución Tenemos evidencia razonablemente sólida de que la correspondencia del resultado está disminuyendo. Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento a un valor que reduciría la adquisición del día 0 en equilibrio, o concluir que esto no es posible. Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día 0. No está claro cuán significativos serían los resultados del aprendizaje si se agregaran Ds al conjunto de datos de entrenamiento. De hecho, los datos adicionales pueden aumentar realmente la varianza del aprendizaje. Recuerde que el objetivo de los diseñadores es incentivar la adquisición agregada del día 0 que esté por debajo del umbral α. Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultados estimada a partir de D que produce θ = 320. Los datos para θ = 320 fueron recopilados de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos por 33 iteraciones de BestFirstSearch. La Figura 3 muestra los límites detallados para todos los perfiles en términos de sus valores correspondientes de φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Límites de ε de Adquisición Total Día-0 Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320. Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ(a). La región gris corresponde a ˆφ∗ (320) con δ = 2.5M. El conjunto estimado de resultados agregados del día 0 es muy cercano al de θ = 200, lo que indica que hay poco beneficio adicional al aumentar los costos de almacenamiento por encima de 200. Observa que incluso el límite inferior de nuestro conjunto estimado de equilibrios de Nash está muy por encima de la adquisición objetivo del día 0 de 2. Además, las recompensas para los agentes son casi siempre negativas en θ = 320. Por consiguiente, aumentar los costos aún más sería indeseable incluso si finalmente se pudiera reducir la adquisición en el día 0. Dado que tenemos una confianza razonable de que φ∗ (θ) está disminuyendo en θ, tampoco esperamos que establecer θ en algún lugar entre 200 y 320 logre el resultado deseado. Concluimos que es poco probable que la adquisición del día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento. Que nuestras predicciones tienden a subestimar los resultados del torneo refuerza esta conclusión. Para lograr la reducción deseada en la adquisición del día 0 se requiere rediseñar otros aspectos del mecanismo. 4.5 Análisis Probabilístico Nuestro análisis empírico ha producido evidencia en apoyo a la conclusión de que ninguna configuración razonable del costo de almacenamiento probablemente sería suficiente para frenar la adquisición excesiva del día 0 en TAC/SCM 04. Toda esta evidencia ha sido en forma de simple interpolación y extrapolación de estimaciones de la correspondencia del equilibrio de Nash. Estas estimaciones se basan en simular instancias del juego y están sujetas a ruido de muestreo contribuido por los diversos elementos estocásticos del juego. En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos -bound a tales efectos estocásticos. Supongamos que todos los agentes tienen conjuntos de estrategias puras finitos (y pequeños), A. Por lo tanto, es factible muestrear toda la matriz de pagos del juego. Además, supongamos que el ruido es aditivo con media cero en promedio durante todo el juego, por lo que en la práctica probablemente querríamos que el umbral sea aún más bajo. 310 y varianza finita, es decir, Ui(a) = ui(a) + ˜ξi(a), donde Ui(a) es la ganancia observada para i cuando se jugó a, ui(a) es la ganancia correspondiente real, y ˜ξi(a) es una variable aleatoria normal con media cero. Designamos la varianza conocida de ˜ξi(a) como σ2 i (a). Por lo tanto, asumimos que ˜ξi(a) es normal con distribución N(0, σ2 i (a)). Tomamos ¯ui(a) como la media muestral de todos los Ui(a) en D, y seguimos a Chang y Huang [3] al asumir que tenemos una priori impropia sobre las ganancias reales ui(a) y el muestreo fue independiente para todos i y a. También confiamos en su resultado de que ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] son independientes con distribuciones posteriores N(¯ui(a), σ2 i (a)/ni(a)), donde ni(a) es el número de muestras tomadas de los pagos para i en el perfil puro a, y Zi(a) ∼ N(0, 1). Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio de Nash -Nash. Si ui(·)|¯ui(·) son independientes para todo i ∈ I y a ∈ A, tenemos el siguiente resultado (a partir de este punto omitimos la condición sobre ¯ui(·) por brevedad): PROPOSICIÓN 1. Para todo \\( i \\in I \\), \\( \\max_{b \\in A_i} u_i(b, a_{-i}) - u_i(a) \\leq \\varepsilon \\), donde \\( \\varepsilon = \\int_{Y_i} \\int_{Z} \\int_{R} \\int_{Y} \\int_{b \\in A_i \\backslash a_i} \\Pr(u_i(b, a_{-i}) \\leq u + \\varepsilon) f_{u_i(a)}(u) du \\), donde \\( f_{u_i(a)}(u) \\) es la función de densidad de probabilidad de \\( N(\\overline{u_i(a)}, \\sigma_i(a)) \\). Las pruebas de este y todos los resultados posteriores se encuentran en el Apéndice. La distribución posterior de la media óptima de n muestras, derivada por Chang y Huang [3], es Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) donde a ∈ A y Φ(·) es la función de distribución N(0, 1). Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilístico que (a) ≤ γ para un γ dado. Ahora, consideramos casos de datos incompletos y utilizamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en los datos) en la distribución de sup{φ∗ (θ)} e inf{φ∗ (θ)} (asumiendo que ambos son alcanzables): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, donde x es un número real y ≤D indica que el límite superior solo considera estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} y {inf{φ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf{φ∗ (θ)} ≤ x}. Los valores así derivados comprenden las Tablas 1 y 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Tabla 1: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando N(θ) es un conjunto de equilibrios de Nash. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Tabla 2: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {150, 200, 320} cuando N(θ) es un conjunto de equilibrios de Nash. Las Tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ(a) < 2.7 es poco probable para cualquier θ del cual tengamos datos, aunque este juicio, como mencionamos, se refiere únicamente a los perfiles que hemos muestreado realmente. Podemos entonces aceptar esto como otra pieza de evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, parece poco probable que el diseñador logre su objetivo incluso si pudiera persuadir a los participantes a jugar un equilibrio deseable. La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM de 2004 eran, de hecho, racionales al adquirir grandes cantidades de componentes al comienzo del juego. Si observamos la tercera columna de esta tabla, que corresponde a θ = 100, podemos deducir que ningún perfil a en nuestros datos con φ(a) < 3 es muy probable que se juegue en equilibrio. Los límites anteriores proporcionan algunas pruebas generales, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos muestreado. Particularmente, nos gustaría decir algo sobre lo que sucede en los ajustes de θ para los cuales no tenemos datos. Para derivar un límite probabilístico aproximado sobre la probabilidad de que ningún θ ∈ Θ haya logrado el objetivo del diseñador, sea ∪J j=1Θj una partición de Θ, y asuma que la función sup{φ∗ (θ)} satisface la condición de Lipschitz con constante de Lipschitz Aj en cada subconjunto Θj. Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a Θ = [0, 320]. Ahora definimos cada subconjunto j como el intervalo entre dos puntos para los cuales hemos producido datos. Por lo tanto, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], con j variando entre 1 y 5, correspondiendo a los subintervalos anteriores. Denotaremos cada Θj por (aj, bj]. Luego, la siguiente proposición nos da una cota superior aproximada sobre la probabilidad de que sup{φ∗ (θ)} ≤ α. PROPOSICIÓN 2. Debido a que nuestros límites son aproximados, no podemos utilizarlos como una evaluación probabilística concluyente. En cambio, tomamos esto como otra pieza de evidencia para complementar nuestros hallazgos. Aunque podamos asumir que una función que aproximamos a partir de datos es Lipschitz continua, rara vez conocemos en realidad la constante de Lipschitz para cualquier subconjunto de Θ. Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de los datos. Aquí, probamos tres métodos para hacer esto. El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subintervalo. Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo. Un método alternativo es tomar un límite superior en la pendiente obtenida dentro de cada subintervalo utilizando los datos disponibles. Esto produce un límite superior de probabilidades mucho menos conservador. Sin embargo, dado que el límite superior real suele ser mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso. Un último método que intentamos es un compromiso entre los dos anteriores. En lugar de tomar el límite superior conservador basado en datos sobre todo el dominio de la función Θ, tomamos el promedio de los límites superiores obtenidos en cada Θj. El límite en un intervalo se toma como el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos. Los resultados de evaluar la expresión para Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3. En términos de nuestras afirmaciones en maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Tabla 3: Límite superior aproximado de la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con un objetivo α = 2. Se utilizan diferentes métodos para aproximar el límite superior de la pendiente en cada subintervalo j. En este trabajo, la expresión proporciona un límite superior a la probabilidad de que alguna configuración de θ (es decir, costo de almacenamiento) en el intervalo [0,320] resulte en una adquisición total del día 0 que no sea mayor en ningún equilibrio que el objetivo especificado por α y tomado aquí como 2. Como sospechábamos, el enfoque más conservador para estimar el límite superior de la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí. Sin embargo, los otros dos enfoques de estimación, encontrados en las columnas dos y tres de la Tabla 3, sugieren que de hecho estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría funcionado. Dada la tremenda dificultad del problema, este resultado es muy sólido. Aun así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia. Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y los conjuntos de estrategias). Tampoco podemos esperar obtener nunca suficiente evidencia para llegar a conclusiones completamente objetivas. En cambio, el enfoque que defendemos aquí es recopilar la mayor cantidad de evidencia posible dadas las limitaciones de recursos, y tomar la decisión más convincente basada en esta evidencia, si es posible. RESULTADOS DE CONVERGENCIA En este punto, exploramos abstractamente si una elección de parámetro de diseño basada en datos de pago puede ser asintóticamente confiable. Dado que no teníamos todas las desviaciones posibles para cualquier perfil disponible en los datos, los verdaderos límites superiores pueden ser aún más bajos. Por conveniencia, utilizaremos la notación un,i(a) para referirnos a una función de pago del jugador i basada en un promedio sobre n muestras i.i.d. de la distribución de pagos. También asumimos que un,i(a) son independientes para todo a ∈ A e i ∈ I. Utilizaremos la notación Γn para referirnos al juego [I, R, {ui,n(·)}], mientras que Γ denotará el juego subyacente, [I, R, {ui(·)}]. De manera similar, definimos n(r) como (r) con respecto al juego Γn. En esta sección, demostramos que n(s) → (s) casi seguramente de forma uniforme en el espacio de estrategias mixtas para cualquier juego finito, y, además, que todas las equilibrios de Nash en estrategias mixtas en juegos empíricos eventualmente se acercan arbitrariamente a algunas estrategias de equilibrio de Nash en el juego subyacente. Utilizamos estos resultados para demostrar que bajo ciertas condiciones, la elección óptima del parámetro de diseño basada en datos empíricos converge casi seguramente al óptimo real. TEOREMA 3. Supongamos que |I| < ∞, |A| < ∞. Entonces n(s) → (s) casi seguramente uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios de Nash de Γ. Si definimos Nn,γ = {s ∈ S : n(s) ≤ γ}, tenemos el siguiente corolario del Teorema 3: COROLARIO 4. Para todo γ > 0, existe un M tal que para todo n ≥ M, N ⊂ Nn,γ casi seguramente. PRUEBA. Dado que n(s) = 0 para todo s ∈ N, podemos encontrar un M lo suficientemente grande tal que Pr{supn≥M sups∈N n(s) < γ} = 1. Según el Corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier > 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios de Nash empíricos si se han tomado suficientes muestras. Como mostramos ahora, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un límite no nulo como una estimación del conjunto de equilibrios de Nash. Primero, supongamos que concluimos que para una configuración particular de θ, sup{ˆφ∗ (θ)} ≤ α. Entonces, dado que para cualquier fijo > 0, N(θ) ⊂ Nn, (θ) cuando n es suficientemente grande, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α para cualquier n de este tipo. Así, dado que definimos la función de bienestar del diseñador como I{sup{φ∗ (θ)} ≤ α} en nuestro dominio de interés, la elección empírica de θ satisface el objetivo del diseñador, maximizando así su función de bienestar. Alternativamente, supongamos que concluimos que inf{ˆφ∗ (θ)} > α para cada θ en el dominio. Entonces, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, para todo θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo del diseñador. Ahora, demostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de Γn está cerca de algún equilibrio de Nash del juego subyacente. Este resultado nos llevará a considerar la convergencia de los optimizadores basados en datos empíricos a los ajustes óptimos reales de los parámetros del mecanismo. Primero notamos que la función (s) es continua en un juego finito. LEMMA 5. \n\nLEMMA 5. Sea S un conjunto de estrategias mixtas definido en un juego finito. Entonces: S → R es continua. Para la exposición que sigue, necesitamos un poco de notación adicional. Primero, sea (Z, d) un espacio métrico, y X, Y ⊂ Z y definamos la distancia de Hausdorff dirigida de X a Y como h(X, Y) = sup x∈X inf y∈Y d(x, y). Observa que U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ). Además, define BS(x, δ) como una bola abierta en S ⊂ Z con centro en x ∈ S y radio δ. Ahora, dejemos que Nn denote todos los equilibrios de Nash del juego Γn y sea Nδ = [ x∈N BS(x, δ), es decir, la unión de bolas abiertas de radio δ con centros en los equilibrios de Nash de Γ. Ten en cuenta que h(Nδ, N) = δ. Podemos entonces demostrar el siguiente resultado general. TEOREMA 6. Supongamos que |I| < ∞ y |A| < ∞. Entonces casi con seguridad h(Nn, N) converge a 0. Ahora demostraremos que en el caso especial cuando Θ y A son finitos y cada Γθ tiene un equilibrio de Nash único, las estimaciones ˆθ del parámetro óptimo del diseñador convergen a un optimizador real casi seguramente. Sea ˆθ = arg maxθ∈Θ W (Nn(θ), θ), donde n es el número de veces que se muestreó cada perfil puro en Γθ para cada θ, y sea θ∗ = arg maxθ∈Θ W (N(θ), θ). TEOREMA 7. Supongamos que |N(θ)| = 1 para todo θ ∈ Θ y supongamos que Θ y A son finitos. Sea W (s, θ) continua en el único s∗ (θ) ∈ N(θ) para cada θ ∈ Θ. Entonces ˆθ es un estimador consistente de θ∗ si W (N(θ), θ) se define como un supremo, ínfimo o esperanza sobre el conjunto de equilibrios de Nash. De hecho, ˆθ → θ∗ casi seguramente en cada uno de estos casos. La limitación del resultado anterior es que, dentro de nuestro marco de trabajo, el diseñador no tiene forma de saber o asegurar que Γθ tenga equilibrios únicos. Sin embargo, sí proporciona cierta justificación teórica para seguir el diseño de esta manera, y quizás servirá como guía para obtener resultados más generales en el futuro. 6. TRABAJO RELACIONADO La literatura de diseño de mecanismos en Economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10]. Además, existe una extensa literatura sobre el diseño óptimo de subastas [10], del cual el trabajo de Roger Myerson [11] es, quizás, el más relevante. En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y teniendo en cuenta restricciones como la compatibilidad de incentivos y la racionalidad individual. Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de Ciencias de la Computación. Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros relevantes del juego son conocimiento común. Cuando las funciones de pago de los jugadores son desconocidas, se ha explorado la realización de búsquedas mediante simulaciones como alternativa. Un enfoque en esa dirección, tomado en [4] y [15], es coevolucionar el parámetro del mecanismo y las estrategias de los agentes, utilizando alguna noción de utilidad social y pagos de los agentes como criterios de aptitud. Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética. En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron un resultado de un juego inducido por un parámetro del mecanismo como el resultado del aprendizaje conjunto de los agentes. Más recientemente, Phelps et al. [14] compararon dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en juegos definidos por estrategias heurísticas, como en [18]. 7. CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el diseño empírico de mecanismos. Definimos un modelo formal de <br>teoría de juegos</br> de interacción entre el diseñador y los participantes del mecanismo como un juego de dos etapas. También describimos en cierta generalidad los métodos para estimar una función de equilibrio de Nash de muestra cuando los datos son extremadamente escasos, o una correspondencia de equilibrio de Nash cuando hay más datos disponibles. Nuestras técnicas están diseñadas específicamente para abordar problemas en los que tanto el espacio de parámetros del mecanismo como los conjuntos de estrategias de los agentes son infinitos y solo se puede adquirir un conjunto de datos relativamente pequeño. Un problema de diseño difícil en el juego TAC/SCM que la comunidad de TAC ha estado ansiosa por abordar nos brinda un escenario para probar nuestros métodos. Al aplicar el análisis empírico del juego al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos. Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia del equilibrio de Nash. Al final, podemos intentar proporcionar suficiente evidencia para prescribir una configuración de parámetros, o sugerir que no es posible encontrar una configuración que satisfaga al diseñador. En el caso de TAC/SCM, nuestra evidencia sugiere bastante claramente que el costo de almacenamiento no pudo haber sido ajustado de manera efectiva en el torneo de 2004 para frenar la adquisición excesiva del día 0 sin efectos perjudiciales en la rentabilidad general. El éxito de nuestro análisis en este entorno extremadamente complejo con altos costos de simulación nos hace ser optimistas de que nuestros métodos pueden brindar orientación en la toma de decisiones de diseño de mecanismos en otros dominios desafiantes. Los resultados teóricos confirman algunas intuiciones detrás de los métodos de diseño de mecanismos empíricos que hemos introducido, y aumentan nuestra confianza en que nuestro marco puede ser efectivo para estimar la mejor elección de parámetros del mecanismo en entornos relativamente generales. Agradecimientos Agradecemos a Terence Kelly, Matthew Rudary y Satinder Singh por sus útiles comentarios sobre versiones anteriores de este trabajo. Este trabajo fue apoyado en parte por la subvención de la NSF IIS-0205435 y el programa de razonamiento estratégico DARPA REAL. 8. REFERENCIAS [1] R. Arunachalam y N. M. Sadeh. La competencia de agentes de comercio de la cadena de suministro. Investigación y aplicaciones del comercio electrónico, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy y M. Tschantz. Un enfoque de programación estocástica para la planificación en TAC SCM. En la Quinta Conferencia ACM sobre Comercio Electrónico, páginas 152-159, Nueva York, 2004. [3] Y.-P. Chang y W.-T. Huang. Intervalos de confianza generalizados para el valor más grande de algunas funciones de parámetros bajo normalidad. Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.\nEstadística Sinica, 10:1369-1383, 2000. [4] D. Cliff. Evolución del mecanismo de mercado a través de un espacio continuo de tipos de subasta. En el Congreso de Computación Evolutiva de 2002. [5] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [6] V. Conitzer y T. Sandholm. Un algoritmo para diseñar automáticamente mecanismos determinísticos sin pagos. En la Tercera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagente, páginas 128-135, 2004. [7] D. Friedman. Juegos evolutivos en economía. Econometrica, 59(3):637-666, mayo de 1991. [8] R. Keener. Teoría Estadística: Una Mezcla de Temas Fundamentales. Departamento de Estadística de la Universidad de Michigan, 2004. [9] C. Kiekintveld, Y. Vorobeychik y M. P. Wellman. Un análisis de la competencia de agentes comerciales de gestión de la cadena de suministro de 2004. En el taller IJCAI-05 sobre Diseño y Análisis de Agentes de Negociación, Edimburgo, 2005. [10] A. Mas-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [11] R. B. Myerson.\nEditorial de la Universidad de Oxford, 1995. [11] R. B. Myerson. Diseño óptimo de subasta. Matemáticas de la Investigación de Operaciones, 6(1):58-73, febrero de 1981. [12] S. Olafsson y J. Kim. Optimización de simulación. En E. Yucesan, C.-H. Chen, J. Snowdon y J. Charnes, editores, Conferencia de Simulación de Invierno 2002, 2002. [13] D. Pardoe y P. Stone. TacTex-03: Un agente de gestión de la cadena de suministro. SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, y P. McBurney. Agentes automatizados versus humanos virtuales: una comparación teórica evolutiva de dos diseños de mercado de subasta doble. En Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney y E. Sklar. Co-evolución de mecanismos de subasta y estrategias de negociación: hacia un enfoque novedoso para el diseño microeconómico. En el taller ECOMAS 2002, 2002. [16] S. Phelps, S. Parsons, E. Sklar y P. McBurney. Utilizando programación genética para optimizar reglas de precios para un mercado de subasta doble. En Taller sobre Agentes para el Comercio Electrónico, 2003. [17] Y. Vorobeychik, M. P. Wellman y S. Singh. Aprendiendo funciones de pago en juegos infinitos. En la Decimonovena Conferencia Internacional Conjunta sobre Inteligencia Artificial, páginas 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro y J. O. Kephart. Analizando interacciones estratégicas complejas en sistemas multiagente. En el taller AAAI-02 sobre agentes teóricos de juegos y de toma de decisiones, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld y V. Soni. Interacciones estratégicas en un juego de cadena de suministro. Inteligencia Computacional, 21(1):1-26, febrero de 2005. APÉNDICE A. PRUEBAS A.1 Prueba de la Proposición 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du. A.2 Prueba de la Proposición 2 Primero, supongamos que alguna función, f(x), definida en [ai, bi], satisface la condición de Lipschitz en (ai, bi] con una constante de Lipschitz Ai. Entonces se cumple la siguiente afirmación: Afirmación: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai). Para demostrar esta afirmación, observe que la intersección de las líneas en f(ai) y f(bi) con pendientes -Ai y Ai respectivamente determinará el límite inferior del mínimo de f(x) en [ai, bi] (que es un límite inferior del ínfimo de f(x) en (ai, bj]). La línea en f(ai) está determinada por f(ai) = −Aiai + cL y la línea en f(bi) está determinada por f(bi) = Aibi + cR. Por lo tanto, las intercepciones son cL = f(ai) + Aiai y cR = f(bi) + Aibi respectivamente. Sea x∗ el punto en el que estas líneas se cruzan. Entonces, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A. Al sustituir las expresiones de cR y cL, obtenemos el resultado deseado. Ahora, la subaditividad nos da Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, y, por la afirmación, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}. Dado que tenemos un número finito de puntos en el conjunto de datos para cada θ, podemos obtener la siguiente expresión: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}. Ahora podemos restringir nuestra atención en obtener una cota superior en Pr{sup{φ∗ (θ)} = y} para un θ fijo. Para hacer esto, observe que Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} por subaditividad y el hecho de que un perfil a es un equilibrio de Nash si y solo si (a) = 0. Poner todo junto produce el resultado deseado. Prueba de Teorema 3 En primer lugar, necesitaremos el siguiente hecho: Afirmación: Dada una función fi(x) y un conjunto X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|. Para demostrar esta afirmación, observe que | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) si maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) si maxx f2(x) ≥ maxx f1(x) En el primer caso, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 De manera similar, en el segundo caso, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|. Por lo tanto, la afirmación se mantiene. Por la Ley Fuerte de los Grandes Números, un,i(a) → ui(a) casi seguramente para todo i ∈ I, a ∈ A. Es decir, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, o, equivalentemente [8], para cualquier α > 0 y δ > 0, existe M(i, a) > 0 tal que Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Al tomar M = maxi∈I maxa∈A M(i, a), tenemos que Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Así, por la afirmación, para cualquier n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ con una probabilidad de al menos 1 − α. Ten en cuenta que dado que s−i(a) y s(a) están acotados entre 0 y 1, pudimos eliminarlos de las expresiones anteriores para obtener una cota que será válida independientemente de la elección particular de s. Además, dado que el resultado anterior se puede obtener para un α arbitrario > 0 y δ > 0, tenemos que Pr{limn→∞ n(s) = (s)} = 1 uniformemente en S. A.4 Prueba del Lema 5 Demostramos el resultado utilizando la continuidad uniforme de ui(s) y la preservación de la continuidad bajo el máximo. Afirmación: Una función f : Rk → R definida por f(t) = Σi=1k zi ti, donde zi son constantes en R, es uniformemente continua en t. La afirmación se sigue porque |f(t)−f(t )| = | Σi=1k zi(ti−ti)| ≤ Σi=1k |zi||ti − ti|. Un resultado inmediato de esto para nuestros propósitos es que ui(s) es uniformemente continua en s y ui(ai, s−i) es uniformemente continua en s−i. Afirmación: Sea f(a, b) uniformemente continua en b ∈ B para cada a ∈ A, con |A| < ∞. Entonces V (b) = maxa∈A f(a, b) es uniformemente continua en b. Para demostrar esto, toma γ > 0 y deja que b, b ∈ B tal que b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ. Ahora toma δ = mina∈A δ(a). Entonces, cada vez que b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ. Ahora, recuerda que (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)]. Según las afirmaciones anteriores, maxai∈Ai ui(ai, s−i) es uniformemente continua en s−i y ui(s) es uniformemente continua en s. Dado que la diferencia de dos funciones uniformemente continuas es uniformemente continua, y dado que esta continuidad se conserva bajo el máximo según nuestra segunda afirmación, obtenemos el resultado deseado. Prueba de Teorema 6. Elija δ > 0. Primero, necesitamos asegurarnos de que se cumple la siguiente afirmación: Afirmación: ¯ = mins∈S\\Nδ (s) existe y ¯ > 0. Dado que Nδ es un subconjunto abierto de S compacto, se sigue que S \\ Nδ es compacto. Como también habíamos demostrado en el Lema 5 que (s) es continua, la existencia se sigue del teorema de Weierstrass. Es claro que ¯ > 0 ya que (s) = 0 si y solo si s es un equilibrio de Nash de Γ. Ahora, por el Teorema 3, para cualquier α > 0 existe un M tal que Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. En consecuencia, para cualquier δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Dado que esto se cumple para un α arbitrario > 0 y δ > 0, se obtiene el resultado deseado. Prueba de Teorema 7. Fija θ y elige δ > 0. Dado que W (s, θ) es continua en s∗ (θ), dado > 0 existe δ > 0 tal que para cada s que esté dentro de δ de s∗ (θ), |W (s, θ) - W (s∗ (θ), θ)| < . Según el Teorema 6, podemos encontrar M(θ) lo suficientemente grande para que todos los s ∈ Nn estén dentro de δ de s∗ (θ) para todo n ≥ M(θ) con probabilidad 1. Por consiguiente, para cualquier > 0 podemos encontrar M(θ) lo suficientemente grande tal que con probabilidad 1 tengamos supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < . Asumamos sin pérdida de generalidad que hay una elección óptima única de θ. Ahora, dado que el conjunto Θ es finito, también existe la segunda mejor opción de θ (si solo hay un θ ∈ Θ, esta discusión no tiene sentido de todos modos): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ). Supongamos sin pérdida de generalidad que θ∗∗ también es único y sea ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ). Entonces, si dejamos < ∆/2 y dejamos que M = maxθ∈Θ M(θ), donde cada M(θ) es lo suficientemente grande como para que supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., la elección óptima de θ basada en cualquier equilibrio empírico será θ∗ con probabilidad 1. Por lo tanto, en particular, dado cualquier distribución de probabilidad sobre equilibrios empíricos, la mejor elección de θ será θ∗ con probabilidad 1 (similarmente, si tomamos el supremo o el ínfimo de W (Nn(θ), θ) sobre el conjunto de equilibrios empíricos al construir la función objetivo). ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "analysis": {
            "translated_key": "análisis",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism <br>analysis</br> models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic <br>analysis</br> of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our <br>analysis</br> focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic <br>analysis</br> to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact <br>analysis</br>.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN <br>analysis</br> Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic <br>analysis</br> methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design <br>analysis</br> methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our <br>analysis</br>6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic <br>analysis</br> of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 <br>analysis</br> of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 <br>analysis</br> of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic <br>analysis</br> Our empirical <br>analysis</br> has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game <br>analysis</br> to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our <br>analysis</br> in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An <br>analysis</br> of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and <br>analysis</br>, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [
                "Our empirical mechanism <br>analysis</br> models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic <br>analysis</br> of design options.",
                "Our <br>analysis</br> focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic <br>analysis</br> to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact <br>analysis</br>."
            ],
            "translated_annotated_samples": [
                "Nuestros modelos de <br>análisis</br> de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado.",
                "El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un <br>análisis</br> más sistemático de las opciones de diseño.",
                "Nuestro <br>análisis</br> se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado.",
                "Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un <br>análisis probabilístico</br> restringido para evaluar la probabilidad de conclusiones.",
                "Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un <br>análisis</br> exacto."
            ],
            "translated_text": "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de <br>análisis</br> de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un <br>análisis</br> más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismos empíricos. En la continuación, desarrollamos algunos métodos generales para el diseño empírico de mecanismos y los aplicamos al problema de rediseño TAC/SCM. Nuestro <br>análisis</br> se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un <br>análisis probabilístico</br> restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un <br>análisis</br> exacto. ",
            "candidates": [],
            "error": [
                [
                    "análisis",
                    "análisis",
                    "análisis",
                    "análisis probabilístico",
                    "análisis"
                ]
            ]
        },
        "nash equilibrium": {
            "translated_key": "equilibrio de Nash",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a <br>nash equilibrium</br>.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a <br>nash equilibrium</br> of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy <br>nash equilibrium</br>; otherwise the definition describes a mixed strategy <br>nash equilibrium</br>.",
                "We often appeal to the concept of an approximate, or -<br>nash equilibrium</br>, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -<br>nash equilibrium</br> iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt <br>nash equilibrium</br> as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the <br>nash equilibrium</br> correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample <br>nash equilibrium</br> using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-<br>nash equilibrium</br>.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the <br>nash equilibrium</br> correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our <br>nash equilibrium</br> estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the <br>nash equilibrium</br> correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -<br>nash equilibrium</br>.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some <br>nash equilibrium</br> strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every <br>nash equilibrium</br> of Γn is close to some <br>nash equilibrium</br> of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique <br>nash equilibrium</br>, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample <br>nash equilibrium</br> function when the data is extremely scarce, or a <br>nash equilibrium</br> correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the <br>nash equilibrium</br> correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a <br>nash equilibrium</br> if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a <br>nash equilibrium</br> of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [
                "A configuration where all agents play strategies that are best responses to the others constitutes a <br>nash equilibrium</br>.",
                "A strategy profile r = (r1, . . . , rm) constitutes a <br>nash equilibrium</br> of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy <br>nash equilibrium</br>; otherwise the definition describes a mixed strategy <br>nash equilibrium</br>.",
                "We often appeal to the concept of an approximate, or -<br>nash equilibrium</br>, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -<br>nash equilibrium</br> iff (r) ≤ ."
            ],
            "translated_annotated_samples": [
                "Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un <br>equilibrio de Nash</br>.",
                "Un perfil estratégico r = (r1, . . . , rm) constituye un <br>equilibrio de Nash</br> del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "Cuando r ∈ A, lo anterior define un <br>equilibrio de Nash</br> de estrategia pura; de lo contrario, la definición describe un <br>equilibrio de Nash</br> de estrategia mixta.",
                "A menudo recurrimos al concepto de un equilibrio aproximado, o <br>equilibrio de Nash</br>, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita.",
                "Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un <br>equilibrio de Nash</br> si (r) ≤ ."
            ],
            "translated_text": "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismos empíricos. En la continuación, desarrollamos algunos métodos generales para el diseño empírico de mecanismos y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto. En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2. Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores. Ri es el conjunto de estrategias disponibles para el jugador i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×. . .×Am. A menudo es conveniente referirse a la estrategia del jugador i por separado de la de los demás jugadores. Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama un perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i). Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el jugador i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada jugador i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i. Podemos extender esta definición a estrategias mixtas asumiendo que ui son utilidades de von Neumann-Morgenstern (vNM) de la siguiente manera: ui(s) = Es[ui], donde Es es la expectativa tomada con respecto a la distribución de probabilidad del juego inducida por la estrategia mixta de los jugadores s. Al emplear la forma normal, modelamos a los agentes jugando una única acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones más detalladas sobre la acción a lo largo del tiempo en la forma extensiva. Aunque cualquier juego extenso puede ser reformulado en forma normal, hacerlo puede sacrificar la concisión y difuminar distinciones relevantes (por ejemplo, la perfección en subjuegos). Ocasionalmente, escribimos ui(x, y) para indicar que x ∈ Ai o Si y y ∈ A−i o S−i dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u(·) = {u1(·), . . . , um(·)}. Definimos una función, : R → R, interpretada como el beneficio máximo que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) donde r pertenece a algún conjunto de estrategias, R, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada aquellas jugadas por los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un <br>equilibrio de Nash</br>. DEFINICIÓN 1. Un perfil estratégico r = (r1, . . . , rm) constituye un <br>equilibrio de Nash</br> del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). Cuando r ∈ A, lo anterior define un <br>equilibrio de Nash</br> de estrategia pura; de lo contrario, la definición describe un <br>equilibrio de Nash</br> de estrategia mixta. A menudo recurrimos al concepto de un equilibrio aproximado, o <br>equilibrio de Nash</br>, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita. Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un <br>equilibrio de Nash</br> si (r) ≤ . ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "empirical mechanism design": {
            "translated_key": "diseño de mecanismos empíricos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>empirical mechanism design</br>: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as <br>empirical mechanism design</br>.",
                "In the sequel, we develop some general methods for <br>empirical mechanism design</br> and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for <br>empirical mechanism design</br>.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the <br>empirical mechanism design</br> methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [
                "<br>empirical mechanism design</br>: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as <br>empirical mechanism design</br>.",
                "In the sequel, we develop some general methods for <br>empirical mechanism design</br> and apply them to the TAC/SCM redesign problem.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for <br>empirical mechanism design</br>.",
                "The theoretical results confirm some intuitions behind the <br>empirical mechanism design</br> methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings."
            ],
            "translated_annotated_samples": [
                "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo.",
                "Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como <br>diseño de mecanismos empíricos</br>.",
                "En la continuación, desarrollamos algunos métodos generales para el <br>diseño empírico de mecanismos</br> y los aplicamos al problema de rediseño TAC/SCM.",
                "CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el <br>diseño empírico de mecanismos</br>.",
                "Los resultados teóricos confirman algunas intuiciones detrás de los métodos de <br>diseño de mecanismos empíricos</br> que hemos introducido, y aumentan nuestra confianza en que nuestro marco puede ser efectivo para estimar la mejor elección de parámetros del mecanismo en entornos relativamente generales."
            ],
            "translated_text": "Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características del resultado de interés como una función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de la cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir ciertos comportamientos de adquisición, pero las medidas resultaron insuficientes. Nuestros modelos de análisis de mecanismos empíricos estudian la relación entre un parámetro clave de diseño y los resultados, confirmando el comportamiento observado e indicando que ninguna configuración razonable de parámetros habría sido probable de lograr el efecto deseado. Más generalmente, demostramos que bajo ciertas condiciones, el estimador del ajuste óptimo de parámetros del mecanismo basado en datos empíricos es consistente. Categorías y Descriptores de Asignaturas I.6 [Metodologías de Computación]: Simulación y Modelado; J.4 [Aplicaciones de Computadora]: Ciencias Sociales y del Comportamiento-Economía Términos Generales Algoritmos, Economía, Diseño 1. MOTIVACIÓN Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de Gestión de la Cadena de Suministro (SCM) de la Competencia de Agentes Comerciales (TAC) de 2003 y 2004. TAC/SCM [1] define un escenario donde los agentes compiten para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes adquieren componentes de varios proveedores y ensamblan productos terminados para vender a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes adquirieran grandes cantidades de componentes el día 0: el comienzo mismo de la simulación. Durante las primeras rondas de la competencia SCM de 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayor parte de sus compras el día 0. Aunque la lucha por la adquisición en el día 0 resultó ser un tema estratégico interesante en sí mismo [19], el fenómeno restó importancia a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica de la producción, las ventas y el inventario. Varios participantes señalaron que la predominancia de la adquisición del día 0 eclipsaba otros temas clave de investigación, como la programación de fábricas y la optimización de ofertas para pedidos de clientes. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir las grandes adquisiciones en el día 0. La tarea que enfrentan los organizadores de juegos puede ser vista como un problema en el diseño de mecanismos. Los diseñadores tienen ciertas características del juego bajo su control, y un conjunto de objetivos relacionados con los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño de mecanismos, el objetivo es una característica conductual (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se considera que requieren solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de una sola vez, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de los entornos de diseño de mecanismos prácticos, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios en las reglas destinados a penalizar los pedidos grandes del día 0. Estos incluyeron modificaciones a las políticas de precios de los proveedores y la introducción de costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición en el día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el GameMaster impuso un aumento quíntuple en los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (según algunas medidas) desde 2003 [9]. La aparente dificultad en identificar modificaciones de reglas que afecten la moderación en la adquisición del día 0 es bastante llamativa. Aunque los diseños fueron ampliamente discutidos, las predicciones sobre los efectos de varias propuestas estaban respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos aproximados. Gran parte de la dificultad, por supuesto, radica en anticipar las respuestas de los agentes (y sus desarrolladores) sin necesariamente llevar a cabo un ejercicio de juego con ese propósito. El episodio nos hizo considerar si nuevos enfoques o herramientas podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de teoría de juegos y diseño de mecanismos son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como <br>diseño de mecanismos empíricos</br>. En la continuación, desarrollamos algunos métodos generales para el <br>diseño empírico de mecanismos</br> y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en el establecimiento de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el obstáculo más directo para la adquisición temprana adoptado. Nuestros resultados confirman la intuición básica de que los incentivos para la compra del día 0 disminuyen a medida que aumentan los costos de almacenamiento. También confirmamos que la alta adquisición observada en el día 0 del torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos a partir de nuestros datos que es muy improbable que cualquier configuración razonable de costos de almacenamiento resulte en niveles aceptables de adquisición en el día 0, por lo que se hubiera requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismos indirectos en entornos donde solo se dispone de una descripción de caja negra de las utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios de Nash y equilibrios de Nash de muestra, utilizados en conjunto para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que la mayoría de los problemas realistas son demasiado complejos para ser susceptibles de un análisis exacto. En consecuencia, abogamos por el enfoque de recopilar evidencia para proporcionar apoyo indirecto a hipótesis específicas. 2. Los preliminares de un juego en forma normal se denotan por [I, {Ri}, {ui(r)}], donde I se refiere al conjunto de jugadores y m = |I| es el número de jugadores. Ri es el conjunto de estrategias disponibles para el jugador i ∈ I, con R = R1 ×. . .×Rm representando el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador i por Ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×. . .×Am. A menudo es conveniente referirse a la estrategia del jugador i por separado de la de los demás jugadores. Para dar cabida a esto, usamos a−i para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre Ai y, de manera similar, S sea el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama un perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son ambos finitos), la probabilidad de que a ∈ A se juegue bajo s se escribe s(a) = s(ai, a−i). Cuando la distribución s no está correlacionada, simplemente podemos decir si(ai) al referirnos a la probabilidad de que el jugador i juegue ai bajo s. A continuación, definimos la función de pago (utilidad) de cada jugador i como ui: A1 ×· · ·×Am → R, donde ui(ai, a−i) indica el pago al jugador i por jugar la estrategia pura ai cuando los demás jugadores juegan a−i. Podemos extender esta definición a estrategias mixtas asumiendo que ui son utilidades de von Neumann-Morgenstern (vNM) de la siguiente manera: ui(s) = Es[ui], donde Es es la expectativa tomada con respecto a la distribución de probabilidad del juego inducida por la estrategia mixta de los jugadores s. Al emplear la forma normal, modelamos a los agentes jugando una única acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones más detalladas sobre la acción a lo largo del tiempo en la forma extensiva. Aunque cualquier juego extenso puede ser reformulado en forma normal, hacerlo puede sacrificar la concisión y difuminar distinciones relevantes (por ejemplo, la perfección en subjuegos). Ocasionalmente, escribimos ui(x, y) para indicar que x ∈ Ai o Si y y ∈ A−i o S−i dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u(·) = {u1(·), . . . , um(·)}. Definimos una función, : R → R, interpretada como el beneficio máximo que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) donde r pertenece a algún conjunto de estrategias, R, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada aquellas jugadas por los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a los demás constituye un equilibrio de Nash. DEFINICIÓN 1. Un perfil estratégico r = (r1, . . . , rm) constituye un equilibrio de Nash del juego [I, {Ri}, {ui(r)}] si para cada i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). Cuando r ∈ A, lo anterior define un equilibrio de Nash de estrategia pura; de lo contrario, la definición describe un equilibrio de Nash de estrategia mixta. A menudo recurrimos al concepto de un equilibrio aproximado, o equilibrio de Nash, donde se encuentra el beneficio máximo para cualquier agente al desviarse de la estrategia prescrita. Por lo tanto, (r) como se define arriba (1) es tal que el perfil r es un equilibrio de Nash si (r) ≤ . En este estudio dedicamos especial atención a los juegos que presentan simetría en cuanto a los pagos, lo que hace que los agentes sean estratégicamente idénticos. DEFINICIÓN 2. Un juego [I, {Ri}, {ui(r)}] es simétrico si para todo i, j ∈ I, (a) Ri = Rj y (b) ui(ri, r−i) = uj (rj, r−j) siempre que ri = rj y r−i = r−j. EL MODELO Modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un juego de dos etapas. El diseñador comienza seleccionando primero un valor, θ, de un conjunto de configuraciones de mecanismos permitidas, Θ. Todos los agentes participantes observan el parámetro θ del mecanismo y se mueven simultáneamente después. Por ejemplo, el diseñador podría estar decidiendo entre mecanismos de subasta de sobre cerrado de precio único y de precio único, con la presunción de que una vez tomada la decisión, los postores participarán con pleno conocimiento de las reglas de la subasta. Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como Γθ = [I, {Ri}, {ui(r, θ)}]. Nos referimos a Γθ como un juego inducido por θ. Sea N(θ) el conjunto de perfiles estratégicos considerados soluciones del juego Γθ.3. Supongamos que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, W(r, θ), dependiente del parámetro del mecanismo y del juego resultante, r. Definimos una medida pesimista, W( ˆR, θ) = inf{W(r, θ) : r ∈ ˆR}, que representa el bienestar en el peor de los casos del juego inducido por θ, asumiendo que los agentes juegan alguna estrategia conjunta en ˆR. Normalmente nos preocupamos por W (N(θ), θ), el resultado en el peor de los casos de jugar alguna solución. En algunos problemas podemos obtener una considerable ventaja al utilizar una función de agregación para mapear el resultado del bienestar de un juego. Generalmente adoptamos el equilibrio de Nash como concepto de solución, y por lo tanto tomamos N(θ) como el conjunto de equilibrios. Sin embargo, gran parte de la metodología desarrollada aquí podría ser utilizada con criterios alternativos para derivar el comportamiento del agente a partir de una definición del juego. Nuevamente, existen alternativas disponibles. Por ejemplo, si se tiene una distribución de probabilidad sobre el conjunto de soluciones N(θ), sería natural tomar la expectativa de W(r, θ) en su lugar. 307 especificado en términos de estrategias de agentes a un resultado de bienestar equivalente especificado en términos de un resumen de menor dimensión. DEFINICIÓN 3. Una función φ: R1 × · · · × Rm → Rq es una función de agregación si m ≥ q y W(r, θ) = V(φ(r), θ) para alguna función V. Sobrecargamos el símbolo de función para aplicar a conjuntos de perfiles estratégicos: φ( ˆR) = {φ(r) : r ∈ ˆR}. Para mayor comodidad en la exposición, escribimos φ∗ (θ) para denotar φ(N(θ)). El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia. Por ejemplo, supongamos, como en nuestra aplicación a continuación, que la estrategia de un agente está definida por un parámetro numérico. Si todo lo que nos importa es el valor total jugado, podemos tomar φ(a) = Πm i=1 ai. Si hemos elegido nuestro agregador cuidadosamente, también podemos capturar estructuras que de otra manera no serían evidentes. Por ejemplo, φ∗ (θ) podría estar disminuyendo en θ, mientras que N(θ) podría tener una estructura más compleja. Dada una descripción de la correspondencia de solución N(θ) (equivalentemente, φ∗(θ)), el diseñador se enfrenta a un problema estándar de optimización. Alternativamente, dado un simulador que pudiera producir una muestra imparcial de la distribución de W (N(θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12]. Sin embargo, incluso para un juego Γθ con pagos conocidos, puede resultar computacionalmente intratable resolver los equilibrios de Nash, especialmente si el juego tiene conjuntos de estrategias grandes o infinitos. Además, deseamos estudiar juegos en los que los pagos no se dan explícitamente, sino que deben determinarse a partir de simulaciones u otra experiencia con el juego. Por lo tanto, asumimos que se nos proporciona un conjunto de datos (posiblemente ruidoso) de realizaciones de pagos: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, donde para cada punto de datos θi es el ajuste observado del parámetro del mecanismo, ai es el perfil de estrategia pura observado de los participantes, y Ui es la realización correspondiente de los pagos de los agentes. También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}. Sea D = {Do, Ds} el conjunto de datos combinado. (Ya sea que Do o Ds puedan ser nulos para un problema particular). En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos empíricos de teoría de juegos, para responder preguntas sobre el diseño del escenario TAC/SCM. 4. ANÁLISIS DE DISEÑO EMPÍRICO Dado que nuestros datos se presentan en forma de experiencia de pago y no como el valor de una función objetivo para configuraciones dadas de la variable de control, ya no podemos confiar en los métodos para optimizar funciones utilizando simulaciones. De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia del equilibrio de Nash. Además, no podemos depender directamente de los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilístico adaptados a nuestra configuración de problema. 4.1 Problema de Diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente. Recuerde que durante el torneo de 2004, los diseñadores del juego de la cadena de suministro optaron por aumentar drásticamente los costos de almacenamiento como medida para frenar las compras del día 0, con poco éxito. Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y la cantidad agregada de componentes adquiridos el día 0 en equilibrio. Esto suele ser el caso en juegos reales de interés, donde descripciones en lenguaje natural o algorítmicas pueden sustituir a una especificación formal de estrategias y funciones de pago. Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo. ¿Primero, ¿el aumento de los costos de almacenamiento realmente reduce la adquisición en el día 0? ¿Fue racional la adquisición excesiva observada durante el día 0 del torneo de 2004? Y en tercer lugar, ¿podría haber reducido de manera suficiente los costos de almacenamiento la adquisición del día 0 a un nivel aceptable, y en tal caso, cuál debería haber sido el ajuste de los costos de almacenamiento? Es esta tercera pregunta la que define el aspecto del diseño de mecanismos de nuestro análisis. Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de los agentes, la función de bienestar de los diseñadores, el espacio de parámetros del mecanismo y la fuente de datos. Restringimos las estrategias de los agentes para que sean un multiplicador de la cantidad de solicitudes del día 0 de uno de los finalistas, Deep Maize, en el torneo TAC/SCM de 2004. Lo restringimos aún más al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias por encima de 1.5 son extremadamente agresivas (por lo tanto, poco probables de proporcionar desviaciones refutadoras más allá de las disponibles en las estrategias incluidas, y ciertamente no forman parte de ningún equilibrio deseable). Todo otro comportamiento se basa en el comportamiento de Deep Maize y es idéntico para todos los agentes. Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico. Sin embargo, creemos que la forma general de los resultados debería ser robusta ante cambios en el comportamiento completo del agente. Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0. Sea φ(a) = Σ6 i=1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego particular de la cadena de suministro (para perfiles de estrategia mixta s, tomamos la esperanza de φ con respecto a la mezcla). La función de bienestar de los diseñadores W (N(θ), θ) se define entonces como I{sup{φ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de adquisición en el día 0 y I es la función indicadora. El diseñador selecciona un valor θ de costos de almacenamiento, expresado como un porcentaje anual del valor base de los componentes en el inventario (cobrado diariamente), del conjunto Θ = R+. Dado que la decisión de los diseñadores depende solo de φ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación. 4.2 Estimación de equilibrios de Nash El objetivo de los agentes de TAC/SCM es maximizar los beneficios obtenidos en una instancia del juego. Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, U(a)). Si también hemos fijado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de jugadores y sus correspondientes pagos, y, en consecuencia, para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios de Nash de cada juego Γθ. Por lo tanto, necesitamos métodos para aproximar equilibrios de Nash en juegos infinitos. A continuación, describimos los dos métodos que utilizamos en nuestro estudio. El primero ha sido explorado empíricamente anteriormente, mientras que el segundo se introduce aquí como el método específicamente diseñado para aproximar un conjunto de equilibrios de Nash. 4.2.1 Aproximación de la Función de Pago El primer método para estimar equilibrios de Nash basado en datos utiliza aprendizaje supervisado para aproximar las funciones de pago de mech6. No abordamos si y cómo otras medidas (por ejemplo, restringir directamente la adquisición) podrían haber logrado los objetivos de diseño. Nuestro enfoque considera como dado un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento. En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con un crecimiento de complejidad correspondiente. 308 participantes del mecanismo de un conjunto de datos de experiencia de juego [17]. Una vez que las funciones de pago aproximadas estén disponibles para todos los jugadores, los equilibrios de Nash pueden encontrarse ya sea de forma analítica o aproximada utilizando técnicas numéricas, dependiendo del modelo de aprendizaje. En lo que sigue, estimamos solo un equilibrio de Nash de muestra utilizando esta técnica, aunque esta restricción puede eliminarse a expensas de un tiempo de cálculo adicional. Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador. Por lo tanto, podemos aplicarlo cuando Ds = ∅. Si hay un simulador disponible, podemos generar datos adicionales para aumentar la confianza en nuestras estimaciones iniciales. Probamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado local (LWA) y regresión lineal ponderada localmente (LWLR). También utilizamos variables de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis empírico previo de teoría de juegos de TAC/SCM-03 [19]. El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido de forma analítica. Para los otros métodos aplicamos dinámica replicadora [7] a una aproximación discreta del juego aprendido. El total esperado de adquisiciones del día 0 en equilibrio se tomó como la estimación de un resultado. 4.2.2 Búsqueda en el Espacio de Perfiles de Estrategia Cuando tenemos acceso a un simulador, también podemos utilizar la búsqueda dirigida a través del espacio de perfiles para estimar el conjunto de equilibrios de Nash, que describimos aquí después de presentar alguna notación adicional. DEFINICIÓN 4. Un vecino estratégico de un perfil de estrategia pura a es un perfil que es idéntico a a en todo menos en una estrategia. Definimos Snb(a, D) como el conjunto de todos los vecinos estratégicos de a disponibles en el conjunto de datos D. De manera similar, definimos Snb(a, ˜D) como todos los vecinos estratégicos de a que no están en D. Finalmente, para cualquier a ∈ Snb(a, D) definimos al agente que se desvía como i(a, a). DEFINICIÓN 5. La -ligadura, ˆ, de un perfil de estrategia pura a se define como maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}. Decimos que a es un candidato a δ-equilibrio para δ ≥ ˆ. Cuando Snb(a, ˜D) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), a se confirma como un equilibrio de Nash ˆ. Nuestro método de búsqueda opera explorando desviaciones de los equilibrios candidatos. Nos referimos a esto como BestFirstSearch, ya que selecciona con probabilidad uno un perfil de estrategia a ∈ Snb(a, ˜D) que tiene el menor ˆin D. Finalmente definimos un estimador para un conjunto de equilibrios de Nash. DEFINICIÓN 6. Para un conjunto K, define Co(K) como la envoltura convexa de K. Sea Bδ el conjunto de candidatos en el nivel δ. Definimos ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) para un δ fijo como un estimador de φ∗ (θ). En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles estratégicos agregados con límite inferior -bound por debajo de un δ fijo. Esta definición nos permite explotar la estructura que surge de la función de agregación. Si dos perfiles son cercanos en términos de valores de agregación, es probable que tengan límites similares. En particular, si uno está en equilibrio, el otro también puede estarlo. Presentamos un respaldo teórico para este método de estimación del conjunto de equilibrios de Nash a continuación. Dado que el juego en el que estamos interesados es infinito, es necesario terminar BestFirstSearch antes de explorar todo el espacio de strat7. Por ejemplo, podemos utilizar técnicas de aprendizaje activo [5] para mejorar la calidad de la aproximación de la función de recompensa. En este trabajo, nos concentramos en la búsqueda en el espacio de perfiles estratégicos. Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos. Generación de datos Nuestros datos fueron recopilados simulando juegos TAC/SCM en una versión local del servidor TAC/SCM de 2004, que tiene una configuración para el costo de almacenamiento. Las estrategias de los agentes en juegos simulados fueron seleccionadas del conjunto {0, 0.3, 0.6, . . . , 1.5} con el fin de tener una probabilidad positiva de generar vecinos estratégicos. Se generó un conjunto de datos base Do mediante el muestreo de 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}. Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varios defectos. Utilizamos la búsqueda para generar un conjunto de datos simulados Ds, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ. Dado que el costo de la simulación es extremadamente alto (un juego tarda casi 1 hora en ejecutarse), pudimos ejecutar un total de 2670 juegos en el transcurso de más de seis meses. Para hacer una comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategias conjuntas finitas restringidas para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces). 4.4 Resultados 4.4.1 Análisis del conjunto de datos base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos base Do. Además, generamos una estimación de la correspondencia del equilibrio de Nash, ˆφ∗ (θ), aplicando la Definición 6 con δ = 2.5E6. Los resultados se muestran en la Figura 1. Como podemos ver, la correspondencia ˆφ∗ (θ) tiene poco poder predictivo basado en Do, y no revela ninguna estructura interesante sobre el juego. Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición Total Día 0 LWA LWLR QR BaselineMin BaselineMax Figura 1: Estimaciones de adquisición del día 0 agregadas basadas en Do. La correspondencia ˆφ∗ (θ) es el intervalo entre BaselineMin y BaselineMax. En general, la búsqueda se detiene una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para obtener conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego. Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash a permanecer en este subconjunto discreto de [0,1.5]. Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron accidentes, problemas de conectividad de red y otras anomalías obvias), el juego sería descartado. Análisis de los datos de búsqueda Para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ∗ (θ) (nuevamente, usando δ =2.5E6) en el conjunto de datos D = {Do, Ds}, donde Ds es datos generados a través de la aplicación de BestFirstSearch. Los resultados de esta estimación se representan gráficamente frente a los resultados de los métodos de aprendizaje entrenados en Do 11 en la Figura 2. Primero, observamos que la adición de los datos de búsqueda reduce considerablemente el rango de posibles equilibrios. Además, las predicciones puntuales reales de los métodos de aprendizaje y aquellas basadas en límites después de la búsqueda son razonablemente cercanas. Combinar la evidencia recopilada de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquiera de los métodos utilizados de forma aislada. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de Almacenamiento Adquisición del Día 0 LWA LWLR QR Búsqueda Mínima Búsqueda Máxima Figura 2: Estimaciones agregadas de adquisición del día 0 basadas en la búsqueda en el espacio de perfiles de estrategia en comparación con técnicas de aproximación de funciones entrenadas en Do. La correspondencia ˆφ∗ (θ) para D = {Do, Ds} es el intervalo entre SearchMin y SearchMax. Esta evidencia respalda la intuición inicial de que la adquisición del día 0 debería disminuir con los costos de almacenamiento. También confirma que los altos niveles de adquisición en el día 0 son una respuesta racional al entorno del torneo de 2004 con un costo promedio de almacenamiento, que corresponde a θ = 100. La predicción mínima para la adquisición agregada en este nivel de costos de almacenamiento, dada por cualquier método experimental, es aproximadamente 3. Esto es bastante alto, ya que corresponde a un compromiso esperado del 1/3 de la capacidad total del proveedor para todo el juego. La predicción máxima es considerablemente mayor a 4.5. En la competencia actual de 2004, la adquisición total del día 0 equivalía a 5.71 en la escala utilizada aquí [9]. Nuestras predicciones subestiman este resultado en cierta medida, pero muestran que cualquier resultado racional probablemente tendría una alta adquisición en el día 0. 4.4.3 Extrapolando la Correspondencia de la Solución Tenemos evidencia razonablemente sólida de que la correspondencia del resultado está disminuyendo. Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento a un valor que reduciría la adquisición del día 0 en equilibrio, o concluir que esto no es posible. Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día 0. No está claro cuán significativos serían los resultados del aprendizaje si se agregaran Ds al conjunto de datos de entrenamiento. De hecho, los datos adicionales pueden aumentar realmente la varianza del aprendizaje. Recuerde que el objetivo de los diseñadores es incentivar la adquisición agregada del día 0 que esté por debajo del umbral α. Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultados estimada a partir de D que produce θ = 320. Los datos para θ = 320 fueron recopilados de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos por 33 iteraciones de BestFirstSearch. La Figura 3 muestra los límites detallados para todos los perfiles en términos de sus valores correspondientes de φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Límites de ε de Adquisición Total Día-0 Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320. Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ(a). La región gris corresponde a ˆφ∗ (320) con δ = 2.5M. El conjunto estimado de resultados agregados del día 0 es muy cercano al de θ = 200, lo que indica que hay poco beneficio adicional al aumentar los costos de almacenamiento por encima de 200. Observa que incluso el límite inferior de nuestro conjunto estimado de equilibrios de Nash está muy por encima de la adquisición objetivo del día 0 de 2. Además, las recompensas para los agentes son casi siempre negativas en θ = 320. Por consiguiente, aumentar los costos aún más sería indeseable incluso si finalmente se pudiera reducir la adquisición en el día 0. Dado que tenemos una confianza razonable de que φ∗ (θ) está disminuyendo en θ, tampoco esperamos que establecer θ en algún lugar entre 200 y 320 logre el resultado deseado. Concluimos que es poco probable que la adquisición del día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento. Que nuestras predicciones tienden a subestimar los resultados del torneo refuerza esta conclusión. Para lograr la reducción deseada en la adquisición del día 0 se requiere rediseñar otros aspectos del mecanismo. 4.5 Análisis Probabilístico Nuestro análisis empírico ha producido evidencia en apoyo a la conclusión de que ninguna configuración razonable del costo de almacenamiento probablemente sería suficiente para frenar la adquisición excesiva del día 0 en TAC/SCM 04. Toda esta evidencia ha sido en forma de simple interpolación y extrapolación de estimaciones de la correspondencia del equilibrio de Nash. Estas estimaciones se basan en simular instancias del juego y están sujetas a ruido de muestreo contribuido por los diversos elementos estocásticos del juego. En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos -bound a tales efectos estocásticos. Supongamos que todos los agentes tienen conjuntos de estrategias puras finitos (y pequeños), A. Por lo tanto, es factible muestrear toda la matriz de pagos del juego. Además, supongamos que el ruido es aditivo con media cero en promedio durante todo el juego, por lo que en la práctica probablemente querríamos que el umbral sea aún más bajo. 310 y varianza finita, es decir, Ui(a) = ui(a) + ˜ξi(a), donde Ui(a) es la ganancia observada para i cuando se jugó a, ui(a) es la ganancia correspondiente real, y ˜ξi(a) es una variable aleatoria normal con media cero. Designamos la varianza conocida de ˜ξi(a) como σ2 i (a). Por lo tanto, asumimos que ˜ξi(a) es normal con distribución N(0, σ2 i (a)). Tomamos ¯ui(a) como la media muestral de todos los Ui(a) en D, y seguimos a Chang y Huang [3] al asumir que tenemos una priori impropia sobre las ganancias reales ui(a) y el muestreo fue independiente para todos i y a. También confiamos en su resultado de que ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] son independientes con distribuciones posteriores N(¯ui(a), σ2 i (a)/ni(a)), donde ni(a) es el número de muestras tomadas de los pagos para i en el perfil puro a, y Zi(a) ∼ N(0, 1). Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio de Nash -Nash. Si ui(·)|¯ui(·) son independientes para todo i ∈ I y a ∈ A, tenemos el siguiente resultado (a partir de este punto omitimos la condición sobre ¯ui(·) por brevedad): PROPOSICIÓN 1. Para todo \\( i \\in I \\), \\( \\max_{b \\in A_i} u_i(b, a_{-i}) - u_i(a) \\leq \\varepsilon \\), donde \\( \\varepsilon = \\int_{Y_i} \\int_{Z} \\int_{R} \\int_{Y} \\int_{b \\in A_i \\backslash a_i} \\Pr(u_i(b, a_{-i}) \\leq u + \\varepsilon) f_{u_i(a)}(u) du \\), donde \\( f_{u_i(a)}(u) \\) es la función de densidad de probabilidad de \\( N(\\overline{u_i(a)}, \\sigma_i(a)) \\). Las pruebas de este y todos los resultados posteriores se encuentran en el Apéndice. La distribución posterior de la media óptima de n muestras, derivada por Chang y Huang [3], es Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) donde a ∈ A y Φ(·) es la función de distribución N(0, 1). Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilístico que (a) ≤ γ para un γ dado. Ahora, consideramos casos de datos incompletos y utilizamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en los datos) en la distribución de sup{φ∗ (θ)} e inf{φ∗ (θ)} (asumiendo que ambos son alcanzables): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, donde x es un número real y ≤D indica que el límite superior solo considera estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} y {inf{φ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf{φ∗ (θ)} ≤ x}. Los valores así derivados comprenden las Tablas 1 y 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Tabla 1: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando N(θ) es un conjunto de equilibrios de Nash. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Tabla 2: Límites superiores en la distribución de inf{φ∗ (θ)} restringida a D para θ ∈ {150, 200, 320} cuando N(θ) es un conjunto de equilibrios de Nash. Las Tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ(a) < 2.7 es poco probable para cualquier θ del cual tengamos datos, aunque este juicio, como mencionamos, se refiere únicamente a los perfiles que hemos muestreado realmente. Podemos entonces aceptar esto como otra pieza de evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, parece poco probable que el diseñador logre su objetivo incluso si pudiera persuadir a los participantes a jugar un equilibrio deseable. La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM de 2004 eran, de hecho, racionales al adquirir grandes cantidades de componentes al comienzo del juego. Si observamos la tercera columna de esta tabla, que corresponde a θ = 100, podemos deducir que ningún perfil a en nuestros datos con φ(a) < 3 es muy probable que se juegue en equilibrio. Los límites anteriores proporcionan algunas pruebas generales, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos muestreado. Particularmente, nos gustaría decir algo sobre lo que sucede en los ajustes de θ para los cuales no tenemos datos. Para derivar un límite probabilístico aproximado sobre la probabilidad de que ningún θ ∈ Θ haya logrado el objetivo del diseñador, sea ∪J j=1Θj una partición de Θ, y asuma que la función sup{φ∗ (θ)} satisface la condición de Lipschitz con constante de Lipschitz Aj en cada subconjunto Θj. Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a Θ = [0, 320]. Ahora definimos cada subconjunto j como el intervalo entre dos puntos para los cuales hemos producido datos. Por lo tanto, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], con j variando entre 1 y 5, correspondiendo a los subintervalos anteriores. Denotaremos cada Θj por (aj, bj]. Luego, la siguiente proposición nos da una cota superior aproximada sobre la probabilidad de que sup{φ∗ (θ)} ≤ α. PROPOSICIÓN 2. Debido a que nuestros límites son aproximados, no podemos utilizarlos como una evaluación probabilística concluyente. En cambio, tomamos esto como otra pieza de evidencia para complementar nuestros hallazgos. Aunque podamos asumir que una función que aproximamos a partir de datos es Lipschitz continua, rara vez conocemos en realidad la constante de Lipschitz para cualquier subconjunto de Θ. Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de los datos. Aquí, probamos tres métodos para hacer esto. El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subintervalo. Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo. Un método alternativo es tomar un límite superior en la pendiente obtenida dentro de cada subintervalo utilizando los datos disponibles. Esto produce un límite superior de probabilidades mucho menos conservador. Sin embargo, dado que el límite superior real suele ser mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso. Un último método que intentamos es un compromiso entre los dos anteriores. En lugar de tomar el límite superior conservador basado en datos sobre todo el dominio de la función Θ, tomamos el promedio de los límites superiores obtenidos en cada Θj. El límite en un intervalo se toma como el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos. Los resultados de evaluar la expresión para Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3. En términos de nuestras afirmaciones en maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Tabla 3: Límite superior aproximado de la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con un objetivo α = 2. Se utilizan diferentes métodos para aproximar el límite superior de la pendiente en cada subintervalo j. En este trabajo, la expresión proporciona un límite superior a la probabilidad de que alguna configuración de θ (es decir, costo de almacenamiento) en el intervalo [0,320] resulte en una adquisición total del día 0 que no sea mayor en ningún equilibrio que el objetivo especificado por α y tomado aquí como 2. Como sospechábamos, el enfoque más conservador para estimar el límite superior de la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí. Sin embargo, los otros dos enfoques de estimación, encontrados en las columnas dos y tres de la Tabla 3, sugieren que de hecho estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría funcionado. Dada la tremenda dificultad del problema, este resultado es muy sólido. Aun así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia. Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y los conjuntos de estrategias). Tampoco podemos esperar obtener nunca suficiente evidencia para llegar a conclusiones completamente objetivas. En cambio, el enfoque que defendemos aquí es recopilar la mayor cantidad de evidencia posible dadas las limitaciones de recursos, y tomar la decisión más convincente basada en esta evidencia, si es posible. RESULTADOS DE CONVERGENCIA En este punto, exploramos abstractamente si una elección de parámetro de diseño basada en datos de pago puede ser asintóticamente confiable. Dado que no teníamos todas las desviaciones posibles para cualquier perfil disponible en los datos, los verdaderos límites superiores pueden ser aún más bajos. Por conveniencia, utilizaremos la notación un,i(a) para referirnos a una función de pago del jugador i basada en un promedio sobre n muestras i.i.d. de la distribución de pagos. También asumimos que un,i(a) son independientes para todo a ∈ A e i ∈ I. Utilizaremos la notación Γn para referirnos al juego [I, R, {ui,n(·)}], mientras que Γ denotará el juego subyacente, [I, R, {ui(·)}]. De manera similar, definimos n(r) como (r) con respecto al juego Γn. En esta sección, demostramos que n(s) → (s) casi seguramente de forma uniforme en el espacio de estrategias mixtas para cualquier juego finito, y, además, que todas las equilibrios de Nash en estrategias mixtas en juegos empíricos eventualmente se acercan arbitrariamente a algunas estrategias de equilibrio de Nash en el juego subyacente. Utilizamos estos resultados para demostrar que bajo ciertas condiciones, la elección óptima del parámetro de diseño basada en datos empíricos converge casi seguramente al óptimo real. TEOREMA 3. Supongamos que |I| < ∞, |A| < ∞. Entonces n(s) → (s) casi seguramente uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios de Nash de Γ. Si definimos Nn,γ = {s ∈ S : n(s) ≤ γ}, tenemos el siguiente corolario del Teorema 3: COROLARIO 4. Para todo γ > 0, existe un M tal que para todo n ≥ M, N ⊂ Nn,γ casi seguramente. PRUEBA. Dado que n(s) = 0 para todo s ∈ N, podemos encontrar un M lo suficientemente grande tal que Pr{supn≥M sups∈N n(s) < γ} = 1. Según el Corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier > 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios de Nash empíricos si se han tomado suficientes muestras. Como mostramos ahora, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un límite no nulo como una estimación del conjunto de equilibrios de Nash. Primero, supongamos que concluimos que para una configuración particular de θ, sup{ˆφ∗ (θ)} ≤ α. Entonces, dado que para cualquier fijo > 0, N(θ) ⊂ Nn, (θ) cuando n es suficientemente grande, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α para cualquier n de este tipo. Así, dado que definimos la función de bienestar del diseñador como I{sup{φ∗ (θ)} ≤ α} en nuestro dominio de interés, la elección empírica de θ satisface el objetivo del diseñador, maximizando así su función de bienestar. Alternativamente, supongamos que concluimos que inf{ˆφ∗ (θ)} > α para cada θ en el dominio. Entonces, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, para todo θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo del diseñador. Ahora, demostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de Γn está cerca de algún equilibrio de Nash del juego subyacente. Este resultado nos llevará a considerar la convergencia de los optimizadores basados en datos empíricos a los ajustes óptimos reales de los parámetros del mecanismo. Primero notamos que la función (s) es continua en un juego finito. LEMMA 5. \n\nLEMMA 5. Sea S un conjunto de estrategias mixtas definido en un juego finito. Entonces: S → R es continua. Para la exposición que sigue, necesitamos un poco de notación adicional. Primero, sea (Z, d) un espacio métrico, y X, Y ⊂ Z y definamos la distancia de Hausdorff dirigida de X a Y como h(X, Y) = sup x∈X inf y∈Y d(x, y). Observa que U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ). Además, define BS(x, δ) como una bola abierta en S ⊂ Z con centro en x ∈ S y radio δ. Ahora, dejemos que Nn denote todos los equilibrios de Nash del juego Γn y sea Nδ = [ x∈N BS(x, δ), es decir, la unión de bolas abiertas de radio δ con centros en los equilibrios de Nash de Γ. Ten en cuenta que h(Nδ, N) = δ. Podemos entonces demostrar el siguiente resultado general. TEOREMA 6. Supongamos que |I| < ∞ y |A| < ∞. Entonces casi con seguridad h(Nn, N) converge a 0. Ahora demostraremos que en el caso especial cuando Θ y A son finitos y cada Γθ tiene un equilibrio de Nash único, las estimaciones ˆθ del parámetro óptimo del diseñador convergen a un optimizador real casi seguramente. Sea ˆθ = arg maxθ∈Θ W (Nn(θ), θ), donde n es el número de veces que se muestreó cada perfil puro en Γθ para cada θ, y sea θ∗ = arg maxθ∈Θ W (N(θ), θ). TEOREMA 7. Supongamos que |N(θ)| = 1 para todo θ ∈ Θ y supongamos que Θ y A son finitos. Sea W (s, θ) continua en el único s∗ (θ) ∈ N(θ) para cada θ ∈ Θ. Entonces ˆθ es un estimador consistente de θ∗ si W (N(θ), θ) se define como un supremo, ínfimo o esperanza sobre el conjunto de equilibrios de Nash. De hecho, ˆθ → θ∗ casi seguramente en cada uno de estos casos. La limitación del resultado anterior es que, dentro de nuestro marco de trabajo, el diseñador no tiene forma de saber o asegurar que Γθ tenga equilibrios únicos. Sin embargo, sí proporciona cierta justificación teórica para seguir el diseño de esta manera, y quizás servirá como guía para obtener resultados más generales en el futuro. 6. TRABAJO RELACIONADO La literatura de diseño de mecanismos en Economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10]. Además, existe una extensa literatura sobre el diseño óptimo de subastas [10], del cual el trabajo de Roger Myerson [11] es, quizás, el más relevante. En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y teniendo en cuenta restricciones como la compatibilidad de incentivos y la racionalidad individual. Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de Ciencias de la Computación. Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros relevantes del juego son conocimiento común. Cuando las funciones de pago de los jugadores son desconocidas, se ha explorado la realización de búsquedas mediante simulaciones como alternativa. Un enfoque en esa dirección, tomado en [4] y [15], es coevolucionar el parámetro del mecanismo y las estrategias de los agentes, utilizando alguna noción de utilidad social y pagos de los agentes como criterios de aptitud. Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética. En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron un resultado de un juego inducido por un parámetro del mecanismo como el resultado del aprendizaje conjunto de los agentes. Más recientemente, Phelps et al. [14] compararon dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en juegos definidos por estrategias heurísticas, como en [18]. 7. CONCLUSIÓN En este trabajo dedicamos un esfuerzo considerable al desarrollo de tácticas generales para el <br>diseño empírico de mecanismos</br>. Definimos un modelo formal de teoría de juegos de interacción entre el diseñador y los participantes del mecanismo como un juego de dos etapas. También describimos en cierta generalidad los métodos para estimar una función de equilibrio de Nash de muestra cuando los datos son extremadamente escasos, o una correspondencia de equilibrio de Nash cuando hay más datos disponibles. Nuestras técnicas están diseñadas específicamente para abordar problemas en los que tanto el espacio de parámetros del mecanismo como los conjuntos de estrategias de los agentes son infinitos y solo se puede adquirir un conjunto de datos relativamente pequeño. Un problema de diseño difícil en el juego TAC/SCM que la comunidad de TAC ha estado ansiosa por abordar nos brinda un escenario para probar nuestros métodos. Al aplicar el análisis empírico del juego al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos. Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia del equilibrio de Nash. Al final, podemos intentar proporcionar suficiente evidencia para prescribir una configuración de parámetros, o sugerir que no es posible encontrar una configuración que satisfaga al diseñador. En el caso de TAC/SCM, nuestra evidencia sugiere bastante claramente que el costo de almacenamiento no pudo haber sido ajustado de manera efectiva en el torneo de 2004 para frenar la adquisición excesiva del día 0 sin efectos perjudiciales en la rentabilidad general. El éxito de nuestro análisis en este entorno extremadamente complejo con altos costos de simulación nos hace ser optimistas de que nuestros métodos pueden brindar orientación en la toma de decisiones de diseño de mecanismos en otros dominios desafiantes. Los resultados teóricos confirman algunas intuiciones detrás de los métodos de <br>diseño de mecanismos empíricos</br> que hemos introducido, y aumentan nuestra confianza en que nuestro marco puede ser efectivo para estimar la mejor elección de parámetros del mecanismo en entornos relativamente generales. ",
            "candidates": [],
            "error": [
                [
                    "diseño de mecanismos empíricos",
                    "diseño empírico de mecanismos",
                    "diseño empírico de mecanismos",
                    "diseño de mecanismos empíricos"
                ]
            ]
        },
        "game theory": {
            "translated_key": "teoría de juegos",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        }
    }
}